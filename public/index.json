[{"content":"üëã About me I\u0026rsquo;m \u0026hellip;\nüìö Education üá≠üá∞ The University of Hong Kong 09/2024 - Expected 11/2025 School of Computing and Data Science Master of Science in Electronic Commerce \u0026amp; Internet Computing Relevant Courses: Machine learning for business and e-commerce, Knowledge graphs, Financial fraud analytics, Internet infrastructure technologies, Website engineering, Blockchain and cryptocurrency, etc. üá®üá≥ Beijing Institute of Technology 09/2020 - 06/2024 School of Computer Science \u0026amp; Technology Bachelor of Engineering in Software Engineering, last two years GPA: 3.7/4 Relevant Courses: Reinforcement Learning, Deep Learning and Computer Vision, Artificial Intelligence and Robot Ethics, Almost Human: Mind, Brain and Artificial Intelligence, Mathematical Analysis for Engineering, Linear Algebra, Probability and Mathematical Statistics, etc. Skills: Python, Java, common data structures, design patterns, machine learning basics and algorithms, Linux, PyTorch, and some development tools (git, conda, etc.). üèÜ Awards \u0026amp; Honors Beijing Institute of Technology Undergraduate Scholarship (Top 20% of Grade) 06/2023 3rd Prize of China International \u0026#34;Internet \u0026#43;\u0026#34; College Student\u0026#39;s Innovation Competition 08/2022 Bronze Prize of \u0026#34;Challenge Cup\u0026#34; Capital University Entrepreneurship Competition 05/2022 üíº Project Experience Online Transaction Fraud Detection 09/2024 ‚Äì 01/2025 Independent project, supervised by Dr. Vivien Chan Focused on addressing financial fraud in e-commerce to enhance the accuracy of transaction anomaly detection, while independently managing the entire case study that included data preprocessing, feature engineering, model building, evaluation, and results analysis. Effectively resolved class imbalance issues using SMOTE and ROSE techniques. Built various models including Logistic Regression, Random Forest, XGBoost, and LightGBM, ultimately selecting the LightGBM model to achieve a recall rate of 95.45% and an AUC of 99.84%. Wrote efficient and maintainable code, enhancing model training and data processing efficiency through parallel computing and logging. Multi-Model Intelligent Text Keyword Extraction System 08/2023 ‚Äì 09/2023 Group project, supervised by Associate Prof. Xiaolin Zhao Designed and implemented an intelligent text summary system that automatically extracts keywords from article titles and abstracts, enhancing the understanding and summarization of text information. Participated in the planning of the technical route and built a hybrid model combining extractive and generative approaches, utilizing advanced natural language processing techniques including KeyBERT, Sentence Transformer, BERT, and T5 models. Responsible for data preprocessing and tokenization, as well as the end-to-end implementation and training of the T5 model, optimizing the model architecture and hyperparameters, achieving satisfactory results after only 3 epochs of training. Model evaluation results showed that the Rouge-1, Rouge-2, and Rouge-L metrics reached 0.6345, 0.5038, and 0.5282, respectively, in the third epoch, validating the model\u0026rsquo;s effectiveness in the summarization task. Cambridge University Machine Learning Summer Project 07/2023 ‚Äì 08/2023 Group project, supervised by Prof. Pietro Li√≤ Participated in the Cambridge University deep learning summer project, focusing on deep reinforcement learning; explored multi-agent learning algorithms across different environments. Reproduced the Multi-Agent Deep Deterministic Policy Gradient (MADDPG) algorithm in the Simple Adversary environment and studied the effect of agent numbers on convergence speed and stability, finding optimal stability at 21 agents. Designed and implemented comparative experiments inspired by the Rainbow algorithm, assessing target network strategies versus the Double Deep Q-Network (Double DQN). The results demonstrated that Double DQN significantly enhanced convergence speed, optimizing the overall learning process. Co-authored a group project paper on agent numbers and strategies effectiveness in multi-agent systems, achieving a score of 71% in the summer program (the highest in my group) and a \u0026ldquo;First Class\u0026rdquo; classification in the UK grading system. Deep Learning and Computer Vision Semester Project 09/2022 ‚Äì 12/2022 Independent project, supervised by Associate Prof. Guangyu Gao Designed and implemented a waste classifier using the ResNet model to improve classification accuracy and reduce resource waste. The project also enhanced understanding of transfer learning techniques with ResNet. Collected a dataset of 16 waste categories and preprocessed the images for uniformity and standardization, incorporating data augmentation techniques to enhance the dataset. Conducted experiments using ResNet34 and ResNet50 models through transfer learning, accelerating network convergence by leveraging pretrained weights. During training, techniques such as Batch Normalization and Dropout were applied to mitigate the risk of overfitting. The final model achieved an accuracy of 90% on the training set, while the performance on the test set was 61%, indicating a significant overfitting phenomenon during the training process. üéì Internship Beijing Academy of Quantum Information Science 08/2023 ‚Äì 01/2024 Research Intern at Quantum Computation Department Proposed a quantum convolution kernel design based on variational quantum circuits and developed a universal quantum convolution layer, successfully integrating it into classical CNN architectures such as VGG, GoogLeNet, and ResNet. Developed and evaluated various hybrid models, including a simple model named HQCCNN-2, which achieved 84.45% accuracy on the FashionMNIST dataset, surpassing the traditional CNN\u0026rsquo;s 80.72%. This demonstrates the effectiveness of the quantum convolution layer in improving model performance. Tested on a real quantum computer further validated the effectiveness of the hybrid model, demonstrating the viable integration of quantum computing with deep learning, and highlighting the potential for leveraging quantum properties to enhance model performance. üèÖ Competition Experience China International \u0026#34;Internet \u0026#43;\u0026#34; College Students\u0026#39; Innovation Competition 08/2022 Zhongke Ushield: Deep Learning-based Face Privacy Protection Authentication System Responsible for constructing a localized facial feature extraction engine based on MobileFaceNet, ensuring feature extraction is completed on end devices (such as mobile phones and cameras), guaranteeing that raw data does not leave the domain and is not stored, thus enhancing user privacy protection while improving recognition efficiency. \u0026#34;Challenge Cup\u0026#34; Capital University Entrepreneurship Competition 05/2022 Smart Orchard Responsible for the development of the fruit detection, ripeness prediction, and pest identification system, using deep convolutional neural network (CNN) technology for intelligent monitoring of crop growth conditions. Applied advanced object detection algorithms such as Faster R-CNN and YOLO to achieve high precision in apple detection and ripeness assessment, with an accuracy rate exceeding 90%, significantly enhancing the intelligence level of orchard management. Built and trained a dedicated dataset containing various pest samples, optimizing pest detection accuracy through data preprocessing (such as image normalization and resizing) and data augmentation techniques (like rotation, flipping, and noise addition), enabling the real-time monitoring system to accurately identify over 80% of pests, providing effective scientific maintenance recommendations to help farmers reduce crop losses. üìã Extracurricular Activities Vice President, Cyber Security Club, Beijing Institute of Technology 09/2021-09/2022 Backbone, Media Center of the Student Union of Beijing Institute of Technology 10/2020-06/2021 üì´ Contact üìß zongsi.xu@outlook.com üëî Zongsi (Tristan) Xu üíª github.com/BaizeXS üìç Hong Kong SAR, China ","permalink":"http://localhost:1313/resume/","summary":"Personal resume of Zongsi (Tristan) Xu","title":"Zongsi (Tristan) Xu"},{"content":"üëã About me I\u0026rsquo;m \u0026hellip;\nüìö Education üá≠üá∞ The University of Hong Kong 09/2024 - Expected 11/2025 School of Computing and Data Science Master of Science in Electronic Commerce \u0026amp; Internet Computing Relevant Courses: Machine learning for business and e-commerce, Knowledge graphs, Financial fraud analytics, Internet infrastructure technologies, Website engineering, Blockchain and cryptocurrency, etc. üá®üá≥ Beijing Institute of Technology 09/2020 - 06/2024 School of Computer Science \u0026amp; Technology Bachelor of Engineering in Software Engineering, last two years GPA: 3.7/4 Relevant Courses: Reinforcement Learning, Deep Learning and Computer Vision, Artificial Intelligence and Robot Ethics, Almost Human: Mind, Brain and Artificial Intelligence, Mathematical Analysis for Engineering, Linear Algebra, Probability and Mathematical Statistics, etc. Skills: Python, Java, common data structures, design patterns, machine learning basics and algorithms, Linux, PyTorch, and some development tools (git, conda, etc.). üèÜ Awards \u0026amp; Honors Beijing Institute of Technology Undergraduate Scholarship (Top 20% of Grade) 06/2023 3rd Prize of China International \u0026#34;Internet \u0026#43;\u0026#34; College Student\u0026#39;s Innovation Competition 08/2022 Bronze Prize of \u0026#34;Challenge Cup\u0026#34; Capital University Entrepreneurship Competition 05/2022 üíº Project Experience Online Transaction Fraud Detection 09/2024 ‚Äì 01/2025 Independent project, supervised by Dr. Vivien Chan Focused on addressing financial fraud in e-commerce to enhance the accuracy of transaction anomaly detection, while independently managing the entire case study that included data preprocessing, feature engineering, model building, evaluation, and results analysis. Effectively resolved class imbalance issues using SMOTE and ROSE techniques. Built various models including Logistic Regression, Random Forest, XGBoost, and LightGBM, ultimately selecting the LightGBM model to achieve a recall rate of 95.45% and an AUC of 99.84%. Wrote efficient and maintainable code, enhancing model training and data processing efficiency through parallel computing and logging. Multi-Model Intelligent Text Keyword Extraction System 08/2023 ‚Äì 09/2023 Group project, supervised by Associate Prof. Xiaolin Zhao Designed and implemented an intelligent text summary system that automatically extracts keywords from article titles and abstracts, enhancing the understanding and summarization of text information. Participated in the planning of the technical route and built a hybrid model combining extractive and generative approaches, utilizing advanced natural language processing techniques including KeyBERT, Sentence Transformer, BERT, and T5 models. Responsible for data preprocessing and tokenization, as well as the end-to-end implementation and training of the T5 model, optimizing the model architecture and hyperparameters, achieving satisfactory results after only 3 epochs of training. Model evaluation results showed that the Rouge-1, Rouge-2, and Rouge-L metrics reached 0.6345, 0.5038, and 0.5282, respectively, in the third epoch, validating the model\u0026rsquo;s effectiveness in the summarization task. Cambridge University Machine Learning Summer Project 07/2023 ‚Äì 08/2023 Group project, supervised by Prof. Pietro Li√≤ Participated in the Cambridge University deep learning summer project, focusing on deep reinforcement learning; explored multi-agent learning algorithms across different environments. Reproduced the Multi-Agent Deep Deterministic Policy Gradient (MADDPG) algorithm in the Simple Adversary environment and studied the effect of agent numbers on convergence speed and stability, finding optimal stability at 21 agents. Designed and implemented comparative experiments inspired by the Rainbow algorithm, assessing target network strategies versus the Double Deep Q-Network (Double DQN). The results demonstrated that Double DQN significantly enhanced convergence speed, optimizing the overall learning process. Co-authored a group project paper on agent numbers and strategies effectiveness in multi-agent systems, achieving a score of 71% in the summer program (the highest in my group) and a \u0026ldquo;First Class\u0026rdquo; classification in the UK grading system. Deep Learning and Computer Vision Semester Project 09/2022 ‚Äì 12/2022 Independent project, supervised by Associate Prof. Guangyu Gao Designed and implemented a waste classifier using the ResNet model to improve classification accuracy and reduce resource waste. The project also enhanced understanding of transfer learning techniques with ResNet. Collected a dataset of 16 waste categories and preprocessed the images for uniformity and standardization, incorporating data augmentation techniques to enhance the dataset. Conducted experiments using ResNet34 and ResNet50 models through transfer learning, accelerating network convergence by leveraging pretrained weights. During training, techniques such as Batch Normalization and Dropout were applied to mitigate the risk of overfitting. The final model achieved an accuracy of 90% on the training set, while the performance on the test set was 61%, indicating a significant overfitting phenomenon during the training process. üéì Internship Beijing Academy of Quantum Information Science 08/2023 ‚Äì 01/2024 Research Intern at Quantum Computation Department Proposed a quantum convolution kernel design based on variational quantum circuits and developed a universal quantum convolution layer, successfully integrating it into classical CNN architectures such as VGG, GoogLeNet, and ResNet. Developed and evaluated various hybrid models, including a simple model named HQCCNN-2, which achieved 84.45% accuracy on the FashionMNIST dataset, surpassing the traditional CNN\u0026rsquo;s 80.72%. This demonstrates the effectiveness of the quantum convolution layer in improving model performance. Tested on a real quantum computer further validated the effectiveness of the hybrid model, demonstrating the viable integration of quantum computing with deep learning, and highlighting the potential for leveraging quantum properties to enhance model performance. üèÖ Competition Experience China International \u0026#34;Internet \u0026#43;\u0026#34; College Students\u0026#39; Innovation Competition 08/2022 Zhongke Ushield: Deep Learning-based Face Privacy Protection Authentication System Responsible for constructing a localized facial feature extraction engine based on MobileFaceNet, ensuring feature extraction is completed on end devices (such as mobile phones and cameras), guaranteeing that raw data does not leave the domain and is not stored, thus enhancing user privacy protection while improving recognition efficiency. \u0026#34;Challenge Cup\u0026#34; Capital University Entrepreneurship Competition 05/2022 Smart Orchard Responsible for the development of the fruit detection, ripeness prediction, and pest identification system, using deep convolutional neural network (CNN) technology for intelligent monitoring of crop growth conditions. Applied advanced object detection algorithms such as Faster R-CNN and YOLO to achieve high precision in apple detection and ripeness assessment, with an accuracy rate exceeding 90%, significantly enhancing the intelligence level of orchard management. Built and trained a dedicated dataset containing various pest samples, optimizing pest detection accuracy through data preprocessing (such as image normalization and resizing) and data augmentation techniques (like rotation, flipping, and noise addition), enabling the real-time monitoring system to accurately identify over 80% of pests, providing effective scientific maintenance recommendations to help farmers reduce crop losses. üìã Extracurricular Activities Vice President, Cyber Security Club, Beijing Institute of Technology 09/2021-09/2022 Backbone, Media Center of the Student Union of Beijing Institute of Technology 10/2020-06/2021 üì´ Contact üìß zongsi.xu@outlook.com üëî Zongsi (Tristan) Xu üíª github.com/BaizeXS üìç Hong Kong SAR, China ","permalink":"http://localhost:1313/resume/","summary":"Personal resume of Zongsi (Tristan) Xu","title":"Zongsi (Tristan) Xu"},{"content":"üëã About me I\u0026rsquo;m \u0026hellip;\nüìö Education üá≠üá∞ The University of Hong Kong 09/2024 - Expected 11/2025 School of Computing and Data Science Master of Science in Electronic Commerce \u0026amp; Internet Computing Relevant Courses: Machine learning for business and e-commerce, Knowledge graphs, Financial fraud analytics, Internet infrastructure technologies, Website engineering, Blockchain and cryptocurrency, etc. üá®üá≥ Beijing Institute of Technology 09/2020 - 06/2024 School of Computer Science \u0026amp; Technology Bachelor of Engineering in Software Engineering, last two years GPA: 3.7/4 Relevant Courses: Reinforcement Learning, Deep Learning and Computer Vision, Artificial Intelligence and Robot Ethics, Almost Human: Mind, Brain and Artificial Intelligence, Mathematical Analysis for Engineering, Linear Algebra, Probability and Mathematical Statistics, etc. Skills: Python, Java, common data structures, design patterns, machine learning basics and algorithms, Linux, PyTorch, and some development tools (git, conda, etc.). üèÜ Awards \u0026amp; Honors Beijing Institute of Technology Undergraduate Scholarship (Top 20% of Grade) 06/2023 3rd Prize of China International \u0026#34;Internet \u0026#43;\u0026#34; College Student\u0026#39;s Innovation Competition 08/2022 Bronze Prize of \u0026#34;Challenge Cup\u0026#34; Capital University Entrepreneurship Competition 05/2022 üíº Project Experience Online Transaction Fraud Detection 09/2024 ‚Äì 01/2025 Independent project, supervised by Dr. Vivien Chan Focused on addressing financial fraud in e-commerce to enhance the accuracy of transaction anomaly detection, while independently managing the entire case study that included data preprocessing, feature engineering, model building, evaluation, and results analysis. Effectively resolved class imbalance issues using SMOTE and ROSE techniques. Built various models including Logistic Regression, Random Forest, XGBoost, and LightGBM, ultimately selecting the LightGBM model to achieve a recall rate of 95.45% and an AUC of 99.84%. Wrote efficient and maintainable code, enhancing model training and data processing efficiency through parallel computing and logging. Multi-Model Intelligent Text Keyword Extraction System 08/2023 ‚Äì 09/2023 Group project, supervised by Associate Prof. Xiaolin Zhao Designed and implemented an intelligent text summary system that automatically extracts keywords from article titles and abstracts, enhancing the understanding and summarization of text information. Participated in the planning of the technical route and built a hybrid model combining extractive and generative approaches, utilizing advanced natural language processing techniques including KeyBERT, Sentence Transformer, BERT, and T5 models. Responsible for data preprocessing and tokenization, as well as the end-to-end implementation and training of the T5 model, optimizing the model architecture and hyperparameters, achieving satisfactory results after only 3 epochs of training. Model evaluation results showed that the Rouge-1, Rouge-2, and Rouge-L metrics reached 0.6345, 0.5038, and 0.5282, respectively, in the third epoch, validating the model\u0026rsquo;s effectiveness in the summarization task. Cambridge University Machine Learning Summer Project 07/2023 ‚Äì 08/2023 Group project, supervised by Prof. Pietro Li√≤ Participated in the Cambridge University deep learning summer project, focusing on deep reinforcement learning; explored multi-agent learning algorithms across different environments. Reproduced the Multi-Agent Deep Deterministic Policy Gradient (MADDPG) algorithm in the Simple Adversary environment and studied the effect of agent numbers on convergence speed and stability, finding optimal stability at 21 agents. Designed and implemented comparative experiments inspired by the Rainbow algorithm, assessing target network strategies versus the Double Deep Q-Network (Double DQN). The results demonstrated that Double DQN significantly enhanced convergence speed, optimizing the overall learning process. Co-authored a group project paper on agent numbers and strategies effectiveness in multi-agent systems, achieving a score of 71% in the summer program (the highest in my group) and a \u0026ldquo;First Class\u0026rdquo; classification in the UK grading system. Deep Learning and Computer Vision Semester Project 09/2022 ‚Äì 12/2022 Independent project, supervised by Associate Prof. Guangyu Gao Designed and implemented a waste classifier using the ResNet model to improve classification accuracy and reduce resource waste. The project also enhanced understanding of transfer learning techniques with ResNet. Collected a dataset of 16 waste categories and preprocessed the images for uniformity and standardization, incorporating data augmentation techniques to enhance the dataset. Conducted experiments using ResNet34 and ResNet50 models through transfer learning, accelerating network convergence by leveraging pretrained weights. During training, techniques such as Batch Normalization and Dropout were applied to mitigate the risk of overfitting. The final model achieved an accuracy of 90% on the training set, while the performance on the test set was 61%, indicating a significant overfitting phenomenon during the training process. üéì Internship Beijing Academy of Quantum Information Science 08/2023 ‚Äì 01/2024 Research Intern at Quantum Computation Department Proposed a quantum convolution kernel design based on variational quantum circuits and developed a universal quantum convolution layer, successfully integrating it into classical CNN architectures such as VGG, GoogLeNet, and ResNet. Developed and evaluated various hybrid models, including a simple model named HQCCNN-2, which achieved 84.45% accuracy on the FashionMNIST dataset, surpassing the traditional CNN\u0026rsquo;s 80.72%. This demonstrates the effectiveness of the quantum convolution layer in improving model performance. Tested on a real quantum computer further validated the effectiveness of the hybrid model, demonstrating the viable integration of quantum computing with deep learning, and highlighting the potential for leveraging quantum properties to enhance model performance. üèÖ Competition Experience China International \u0026#34;Internet \u0026#43;\u0026#34; College Students\u0026#39; Innovation Competition 08/2022 Zhongke Ushield: Deep Learning-based Face Privacy Protection Authentication System Responsible for constructing a localized facial feature extraction engine based on MobileFaceNet, ensuring feature extraction is completed on end devices (such as mobile phones and cameras), guaranteeing that raw data does not leave the domain and is not stored, thus enhancing user privacy protection while improving recognition efficiency. \u0026#34;Challenge Cup\u0026#34; Capital University Entrepreneurship Competition 05/2022 Smart Orchard Responsible for the development of the fruit detection, ripeness prediction, and pest identification system, using deep convolutional neural network (CNN) technology for intelligent monitoring of crop growth conditions. Applied advanced object detection algorithms such as Faster R-CNN and YOLO to achieve high precision in apple detection and ripeness assessment, with an accuracy rate exceeding 90%, significantly enhancing the intelligence level of orchard management. Built and trained a dedicated dataset containing various pest samples, optimizing pest detection accuracy through data preprocessing (such as image normalization and resizing) and data augmentation techniques (like rotation, flipping, and noise addition), enabling the real-time monitoring system to accurately identify over 80% of pests, providing effective scientific maintenance recommendations to help farmers reduce crop losses. üìã Extracurricular Activities Vice President, Cyber Security Club, Beijing Institute of Technology 09/2021-09/2022 Backbone, Media Center of the Student Union of Beijing Institute of Technology 10/2020-06/2021 üì´ Contact üìß zongsi.xu@outlook.com üëî Zongsi (Tristan) Xu üíª github.com/BaizeXS üìç Hong Kong SAR, China ","permalink":"http://localhost:1313/resume/","summary":"Personal resume of Zongsi (Tristan) Xu","title":"Zongsi (Tristan) Xu"},{"content":"üëã About me I\u0026rsquo;m \u0026hellip;\nüìö Education üá≠üá∞ The University of Hong Kong 09/2024 - Expected 11/2025 School of Computing and Data Science Master of Science in Electronic Commerce \u0026amp; Internet Computing Relevant Courses: Machine learning for business and e-commerce, Knowledge graphs, Financial fraud analytics, Internet infrastructure technologies, Website engineering, Blockchain and cryptocurrency, etc. üá®üá≥ Beijing Institute of Technology 09/2020 - 06/2024 School of Computer Science \u0026amp; Technology Bachelor of Engineering in Software Engineering, last two years GPA: 3.7/4 Relevant Courses: Reinforcement Learning, Deep Learning and Computer Vision, Artificial Intelligence and Robot Ethics, Almost Human: Mind, Brain and Artificial Intelligence, Mathematical Analysis for Engineering, Linear Algebra, Probability and Mathematical Statistics, etc. Skills: Python, Java, common data structures, design patterns, machine learning basics and algorithms, Linux, PyTorch, and some development tools (git, conda, etc.). üèÜ Awards \u0026amp; Honors Beijing Institute of Technology Undergraduate Scholarship (Top 20% of Grade) 06/2023 3rd Prize of China International \u0026#34;Internet \u0026#43;\u0026#34; College Student\u0026#39;s Innovation Competition 08/2022 Bronze Prize of \u0026#34;Challenge Cup\u0026#34; Capital University Entrepreneurship Competition 05/2022 üíº Project Experience Online Transaction Fraud Detection 09/2024 ‚Äì 01/2025 Independent project, supervised by Dr. Vivien Chan Focused on addressing financial fraud in e-commerce to enhance the accuracy of transaction anomaly detection, while independently managing the entire case study that included data preprocessing, feature engineering, model building, evaluation, and results analysis. Effectively resolved class imbalance issues using SMOTE and ROSE techniques. Built various models including Logistic Regression, Random Forest, XGBoost, and LightGBM, ultimately selecting the LightGBM model to achieve a recall rate of 95.45% and an AUC of 99.84%. Wrote efficient and maintainable code, enhancing model training and data processing efficiency through parallel computing and logging. Multi-Model Intelligent Text Keyword Extraction System 08/2023 ‚Äì 09/2023 Group project, supervised by Associate Prof. Xiaolin Zhao Designed and implemented an intelligent text summary system that automatically extracts keywords from article titles and abstracts, enhancing the understanding and summarization of text information. Participated in the planning of the technical route and built a hybrid model combining extractive and generative approaches, utilizing advanced natural language processing techniques including KeyBERT, Sentence Transformer, BERT, and T5 models. Responsible for data preprocessing and tokenization, as well as the end-to-end implementation and training of the T5 model, optimizing the model architecture and hyperparameters, achieving satisfactory results after only 3 epochs of training. Model evaluation results showed that the Rouge-1, Rouge-2, and Rouge-L metrics reached 0.6345, 0.5038, and 0.5282, respectively, in the third epoch, validating the model\u0026rsquo;s effectiveness in the summarization task. Cambridge University Machine Learning Summer Project 07/2023 ‚Äì 08/2023 Group project, supervised by Prof. Pietro Li√≤ Participated in the Cambridge University deep learning summer project, focusing on deep reinforcement learning; explored multi-agent learning algorithms across different environments. Reproduced the Multi-Agent Deep Deterministic Policy Gradient (MADDPG) algorithm in the Simple Adversary environment and studied the effect of agent numbers on convergence speed and stability, finding optimal stability at 21 agents. Designed and implemented comparative experiments inspired by the Rainbow algorithm, assessing target network strategies versus the Double Deep Q-Network (Double DQN). The results demonstrated that Double DQN significantly enhanced convergence speed, optimizing the overall learning process. Co-authored a group project paper on agent numbers and strategies effectiveness in multi-agent systems, achieving a score of 71% in the summer program (the highest in my group) and a \u0026ldquo;First Class\u0026rdquo; classification in the UK grading system. Deep Learning and Computer Vision Semester Project 09/2022 ‚Äì 12/2022 Independent project, supervised by Associate Prof. Guangyu Gao Designed and implemented a waste classifier using the ResNet model to improve classification accuracy and reduce resource waste. The project also enhanced understanding of transfer learning techniques with ResNet. Collected a dataset of 16 waste categories and preprocessed the images for uniformity and standardization, incorporating data augmentation techniques to enhance the dataset. Conducted experiments using ResNet34 and ResNet50 models through transfer learning, accelerating network convergence by leveraging pretrained weights. During training, techniques such as Batch Normalization and Dropout were applied to mitigate the risk of overfitting. The final model achieved an accuracy of 90% on the training set, while the performance on the test set was 61%, indicating a significant overfitting phenomenon during the training process. üéì Internship Beijing Academy of Quantum Information Science 08/2023 ‚Äì 01/2024 Research Intern at Quantum Computation Department Proposed a quantum convolution kernel design based on variational quantum circuits and developed a universal quantum convolution layer, successfully integrating it into classical CNN architectures such as VGG, GoogLeNet, and ResNet. Developed and evaluated various hybrid models, including a simple model named HQCCNN-2, which achieved 84.45% accuracy on the FashionMNIST dataset, surpassing the traditional CNN\u0026rsquo;s 80.72%. This demonstrates the effectiveness of the quantum convolution layer in improving model performance. Tested on a real quantum computer further validated the effectiveness of the hybrid model, demonstrating the viable integration of quantum computing with deep learning, and highlighting the potential for leveraging quantum properties to enhance model performance. üèÖ Competition Experience China International \u0026#34;Internet \u0026#43;\u0026#34; College Students\u0026#39; Innovation Competition 08/2022 Zhongke Ushield: Deep Learning-based Face Privacy Protection Authentication System Responsible for constructing a localized facial feature extraction engine based on MobileFaceNet, ensuring feature extraction is completed on end devices (such as mobile phones and cameras), guaranteeing that raw data does not leave the domain and is not stored, thus enhancing user privacy protection while improving recognition efficiency. \u0026#34;Challenge Cup\u0026#34; Capital University Entrepreneurship Competition 05/2022 Smart Orchard Responsible for the development of the fruit detection, ripeness prediction, and pest identification system, using deep convolutional neural network (CNN) technology for intelligent monitoring of crop growth conditions. Applied advanced object detection algorithms such as Faster R-CNN and YOLO to achieve high precision in apple detection and ripeness assessment, with an accuracy rate exceeding 90%, significantly enhancing the intelligence level of orchard management. Built and trained a dedicated dataset containing various pest samples, optimizing pest detection accuracy through data preprocessing (such as image normalization and resizing) and data augmentation techniques (like rotation, flipping, and noise addition), enabling the real-time monitoring system to accurately identify over 80% of pests, providing effective scientific maintenance recommendations to help farmers reduce crop losses. üìã Extracurricular Activities Vice President, Cyber Security Club, Beijing Institute of Technology 09/2021-09/2022 Backbone, Media Center of the Student Union of Beijing Institute of Technology 10/2020-06/2021 üì´ Contact üìß zongsi.xu@outlook.com üëî Zongsi (Tristan) Xu üíª github.com/BaizeXS üìç Hong Kong SAR, China ","permalink":"http://localhost:1313/resume/","summary":"Personal resume of Zongsi (Tristan) Xu","title":"Zongsi (Tristan) Xu"},{"content":"üëã About me I\u0026rsquo;m \u0026hellip;\nüìö Education üá≠üá∞ The University of Hong Kong 09/2024 - Expected 11/2025 School of Computing and Data Science Master of Science in Electronic Commerce \u0026amp; Internet Computing Relevant Courses: Machine learning for business and e-commerce, Knowledge graphs, Financial fraud analytics, Internet infrastructure technologies, Website engineering, Blockchain and cryptocurrency, etc. üá®üá≥ Beijing Institute of Technology 09/2020 - 06/2024 School of Computer Science \u0026amp; Technology Bachelor of Engineering in Software Engineering, last two years GPA: 3.7/4 Relevant Courses: Reinforcement Learning, Deep Learning and Computer Vision, Artificial Intelligence and Robot Ethics, Almost Human: Mind, Brain and Artificial Intelligence, Mathematical Analysis for Engineering, Linear Algebra, Probability and Mathematical Statistics, etc. Skills: Python, Java, common data structures, design patterns, machine learning basics and algorithms, Linux, PyTorch, and some development tools (git, conda, etc.). üèÜ Awards \u0026amp; Honors Beijing Institute of Technology Undergraduate Scholarship (Top 20% of Grade) 06/2023 3rd Prize of China International \u0026#34;Internet \u0026#43;\u0026#34; College Student\u0026#39;s Innovation Competition 08/2022 Bronze Prize of \u0026#34;Challenge Cup\u0026#34; Capital University Entrepreneurship Competition 05/2022 üíº Project Experience Online Transaction Fraud Detection 09/2024 ‚Äì 01/2025 Independent project, supervised by Dr. Vivien Chan Focused on addressing financial fraud in e-commerce to enhance the accuracy of transaction anomaly detection, while independently managing the entire case study that included data preprocessing, feature engineering, model building, evaluation, and results analysis. Effectively resolved class imbalance issues using SMOTE and ROSE techniques. Built various models including Logistic Regression, Random Forest, XGBoost, and LightGBM, ultimately selecting the LightGBM model to achieve a recall rate of 95.45% and an AUC of 99.84%. Wrote efficient and maintainable code, enhancing model training and data processing efficiency through parallel computing and logging. Multi-Model Intelligent Text Keyword Extraction System 08/2023 ‚Äì 09/2023 Group project, supervised by Associate Prof. Xiaolin Zhao Designed and implemented an intelligent text summary system that automatically extracts keywords from article titles and abstracts, enhancing the understanding and summarization of text information. Participated in the planning of the technical route and built a hybrid model combining extractive and generative approaches, utilizing advanced natural language processing techniques including KeyBERT, Sentence Transformer, BERT, and T5 models. Responsible for data preprocessing and tokenization, as well as the end-to-end implementation and training of the T5 model, optimizing the model architecture and hyperparameters, achieving satisfactory results after only 3 epochs of training. Model evaluation results showed that the Rouge-1, Rouge-2, and Rouge-L metrics reached 0.6345, 0.5038, and 0.5282, respectively, in the third epoch, validating the model\u0026rsquo;s effectiveness in the summarization task. Cambridge University Machine Learning Summer Project 07/2023 ‚Äì 08/2023 Group project, supervised by Prof. Pietro Li√≤ Participated in the Cambridge University deep learning summer project, focusing on deep reinforcement learning; explored multi-agent learning algorithms across different environments. Reproduced the Multi-Agent Deep Deterministic Policy Gradient (MADDPG) algorithm in the Simple Adversary environment and studied the effect of agent numbers on convergence speed and stability, finding optimal stability at 21 agents. Designed and implemented comparative experiments inspired by the Rainbow algorithm, assessing target network strategies versus the Double Deep Q-Network (Double DQN). The results demonstrated that Double DQN significantly enhanced convergence speed, optimizing the overall learning process. Co-authored a group project paper on agent numbers and strategies effectiveness in multi-agent systems, achieving a score of 71% in the summer program (the highest in my group) and a \u0026ldquo;First Class\u0026rdquo; classification in the UK grading system. Deep Learning and Computer Vision Semester Project 09/2022 ‚Äì 12/2022 Independent project, supervised by Associate Prof. Guangyu Gao Designed and implemented a waste classifier using the ResNet model to improve classification accuracy and reduce resource waste. The project also enhanced understanding of transfer learning techniques with ResNet. Collected a dataset of 16 waste categories and preprocessed the images for uniformity and standardization, incorporating data augmentation techniques to enhance the dataset. Conducted experiments using ResNet34 and ResNet50 models through transfer learning, accelerating network convergence by leveraging pretrained weights. During training, techniques such as Batch Normalization and Dropout were applied to mitigate the risk of overfitting. The final model achieved an accuracy of 90% on the training set, while the performance on the test set was 61%, indicating a significant overfitting phenomenon during the training process. üéì Internship Beijing Academy of Quantum Information Science 08/2023 ‚Äì 01/2024 Research Intern at Quantum Computation Department Proposed a quantum convolution kernel design based on variational quantum circuits and developed a universal quantum convolution layer, successfully integrating it into classical CNN architectures such as VGG, GoogLeNet, and ResNet. Developed and evaluated various hybrid models, including a simple model named HQCCNN-2, which achieved 84.45% accuracy on the FashionMNIST dataset, surpassing the traditional CNN\u0026rsquo;s 80.72%. This demonstrates the effectiveness of the quantum convolution layer in improving model performance. Tested on a real quantum computer further validated the effectiveness of the hybrid model, demonstrating the viable integration of quantum computing with deep learning, and highlighting the potential for leveraging quantum properties to enhance model performance. üèÖ Competition Experience China International \u0026#34;Internet \u0026#43;\u0026#34; College Students\u0026#39; Innovation Competition 08/2022 Zhongke Ushield: Deep Learning-based Face Privacy Protection Authentication System Responsible for constructing a localized facial feature extraction engine based on MobileFaceNet, ensuring feature extraction is completed on end devices (such as mobile phones and cameras), guaranteeing that raw data does not leave the domain and is not stored, thus enhancing user privacy protection while improving recognition efficiency. \u0026#34;Challenge Cup\u0026#34; Capital University Entrepreneurship Competition 05/2022 Smart Orchard Responsible for the development of the fruit detection, ripeness prediction, and pest identification system, using deep convolutional neural network (CNN) technology for intelligent monitoring of crop growth conditions. Applied advanced object detection algorithms such as Faster R-CNN and YOLO to achieve high precision in apple detection and ripeness assessment, with an accuracy rate exceeding 90%, significantly enhancing the intelligence level of orchard management. Built and trained a dedicated dataset containing various pest samples, optimizing pest detection accuracy through data preprocessing (such as image normalization and resizing) and data augmentation techniques (like rotation, flipping, and noise addition), enabling the real-time monitoring system to accurately identify over 80% of pests, providing effective scientific maintenance recommendations to help farmers reduce crop losses. üìã Extracurricular Activities Vice President, Cyber Security Club, Beijing Institute of Technology 09/2021-09/2022 Backbone, Media Center of the Student Union of Beijing Institute of Technology 10/2020-06/2021 üì´ Contact üìß zongsi.xu@outlook.com üëî Zongsi (Tristan) Xu üíª github.com/BaizeXS üìç Hong Kong SAR, China ","permalink":"http://localhost:1313/resume/","summary":"Personal resume of Zongsi (Tristan) Xu","title":"Zongsi (Tristan) Xu"},{"content":"üëã About me I\u0026rsquo;m \u0026hellip;\nüìö Education üá≠üá∞ The University of Hong Kong 09/2024 - Expected 11/2025 School of Computing and Data Science Master of Science in Electronic Commerce \u0026amp; Internet Computing Relevant Courses: Machine learning for business and e-commerce, Knowledge graphs, Financial fraud analytics, Internet infrastructure technologies, Website engineering, Blockchain and cryptocurrency, etc. üá®üá≥ Beijing Institute of Technology 09/2020 - 06/2024 School of Computer Science \u0026amp; Technology Bachelor of Engineering in Software Engineering, last two years GPA: 3.7/4 Relevant Courses: Reinforcement Learning, Deep Learning and Computer Vision, Artificial Intelligence and Robot Ethics, Almost Human: Mind, Brain and Artificial Intelligence, Mathematical Analysis for Engineering, Linear Algebra, Probability and Mathematical Statistics, etc. Skills: Python, Java, common data structures, design patterns, machine learning basics and algorithms, Linux, PyTorch, and some development tools (git, conda, etc.). üèÜ Awards \u0026amp; Honors Beijing Institute of Technology Undergraduate Scholarship (Top 20% of Grade) 06/2023 3rd Prize of China International \u0026#34;Internet \u0026#43;\u0026#34; College Student\u0026#39;s Innovation Competition 08/2022 Bronze Prize of \u0026#34;Challenge Cup\u0026#34; Capital University Entrepreneurship Competition 05/2022 üíº Project Experience Online Transaction Fraud Detection 09/2024 ‚Äì 01/2025 Independent project, supervised by Dr. Vivien Chan Focused on addressing financial fraud in e-commerce to enhance the accuracy of transaction anomaly detection, while independently managing the entire case study that included data preprocessing, feature engineering, model building, evaluation, and results analysis. Effectively resolved class imbalance issues using SMOTE and ROSE techniques. Built various models including Logistic Regression, Random Forest, XGBoost, and LightGBM, ultimately selecting the LightGBM model to achieve a recall rate of 95.45% and an AUC of 99.84%. Wrote efficient and maintainable code, enhancing model training and data processing efficiency through parallel computing and logging. Multi-Model Intelligent Text Keyword Extraction System 08/2023 ‚Äì 09/2023 Group project, supervised by Associate Prof. Xiaolin Zhao Designed and implemented an intelligent text summary system that automatically extracts keywords from article titles and abstracts, enhancing the understanding and summarization of text information. Participated in the planning of the technical route and built a hybrid model combining extractive and generative approaches, utilizing advanced natural language processing techniques including KeyBERT, Sentence Transformer, BERT, and T5 models. Responsible for data preprocessing and tokenization, as well as the end-to-end implementation and training of the T5 model, optimizing the model architecture and hyperparameters, achieving satisfactory results after only 3 epochs of training. Model evaluation results showed that the Rouge-1, Rouge-2, and Rouge-L metrics reached 0.6345, 0.5038, and 0.5282, respectively, in the third epoch, validating the model\u0026rsquo;s effectiveness in the summarization task. Cambridge University Machine Learning Summer Project 07/2023 ‚Äì 08/2023 Group project, supervised by Prof. Pietro Li√≤ Participated in the Cambridge University deep learning summer project, focusing on deep reinforcement learning; explored multi-agent learning algorithms across different environments. Reproduced the Multi-Agent Deep Deterministic Policy Gradient (MADDPG) algorithm in the Simple Adversary environment and studied the effect of agent numbers on convergence speed and stability, finding optimal stability at 21 agents. Designed and implemented comparative experiments inspired by the Rainbow algorithm, assessing target network strategies versus the Double Deep Q-Network (Double DQN). The results demonstrated that Double DQN significantly enhanced convergence speed, optimizing the overall learning process. Co-authored a group project paper on agent numbers and strategies effectiveness in multi-agent systems, achieving a score of 71% in the summer program (the highest in my group) and a \u0026ldquo;First Class\u0026rdquo; classification in the UK grading system. Deep Learning and Computer Vision Semester Project 09/2022 ‚Äì 12/2022 Independent project, supervised by Associate Prof. Guangyu Gao Designed and implemented a waste classifier using the ResNet model to improve classification accuracy and reduce resource waste. The project also enhanced understanding of transfer learning techniques with ResNet. Collected a dataset of 16 waste categories and preprocessed the images for uniformity and standardization, incorporating data augmentation techniques to enhance the dataset. Conducted experiments using ResNet34 and ResNet50 models through transfer learning, accelerating network convergence by leveraging pretrained weights. During training, techniques such as Batch Normalization and Dropout were applied to mitigate the risk of overfitting. The final model achieved an accuracy of 90% on the training set, while the performance on the test set was 61%, indicating a significant overfitting phenomenon during the training process. üéì Internship Beijing Academy of Quantum Information Science 08/2023 ‚Äì 01/2024 Research Intern at Quantum Computation Department Proposed a quantum convolution kernel design based on variational quantum circuits and developed a universal quantum convolution layer, successfully integrating it into classical CNN architectures such as VGG, GoogLeNet, and ResNet. Developed and evaluated various hybrid models, including a simple model named HQCCNN-2, which achieved 84.45% accuracy on the FashionMNIST dataset, surpassing the traditional CNN\u0026rsquo;s 80.72%. This demonstrates the effectiveness of the quantum convolution layer in improving model performance. Tested on a real quantum computer further validated the effectiveness of the hybrid model, demonstrating the viable integration of quantum computing with deep learning, and highlighting the potential for leveraging quantum properties to enhance model performance. üèÖ Competition Experience China International \u0026#34;Internet \u0026#43;\u0026#34; College Students\u0026#39; Innovation Competition 08/2022 Zhongke Ushield: Deep Learning-based Face Privacy Protection Authentication System Responsible for constructing a localized facial feature extraction engine based on MobileFaceNet, ensuring feature extraction is completed on end devices (such as mobile phones and cameras), guaranteeing that raw data does not leave the domain and is not stored, thus enhancing user privacy protection while improving recognition efficiency. \u0026#34;Challenge Cup\u0026#34; Capital University Entrepreneurship Competition 05/2022 Smart Orchard Responsible for the development of the fruit detection, ripeness prediction, and pest identification system, using deep convolutional neural network (CNN) technology for intelligent monitoring of crop growth conditions. Applied advanced object detection algorithms such as Faster R-CNN and YOLO to achieve high precision in apple detection and ripeness assessment, with an accuracy rate exceeding 90%, significantly enhancing the intelligence level of orchard management. Built and trained a dedicated dataset containing various pest samples, optimizing pest detection accuracy through data preprocessing (such as image normalization and resizing) and data augmentation techniques (like rotation, flipping, and noise addition), enabling the real-time monitoring system to accurately identify over 80% of pests, providing effective scientific maintenance recommendations to help farmers reduce crop losses. üìã Extracurricular Activities Vice President, Cyber Security Club, Beijing Institute of Technology 09/2021-09/2022 Backbone, Media Center of the Student Union of Beijing Institute of Technology 10/2020-06/2021 üì´ Contact üìß zongsi.xu@outlook.com üëî Zongsi (Tristan) Xu üíª github.com/BaizeXS üìç Hong Kong SAR, China ","permalink":"http://localhost:1313/resume/","summary":"Personal resume of Zongsi (Tristan) Xu","title":"Zongsi (Tristan) Xu"},{"content":"üëã About me I\u0026rsquo;m \u0026hellip;\nüìö Education üá≠üá∞ The University of Hong Kong 09/2024 - Expected 11/2025 School of Computing and Data Science Master of Science in Electronic Commerce \u0026amp; Internet Computing Relevant Courses: Machine learning for business and e-commerce, Knowledge graphs, Financial fraud analytics, Internet infrastructure technologies, Website engineering, Blockchain and cryptocurrency, etc. üá®üá≥ Beijing Institute of Technology 09/2020 - 06/2024 School of Computer Science \u0026amp; Technology Bachelor of Engineering in Software Engineering, last two years GPA: 3.7/4 Relevant Courses: Reinforcement Learning, Deep Learning and Computer Vision, Artificial Intelligence and Robot Ethics, Almost Human: Mind, Brain and Artificial Intelligence, Mathematical Analysis for Engineering, Linear Algebra, Probability and Mathematical Statistics, etc. Skills: Python, Java, common data structures, design patterns, machine learning basics and algorithms, Linux, PyTorch, and some development tools (git, conda, etc.). üèÜ Awards \u0026amp; Honors Beijing Institute of Technology Undergraduate Scholarship (Top 20% of Grade) 06/2023 3rd Prize of China International \u0026#34;Internet \u0026#43;\u0026#34; College Student\u0026#39;s Innovation Competition 08/2022 Bronze Prize of \u0026#34;Challenge Cup\u0026#34; Capital University Entrepreneurship Competition 05/2022 üíº Project Experience Online Transaction Fraud Detection 09/2024 ‚Äì 01/2025 Independent project, supervised by Dr. Vivien Chan Focused on addressing financial fraud in e-commerce to enhance the accuracy of transaction anomaly detection, while independently managing the entire case study that included data preprocessing, feature engineering, model building, evaluation, and results analysis. Effectively resolved class imbalance issues using SMOTE and ROSE techniques. Built various models including Logistic Regression, Random Forest, XGBoost, and LightGBM, ultimately selecting the LightGBM model to achieve a recall rate of 95.45% and an AUC of 99.84%. Wrote efficient and maintainable code, enhancing model training and data processing efficiency through parallel computing and logging. Multi-Model Intelligent Text Keyword Extraction System 08/2023 ‚Äì 09/2023 Group project, supervised by Associate Prof. Xiaolin Zhao Designed and implemented an intelligent text summary system that automatically extracts keywords from article titles and abstracts, enhancing the understanding and summarization of text information. Participated in the planning of the technical route and built a hybrid model combining extractive and generative approaches, utilizing advanced natural language processing techniques including KeyBERT, Sentence Transformer, BERT, and T5 models. Responsible for data preprocessing and tokenization, as well as the end-to-end implementation and training of the T5 model, optimizing the model architecture and hyperparameters, achieving satisfactory results after only 3 epochs of training. Model evaluation results showed that the Rouge-1, Rouge-2, and Rouge-L metrics reached 0.6345, 0.5038, and 0.5282, respectively, in the third epoch, validating the model\u0026rsquo;s effectiveness in the summarization task. Cambridge University Machine Learning Summer Project 07/2023 ‚Äì 08/2023 Group project, supervised by Prof. Pietro Li√≤ Participated in the Cambridge University deep learning summer project, focusing on deep reinforcement learning; explored multi-agent learning algorithms across different environments. Reproduced the Multi-Agent Deep Deterministic Policy Gradient (MADDPG) algorithm in the Simple Adversary environment and studied the effect of agent numbers on convergence speed and stability, finding optimal stability at 21 agents. Designed and implemented comparative experiments inspired by the Rainbow algorithm, assessing target network strategies versus the Double Deep Q-Network (Double DQN). The results demonstrated that Double DQN significantly enhanced convergence speed, optimizing the overall learning process. Co-authored a group project paper on agent numbers and strategies effectiveness in multi-agent systems, achieving a score of 71% in the summer program (the highest in my group) and a \u0026ldquo;First Class\u0026rdquo; classification in the UK grading system. Deep Learning and Computer Vision Semester Project 09/2022 ‚Äì 12/2022 Independent project, supervised by Associate Prof. Guangyu Gao Designed and implemented a waste classifier using the ResNet model to improve classification accuracy and reduce resource waste. The project also enhanced understanding of transfer learning techniques with ResNet. Collected a dataset of 16 waste categories and preprocessed the images for uniformity and standardization, incorporating data augmentation techniques to enhance the dataset. Conducted experiments using ResNet34 and ResNet50 models through transfer learning, accelerating network convergence by leveraging pretrained weights. During training, techniques such as Batch Normalization and Dropout were applied to mitigate the risk of overfitting. The final model achieved an accuracy of 90% on the training set, while the performance on the test set was 61%, indicating a significant overfitting phenomenon during the training process. üéì Internship Beijing Academy of Quantum Information Science 08/2023 ‚Äì 01/2024 Research Intern at Quantum Computation Department Proposed a quantum convolution kernel design based on variational quantum circuits and developed a universal quantum convolution layer, successfully integrating it into classical CNN architectures such as VGG, GoogLeNet, and ResNet. Developed and evaluated various hybrid models, including a simple model named HQCCNN-2, which achieved 84.45% accuracy on the FashionMNIST dataset, surpassing the traditional CNN\u0026rsquo;s 80.72%. This demonstrates the effectiveness of the quantum convolution layer in improving model performance. Tested on a real quantum computer further validated the effectiveness of the hybrid model, demonstrating the viable integration of quantum computing with deep learning, and highlighting the potential for leveraging quantum properties to enhance model performance. üèÖ Competition Experience China International \u0026#34;Internet \u0026#43;\u0026#34; College Students\u0026#39; Innovation Competition 08/2022 Zhongke Ushield: Deep Learning-based Face Privacy Protection Authentication System Responsible for constructing a localized facial feature extraction engine based on MobileFaceNet, ensuring feature extraction is completed on end devices (such as mobile phones and cameras), guaranteeing that raw data does not leave the domain and is not stored, thus enhancing user privacy protection while improving recognition efficiency. \u0026#34;Challenge Cup\u0026#34; Capital University Entrepreneurship Competition 05/2022 Smart Orchard Responsible for the development of the fruit detection, ripeness prediction, and pest identification system, using deep convolutional neural network (CNN) technology for intelligent monitoring of crop growth conditions. Applied advanced object detection algorithms such as Faster R-CNN and YOLO to achieve high precision in apple detection and ripeness assessment, with an accuracy rate exceeding 90%, significantly enhancing the intelligence level of orchard management. Built and trained a dedicated dataset containing various pest samples, optimizing pest detection accuracy through data preprocessing (such as image normalization and resizing) and data augmentation techniques (like rotation, flipping, and noise addition), enabling the real-time monitoring system to accurately identify over 80% of pests, providing effective scientific maintenance recommendations to help farmers reduce crop losses. üìã Extracurricular Activities Vice President, Cyber Security Club, Beijing Institute of Technology 09/2021-09/2022 Backbone, Media Center of the Student Union of Beijing Institute of Technology 10/2020-06/2021 üì´ Contact üìß zongsi.xu@outlook.com üëî Zongsi (Tristan) Xu üíª github.com/BaizeXS üìç Hong Kong SAR, China ","permalink":"http://localhost:1313/resume/","summary":"Personal resume of Zongsi (Tristan) Xu","title":"Zongsi (Tristan) Xu"},{"content":"üëã About me I\u0026rsquo;m \u0026hellip;\nüìö Education üá≠üá∞ The University of Hong Kong 09/2024 - Expected 11/2025 School of Computing and Data Science Master of Science in Electronic Commerce \u0026amp; Internet Computing Relevant Courses: Machine learning for business and e-commerce, Knowledge graphs, Financial fraud analytics, Internet infrastructure technologies, Website engineering, Blockchain and cryptocurrency, etc. üá®üá≥ Beijing Institute of Technology 09/2020 - 06/2024 School of Computer Science \u0026amp; Technology Bachelor of Engineering in Software Engineering, last two years GPA: 3.7/4 Relevant Courses: Reinforcement Learning, Deep Learning and Computer Vision, Artificial Intelligence and Robot Ethics, Almost Human: Mind, Brain and Artificial Intelligence, Mathematical Analysis for Engineering, Linear Algebra, Probability and Mathematical Statistics, etc. Skills: Python, Java, common data structures, design patterns, machine learning basics and algorithms, Linux, PyTorch, and some development tools (git, conda, etc.). üèÜ Awards \u0026amp; Honors Beijing Institute of Technology Undergraduate Scholarship (Top 20% of Grade) 06/2023 3rd Prize of China International \u0026#34;Internet \u0026#43;\u0026#34; College Student\u0026#39;s Innovation Competition 08/2022 Bronze Prize of \u0026#34;Challenge Cup\u0026#34; Capital University Entrepreneurship Competition 05/2022 üíº Project Experience Online Transaction Fraud Detection 09/2024 ‚Äì 01/2025 Independent project, supervised by Dr. Vivien Chan Focused on addressing financial fraud in e-commerce to enhance the accuracy of transaction anomaly detection, while independently managing the entire case study that included data preprocessing, feature engineering, model building, evaluation, and results analysis. Effectively resolved class imbalance issues using SMOTE and ROSE techniques. Built various models including Logistic Regression, Random Forest, XGBoost, and LightGBM, ultimately selecting the LightGBM model to achieve a recall rate of 95.45% and an AUC of 99.84%. Wrote efficient and maintainable code, enhancing model training and data processing efficiency through parallel computing and logging. Multi-Model Intelligent Text Keyword Extraction System 08/2023 ‚Äì 09/2023 Group project, supervised by Associate Prof. Xiaolin Zhao Designed and implemented an intelligent text summary system that automatically extracts keywords from article titles and abstracts, enhancing the understanding and summarization of text information. Participated in the planning of the technical route and built a hybrid model combining extractive and generative approaches, utilizing advanced natural language processing techniques including KeyBERT, Sentence Transformer, BERT, and T5 models. Responsible for data preprocessing and tokenization, as well as the end-to-end implementation and training of the T5 model, optimizing the model architecture and hyperparameters, achieving satisfactory results after only 3 epochs of training. Model evaluation results showed that the Rouge-1, Rouge-2, and Rouge-L metrics reached 0.6345, 0.5038, and 0.5282, respectively, in the third epoch, validating the model\u0026rsquo;s effectiveness in the summarization task. Cambridge University Machine Learning Summer Project 07/2023 ‚Äì 08/2023 Group project, supervised by Prof. Pietro Li√≤ Participated in the Cambridge University deep learning summer project, focusing on deep reinforcement learning; explored multi-agent learning algorithms across different environments. Reproduced the Multi-Agent Deep Deterministic Policy Gradient (MADDPG) algorithm in the Simple Adversary environment and studied the effect of agent numbers on convergence speed and stability, finding optimal stability at 21 agents. Designed and implemented comparative experiments inspired by the Rainbow algorithm, assessing target network strategies versus the Double Deep Q-Network (Double DQN). The results demonstrated that Double DQN significantly enhanced convergence speed, optimizing the overall learning process. Co-authored a group project paper on agent numbers and strategies effectiveness in multi-agent systems, achieving a score of 71% in the summer program (the highest in my group) and a \u0026ldquo;First Class\u0026rdquo; classification in the UK grading system. Deep Learning and Computer Vision Semester Project 09/2022 ‚Äì 12/2022 Independent project, supervised by Associate Prof. Guangyu Gao Designed and implemented a waste classifier using the ResNet model to improve classification accuracy and reduce resource waste. The project also enhanced understanding of transfer learning techniques with ResNet. Collected a dataset of 16 waste categories and preprocessed the images for uniformity and standardization, incorporating data augmentation techniques to enhance the dataset. Conducted experiments using ResNet34 and ResNet50 models through transfer learning, accelerating network convergence by leveraging pretrained weights. During training, techniques such as Batch Normalization and Dropout were applied to mitigate the risk of overfitting. The final model achieved an accuracy of 90% on the training set, while the performance on the test set was 61%, indicating a significant overfitting phenomenon during the training process. üéì Internship Beijing Academy of Quantum Information Science 08/2023 ‚Äì 01/2024 Research Intern at Quantum Computation Department Proposed a quantum convolution kernel design based on variational quantum circuits and developed a universal quantum convolution layer, successfully integrating it into classical CNN architectures such as VGG, GoogLeNet, and ResNet. Developed and evaluated various hybrid models, including a simple model named HQCCNN-2, which achieved 84.45% accuracy on the FashionMNIST dataset, surpassing the traditional CNN\u0026rsquo;s 80.72%. This demonstrates the effectiveness of the quantum convolution layer in improving model performance. Tested on a real quantum computer further validated the effectiveness of the hybrid model, demonstrating the viable integration of quantum computing with deep learning, and highlighting the potential for leveraging quantum properties to enhance model performance. üèÖ Competition Experience China International \u0026#34;Internet \u0026#43;\u0026#34; College Students\u0026#39; Innovation Competition 08/2022 Zhongke Ushield: Deep Learning-based Face Privacy Protection Authentication System Responsible for constructing a localized facial feature extraction engine based on MobileFaceNet, ensuring feature extraction is completed on end devices (such as mobile phones and cameras), guaranteeing that raw data does not leave the domain and is not stored, thus enhancing user privacy protection while improving recognition efficiency. \u0026#34;Challenge Cup\u0026#34; Capital University Entrepreneurship Competition 05/2022 Smart Orchard Responsible for the development of the fruit detection, ripeness prediction, and pest identification system, using deep convolutional neural network (CNN) technology for intelligent monitoring of crop growth conditions. Applied advanced object detection algorithms such as Faster R-CNN and YOLO to achieve high precision in apple detection and ripeness assessment, with an accuracy rate exceeding 90%, significantly enhancing the intelligence level of orchard management. Built and trained a dedicated dataset containing various pest samples, optimizing pest detection accuracy through data preprocessing (such as image normalization and resizing) and data augmentation techniques (like rotation, flipping, and noise addition), enabling the real-time monitoring system to accurately identify over 80% of pests, providing effective scientific maintenance recommendations to help farmers reduce crop losses. üìã Extracurricular Activities Vice President, Cyber Security Club, Beijing Institute of Technology 09/2021-09/2022 Backbone, Media Center of the Student Union of Beijing Institute of Technology 10/2020-06/2021 üì´ Contact üìß zongsi.xu@outlook.com üëî Zongsi (Tristan) Xu üíª github.com/BaizeXS üìç Hong Kong SAR, China ","permalink":"http://localhost:1313/resume/","summary":"Personal resume of Zongsi (Tristan) Xu","title":"Zongsi (Tristan) Xu"},{"content":"üëã About me I\u0026rsquo;m \u0026hellip;\nüìö Education üá≠üá∞ The University of Hong Kong 09/2024 - Expected 11/2025 School of Computing and Data Science Master of Science in Electronic Commerce \u0026amp; Internet Computing Relevant Courses: Machine learning for business and e-commerce, Knowledge graphs, Financial fraud analytics, Internet infrastructure technologies, Website engineering, Blockchain and cryptocurrency, etc. üá®üá≥ Beijing Institute of Technology 09/2020 - 06/2024 School of Computer Science \u0026amp; Technology Bachelor of Engineering in Software Engineering, last two years GPA: 3.7/4 Relevant Courses: Reinforcement Learning, Deep Learning and Computer Vision, Artificial Intelligence and Robot Ethics, Almost Human: Mind, Brain and Artificial Intelligence, Mathematical Analysis for Engineering, Linear Algebra, Probability and Mathematical Statistics, etc. Skills: Python, Java, common data structures, design patterns, machine learning basics and algorithms, Linux, PyTorch, and some development tools (git, conda, etc.). üèÜ Awards \u0026amp; Honors Beijing Institute of Technology Undergraduate Scholarship (Top 20% of Grade) 06/2023 3rd Prize of China International \u0026#34;Internet \u0026#43;\u0026#34; College Student\u0026#39;s Innovation Competition 08/2022 Bronze Prize of \u0026#34;Challenge Cup\u0026#34; Capital University Entrepreneurship Competition 05/2022 üíº Project Experience Online Transaction Fraud Detection 09/2024 ‚Äì 01/2025 Independent project, supervised by Dr. Vivien Chan Focused on addressing financial fraud in e-commerce to enhance the accuracy of transaction anomaly detection, while independently managing the entire case study that included data preprocessing, feature engineering, model building, evaluation, and results analysis. Effectively resolved class imbalance issues using SMOTE and ROSE techniques. Built various models including Logistic Regression, Random Forest, XGBoost, and LightGBM, ultimately selecting the LightGBM model to achieve a recall rate of 95.45% and an AUC of 99.84%. Wrote efficient and maintainable code, enhancing model training and data processing efficiency through parallel computing and logging. Multi-Model Intelligent Text Keyword Extraction System 08/2023 ‚Äì 09/2023 Group project, supervised by Associate Prof. Xiaolin Zhao Designed and implemented an intelligent text summary system that automatically extracts keywords from article titles and abstracts, enhancing the understanding and summarization of text information. Participated in the planning of the technical route and built a hybrid model combining extractive and generative approaches, utilizing advanced natural language processing techniques including KeyBERT, Sentence Transformer, BERT, and T5 models. Responsible for data preprocessing and tokenization, as well as the end-to-end implementation and training of the T5 model, optimizing the model architecture and hyperparameters, achieving satisfactory results after only 3 epochs of training. Model evaluation results showed that the Rouge-1, Rouge-2, and Rouge-L metrics reached 0.6345, 0.5038, and 0.5282, respectively, in the third epoch, validating the model\u0026rsquo;s effectiveness in the summarization task. Cambridge University Machine Learning Summer Project 07/2023 ‚Äì 08/2023 Group project, supervised by Prof. Pietro Li√≤ Participated in the Cambridge University deep learning summer project, focusing on deep reinforcement learning; explored multi-agent learning algorithms across different environments. Reproduced the Multi-Agent Deep Deterministic Policy Gradient (MADDPG) algorithm in the Simple Adversary environment and studied the effect of agent numbers on convergence speed and stability, finding optimal stability at 21 agents. Designed and implemented comparative experiments inspired by the Rainbow algorithm, assessing target network strategies versus the Double Deep Q-Network (Double DQN). The results demonstrated that Double DQN significantly enhanced convergence speed, optimizing the overall learning process. Co-authored a group project paper on agent numbers and strategies effectiveness in multi-agent systems, achieving a score of 71% in the summer program (the highest in my group) and a \u0026ldquo;First Class\u0026rdquo; classification in the UK grading system. Deep Learning and Computer Vision Semester Project 09/2022 ‚Äì 12/2022 Independent project, supervised by Associate Prof. Guangyu Gao Designed and implemented a waste classifier using the ResNet model to improve classification accuracy and reduce resource waste. The project also enhanced understanding of transfer learning techniques with ResNet. Collected a dataset of 16 waste categories and preprocessed the images for uniformity and standardization, incorporating data augmentation techniques to enhance the dataset. Conducted experiments using ResNet34 and ResNet50 models through transfer learning, accelerating network convergence by leveraging pretrained weights. During training, techniques such as Batch Normalization and Dropout were applied to mitigate the risk of overfitting. The final model achieved an accuracy of 90% on the training set, while the performance on the test set was 61%, indicating a significant overfitting phenomenon during the training process. üéì Internship Beijing Academy of Quantum Information Science 08/2023 ‚Äì 01/2024 Research Intern at Quantum Computation Department Proposed a quantum convolution kernel design based on variational quantum circuits and developed a universal quantum convolution layer, successfully integrating it into classical CNN architectures such as VGG, GoogLeNet, and ResNet. Developed and evaluated various hybrid models, including a simple model named HQCCNN-2, which achieved 84.45% accuracy on the FashionMNIST dataset, surpassing the traditional CNN\u0026rsquo;s 80.72%. This demonstrates the effectiveness of the quantum convolution layer in improving model performance. Tested on a real quantum computer further validated the effectiveness of the hybrid model, demonstrating the viable integration of quantum computing with deep learning, and highlighting the potential for leveraging quantum properties to enhance model performance. üèÖ Competition Experience China International \u0026#34;Internet \u0026#43;\u0026#34; College Students\u0026#39; Innovation Competition 08/2022 Zhongke Ushield: Deep Learning-based Face Privacy Protection Authentication System Responsible for constructing a localized facial feature extraction engine based on MobileFaceNet, ensuring feature extraction is completed on end devices (such as mobile phones and cameras), guaranteeing that raw data does not leave the domain and is not stored, thus enhancing user privacy protection while improving recognition efficiency. \u0026#34;Challenge Cup\u0026#34; Capital University Entrepreneurship Competition 05/2022 Smart Orchard Responsible for the development of the fruit detection, ripeness prediction, and pest identification system, using deep convolutional neural network (CNN) technology for intelligent monitoring of crop growth conditions. Applied advanced object detection algorithms such as Faster R-CNN and YOLO to achieve high precision in apple detection and ripeness assessment, with an accuracy rate exceeding 90%, significantly enhancing the intelligence level of orchard management. Built and trained a dedicated dataset containing various pest samples, optimizing pest detection accuracy through data preprocessing (such as image normalization and resizing) and data augmentation techniques (like rotation, flipping, and noise addition), enabling the real-time monitoring system to accurately identify over 80% of pests, providing effective scientific maintenance recommendations to help farmers reduce crop losses. üìã Extracurricular Activities Vice President, Cyber Security Club, Beijing Institute of Technology 09/2021-09/2022 Backbone, Media Center of the Student Union of Beijing Institute of Technology 10/2020-06/2021 üì´ Contact üìß zongsi.xu@outlook.com üëî Zongsi (Tristan) Xu üíª github.com/BaizeXS üìç Hong Kong SAR, China ","permalink":"http://localhost:1313/resume/","summary":"Personal resume of Zongsi (Tristan) Xu","title":"Zongsi (Tristan) Xu"},{"content":"‰∏Ä„ÄÅÊï∞ÂÄºÁâπÂæÅ‰∏éÁ±ªÂà´ÁâπÂæÅ Êï∞ÂÄºÁâπÂæÅ (Numeric Features) ÂÖ∑ÊúâÂèØÂä†ÂáèÁöÑÊÑè‰πâÔºå‰∏îÂ≠òÂú®Â§ßÂ∞èÈ°∫Â∫è„ÄÇ ‰æãÂ≠êÔºöÂπ¥ÈæÑ„ÄÅÊ∏©Â∫¶Á≠â„ÄÇÂèØ‰ª•Áõ¥Êé•‰øùÁïôÂÖ∂Êï¥Êï∞ÊàñÊµÆÁÇπÊï∞ÂΩ¢Âºè‰æõÊ®°Âûã‰ΩøÁî®„ÄÇ Á±ªÂà´ÁâπÂæÅ (Categorical Features) Êï∞ÊçÆÂÄºÁ¶ªÊï£Ôºå‰∏çÂÖ∑Â§á‚ÄúÊï∞ÂÄºÂ§ßÂ∞è‚ÄùÈó¥ÁöÑÂèØÊØîÊÑè‰πâ„ÄÇ ‰æãÂ≠êÔºöÂõΩÁ±çÔºàÁæéÂõΩ/‰∏≠ÂõΩ/Âç∞Â∫¶Á≠âÔºâ„ÄÅÊÄßÂà´ÔºàÁî∑/Â•≥ÔºâÁ≠â„ÄÇ ÈóÆÈ¢òÔºöËã•‰ªÖÁî®Êï¥Êï∞Ë°®Á§∫ÔºàÁæéÂõΩ=1, ‰∏≠ÂõΩ=2ÔºâÔºå‰ºöÂºïÂÖ•ÈîôËØØÁöÑÊï∞ÂÄºËøêÁÆóÂÖ≥Á≥ªÔºåÂ¶Ç ‚ÄúÁæéÂõΩ + ‰∏≠ÂõΩ = Âç∞Â∫¶‚Äù„ÄÇ ‰∫å„ÄÅOne-HotÁºñÁ†ÅÁöÑÂä®Êú∫‰∏éÊµÅÁ®ã ‰∏∫‰ªÄ‰πà‰ΩøÁî®One-Hot\nÈÄöËøáÂ∞ÜÁ±ªÂà´Êò†Â∞Ñ‰∏∫ÂêëÈáèÔºåÈÅøÂÖçÊï¥Êï∞ÁºñÁ†ÅÂºïÂÖ•ÁöÑ‰º™Êï∞ÂÄºÂÖ≥Á≥ª„ÄÇ ÂêåÊó∂‰øùÁïôÂêÑÁßçÂèØËÉΩÁ±ªÂà´ÁöÑ‰ø°ÊÅØÔºå‰∏î‰ªÖÂú®ÂØπÂ∫î‰ΩçÁΩÆ‰∏∫1ÔºåÂÖ∂‰ªñ‰ΩçÁΩÆ‰∏∫0„ÄÇ Âª∫Á´ãÊò†Â∞ÑÔºö‰ªéÁ±ªÂà´Âà∞Á¥¢Âºï\n‰∏∫ÊØè‰∏™Á±ªÂà´ÂàÜÈÖç‰∏Ä‰∏™ÂîØ‰∏ÄÁ¥¢ÂºïÔºåÈÄöÂ∏∏‰ªé1ÂºÄÂßã„ÄÇ È¢ÑÁïôÁ¥¢Âºï0Ë°®Á§∫‚ÄúÊú™Áü•‚ÄùÊàñ‚ÄúÁº∫Â§±‚ÄùÔºåÂØπÂ∫îÂÖ®0ÂêëÈáè„ÄÇ ËΩ¨Êç¢‰∏∫One-HotÂêëÈáè\nËã•Á±ªÂà´ÊÄªÊï∞‰∏∫197ÔºåÂàôÁî®197Áª¥ÂêëÈáèË°®Á§∫„ÄÇ ‰æãÂ≠êÔºöÁæéÂõΩ [1, 0, 0, 0, ‚Ä¶]Ôºå ‰∏≠ÂõΩ [0, 1, 0, 0, ‚Ä¶]„ÄÇ Á§∫‰æãÔºöË°®Á§∫‰∏Ä‰∏™‰∫∫ÁöÑÁâπÂæÅ\nÁâπÂæÅÂåÖÂê´ÔºàÂπ¥ÈæÑ, ÊÄßÂà´, ÂõΩÁ±çÔºåÂÖ∂‰∏≠ÂõΩÁ±ç197ÁßçÔºâ Áª¥Â∫¶ÊÄªÂíåÔºö1Áª¥_age + 1Áª¥_gender + 197Áª¥_nationality = 199Áª¥„ÄÇ ‰æãÂ¶Ç (28, Â•≥, ‰∏≠ÂõΩ) ‚Üí [28, 0, 0, 1, 0, ‚Ä¶, 0]„ÄÇ ‰∏â„ÄÅÊñáÊú¨Êï∞ÊçÆÂ§ÑÁêÜÊµÅÁ®ã ÊñáÊú¨Âú®Ëá™ÁÑ∂ËØ≠Ë®ÄÂ§ÑÁêÜÔºàNLPÔºâ‰∏≠‰Ωú‰∏∫Â∏∏ËßÅÁöÑÂéüÂßãËæìÂÖ•ÔºåÈúÄË¶ÅÊï∞ÂÄºÂåñÊâçËÉΩÈÄÅÂÖ•Ê®°Âûã„ÄÇ‰∏ÄËà¨Ê≠•È™§Â¶Ç‰∏ãÔºö\nÂàÜËØç (Tokenization)\nÂ∞ÜÊñáÊú¨ÊãÜÂàÜ‰∏∫‰∏Ä‰∏™‰∏™ÂçïËØçÔºàTokenÔºâ„ÄÇ ‰æãÂ≠êÔºö\u0026quot;... to be or not to be...\u0026quot; ‚Üí [\u0026quot;...\u0026quot;, \u0026quot;to\u0026quot;, \u0026quot;be\u0026quot;, \u0026quot;or\u0026quot;, \u0026quot;not\u0026quot;, \u0026quot;to\u0026quot;, \u0026quot;be\u0026quot;, \u0026quot;...\u0026quot;]„ÄÇ ÁªüËÆ°ËØçÈ¢ë \u0026amp; ÊûÑÂª∫ËØçÂÖ∏\nËØçÈ¢ëÁªüËÆ° Áî®ÂìàÂ∏åË°®/Â≠óÂÖ∏ËÆ∞ÂΩïÊØè‰∏™ÂçïËØçÂá∫Áé∞Ê¨°Êï∞„ÄÇ ÈÅçÂéÜÊñáÊú¨Êó∂ÔºåËã•ÂçïËØçÂ∞öÊú™ÂÖ•Ë°®ÔºåÂàôÊñ∞Âª∫ËÆ∞ÂΩïÔºõËã•Â∑≤Â≠òÂú®ÔºåÂàôËÆ°Êï∞+1„ÄÇ ÊéíÂ∫è‰∏éÁ¥¢Âºï ÊåâËØçÈ¢ëÈôçÂ∫èÊéíÂ∫èÔºåËØçÈ¢ëÊúÄÈ´òÁöÑÂçïËØçÊéíÂú®ÂâçÈù¢„ÄÇ Á¥¢Âºï‰ªé1ÂºÄÂßãÔºå0ÁïôÁªô‚ÄúÊú™Áü•‚Äù„ÄÇ ËØçÂÖ∏ËßÑÊ®°ÔºàvocabularyÔºâÂèØËßÜÈúÄÊ±ÇÊà™Êñ≠Ôºà‰æãÂ¶ÇÂè™‰øùÁïôTop 10kÔºâ„ÄÇ ‰∏∫‰ªÄ‰πàÁßªÈô§‰ΩéÈ¢ëËØç ‰ΩéÈ¢ëËØçÂèØËÉΩÊòØÊãºÂÜôÈîôËØØ„ÄÅÁΩïËßÅ‰∫∫ÂêçÁ≠âÔºåÂØπÊ®°ÂûãÂ∏ÆÂä©ÊúâÈôê„ÄÇ ÂáèÂ∞ëËØçÂÖ∏ËßÑÊ®°ÂèØÈôç‰ΩéËøêÁÆóÂºÄÈîÄ„ÄÅÂä†Âø´Ê®°ÂûãËÆ≠ÁªÉ‰∏éÊé®ÁêÜÈÄüÂ∫¶„ÄÇ Áã¨ÁÉ≠ÁºñÁ†Å (One-Hot Encoding)\nÂ∞ÜÊØè‰∏™ÂçïËØçÊò†Â∞Ñ‰∏∫ËØçÂÖ∏‰∏≠ÁöÑÁ¥¢ÂºïÂêéÔºàÂ¶Ç [2, 4, 1, 8, ‚Ä¶]ÔºâÔºåÂèØËøõ‰∏ÄÊ≠•ËΩ¨Êç¢ÊàêOne-HotÂêëÈáè„ÄÇ One-HotÁª¥Â∫¶ÂèñÂÜ≥‰∫é‰øùÁïô‰∏ãÊù•ÁöÑËØçÂÖ∏Â§ßÂ∞èÔºà‰æãÂ¶Ç1‰∏áÔºâ„ÄÇ Êú™Êî∂ÂΩïÂçïËØçÂèØËÉΩÁõ¥Êé•ÂøΩÁï•ÔºåÊàñÁªü‰∏ÄÁî®Á¥¢Âºï0‰ª£Êõø„ÄÇ Âõõ„ÄÅÊ†∏ÂøÉÊî∂Ëé∑‰∏éÂ∫îÁî® Á±ªÂà´ÁâπÂæÅÂøÖÈúÄÊï∞ÂÄºÂåñÔºö\n‰ΩøÁî®Êï¥Êï∞1,2,3‚Ä¶‰ªÖË°®Á§∫Á±ªÂà´‚ÄúÊ†áËØÜ‚ÄùÔºåÂπ∂‰∏ç‰ª£Ë°®ÂÆÉ‰ª¨ÂèØËøõË°åÊï∞ÂÄºËøêÁÆó„ÄÇ Âõ†Ê≠§ÈúÄË¶ÅOne-HotÁ≠âÁºñÁ†ÅÊñπÂºèÔºåÈÅøÂÖçÊï∞ÂÄºËØØËß£„ÄÇ ÊñáÊú¨Êï∞ÊçÆÈ¢ÑÂ§ÑÁêÜÔºö\nÂàÜËØç„ÄÅËØçÈ¢ëÁªüËÆ°„ÄÅÊûÑÂª∫ËØçÂÖ∏„ÄÅÁ¥¢ÂºïÂåñ„ÄÅOne-HotÊàñÂÖ∂‰ªñÊñπÂºèÔºàÂ¶ÇËØçÂµåÂÖ•ÔºâÊòØÂ∏∏ËßÅÊµÅÁ®ã„ÄÇ Ê≠£Á°ÆÁöÑÊñáÊú¨È¢ÑÂ§ÑÁêÜÂèØÊòæËëóÂΩ±ÂìçÊ®°ÂûãÊÄßËÉΩÂíåÊïàÁéá„ÄÇ ‰øùÁïôÊú™Áü•Á¥¢ÂºïÔºö\n‰øùËØÅÂØπÁº∫Â§±Êï∞ÊçÆÊàñÂ≠óÂÖ∏Â§ñÊñ∞ËØçËÉΩÊúâÂü∫Êú¨ÁöÑË°®Á§∫ÔºåÊèêÂçáÊ®°ÂûãÂÆπÈîôÊÄß„ÄÇ ÂÆûÈôÖ‰ΩøÁî®Ôºö\nÂØπ‰∫éÂ∞èËßÑÊ®°Á±ªÂà´ÂèØÁõ¥Êé•One-HotÁºñÁ†ÅÔºõÂØπ‰∫éËØçÂÖ∏ÂæàÂ§ßÁöÑÂú∫ÊôØÔºåÈÄöÂ∏∏‰ºöËøõ‰∏ÄÊ≠•ËÄÉËôëËØçÂµåÂÖ•ÔºàWord EmbeddingÔºâÊàñÈ¢ÑËÆ≠ÁªÉËØ≠Ë®ÄÊ®°Âûã„ÄÇ ","permalink":"http://localhost:1313/posts/nlp-1/","summary":"\u003ch2 id=\"‰∏ÄÊï∞ÂÄºÁâπÂæÅ‰∏éÁ±ªÂà´ÁâπÂæÅ\"\u003e‰∏Ä„ÄÅÊï∞ÂÄºÁâπÂæÅ‰∏éÁ±ªÂà´ÁâπÂæÅ\u003c/h2\u003e\n\u003col\u003e\n\u003cli\u003e\u003cstrong\u003eÊï∞ÂÄºÁâπÂæÅ (Numeric Features)\u003c/strong\u003e\n\u003cul\u003e\n\u003cli\u003eÂÖ∑ÊúâÂèØÂä†ÂáèÁöÑÊÑè‰πâÔºå‰∏îÂ≠òÂú®Â§ßÂ∞èÈ°∫Â∫è„ÄÇ\u003c/li\u003e\n\u003cli\u003e‰æãÂ≠êÔºöÂπ¥ÈæÑ„ÄÅÊ∏©Â∫¶Á≠â„ÄÇÂèØ‰ª•Áõ¥Êé•‰øùÁïôÂÖ∂Êï¥Êï∞ÊàñÊµÆÁÇπÊï∞ÂΩ¢Âºè‰æõÊ®°Âûã‰ΩøÁî®„ÄÇ\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003eÁ±ªÂà´ÁâπÂæÅ (Categorical Features)\u003c/strong\u003e\n\u003cul\u003e\n\u003cli\u003eÊï∞ÊçÆÂÄºÁ¶ªÊï£Ôºå‰∏çÂÖ∑Â§á‚ÄúÊï∞ÂÄºÂ§ßÂ∞è‚ÄùÈó¥ÁöÑÂèØÊØîÊÑè‰πâ„ÄÇ\u003c/li\u003e\n\u003cli\u003e‰æãÂ≠êÔºöÂõΩÁ±çÔºàÁæéÂõΩ/‰∏≠ÂõΩ/Âç∞Â∫¶Á≠âÔºâ„ÄÅÊÄßÂà´ÔºàÁî∑/Â•≥ÔºâÁ≠â„ÄÇ\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003eÈóÆÈ¢ò\u003c/strong\u003eÔºöËã•‰ªÖÁî®Êï¥Êï∞Ë°®Á§∫ÔºàÁæéÂõΩ=1, ‰∏≠ÂõΩ=2ÔºâÔºå‰ºöÂºïÂÖ•ÈîôËØØÁöÑÊï∞ÂÄºËøêÁÆóÂÖ≥Á≥ªÔºåÂ¶Ç ‚ÄúÁæéÂõΩ + ‰∏≠ÂõΩ = Âç∞Â∫¶‚Äù„ÄÇ\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003c/ol\u003e\n\u003ch2 id=\"‰∫åone-hotÁºñÁ†ÅÁöÑÂä®Êú∫‰∏éÊµÅÁ®ã\"\u003e‰∫å„ÄÅOne-HotÁºñÁ†ÅÁöÑÂä®Êú∫‰∏éÊµÅÁ®ã\u003c/h2\u003e\n\u003col\u003e\n\u003cli\u003e\n\u003cp\u003e\u003cstrong\u003e‰∏∫‰ªÄ‰πà‰ΩøÁî®One-Hot\u003c/strong\u003e\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eÈÄöËøáÂ∞ÜÁ±ªÂà´Êò†Â∞Ñ‰∏∫ÂêëÈáèÔºåÈÅøÂÖçÊï¥Êï∞ÁºñÁ†ÅÂºïÂÖ•ÁöÑ‰º™Êï∞ÂÄºÂÖ≥Á≥ª„ÄÇ\u003c/li\u003e\n\u003cli\u003eÂêåÊó∂‰øùÁïôÂêÑÁßçÂèØËÉΩÁ±ªÂà´ÁöÑ‰ø°ÊÅØÔºå‰∏î‰ªÖÂú®ÂØπÂ∫î‰ΩçÁΩÆ‰∏∫1ÔºåÂÖ∂‰ªñ‰ΩçÁΩÆ‰∏∫0„ÄÇ\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003e\u003cstrong\u003eÂª∫Á´ãÊò†Â∞ÑÔºö‰ªéÁ±ªÂà´Âà∞Á¥¢Âºï\u003c/strong\u003e\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e‰∏∫ÊØè‰∏™Á±ªÂà´ÂàÜÈÖç‰∏Ä‰∏™ÂîØ‰∏ÄÁ¥¢ÂºïÔºåÈÄöÂ∏∏‰ªé1ÂºÄÂßã„ÄÇ\u003c/li\u003e\n\u003cli\u003eÈ¢ÑÁïôÁ¥¢Âºï0Ë°®Á§∫‚ÄúÊú™Áü•‚ÄùÊàñ‚ÄúÁº∫Â§±‚ÄùÔºåÂØπÂ∫îÂÖ®0ÂêëÈáè„ÄÇ\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003e\u003cstrong\u003eËΩ¨Êç¢‰∏∫One-HotÂêëÈáè\u003c/strong\u003e\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eËã•Á±ªÂà´ÊÄªÊï∞‰∏∫197ÔºåÂàôÁî®197Áª¥ÂêëÈáèË°®Á§∫„ÄÇ\u003c/li\u003e\n\u003cli\u003e‰æãÂ≠êÔºöÁæéÂõΩ \u003ccode\u003e[1, 0, 0, 0, ‚Ä¶]\u003c/code\u003eÔºå ‰∏≠ÂõΩ \u003ccode\u003e[0, 1, 0, 0, ‚Ä¶]\u003c/code\u003e„ÄÇ\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003e\u003cstrong\u003eÁ§∫‰æãÔºöË°®Á§∫‰∏Ä‰∏™‰∫∫ÁöÑÁâπÂæÅ\u003c/strong\u003e\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eÁâπÂæÅÂåÖÂê´ÔºàÂπ¥ÈæÑ, ÊÄßÂà´, ÂõΩÁ±çÔºåÂÖ∂‰∏≠ÂõΩÁ±ç197ÁßçÔºâ\u003c/li\u003e\n\u003cli\u003eÁª¥Â∫¶ÊÄªÂíåÔºö1Áª¥_age + 1Áª¥_gender + 197Áª¥_nationality = 199Áª¥„ÄÇ\u003c/li\u003e\n\u003cli\u003e‰æãÂ¶Ç \u003ccode\u003e(28, Â•≥, ‰∏≠ÂõΩ)\u003c/code\u003e ‚Üí \u003ccode\u003e[28, 0, 0, 1, 0, ‚Ä¶, 0]\u003c/code\u003e„ÄÇ\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003c/ol\u003e\n\u003ch2 id=\"‰∏âÊñáÊú¨Êï∞ÊçÆÂ§ÑÁêÜÊµÅÁ®ã\"\u003e‰∏â„ÄÅÊñáÊú¨Êï∞ÊçÆÂ§ÑÁêÜÊµÅÁ®ã\u003c/h2\u003e\n\u003cp\u003eÊñáÊú¨Âú®Ëá™ÁÑ∂ËØ≠Ë®ÄÂ§ÑÁêÜÔºàNLPÔºâ‰∏≠‰Ωú‰∏∫Â∏∏ËßÅÁöÑÂéüÂßãËæìÂÖ•ÔºåÈúÄË¶ÅÊï∞ÂÄºÂåñÊâçËÉΩÈÄÅÂÖ•Ê®°Âûã„ÄÇ‰∏ÄËà¨Ê≠•È™§Â¶Ç‰∏ãÔºö\u003c/p\u003e\n\u003col\u003e\n\u003cli\u003e\n\u003cp\u003e\u003cstrong\u003eÂàÜËØç (Tokenization)\u003c/strong\u003e\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eÂ∞ÜÊñáÊú¨ÊãÜÂàÜ‰∏∫‰∏Ä‰∏™‰∏™ÂçïËØçÔºàTokenÔºâ„ÄÇ\u003c/li\u003e\n\u003cli\u003e‰æãÂ≠êÔºö\u003ccode\u003e\u0026quot;... to be or not to be...\u0026quot;\u003c/code\u003e ‚Üí \u003ccode\u003e[\u0026quot;...\u0026quot;, \u0026quot;to\u0026quot;, \u0026quot;be\u0026quot;, \u0026quot;or\u0026quot;, \u0026quot;not\u0026quot;, \u0026quot;to\u0026quot;, \u0026quot;be\u0026quot;, \u0026quot;...\u0026quot;]\u003c/code\u003e„ÄÇ\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003e\u003cstrong\u003eÁªüËÆ°ËØçÈ¢ë \u0026amp; ÊûÑÂª∫ËØçÂÖ∏\u003c/strong\u003e\u003c/p\u003e","title":""},{"content":"üëã About me I\u0026rsquo;m \u0026hellip;\nüìö Education üá≠üá∞ The University of Hong Kong 09/2024 - Expected 11/2025 School of Computing and Data Science Master of Science in Electronic Commerce \u0026amp; Internet Computing Relevant Courses: Machine learning for business and e-commerce, Knowledge graphs, Financial fraud analytics, Internet infrastructure technologies, Website engineering, Blockchain and cryptocurrency, etc. üá®üá≥ Beijing Institute of Technology 09/2020 - 06/2024 School of Computer Science \u0026amp; Technology Bachelor of Engineering in Software Engineering, last two years GPA: 3.7/4 Relevant Courses: Reinforcement Learning, Deep Learning and Computer Vision, Artificial Intelligence and Robot Ethics, Almost Human: Mind, Brain and Artificial Intelligence, Mathematical Analysis for Engineering, Linear Algebra, Probability and Mathematical Statistics, etc. Skills: Python, Java, common data structures, design patterns, machine learning basics and algorithms, Linux, PyTorch, and some development tools (git, conda, etc.). üèÜ Awards \u0026amp; Honors Beijing Institute of Technology Undergraduate Scholarship (Top 20% of Grade) 06/2023 3rd Prize of China International \u0026#34;Internet \u0026#43;\u0026#34; College Student\u0026#39;s Innovation Competition 08/2022 Bronze Prize of \u0026#34;Challenge Cup\u0026#34; Capital University Entrepreneurship Competition 05/2022 üíº Project Experience Online Transaction Fraud Detection 09/2024 ‚Äì 01/2025 Independent project, supervised by Dr. Vivien Chan Focused on addressing financial fraud in e-commerce to enhance the accuracy of transaction anomaly detection, while independently managing the entire case study that included data preprocessing, feature engineering, model building, evaluation, and results analysis. Effectively resolved class imbalance issues using SMOTE and ROSE techniques. Built various models including Logistic Regression, Random Forest, XGBoost, and LightGBM, ultimately selecting the LightGBM model to achieve a recall rate of 95.45% and an AUC of 99.84%. Wrote efficient and maintainable code, enhancing model training and data processing efficiency through parallel computing and logging. Multi-Model Intelligent Text Keyword Extraction System 08/2023 ‚Äì 09/2023 Group project, supervised by Associate Prof. Xiaolin Zhao Designed and implemented an intelligent text summary system that automatically extracts keywords from article titles and abstracts, enhancing the understanding and summarization of text information. Participated in the planning of the technical route and built a hybrid model combining extractive and generative approaches, utilizing advanced natural language processing techniques including KeyBERT, Sentence Transformer, BERT, and T5 models. Responsible for data preprocessing and tokenization, as well as the end-to-end implementation and training of the T5 model, optimizing the model architecture and hyperparameters, achieving satisfactory results after only 3 epochs of training. Model evaluation results showed that the Rouge-1, Rouge-2, and Rouge-L metrics reached 0.6345, 0.5038, and 0.5282, respectively, in the third epoch, validating the model\u0026rsquo;s effectiveness in the summarization task. Cambridge University Machine Learning Summer Project 07/2023 ‚Äì 08/2023 Group project, supervised by Prof. Pietro Li√≤ Participated in the Cambridge University deep learning summer project, focusing on deep reinforcement learning; explored multi-agent learning algorithms across different environments. Reproduced the Multi-Agent Deep Deterministic Policy Gradient (MADDPG) algorithm in the Simple Adversary environment and studied the effect of agent numbers on convergence speed and stability, finding optimal stability at 21 agents. Designed and implemented comparative experiments inspired by the Rainbow algorithm, assessing target network strategies versus the Double Deep Q-Network (Double DQN). The results demonstrated that Double DQN significantly enhanced convergence speed, optimizing the overall learning process. Co-authored a group project paper on agent numbers and strategies effectiveness in multi-agent systems, achieving a score of 71% in the summer program (the highest in my group) and a \u0026ldquo;First Class\u0026rdquo; classification in the UK grading system. Deep Learning and Computer Vision Semester Project 09/2022 ‚Äì 12/2022 Independent project, supervised by Associate Prof. Guangyu Gao Designed and implemented a waste classifier using the ResNet model to improve classification accuracy and reduce resource waste. The project also enhanced understanding of transfer learning techniques with ResNet. Collected a dataset of 16 waste categories and preprocessed the images for uniformity and standardization, incorporating data augmentation techniques to enhance the dataset. Conducted experiments using ResNet34 and ResNet50 models through transfer learning, accelerating network convergence by leveraging pretrained weights. During training, techniques such as Batch Normalization and Dropout were applied to mitigate the risk of overfitting. The final model achieved an accuracy of 90% on the training set, while the performance on the test set was 61%, indicating a significant overfitting phenomenon during the training process. üéì Internship Beijing Academy of Quantum Information Science 08/2023 ‚Äì 01/2024 Research Intern at Quantum Computation Department Proposed a quantum convolution kernel design based on variational quantum circuits and developed a universal quantum convolution layer, successfully integrating it into classical CNN architectures such as VGG, GoogLeNet, and ResNet. Developed and evaluated various hybrid models, including a simple model named HQCCNN-2, which achieved 84.45% accuracy on the FashionMNIST dataset, surpassing the traditional CNN\u0026rsquo;s 80.72%. This demonstrates the effectiveness of the quantum convolution layer in improving model performance. Tested on a real quantum computer further validated the effectiveness of the hybrid model, demonstrating the viable integration of quantum computing with deep learning, and highlighting the potential for leveraging quantum properties to enhance model performance. üèÖ Competition Experience China International \u0026#34;Internet \u0026#43;\u0026#34; College Students\u0026#39; Innovation Competition 08/2022 Zhongke Ushield: Deep Learning-based Face Privacy Protection Authentication System Responsible for constructing a localized facial feature extraction engine based on MobileFaceNet, ensuring feature extraction is completed on end devices (such as mobile phones and cameras), guaranteeing that raw data does not leave the domain and is not stored, thus enhancing user privacy protection while improving recognition efficiency. \u0026#34;Challenge Cup\u0026#34; Capital University Entrepreneurship Competition 05/2022 Smart Orchard Responsible for the development of the fruit detection, ripeness prediction, and pest identification system, using deep convolutional neural network (CNN) technology for intelligent monitoring of crop growth conditions. Applied advanced object detection algorithms such as Faster R-CNN and YOLO to achieve high precision in apple detection and ripeness assessment, with an accuracy rate exceeding 90%, significantly enhancing the intelligence level of orchard management. Built and trained a dedicated dataset containing various pest samples, optimizing pest detection accuracy through data preprocessing (such as image normalization and resizing) and data augmentation techniques (like rotation, flipping, and noise addition), enabling the real-time monitoring system to accurately identify over 80% of pests, providing effective scientific maintenance recommendations to help farmers reduce crop losses. üìã Extracurricular Activities Vice President, Cyber Security Club, Beijing Institute of Technology 09/2021-09/2022 Backbone, Media Center of the Student Union of Beijing Institute of Technology 10/2020-06/2021 üì´ Contact üìß zongsi.xu@outlook.com üëî Zongsi (Tristan) Xu üíª github.com/BaizeXS üìç Hong Kong SAR, China ","permalink":"http://localhost:1313/resume/","summary":"Personal resume of Zongsi (Tristan) Xu","title":"Zongsi (Tristan) Xu"},{"content":"‰∏Ä„ÄÅÊï∞ÂÄºÁâπÂæÅ‰∏éÁ±ªÂà´ÁâπÂæÅ Êï∞ÂÄºÁâπÂæÅ (Numeric Features) ÂÖ∑ÊúâÂèØÂä†ÂáèÁöÑÊÑè‰πâÔºå‰∏îÂ≠òÂú®Â§ßÂ∞èÈ°∫Â∫è„ÄÇ ‰æãÂ≠êÔºöÂπ¥ÈæÑ„ÄÅÊ∏©Â∫¶Á≠â„ÄÇÂèØ‰ª•Áõ¥Êé•‰øùÁïôÂÖ∂Êï¥Êï∞ÊàñÊµÆÁÇπÊï∞ÂΩ¢Âºè‰æõÊ®°Âûã‰ΩøÁî®„ÄÇ Á±ªÂà´ÁâπÂæÅ (Categorical Features) Êï∞ÊçÆÂÄºÁ¶ªÊï£Ôºå‰∏çÂÖ∑Â§á‚ÄúÊï∞ÂÄºÂ§ßÂ∞è‚ÄùÈó¥ÁöÑÂèØÊØîÊÑè‰πâ„ÄÇ ‰æãÂ≠êÔºöÂõΩÁ±çÔºàÁæéÂõΩ/‰∏≠ÂõΩ/Âç∞Â∫¶Á≠âÔºâ„ÄÅÊÄßÂà´ÔºàÁî∑/Â•≥ÔºâÁ≠â„ÄÇ ÈóÆÈ¢òÔºöËã•‰ªÖÁî®Êï¥Êï∞Ë°®Á§∫ÔºàÁæéÂõΩ=1, ‰∏≠ÂõΩ=2ÔºâÔºå‰ºöÂºïÂÖ•ÈîôËØØÁöÑÊï∞ÂÄºËøêÁÆóÂÖ≥Á≥ªÔºåÂ¶Ç ‚ÄúÁæéÂõΩ + ‰∏≠ÂõΩ = Âç∞Â∫¶‚Äù„ÄÇ ‰∫å„ÄÅOne-HotÁºñÁ†ÅÁöÑÂä®Êú∫‰∏éÊµÅÁ®ã ‰∏∫‰ªÄ‰πà‰ΩøÁî®One-Hot\nÈÄöËøáÂ∞ÜÁ±ªÂà´Êò†Â∞Ñ‰∏∫ÂêëÈáèÔºåÈÅøÂÖçÊï¥Êï∞ÁºñÁ†ÅÂºïÂÖ•ÁöÑ‰º™Êï∞ÂÄºÂÖ≥Á≥ª„ÄÇ ÂêåÊó∂‰øùÁïôÂêÑÁßçÂèØËÉΩÁ±ªÂà´ÁöÑ‰ø°ÊÅØÔºå‰∏î‰ªÖÂú®ÂØπÂ∫î‰ΩçÁΩÆ‰∏∫1ÔºåÂÖ∂‰ªñ‰ΩçÁΩÆ‰∏∫0„ÄÇ Âª∫Á´ãÊò†Â∞ÑÔºö‰ªéÁ±ªÂà´Âà∞Á¥¢Âºï\n‰∏∫ÊØè‰∏™Á±ªÂà´ÂàÜÈÖç‰∏Ä‰∏™ÂîØ‰∏ÄÁ¥¢ÂºïÔºåÈÄöÂ∏∏‰ªé1ÂºÄÂßã„ÄÇ È¢ÑÁïôÁ¥¢Âºï0Ë°®Á§∫‚ÄúÊú™Áü•‚ÄùÊàñ‚ÄúÁº∫Â§±‚ÄùÔºåÂØπÂ∫îÂÖ®0ÂêëÈáè„ÄÇ ËΩ¨Êç¢‰∏∫One-HotÂêëÈáè\nËã•Á±ªÂà´ÊÄªÊï∞‰∏∫197ÔºåÂàôÁî®197Áª¥ÂêëÈáèË°®Á§∫„ÄÇ ‰æãÂ≠êÔºöÁæéÂõΩ [1, 0, 0, 0, ‚Ä¶]Ôºå ‰∏≠ÂõΩ [0, 1, 0, 0, ‚Ä¶]„ÄÇ Á§∫‰æãÔºöË°®Á§∫‰∏Ä‰∏™‰∫∫ÁöÑÁâπÂæÅ\nÁâπÂæÅÂåÖÂê´ÔºàÂπ¥ÈæÑ, ÊÄßÂà´, ÂõΩÁ±çÔºåÂÖ∂‰∏≠ÂõΩÁ±ç197ÁßçÔºâ Áª¥Â∫¶ÊÄªÂíåÔºö1Áª¥_age + 1Áª¥_gender + 197Áª¥_nationality = 199Áª¥„ÄÇ ‰æãÂ¶Ç (28, Â•≥, ‰∏≠ÂõΩ) ‚Üí [28, 0, 0, 1, 0, ‚Ä¶, 0]„ÄÇ ‰∏â„ÄÅÊñáÊú¨Êï∞ÊçÆÂ§ÑÁêÜÊµÅÁ®ã ÊñáÊú¨Âú®Ëá™ÁÑ∂ËØ≠Ë®ÄÂ§ÑÁêÜÔºàNLPÔºâ‰∏≠‰Ωú‰∏∫Â∏∏ËßÅÁöÑÂéüÂßãËæìÂÖ•ÔºåÈúÄË¶ÅÊï∞ÂÄºÂåñÊâçËÉΩÈÄÅÂÖ•Ê®°Âûã„ÄÇ‰∏ÄËà¨Ê≠•È™§Â¶Ç‰∏ãÔºö\nÂàÜËØç (Tokenization)\nÂ∞ÜÊñáÊú¨ÊãÜÂàÜ‰∏∫‰∏Ä‰∏™‰∏™ÂçïËØçÔºàTokenÔºâ„ÄÇ ‰æãÂ≠êÔºö\u0026quot;... to be or not to be...\u0026quot; ‚Üí [\u0026quot;...\u0026quot;, \u0026quot;to\u0026quot;, \u0026quot;be\u0026quot;, \u0026quot;or\u0026quot;, \u0026quot;not\u0026quot;, \u0026quot;to\u0026quot;, \u0026quot;be\u0026quot;, \u0026quot;...\u0026quot;]„ÄÇ ÁªüËÆ°ËØçÈ¢ë \u0026amp; ÊûÑÂª∫ËØçÂÖ∏\nËØçÈ¢ëÁªüËÆ° Áî®ÂìàÂ∏åË°®/Â≠óÂÖ∏ËÆ∞ÂΩïÊØè‰∏™ÂçïËØçÂá∫Áé∞Ê¨°Êï∞„ÄÇ ÈÅçÂéÜÊñáÊú¨Êó∂ÔºåËã•ÂçïËØçÂ∞öÊú™ÂÖ•Ë°®ÔºåÂàôÊñ∞Âª∫ËÆ∞ÂΩïÔºõËã•Â∑≤Â≠òÂú®ÔºåÂàôËÆ°Êï∞+1„ÄÇ ÊéíÂ∫è‰∏éÁ¥¢Âºï ÊåâËØçÈ¢ëÈôçÂ∫èÊéíÂ∫èÔºåËØçÈ¢ëÊúÄÈ´òÁöÑÂçïËØçÊéíÂú®ÂâçÈù¢„ÄÇ Á¥¢Âºï‰ªé1ÂºÄÂßãÔºå0ÁïôÁªô‚ÄúÊú™Áü•‚Äù„ÄÇ ËØçÂÖ∏ËßÑÊ®°ÔºàvocabularyÔºâÂèØËßÜÈúÄÊ±ÇÊà™Êñ≠Ôºà‰æãÂ¶ÇÂè™‰øùÁïôTop 10kÔºâ„ÄÇ ‰∏∫‰ªÄ‰πàÁßªÈô§‰ΩéÈ¢ëËØç ‰ΩéÈ¢ëËØçÂèØËÉΩÊòØÊãºÂÜôÈîôËØØ„ÄÅÁΩïËßÅ‰∫∫ÂêçÁ≠âÔºåÂØπÊ®°ÂûãÂ∏ÆÂä©ÊúâÈôê„ÄÇ ÂáèÂ∞ëËØçÂÖ∏ËßÑÊ®°ÂèØÈôç‰ΩéËøêÁÆóÂºÄÈîÄ„ÄÅÂä†Âø´Ê®°ÂûãËÆ≠ÁªÉ‰∏éÊé®ÁêÜÈÄüÂ∫¶„ÄÇ Áã¨ÁÉ≠ÁºñÁ†Å (One-Hot Encoding)\nÂ∞ÜÊØè‰∏™ÂçïËØçÊò†Â∞Ñ‰∏∫ËØçÂÖ∏‰∏≠ÁöÑÁ¥¢ÂºïÂêéÔºàÂ¶Ç [2, 4, 1, 8, ‚Ä¶]ÔºâÔºåÂèØËøõ‰∏ÄÊ≠•ËΩ¨Êç¢ÊàêOne-HotÂêëÈáè„ÄÇ One-HotÁª¥Â∫¶ÂèñÂÜ≥‰∫é‰øùÁïô‰∏ãÊù•ÁöÑËØçÂÖ∏Â§ßÂ∞èÔºà‰æãÂ¶Ç1‰∏áÔºâ„ÄÇ Êú™Êî∂ÂΩïÂçïËØçÂèØËÉΩÁõ¥Êé•ÂøΩÁï•ÔºåÊàñÁªü‰∏ÄÁî®Á¥¢Âºï0‰ª£Êõø„ÄÇ Âõõ„ÄÅÊ†∏ÂøÉÊî∂Ëé∑‰∏éÂ∫îÁî® Á±ªÂà´ÁâπÂæÅÂøÖÈúÄÊï∞ÂÄºÂåñÔºö\n‰ΩøÁî®Êï¥Êï∞1,2,3‚Ä¶‰ªÖË°®Á§∫Á±ªÂà´‚ÄúÊ†áËØÜ‚ÄùÔºåÂπ∂‰∏ç‰ª£Ë°®ÂÆÉ‰ª¨ÂèØËøõË°åÊï∞ÂÄºËøêÁÆó„ÄÇ Âõ†Ê≠§ÈúÄË¶ÅOne-HotÁ≠âÁºñÁ†ÅÊñπÂºèÔºåÈÅøÂÖçÊï∞ÂÄºËØØËß£„ÄÇ ÊñáÊú¨Êï∞ÊçÆÈ¢ÑÂ§ÑÁêÜÔºö\nÂàÜËØç„ÄÅËØçÈ¢ëÁªüËÆ°„ÄÅÊûÑÂª∫ËØçÂÖ∏„ÄÅÁ¥¢ÂºïÂåñ„ÄÅOne-HotÊàñÂÖ∂‰ªñÊñπÂºèÔºàÂ¶ÇËØçÂµåÂÖ•ÔºâÊòØÂ∏∏ËßÅÊµÅÁ®ã„ÄÇ Ê≠£Á°ÆÁöÑÊñáÊú¨È¢ÑÂ§ÑÁêÜÂèØÊòæËëóÂΩ±ÂìçÊ®°ÂûãÊÄßËÉΩÂíåÊïàÁéá„ÄÇ ‰øùÁïôÊú™Áü•Á¥¢ÂºïÔºö\n‰øùËØÅÂØπÁº∫Â§±Êï∞ÊçÆÊàñÂ≠óÂÖ∏Â§ñÊñ∞ËØçËÉΩÊúâÂü∫Êú¨ÁöÑË°®Á§∫ÔºåÊèêÂçáÊ®°ÂûãÂÆπÈîôÊÄß„ÄÇ ÂÆûÈôÖ‰ΩøÁî®Ôºö\nÂØπ‰∫éÂ∞èËßÑÊ®°Á±ªÂà´ÂèØÁõ¥Êé•One-HotÁºñÁ†ÅÔºõÂØπ‰∫éËØçÂÖ∏ÂæàÂ§ßÁöÑÂú∫ÊôØÔºåÈÄöÂ∏∏‰ºöËøõ‰∏ÄÊ≠•ËÄÉËôëËØçÂµåÂÖ•ÔºàWord EmbeddingÔºâÊàñÈ¢ÑËÆ≠ÁªÉËØ≠Ë®ÄÊ®°Âûã„ÄÇ ","permalink":"http://localhost:1313/posts/nlp-1/","summary":"\u003ch2 id=\"‰∏ÄÊï∞ÂÄºÁâπÂæÅ‰∏éÁ±ªÂà´ÁâπÂæÅ\"\u003e‰∏Ä„ÄÅÊï∞ÂÄºÁâπÂæÅ‰∏éÁ±ªÂà´ÁâπÂæÅ\u003c/h2\u003e\n\u003col\u003e\n\u003cli\u003e\u003cstrong\u003eÊï∞ÂÄºÁâπÂæÅ (Numeric Features)\u003c/strong\u003e\n\u003cul\u003e\n\u003cli\u003eÂÖ∑ÊúâÂèØÂä†ÂáèÁöÑÊÑè‰πâÔºå‰∏îÂ≠òÂú®Â§ßÂ∞èÈ°∫Â∫è„ÄÇ\u003c/li\u003e\n\u003cli\u003e‰æãÂ≠êÔºöÂπ¥ÈæÑ„ÄÅÊ∏©Â∫¶Á≠â„ÄÇÂèØ‰ª•Áõ¥Êé•‰øùÁïôÂÖ∂Êï¥Êï∞ÊàñÊµÆÁÇπÊï∞ÂΩ¢Âºè‰æõÊ®°Âûã‰ΩøÁî®„ÄÇ\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003eÁ±ªÂà´ÁâπÂæÅ (Categorical Features)\u003c/strong\u003e\n\u003cul\u003e\n\u003cli\u003eÊï∞ÊçÆÂÄºÁ¶ªÊï£Ôºå‰∏çÂÖ∑Â§á‚ÄúÊï∞ÂÄºÂ§ßÂ∞è‚ÄùÈó¥ÁöÑÂèØÊØîÊÑè‰πâ„ÄÇ\u003c/li\u003e\n\u003cli\u003e‰æãÂ≠êÔºöÂõΩÁ±çÔºàÁæéÂõΩ/‰∏≠ÂõΩ/Âç∞Â∫¶Á≠âÔºâ„ÄÅÊÄßÂà´ÔºàÁî∑/Â•≥ÔºâÁ≠â„ÄÇ\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003eÈóÆÈ¢ò\u003c/strong\u003eÔºöËã•‰ªÖÁî®Êï¥Êï∞Ë°®Á§∫ÔºàÁæéÂõΩ=1, ‰∏≠ÂõΩ=2ÔºâÔºå‰ºöÂºïÂÖ•ÈîôËØØÁöÑÊï∞ÂÄºËøêÁÆóÂÖ≥Á≥ªÔºåÂ¶Ç ‚ÄúÁæéÂõΩ + ‰∏≠ÂõΩ = Âç∞Â∫¶‚Äù„ÄÇ\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003c/ol\u003e\n\u003ch2 id=\"‰∫åone-hotÁºñÁ†ÅÁöÑÂä®Êú∫‰∏éÊµÅÁ®ã\"\u003e‰∫å„ÄÅOne-HotÁºñÁ†ÅÁöÑÂä®Êú∫‰∏éÊµÅÁ®ã\u003c/h2\u003e\n\u003col\u003e\n\u003cli\u003e\n\u003cp\u003e\u003cstrong\u003e‰∏∫‰ªÄ‰πà‰ΩøÁî®One-Hot\u003c/strong\u003e\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eÈÄöËøáÂ∞ÜÁ±ªÂà´Êò†Â∞Ñ‰∏∫ÂêëÈáèÔºåÈÅøÂÖçÊï¥Êï∞ÁºñÁ†ÅÂºïÂÖ•ÁöÑ‰º™Êï∞ÂÄºÂÖ≥Á≥ª„ÄÇ\u003c/li\u003e\n\u003cli\u003eÂêåÊó∂‰øùÁïôÂêÑÁßçÂèØËÉΩÁ±ªÂà´ÁöÑ‰ø°ÊÅØÔºå‰∏î‰ªÖÂú®ÂØπÂ∫î‰ΩçÁΩÆ‰∏∫1ÔºåÂÖ∂‰ªñ‰ΩçÁΩÆ‰∏∫0„ÄÇ\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003e\u003cstrong\u003eÂª∫Á´ãÊò†Â∞ÑÔºö‰ªéÁ±ªÂà´Âà∞Á¥¢Âºï\u003c/strong\u003e\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e‰∏∫ÊØè‰∏™Á±ªÂà´ÂàÜÈÖç‰∏Ä‰∏™ÂîØ‰∏ÄÁ¥¢ÂºïÔºåÈÄöÂ∏∏‰ªé1ÂºÄÂßã„ÄÇ\u003c/li\u003e\n\u003cli\u003eÈ¢ÑÁïôÁ¥¢Âºï0Ë°®Á§∫‚ÄúÊú™Áü•‚ÄùÊàñ‚ÄúÁº∫Â§±‚ÄùÔºåÂØπÂ∫îÂÖ®0ÂêëÈáè„ÄÇ\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003e\u003cstrong\u003eËΩ¨Êç¢‰∏∫One-HotÂêëÈáè\u003c/strong\u003e\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eËã•Á±ªÂà´ÊÄªÊï∞‰∏∫197ÔºåÂàôÁî®197Áª¥ÂêëÈáèË°®Á§∫„ÄÇ\u003c/li\u003e\n\u003cli\u003e‰æãÂ≠êÔºöÁæéÂõΩ \u003ccode\u003e[1, 0, 0, 0, ‚Ä¶]\u003c/code\u003eÔºå ‰∏≠ÂõΩ \u003ccode\u003e[0, 1, 0, 0, ‚Ä¶]\u003c/code\u003e„ÄÇ\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003e\u003cstrong\u003eÁ§∫‰æãÔºöË°®Á§∫‰∏Ä‰∏™‰∫∫ÁöÑÁâπÂæÅ\u003c/strong\u003e\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eÁâπÂæÅÂåÖÂê´ÔºàÂπ¥ÈæÑ, ÊÄßÂà´, ÂõΩÁ±çÔºåÂÖ∂‰∏≠ÂõΩÁ±ç197ÁßçÔºâ\u003c/li\u003e\n\u003cli\u003eÁª¥Â∫¶ÊÄªÂíåÔºö1Áª¥_age + 1Áª¥_gender + 197Áª¥_nationality = 199Áª¥„ÄÇ\u003c/li\u003e\n\u003cli\u003e‰æãÂ¶Ç \u003ccode\u003e(28, Â•≥, ‰∏≠ÂõΩ)\u003c/code\u003e ‚Üí \u003ccode\u003e[28, 0, 0, 1, 0, ‚Ä¶, 0]\u003c/code\u003e„ÄÇ\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003c/ol\u003e\n\u003ch2 id=\"‰∏âÊñáÊú¨Êï∞ÊçÆÂ§ÑÁêÜÊµÅÁ®ã\"\u003e‰∏â„ÄÅÊñáÊú¨Êï∞ÊçÆÂ§ÑÁêÜÊµÅÁ®ã\u003c/h2\u003e\n\u003cp\u003eÊñáÊú¨Âú®Ëá™ÁÑ∂ËØ≠Ë®ÄÂ§ÑÁêÜÔºàNLPÔºâ‰∏≠‰Ωú‰∏∫Â∏∏ËßÅÁöÑÂéüÂßãËæìÂÖ•ÔºåÈúÄË¶ÅÊï∞ÂÄºÂåñÊâçËÉΩÈÄÅÂÖ•Ê®°Âûã„ÄÇ‰∏ÄËà¨Ê≠•È™§Â¶Ç‰∏ãÔºö\u003c/p\u003e\n\u003col\u003e\n\u003cli\u003e\n\u003cp\u003e\u003cstrong\u003eÂàÜËØç (Tokenization)\u003c/strong\u003e\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eÂ∞ÜÊñáÊú¨ÊãÜÂàÜ‰∏∫‰∏Ä‰∏™‰∏™ÂçïËØçÔºàTokenÔºâ„ÄÇ\u003c/li\u003e\n\u003cli\u003e‰æãÂ≠êÔºö\u003ccode\u003e\u0026quot;... to be or not to be...\u0026quot;\u003c/code\u003e ‚Üí \u003ccode\u003e[\u0026quot;...\u0026quot;, \u0026quot;to\u0026quot;, \u0026quot;be\u0026quot;, \u0026quot;or\u0026quot;, \u0026quot;not\u0026quot;, \u0026quot;to\u0026quot;, \u0026quot;be\u0026quot;, \u0026quot;...\u0026quot;]\u003c/code\u003e„ÄÇ\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003e\u003cstrong\u003eÁªüËÆ°ËØçÈ¢ë \u0026amp; ÊûÑÂª∫ËØçÂÖ∏\u003c/strong\u003e\u003c/p\u003e","title":""},{"content":"Text to Sequence ÊñáÊú¨Â§ÑÁêÜ\nStep1: Tokenization\nTokenization breaks a piece of text down into a list of tokens.\nHere, a token is a word. (A token can be a character in some applications.)\nTokenizationËÆ≤Á©∂ÂæàÂ§öÔºå‰æãÂ¶ÇÊòØÂê¶Â∫îËØ•ÊääÂ§ßÂÜôÊîπÊàêÂ∞èÂÜôÂë¢ÔºüËøõË°åtypo correctionÁ≠âÁ≠â\nStep2: Build Dictionary\nUse a dictionary (hash table) to count word frequencies.\nThe dictionary maps word to index.\nÂèØ‰ª•È¶ñÂÖàÁªüËÆ°ËØçÈ¢ëÂéªÊéâ‰ΩéÈ¢ëËØçÔºåÁÑ∂ÂêéËÆ©ÊØè‰∏™ËØçÂØπÂ∫î‰∏Ä‰∏™Ê≠£Êï¥Êï∞ÔºõËøôÊ†∑ÁöÑËØùÔºå‰∏ÄÂè•ËØùÂ∞±ÂèØ‰ª•Áî®‰∏Ä‰∏™Ê≠£Êï¥Êï∞ÂàóË°®Ë°®Á§∫ÔºåËøô‰∏™ÂàóË°®Â∞±Âè´sequenceÔºõÂ¶ÇÊûúÂøÖË¶ÅÂ∞±ËøòÂæóÂÅöone-hot encoding„ÄÇ\nÁªìÊûú\n‰ΩÜÊòØÈïøÂ∫¶‰∏çÁªü‰∏Ä\nStep4: ÂØπÈΩêsequence\nËß£ÂÜ≥ÊñπÊ°àÊòØËøôÊ†∑ÁöÑÔºöÂèØ‰ª•Âõ∫ÂÆöÈïøÂ∫¶‰∏∫wÔºåÂä†ÂÖ•‰∏Ä‰∏™Â∫èÂàóÈïøÂ∫¶Â§™ÈïøÔºåÂ∞±Á†çÊéâÂâçÈù¢ÁöÑËØçÔºåÂè™‰øùÁïôÊúÄÂêéw‰∏™ËØçÔºõÂ¶ÇÊûú‰∏Ä‰∏™Â∫èÂàóÂ§™Áü≠ÔºåÂ∞±ÂÅözero paddingÔºåÁî®0Â°´ÂÖÖ\nËøôÊ†∑‰∏ÄÊù•ÔºåÊâÄÊúâÁöÑÂ∫èÂàóÈïøÂ∫¶Â∞±Áªü‰∏Ä‰∫Ü\nÊñáÊú¨Â§ÑÁêÜÂÆåÊàê‰∫ÜÔºåÊé•‰∏ãÊù•ÊòØword embeddingÔºåÊääÂçïËØçË°®Á§∫‰∏∫‰∏Ä‰∏™‰ΩéÁª¥ÂêëÈáèÔºõ\nÁÑ∂ËÄåËøôÊ†∑ÂÅöÁöÑËØùÔºåÂ¶ÇÊûúÊòØ10000‰∏™ÂçïËØçÔºåÁª¥Â∫¶Â∞±ÊòØ10000Áª¥ÔºåÁª¥Â∫¶Â§™È´ò‰∫ÜÔºõÂõ†Ê≠§Ë¶ÅÂÅöword embeddingÔºõ\nÂÖ∑‰ΩìÂÅöÊ≥ïÂ∞±ÊòØÊääone-hotÂêëÈáèe_iÂíåÂèÇÊï∞Áü©ÈòµpÁõ∏‰πòÔºõÁü©ÈòµPËΩ¨ÁΩÆÁöÑÂ§ßÂ∞èÊòØd x vÔºõdÊòØËØçÂêëÈáèÁöÑÁª¥Â∫¶ÔºõvÊòØÂ≠óÂÖ∏ÈáåËØçÊ±áÁöÑÊï∞ÈáèÔºõÁªìÊûú‰∏∫x_iÔºõx_iÂ∞±ÊòØ‰∏Ä‰∏™ËØçÂêëÈáèÔºõÂ¶ÇÊûúone-hotÂêëÈáèÁöÑÁ¨¨‰∏âË°å‰∏∫1ÔºõÈÇ£‰πàx_iÂ∞±ÊòØPËΩ¨ÁΩÆÁü©ÈòµÁöÑÁ¨¨‰∏âÂàóÔºàÂÖ∂‰ΩôÂàóÈÉΩ‰∏∫0ÔºâÔºõÊâÄ‰ª•PËΩ¨ÁΩÆÊØè‰∏ÄÂàóÈÉΩÊòØ‰∏Ä‰∏™ËØçÂêëÈáèÔºõÊâÄ‰ª•Áü©ÈòµPÊú¨Ë∫´ÁöÑÊØè‰∏ÄË°åÂ∞±ÊòØ‰∏Ä‰∏™ËØçÂêëÈáèÔºõÂÖ∂Ë°åÊï∞‰∏∫vÔºõÂç≥vocabularyÔºåËØçÊ±áÈáèÔºõÊØè‰∏ÄË°åÂØπÂ∫î‰∏Ä‰∏™ÂçïËØçÔºõÁü©ÈòµÁöÑÂàóÊï∞‰∏∫dÔºõdÊòØÁî®Êà∑ÂÜ≥ÂÆöÁöÑÔºõdÁöÑÂ§ßÂ∞è‰ºöÂÜ≥ÂÆöÊú∫Âô®Â≠¶‰π†Ê®°ÂûãÁöÑË°®Áé∞ÔºõÂ∫îËØ•Áî®xxxÊù•ÈÄâÊã©‰∏Ä‰∏™ÊØîËæÉÂ•ΩÁöÑdÔºõ\nÊàë‰ª¨ÁöÑ‰ªªÂä°ÊòØÁúãËØÑËÆ∫ÊòØÊ≠£Èù¢ÁöÑËøòÊòØË¥üÈù¢ÁöÑÔºõÂèÇÊï∞Áü©ÈòµÊòØ‰ªéËÆ≠ÁªÉÊï∞ÊçÆ‰∏≠Â≠¶‰π†Âá∫Êù•ÁöÑÔºåÊâÄ‰ª•Â≠¶Âá∫Êù•ÁöÑËØçÂêëÈáèÊòØÂ∏¶ÊúâÊÑüÊÉÖËâ≤ÂΩ©ÁöÑÔºõÂÅáËÆæËøô‰∫õËØçÂêëÈáèÈÉΩÊòØ‰∫åÁª¥ÁöÑÔºåÂàôÂèØ‰ª•Âú®Âπ≥Èù¢ÂùêÊ†áÁ≥ª‰∏≠Ê†áÂá∫‰∏ãÈù¢ËØçÂêëÈáè\nkerasÊèê‰æõembeddingÂ±ÇÔºõÁî®Êà∑ÂèØ‰ª•ÊåáÂÆövocabularyÂ§ßÂ∞èÂíådÁöÑÂ§ßÂ∞èÔºõ‰ª•ÂèäÊØè‰∏Ä‰∏™sequenceÁöÑÈïøÂ∫¶ÔºõdÊòØÊ†πÊçÆÁÆóÊ≥ïÈÄâÂá∫Êù•ÁöÑ Âà∞Ëøô‰∏ÄÊ≠•ÔºåÊàë‰ª¨Â∑≤ÁªèÂÆåÊàê‰∫ÜÊñáÊú¨Â§ÑÁêÜÂíåword embedding„ÄÇÊé•‰∏ãÊù•Â∞±ÊòØÁî®Logistic Regression for Binary ClassificationÂÅö‰∫åÂàÜÁ±ªÔºõ\n","permalink":"http://localhost:1313/posts/nlp-2/","summary":"\u003ch3 id=\"text-to-sequence\"\u003eText to Sequence\u003c/h3\u003e\n\u003cp\u003eÊñáÊú¨Â§ÑÁêÜ\u003c/p\u003e\n\u003cp\u003eStep1: Tokenization\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\n\u003cp\u003eTokenization breaks a piece of text down into a list of tokens.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003eHere, a token is a word. (A token can be a character in some applications.)\u003c/p\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003eTokenizationËÆ≤Á©∂ÂæàÂ§öÔºå‰æãÂ¶ÇÊòØÂê¶Â∫îËØ•ÊääÂ§ßÂÜôÊîπÊàêÂ∞èÂÜôÂë¢ÔºüËøõË°åtypo correctionÁ≠âÁ≠â\u003c/p\u003e\n\u003cp\u003e\u003cimg alt=\"image-20250322150322238\" loading=\"lazy\" src=\"./NLP-2.assets/image-20250322150322238.png\"\u003e\u003c/p\u003e\n\u003cp\u003eStep2: Build Dictionary\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\n\u003cp\u003eUse a dictionary (hash table) to count word frequencies.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003eThe dictionary maps word to index.\u003c/p\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003eÂèØ‰ª•È¶ñÂÖàÁªüËÆ°ËØçÈ¢ëÂéªÊéâ‰ΩéÈ¢ëËØçÔºåÁÑ∂ÂêéËÆ©ÊØè‰∏™ËØçÂØπÂ∫î‰∏Ä‰∏™Ê≠£Êï¥Êï∞ÔºõËøôÊ†∑ÁöÑËØùÔºå‰∏ÄÂè•ËØùÂ∞±ÂèØ‰ª•Áî®‰∏Ä‰∏™Ê≠£Êï¥Êï∞ÂàóË°®Ë°®Á§∫ÔºåËøô‰∏™ÂàóË°®Â∞±Âè´sequenceÔºõÂ¶ÇÊûúÂøÖË¶ÅÂ∞±ËøòÂæóÂÅöone-hot encoding„ÄÇ\u003cimg alt=\"image-20250322150620890\" loading=\"lazy\" src=\"./NLP-2.assets/image-20250322150620890.png\"\u003e\u003c/p\u003e\n\u003cp\u003eÁªìÊûú\u003c/p\u003e\n\u003cp\u003e\u003cimg alt=\"image-20250322150754528\" loading=\"lazy\" src=\"./NLP-2.assets/image-20250322150754528.png\"\u003e\u003c/p\u003e\n\u003cp\u003e‰ΩÜÊòØÈïøÂ∫¶‰∏çÁªü‰∏Ä\u003c/p\u003e\n\u003cp\u003eStep4: ÂØπÈΩêsequence\u003c/p\u003e\n\u003cp\u003e\u003cimg alt=\"image-20250322150854986\" loading=\"lazy\" src=\"./NLP-2.assets/image-20250322150854986.png\"\u003e\u003c/p\u003e\n\u003cp\u003eËß£ÂÜ≥ÊñπÊ°àÊòØËøôÊ†∑ÁöÑÔºöÂèØ‰ª•Âõ∫ÂÆöÈïøÂ∫¶‰∏∫wÔºåÂä†ÂÖ•‰∏Ä‰∏™Â∫èÂàóÈïøÂ∫¶Â§™ÈïøÔºåÂ∞±Á†çÊéâÂâçÈù¢ÁöÑËØçÔºåÂè™‰øùÁïôÊúÄÂêéw‰∏™ËØçÔºõÂ¶ÇÊûú‰∏Ä‰∏™Â∫èÂàóÂ§™Áü≠ÔºåÂ∞±ÂÅözero paddingÔºåÁî®0Â°´ÂÖÖ\u003c/p\u003e\n\u003cp\u003e\u003cimg alt=\"image-20250322151030119\" loading=\"lazy\" src=\"./NLP-2.assets/image-20250322151030119.png\"\u003e\u003c/p\u003e\n\u003cp\u003eËøôÊ†∑‰∏ÄÊù•ÔºåÊâÄÊúâÁöÑÂ∫èÂàóÈïøÂ∫¶Â∞±Áªü‰∏Ä‰∫Ü\u003c/p\u003e\n\u003cp\u003e\u003cimg alt=\"image-20250322151117125\" loading=\"lazy\" src=\"./NLP-2.assets/image-20250322151117125.png\"\u003e\u003c/p\u003e\n\u003cp\u003eÊñáÊú¨Â§ÑÁêÜÂÆåÊàê‰∫ÜÔºåÊé•‰∏ãÊù•ÊòØword embeddingÔºåÊääÂçïËØçË°®Á§∫‰∏∫‰∏Ä‰∏™‰ΩéÁª¥ÂêëÈáèÔºõ\u003c/p\u003e\n\u003cp\u003e\u003cimg alt=\"image-20250322151252837\" loading=\"lazy\" src=\"./NLP-2.assets/image-20250322151252837.png\"\u003e\u003c/p\u003e","title":""},{"content":"üëã About me I\u0026rsquo;m \u0026hellip;\nüìö Education üá≠üá∞ The University of Hong Kong 09/2024 - Expected 11/2025 School of Computing and Data Science Master of Science in Electronic Commerce \u0026amp; Internet Computing Relevant Courses: Machine learning for business and e-commerce, Knowledge graphs, Financial fraud analytics, Internet infrastructure technologies, Website engineering, Blockchain and cryptocurrency, etc. üá®üá≥ Beijing Institute of Technology 09/2020 - 06/2024 School of Computer Science \u0026amp; Technology Bachelor of Engineering in Software Engineering, last two years GPA: 3.7/4 Relevant Courses: Reinforcement Learning, Deep Learning and Computer Vision, Artificial Intelligence and Robot Ethics, Almost Human: Mind, Brain and Artificial Intelligence, Mathematical Analysis for Engineering, Linear Algebra, Probability and Mathematical Statistics, etc. Skills: Python, Java, common data structures, design patterns, machine learning basics and algorithms, Linux, PyTorch, and some development tools (git, conda, etc.). üèÜ Awards \u0026amp; Honors Beijing Institute of Technology Undergraduate Scholarship (Top 20% of Grade) 06/2023 3rd Prize of China International \u0026#34;Internet \u0026#43;\u0026#34; College Student\u0026#39;s Innovation Competition 08/2022 Bronze Prize of \u0026#34;Challenge Cup\u0026#34; Capital University Entrepreneurship Competition 05/2022 üíº Project Experience Online Transaction Fraud Detection 09/2024 ‚Äì 01/2025 Independent project, supervised by Dr. Vivien Chan Focused on addressing financial fraud in e-commerce to enhance the accuracy of transaction anomaly detection, while independently managing the entire case study that included data preprocessing, feature engineering, model building, evaluation, and results analysis. Effectively resolved class imbalance issues using SMOTE and ROSE techniques. Built various models including Logistic Regression, Random Forest, XGBoost, and LightGBM, ultimately selecting the LightGBM model to achieve a recall rate of 95.45% and an AUC of 99.84%. Wrote efficient and maintainable code, enhancing model training and data processing efficiency through parallel computing and logging. Multi-Model Intelligent Text Keyword Extraction System 08/2023 ‚Äì 09/2023 Group project, supervised by Associate Prof. Xiaolin Zhao Designed and implemented an intelligent text summary system that automatically extracts keywords from article titles and abstracts, enhancing the understanding and summarization of text information. Participated in the planning of the technical route and built a hybrid model combining extractive and generative approaches, utilizing advanced natural language processing techniques including KeyBERT, Sentence Transformer, BERT, and T5 models. Responsible for data preprocessing and tokenization, as well as the end-to-end implementation and training of the T5 model, optimizing the model architecture and hyperparameters, achieving satisfactory results after only 3 epochs of training. Model evaluation results showed that the Rouge-1, Rouge-2, and Rouge-L metrics reached 0.6345, 0.5038, and 0.5282, respectively, in the third epoch, validating the model\u0026rsquo;s effectiveness in the summarization task. Cambridge University Machine Learning Summer Project 07/2023 ‚Äì 08/2023 Group project, supervised by Prof. Pietro Li√≤ Participated in the Cambridge University deep learning summer project, focusing on deep reinforcement learning; explored multi-agent learning algorithms across different environments. Reproduced the Multi-Agent Deep Deterministic Policy Gradient (MADDPG) algorithm in the Simple Adversary environment and studied the effect of agent numbers on convergence speed and stability, finding optimal stability at 21 agents. Designed and implemented comparative experiments inspired by the Rainbow algorithm, assessing target network strategies versus the Double Deep Q-Network (Double DQN). The results demonstrated that Double DQN significantly enhanced convergence speed, optimizing the overall learning process. Co-authored a group project paper on agent numbers and strategies effectiveness in multi-agent systems, achieving a score of 71% in the summer program (the highest in my group) and a \u0026ldquo;First Class\u0026rdquo; classification in the UK grading system. Deep Learning and Computer Vision Semester Project 09/2022 ‚Äì 12/2022 Independent project, supervised by Associate Prof. Guangyu Gao Designed and implemented a waste classifier using the ResNet model to improve classification accuracy and reduce resource waste. The project also enhanced understanding of transfer learning techniques with ResNet. Collected a dataset of 16 waste categories and preprocessed the images for uniformity and standardization, incorporating data augmentation techniques to enhance the dataset. Conducted experiments using ResNet34 and ResNet50 models through transfer learning, accelerating network convergence by leveraging pretrained weights. During training, techniques such as Batch Normalization and Dropout were applied to mitigate the risk of overfitting. The final model achieved an accuracy of 90% on the training set, while the performance on the test set was 61%, indicating a significant overfitting phenomenon during the training process. üéì Internship Beijing Academy of Quantum Information Science 08/2023 ‚Äì 01/2024 Research Intern at Quantum Computation Department Proposed a quantum convolution kernel design based on variational quantum circuits and developed a universal quantum convolution layer, successfully integrating it into classical CNN architectures such as VGG, GoogLeNet, and ResNet. Developed and evaluated various hybrid models, including a simple model named HQCCNN-2, which achieved 84.45% accuracy on the FashionMNIST dataset, surpassing the traditional CNN\u0026rsquo;s 80.72%. This demonstrates the effectiveness of the quantum convolution layer in improving model performance. Tested on a real quantum computer further validated the effectiveness of the hybrid model, demonstrating the viable integration of quantum computing with deep learning, and highlighting the potential for leveraging quantum properties to enhance model performance. üèÖ Competition Experience China International \u0026#34;Internet \u0026#43;\u0026#34; College Students\u0026#39; Innovation Competition 08/2022 Zhongke Ushield: Deep Learning-based Face Privacy Protection Authentication System Responsible for constructing a localized facial feature extraction engine based on MobileFaceNet, ensuring feature extraction is completed on end devices (such as mobile phones and cameras), guaranteeing that raw data does not leave the domain and is not stored, thus enhancing user privacy protection while improving recognition efficiency. \u0026#34;Challenge Cup\u0026#34; Capital University Entrepreneurship Competition 05/2022 Smart Orchard Responsible for the development of the fruit detection, ripeness prediction, and pest identification system, using deep convolutional neural network (CNN) technology for intelligent monitoring of crop growth conditions. Applied advanced object detection algorithms such as Faster R-CNN and YOLO to achieve high precision in apple detection and ripeness assessment, with an accuracy rate exceeding 90%, significantly enhancing the intelligence level of orchard management. Built and trained a dedicated dataset containing various pest samples, optimizing pest detection accuracy through data preprocessing (such as image normalization and resizing) and data augmentation techniques (like rotation, flipping, and noise addition), enabling the real-time monitoring system to accurately identify over 80% of pests, providing effective scientific maintenance recommendations to help farmers reduce crop losses. üìã Extracurricular Activities Vice President, Cyber Security Club, Beijing Institute of Technology 09/2021-09/2022 Backbone, Media Center of the Student Union of Beijing Institute of Technology 10/2020-06/2021 üì´ Contact üìß zongsi.xu@outlook.com üëî Zongsi (Tristan) Xu üíª github.com/BaizeXS üìç Hong Kong SAR, China ","permalink":"http://localhost:1313/resume/","summary":"Personal resume of Zongsi (Tristan) Xu","title":"Zongsi (Tristan) Xu"},{"content":"‰∏Ä„ÄÅÊï∞ÂÄºÁâπÂæÅ‰∏éÁ±ªÂà´ÁâπÂæÅ Êï∞ÂÄºÁâπÂæÅ (Numeric Features) ÂÖ∑ÊúâÂèØÂä†ÂáèÁöÑÊÑè‰πâÔºå‰∏îÂ≠òÂú®Â§ßÂ∞èÈ°∫Â∫è„ÄÇ ‰æãÂ≠êÔºöÂπ¥ÈæÑ„ÄÅÊ∏©Â∫¶Á≠â„ÄÇÂèØ‰ª•Áõ¥Êé•‰øùÁïôÂÖ∂Êï¥Êï∞ÊàñÊµÆÁÇπÊï∞ÂΩ¢Âºè‰æõÊ®°Âûã‰ΩøÁî®„ÄÇ Á±ªÂà´ÁâπÂæÅ (Categorical Features) Êï∞ÊçÆÂÄºÁ¶ªÊï£Ôºå‰∏çÂÖ∑Â§á‚ÄúÊï∞ÂÄºÂ§ßÂ∞è‚ÄùÈó¥ÁöÑÂèØÊØîÊÑè‰πâ„ÄÇ ‰æãÂ≠êÔºöÂõΩÁ±çÔºàÁæéÂõΩ/‰∏≠ÂõΩ/Âç∞Â∫¶Á≠âÔºâ„ÄÅÊÄßÂà´ÔºàÁî∑/Â•≥ÔºâÁ≠â„ÄÇ ÈóÆÈ¢òÔºöËã•‰ªÖÁî®Êï¥Êï∞Ë°®Á§∫ÔºàÁæéÂõΩ=1, ‰∏≠ÂõΩ=2ÔºâÔºå‰ºöÂºïÂÖ•ÈîôËØØÁöÑÊï∞ÂÄºËøêÁÆóÂÖ≥Á≥ªÔºåÂ¶Ç ‚ÄúÁæéÂõΩ + ‰∏≠ÂõΩ = Âç∞Â∫¶‚Äù„ÄÇ ‰∫å„ÄÅOne-HotÁºñÁ†ÅÁöÑÂä®Êú∫‰∏éÊµÅÁ®ã ‰∏∫‰ªÄ‰πà‰ΩøÁî®One-Hot\nÈÄöËøáÂ∞ÜÁ±ªÂà´Êò†Â∞Ñ‰∏∫ÂêëÈáèÔºåÈÅøÂÖçÊï¥Êï∞ÁºñÁ†ÅÂºïÂÖ•ÁöÑ‰º™Êï∞ÂÄºÂÖ≥Á≥ª„ÄÇ ÂêåÊó∂‰øùÁïôÂêÑÁßçÂèØËÉΩÁ±ªÂà´ÁöÑ‰ø°ÊÅØÔºå‰∏î‰ªÖÂú®ÂØπÂ∫î‰ΩçÁΩÆ‰∏∫1ÔºåÂÖ∂‰ªñ‰ΩçÁΩÆ‰∏∫0„ÄÇ Âª∫Á´ãÊò†Â∞ÑÔºö‰ªéÁ±ªÂà´Âà∞Á¥¢Âºï\n‰∏∫ÊØè‰∏™Á±ªÂà´ÂàÜÈÖç‰∏Ä‰∏™ÂîØ‰∏ÄÁ¥¢ÂºïÔºåÈÄöÂ∏∏‰ªé1ÂºÄÂßã„ÄÇ È¢ÑÁïôÁ¥¢Âºï0Ë°®Á§∫‚ÄúÊú™Áü•‚ÄùÊàñ‚ÄúÁº∫Â§±‚ÄùÔºåÂØπÂ∫îÂÖ®0ÂêëÈáè„ÄÇ ËΩ¨Êç¢‰∏∫One-HotÂêëÈáè\nËã•Á±ªÂà´ÊÄªÊï∞‰∏∫197ÔºåÂàôÁî®197Áª¥ÂêëÈáèË°®Á§∫„ÄÇ ‰æãÂ≠êÔºöÁæéÂõΩ [1, 0, 0, 0, ‚Ä¶]Ôºå ‰∏≠ÂõΩ [0, 1, 0, 0, ‚Ä¶]„ÄÇ Á§∫‰æãÔºöË°®Á§∫‰∏Ä‰∏™‰∫∫ÁöÑÁâπÂæÅ\nÁâπÂæÅÂåÖÂê´ÔºàÂπ¥ÈæÑ, ÊÄßÂà´, ÂõΩÁ±çÔºåÂÖ∂‰∏≠ÂõΩÁ±ç197ÁßçÔºâ Áª¥Â∫¶ÊÄªÂíåÔºö1Áª¥_age + 1Áª¥_gender + 197Áª¥_nationality = 199Áª¥„ÄÇ ‰æãÂ¶Ç (28, Â•≥, ‰∏≠ÂõΩ) ‚Üí [28, 0, 0, 1, 0, ‚Ä¶, 0]„ÄÇ ‰∏â„ÄÅÊñáÊú¨Êï∞ÊçÆÂ§ÑÁêÜÊµÅÁ®ã ÊñáÊú¨Âú®Ëá™ÁÑ∂ËØ≠Ë®ÄÂ§ÑÁêÜÔºàNLPÔºâ‰∏≠‰Ωú‰∏∫Â∏∏ËßÅÁöÑÂéüÂßãËæìÂÖ•ÔºåÈúÄË¶ÅÊï∞ÂÄºÂåñÊâçËÉΩÈÄÅÂÖ•Ê®°Âûã„ÄÇ‰∏ÄËà¨Ê≠•È™§Â¶Ç‰∏ãÔºö\nÂàÜËØç (Tokenization)\nÂ∞ÜÊñáÊú¨ÊãÜÂàÜ‰∏∫‰∏Ä‰∏™‰∏™ÂçïËØçÔºàTokenÔºâ„ÄÇ ‰æãÂ≠êÔºö\u0026quot;... to be or not to be...\u0026quot; ‚Üí [\u0026quot;...\u0026quot;, \u0026quot;to\u0026quot;, \u0026quot;be\u0026quot;, \u0026quot;or\u0026quot;, \u0026quot;not\u0026quot;, \u0026quot;to\u0026quot;, \u0026quot;be\u0026quot;, \u0026quot;...\u0026quot;]„ÄÇ ÁªüËÆ°ËØçÈ¢ë \u0026amp; ÊûÑÂª∫ËØçÂÖ∏\nËØçÈ¢ëÁªüËÆ° Áî®ÂìàÂ∏åË°®/Â≠óÂÖ∏ËÆ∞ÂΩïÊØè‰∏™ÂçïËØçÂá∫Áé∞Ê¨°Êï∞„ÄÇ ÈÅçÂéÜÊñáÊú¨Êó∂ÔºåËã•ÂçïËØçÂ∞öÊú™ÂÖ•Ë°®ÔºåÂàôÊñ∞Âª∫ËÆ∞ÂΩïÔºõËã•Â∑≤Â≠òÂú®ÔºåÂàôËÆ°Êï∞+1„ÄÇ ÊéíÂ∫è‰∏éÁ¥¢Âºï ÊåâËØçÈ¢ëÈôçÂ∫èÊéíÂ∫èÔºåËØçÈ¢ëÊúÄÈ´òÁöÑÂçïËØçÊéíÂú®ÂâçÈù¢„ÄÇ Á¥¢Âºï‰ªé1ÂºÄÂßãÔºå0ÁïôÁªô‚ÄúÊú™Áü•‚Äù„ÄÇ ËØçÂÖ∏ËßÑÊ®°ÔºàvocabularyÔºâÂèØËßÜÈúÄÊ±ÇÊà™Êñ≠Ôºà‰æãÂ¶ÇÂè™‰øùÁïôTop 10kÔºâ„ÄÇ ‰∏∫‰ªÄ‰πàÁßªÈô§‰ΩéÈ¢ëËØç ‰ΩéÈ¢ëËØçÂèØËÉΩÊòØÊãºÂÜôÈîôËØØ„ÄÅÁΩïËßÅ‰∫∫ÂêçÁ≠âÔºåÂØπÊ®°ÂûãÂ∏ÆÂä©ÊúâÈôê„ÄÇ ÂáèÂ∞ëËØçÂÖ∏ËßÑÊ®°ÂèØÈôç‰ΩéËøêÁÆóÂºÄÈîÄ„ÄÅÂä†Âø´Ê®°ÂûãËÆ≠ÁªÉ‰∏éÊé®ÁêÜÈÄüÂ∫¶„ÄÇ Áã¨ÁÉ≠ÁºñÁ†Å (One-Hot Encoding)\nÂ∞ÜÊØè‰∏™ÂçïËØçÊò†Â∞Ñ‰∏∫ËØçÂÖ∏‰∏≠ÁöÑÁ¥¢ÂºïÂêéÔºàÂ¶Ç [2, 4, 1, 8, ‚Ä¶]ÔºâÔºåÂèØËøõ‰∏ÄÊ≠•ËΩ¨Êç¢ÊàêOne-HotÂêëÈáè„ÄÇ One-HotÁª¥Â∫¶ÂèñÂÜ≥‰∫é‰øùÁïô‰∏ãÊù•ÁöÑËØçÂÖ∏Â§ßÂ∞èÔºà‰æãÂ¶Ç1‰∏áÔºâ„ÄÇ Êú™Êî∂ÂΩïÂçïËØçÂèØËÉΩÁõ¥Êé•ÂøΩÁï•ÔºåÊàñÁªü‰∏ÄÁî®Á¥¢Âºï0‰ª£Êõø„ÄÇ Âõõ„ÄÅÊ†∏ÂøÉÊî∂Ëé∑‰∏éÂ∫îÁî® Á±ªÂà´ÁâπÂæÅÂøÖÈúÄÊï∞ÂÄºÂåñÔºö\n‰ΩøÁî®Êï¥Êï∞1,2,3‚Ä¶‰ªÖË°®Á§∫Á±ªÂà´‚ÄúÊ†áËØÜ‚ÄùÔºåÂπ∂‰∏ç‰ª£Ë°®ÂÆÉ‰ª¨ÂèØËøõË°åÊï∞ÂÄºËøêÁÆó„ÄÇ Âõ†Ê≠§ÈúÄË¶ÅOne-HotÁ≠âÁºñÁ†ÅÊñπÂºèÔºåÈÅøÂÖçÊï∞ÂÄºËØØËß£„ÄÇ ÊñáÊú¨Êï∞ÊçÆÈ¢ÑÂ§ÑÁêÜÔºö\nÂàÜËØç„ÄÅËØçÈ¢ëÁªüËÆ°„ÄÅÊûÑÂª∫ËØçÂÖ∏„ÄÅÁ¥¢ÂºïÂåñ„ÄÅOne-HotÊàñÂÖ∂‰ªñÊñπÂºèÔºàÂ¶ÇËØçÂµåÂÖ•ÔºâÊòØÂ∏∏ËßÅÊµÅÁ®ã„ÄÇ Ê≠£Á°ÆÁöÑÊñáÊú¨È¢ÑÂ§ÑÁêÜÂèØÊòæËëóÂΩ±ÂìçÊ®°ÂûãÊÄßËÉΩÂíåÊïàÁéá„ÄÇ ‰øùÁïôÊú™Áü•Á¥¢ÂºïÔºö\n‰øùËØÅÂØπÁº∫Â§±Êï∞ÊçÆÊàñÂ≠óÂÖ∏Â§ñÊñ∞ËØçËÉΩÊúâÂü∫Êú¨ÁöÑË°®Á§∫ÔºåÊèêÂçáÊ®°ÂûãÂÆπÈîôÊÄß„ÄÇ ÂÆûÈôÖ‰ΩøÁî®Ôºö\nÂØπ‰∫éÂ∞èËßÑÊ®°Á±ªÂà´ÂèØÁõ¥Êé•One-HotÁºñÁ†ÅÔºõÂØπ‰∫éËØçÂÖ∏ÂæàÂ§ßÁöÑÂú∫ÊôØÔºåÈÄöÂ∏∏‰ºöËøõ‰∏ÄÊ≠•ËÄÉËôëËØçÂµåÂÖ•ÔºàWord EmbeddingÔºâÊàñÈ¢ÑËÆ≠ÁªÉËØ≠Ë®ÄÊ®°Âûã„ÄÇ ","permalink":"http://localhost:1313/posts/nlp-1/","summary":"\u003ch2 id=\"‰∏ÄÊï∞ÂÄºÁâπÂæÅ‰∏éÁ±ªÂà´ÁâπÂæÅ\"\u003e‰∏Ä„ÄÅÊï∞ÂÄºÁâπÂæÅ‰∏éÁ±ªÂà´ÁâπÂæÅ\u003c/h2\u003e\n\u003col\u003e\n\u003cli\u003e\u003cstrong\u003eÊï∞ÂÄºÁâπÂæÅ (Numeric Features)\u003c/strong\u003e\n\u003cul\u003e\n\u003cli\u003eÂÖ∑ÊúâÂèØÂä†ÂáèÁöÑÊÑè‰πâÔºå‰∏îÂ≠òÂú®Â§ßÂ∞èÈ°∫Â∫è„ÄÇ\u003c/li\u003e\n\u003cli\u003e‰æãÂ≠êÔºöÂπ¥ÈæÑ„ÄÅÊ∏©Â∫¶Á≠â„ÄÇÂèØ‰ª•Áõ¥Êé•‰øùÁïôÂÖ∂Êï¥Êï∞ÊàñÊµÆÁÇπÊï∞ÂΩ¢Âºè‰æõÊ®°Âûã‰ΩøÁî®„ÄÇ\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003eÁ±ªÂà´ÁâπÂæÅ (Categorical Features)\u003c/strong\u003e\n\u003cul\u003e\n\u003cli\u003eÊï∞ÊçÆÂÄºÁ¶ªÊï£Ôºå‰∏çÂÖ∑Â§á‚ÄúÊï∞ÂÄºÂ§ßÂ∞è‚ÄùÈó¥ÁöÑÂèØÊØîÊÑè‰πâ„ÄÇ\u003c/li\u003e\n\u003cli\u003e‰æãÂ≠êÔºöÂõΩÁ±çÔºàÁæéÂõΩ/‰∏≠ÂõΩ/Âç∞Â∫¶Á≠âÔºâ„ÄÅÊÄßÂà´ÔºàÁî∑/Â•≥ÔºâÁ≠â„ÄÇ\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003eÈóÆÈ¢ò\u003c/strong\u003eÔºöËã•‰ªÖÁî®Êï¥Êï∞Ë°®Á§∫ÔºàÁæéÂõΩ=1, ‰∏≠ÂõΩ=2ÔºâÔºå‰ºöÂºïÂÖ•ÈîôËØØÁöÑÊï∞ÂÄºËøêÁÆóÂÖ≥Á≥ªÔºåÂ¶Ç ‚ÄúÁæéÂõΩ + ‰∏≠ÂõΩ = Âç∞Â∫¶‚Äù„ÄÇ\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003c/ol\u003e\n\u003ch2 id=\"‰∫åone-hotÁºñÁ†ÅÁöÑÂä®Êú∫‰∏éÊµÅÁ®ã\"\u003e‰∫å„ÄÅOne-HotÁºñÁ†ÅÁöÑÂä®Êú∫‰∏éÊµÅÁ®ã\u003c/h2\u003e\n\u003col\u003e\n\u003cli\u003e\n\u003cp\u003e\u003cstrong\u003e‰∏∫‰ªÄ‰πà‰ΩøÁî®One-Hot\u003c/strong\u003e\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eÈÄöËøáÂ∞ÜÁ±ªÂà´Êò†Â∞Ñ‰∏∫ÂêëÈáèÔºåÈÅøÂÖçÊï¥Êï∞ÁºñÁ†ÅÂºïÂÖ•ÁöÑ‰º™Êï∞ÂÄºÂÖ≥Á≥ª„ÄÇ\u003c/li\u003e\n\u003cli\u003eÂêåÊó∂‰øùÁïôÂêÑÁßçÂèØËÉΩÁ±ªÂà´ÁöÑ‰ø°ÊÅØÔºå‰∏î‰ªÖÂú®ÂØπÂ∫î‰ΩçÁΩÆ‰∏∫1ÔºåÂÖ∂‰ªñ‰ΩçÁΩÆ‰∏∫0„ÄÇ\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003e\u003cstrong\u003eÂª∫Á´ãÊò†Â∞ÑÔºö‰ªéÁ±ªÂà´Âà∞Á¥¢Âºï\u003c/strong\u003e\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e‰∏∫ÊØè‰∏™Á±ªÂà´ÂàÜÈÖç‰∏Ä‰∏™ÂîØ‰∏ÄÁ¥¢ÂºïÔºåÈÄöÂ∏∏‰ªé1ÂºÄÂßã„ÄÇ\u003c/li\u003e\n\u003cli\u003eÈ¢ÑÁïôÁ¥¢Âºï0Ë°®Á§∫‚ÄúÊú™Áü•‚ÄùÊàñ‚ÄúÁº∫Â§±‚ÄùÔºåÂØπÂ∫îÂÖ®0ÂêëÈáè„ÄÇ\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003e\u003cstrong\u003eËΩ¨Êç¢‰∏∫One-HotÂêëÈáè\u003c/strong\u003e\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eËã•Á±ªÂà´ÊÄªÊï∞‰∏∫197ÔºåÂàôÁî®197Áª¥ÂêëÈáèË°®Á§∫„ÄÇ\u003c/li\u003e\n\u003cli\u003e‰æãÂ≠êÔºöÁæéÂõΩ \u003ccode\u003e[1, 0, 0, 0, ‚Ä¶]\u003c/code\u003eÔºå ‰∏≠ÂõΩ \u003ccode\u003e[0, 1, 0, 0, ‚Ä¶]\u003c/code\u003e„ÄÇ\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003e\u003cstrong\u003eÁ§∫‰æãÔºöË°®Á§∫‰∏Ä‰∏™‰∫∫ÁöÑÁâπÂæÅ\u003c/strong\u003e\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eÁâπÂæÅÂåÖÂê´ÔºàÂπ¥ÈæÑ, ÊÄßÂà´, ÂõΩÁ±çÔºåÂÖ∂‰∏≠ÂõΩÁ±ç197ÁßçÔºâ\u003c/li\u003e\n\u003cli\u003eÁª¥Â∫¶ÊÄªÂíåÔºö1Áª¥_age + 1Áª¥_gender + 197Áª¥_nationality = 199Áª¥„ÄÇ\u003c/li\u003e\n\u003cli\u003e‰æãÂ¶Ç \u003ccode\u003e(28, Â•≥, ‰∏≠ÂõΩ)\u003c/code\u003e ‚Üí \u003ccode\u003e[28, 0, 0, 1, 0, ‚Ä¶, 0]\u003c/code\u003e„ÄÇ\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003c/ol\u003e\n\u003ch2 id=\"‰∏âÊñáÊú¨Êï∞ÊçÆÂ§ÑÁêÜÊµÅÁ®ã\"\u003e‰∏â„ÄÅÊñáÊú¨Êï∞ÊçÆÂ§ÑÁêÜÊµÅÁ®ã\u003c/h2\u003e\n\u003cp\u003eÊñáÊú¨Âú®Ëá™ÁÑ∂ËØ≠Ë®ÄÂ§ÑÁêÜÔºàNLPÔºâ‰∏≠‰Ωú‰∏∫Â∏∏ËßÅÁöÑÂéüÂßãËæìÂÖ•ÔºåÈúÄË¶ÅÊï∞ÂÄºÂåñÊâçËÉΩÈÄÅÂÖ•Ê®°Âûã„ÄÇ‰∏ÄËà¨Ê≠•È™§Â¶Ç‰∏ãÔºö\u003c/p\u003e\n\u003col\u003e\n\u003cli\u003e\n\u003cp\u003e\u003cstrong\u003eÂàÜËØç (Tokenization)\u003c/strong\u003e\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eÂ∞ÜÊñáÊú¨ÊãÜÂàÜ‰∏∫‰∏Ä‰∏™‰∏™ÂçïËØçÔºàTokenÔºâ„ÄÇ\u003c/li\u003e\n\u003cli\u003e‰æãÂ≠êÔºö\u003ccode\u003e\u0026quot;... to be or not to be...\u0026quot;\u003c/code\u003e ‚Üí \u003ccode\u003e[\u0026quot;...\u0026quot;, \u0026quot;to\u0026quot;, \u0026quot;be\u0026quot;, \u0026quot;or\u0026quot;, \u0026quot;not\u0026quot;, \u0026quot;to\u0026quot;, \u0026quot;be\u0026quot;, \u0026quot;...\u0026quot;]\u003c/code\u003e„ÄÇ\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003e\u003cstrong\u003eÁªüËÆ°ËØçÈ¢ë \u0026amp; ÊûÑÂª∫ËØçÂÖ∏\u003c/strong\u003e\u003c/p\u003e","title":""},{"content":"Text to Sequence ÊñáÊú¨Â§ÑÁêÜ\nStep1: Tokenization\nTokenization breaks a piece of text down into a list of tokens.\nHere, a token is a word. (A token can be a character in some applications.)\nTokenizationËÆ≤Á©∂ÂæàÂ§öÔºå‰æãÂ¶ÇÊòØÂê¶Â∫îËØ•ÊääÂ§ßÂÜôÊîπÊàêÂ∞èÂÜôÂë¢ÔºüËøõË°åtypo correctionÁ≠âÁ≠â\nStep2: Build Dictionary\nUse a dictionary (hash table) to count word frequencies.\nThe dictionary maps word to index.\nÂèØ‰ª•È¶ñÂÖàÁªüËÆ°ËØçÈ¢ëÂéªÊéâ‰ΩéÈ¢ëËØçÔºåÁÑ∂ÂêéËÆ©ÊØè‰∏™ËØçÂØπÂ∫î‰∏Ä‰∏™Ê≠£Êï¥Êï∞ÔºõËøôÊ†∑ÁöÑËØùÔºå‰∏ÄÂè•ËØùÂ∞±ÂèØ‰ª•Áî®‰∏Ä‰∏™Ê≠£Êï¥Êï∞ÂàóË°®Ë°®Á§∫ÔºåËøô‰∏™ÂàóË°®Â∞±Âè´sequenceÔºõÂ¶ÇÊûúÂøÖË¶ÅÂ∞±ËøòÂæóÂÅöone-hot encoding„ÄÇ\nÁªìÊûú\n‰ΩÜÊòØÈïøÂ∫¶‰∏çÁªü‰∏Ä\nStep4: ÂØπÈΩêsequence\nËß£ÂÜ≥ÊñπÊ°àÊòØËøôÊ†∑ÁöÑÔºöÂèØ‰ª•Âõ∫ÂÆöÈïøÂ∫¶‰∏∫wÔºåÂä†ÂÖ•‰∏Ä‰∏™Â∫èÂàóÈïøÂ∫¶Â§™ÈïøÔºåÂ∞±Á†çÊéâÂâçÈù¢ÁöÑËØçÔºåÂè™‰øùÁïôÊúÄÂêéw‰∏™ËØçÔºõÂ¶ÇÊûú‰∏Ä‰∏™Â∫èÂàóÂ§™Áü≠ÔºåÂ∞±ÂÅözero paddingÔºåÁî®0Â°´ÂÖÖ\nËøôÊ†∑‰∏ÄÊù•ÔºåÊâÄÊúâÁöÑÂ∫èÂàóÈïøÂ∫¶Â∞±Áªü‰∏Ä‰∫Ü\nÊñáÊú¨Â§ÑÁêÜÂÆåÊàê‰∫ÜÔºåÊé•‰∏ãÊù•ÊòØword embeddingÔºåÊääÂçïËØçË°®Á§∫‰∏∫‰∏Ä‰∏™‰ΩéÁª¥ÂêëÈáèÔºõ\nÁÑ∂ËÄåËøôÊ†∑ÂÅöÁöÑËØùÔºåÂ¶ÇÊûúÊòØ10000‰∏™ÂçïËØçÔºåÁª¥Â∫¶Â∞±ÊòØ10000Áª¥ÔºåÁª¥Â∫¶Â§™È´ò‰∫ÜÔºõÂõ†Ê≠§Ë¶ÅÂÅöword embeddingÔºõ\nÂÖ∑‰ΩìÂÅöÊ≥ïÂ∞±ÊòØÊääone-hotÂêëÈáèe_iÂíåÂèÇÊï∞Áü©ÈòµpÁõ∏‰πòÔºõÁü©ÈòµPËΩ¨ÁΩÆÁöÑÂ§ßÂ∞èÊòØd x vÔºõdÊòØËØçÂêëÈáèÁöÑÁª¥Â∫¶ÔºõvÊòØÂ≠óÂÖ∏ÈáåËØçÊ±áÁöÑÊï∞ÈáèÔºõÁªìÊûú‰∏∫x_iÔºõx_iÂ∞±ÊòØ‰∏Ä‰∏™ËØçÂêëÈáèÔºõÂ¶ÇÊûúone-hotÂêëÈáèÁöÑÁ¨¨‰∏âË°å‰∏∫1ÔºõÈÇ£‰πàx_iÂ∞±ÊòØPËΩ¨ÁΩÆÁü©ÈòµÁöÑÁ¨¨‰∏âÂàóÔºàÂÖ∂‰ΩôÂàóÈÉΩ‰∏∫0ÔºâÔºõÊâÄ‰ª•PËΩ¨ÁΩÆÊØè‰∏ÄÂàóÈÉΩÊòØ‰∏Ä‰∏™ËØçÂêëÈáèÔºõÊâÄ‰ª•Áü©ÈòµPÊú¨Ë∫´ÁöÑÊØè‰∏ÄË°åÂ∞±ÊòØ‰∏Ä‰∏™ËØçÂêëÈáèÔºõÂÖ∂Ë°åÊï∞‰∏∫vÔºõÂç≥vocabularyÔºåËØçÊ±áÈáèÔºõÊØè‰∏ÄË°åÂØπÂ∫î‰∏Ä‰∏™ÂçïËØçÔºõÁü©ÈòµÁöÑÂàóÊï∞‰∏∫dÔºõdÊòØÁî®Êà∑ÂÜ≥ÂÆöÁöÑÔºõdÁöÑÂ§ßÂ∞è‰ºöÂÜ≥ÂÆöÊú∫Âô®Â≠¶‰π†Ê®°ÂûãÁöÑË°®Áé∞ÔºõÂ∫îËØ•Áî®xxxÊù•ÈÄâÊã©‰∏Ä‰∏™ÊØîËæÉÂ•ΩÁöÑdÔºõ\nÊàë‰ª¨ÁöÑ‰ªªÂä°ÊòØÁúãËØÑËÆ∫ÊòØÊ≠£Èù¢ÁöÑËøòÊòØË¥üÈù¢ÁöÑÔºõÂèÇÊï∞Áü©ÈòµÊòØ‰ªéËÆ≠ÁªÉÊï∞ÊçÆ‰∏≠Â≠¶‰π†Âá∫Êù•ÁöÑÔºåÊâÄ‰ª•Â≠¶Âá∫Êù•ÁöÑËØçÂêëÈáèÊòØÂ∏¶ÊúâÊÑüÊÉÖËâ≤ÂΩ©ÁöÑÔºõÂÅáËÆæËøô‰∫õËØçÂêëÈáèÈÉΩÊòØ‰∫åÁª¥ÁöÑÔºåÂàôÂèØ‰ª•Âú®Âπ≥Èù¢ÂùêÊ†áÁ≥ª‰∏≠Ê†áÂá∫‰∏ãÈù¢ËØçÂêëÈáè\nkerasÊèê‰æõembeddingÂ±ÇÔºõÁî®Êà∑ÂèØ‰ª•ÊåáÂÆövocabularyÂ§ßÂ∞èÂíådÁöÑÂ§ßÂ∞èÔºõ‰ª•ÂèäÊØè‰∏Ä‰∏™sequenceÁöÑÈïøÂ∫¶ÔºõdÊòØÊ†πÊçÆÁÆóÊ≥ïÈÄâÂá∫Êù•ÁöÑ Âà∞Ëøô‰∏ÄÊ≠•ÔºåÊàë‰ª¨Â∑≤ÁªèÂÆåÊàê‰∫ÜÊñáÊú¨Â§ÑÁêÜÂíåword embedding„ÄÇÊé•‰∏ãÊù•Â∞±ÊòØÁî®Logistic Regression for Binary ClassificationÂÅö‰∫åÂàÜÁ±ªÔºõ\n","permalink":"http://localhost:1313/posts/nlp-2/","summary":"\u003ch3 id=\"text-to-sequence\"\u003eText to Sequence\u003c/h3\u003e\n\u003cp\u003eÊñáÊú¨Â§ÑÁêÜ\u003c/p\u003e\n\u003cp\u003eStep1: Tokenization\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\n\u003cp\u003eTokenization breaks a piece of text down into a list of tokens.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003eHere, a token is a word. (A token can be a character in some applications.)\u003c/p\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003eTokenizationËÆ≤Á©∂ÂæàÂ§öÔºå‰æãÂ¶ÇÊòØÂê¶Â∫îËØ•ÊääÂ§ßÂÜôÊîπÊàêÂ∞èÂÜôÂë¢ÔºüËøõË°åtypo correctionÁ≠âÁ≠â\u003c/p\u003e\n\u003cp\u003e\u003cimg alt=\"image-20250322150322238\" loading=\"lazy\" src=\"./NLP-2.assets/image-20250322150322238.png\"\u003e\u003c/p\u003e\n\u003cp\u003eStep2: Build Dictionary\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\n\u003cp\u003eUse a dictionary (hash table) to count word frequencies.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003eThe dictionary maps word to index.\u003c/p\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003eÂèØ‰ª•È¶ñÂÖàÁªüËÆ°ËØçÈ¢ëÂéªÊéâ‰ΩéÈ¢ëËØçÔºåÁÑ∂ÂêéËÆ©ÊØè‰∏™ËØçÂØπÂ∫î‰∏Ä‰∏™Ê≠£Êï¥Êï∞ÔºõËøôÊ†∑ÁöÑËØùÔºå‰∏ÄÂè•ËØùÂ∞±ÂèØ‰ª•Áî®‰∏Ä‰∏™Ê≠£Êï¥Êï∞ÂàóË°®Ë°®Á§∫ÔºåËøô‰∏™ÂàóË°®Â∞±Âè´sequenceÔºõÂ¶ÇÊûúÂøÖË¶ÅÂ∞±ËøòÂæóÂÅöone-hot encoding„ÄÇ\u003cimg alt=\"image-20250322150620890\" loading=\"lazy\" src=\"./NLP-2.assets/image-20250322150620890.png\"\u003e\u003c/p\u003e\n\u003cp\u003eÁªìÊûú\u003c/p\u003e\n\u003cp\u003e\u003cimg alt=\"image-20250322150754528\" loading=\"lazy\" src=\"./NLP-2.assets/image-20250322150754528.png\"\u003e\u003c/p\u003e\n\u003cp\u003e‰ΩÜÊòØÈïøÂ∫¶‰∏çÁªü‰∏Ä\u003c/p\u003e\n\u003cp\u003eStep4: ÂØπÈΩêsequence\u003c/p\u003e\n\u003cp\u003e\u003cimg alt=\"image-20250322150854986\" loading=\"lazy\" src=\"./NLP-2.assets/image-20250322150854986.png\"\u003e\u003c/p\u003e\n\u003cp\u003eËß£ÂÜ≥ÊñπÊ°àÊòØËøôÊ†∑ÁöÑÔºöÂèØ‰ª•Âõ∫ÂÆöÈïøÂ∫¶‰∏∫wÔºåÂä†ÂÖ•‰∏Ä‰∏™Â∫èÂàóÈïøÂ∫¶Â§™ÈïøÔºåÂ∞±Á†çÊéâÂâçÈù¢ÁöÑËØçÔºåÂè™‰øùÁïôÊúÄÂêéw‰∏™ËØçÔºõÂ¶ÇÊûú‰∏Ä‰∏™Â∫èÂàóÂ§™Áü≠ÔºåÂ∞±ÂÅözero paddingÔºåÁî®0Â°´ÂÖÖ\u003c/p\u003e\n\u003cp\u003e\u003cimg alt=\"image-20250322151030119\" loading=\"lazy\" src=\"./NLP-2.assets/image-20250322151030119.png\"\u003e\u003c/p\u003e\n\u003cp\u003eËøôÊ†∑‰∏ÄÊù•ÔºåÊâÄÊúâÁöÑÂ∫èÂàóÈïøÂ∫¶Â∞±Áªü‰∏Ä‰∫Ü\u003c/p\u003e\n\u003cp\u003e\u003cimg alt=\"image-20250322151117125\" loading=\"lazy\" src=\"./NLP-2.assets/image-20250322151117125.png\"\u003e\u003c/p\u003e\n\u003cp\u003eÊñáÊú¨Â§ÑÁêÜÂÆåÊàê‰∫ÜÔºåÊé•‰∏ãÊù•ÊòØword embeddingÔºåÊääÂçïËØçË°®Á§∫‰∏∫‰∏Ä‰∏™‰ΩéÁª¥ÂêëÈáèÔºõ\u003c/p\u003e\n\u003cp\u003e\u003cimg alt=\"image-20250322151252837\" loading=\"lazy\" src=\"./NLP-2.assets/image-20250322151252837.png\"\u003e\u003c/p\u003e","title":""},{"content":"üëã About me I\u0026rsquo;m \u0026hellip;\nüìö Education üá≠üá∞ The University of Hong Kong 09/2024 - Expected 11/2025 School of Computing and Data Science Master of Science in Electronic Commerce \u0026amp; Internet Computing Relevant Courses: Machine learning for business and e-commerce, Knowledge graphs, Financial fraud analytics, Internet infrastructure technologies, Website engineering, Blockchain and cryptocurrency, etc. üá®üá≥ Beijing Institute of Technology 09/2020 - 06/2024 School of Computer Science \u0026amp; Technology Bachelor of Engineering in Software Engineering, last two years GPA: 3.7/4 Relevant Courses: Reinforcement Learning, Deep Learning and Computer Vision, Artificial Intelligence and Robot Ethics, Almost Human: Mind, Brain and Artificial Intelligence, Mathematical Analysis for Engineering, Linear Algebra, Probability and Mathematical Statistics, etc. Skills: Python, Java, common data structures, design patterns, machine learning basics and algorithms, Linux, PyTorch, and some development tools (git, conda, etc.). üèÜ Awards \u0026amp; Honors Beijing Institute of Technology Undergraduate Scholarship (Top 20% of Grade) 06/2023 3rd Prize of China International \u0026#34;Internet \u0026#43;\u0026#34; College Student\u0026#39;s Innovation Competition 08/2022 Bronze Prize of \u0026#34;Challenge Cup\u0026#34; Capital University Entrepreneurship Competition 05/2022 üíº Project Experience Online Transaction Fraud Detection 09/2024 ‚Äì 01/2025 Independent project, supervised by Dr. Vivien Chan Focused on addressing financial fraud in e-commerce to enhance the accuracy of transaction anomaly detection, while independently managing the entire case study that included data preprocessing, feature engineering, model building, evaluation, and results analysis. Effectively resolved class imbalance issues using SMOTE and ROSE techniques. Built various models including Logistic Regression, Random Forest, XGBoost, and LightGBM, ultimately selecting the LightGBM model to achieve a recall rate of 95.45% and an AUC of 99.84%. Wrote efficient and maintainable code, enhancing model training and data processing efficiency through parallel computing and logging. Multi-Model Intelligent Text Keyword Extraction System 08/2023 ‚Äì 09/2023 Group project, supervised by Associate Prof. Xiaolin Zhao Designed and implemented an intelligent text summary system that automatically extracts keywords from article titles and abstracts, enhancing the understanding and summarization of text information. Participated in the planning of the technical route and built a hybrid model combining extractive and generative approaches, utilizing advanced natural language processing techniques including KeyBERT, Sentence Transformer, BERT, and T5 models. Responsible for data preprocessing and tokenization, as well as the end-to-end implementation and training of the T5 model, optimizing the model architecture and hyperparameters, achieving satisfactory results after only 3 epochs of training. Model evaluation results showed that the Rouge-1, Rouge-2, and Rouge-L metrics reached 0.6345, 0.5038, and 0.5282, respectively, in the third epoch, validating the model\u0026rsquo;s effectiveness in the summarization task. Cambridge University Machine Learning Summer Project 07/2023 ‚Äì 08/2023 Group project, supervised by Prof. Pietro Li√≤ Participated in the Cambridge University deep learning summer project, focusing on deep reinforcement learning; explored multi-agent learning algorithms across different environments. Reproduced the Multi-Agent Deep Deterministic Policy Gradient (MADDPG) algorithm in the Simple Adversary environment and studied the effect of agent numbers on convergence speed and stability, finding optimal stability at 21 agents. Designed and implemented comparative experiments inspired by the Rainbow algorithm, assessing target network strategies versus the Double Deep Q-Network (Double DQN). The results demonstrated that Double DQN significantly enhanced convergence speed, optimizing the overall learning process. Co-authored a group project paper on agent numbers and strategies effectiveness in multi-agent systems, achieving a score of 71% in the summer program (the highest in my group) and a \u0026ldquo;First Class\u0026rdquo; classification in the UK grading system. Deep Learning and Computer Vision Semester Project 09/2022 ‚Äì 12/2022 Independent project, supervised by Associate Prof. Guangyu Gao Designed and implemented a waste classifier using the ResNet model to improve classification accuracy and reduce resource waste. The project also enhanced understanding of transfer learning techniques with ResNet. Collected a dataset of 16 waste categories and preprocessed the images for uniformity and standardization, incorporating data augmentation techniques to enhance the dataset. Conducted experiments using ResNet34 and ResNet50 models through transfer learning, accelerating network convergence by leveraging pretrained weights. During training, techniques such as Batch Normalization and Dropout were applied to mitigate the risk of overfitting. The final model achieved an accuracy of 90% on the training set, while the performance on the test set was 61%, indicating a significant overfitting phenomenon during the training process. üéì Internship Beijing Academy of Quantum Information Science 08/2023 ‚Äì 01/2024 Research Intern at Quantum Computation Department Proposed a quantum convolution kernel design based on variational quantum circuits and developed a universal quantum convolution layer, successfully integrating it into classical CNN architectures such as VGG, GoogLeNet, and ResNet. Developed and evaluated various hybrid models, including a simple model named HQCCNN-2, which achieved 84.45% accuracy on the FashionMNIST dataset, surpassing the traditional CNN\u0026rsquo;s 80.72%. This demonstrates the effectiveness of the quantum convolution layer in improving model performance. Tested on a real quantum computer further validated the effectiveness of the hybrid model, demonstrating the viable integration of quantum computing with deep learning, and highlighting the potential for leveraging quantum properties to enhance model performance. üèÖ Competition Experience China International \u0026#34;Internet \u0026#43;\u0026#34; College Students\u0026#39; Innovation Competition 08/2022 Zhongke Ushield: Deep Learning-based Face Privacy Protection Authentication System Responsible for constructing a localized facial feature extraction engine based on MobileFaceNet, ensuring feature extraction is completed on end devices (such as mobile phones and cameras), guaranteeing that raw data does not leave the domain and is not stored, thus enhancing user privacy protection while improving recognition efficiency. \u0026#34;Challenge Cup\u0026#34; Capital University Entrepreneurship Competition 05/2022 Smart Orchard Responsible for the development of the fruit detection, ripeness prediction, and pest identification system, using deep convolutional neural network (CNN) technology for intelligent monitoring of crop growth conditions. Applied advanced object detection algorithms such as Faster R-CNN and YOLO to achieve high precision in apple detection and ripeness assessment, with an accuracy rate exceeding 90%, significantly enhancing the intelligence level of orchard management. Built and trained a dedicated dataset containing various pest samples, optimizing pest detection accuracy through data preprocessing (such as image normalization and resizing) and data augmentation techniques (like rotation, flipping, and noise addition), enabling the real-time monitoring system to accurately identify over 80% of pests, providing effective scientific maintenance recommendations to help farmers reduce crop losses. üìã Extracurricular Activities Vice President, Cyber Security Club, Beijing Institute of Technology 09/2021-09/2022 Backbone, Media Center of the Student Union of Beijing Institute of Technology 10/2020-06/2021 üì´ Contact üìß zongsi.xu@outlook.com üëî Zongsi (Tristan) Xu üíª github.com/BaizeXS üìç Hong Kong SAR, China ","permalink":"http://localhost:1313/resume/","summary":"Personal resume of Zongsi (Tristan) Xu","title":"Zongsi (Tristan) Xu"},{"content":"‰∏Ä„ÄÅÊï∞ÂÄºÁâπÂæÅ‰∏éÁ±ªÂà´ÁâπÂæÅ Êï∞ÂÄºÁâπÂæÅ (Numeric Features) ÂÖ∑ÊúâÂèØÂä†ÂáèÁöÑÊÑè‰πâÔºå‰∏îÂ≠òÂú®Â§ßÂ∞èÈ°∫Â∫è„ÄÇ ‰æãÂ≠êÔºöÂπ¥ÈæÑ„ÄÅÊ∏©Â∫¶Á≠â„ÄÇÂèØ‰ª•Áõ¥Êé•‰øùÁïôÂÖ∂Êï¥Êï∞ÊàñÊµÆÁÇπÊï∞ÂΩ¢Âºè‰æõÊ®°Âûã‰ΩøÁî®„ÄÇ Á±ªÂà´ÁâπÂæÅ (Categorical Features) Êï∞ÊçÆÂÄºÁ¶ªÊï£Ôºå‰∏çÂÖ∑Â§á‚ÄúÊï∞ÂÄºÂ§ßÂ∞è‚ÄùÈó¥ÁöÑÂèØÊØîÊÑè‰πâ„ÄÇ ‰æãÂ≠êÔºöÂõΩÁ±çÔºàÁæéÂõΩ/‰∏≠ÂõΩ/Âç∞Â∫¶Á≠âÔºâ„ÄÅÊÄßÂà´ÔºàÁî∑/Â•≥ÔºâÁ≠â„ÄÇ ÈóÆÈ¢òÔºöËã•‰ªÖÁî®Êï¥Êï∞Ë°®Á§∫ÔºàÁæéÂõΩ=1, ‰∏≠ÂõΩ=2ÔºâÔºå‰ºöÂºïÂÖ•ÈîôËØØÁöÑÊï∞ÂÄºËøêÁÆóÂÖ≥Á≥ªÔºåÂ¶Ç ‚ÄúÁæéÂõΩ + ‰∏≠ÂõΩ = Âç∞Â∫¶‚Äù„ÄÇ ‰∫å„ÄÅOne-HotÁºñÁ†ÅÁöÑÂä®Êú∫‰∏éÊµÅÁ®ã ‰∏∫‰ªÄ‰πà‰ΩøÁî®One-Hot\nÈÄöËøáÂ∞ÜÁ±ªÂà´Êò†Â∞Ñ‰∏∫ÂêëÈáèÔºåÈÅøÂÖçÊï¥Êï∞ÁºñÁ†ÅÂºïÂÖ•ÁöÑ‰º™Êï∞ÂÄºÂÖ≥Á≥ª„ÄÇ ÂêåÊó∂‰øùÁïôÂêÑÁßçÂèØËÉΩÁ±ªÂà´ÁöÑ‰ø°ÊÅØÔºå‰∏î‰ªÖÂú®ÂØπÂ∫î‰ΩçÁΩÆ‰∏∫1ÔºåÂÖ∂‰ªñ‰ΩçÁΩÆ‰∏∫0„ÄÇ Âª∫Á´ãÊò†Â∞ÑÔºö‰ªéÁ±ªÂà´Âà∞Á¥¢Âºï\n‰∏∫ÊØè‰∏™Á±ªÂà´ÂàÜÈÖç‰∏Ä‰∏™ÂîØ‰∏ÄÁ¥¢ÂºïÔºåÈÄöÂ∏∏‰ªé1ÂºÄÂßã„ÄÇ È¢ÑÁïôÁ¥¢Âºï0Ë°®Á§∫‚ÄúÊú™Áü•‚ÄùÊàñ‚ÄúÁº∫Â§±‚ÄùÔºåÂØπÂ∫îÂÖ®0ÂêëÈáè„ÄÇ ËΩ¨Êç¢‰∏∫One-HotÂêëÈáè\nËã•Á±ªÂà´ÊÄªÊï∞‰∏∫197ÔºåÂàôÁî®197Áª¥ÂêëÈáèË°®Á§∫„ÄÇ ‰æãÂ≠êÔºöÁæéÂõΩ [1, 0, 0, 0, ‚Ä¶]Ôºå ‰∏≠ÂõΩ [0, 1, 0, 0, ‚Ä¶]„ÄÇ Á§∫‰æãÔºöË°®Á§∫‰∏Ä‰∏™‰∫∫ÁöÑÁâπÂæÅ\nÁâπÂæÅÂåÖÂê´ÔºàÂπ¥ÈæÑ, ÊÄßÂà´, ÂõΩÁ±çÔºåÂÖ∂‰∏≠ÂõΩÁ±ç197ÁßçÔºâ Áª¥Â∫¶ÊÄªÂíåÔºö1Áª¥_age + 1Áª¥_gender + 197Áª¥_nationality = 199Áª¥„ÄÇ ‰æãÂ¶Ç (28, Â•≥, ‰∏≠ÂõΩ) ‚Üí [28, 0, 0, 1, 0, ‚Ä¶, 0]„ÄÇ ‰∏â„ÄÅÊñáÊú¨Êï∞ÊçÆÂ§ÑÁêÜÊµÅÁ®ã ÊñáÊú¨Âú®Ëá™ÁÑ∂ËØ≠Ë®ÄÂ§ÑÁêÜÔºàNLPÔºâ‰∏≠‰Ωú‰∏∫Â∏∏ËßÅÁöÑÂéüÂßãËæìÂÖ•ÔºåÈúÄË¶ÅÊï∞ÂÄºÂåñÊâçËÉΩÈÄÅÂÖ•Ê®°Âûã„ÄÇ‰∏ÄËà¨Ê≠•È™§Â¶Ç‰∏ãÔºö\nÂàÜËØç (Tokenization)\nÂ∞ÜÊñáÊú¨ÊãÜÂàÜ‰∏∫‰∏Ä‰∏™‰∏™ÂçïËØçÔºàTokenÔºâ„ÄÇ ‰æãÂ≠êÔºö\u0026quot;... to be or not to be...\u0026quot; ‚Üí [\u0026quot;...\u0026quot;, \u0026quot;to\u0026quot;, \u0026quot;be\u0026quot;, \u0026quot;or\u0026quot;, \u0026quot;not\u0026quot;, \u0026quot;to\u0026quot;, \u0026quot;be\u0026quot;, \u0026quot;...\u0026quot;]„ÄÇ ÁªüËÆ°ËØçÈ¢ë \u0026amp; ÊûÑÂª∫ËØçÂÖ∏\nËØçÈ¢ëÁªüËÆ° Áî®ÂìàÂ∏åË°®/Â≠óÂÖ∏ËÆ∞ÂΩïÊØè‰∏™ÂçïËØçÂá∫Áé∞Ê¨°Êï∞„ÄÇ ÈÅçÂéÜÊñáÊú¨Êó∂ÔºåËã•ÂçïËØçÂ∞öÊú™ÂÖ•Ë°®ÔºåÂàôÊñ∞Âª∫ËÆ∞ÂΩïÔºõËã•Â∑≤Â≠òÂú®ÔºåÂàôËÆ°Êï∞+1„ÄÇ ÊéíÂ∫è‰∏éÁ¥¢Âºï ÊåâËØçÈ¢ëÈôçÂ∫èÊéíÂ∫èÔºåËØçÈ¢ëÊúÄÈ´òÁöÑÂçïËØçÊéíÂú®ÂâçÈù¢„ÄÇ Á¥¢Âºï‰ªé1ÂºÄÂßãÔºå0ÁïôÁªô‚ÄúÊú™Áü•‚Äù„ÄÇ ËØçÂÖ∏ËßÑÊ®°ÔºàvocabularyÔºâÂèØËßÜÈúÄÊ±ÇÊà™Êñ≠Ôºà‰æãÂ¶ÇÂè™‰øùÁïôTop 10kÔºâ„ÄÇ ‰∏∫‰ªÄ‰πàÁßªÈô§‰ΩéÈ¢ëËØç ‰ΩéÈ¢ëËØçÂèØËÉΩÊòØÊãºÂÜôÈîôËØØ„ÄÅÁΩïËßÅ‰∫∫ÂêçÁ≠âÔºåÂØπÊ®°ÂûãÂ∏ÆÂä©ÊúâÈôê„ÄÇ ÂáèÂ∞ëËØçÂÖ∏ËßÑÊ®°ÂèØÈôç‰ΩéËøêÁÆóÂºÄÈîÄ„ÄÅÂä†Âø´Ê®°ÂûãËÆ≠ÁªÉ‰∏éÊé®ÁêÜÈÄüÂ∫¶„ÄÇ Áã¨ÁÉ≠ÁºñÁ†Å (One-Hot Encoding)\nÂ∞ÜÊØè‰∏™ÂçïËØçÊò†Â∞Ñ‰∏∫ËØçÂÖ∏‰∏≠ÁöÑÁ¥¢ÂºïÂêéÔºàÂ¶Ç [2, 4, 1, 8, ‚Ä¶]ÔºâÔºåÂèØËøõ‰∏ÄÊ≠•ËΩ¨Êç¢ÊàêOne-HotÂêëÈáè„ÄÇ One-HotÁª¥Â∫¶ÂèñÂÜ≥‰∫é‰øùÁïô‰∏ãÊù•ÁöÑËØçÂÖ∏Â§ßÂ∞èÔºà‰æãÂ¶Ç1‰∏áÔºâ„ÄÇ Êú™Êî∂ÂΩïÂçïËØçÂèØËÉΩÁõ¥Êé•ÂøΩÁï•ÔºåÊàñÁªü‰∏ÄÁî®Á¥¢Âºï0‰ª£Êõø„ÄÇ Âõõ„ÄÅÊ†∏ÂøÉÊî∂Ëé∑‰∏éÂ∫îÁî® Á±ªÂà´ÁâπÂæÅÂøÖÈúÄÊï∞ÂÄºÂåñÔºö\n‰ΩøÁî®Êï¥Êï∞1,2,3‚Ä¶‰ªÖË°®Á§∫Á±ªÂà´‚ÄúÊ†áËØÜ‚ÄùÔºåÂπ∂‰∏ç‰ª£Ë°®ÂÆÉ‰ª¨ÂèØËøõË°åÊï∞ÂÄºËøêÁÆó„ÄÇ Âõ†Ê≠§ÈúÄË¶ÅOne-HotÁ≠âÁºñÁ†ÅÊñπÂºèÔºåÈÅøÂÖçÊï∞ÂÄºËØØËß£„ÄÇ ÊñáÊú¨Êï∞ÊçÆÈ¢ÑÂ§ÑÁêÜÔºö\nÂàÜËØç„ÄÅËØçÈ¢ëÁªüËÆ°„ÄÅÊûÑÂª∫ËØçÂÖ∏„ÄÅÁ¥¢ÂºïÂåñ„ÄÅOne-HotÊàñÂÖ∂‰ªñÊñπÂºèÔºàÂ¶ÇËØçÂµåÂÖ•ÔºâÊòØÂ∏∏ËßÅÊµÅÁ®ã„ÄÇ Ê≠£Á°ÆÁöÑÊñáÊú¨È¢ÑÂ§ÑÁêÜÂèØÊòæËëóÂΩ±ÂìçÊ®°ÂûãÊÄßËÉΩÂíåÊïàÁéá„ÄÇ ‰øùÁïôÊú™Áü•Á¥¢ÂºïÔºö\n‰øùËØÅÂØπÁº∫Â§±Êï∞ÊçÆÊàñÂ≠óÂÖ∏Â§ñÊñ∞ËØçËÉΩÊúâÂü∫Êú¨ÁöÑË°®Á§∫ÔºåÊèêÂçáÊ®°ÂûãÂÆπÈîôÊÄß„ÄÇ ÂÆûÈôÖ‰ΩøÁî®Ôºö\nÂØπ‰∫éÂ∞èËßÑÊ®°Á±ªÂà´ÂèØÁõ¥Êé•One-HotÁºñÁ†ÅÔºõÂØπ‰∫éËØçÂÖ∏ÂæàÂ§ßÁöÑÂú∫ÊôØÔºåÈÄöÂ∏∏‰ºöËøõ‰∏ÄÊ≠•ËÄÉËôëËØçÂµåÂÖ•ÔºàWord EmbeddingÔºâÊàñÈ¢ÑËÆ≠ÁªÉËØ≠Ë®ÄÊ®°Âûã„ÄÇ ","permalink":"http://localhost:1313/posts/nlp-1/","summary":"\u003ch2 id=\"‰∏ÄÊï∞ÂÄºÁâπÂæÅ‰∏éÁ±ªÂà´ÁâπÂæÅ\"\u003e‰∏Ä„ÄÅÊï∞ÂÄºÁâπÂæÅ‰∏éÁ±ªÂà´ÁâπÂæÅ\u003c/h2\u003e\n\u003col\u003e\n\u003cli\u003e\u003cstrong\u003eÊï∞ÂÄºÁâπÂæÅ (Numeric Features)\u003c/strong\u003e\n\u003cul\u003e\n\u003cli\u003eÂÖ∑ÊúâÂèØÂä†ÂáèÁöÑÊÑè‰πâÔºå‰∏îÂ≠òÂú®Â§ßÂ∞èÈ°∫Â∫è„ÄÇ\u003c/li\u003e\n\u003cli\u003e‰æãÂ≠êÔºöÂπ¥ÈæÑ„ÄÅÊ∏©Â∫¶Á≠â„ÄÇÂèØ‰ª•Áõ¥Êé•‰øùÁïôÂÖ∂Êï¥Êï∞ÊàñÊµÆÁÇπÊï∞ÂΩ¢Âºè‰æõÊ®°Âûã‰ΩøÁî®„ÄÇ\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003eÁ±ªÂà´ÁâπÂæÅ (Categorical Features)\u003c/strong\u003e\n\u003cul\u003e\n\u003cli\u003eÊï∞ÊçÆÂÄºÁ¶ªÊï£Ôºå‰∏çÂÖ∑Â§á‚ÄúÊï∞ÂÄºÂ§ßÂ∞è‚ÄùÈó¥ÁöÑÂèØÊØîÊÑè‰πâ„ÄÇ\u003c/li\u003e\n\u003cli\u003e‰æãÂ≠êÔºöÂõΩÁ±çÔºàÁæéÂõΩ/‰∏≠ÂõΩ/Âç∞Â∫¶Á≠âÔºâ„ÄÅÊÄßÂà´ÔºàÁî∑/Â•≥ÔºâÁ≠â„ÄÇ\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003eÈóÆÈ¢ò\u003c/strong\u003eÔºöËã•‰ªÖÁî®Êï¥Êï∞Ë°®Á§∫ÔºàÁæéÂõΩ=1, ‰∏≠ÂõΩ=2ÔºâÔºå‰ºöÂºïÂÖ•ÈîôËØØÁöÑÊï∞ÂÄºËøêÁÆóÂÖ≥Á≥ªÔºåÂ¶Ç ‚ÄúÁæéÂõΩ + ‰∏≠ÂõΩ = Âç∞Â∫¶‚Äù„ÄÇ\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003c/ol\u003e\n\u003ch2 id=\"‰∫åone-hotÁºñÁ†ÅÁöÑÂä®Êú∫‰∏éÊµÅÁ®ã\"\u003e‰∫å„ÄÅOne-HotÁºñÁ†ÅÁöÑÂä®Êú∫‰∏éÊµÅÁ®ã\u003c/h2\u003e\n\u003col\u003e\n\u003cli\u003e\n\u003cp\u003e\u003cstrong\u003e‰∏∫‰ªÄ‰πà‰ΩøÁî®One-Hot\u003c/strong\u003e\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eÈÄöËøáÂ∞ÜÁ±ªÂà´Êò†Â∞Ñ‰∏∫ÂêëÈáèÔºåÈÅøÂÖçÊï¥Êï∞ÁºñÁ†ÅÂºïÂÖ•ÁöÑ‰º™Êï∞ÂÄºÂÖ≥Á≥ª„ÄÇ\u003c/li\u003e\n\u003cli\u003eÂêåÊó∂‰øùÁïôÂêÑÁßçÂèØËÉΩÁ±ªÂà´ÁöÑ‰ø°ÊÅØÔºå‰∏î‰ªÖÂú®ÂØπÂ∫î‰ΩçÁΩÆ‰∏∫1ÔºåÂÖ∂‰ªñ‰ΩçÁΩÆ‰∏∫0„ÄÇ\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003e\u003cstrong\u003eÂª∫Á´ãÊò†Â∞ÑÔºö‰ªéÁ±ªÂà´Âà∞Á¥¢Âºï\u003c/strong\u003e\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e‰∏∫ÊØè‰∏™Á±ªÂà´ÂàÜÈÖç‰∏Ä‰∏™ÂîØ‰∏ÄÁ¥¢ÂºïÔºåÈÄöÂ∏∏‰ªé1ÂºÄÂßã„ÄÇ\u003c/li\u003e\n\u003cli\u003eÈ¢ÑÁïôÁ¥¢Âºï0Ë°®Á§∫‚ÄúÊú™Áü•‚ÄùÊàñ‚ÄúÁº∫Â§±‚ÄùÔºåÂØπÂ∫îÂÖ®0ÂêëÈáè„ÄÇ\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003e\u003cstrong\u003eËΩ¨Êç¢‰∏∫One-HotÂêëÈáè\u003c/strong\u003e\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eËã•Á±ªÂà´ÊÄªÊï∞‰∏∫197ÔºåÂàôÁî®197Áª¥ÂêëÈáèË°®Á§∫„ÄÇ\u003c/li\u003e\n\u003cli\u003e‰æãÂ≠êÔºöÁæéÂõΩ \u003ccode\u003e[1, 0, 0, 0, ‚Ä¶]\u003c/code\u003eÔºå ‰∏≠ÂõΩ \u003ccode\u003e[0, 1, 0, 0, ‚Ä¶]\u003c/code\u003e„ÄÇ\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003e\u003cstrong\u003eÁ§∫‰æãÔºöË°®Á§∫‰∏Ä‰∏™‰∫∫ÁöÑÁâπÂæÅ\u003c/strong\u003e\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eÁâπÂæÅÂåÖÂê´ÔºàÂπ¥ÈæÑ, ÊÄßÂà´, ÂõΩÁ±çÔºåÂÖ∂‰∏≠ÂõΩÁ±ç197ÁßçÔºâ\u003c/li\u003e\n\u003cli\u003eÁª¥Â∫¶ÊÄªÂíåÔºö1Áª¥_age + 1Áª¥_gender + 197Áª¥_nationality = 199Áª¥„ÄÇ\u003c/li\u003e\n\u003cli\u003e‰æãÂ¶Ç \u003ccode\u003e(28, Â•≥, ‰∏≠ÂõΩ)\u003c/code\u003e ‚Üí \u003ccode\u003e[28, 0, 0, 1, 0, ‚Ä¶, 0]\u003c/code\u003e„ÄÇ\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003c/ol\u003e\n\u003ch2 id=\"‰∏âÊñáÊú¨Êï∞ÊçÆÂ§ÑÁêÜÊµÅÁ®ã\"\u003e‰∏â„ÄÅÊñáÊú¨Êï∞ÊçÆÂ§ÑÁêÜÊµÅÁ®ã\u003c/h2\u003e\n\u003cp\u003eÊñáÊú¨Âú®Ëá™ÁÑ∂ËØ≠Ë®ÄÂ§ÑÁêÜÔºàNLPÔºâ‰∏≠‰Ωú‰∏∫Â∏∏ËßÅÁöÑÂéüÂßãËæìÂÖ•ÔºåÈúÄË¶ÅÊï∞ÂÄºÂåñÊâçËÉΩÈÄÅÂÖ•Ê®°Âûã„ÄÇ‰∏ÄËà¨Ê≠•È™§Â¶Ç‰∏ãÔºö\u003c/p\u003e\n\u003col\u003e\n\u003cli\u003e\n\u003cp\u003e\u003cstrong\u003eÂàÜËØç (Tokenization)\u003c/strong\u003e\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eÂ∞ÜÊñáÊú¨ÊãÜÂàÜ‰∏∫‰∏Ä‰∏™‰∏™ÂçïËØçÔºàTokenÔºâ„ÄÇ\u003c/li\u003e\n\u003cli\u003e‰æãÂ≠êÔºö\u003ccode\u003e\u0026quot;... to be or not to be...\u0026quot;\u003c/code\u003e ‚Üí \u003ccode\u003e[\u0026quot;...\u0026quot;, \u0026quot;to\u0026quot;, \u0026quot;be\u0026quot;, \u0026quot;or\u0026quot;, \u0026quot;not\u0026quot;, \u0026quot;to\u0026quot;, \u0026quot;be\u0026quot;, \u0026quot;...\u0026quot;]\u003c/code\u003e„ÄÇ\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003e\u003cstrong\u003eÁªüËÆ°ËØçÈ¢ë \u0026amp; ÊûÑÂª∫ËØçÂÖ∏\u003c/strong\u003e\u003c/p\u003e","title":""},{"content":"Text to Sequence ÊñáÊú¨Â§ÑÁêÜ\nStep1: Tokenization\nTokenization breaks a piece of text down into a list of tokens.\nHere, a token is a word. (A token can be a character in some applications.)\nTokenizationËÆ≤Á©∂ÂæàÂ§öÔºå‰æãÂ¶ÇÊòØÂê¶Â∫îËØ•ÊääÂ§ßÂÜôÊîπÊàêÂ∞èÂÜôÂë¢ÔºüËøõË°åtypo correctionÁ≠âÁ≠â\nStep2: Build Dictionary\nUse a dictionary (hash table) to count word frequencies.\nThe dictionary maps word to index.\nÂèØ‰ª•È¶ñÂÖàÁªüËÆ°ËØçÈ¢ëÂéªÊéâ‰ΩéÈ¢ëËØçÔºåÁÑ∂ÂêéËÆ©ÊØè‰∏™ËØçÂØπÂ∫î‰∏Ä‰∏™Ê≠£Êï¥Êï∞ÔºõËøôÊ†∑ÁöÑËØùÔºå‰∏ÄÂè•ËØùÂ∞±ÂèØ‰ª•Áî®‰∏Ä‰∏™Ê≠£Êï¥Êï∞ÂàóË°®Ë°®Á§∫ÔºåËøô‰∏™ÂàóË°®Â∞±Âè´sequenceÔºõÂ¶ÇÊûúÂøÖË¶ÅÂ∞±ËøòÂæóÂÅöone-hot encoding„ÄÇ\nÁªìÊûú\n‰ΩÜÊòØÈïøÂ∫¶‰∏çÁªü‰∏Ä\nStep4: ÂØπÈΩêsequence\nËß£ÂÜ≥ÊñπÊ°àÊòØËøôÊ†∑ÁöÑÔºöÂèØ‰ª•Âõ∫ÂÆöÈïøÂ∫¶‰∏∫wÔºåÂä†ÂÖ•‰∏Ä‰∏™Â∫èÂàóÈïøÂ∫¶Â§™ÈïøÔºåÂ∞±Á†çÊéâÂâçÈù¢ÁöÑËØçÔºåÂè™‰øùÁïôÊúÄÂêéw‰∏™ËØçÔºõÂ¶ÇÊûú‰∏Ä‰∏™Â∫èÂàóÂ§™Áü≠ÔºåÂ∞±ÂÅözero paddingÔºåÁî®0Â°´ÂÖÖ\nËøôÊ†∑‰∏ÄÊù•ÔºåÊâÄÊúâÁöÑÂ∫èÂàóÈïøÂ∫¶Â∞±Áªü‰∏Ä‰∫Ü\nÊñáÊú¨Â§ÑÁêÜÂÆåÊàê‰∫ÜÔºåÊé•‰∏ãÊù•ÊòØword embeddingÔºåÊääÂçïËØçË°®Á§∫‰∏∫‰∏Ä‰∏™‰ΩéÁª¥ÂêëÈáèÔºõ\nÁÑ∂ËÄåËøôÊ†∑ÂÅöÁöÑËØùÔºåÂ¶ÇÊûúÊòØ10000‰∏™ÂçïËØçÔºåÁª¥Â∫¶Â∞±ÊòØ10000Áª¥ÔºåÁª¥Â∫¶Â§™È´ò‰∫ÜÔºõÂõ†Ê≠§Ë¶ÅÂÅöword embeddingÔºõ\nÂÖ∑‰ΩìÂÅöÊ≥ïÂ∞±ÊòØÊääone-hotÂêëÈáèe_iÂíåÂèÇÊï∞Áü©ÈòµpÁõ∏‰πòÔºõÁü©ÈòµPËΩ¨ÁΩÆÁöÑÂ§ßÂ∞èÊòØd x vÔºõdÊòØËØçÂêëÈáèÁöÑÁª¥Â∫¶ÔºõvÊòØÂ≠óÂÖ∏ÈáåËØçÊ±áÁöÑÊï∞ÈáèÔºõÁªìÊûú‰∏∫x_iÔºõx_iÂ∞±ÊòØ‰∏Ä‰∏™ËØçÂêëÈáèÔºõÂ¶ÇÊûúone-hotÂêëÈáèÁöÑÁ¨¨‰∏âË°å‰∏∫1ÔºõÈÇ£‰πàx_iÂ∞±ÊòØPËΩ¨ÁΩÆÁü©ÈòµÁöÑÁ¨¨‰∏âÂàóÔºàÂÖ∂‰ΩôÂàóÈÉΩ‰∏∫0ÔºâÔºõÊâÄ‰ª•PËΩ¨ÁΩÆÊØè‰∏ÄÂàóÈÉΩÊòØ‰∏Ä‰∏™ËØçÂêëÈáèÔºõÊâÄ‰ª•Áü©ÈòµPÊú¨Ë∫´ÁöÑÊØè‰∏ÄË°åÂ∞±ÊòØ‰∏Ä‰∏™ËØçÂêëÈáèÔºõÂÖ∂Ë°åÊï∞‰∏∫vÔºõÂç≥vocabularyÔºåËØçÊ±áÈáèÔºõÊØè‰∏ÄË°åÂØπÂ∫î‰∏Ä‰∏™ÂçïËØçÔºõÁü©ÈòµÁöÑÂàóÊï∞‰∏∫dÔºõdÊòØÁî®Êà∑ÂÜ≥ÂÆöÁöÑÔºõdÁöÑÂ§ßÂ∞è‰ºöÂÜ≥ÂÆöÊú∫Âô®Â≠¶‰π†Ê®°ÂûãÁöÑË°®Áé∞ÔºõÂ∫îËØ•Áî®xxxÊù•ÈÄâÊã©‰∏Ä‰∏™ÊØîËæÉÂ•ΩÁöÑdÔºõ\nÊàë‰ª¨ÁöÑ‰ªªÂä°ÊòØÁúãËØÑËÆ∫ÊòØÊ≠£Èù¢ÁöÑËøòÊòØË¥üÈù¢ÁöÑÔºõÂèÇÊï∞Áü©ÈòµÊòØ‰ªéËÆ≠ÁªÉÊï∞ÊçÆ‰∏≠Â≠¶‰π†Âá∫Êù•ÁöÑÔºåÊâÄ‰ª•Â≠¶Âá∫Êù•ÁöÑËØçÂêëÈáèÊòØÂ∏¶ÊúâÊÑüÊÉÖËâ≤ÂΩ©ÁöÑÔºõÂÅáËÆæËøô‰∫õËØçÂêëÈáèÈÉΩÊòØ‰∫åÁª¥ÁöÑÔºåÂàôÂèØ‰ª•Âú®Âπ≥Èù¢ÂùêÊ†áÁ≥ª‰∏≠Ê†áÂá∫‰∏ãÈù¢ËØçÂêëÈáè\nkerasÊèê‰æõembeddingÂ±ÇÔºõÁî®Êà∑ÂèØ‰ª•ÊåáÂÆövocabularyÂ§ßÂ∞èÂíådÁöÑÂ§ßÂ∞èÔºõ‰ª•ÂèäÊØè‰∏Ä‰∏™sequenceÁöÑÈïøÂ∫¶ÔºõdÊòØÊ†πÊçÆÁÆóÊ≥ïÈÄâÂá∫Êù•ÁöÑ Âà∞Ëøô‰∏ÄÊ≠•ÔºåÊàë‰ª¨Â∑≤ÁªèÂÆåÊàê‰∫ÜÊñáÊú¨Â§ÑÁêÜÂíåword embedding„ÄÇÊé•‰∏ãÊù•Â∞±ÊòØÁî®Logistic Regression for Binary ClassificationÂÅö‰∫åÂàÜÁ±ªÔºõ\n","permalink":"http://localhost:1313/posts/nlp-2/","summary":"\u003ch3 id=\"text-to-sequence\"\u003eText to Sequence\u003c/h3\u003e\n\u003cp\u003eÊñáÊú¨Â§ÑÁêÜ\u003c/p\u003e\n\u003cp\u003eStep1: Tokenization\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\n\u003cp\u003eTokenization breaks a piece of text down into a list of tokens.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003eHere, a token is a word. (A token can be a character in some applications.)\u003c/p\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003eTokenizationËÆ≤Á©∂ÂæàÂ§öÔºå‰æãÂ¶ÇÊòØÂê¶Â∫îËØ•ÊääÂ§ßÂÜôÊîπÊàêÂ∞èÂÜôÂë¢ÔºüËøõË°åtypo correctionÁ≠âÁ≠â\u003c/p\u003e\n\u003cp\u003e\u003cimg alt=\"image-20250322150322238\" loading=\"lazy\" src=\"./NLP-2.assets/image-20250322150322238.png\"\u003e\u003c/p\u003e\n\u003cp\u003eStep2: Build Dictionary\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\n\u003cp\u003eUse a dictionary (hash table) to count word frequencies.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003eThe dictionary maps word to index.\u003c/p\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003eÂèØ‰ª•È¶ñÂÖàÁªüËÆ°ËØçÈ¢ëÂéªÊéâ‰ΩéÈ¢ëËØçÔºåÁÑ∂ÂêéËÆ©ÊØè‰∏™ËØçÂØπÂ∫î‰∏Ä‰∏™Ê≠£Êï¥Êï∞ÔºõËøôÊ†∑ÁöÑËØùÔºå‰∏ÄÂè•ËØùÂ∞±ÂèØ‰ª•Áî®‰∏Ä‰∏™Ê≠£Êï¥Êï∞ÂàóË°®Ë°®Á§∫ÔºåËøô‰∏™ÂàóË°®Â∞±Âè´sequenceÔºõÂ¶ÇÊûúÂøÖË¶ÅÂ∞±ËøòÂæóÂÅöone-hot encoding„ÄÇ\u003cimg alt=\"image-20250322150620890\" loading=\"lazy\" src=\"./NLP-2.assets/image-20250322150620890.png\"\u003e\u003c/p\u003e\n\u003cp\u003eÁªìÊûú\u003c/p\u003e\n\u003cp\u003e\u003cimg alt=\"image-20250322150754528\" loading=\"lazy\" src=\"./NLP-2.assets/image-20250322150754528.png\"\u003e\u003c/p\u003e\n\u003cp\u003e‰ΩÜÊòØÈïøÂ∫¶‰∏çÁªü‰∏Ä\u003c/p\u003e\n\u003cp\u003eStep4: ÂØπÈΩêsequence\u003c/p\u003e\n\u003cp\u003e\u003cimg alt=\"image-20250322150854986\" loading=\"lazy\" src=\"./NLP-2.assets/image-20250322150854986.png\"\u003e\u003c/p\u003e\n\u003cp\u003eËß£ÂÜ≥ÊñπÊ°àÊòØËøôÊ†∑ÁöÑÔºöÂèØ‰ª•Âõ∫ÂÆöÈïøÂ∫¶‰∏∫wÔºåÂä†ÂÖ•‰∏Ä‰∏™Â∫èÂàóÈïøÂ∫¶Â§™ÈïøÔºåÂ∞±Á†çÊéâÂâçÈù¢ÁöÑËØçÔºåÂè™‰øùÁïôÊúÄÂêéw‰∏™ËØçÔºõÂ¶ÇÊûú‰∏Ä‰∏™Â∫èÂàóÂ§™Áü≠ÔºåÂ∞±ÂÅözero paddingÔºåÁî®0Â°´ÂÖÖ\u003c/p\u003e\n\u003cp\u003e\u003cimg alt=\"image-20250322151030119\" loading=\"lazy\" src=\"./NLP-2.assets/image-20250322151030119.png\"\u003e\u003c/p\u003e\n\u003cp\u003eËøôÊ†∑‰∏ÄÊù•ÔºåÊâÄÊúâÁöÑÂ∫èÂàóÈïøÂ∫¶Â∞±Áªü‰∏Ä‰∫Ü\u003c/p\u003e\n\u003cp\u003e\u003cimg alt=\"image-20250322151117125\" loading=\"lazy\" src=\"./NLP-2.assets/image-20250322151117125.png\"\u003e\u003c/p\u003e\n\u003cp\u003eÊñáÊú¨Â§ÑÁêÜÂÆåÊàê‰∫ÜÔºåÊé•‰∏ãÊù•ÊòØword embeddingÔºåÊääÂçïËØçË°®Á§∫‰∏∫‰∏Ä‰∏™‰ΩéÁª¥ÂêëÈáèÔºõ\u003c/p\u003e\n\u003cp\u003e\u003cimg alt=\"image-20250322151252837\" loading=\"lazy\" src=\"./NLP-2.assets/image-20250322151252837.png\"\u003e\u003c/p\u003e","title":""},{"content":"üëã About me Hello! I‚Äôm Xu Zongsi, a passionate technology enthusiast currently pursuing my Master of Science in ECIC at The University of Hong Kong. With a solid background in Software Engineering from the Beijing Institute of Technology, I specialize in emerging areas of artificial intelligence, including machine learning, deep learning, natural language processing, and computer vision.\nI have a strong interest in developing LLM agents and knowledge graphs, leveraging data science techniques for innovative solutions. Additionally, I am skilled in software development, aiming to create impactful applications that enhance user experiences.\nThroughout my academic journey, I have been involved in several innovative projects focused on fraud detection, intelligent text processing, and quantum computing applications in deep learning. My programming skills span languages like Python and Java, with experience in frameworks such as PyTorch.\nWhen I‚Äôm not coding, you can find me exploring new technologies, sharing insights on my blog, or engaging in community activities related to cyber security.\nüìö Education üá≠üá∞ The University of Hong Kong 09/2024 - Expected 11/2025 School of Computing and Data Science Master of Science in Electronic Commerce \u0026amp; Internet Computing Relevant Courses: Machine learning for business and e-commerce, Knowledge graphs, Financial fraud analytics, Internet infrastructure technologies, Website engineering, Blockchain and cryptocurrency, etc. üá®üá≥ Beijing Institute of Technology 09/2020 - 06/2024 School of Computer Science \u0026amp; Technology Bachelor of Engineering in Software Engineering, last two years GPA: 3.7/4 Relevant Courses: Reinforcement Learning, Deep Learning and Computer Vision, Artificial Intelligence and Robot Ethics, Almost Human: Mind, Brain and Artificial Intelligence, Mathematical Analysis for Engineering, Linear Algebra, Probability and Mathematical Statistics, etc. Skills: Python, Java, common data structures, design patterns, machine learning basics and algorithms, Linux, PyTorch, and some development tools (git, conda, etc.). üèÜ Awards \u0026amp; Honors Beijing Institute of Technology Undergraduate Scholarship (Top 20% of Grade) 06/2023 3rd Prize of China International \u0026#34;Internet \u0026#43;\u0026#34; College Student\u0026#39;s Innovation Competition 08/2022 Bronze Prize of \u0026#34;Challenge Cup\u0026#34; Capital University Entrepreneurship Competition 05/2022 üíº Project Experience Online Transaction Fraud Detection 09/2024 ‚Äì 01/2025 Independent project, supervised by Dr. Vivien Chan Focused on addressing financial fraud in e-commerce to enhance the accuracy of transaction anomaly detection, while independently managing the entire case study that included data preprocessing, feature engineering, model building, evaluation, and results analysis. Effectively resolved class imbalance issues using SMOTE and ROSE techniques. Built various models including Logistic Regression, Random Forest, XGBoost, and LightGBM, ultimately selecting the LightGBM model to achieve a recall rate of 95.45% and an AUC of 99.84%. Wrote efficient and maintainable code, enhancing model training and data processing efficiency through parallel computing and logging. Multi-Model Intelligent Text Keyword Extraction System 08/2023 ‚Äì 09/2023 Group project, supervised by Associate Prof. Xiaolin Zhao Designed and implemented an intelligent text summary system that automatically extracts keywords from article titles and abstracts, enhancing the understanding and summarization of text information. Participated in the planning of the technical route and built a hybrid model combining extractive and generative approaches, utilizing advanced natural language processing techniques including KeyBERT, Sentence Transformer, BERT, and T5 models. Responsible for data preprocessing and tokenization, as well as the end-to-end implementation and training of the T5 model, optimizing the model architecture and hyperparameters, achieving satisfactory results after only 3 epochs of training. Model evaluation results showed that the Rouge-1, Rouge-2, and Rouge-L metrics reached 0.6345, 0.5038, and 0.5282, respectively, in the third epoch, validating the model\u0026rsquo;s effectiveness in the summarization task. Cambridge University Machine Learning Summer Project 07/2023 ‚Äì 08/2023 Group project, supervised by Prof. Pietro Li√≤ Participated in the Cambridge University deep learning summer project, focusing on deep reinforcement learning; explored multi-agent learning algorithms across different environments. Reproduced the Multi-Agent Deep Deterministic Policy Gradient (MADDPG) algorithm in the Simple Adversary environment and studied the effect of agent numbers on convergence speed and stability, finding optimal stability at 21 agents. Designed and implemented comparative experiments inspired by the Rainbow algorithm, assessing target network strategies versus the Double Deep Q-Network (Double DQN). The results demonstrated that Double DQN significantly enhanced convergence speed, optimizing the overall learning process. Co-authored a group project paper on agent numbers and strategies effectiveness in multi-agent systems, achieving a score of 71% in the summer program (the highest in my group) and a \u0026ldquo;First Class\u0026rdquo; classification in the UK grading system. Deep Learning and Computer Vision Semester Project 09/2022 ‚Äì 12/2022 Independent project, supervised by Associate Prof. Guangyu Gao Designed and implemented a waste classifier using the ResNet model to improve classification accuracy and reduce resource waste. The project also enhanced understanding of transfer learning techniques with ResNet. Collected a dataset of 16 waste categories and preprocessed the images for uniformity and standardization, incorporating data augmentation techniques to enhance the dataset. Conducted experiments using ResNet34 and ResNet50 models through transfer learning, accelerating network convergence by leveraging pretrained weights. During training, techniques such as Batch Normalization and Dropout were applied to mitigate the risk of overfitting. The final model achieved an accuracy of 90% on the training set, while the performance on the test set was 61%, indicating a significant overfitting phenomenon during the training process. üéì Internship Beijing Academy of Quantum Information Science 08/2023 ‚Äì 01/2024 Research Intern at Quantum Computation Department Proposed a quantum convolution kernel design based on variational quantum circuits and developed a universal quantum convolution layer, successfully integrating it into classical CNN architectures such as VGG, GoogLeNet, and ResNet. Developed and evaluated various hybrid models, including a simple model named HQCCNN-2, which achieved 84.45% accuracy on the FashionMNIST dataset, surpassing the traditional CNN\u0026rsquo;s 80.72%. This demonstrates the effectiveness of the quantum convolution layer in improving model performance. Tested on a real quantum computer further validated the effectiveness of the hybrid model, demonstrating the viable integration of quantum computing with deep learning, and highlighting the potential for leveraging quantum properties to enhance model performance. üèÖ Competition Experience China International \u0026#34;Internet \u0026#43;\u0026#34; College Students\u0026#39; Innovation Competition 08/2022 Zhongke Ushield: Deep Learning-based Face Privacy Protection Authentication System Responsible for constructing a localized facial feature extraction engine based on MobileFaceNet, ensuring feature extraction is completed on end devices (such as mobile phones and cameras), guaranteeing that raw data does not leave the domain and is not stored, thus enhancing user privacy protection while improving recognition efficiency. \u0026#34;Challenge Cup\u0026#34; Capital University Entrepreneurship Competition 05/2022 Smart Orchard Responsible for the development of the fruit detection, ripeness prediction, and pest identification system, using deep convolutional neural network (CNN) technology for intelligent monitoring of crop growth conditions. Applied advanced object detection algorithms such as Faster R-CNN and YOLO to achieve high precision in apple detection and ripeness assessment, with an accuracy rate exceeding 90%, significantly enhancing the intelligence level of orchard management. Built and trained a dedicated dataset containing various pest samples, optimizing pest detection accuracy through data preprocessing (such as image normalization and resizing) and data augmentation techniques (like rotation, flipping, and noise addition), enabling the real-time monitoring system to accurately identify over 80% of pests, providing effective scientific maintenance recommendations to help farmers reduce crop losses. üìã Extracurricular Activities Vice President, Cyber Security Club, Beijing Institute of Technology 09/2021-09/2022 Backbone, Media Center of the Student Union of Beijing Institute of Technology 10/2020-06/2021 üì´ Contact üìß zongsi.xu@outlook.com üëî Zongsi (Tristan) Xu üíª github.com/BaizeXS üìç Hong Kong SAR, China ","permalink":"http://localhost:1313/resume/","summary":"Personal resume of Zongsi (Tristan) Xu","title":"Zongsi (Tristan) Xu"},{"content":"‰∏Ä„ÄÅÊï∞ÂÄºÁâπÂæÅ‰∏éÁ±ªÂà´ÁâπÂæÅ Êï∞ÂÄºÁâπÂæÅ (Numeric Features) ÂÖ∑ÊúâÂèØÂä†ÂáèÁöÑÊÑè‰πâÔºå‰∏îÂ≠òÂú®Â§ßÂ∞èÈ°∫Â∫è„ÄÇ ‰æãÂ≠êÔºöÂπ¥ÈæÑ„ÄÅÊ∏©Â∫¶Á≠â„ÄÇÂèØ‰ª•Áõ¥Êé•‰øùÁïôÂÖ∂Êï¥Êï∞ÊàñÊµÆÁÇπÊï∞ÂΩ¢Âºè‰æõÊ®°Âûã‰ΩøÁî®„ÄÇ Á±ªÂà´ÁâπÂæÅ (Categorical Features) Êï∞ÊçÆÂÄºÁ¶ªÊï£Ôºå‰∏çÂÖ∑Â§á‚ÄúÊï∞ÂÄºÂ§ßÂ∞è‚ÄùÈó¥ÁöÑÂèØÊØîÊÑè‰πâ„ÄÇ ‰æãÂ≠êÔºöÂõΩÁ±çÔºàÁæéÂõΩ/‰∏≠ÂõΩ/Âç∞Â∫¶Á≠âÔºâ„ÄÅÊÄßÂà´ÔºàÁî∑/Â•≥ÔºâÁ≠â„ÄÇ ÈóÆÈ¢òÔºöËã•‰ªÖÁî®Êï¥Êï∞Ë°®Á§∫ÔºàÁæéÂõΩ=1, ‰∏≠ÂõΩ=2ÔºâÔºå‰ºöÂºïÂÖ•ÈîôËØØÁöÑÊï∞ÂÄºËøêÁÆóÂÖ≥Á≥ªÔºåÂ¶Ç ‚ÄúÁæéÂõΩ + ‰∏≠ÂõΩ = Âç∞Â∫¶‚Äù„ÄÇ ‰∫å„ÄÅOne-HotÁºñÁ†ÅÁöÑÂä®Êú∫‰∏éÊµÅÁ®ã ‰∏∫‰ªÄ‰πà‰ΩøÁî®One-Hot\nÈÄöËøáÂ∞ÜÁ±ªÂà´Êò†Â∞Ñ‰∏∫ÂêëÈáèÔºåÈÅøÂÖçÊï¥Êï∞ÁºñÁ†ÅÂºïÂÖ•ÁöÑ‰º™Êï∞ÂÄºÂÖ≥Á≥ª„ÄÇ ÂêåÊó∂‰øùÁïôÂêÑÁßçÂèØËÉΩÁ±ªÂà´ÁöÑ‰ø°ÊÅØÔºå‰∏î‰ªÖÂú®ÂØπÂ∫î‰ΩçÁΩÆ‰∏∫1ÔºåÂÖ∂‰ªñ‰ΩçÁΩÆ‰∏∫0„ÄÇ Âª∫Á´ãÊò†Â∞ÑÔºö‰ªéÁ±ªÂà´Âà∞Á¥¢Âºï\n‰∏∫ÊØè‰∏™Á±ªÂà´ÂàÜÈÖç‰∏Ä‰∏™ÂîØ‰∏ÄÁ¥¢ÂºïÔºåÈÄöÂ∏∏‰ªé1ÂºÄÂßã„ÄÇ È¢ÑÁïôÁ¥¢Âºï0Ë°®Á§∫‚ÄúÊú™Áü•‚ÄùÊàñ‚ÄúÁº∫Â§±‚ÄùÔºåÂØπÂ∫îÂÖ®0ÂêëÈáè„ÄÇ ËΩ¨Êç¢‰∏∫One-HotÂêëÈáè\nËã•Á±ªÂà´ÊÄªÊï∞‰∏∫197ÔºåÂàôÁî®197Áª¥ÂêëÈáèË°®Á§∫„ÄÇ ‰æãÂ≠êÔºöÁæéÂõΩ [1, 0, 0, 0, ‚Ä¶]Ôºå ‰∏≠ÂõΩ [0, 1, 0, 0, ‚Ä¶]„ÄÇ Á§∫‰æãÔºöË°®Á§∫‰∏Ä‰∏™‰∫∫ÁöÑÁâπÂæÅ\nÁâπÂæÅÂåÖÂê´ÔºàÂπ¥ÈæÑ, ÊÄßÂà´, ÂõΩÁ±çÔºåÂÖ∂‰∏≠ÂõΩÁ±ç197ÁßçÔºâ Áª¥Â∫¶ÊÄªÂíåÔºö1Áª¥_age + 1Áª¥_gender + 197Áª¥_nationality = 199Áª¥„ÄÇ ‰æãÂ¶Ç (28, Â•≥, ‰∏≠ÂõΩ) ‚Üí [28, 0, 0, 1, 0, ‚Ä¶, 0]„ÄÇ ‰∏â„ÄÅÊñáÊú¨Êï∞ÊçÆÂ§ÑÁêÜÊµÅÁ®ã ÊñáÊú¨Âú®Ëá™ÁÑ∂ËØ≠Ë®ÄÂ§ÑÁêÜÔºàNLPÔºâ‰∏≠‰Ωú‰∏∫Â∏∏ËßÅÁöÑÂéüÂßãËæìÂÖ•ÔºåÈúÄË¶ÅÊï∞ÂÄºÂåñÊâçËÉΩÈÄÅÂÖ•Ê®°Âûã„ÄÇ‰∏ÄËà¨Ê≠•È™§Â¶Ç‰∏ãÔºö\nÂàÜËØç (Tokenization)\nÂ∞ÜÊñáÊú¨ÊãÜÂàÜ‰∏∫‰∏Ä‰∏™‰∏™ÂçïËØçÔºàTokenÔºâ„ÄÇ ‰æãÂ≠êÔºö\u0026quot;... to be or not to be...\u0026quot; ‚Üí [\u0026quot;...\u0026quot;, \u0026quot;to\u0026quot;, \u0026quot;be\u0026quot;, \u0026quot;or\u0026quot;, \u0026quot;not\u0026quot;, \u0026quot;to\u0026quot;, \u0026quot;be\u0026quot;, \u0026quot;...\u0026quot;]„ÄÇ ÁªüËÆ°ËØçÈ¢ë \u0026amp; ÊûÑÂª∫ËØçÂÖ∏\nËØçÈ¢ëÁªüËÆ° Áî®ÂìàÂ∏åË°®/Â≠óÂÖ∏ËÆ∞ÂΩïÊØè‰∏™ÂçïËØçÂá∫Áé∞Ê¨°Êï∞„ÄÇ ÈÅçÂéÜÊñáÊú¨Êó∂ÔºåËã•ÂçïËØçÂ∞öÊú™ÂÖ•Ë°®ÔºåÂàôÊñ∞Âª∫ËÆ∞ÂΩïÔºõËã•Â∑≤Â≠òÂú®ÔºåÂàôËÆ°Êï∞+1„ÄÇ ÊéíÂ∫è‰∏éÁ¥¢Âºï ÊåâËØçÈ¢ëÈôçÂ∫èÊéíÂ∫èÔºåËØçÈ¢ëÊúÄÈ´òÁöÑÂçïËØçÊéíÂú®ÂâçÈù¢„ÄÇ Á¥¢Âºï‰ªé1ÂºÄÂßãÔºå0ÁïôÁªô‚ÄúÊú™Áü•‚Äù„ÄÇ ËØçÂÖ∏ËßÑÊ®°ÔºàvocabularyÔºâÂèØËßÜÈúÄÊ±ÇÊà™Êñ≠Ôºà‰æãÂ¶ÇÂè™‰øùÁïôTop 10kÔºâ„ÄÇ ‰∏∫‰ªÄ‰πàÁßªÈô§‰ΩéÈ¢ëËØç ‰ΩéÈ¢ëËØçÂèØËÉΩÊòØÊãºÂÜôÈîôËØØ„ÄÅÁΩïËßÅ‰∫∫ÂêçÁ≠âÔºåÂØπÊ®°ÂûãÂ∏ÆÂä©ÊúâÈôê„ÄÇ ÂáèÂ∞ëËØçÂÖ∏ËßÑÊ®°ÂèØÈôç‰ΩéËøêÁÆóÂºÄÈîÄ„ÄÅÂä†Âø´Ê®°ÂûãËÆ≠ÁªÉ‰∏éÊé®ÁêÜÈÄüÂ∫¶„ÄÇ Áã¨ÁÉ≠ÁºñÁ†Å (One-Hot Encoding)\nÂ∞ÜÊØè‰∏™ÂçïËØçÊò†Â∞Ñ‰∏∫ËØçÂÖ∏‰∏≠ÁöÑÁ¥¢ÂºïÂêéÔºàÂ¶Ç [2, 4, 1, 8, ‚Ä¶]ÔºâÔºåÂèØËøõ‰∏ÄÊ≠•ËΩ¨Êç¢ÊàêOne-HotÂêëÈáè„ÄÇ One-HotÁª¥Â∫¶ÂèñÂÜ≥‰∫é‰øùÁïô‰∏ãÊù•ÁöÑËØçÂÖ∏Â§ßÂ∞èÔºà‰æãÂ¶Ç1‰∏áÔºâ„ÄÇ Êú™Êî∂ÂΩïÂçïËØçÂèØËÉΩÁõ¥Êé•ÂøΩÁï•ÔºåÊàñÁªü‰∏ÄÁî®Á¥¢Âºï0‰ª£Êõø„ÄÇ Âõõ„ÄÅÊ†∏ÂøÉÊî∂Ëé∑‰∏éÂ∫îÁî® Á±ªÂà´ÁâπÂæÅÂøÖÈúÄÊï∞ÂÄºÂåñÔºö\n‰ΩøÁî®Êï¥Êï∞1,2,3‚Ä¶‰ªÖË°®Á§∫Á±ªÂà´‚ÄúÊ†áËØÜ‚ÄùÔºåÂπ∂‰∏ç‰ª£Ë°®ÂÆÉ‰ª¨ÂèØËøõË°åÊï∞ÂÄºËøêÁÆó„ÄÇ Âõ†Ê≠§ÈúÄË¶ÅOne-HotÁ≠âÁºñÁ†ÅÊñπÂºèÔºåÈÅøÂÖçÊï∞ÂÄºËØØËß£„ÄÇ ÊñáÊú¨Êï∞ÊçÆÈ¢ÑÂ§ÑÁêÜÔºö\nÂàÜËØç„ÄÅËØçÈ¢ëÁªüËÆ°„ÄÅÊûÑÂª∫ËØçÂÖ∏„ÄÅÁ¥¢ÂºïÂåñ„ÄÅOne-HotÊàñÂÖ∂‰ªñÊñπÂºèÔºàÂ¶ÇËØçÂµåÂÖ•ÔºâÊòØÂ∏∏ËßÅÊµÅÁ®ã„ÄÇ Ê≠£Á°ÆÁöÑÊñáÊú¨È¢ÑÂ§ÑÁêÜÂèØÊòæËëóÂΩ±ÂìçÊ®°ÂûãÊÄßËÉΩÂíåÊïàÁéá„ÄÇ ‰øùÁïôÊú™Áü•Á¥¢ÂºïÔºö\n‰øùËØÅÂØπÁº∫Â§±Êï∞ÊçÆÊàñÂ≠óÂÖ∏Â§ñÊñ∞ËØçËÉΩÊúâÂü∫Êú¨ÁöÑË°®Á§∫ÔºåÊèêÂçáÊ®°ÂûãÂÆπÈîôÊÄß„ÄÇ ÂÆûÈôÖ‰ΩøÁî®Ôºö\nÂØπ‰∫éÂ∞èËßÑÊ®°Á±ªÂà´ÂèØÁõ¥Êé•One-HotÁºñÁ†ÅÔºõÂØπ‰∫éËØçÂÖ∏ÂæàÂ§ßÁöÑÂú∫ÊôØÔºåÈÄöÂ∏∏‰ºöËøõ‰∏ÄÊ≠•ËÄÉËôëËØçÂµåÂÖ•ÔºàWord EmbeddingÔºâÊàñÈ¢ÑËÆ≠ÁªÉËØ≠Ë®ÄÊ®°Âûã„ÄÇ ","permalink":"http://localhost:1313/posts/nlp-1/","summary":"\u003ch2 id=\"‰∏ÄÊï∞ÂÄºÁâπÂæÅ‰∏éÁ±ªÂà´ÁâπÂæÅ\"\u003e‰∏Ä„ÄÅÊï∞ÂÄºÁâπÂæÅ‰∏éÁ±ªÂà´ÁâπÂæÅ\u003c/h2\u003e\n\u003col\u003e\n\u003cli\u003e\u003cstrong\u003eÊï∞ÂÄºÁâπÂæÅ (Numeric Features)\u003c/strong\u003e\n\u003cul\u003e\n\u003cli\u003eÂÖ∑ÊúâÂèØÂä†ÂáèÁöÑÊÑè‰πâÔºå‰∏îÂ≠òÂú®Â§ßÂ∞èÈ°∫Â∫è„ÄÇ\u003c/li\u003e\n\u003cli\u003e‰æãÂ≠êÔºöÂπ¥ÈæÑ„ÄÅÊ∏©Â∫¶Á≠â„ÄÇÂèØ‰ª•Áõ¥Êé•‰øùÁïôÂÖ∂Êï¥Êï∞ÊàñÊµÆÁÇπÊï∞ÂΩ¢Âºè‰æõÊ®°Âûã‰ΩøÁî®„ÄÇ\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003eÁ±ªÂà´ÁâπÂæÅ (Categorical Features)\u003c/strong\u003e\n\u003cul\u003e\n\u003cli\u003eÊï∞ÊçÆÂÄºÁ¶ªÊï£Ôºå‰∏çÂÖ∑Â§á‚ÄúÊï∞ÂÄºÂ§ßÂ∞è‚ÄùÈó¥ÁöÑÂèØÊØîÊÑè‰πâ„ÄÇ\u003c/li\u003e\n\u003cli\u003e‰æãÂ≠êÔºöÂõΩÁ±çÔºàÁæéÂõΩ/‰∏≠ÂõΩ/Âç∞Â∫¶Á≠âÔºâ„ÄÅÊÄßÂà´ÔºàÁî∑/Â•≥ÔºâÁ≠â„ÄÇ\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003eÈóÆÈ¢ò\u003c/strong\u003eÔºöËã•‰ªÖÁî®Êï¥Êï∞Ë°®Á§∫ÔºàÁæéÂõΩ=1, ‰∏≠ÂõΩ=2ÔºâÔºå‰ºöÂºïÂÖ•ÈîôËØØÁöÑÊï∞ÂÄºËøêÁÆóÂÖ≥Á≥ªÔºåÂ¶Ç ‚ÄúÁæéÂõΩ + ‰∏≠ÂõΩ = Âç∞Â∫¶‚Äù„ÄÇ\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003c/ol\u003e\n\u003ch2 id=\"‰∫åone-hotÁºñÁ†ÅÁöÑÂä®Êú∫‰∏éÊµÅÁ®ã\"\u003e‰∫å„ÄÅOne-HotÁºñÁ†ÅÁöÑÂä®Êú∫‰∏éÊµÅÁ®ã\u003c/h2\u003e\n\u003col\u003e\n\u003cli\u003e\n\u003cp\u003e\u003cstrong\u003e‰∏∫‰ªÄ‰πà‰ΩøÁî®One-Hot\u003c/strong\u003e\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eÈÄöËøáÂ∞ÜÁ±ªÂà´Êò†Â∞Ñ‰∏∫ÂêëÈáèÔºåÈÅøÂÖçÊï¥Êï∞ÁºñÁ†ÅÂºïÂÖ•ÁöÑ‰º™Êï∞ÂÄºÂÖ≥Á≥ª„ÄÇ\u003c/li\u003e\n\u003cli\u003eÂêåÊó∂‰øùÁïôÂêÑÁßçÂèØËÉΩÁ±ªÂà´ÁöÑ‰ø°ÊÅØÔºå‰∏î‰ªÖÂú®ÂØπÂ∫î‰ΩçÁΩÆ‰∏∫1ÔºåÂÖ∂‰ªñ‰ΩçÁΩÆ‰∏∫0„ÄÇ\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003e\u003cstrong\u003eÂª∫Á´ãÊò†Â∞ÑÔºö‰ªéÁ±ªÂà´Âà∞Á¥¢Âºï\u003c/strong\u003e\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e‰∏∫ÊØè‰∏™Á±ªÂà´ÂàÜÈÖç‰∏Ä‰∏™ÂîØ‰∏ÄÁ¥¢ÂºïÔºåÈÄöÂ∏∏‰ªé1ÂºÄÂßã„ÄÇ\u003c/li\u003e\n\u003cli\u003eÈ¢ÑÁïôÁ¥¢Âºï0Ë°®Á§∫‚ÄúÊú™Áü•‚ÄùÊàñ‚ÄúÁº∫Â§±‚ÄùÔºåÂØπÂ∫îÂÖ®0ÂêëÈáè„ÄÇ\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003e\u003cstrong\u003eËΩ¨Êç¢‰∏∫One-HotÂêëÈáè\u003c/strong\u003e\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eËã•Á±ªÂà´ÊÄªÊï∞‰∏∫197ÔºåÂàôÁî®197Áª¥ÂêëÈáèË°®Á§∫„ÄÇ\u003c/li\u003e\n\u003cli\u003e‰æãÂ≠êÔºöÁæéÂõΩ \u003ccode\u003e[1, 0, 0, 0, ‚Ä¶]\u003c/code\u003eÔºå ‰∏≠ÂõΩ \u003ccode\u003e[0, 1, 0, 0, ‚Ä¶]\u003c/code\u003e„ÄÇ\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003e\u003cstrong\u003eÁ§∫‰æãÔºöË°®Á§∫‰∏Ä‰∏™‰∫∫ÁöÑÁâπÂæÅ\u003c/strong\u003e\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eÁâπÂæÅÂåÖÂê´ÔºàÂπ¥ÈæÑ, ÊÄßÂà´, ÂõΩÁ±çÔºåÂÖ∂‰∏≠ÂõΩÁ±ç197ÁßçÔºâ\u003c/li\u003e\n\u003cli\u003eÁª¥Â∫¶ÊÄªÂíåÔºö1Áª¥_age + 1Áª¥_gender + 197Áª¥_nationality = 199Áª¥„ÄÇ\u003c/li\u003e\n\u003cli\u003e‰æãÂ¶Ç \u003ccode\u003e(28, Â•≥, ‰∏≠ÂõΩ)\u003c/code\u003e ‚Üí \u003ccode\u003e[28, 0, 0, 1, 0, ‚Ä¶, 0]\u003c/code\u003e„ÄÇ\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003c/ol\u003e\n\u003ch2 id=\"‰∏âÊñáÊú¨Êï∞ÊçÆÂ§ÑÁêÜÊµÅÁ®ã\"\u003e‰∏â„ÄÅÊñáÊú¨Êï∞ÊçÆÂ§ÑÁêÜÊµÅÁ®ã\u003c/h2\u003e\n\u003cp\u003eÊñáÊú¨Âú®Ëá™ÁÑ∂ËØ≠Ë®ÄÂ§ÑÁêÜÔºàNLPÔºâ‰∏≠‰Ωú‰∏∫Â∏∏ËßÅÁöÑÂéüÂßãËæìÂÖ•ÔºåÈúÄË¶ÅÊï∞ÂÄºÂåñÊâçËÉΩÈÄÅÂÖ•Ê®°Âûã„ÄÇ‰∏ÄËà¨Ê≠•È™§Â¶Ç‰∏ãÔºö\u003c/p\u003e\n\u003col\u003e\n\u003cli\u003e\n\u003cp\u003e\u003cstrong\u003eÂàÜËØç (Tokenization)\u003c/strong\u003e\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eÂ∞ÜÊñáÊú¨ÊãÜÂàÜ‰∏∫‰∏Ä‰∏™‰∏™ÂçïËØçÔºàTokenÔºâ„ÄÇ\u003c/li\u003e\n\u003cli\u003e‰æãÂ≠êÔºö\u003ccode\u003e\u0026quot;... to be or not to be...\u0026quot;\u003c/code\u003e ‚Üí \u003ccode\u003e[\u0026quot;...\u0026quot;, \u0026quot;to\u0026quot;, \u0026quot;be\u0026quot;, \u0026quot;or\u0026quot;, \u0026quot;not\u0026quot;, \u0026quot;to\u0026quot;, \u0026quot;be\u0026quot;, \u0026quot;...\u0026quot;]\u003c/code\u003e„ÄÇ\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003e\u003cstrong\u003eÁªüËÆ°ËØçÈ¢ë \u0026amp; ÊûÑÂª∫ËØçÂÖ∏\u003c/strong\u003e\u003c/p\u003e","title":""},{"content":"Text to Sequence ÊñáÊú¨Â§ÑÁêÜ\nStep1: Tokenization\nTokenization breaks a piece of text down into a list of tokens.\nHere, a token is a word. (A token can be a character in some applications.)\nTokenizationËÆ≤Á©∂ÂæàÂ§öÔºå‰æãÂ¶ÇÊòØÂê¶Â∫îËØ•ÊääÂ§ßÂÜôÊîπÊàêÂ∞èÂÜôÂë¢ÔºüËøõË°åtypo correctionÁ≠âÁ≠â\nStep2: Build Dictionary\nUse a dictionary (hash table) to count word frequencies.\nThe dictionary maps word to index.\nÂèØ‰ª•È¶ñÂÖàÁªüËÆ°ËØçÈ¢ëÂéªÊéâ‰ΩéÈ¢ëËØçÔºåÁÑ∂ÂêéËÆ©ÊØè‰∏™ËØçÂØπÂ∫î‰∏Ä‰∏™Ê≠£Êï¥Êï∞ÔºõËøôÊ†∑ÁöÑËØùÔºå‰∏ÄÂè•ËØùÂ∞±ÂèØ‰ª•Áî®‰∏Ä‰∏™Ê≠£Êï¥Êï∞ÂàóË°®Ë°®Á§∫ÔºåËøô‰∏™ÂàóË°®Â∞±Âè´sequenceÔºõÂ¶ÇÊûúÂøÖË¶ÅÂ∞±ËøòÂæóÂÅöone-hot encoding„ÄÇ\nÁªìÊûú\n‰ΩÜÊòØÈïøÂ∫¶‰∏çÁªü‰∏Ä\nStep4: ÂØπÈΩêsequence\nËß£ÂÜ≥ÊñπÊ°àÊòØËøôÊ†∑ÁöÑÔºöÂèØ‰ª•Âõ∫ÂÆöÈïøÂ∫¶‰∏∫wÔºåÂä†ÂÖ•‰∏Ä‰∏™Â∫èÂàóÈïøÂ∫¶Â§™ÈïøÔºåÂ∞±Á†çÊéâÂâçÈù¢ÁöÑËØçÔºåÂè™‰øùÁïôÊúÄÂêéw‰∏™ËØçÔºõÂ¶ÇÊûú‰∏Ä‰∏™Â∫èÂàóÂ§™Áü≠ÔºåÂ∞±ÂÅözero paddingÔºåÁî®0Â°´ÂÖÖ\nËøôÊ†∑‰∏ÄÊù•ÔºåÊâÄÊúâÁöÑÂ∫èÂàóÈïøÂ∫¶Â∞±Áªü‰∏Ä‰∫Ü\nÊñáÊú¨Â§ÑÁêÜÂÆåÊàê‰∫ÜÔºåÊé•‰∏ãÊù•ÊòØword embeddingÔºåÊääÂçïËØçË°®Á§∫‰∏∫‰∏Ä‰∏™‰ΩéÁª¥ÂêëÈáèÔºõ\nÁÑ∂ËÄåËøôÊ†∑ÂÅöÁöÑËØùÔºåÂ¶ÇÊûúÊòØ10000‰∏™ÂçïËØçÔºåÁª¥Â∫¶Â∞±ÊòØ10000Áª¥ÔºåÁª¥Â∫¶Â§™È´ò‰∫ÜÔºõÂõ†Ê≠§Ë¶ÅÂÅöword embeddingÔºõ\nÂÖ∑‰ΩìÂÅöÊ≥ïÂ∞±ÊòØÊääone-hotÂêëÈáèe_iÂíåÂèÇÊï∞Áü©ÈòµpÁõ∏‰πòÔºõÁü©ÈòµPËΩ¨ÁΩÆÁöÑÂ§ßÂ∞èÊòØd x vÔºõdÊòØËØçÂêëÈáèÁöÑÁª¥Â∫¶ÔºõvÊòØÂ≠óÂÖ∏ÈáåËØçÊ±áÁöÑÊï∞ÈáèÔºõÁªìÊûú‰∏∫x_iÔºõx_iÂ∞±ÊòØ‰∏Ä‰∏™ËØçÂêëÈáèÔºõÂ¶ÇÊûúone-hotÂêëÈáèÁöÑÁ¨¨‰∏âË°å‰∏∫1ÔºõÈÇ£‰πàx_iÂ∞±ÊòØPËΩ¨ÁΩÆÁü©ÈòµÁöÑÁ¨¨‰∏âÂàóÔºàÂÖ∂‰ΩôÂàóÈÉΩ‰∏∫0ÔºâÔºõÊâÄ‰ª•PËΩ¨ÁΩÆÊØè‰∏ÄÂàóÈÉΩÊòØ‰∏Ä‰∏™ËØçÂêëÈáèÔºõÊâÄ‰ª•Áü©ÈòµPÊú¨Ë∫´ÁöÑÊØè‰∏ÄË°åÂ∞±ÊòØ‰∏Ä‰∏™ËØçÂêëÈáèÔºõÂÖ∂Ë°åÊï∞‰∏∫vÔºõÂç≥vocabularyÔºåËØçÊ±áÈáèÔºõÊØè‰∏ÄË°åÂØπÂ∫î‰∏Ä‰∏™ÂçïËØçÔºõÁü©ÈòµÁöÑÂàóÊï∞‰∏∫dÔºõdÊòØÁî®Êà∑ÂÜ≥ÂÆöÁöÑÔºõdÁöÑÂ§ßÂ∞è‰ºöÂÜ≥ÂÆöÊú∫Âô®Â≠¶‰π†Ê®°ÂûãÁöÑË°®Áé∞ÔºõÂ∫îËØ•Áî®xxxÊù•ÈÄâÊã©‰∏Ä‰∏™ÊØîËæÉÂ•ΩÁöÑdÔºõ\nÊàë‰ª¨ÁöÑ‰ªªÂä°ÊòØÁúãËØÑËÆ∫ÊòØÊ≠£Èù¢ÁöÑËøòÊòØË¥üÈù¢ÁöÑÔºõÂèÇÊï∞Áü©ÈòµÊòØ‰ªéËÆ≠ÁªÉÊï∞ÊçÆ‰∏≠Â≠¶‰π†Âá∫Êù•ÁöÑÔºåÊâÄ‰ª•Â≠¶Âá∫Êù•ÁöÑËØçÂêëÈáèÊòØÂ∏¶ÊúâÊÑüÊÉÖËâ≤ÂΩ©ÁöÑÔºõÂÅáËÆæËøô‰∫õËØçÂêëÈáèÈÉΩÊòØ‰∫åÁª¥ÁöÑÔºåÂàôÂèØ‰ª•Âú®Âπ≥Èù¢ÂùêÊ†áÁ≥ª‰∏≠Ê†áÂá∫‰∏ãÈù¢ËØçÂêëÈáè\nkerasÊèê‰æõembeddingÂ±ÇÔºõÁî®Êà∑ÂèØ‰ª•ÊåáÂÆövocabularyÂ§ßÂ∞èÂíådÁöÑÂ§ßÂ∞èÔºõ‰ª•ÂèäÊØè‰∏Ä‰∏™sequenceÁöÑÈïøÂ∫¶ÔºõdÊòØÊ†πÊçÆÁÆóÊ≥ïÈÄâÂá∫Êù•ÁöÑ Âà∞Ëøô‰∏ÄÊ≠•ÔºåÊàë‰ª¨Â∑≤ÁªèÂÆåÊàê‰∫ÜÊñáÊú¨Â§ÑÁêÜÂíåword embedding„ÄÇÊé•‰∏ãÊù•Â∞±ÊòØÁî®Logistic Regression for Binary ClassificationÂÅö‰∫åÂàÜÁ±ªÔºõ\n","permalink":"http://localhost:1313/posts/nlp-2/","summary":"\u003ch3 id=\"text-to-sequence\"\u003eText to Sequence\u003c/h3\u003e\n\u003cp\u003eÊñáÊú¨Â§ÑÁêÜ\u003c/p\u003e\n\u003cp\u003eStep1: Tokenization\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\n\u003cp\u003eTokenization breaks a piece of text down into a list of tokens.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003eHere, a token is a word. (A token can be a character in some applications.)\u003c/p\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003eTokenizationËÆ≤Á©∂ÂæàÂ§öÔºå‰æãÂ¶ÇÊòØÂê¶Â∫îËØ•ÊääÂ§ßÂÜôÊîπÊàêÂ∞èÂÜôÂë¢ÔºüËøõË°åtypo correctionÁ≠âÁ≠â\u003c/p\u003e\n\u003cp\u003e\u003cimg alt=\"image-20250322150322238\" loading=\"lazy\" src=\"./NLP-2.assets/image-20250322150322238.png\"\u003e\u003c/p\u003e\n\u003cp\u003eStep2: Build Dictionary\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\n\u003cp\u003eUse a dictionary (hash table) to count word frequencies.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003eThe dictionary maps word to index.\u003c/p\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003eÂèØ‰ª•È¶ñÂÖàÁªüËÆ°ËØçÈ¢ëÂéªÊéâ‰ΩéÈ¢ëËØçÔºåÁÑ∂ÂêéËÆ©ÊØè‰∏™ËØçÂØπÂ∫î‰∏Ä‰∏™Ê≠£Êï¥Êï∞ÔºõËøôÊ†∑ÁöÑËØùÔºå‰∏ÄÂè•ËØùÂ∞±ÂèØ‰ª•Áî®‰∏Ä‰∏™Ê≠£Êï¥Êï∞ÂàóË°®Ë°®Á§∫ÔºåËøô‰∏™ÂàóË°®Â∞±Âè´sequenceÔºõÂ¶ÇÊûúÂøÖË¶ÅÂ∞±ËøòÂæóÂÅöone-hot encoding„ÄÇ\u003cimg alt=\"image-20250322150620890\" loading=\"lazy\" src=\"./NLP-2.assets/image-20250322150620890.png\"\u003e\u003c/p\u003e\n\u003cp\u003eÁªìÊûú\u003c/p\u003e\n\u003cp\u003e\u003cimg alt=\"image-20250322150754528\" loading=\"lazy\" src=\"./NLP-2.assets/image-20250322150754528.png\"\u003e\u003c/p\u003e\n\u003cp\u003e‰ΩÜÊòØÈïøÂ∫¶‰∏çÁªü‰∏Ä\u003c/p\u003e\n\u003cp\u003eStep4: ÂØπÈΩêsequence\u003c/p\u003e\n\u003cp\u003e\u003cimg alt=\"image-20250322150854986\" loading=\"lazy\" src=\"./NLP-2.assets/image-20250322150854986.png\"\u003e\u003c/p\u003e\n\u003cp\u003eËß£ÂÜ≥ÊñπÊ°àÊòØËøôÊ†∑ÁöÑÔºöÂèØ‰ª•Âõ∫ÂÆöÈïøÂ∫¶‰∏∫wÔºåÂä†ÂÖ•‰∏Ä‰∏™Â∫èÂàóÈïøÂ∫¶Â§™ÈïøÔºåÂ∞±Á†çÊéâÂâçÈù¢ÁöÑËØçÔºåÂè™‰øùÁïôÊúÄÂêéw‰∏™ËØçÔºõÂ¶ÇÊûú‰∏Ä‰∏™Â∫èÂàóÂ§™Áü≠ÔºåÂ∞±ÂÅözero paddingÔºåÁî®0Â°´ÂÖÖ\u003c/p\u003e\n\u003cp\u003e\u003cimg alt=\"image-20250322151030119\" loading=\"lazy\" src=\"./NLP-2.assets/image-20250322151030119.png\"\u003e\u003c/p\u003e\n\u003cp\u003eËøôÊ†∑‰∏ÄÊù•ÔºåÊâÄÊúâÁöÑÂ∫èÂàóÈïøÂ∫¶Â∞±Áªü‰∏Ä‰∫Ü\u003c/p\u003e\n\u003cp\u003e\u003cimg alt=\"image-20250322151117125\" loading=\"lazy\" src=\"./NLP-2.assets/image-20250322151117125.png\"\u003e\u003c/p\u003e\n\u003cp\u003eÊñáÊú¨Â§ÑÁêÜÂÆåÊàê‰∫ÜÔºåÊé•‰∏ãÊù•ÊòØword embeddingÔºåÊääÂçïËØçË°®Á§∫‰∏∫‰∏Ä‰∏™‰ΩéÁª¥ÂêëÈáèÔºõ\u003c/p\u003e\n\u003cp\u003e\u003cimg alt=\"image-20250322151252837\" loading=\"lazy\" src=\"./NLP-2.assets/image-20250322151252837.png\"\u003e\u003c/p\u003e","title":""},{"content":"üëã About me Hello! I‚Äôm Xu Zongsi, a passionate technology enthusiast currently pursuing my Master of Science in ECIC at The University of Hong Kong. With a solid background in Software Engineering from the Beijing Institute of Technology, I specialize in emerging areas of artificial intelligence, including machine learning, deep learning, natural language processing, computer vision, and reinforcement learning.\nI have a strong interest in developing LLM agents and knowledge graphs, leveraging data science techniques for innovative solutions. Additionally, I am skilled in software development, aiming to create impactful applications that enhance user experiences.\nThroughout my academic journey, I have been involved in several innovative projects focused on fraud detection, intelligent text processing, and quantum computing applications in deep learning. My programming skills span languages like Python and Java, with experience in frameworks such as PyTorch.\nWhen I‚Äôm not coding, you can find me exploring new technologies, sharing insights on my blog, or engaging in community activities related to cyber security.\nüìö Education üá≠üá∞ The University of Hong Kong 09/2024 - Expected 11/2025 School of Computing and Data Science Master of Science in Electronic Commerce \u0026amp; Internet Computing Relevant Courses: Machine learning for business and e-commerce, Knowledge graphs, Financial fraud analytics, Internet infrastructure technologies, Website engineering, Blockchain and cryptocurrency, etc. üá®üá≥ Beijing Institute of Technology 09/2020 - 06/2024 School of Computer Science \u0026amp; Technology Bachelor of Engineering in Software Engineering, last two years GPA: 3.7/4 Relevant Courses: Reinforcement Learning, Deep Learning and Computer Vision, Artificial Intelligence and Robot Ethics, Almost Human: Mind, Brain and Artificial Intelligence, Mathematical Analysis for Engineering, Linear Algebra, Probability and Mathematical Statistics, etc. Skills: Python, Java, common data structures, design patterns, machine learning basics and algorithms, Linux, PyTorch, and some development tools (git, conda, etc.). üèÜ Awards \u0026amp; Honors Beijing Institute of Technology Undergraduate Scholarship (Top 20% of Grade) 06/2023 3rd Prize of China International \u0026#34;Internet \u0026#43;\u0026#34; College Student\u0026#39;s Innovation Competition 08/2022 Bronze Prize of \u0026#34;Challenge Cup\u0026#34; Capital University Entrepreneurship Competition 05/2022 üíº Project Experience Online Transaction Fraud Detection 09/2024 ‚Äì 01/2025 Independent project, supervised by Dr. Vivien Chan Focused on addressing financial fraud in e-commerce to enhance the accuracy of transaction anomaly detection, while independently managing the entire case study that included data preprocessing, feature engineering, model building, evaluation, and results analysis. Effectively resolved class imbalance issues using SMOTE and ROSE techniques. Built various models including Logistic Regression, Random Forest, XGBoost, and LightGBM, ultimately selecting the LightGBM model to achieve a recall rate of 95.45% and an AUC of 99.84%. Wrote efficient and maintainable code, enhancing model training and data processing efficiency through parallel computing and logging. Multi-Model Intelligent Text Keyword Extraction System 08/2023 ‚Äì 09/2023 Group project, supervised by Associate Prof. Xiaolin Zhao Designed and implemented an intelligent text summary system that automatically extracts keywords from article titles and abstracts, enhancing the understanding and summarization of text information. Participated in the planning of the technical route and built a hybrid model combining extractive and generative approaches, utilizing advanced natural language processing techniques including KeyBERT, Sentence Transformer, BERT, and T5 models. Responsible for data preprocessing and tokenization, as well as the end-to-end implementation and training of the T5 model, optimizing the model architecture and hyperparameters, achieving satisfactory results after only 3 epochs of training. Model evaluation results showed that the Rouge-1, Rouge-2, and Rouge-L metrics reached 0.6345, 0.5038, and 0.5282, respectively, in the third epoch, validating the model\u0026rsquo;s effectiveness in the summarization task. Cambridge University Machine Learning Summer Project 07/2023 ‚Äì 08/2023 Group project, supervised by Prof. Pietro Li√≤ Participated in the Cambridge University deep learning summer project, focusing on deep reinforcement learning; explored multi-agent learning algorithms across different environments. Reproduced the Multi-Agent Deep Deterministic Policy Gradient (MADDPG) algorithm in the Simple Adversary environment and studied the effect of agent numbers on convergence speed and stability, finding optimal stability at 21 agents. Designed and implemented comparative experiments inspired by the Rainbow algorithm, assessing target network strategies versus the Double Deep Q-Network (Double DQN). The results demonstrated that Double DQN significantly enhanced convergence speed, optimizing the overall learning process. Co-authored a group project paper on agent numbers and strategies effectiveness in multi-agent systems, achieving a score of 71% in the summer program (the highest in my group) and a \u0026ldquo;First Class\u0026rdquo; classification in the UK grading system. Deep Learning and Computer Vision Semester Project 09/2022 ‚Äì 12/2022 Independent project, supervised by Associate Prof. Guangyu Gao Designed and implemented a waste classifier using the ResNet model to improve classification accuracy and reduce resource waste. The project also enhanced understanding of transfer learning techniques with ResNet. Collected a dataset of 16 waste categories and preprocessed the images for uniformity and standardization, incorporating data augmentation techniques to enhance the dataset. Conducted experiments using ResNet34 and ResNet50 models through transfer learning, accelerating network convergence by leveraging pretrained weights. During training, techniques such as Batch Normalization and Dropout were applied to mitigate the risk of overfitting. The final model achieved an accuracy of 90% on the training set, while the performance on the test set was 61%, indicating a significant overfitting phenomenon during the training process. üéì Internship Beijing Academy of Quantum Information Science 08/2023 ‚Äì 01/2024 Research Intern at Quantum Computation Department Proposed a quantum convolution kernel design based on variational quantum circuits and developed a universal quantum convolution layer, successfully integrating it into classical CNN architectures such as VGG, GoogLeNet, and ResNet. Developed and evaluated various hybrid models, including a simple model named HQCCNN-2, which achieved 84.45% accuracy on the FashionMNIST dataset, surpassing the traditional CNN\u0026rsquo;s 80.72%. This demonstrates the effectiveness of the quantum convolution layer in improving model performance. Tested on a real quantum computer further validated the effectiveness of the hybrid model, demonstrating the viable integration of quantum computing with deep learning, and highlighting the potential for leveraging quantum properties to enhance model performance. üèÖ Competition Experience China International \u0026#34;Internet \u0026#43;\u0026#34; College Students\u0026#39; Innovation Competition 08/2022 Zhongke Ushield: Deep Learning-based Face Privacy Protection Authentication System Responsible for constructing a localized facial feature extraction engine based on MobileFaceNet, ensuring feature extraction is completed on end devices (such as mobile phones and cameras), guaranteeing that raw data does not leave the domain and is not stored, thus enhancing user privacy protection while improving recognition efficiency. \u0026#34;Challenge Cup\u0026#34; Capital University Entrepreneurship Competition 05/2022 Smart Orchard Responsible for the development of the fruit detection, ripeness prediction, and pest identification system, using deep convolutional neural network (CNN) technology for intelligent monitoring of crop growth conditions. Applied advanced object detection algorithms such as Faster R-CNN and YOLO to achieve high precision in apple detection and ripeness assessment, with an accuracy rate exceeding 90%, significantly enhancing the intelligence level of orchard management. Built and trained a dedicated dataset containing various pest samples, optimizing pest detection accuracy through data preprocessing (such as image normalization and resizing) and data augmentation techniques (like rotation, flipping, and noise addition), enabling the real-time monitoring system to accurately identify over 80% of pests, providing effective scientific maintenance recommendations to help farmers reduce crop losses. üìã Extracurricular Activities Vice President, Cyber Security Club, Beijing Institute of Technology 09/2021-09/2022 Backbone, Media Center of the Student Union of Beijing Institute of Technology 10/2020-06/2021 üì´ Contact üìß zongsi.xu@outlook.com üëî Zongsi (Tristan) Xu üíª github.com/BaizeXS üìç Hong Kong SAR, China ","permalink":"http://localhost:1313/resume/","summary":"Personal resume of Zongsi (Tristan) Xu","title":"Zongsi (Tristan) Xu"},{"content":"‰∏Ä„ÄÅÊï∞ÂÄºÁâπÂæÅ‰∏éÁ±ªÂà´ÁâπÂæÅ Êï∞ÂÄºÁâπÂæÅ (Numeric Features) ÂÖ∑ÊúâÂèØÂä†ÂáèÁöÑÊÑè‰πâÔºå‰∏îÂ≠òÂú®Â§ßÂ∞èÈ°∫Â∫è„ÄÇ ‰æãÂ≠êÔºöÂπ¥ÈæÑ„ÄÅÊ∏©Â∫¶Á≠â„ÄÇÂèØ‰ª•Áõ¥Êé•‰øùÁïôÂÖ∂Êï¥Êï∞ÊàñÊµÆÁÇπÊï∞ÂΩ¢Âºè‰æõÊ®°Âûã‰ΩøÁî®„ÄÇ Á±ªÂà´ÁâπÂæÅ (Categorical Features) Êï∞ÊçÆÂÄºÁ¶ªÊï£Ôºå‰∏çÂÖ∑Â§á‚ÄúÊï∞ÂÄºÂ§ßÂ∞è‚ÄùÈó¥ÁöÑÂèØÊØîÊÑè‰πâ„ÄÇ ‰æãÂ≠êÔºöÂõΩÁ±çÔºàÁæéÂõΩ/‰∏≠ÂõΩ/Âç∞Â∫¶Á≠âÔºâ„ÄÅÊÄßÂà´ÔºàÁî∑/Â•≥ÔºâÁ≠â„ÄÇ ÈóÆÈ¢òÔºöËã•‰ªÖÁî®Êï¥Êï∞Ë°®Á§∫ÔºàÁæéÂõΩ=1, ‰∏≠ÂõΩ=2ÔºâÔºå‰ºöÂºïÂÖ•ÈîôËØØÁöÑÊï∞ÂÄºËøêÁÆóÂÖ≥Á≥ªÔºåÂ¶Ç ‚ÄúÁæéÂõΩ + ‰∏≠ÂõΩ = Âç∞Â∫¶‚Äù„ÄÇ ‰∫å„ÄÅOne-HotÁºñÁ†ÅÁöÑÂä®Êú∫‰∏éÊµÅÁ®ã ‰∏∫‰ªÄ‰πà‰ΩøÁî®One-Hot\nÈÄöËøáÂ∞ÜÁ±ªÂà´Êò†Â∞Ñ‰∏∫ÂêëÈáèÔºåÈÅøÂÖçÊï¥Êï∞ÁºñÁ†ÅÂºïÂÖ•ÁöÑ‰º™Êï∞ÂÄºÂÖ≥Á≥ª„ÄÇ ÂêåÊó∂‰øùÁïôÂêÑÁßçÂèØËÉΩÁ±ªÂà´ÁöÑ‰ø°ÊÅØÔºå‰∏î‰ªÖÂú®ÂØπÂ∫î‰ΩçÁΩÆ‰∏∫1ÔºåÂÖ∂‰ªñ‰ΩçÁΩÆ‰∏∫0„ÄÇ Âª∫Á´ãÊò†Â∞ÑÔºö‰ªéÁ±ªÂà´Âà∞Á¥¢Âºï\n‰∏∫ÊØè‰∏™Á±ªÂà´ÂàÜÈÖç‰∏Ä‰∏™ÂîØ‰∏ÄÁ¥¢ÂºïÔºåÈÄöÂ∏∏‰ªé1ÂºÄÂßã„ÄÇ È¢ÑÁïôÁ¥¢Âºï0Ë°®Á§∫‚ÄúÊú™Áü•‚ÄùÊàñ‚ÄúÁº∫Â§±‚ÄùÔºåÂØπÂ∫îÂÖ®0ÂêëÈáè„ÄÇ ËΩ¨Êç¢‰∏∫One-HotÂêëÈáè\nËã•Á±ªÂà´ÊÄªÊï∞‰∏∫197ÔºåÂàôÁî®197Áª¥ÂêëÈáèË°®Á§∫„ÄÇ ‰æãÂ≠êÔºöÁæéÂõΩ [1, 0, 0, 0, ‚Ä¶]Ôºå ‰∏≠ÂõΩ [0, 1, 0, 0, ‚Ä¶]„ÄÇ Á§∫‰æãÔºöË°®Á§∫‰∏Ä‰∏™‰∫∫ÁöÑÁâπÂæÅ\nÁâπÂæÅÂåÖÂê´ÔºàÂπ¥ÈæÑ, ÊÄßÂà´, ÂõΩÁ±çÔºåÂÖ∂‰∏≠ÂõΩÁ±ç197ÁßçÔºâ Áª¥Â∫¶ÊÄªÂíåÔºö1Áª¥_age + 1Áª¥_gender + 197Áª¥_nationality = 199Áª¥„ÄÇ ‰æãÂ¶Ç (28, Â•≥, ‰∏≠ÂõΩ) ‚Üí [28, 0, 0, 1, 0, ‚Ä¶, 0]„ÄÇ ‰∏â„ÄÅÊñáÊú¨Êï∞ÊçÆÂ§ÑÁêÜÊµÅÁ®ã ÊñáÊú¨Âú®Ëá™ÁÑ∂ËØ≠Ë®ÄÂ§ÑÁêÜÔºàNLPÔºâ‰∏≠‰Ωú‰∏∫Â∏∏ËßÅÁöÑÂéüÂßãËæìÂÖ•ÔºåÈúÄË¶ÅÊï∞ÂÄºÂåñÊâçËÉΩÈÄÅÂÖ•Ê®°Âûã„ÄÇ‰∏ÄËà¨Ê≠•È™§Â¶Ç‰∏ãÔºö\nÂàÜËØç (Tokenization)\nÂ∞ÜÊñáÊú¨ÊãÜÂàÜ‰∏∫‰∏Ä‰∏™‰∏™ÂçïËØçÔºàTokenÔºâ„ÄÇ ‰æãÂ≠êÔºö\u0026quot;... to be or not to be...\u0026quot; ‚Üí [\u0026quot;...\u0026quot;, \u0026quot;to\u0026quot;, \u0026quot;be\u0026quot;, \u0026quot;or\u0026quot;, \u0026quot;not\u0026quot;, \u0026quot;to\u0026quot;, \u0026quot;be\u0026quot;, \u0026quot;...\u0026quot;]„ÄÇ ÁªüËÆ°ËØçÈ¢ë \u0026amp; ÊûÑÂª∫ËØçÂÖ∏\nËØçÈ¢ëÁªüËÆ° Áî®ÂìàÂ∏åË°®/Â≠óÂÖ∏ËÆ∞ÂΩïÊØè‰∏™ÂçïËØçÂá∫Áé∞Ê¨°Êï∞„ÄÇ ÈÅçÂéÜÊñáÊú¨Êó∂ÔºåËã•ÂçïËØçÂ∞öÊú™ÂÖ•Ë°®ÔºåÂàôÊñ∞Âª∫ËÆ∞ÂΩïÔºõËã•Â∑≤Â≠òÂú®ÔºåÂàôËÆ°Êï∞+1„ÄÇ ÊéíÂ∫è‰∏éÁ¥¢Âºï ÊåâËØçÈ¢ëÈôçÂ∫èÊéíÂ∫èÔºåËØçÈ¢ëÊúÄÈ´òÁöÑÂçïËØçÊéíÂú®ÂâçÈù¢„ÄÇ Á¥¢Âºï‰ªé1ÂºÄÂßãÔºå0ÁïôÁªô‚ÄúÊú™Áü•‚Äù„ÄÇ ËØçÂÖ∏ËßÑÊ®°ÔºàvocabularyÔºâÂèØËßÜÈúÄÊ±ÇÊà™Êñ≠Ôºà‰æãÂ¶ÇÂè™‰øùÁïôTop 10kÔºâ„ÄÇ ‰∏∫‰ªÄ‰πàÁßªÈô§‰ΩéÈ¢ëËØç ‰ΩéÈ¢ëËØçÂèØËÉΩÊòØÊãºÂÜôÈîôËØØ„ÄÅÁΩïËßÅ‰∫∫ÂêçÁ≠âÔºåÂØπÊ®°ÂûãÂ∏ÆÂä©ÊúâÈôê„ÄÇ ÂáèÂ∞ëËØçÂÖ∏ËßÑÊ®°ÂèØÈôç‰ΩéËøêÁÆóÂºÄÈîÄ„ÄÅÂä†Âø´Ê®°ÂûãËÆ≠ÁªÉ‰∏éÊé®ÁêÜÈÄüÂ∫¶„ÄÇ Áã¨ÁÉ≠ÁºñÁ†Å (One-Hot Encoding)\nÂ∞ÜÊØè‰∏™ÂçïËØçÊò†Â∞Ñ‰∏∫ËØçÂÖ∏‰∏≠ÁöÑÁ¥¢ÂºïÂêéÔºàÂ¶Ç [2, 4, 1, 8, ‚Ä¶]ÔºâÔºåÂèØËøõ‰∏ÄÊ≠•ËΩ¨Êç¢ÊàêOne-HotÂêëÈáè„ÄÇ One-HotÁª¥Â∫¶ÂèñÂÜ≥‰∫é‰øùÁïô‰∏ãÊù•ÁöÑËØçÂÖ∏Â§ßÂ∞èÔºà‰æãÂ¶Ç1‰∏áÔºâ„ÄÇ Êú™Êî∂ÂΩïÂçïËØçÂèØËÉΩÁõ¥Êé•ÂøΩÁï•ÔºåÊàñÁªü‰∏ÄÁî®Á¥¢Âºï0‰ª£Êõø„ÄÇ Âõõ„ÄÅÊ†∏ÂøÉÊî∂Ëé∑‰∏éÂ∫îÁî® Á±ªÂà´ÁâπÂæÅÂøÖÈúÄÊï∞ÂÄºÂåñÔºö\n‰ΩøÁî®Êï¥Êï∞1,2,3‚Ä¶‰ªÖË°®Á§∫Á±ªÂà´‚ÄúÊ†áËØÜ‚ÄùÔºåÂπ∂‰∏ç‰ª£Ë°®ÂÆÉ‰ª¨ÂèØËøõË°åÊï∞ÂÄºËøêÁÆó„ÄÇ Âõ†Ê≠§ÈúÄË¶ÅOne-HotÁ≠âÁºñÁ†ÅÊñπÂºèÔºåÈÅøÂÖçÊï∞ÂÄºËØØËß£„ÄÇ ÊñáÊú¨Êï∞ÊçÆÈ¢ÑÂ§ÑÁêÜÔºö\nÂàÜËØç„ÄÅËØçÈ¢ëÁªüËÆ°„ÄÅÊûÑÂª∫ËØçÂÖ∏„ÄÅÁ¥¢ÂºïÂåñ„ÄÅOne-HotÊàñÂÖ∂‰ªñÊñπÂºèÔºàÂ¶ÇËØçÂµåÂÖ•ÔºâÊòØÂ∏∏ËßÅÊµÅÁ®ã„ÄÇ Ê≠£Á°ÆÁöÑÊñáÊú¨È¢ÑÂ§ÑÁêÜÂèØÊòæËëóÂΩ±ÂìçÊ®°ÂûãÊÄßËÉΩÂíåÊïàÁéá„ÄÇ ‰øùÁïôÊú™Áü•Á¥¢ÂºïÔºö\n‰øùËØÅÂØπÁº∫Â§±Êï∞ÊçÆÊàñÂ≠óÂÖ∏Â§ñÊñ∞ËØçËÉΩÊúâÂü∫Êú¨ÁöÑË°®Á§∫ÔºåÊèêÂçáÊ®°ÂûãÂÆπÈîôÊÄß„ÄÇ ÂÆûÈôÖ‰ΩøÁî®Ôºö\nÂØπ‰∫éÂ∞èËßÑÊ®°Á±ªÂà´ÂèØÁõ¥Êé•One-HotÁºñÁ†ÅÔºõÂØπ‰∫éËØçÂÖ∏ÂæàÂ§ßÁöÑÂú∫ÊôØÔºåÈÄöÂ∏∏‰ºöËøõ‰∏ÄÊ≠•ËÄÉËôëËØçÂµåÂÖ•ÔºàWord EmbeddingÔºâÊàñÈ¢ÑËÆ≠ÁªÉËØ≠Ë®ÄÊ®°Âûã„ÄÇ ","permalink":"http://localhost:1313/posts/nlp-1/","summary":"\u003ch2 id=\"‰∏ÄÊï∞ÂÄºÁâπÂæÅ‰∏éÁ±ªÂà´ÁâπÂæÅ\"\u003e‰∏Ä„ÄÅÊï∞ÂÄºÁâπÂæÅ‰∏éÁ±ªÂà´ÁâπÂæÅ\u003c/h2\u003e\n\u003col\u003e\n\u003cli\u003e\u003cstrong\u003eÊï∞ÂÄºÁâπÂæÅ (Numeric Features)\u003c/strong\u003e\n\u003cul\u003e\n\u003cli\u003eÂÖ∑ÊúâÂèØÂä†ÂáèÁöÑÊÑè‰πâÔºå‰∏îÂ≠òÂú®Â§ßÂ∞èÈ°∫Â∫è„ÄÇ\u003c/li\u003e\n\u003cli\u003e‰æãÂ≠êÔºöÂπ¥ÈæÑ„ÄÅÊ∏©Â∫¶Á≠â„ÄÇÂèØ‰ª•Áõ¥Êé•‰øùÁïôÂÖ∂Êï¥Êï∞ÊàñÊµÆÁÇπÊï∞ÂΩ¢Âºè‰æõÊ®°Âûã‰ΩøÁî®„ÄÇ\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003eÁ±ªÂà´ÁâπÂæÅ (Categorical Features)\u003c/strong\u003e\n\u003cul\u003e\n\u003cli\u003eÊï∞ÊçÆÂÄºÁ¶ªÊï£Ôºå‰∏çÂÖ∑Â§á‚ÄúÊï∞ÂÄºÂ§ßÂ∞è‚ÄùÈó¥ÁöÑÂèØÊØîÊÑè‰πâ„ÄÇ\u003c/li\u003e\n\u003cli\u003e‰æãÂ≠êÔºöÂõΩÁ±çÔºàÁæéÂõΩ/‰∏≠ÂõΩ/Âç∞Â∫¶Á≠âÔºâ„ÄÅÊÄßÂà´ÔºàÁî∑/Â•≥ÔºâÁ≠â„ÄÇ\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003eÈóÆÈ¢ò\u003c/strong\u003eÔºöËã•‰ªÖÁî®Êï¥Êï∞Ë°®Á§∫ÔºàÁæéÂõΩ=1, ‰∏≠ÂõΩ=2ÔºâÔºå‰ºöÂºïÂÖ•ÈîôËØØÁöÑÊï∞ÂÄºËøêÁÆóÂÖ≥Á≥ªÔºåÂ¶Ç ‚ÄúÁæéÂõΩ + ‰∏≠ÂõΩ = Âç∞Â∫¶‚Äù„ÄÇ\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003c/ol\u003e\n\u003ch2 id=\"‰∫åone-hotÁºñÁ†ÅÁöÑÂä®Êú∫‰∏éÊµÅÁ®ã\"\u003e‰∫å„ÄÅOne-HotÁºñÁ†ÅÁöÑÂä®Êú∫‰∏éÊµÅÁ®ã\u003c/h2\u003e\n\u003col\u003e\n\u003cli\u003e\n\u003cp\u003e\u003cstrong\u003e‰∏∫‰ªÄ‰πà‰ΩøÁî®One-Hot\u003c/strong\u003e\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eÈÄöËøáÂ∞ÜÁ±ªÂà´Êò†Â∞Ñ‰∏∫ÂêëÈáèÔºåÈÅøÂÖçÊï¥Êï∞ÁºñÁ†ÅÂºïÂÖ•ÁöÑ‰º™Êï∞ÂÄºÂÖ≥Á≥ª„ÄÇ\u003c/li\u003e\n\u003cli\u003eÂêåÊó∂‰øùÁïôÂêÑÁßçÂèØËÉΩÁ±ªÂà´ÁöÑ‰ø°ÊÅØÔºå‰∏î‰ªÖÂú®ÂØπÂ∫î‰ΩçÁΩÆ‰∏∫1ÔºåÂÖ∂‰ªñ‰ΩçÁΩÆ‰∏∫0„ÄÇ\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003e\u003cstrong\u003eÂª∫Á´ãÊò†Â∞ÑÔºö‰ªéÁ±ªÂà´Âà∞Á¥¢Âºï\u003c/strong\u003e\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e‰∏∫ÊØè‰∏™Á±ªÂà´ÂàÜÈÖç‰∏Ä‰∏™ÂîØ‰∏ÄÁ¥¢ÂºïÔºåÈÄöÂ∏∏‰ªé1ÂºÄÂßã„ÄÇ\u003c/li\u003e\n\u003cli\u003eÈ¢ÑÁïôÁ¥¢Âºï0Ë°®Á§∫‚ÄúÊú™Áü•‚ÄùÊàñ‚ÄúÁº∫Â§±‚ÄùÔºåÂØπÂ∫îÂÖ®0ÂêëÈáè„ÄÇ\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003e\u003cstrong\u003eËΩ¨Êç¢‰∏∫One-HotÂêëÈáè\u003c/strong\u003e\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eËã•Á±ªÂà´ÊÄªÊï∞‰∏∫197ÔºåÂàôÁî®197Áª¥ÂêëÈáèË°®Á§∫„ÄÇ\u003c/li\u003e\n\u003cli\u003e‰æãÂ≠êÔºöÁæéÂõΩ \u003ccode\u003e[1, 0, 0, 0, ‚Ä¶]\u003c/code\u003eÔºå ‰∏≠ÂõΩ \u003ccode\u003e[0, 1, 0, 0, ‚Ä¶]\u003c/code\u003e„ÄÇ\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003e\u003cstrong\u003eÁ§∫‰æãÔºöË°®Á§∫‰∏Ä‰∏™‰∫∫ÁöÑÁâπÂæÅ\u003c/strong\u003e\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eÁâπÂæÅÂåÖÂê´ÔºàÂπ¥ÈæÑ, ÊÄßÂà´, ÂõΩÁ±çÔºåÂÖ∂‰∏≠ÂõΩÁ±ç197ÁßçÔºâ\u003c/li\u003e\n\u003cli\u003eÁª¥Â∫¶ÊÄªÂíåÔºö1Áª¥_age + 1Áª¥_gender + 197Áª¥_nationality = 199Áª¥„ÄÇ\u003c/li\u003e\n\u003cli\u003e‰æãÂ¶Ç \u003ccode\u003e(28, Â•≥, ‰∏≠ÂõΩ)\u003c/code\u003e ‚Üí \u003ccode\u003e[28, 0, 0, 1, 0, ‚Ä¶, 0]\u003c/code\u003e„ÄÇ\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003c/ol\u003e\n\u003ch2 id=\"‰∏âÊñáÊú¨Êï∞ÊçÆÂ§ÑÁêÜÊµÅÁ®ã\"\u003e‰∏â„ÄÅÊñáÊú¨Êï∞ÊçÆÂ§ÑÁêÜÊµÅÁ®ã\u003c/h2\u003e\n\u003cp\u003eÊñáÊú¨Âú®Ëá™ÁÑ∂ËØ≠Ë®ÄÂ§ÑÁêÜÔºàNLPÔºâ‰∏≠‰Ωú‰∏∫Â∏∏ËßÅÁöÑÂéüÂßãËæìÂÖ•ÔºåÈúÄË¶ÅÊï∞ÂÄºÂåñÊâçËÉΩÈÄÅÂÖ•Ê®°Âûã„ÄÇ‰∏ÄËà¨Ê≠•È™§Â¶Ç‰∏ãÔºö\u003c/p\u003e\n\u003col\u003e\n\u003cli\u003e\n\u003cp\u003e\u003cstrong\u003eÂàÜËØç (Tokenization)\u003c/strong\u003e\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eÂ∞ÜÊñáÊú¨ÊãÜÂàÜ‰∏∫‰∏Ä‰∏™‰∏™ÂçïËØçÔºàTokenÔºâ„ÄÇ\u003c/li\u003e\n\u003cli\u003e‰æãÂ≠êÔºö\u003ccode\u003e\u0026quot;... to be or not to be...\u0026quot;\u003c/code\u003e ‚Üí \u003ccode\u003e[\u0026quot;...\u0026quot;, \u0026quot;to\u0026quot;, \u0026quot;be\u0026quot;, \u0026quot;or\u0026quot;, \u0026quot;not\u0026quot;, \u0026quot;to\u0026quot;, \u0026quot;be\u0026quot;, \u0026quot;...\u0026quot;]\u003c/code\u003e„ÄÇ\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003e\u003cstrong\u003eÁªüËÆ°ËØçÈ¢ë \u0026amp; ÊûÑÂª∫ËØçÂÖ∏\u003c/strong\u003e\u003c/p\u003e","title":""},{"content":"Text to Sequence ÊñáÊú¨Â§ÑÁêÜ\nStep1: Tokenization\nTokenization breaks a piece of text down into a list of tokens.\nHere, a token is a word. (A token can be a character in some applications.)\nTokenizationËÆ≤Á©∂ÂæàÂ§öÔºå‰æãÂ¶ÇÊòØÂê¶Â∫îËØ•ÊääÂ§ßÂÜôÊîπÊàêÂ∞èÂÜôÂë¢ÔºüËøõË°åtypo correctionÁ≠âÁ≠â\nStep2: Build Dictionary\nUse a dictionary (hash table) to count word frequencies.\nThe dictionary maps word to index.\nÂèØ‰ª•È¶ñÂÖàÁªüËÆ°ËØçÈ¢ëÂéªÊéâ‰ΩéÈ¢ëËØçÔºåÁÑ∂ÂêéËÆ©ÊØè‰∏™ËØçÂØπÂ∫î‰∏Ä‰∏™Ê≠£Êï¥Êï∞ÔºõËøôÊ†∑ÁöÑËØùÔºå‰∏ÄÂè•ËØùÂ∞±ÂèØ‰ª•Áî®‰∏Ä‰∏™Ê≠£Êï¥Êï∞ÂàóË°®Ë°®Á§∫ÔºåËøô‰∏™ÂàóË°®Â∞±Âè´sequenceÔºõÂ¶ÇÊûúÂøÖË¶ÅÂ∞±ËøòÂæóÂÅöone-hot encoding„ÄÇ\nÁªìÊûú\n‰ΩÜÊòØÈïøÂ∫¶‰∏çÁªü‰∏Ä\nStep4: ÂØπÈΩêsequence\nËß£ÂÜ≥ÊñπÊ°àÊòØËøôÊ†∑ÁöÑÔºöÂèØ‰ª•Âõ∫ÂÆöÈïøÂ∫¶‰∏∫wÔºåÂä†ÂÖ•‰∏Ä‰∏™Â∫èÂàóÈïøÂ∫¶Â§™ÈïøÔºåÂ∞±Á†çÊéâÂâçÈù¢ÁöÑËØçÔºåÂè™‰øùÁïôÊúÄÂêéw‰∏™ËØçÔºõÂ¶ÇÊûú‰∏Ä‰∏™Â∫èÂàóÂ§™Áü≠ÔºåÂ∞±ÂÅözero paddingÔºåÁî®0Â°´ÂÖÖ\nËøôÊ†∑‰∏ÄÊù•ÔºåÊâÄÊúâÁöÑÂ∫èÂàóÈïøÂ∫¶Â∞±Áªü‰∏Ä‰∫Ü\nÊñáÊú¨Â§ÑÁêÜÂÆåÊàê‰∫ÜÔºåÊé•‰∏ãÊù•ÊòØword embeddingÔºåÊääÂçïËØçË°®Á§∫‰∏∫‰∏Ä‰∏™‰ΩéÁª¥ÂêëÈáèÔºõ\nÁÑ∂ËÄåËøôÊ†∑ÂÅöÁöÑËØùÔºåÂ¶ÇÊûúÊòØ10000‰∏™ÂçïËØçÔºåÁª¥Â∫¶Â∞±ÊòØ10000Áª¥ÔºåÁª¥Â∫¶Â§™È´ò‰∫ÜÔºõÂõ†Ê≠§Ë¶ÅÂÅöword embeddingÔºõ\nÂÖ∑‰ΩìÂÅöÊ≥ïÂ∞±ÊòØÊääone-hotÂêëÈáèe_iÂíåÂèÇÊï∞Áü©ÈòµpÁõ∏‰πòÔºõÁü©ÈòµPËΩ¨ÁΩÆÁöÑÂ§ßÂ∞èÊòØd x vÔºõdÊòØËØçÂêëÈáèÁöÑÁª¥Â∫¶ÔºõvÊòØÂ≠óÂÖ∏ÈáåËØçÊ±áÁöÑÊï∞ÈáèÔºõÁªìÊûú‰∏∫x_iÔºõx_iÂ∞±ÊòØ‰∏Ä‰∏™ËØçÂêëÈáèÔºõÂ¶ÇÊûúone-hotÂêëÈáèÁöÑÁ¨¨‰∏âË°å‰∏∫1ÔºõÈÇ£‰πàx_iÂ∞±ÊòØPËΩ¨ÁΩÆÁü©ÈòµÁöÑÁ¨¨‰∏âÂàóÔºàÂÖ∂‰ΩôÂàóÈÉΩ‰∏∫0ÔºâÔºõÊâÄ‰ª•PËΩ¨ÁΩÆÊØè‰∏ÄÂàóÈÉΩÊòØ‰∏Ä‰∏™ËØçÂêëÈáèÔºõÊâÄ‰ª•Áü©ÈòµPÊú¨Ë∫´ÁöÑÊØè‰∏ÄË°åÂ∞±ÊòØ‰∏Ä‰∏™ËØçÂêëÈáèÔºõÂÖ∂Ë°åÊï∞‰∏∫vÔºõÂç≥vocabularyÔºåËØçÊ±áÈáèÔºõÊØè‰∏ÄË°åÂØπÂ∫î‰∏Ä‰∏™ÂçïËØçÔºõÁü©ÈòµÁöÑÂàóÊï∞‰∏∫dÔºõdÊòØÁî®Êà∑ÂÜ≥ÂÆöÁöÑÔºõdÁöÑÂ§ßÂ∞è‰ºöÂÜ≥ÂÆöÊú∫Âô®Â≠¶‰π†Ê®°ÂûãÁöÑË°®Áé∞ÔºõÂ∫îËØ•Áî®xxxÊù•ÈÄâÊã©‰∏Ä‰∏™ÊØîËæÉÂ•ΩÁöÑdÔºõ\nÊàë‰ª¨ÁöÑ‰ªªÂä°ÊòØÁúãËØÑËÆ∫ÊòØÊ≠£Èù¢ÁöÑËøòÊòØË¥üÈù¢ÁöÑÔºõÂèÇÊï∞Áü©ÈòµÊòØ‰ªéËÆ≠ÁªÉÊï∞ÊçÆ‰∏≠Â≠¶‰π†Âá∫Êù•ÁöÑÔºåÊâÄ‰ª•Â≠¶Âá∫Êù•ÁöÑËØçÂêëÈáèÊòØÂ∏¶ÊúâÊÑüÊÉÖËâ≤ÂΩ©ÁöÑÔºõÂÅáËÆæËøô‰∫õËØçÂêëÈáèÈÉΩÊòØ‰∫åÁª¥ÁöÑÔºåÂàôÂèØ‰ª•Âú®Âπ≥Èù¢ÂùêÊ†áÁ≥ª‰∏≠Ê†áÂá∫‰∏ãÈù¢ËØçÂêëÈáè\nkerasÊèê‰æõembeddingÂ±ÇÔºõÁî®Êà∑ÂèØ‰ª•ÊåáÂÆövocabularyÂ§ßÂ∞èÂíådÁöÑÂ§ßÂ∞èÔºõ‰ª•ÂèäÊØè‰∏Ä‰∏™sequenceÁöÑÈïøÂ∫¶ÔºõdÊòØÊ†πÊçÆÁÆóÊ≥ïÈÄâÂá∫Êù•ÁöÑ Âà∞Ëøô‰∏ÄÊ≠•ÔºåÊàë‰ª¨Â∑≤ÁªèÂÆåÊàê‰∫ÜÊñáÊú¨Â§ÑÁêÜÂíåword embedding„ÄÇÊé•‰∏ãÊù•Â∞±ÊòØÁî®Logistic Regression for Binary ClassificationÂÅö‰∫åÂàÜÁ±ªÔºõ\n","permalink":"http://localhost:1313/posts/nlp-2/","summary":"\u003ch3 id=\"text-to-sequence\"\u003eText to Sequence\u003c/h3\u003e\n\u003cp\u003eÊñáÊú¨Â§ÑÁêÜ\u003c/p\u003e\n\u003cp\u003eStep1: Tokenization\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\n\u003cp\u003eTokenization breaks a piece of text down into a list of tokens.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003eHere, a token is a word. (A token can be a character in some applications.)\u003c/p\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003eTokenizationËÆ≤Á©∂ÂæàÂ§öÔºå‰æãÂ¶ÇÊòØÂê¶Â∫îËØ•ÊääÂ§ßÂÜôÊîπÊàêÂ∞èÂÜôÂë¢ÔºüËøõË°åtypo correctionÁ≠âÁ≠â\u003c/p\u003e\n\u003cp\u003e\u003cimg alt=\"image-20250322150322238\" loading=\"lazy\" src=\"./NLP-2.assets/image-20250322150322238.png\"\u003e\u003c/p\u003e\n\u003cp\u003eStep2: Build Dictionary\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\n\u003cp\u003eUse a dictionary (hash table) to count word frequencies.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003eThe dictionary maps word to index.\u003c/p\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003eÂèØ‰ª•È¶ñÂÖàÁªüËÆ°ËØçÈ¢ëÂéªÊéâ‰ΩéÈ¢ëËØçÔºåÁÑ∂ÂêéËÆ©ÊØè‰∏™ËØçÂØπÂ∫î‰∏Ä‰∏™Ê≠£Êï¥Êï∞ÔºõËøôÊ†∑ÁöÑËØùÔºå‰∏ÄÂè•ËØùÂ∞±ÂèØ‰ª•Áî®‰∏Ä‰∏™Ê≠£Êï¥Êï∞ÂàóË°®Ë°®Á§∫ÔºåËøô‰∏™ÂàóË°®Â∞±Âè´sequenceÔºõÂ¶ÇÊûúÂøÖË¶ÅÂ∞±ËøòÂæóÂÅöone-hot encoding„ÄÇ\u003cimg alt=\"image-20250322150620890\" loading=\"lazy\" src=\"./NLP-2.assets/image-20250322150620890.png\"\u003e\u003c/p\u003e\n\u003cp\u003eÁªìÊûú\u003c/p\u003e\n\u003cp\u003e\u003cimg alt=\"image-20250322150754528\" loading=\"lazy\" src=\"./NLP-2.assets/image-20250322150754528.png\"\u003e\u003c/p\u003e\n\u003cp\u003e‰ΩÜÊòØÈïøÂ∫¶‰∏çÁªü‰∏Ä\u003c/p\u003e\n\u003cp\u003eStep4: ÂØπÈΩêsequence\u003c/p\u003e\n\u003cp\u003e\u003cimg alt=\"image-20250322150854986\" loading=\"lazy\" src=\"./NLP-2.assets/image-20250322150854986.png\"\u003e\u003c/p\u003e\n\u003cp\u003eËß£ÂÜ≥ÊñπÊ°àÊòØËøôÊ†∑ÁöÑÔºöÂèØ‰ª•Âõ∫ÂÆöÈïøÂ∫¶‰∏∫wÔºåÂä†ÂÖ•‰∏Ä‰∏™Â∫èÂàóÈïøÂ∫¶Â§™ÈïøÔºåÂ∞±Á†çÊéâÂâçÈù¢ÁöÑËØçÔºåÂè™‰øùÁïôÊúÄÂêéw‰∏™ËØçÔºõÂ¶ÇÊûú‰∏Ä‰∏™Â∫èÂàóÂ§™Áü≠ÔºåÂ∞±ÂÅözero paddingÔºåÁî®0Â°´ÂÖÖ\u003c/p\u003e\n\u003cp\u003e\u003cimg alt=\"image-20250322151030119\" loading=\"lazy\" src=\"./NLP-2.assets/image-20250322151030119.png\"\u003e\u003c/p\u003e\n\u003cp\u003eËøôÊ†∑‰∏ÄÊù•ÔºåÊâÄÊúâÁöÑÂ∫èÂàóÈïøÂ∫¶Â∞±Áªü‰∏Ä‰∫Ü\u003c/p\u003e\n\u003cp\u003e\u003cimg alt=\"image-20250322151117125\" loading=\"lazy\" src=\"./NLP-2.assets/image-20250322151117125.png\"\u003e\u003c/p\u003e\n\u003cp\u003eÊñáÊú¨Â§ÑÁêÜÂÆåÊàê‰∫ÜÔºåÊé•‰∏ãÊù•ÊòØword embeddingÔºåÊääÂçïËØçË°®Á§∫‰∏∫‰∏Ä‰∏™‰ΩéÁª¥ÂêëÈáèÔºõ\u003c/p\u003e\n\u003cp\u003e\u003cimg alt=\"image-20250322151252837\" loading=\"lazy\" src=\"./NLP-2.assets/image-20250322151252837.png\"\u003e\u003c/p\u003e","title":""},{"content":"üëã About me Hello! I‚Äôm Xu Zongsi, a passionate technology enthusiast currently pursuing my Master of Science in Electronic Commerce \u0026amp; Internet Computing at The University of Hong Kong. With a solid background in Software Engineering from the Beijing Institute of Technology, I specialize in emerging areas of artificial intelligence, including machine learning, deep learning, natural language processing, computer vision, and reinforcement learning.\nHello! I‚Äôm Xu Zongsi, a passionate technology enthusiast currently pursuing my Master of Science in ECIC at The University of Hong Kong. With a solid background in Software Engineering from the Beijing Institute of Technology, I specialize in emerging areas of artificial intelligence, including machine learning, deep learning, natural language processing, computer vision, and reinforcement learning.\nI have a strong interest in developing LLM agents and knowledge graphs, leveraging data science techniques for innovative solutions. Additionally, I am skilled in software development, aiming to create impactful applications that enhance user experiences.\nThroughout my academic journey, I have been involved in several innovative projects focused on fraud detection, intelligent text processing, and quantum computing applications in deep learning. My programming skills span languages like Python and Java, with experience in frameworks such as PyTorch.\nWhen I‚Äôm not coding, you can find me exploring new technologies, sharing insights on my blog, or engaging in community activities related to cyber security.\nüìö Education üá≠üá∞ The University of Hong Kong 09/2024 - Expected 11/2025 School of Computing and Data Science Master of Science in Electronic Commerce \u0026amp; Internet Computing Relevant Courses: Machine learning for business and e-commerce, Knowledge graphs, Financial fraud analytics, Internet infrastructure technologies, Website engineering, Blockchain and cryptocurrency, etc. üá®üá≥ Beijing Institute of Technology 09/2020 - 06/2024 School of Computer Science \u0026amp; Technology Bachelor of Engineering in Software Engineering, last two years GPA: 3.7/4 Relevant Courses: Reinforcement Learning, Deep Learning and Computer Vision, Artificial Intelligence and Robot Ethics, Almost Human: Mind, Brain and Artificial Intelligence, Mathematical Analysis for Engineering, Linear Algebra, Probability and Mathematical Statistics, etc. Skills: Python, Java, common data structures, design patterns, machine learning basics and algorithms, Linux, PyTorch, and some development tools (git, conda, etc.). üèÜ Awards \u0026amp; Honors Beijing Institute of Technology Undergraduate Scholarship (Top 20% of Grade) 06/2023 3rd Prize of China International \u0026#34;Internet \u0026#43;\u0026#34; College Student\u0026#39;s Innovation Competition 08/2022 Bronze Prize of \u0026#34;Challenge Cup\u0026#34; Capital University Entrepreneurship Competition 05/2022 üíº Project Experience Online Transaction Fraud Detection 09/2024 ‚Äì 01/2025 Independent project, supervised by Dr. Vivien Chan Focused on addressing financial fraud in e-commerce to enhance the accuracy of transaction anomaly detection, while independently managing the entire case study that included data preprocessing, feature engineering, model building, evaluation, and results analysis. Effectively resolved class imbalance issues using SMOTE and ROSE techniques. Built various models including Logistic Regression, Random Forest, XGBoost, and LightGBM, ultimately selecting the LightGBM model to achieve a recall rate of 95.45% and an AUC of 99.84%. Wrote efficient and maintainable code, enhancing model training and data processing efficiency through parallel computing and logging. Multi-Model Intelligent Text Keyword Extraction System 08/2023 ‚Äì 09/2023 Group project, supervised by Associate Prof. Xiaolin Zhao Designed and implemented an intelligent text summary system that automatically extracts keywords from article titles and abstracts, enhancing the understanding and summarization of text information. Participated in the planning of the technical route and built a hybrid model combining extractive and generative approaches, utilizing advanced natural language processing techniques including KeyBERT, Sentence Transformer, BERT, and T5 models. Responsible for data preprocessing and tokenization, as well as the end-to-end implementation and training of the T5 model, optimizing the model architecture and hyperparameters, achieving satisfactory results after only 3 epochs of training. Model evaluation results showed that the Rouge-1, Rouge-2, and Rouge-L metrics reached 0.6345, 0.5038, and 0.5282, respectively, in the third epoch, validating the model\u0026rsquo;s effectiveness in the summarization task. Cambridge University Machine Learning Summer Project 07/2023 ‚Äì 08/2023 Group project, supervised by Prof. Pietro Li√≤ Participated in the Cambridge University deep learning summer project, focusing on deep reinforcement learning; explored multi-agent learning algorithms across different environments. Reproduced the Multi-Agent Deep Deterministic Policy Gradient (MADDPG) algorithm in the Simple Adversary environment and studied the effect of agent numbers on convergence speed and stability, finding optimal stability at 21 agents. Designed and implemented comparative experiments inspired by the Rainbow algorithm, assessing target network strategies versus the Double Deep Q-Network (Double DQN). The results demonstrated that Double DQN significantly enhanced convergence speed, optimizing the overall learning process. Co-authored a group project paper on agent numbers and strategies effectiveness in multi-agent systems, achieving a score of 71% in the summer program (the highest in my group) and a \u0026ldquo;First Class\u0026rdquo; classification in the UK grading system. Deep Learning and Computer Vision Semester Project 09/2022 ‚Äì 12/2022 Independent project, supervised by Associate Prof. Guangyu Gao Designed and implemented a waste classifier using the ResNet model to improve classification accuracy and reduce resource waste. The project also enhanced understanding of transfer learning techniques with ResNet. Collected a dataset of 16 waste categories and preprocessed the images for uniformity and standardization, incorporating data augmentation techniques to enhance the dataset. Conducted experiments using ResNet34 and ResNet50 models through transfer learning, accelerating network convergence by leveraging pretrained weights. During training, techniques such as Batch Normalization and Dropout were applied to mitigate the risk of overfitting. The final model achieved an accuracy of 90% on the training set, while the performance on the test set was 61%, indicating a significant overfitting phenomenon during the training process. üéì Internship Beijing Academy of Quantum Information Science 08/2023 ‚Äì 01/2024 Research Intern at Quantum Computation Department Proposed a quantum convolution kernel design based on variational quantum circuits and developed a universal quantum convolution layer, successfully integrating it into classical CNN architectures such as VGG, GoogLeNet, and ResNet. Developed and evaluated various hybrid models, including a simple model named HQCCNN-2, which achieved 84.45% accuracy on the FashionMNIST dataset, surpassing the traditional CNN\u0026rsquo;s 80.72%. This demonstrates the effectiveness of the quantum convolution layer in improving model performance. Tested on a real quantum computer further validated the effectiveness of the hybrid model, demonstrating the viable integration of quantum computing with deep learning, and highlighting the potential for leveraging quantum properties to enhance model performance. üèÖ Competition Experience China International \u0026#34;Internet \u0026#43;\u0026#34; College Students\u0026#39; Innovation Competition 08/2022 Zhongke Ushield: Deep Learning-based Face Privacy Protection Authentication System Responsible for constructing a localized facial feature extraction engine based on MobileFaceNet, ensuring feature extraction is completed on end devices (such as mobile phones and cameras), guaranteeing that raw data does not leave the domain and is not stored, thus enhancing user privacy protection while improving recognition efficiency. \u0026#34;Challenge Cup\u0026#34; Capital University Entrepreneurship Competition 05/2022 Smart Orchard Responsible for the development of the fruit detection, ripeness prediction, and pest identification system, using deep convolutional neural network (CNN) technology for intelligent monitoring of crop growth conditions. Applied advanced object detection algorithms such as Faster R-CNN and YOLO to achieve high precision in apple detection and ripeness assessment, with an accuracy rate exceeding 90%, significantly enhancing the intelligence level of orchard management. Built and trained a dedicated dataset containing various pest samples, optimizing pest detection accuracy through data preprocessing (such as image normalization and resizing) and data augmentation techniques (like rotation, flipping, and noise addition), enabling the real-time monitoring system to accurately identify over 80% of pests, providing effective scientific maintenance recommendations to help farmers reduce crop losses. üìã Extracurricular Activities Vice President, Cyber Security Club, Beijing Institute of Technology 09/2021-09/2022 Backbone, Media Center of the Student Union of Beijing Institute of Technology 10/2020-06/2021 üì´ Contact üìß zongsi.xu@outlook.com üëî Zongsi (Tristan) Xu üíª github.com/BaizeXS üìç Hong Kong SAR, China ","permalink":"http://localhost:1313/resume/","summary":"Personal resume of Zongsi (Tristan) Xu","title":"Zongsi (Tristan) Xu"},{"content":"‰∏Ä„ÄÅÊï∞ÂÄºÁâπÂæÅ‰∏éÁ±ªÂà´ÁâπÂæÅ Êï∞ÂÄºÁâπÂæÅ (Numeric Features) ÂÖ∑ÊúâÂèØÂä†ÂáèÁöÑÊÑè‰πâÔºå‰∏îÂ≠òÂú®Â§ßÂ∞èÈ°∫Â∫è„ÄÇ ‰æãÂ≠êÔºöÂπ¥ÈæÑ„ÄÅÊ∏©Â∫¶Á≠â„ÄÇÂèØ‰ª•Áõ¥Êé•‰øùÁïôÂÖ∂Êï¥Êï∞ÊàñÊµÆÁÇπÊï∞ÂΩ¢Âºè‰æõÊ®°Âûã‰ΩøÁî®„ÄÇ Á±ªÂà´ÁâπÂæÅ (Categorical Features) Êï∞ÊçÆÂÄºÁ¶ªÊï£Ôºå‰∏çÂÖ∑Â§á‚ÄúÊï∞ÂÄºÂ§ßÂ∞è‚ÄùÈó¥ÁöÑÂèØÊØîÊÑè‰πâ„ÄÇ ‰æãÂ≠êÔºöÂõΩÁ±çÔºàÁæéÂõΩ/‰∏≠ÂõΩ/Âç∞Â∫¶Á≠âÔºâ„ÄÅÊÄßÂà´ÔºàÁî∑/Â•≥ÔºâÁ≠â„ÄÇ ÈóÆÈ¢òÔºöËã•‰ªÖÁî®Êï¥Êï∞Ë°®Á§∫ÔºàÁæéÂõΩ=1, ‰∏≠ÂõΩ=2ÔºâÔºå‰ºöÂºïÂÖ•ÈîôËØØÁöÑÊï∞ÂÄºËøêÁÆóÂÖ≥Á≥ªÔºåÂ¶Ç ‚ÄúÁæéÂõΩ + ‰∏≠ÂõΩ = Âç∞Â∫¶‚Äù„ÄÇ ‰∫å„ÄÅOne-HotÁºñÁ†ÅÁöÑÂä®Êú∫‰∏éÊµÅÁ®ã ‰∏∫‰ªÄ‰πà‰ΩøÁî®One-Hot\nÈÄöËøáÂ∞ÜÁ±ªÂà´Êò†Â∞Ñ‰∏∫ÂêëÈáèÔºåÈÅøÂÖçÊï¥Êï∞ÁºñÁ†ÅÂºïÂÖ•ÁöÑ‰º™Êï∞ÂÄºÂÖ≥Á≥ª„ÄÇ ÂêåÊó∂‰øùÁïôÂêÑÁßçÂèØËÉΩÁ±ªÂà´ÁöÑ‰ø°ÊÅØÔºå‰∏î‰ªÖÂú®ÂØπÂ∫î‰ΩçÁΩÆ‰∏∫1ÔºåÂÖ∂‰ªñ‰ΩçÁΩÆ‰∏∫0„ÄÇ Âª∫Á´ãÊò†Â∞ÑÔºö‰ªéÁ±ªÂà´Âà∞Á¥¢Âºï\n‰∏∫ÊØè‰∏™Á±ªÂà´ÂàÜÈÖç‰∏Ä‰∏™ÂîØ‰∏ÄÁ¥¢ÂºïÔºåÈÄöÂ∏∏‰ªé1ÂºÄÂßã„ÄÇ È¢ÑÁïôÁ¥¢Âºï0Ë°®Á§∫‚ÄúÊú™Áü•‚ÄùÊàñ‚ÄúÁº∫Â§±‚ÄùÔºåÂØπÂ∫îÂÖ®0ÂêëÈáè„ÄÇ ËΩ¨Êç¢‰∏∫One-HotÂêëÈáè\nËã•Á±ªÂà´ÊÄªÊï∞‰∏∫197ÔºåÂàôÁî®197Áª¥ÂêëÈáèË°®Á§∫„ÄÇ ‰æãÂ≠êÔºöÁæéÂõΩ [1, 0, 0, 0, ‚Ä¶]Ôºå ‰∏≠ÂõΩ [0, 1, 0, 0, ‚Ä¶]„ÄÇ Á§∫‰æãÔºöË°®Á§∫‰∏Ä‰∏™‰∫∫ÁöÑÁâπÂæÅ\nÁâπÂæÅÂåÖÂê´ÔºàÂπ¥ÈæÑ, ÊÄßÂà´, ÂõΩÁ±çÔºåÂÖ∂‰∏≠ÂõΩÁ±ç197ÁßçÔºâ Áª¥Â∫¶ÊÄªÂíåÔºö1Áª¥_age + 1Áª¥_gender + 197Áª¥_nationality = 199Áª¥„ÄÇ ‰æãÂ¶Ç (28, Â•≥, ‰∏≠ÂõΩ) ‚Üí [28, 0, 0, 1, 0, ‚Ä¶, 0]„ÄÇ ‰∏â„ÄÅÊñáÊú¨Êï∞ÊçÆÂ§ÑÁêÜÊµÅÁ®ã ÊñáÊú¨Âú®Ëá™ÁÑ∂ËØ≠Ë®ÄÂ§ÑÁêÜÔºàNLPÔºâ‰∏≠‰Ωú‰∏∫Â∏∏ËßÅÁöÑÂéüÂßãËæìÂÖ•ÔºåÈúÄË¶ÅÊï∞ÂÄºÂåñÊâçËÉΩÈÄÅÂÖ•Ê®°Âûã„ÄÇ‰∏ÄËà¨Ê≠•È™§Â¶Ç‰∏ãÔºö\nÂàÜËØç (Tokenization)\nÂ∞ÜÊñáÊú¨ÊãÜÂàÜ‰∏∫‰∏Ä‰∏™‰∏™ÂçïËØçÔºàTokenÔºâ„ÄÇ ‰æãÂ≠êÔºö\u0026quot;... to be or not to be...\u0026quot; ‚Üí [\u0026quot;...\u0026quot;, \u0026quot;to\u0026quot;, \u0026quot;be\u0026quot;, \u0026quot;or\u0026quot;, \u0026quot;not\u0026quot;, \u0026quot;to\u0026quot;, \u0026quot;be\u0026quot;, \u0026quot;...\u0026quot;]„ÄÇ ÁªüËÆ°ËØçÈ¢ë \u0026amp; ÊûÑÂª∫ËØçÂÖ∏\nËØçÈ¢ëÁªüËÆ° Áî®ÂìàÂ∏åË°®/Â≠óÂÖ∏ËÆ∞ÂΩïÊØè‰∏™ÂçïËØçÂá∫Áé∞Ê¨°Êï∞„ÄÇ ÈÅçÂéÜÊñáÊú¨Êó∂ÔºåËã•ÂçïËØçÂ∞öÊú™ÂÖ•Ë°®ÔºåÂàôÊñ∞Âª∫ËÆ∞ÂΩïÔºõËã•Â∑≤Â≠òÂú®ÔºåÂàôËÆ°Êï∞+1„ÄÇ ÊéíÂ∫è‰∏éÁ¥¢Âºï ÊåâËØçÈ¢ëÈôçÂ∫èÊéíÂ∫èÔºåËØçÈ¢ëÊúÄÈ´òÁöÑÂçïËØçÊéíÂú®ÂâçÈù¢„ÄÇ Á¥¢Âºï‰ªé1ÂºÄÂßãÔºå0ÁïôÁªô‚ÄúÊú™Áü•‚Äù„ÄÇ ËØçÂÖ∏ËßÑÊ®°ÔºàvocabularyÔºâÂèØËßÜÈúÄÊ±ÇÊà™Êñ≠Ôºà‰æãÂ¶ÇÂè™‰øùÁïôTop 10kÔºâ„ÄÇ ‰∏∫‰ªÄ‰πàÁßªÈô§‰ΩéÈ¢ëËØç ‰ΩéÈ¢ëËØçÂèØËÉΩÊòØÊãºÂÜôÈîôËØØ„ÄÅÁΩïËßÅ‰∫∫ÂêçÁ≠âÔºåÂØπÊ®°ÂûãÂ∏ÆÂä©ÊúâÈôê„ÄÇ ÂáèÂ∞ëËØçÂÖ∏ËßÑÊ®°ÂèØÈôç‰ΩéËøêÁÆóÂºÄÈîÄ„ÄÅÂä†Âø´Ê®°ÂûãËÆ≠ÁªÉ‰∏éÊé®ÁêÜÈÄüÂ∫¶„ÄÇ Áã¨ÁÉ≠ÁºñÁ†Å (One-Hot Encoding)\nÂ∞ÜÊØè‰∏™ÂçïËØçÊò†Â∞Ñ‰∏∫ËØçÂÖ∏‰∏≠ÁöÑÁ¥¢ÂºïÂêéÔºàÂ¶Ç [2, 4, 1, 8, ‚Ä¶]ÔºâÔºåÂèØËøõ‰∏ÄÊ≠•ËΩ¨Êç¢ÊàêOne-HotÂêëÈáè„ÄÇ One-HotÁª¥Â∫¶ÂèñÂÜ≥‰∫é‰øùÁïô‰∏ãÊù•ÁöÑËØçÂÖ∏Â§ßÂ∞èÔºà‰æãÂ¶Ç1‰∏áÔºâ„ÄÇ Êú™Êî∂ÂΩïÂçïËØçÂèØËÉΩÁõ¥Êé•ÂøΩÁï•ÔºåÊàñÁªü‰∏ÄÁî®Á¥¢Âºï0‰ª£Êõø„ÄÇ Âõõ„ÄÅÊ†∏ÂøÉÊî∂Ëé∑‰∏éÂ∫îÁî® Á±ªÂà´ÁâπÂæÅÂøÖÈúÄÊï∞ÂÄºÂåñÔºö\n‰ΩøÁî®Êï¥Êï∞1,2,3‚Ä¶‰ªÖË°®Á§∫Á±ªÂà´‚ÄúÊ†áËØÜ‚ÄùÔºåÂπ∂‰∏ç‰ª£Ë°®ÂÆÉ‰ª¨ÂèØËøõË°åÊï∞ÂÄºËøêÁÆó„ÄÇ Âõ†Ê≠§ÈúÄË¶ÅOne-HotÁ≠âÁºñÁ†ÅÊñπÂºèÔºåÈÅøÂÖçÊï∞ÂÄºËØØËß£„ÄÇ ÊñáÊú¨Êï∞ÊçÆÈ¢ÑÂ§ÑÁêÜÔºö\nÂàÜËØç„ÄÅËØçÈ¢ëÁªüËÆ°„ÄÅÊûÑÂª∫ËØçÂÖ∏„ÄÅÁ¥¢ÂºïÂåñ„ÄÅOne-HotÊàñÂÖ∂‰ªñÊñπÂºèÔºàÂ¶ÇËØçÂµåÂÖ•ÔºâÊòØÂ∏∏ËßÅÊµÅÁ®ã„ÄÇ Ê≠£Á°ÆÁöÑÊñáÊú¨È¢ÑÂ§ÑÁêÜÂèØÊòæËëóÂΩ±ÂìçÊ®°ÂûãÊÄßËÉΩÂíåÊïàÁéá„ÄÇ ‰øùÁïôÊú™Áü•Á¥¢ÂºïÔºö\n‰øùËØÅÂØπÁº∫Â§±Êï∞ÊçÆÊàñÂ≠óÂÖ∏Â§ñÊñ∞ËØçËÉΩÊúâÂü∫Êú¨ÁöÑË°®Á§∫ÔºåÊèêÂçáÊ®°ÂûãÂÆπÈîôÊÄß„ÄÇ ÂÆûÈôÖ‰ΩøÁî®Ôºö\nÂØπ‰∫éÂ∞èËßÑÊ®°Á±ªÂà´ÂèØÁõ¥Êé•One-HotÁºñÁ†ÅÔºõÂØπ‰∫éËØçÂÖ∏ÂæàÂ§ßÁöÑÂú∫ÊôØÔºåÈÄöÂ∏∏‰ºöËøõ‰∏ÄÊ≠•ËÄÉËôëËØçÂµåÂÖ•ÔºàWord EmbeddingÔºâÊàñÈ¢ÑËÆ≠ÁªÉËØ≠Ë®ÄÊ®°Âûã„ÄÇ ","permalink":"http://localhost:1313/posts/nlp-1/","summary":"\u003ch2 id=\"‰∏ÄÊï∞ÂÄºÁâπÂæÅ‰∏éÁ±ªÂà´ÁâπÂæÅ\"\u003e‰∏Ä„ÄÅÊï∞ÂÄºÁâπÂæÅ‰∏éÁ±ªÂà´ÁâπÂæÅ\u003c/h2\u003e\n\u003col\u003e\n\u003cli\u003e\u003cstrong\u003eÊï∞ÂÄºÁâπÂæÅ (Numeric Features)\u003c/strong\u003e\n\u003cul\u003e\n\u003cli\u003eÂÖ∑ÊúâÂèØÂä†ÂáèÁöÑÊÑè‰πâÔºå‰∏îÂ≠òÂú®Â§ßÂ∞èÈ°∫Â∫è„ÄÇ\u003c/li\u003e\n\u003cli\u003e‰æãÂ≠êÔºöÂπ¥ÈæÑ„ÄÅÊ∏©Â∫¶Á≠â„ÄÇÂèØ‰ª•Áõ¥Êé•‰øùÁïôÂÖ∂Êï¥Êï∞ÊàñÊµÆÁÇπÊï∞ÂΩ¢Âºè‰æõÊ®°Âûã‰ΩøÁî®„ÄÇ\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003eÁ±ªÂà´ÁâπÂæÅ (Categorical Features)\u003c/strong\u003e\n\u003cul\u003e\n\u003cli\u003eÊï∞ÊçÆÂÄºÁ¶ªÊï£Ôºå‰∏çÂÖ∑Â§á‚ÄúÊï∞ÂÄºÂ§ßÂ∞è‚ÄùÈó¥ÁöÑÂèØÊØîÊÑè‰πâ„ÄÇ\u003c/li\u003e\n\u003cli\u003e‰æãÂ≠êÔºöÂõΩÁ±çÔºàÁæéÂõΩ/‰∏≠ÂõΩ/Âç∞Â∫¶Á≠âÔºâ„ÄÅÊÄßÂà´ÔºàÁî∑/Â•≥ÔºâÁ≠â„ÄÇ\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003eÈóÆÈ¢ò\u003c/strong\u003eÔºöËã•‰ªÖÁî®Êï¥Êï∞Ë°®Á§∫ÔºàÁæéÂõΩ=1, ‰∏≠ÂõΩ=2ÔºâÔºå‰ºöÂºïÂÖ•ÈîôËØØÁöÑÊï∞ÂÄºËøêÁÆóÂÖ≥Á≥ªÔºåÂ¶Ç ‚ÄúÁæéÂõΩ + ‰∏≠ÂõΩ = Âç∞Â∫¶‚Äù„ÄÇ\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003c/ol\u003e\n\u003ch2 id=\"‰∫åone-hotÁºñÁ†ÅÁöÑÂä®Êú∫‰∏éÊµÅÁ®ã\"\u003e‰∫å„ÄÅOne-HotÁºñÁ†ÅÁöÑÂä®Êú∫‰∏éÊµÅÁ®ã\u003c/h2\u003e\n\u003col\u003e\n\u003cli\u003e\n\u003cp\u003e\u003cstrong\u003e‰∏∫‰ªÄ‰πà‰ΩøÁî®One-Hot\u003c/strong\u003e\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eÈÄöËøáÂ∞ÜÁ±ªÂà´Êò†Â∞Ñ‰∏∫ÂêëÈáèÔºåÈÅøÂÖçÊï¥Êï∞ÁºñÁ†ÅÂºïÂÖ•ÁöÑ‰º™Êï∞ÂÄºÂÖ≥Á≥ª„ÄÇ\u003c/li\u003e\n\u003cli\u003eÂêåÊó∂‰øùÁïôÂêÑÁßçÂèØËÉΩÁ±ªÂà´ÁöÑ‰ø°ÊÅØÔºå‰∏î‰ªÖÂú®ÂØπÂ∫î‰ΩçÁΩÆ‰∏∫1ÔºåÂÖ∂‰ªñ‰ΩçÁΩÆ‰∏∫0„ÄÇ\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003e\u003cstrong\u003eÂª∫Á´ãÊò†Â∞ÑÔºö‰ªéÁ±ªÂà´Âà∞Á¥¢Âºï\u003c/strong\u003e\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e‰∏∫ÊØè‰∏™Á±ªÂà´ÂàÜÈÖç‰∏Ä‰∏™ÂîØ‰∏ÄÁ¥¢ÂºïÔºåÈÄöÂ∏∏‰ªé1ÂºÄÂßã„ÄÇ\u003c/li\u003e\n\u003cli\u003eÈ¢ÑÁïôÁ¥¢Âºï0Ë°®Á§∫‚ÄúÊú™Áü•‚ÄùÊàñ‚ÄúÁº∫Â§±‚ÄùÔºåÂØπÂ∫îÂÖ®0ÂêëÈáè„ÄÇ\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003e\u003cstrong\u003eËΩ¨Êç¢‰∏∫One-HotÂêëÈáè\u003c/strong\u003e\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eËã•Á±ªÂà´ÊÄªÊï∞‰∏∫197ÔºåÂàôÁî®197Áª¥ÂêëÈáèË°®Á§∫„ÄÇ\u003c/li\u003e\n\u003cli\u003e‰æãÂ≠êÔºöÁæéÂõΩ \u003ccode\u003e[1, 0, 0, 0, ‚Ä¶]\u003c/code\u003eÔºå ‰∏≠ÂõΩ \u003ccode\u003e[0, 1, 0, 0, ‚Ä¶]\u003c/code\u003e„ÄÇ\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003e\u003cstrong\u003eÁ§∫‰æãÔºöË°®Á§∫‰∏Ä‰∏™‰∫∫ÁöÑÁâπÂæÅ\u003c/strong\u003e\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eÁâπÂæÅÂåÖÂê´ÔºàÂπ¥ÈæÑ, ÊÄßÂà´, ÂõΩÁ±çÔºåÂÖ∂‰∏≠ÂõΩÁ±ç197ÁßçÔºâ\u003c/li\u003e\n\u003cli\u003eÁª¥Â∫¶ÊÄªÂíåÔºö1Áª¥_age + 1Áª¥_gender + 197Áª¥_nationality = 199Áª¥„ÄÇ\u003c/li\u003e\n\u003cli\u003e‰æãÂ¶Ç \u003ccode\u003e(28, Â•≥, ‰∏≠ÂõΩ)\u003c/code\u003e ‚Üí \u003ccode\u003e[28, 0, 0, 1, 0, ‚Ä¶, 0]\u003c/code\u003e„ÄÇ\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003c/ol\u003e\n\u003ch2 id=\"‰∏âÊñáÊú¨Êï∞ÊçÆÂ§ÑÁêÜÊµÅÁ®ã\"\u003e‰∏â„ÄÅÊñáÊú¨Êï∞ÊçÆÂ§ÑÁêÜÊµÅÁ®ã\u003c/h2\u003e\n\u003cp\u003eÊñáÊú¨Âú®Ëá™ÁÑ∂ËØ≠Ë®ÄÂ§ÑÁêÜÔºàNLPÔºâ‰∏≠‰Ωú‰∏∫Â∏∏ËßÅÁöÑÂéüÂßãËæìÂÖ•ÔºåÈúÄË¶ÅÊï∞ÂÄºÂåñÊâçËÉΩÈÄÅÂÖ•Ê®°Âûã„ÄÇ‰∏ÄËà¨Ê≠•È™§Â¶Ç‰∏ãÔºö\u003c/p\u003e\n\u003col\u003e\n\u003cli\u003e\n\u003cp\u003e\u003cstrong\u003eÂàÜËØç (Tokenization)\u003c/strong\u003e\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eÂ∞ÜÊñáÊú¨ÊãÜÂàÜ‰∏∫‰∏Ä‰∏™‰∏™ÂçïËØçÔºàTokenÔºâ„ÄÇ\u003c/li\u003e\n\u003cli\u003e‰æãÂ≠êÔºö\u003ccode\u003e\u0026quot;... to be or not to be...\u0026quot;\u003c/code\u003e ‚Üí \u003ccode\u003e[\u0026quot;...\u0026quot;, \u0026quot;to\u0026quot;, \u0026quot;be\u0026quot;, \u0026quot;or\u0026quot;, \u0026quot;not\u0026quot;, \u0026quot;to\u0026quot;, \u0026quot;be\u0026quot;, \u0026quot;...\u0026quot;]\u003c/code\u003e„ÄÇ\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003e\u003cstrong\u003eÁªüËÆ°ËØçÈ¢ë \u0026amp; ÊûÑÂª∫ËØçÂÖ∏\u003c/strong\u003e\u003c/p\u003e","title":""},{"content":"Text to Sequence ÊñáÊú¨Â§ÑÁêÜ\nStep1: Tokenization\nTokenization breaks a piece of text down into a list of tokens.\nHere, a token is a word. (A token can be a character in some applications.)\nTokenizationËÆ≤Á©∂ÂæàÂ§öÔºå‰æãÂ¶ÇÊòØÂê¶Â∫îËØ•ÊääÂ§ßÂÜôÊîπÊàêÂ∞èÂÜôÂë¢ÔºüËøõË°åtypo correctionÁ≠âÁ≠â\nStep2: Build Dictionary\nUse a dictionary (hash table) to count word frequencies.\nThe dictionary maps word to index.\nÂèØ‰ª•È¶ñÂÖàÁªüËÆ°ËØçÈ¢ëÂéªÊéâ‰ΩéÈ¢ëËØçÔºåÁÑ∂ÂêéËÆ©ÊØè‰∏™ËØçÂØπÂ∫î‰∏Ä‰∏™Ê≠£Êï¥Êï∞ÔºõËøôÊ†∑ÁöÑËØùÔºå‰∏ÄÂè•ËØùÂ∞±ÂèØ‰ª•Áî®‰∏Ä‰∏™Ê≠£Êï¥Êï∞ÂàóË°®Ë°®Á§∫ÔºåËøô‰∏™ÂàóË°®Â∞±Âè´sequenceÔºõÂ¶ÇÊûúÂøÖË¶ÅÂ∞±ËøòÂæóÂÅöone-hot encoding„ÄÇ\nÁªìÊûú\n‰ΩÜÊòØÈïøÂ∫¶‰∏çÁªü‰∏Ä\nStep4: ÂØπÈΩêsequence\nËß£ÂÜ≥ÊñπÊ°àÊòØËøôÊ†∑ÁöÑÔºöÂèØ‰ª•Âõ∫ÂÆöÈïøÂ∫¶‰∏∫wÔºåÂä†ÂÖ•‰∏Ä‰∏™Â∫èÂàóÈïøÂ∫¶Â§™ÈïøÔºåÂ∞±Á†çÊéâÂâçÈù¢ÁöÑËØçÔºåÂè™‰øùÁïôÊúÄÂêéw‰∏™ËØçÔºõÂ¶ÇÊûú‰∏Ä‰∏™Â∫èÂàóÂ§™Áü≠ÔºåÂ∞±ÂÅözero paddingÔºåÁî®0Â°´ÂÖÖ\nËøôÊ†∑‰∏ÄÊù•ÔºåÊâÄÊúâÁöÑÂ∫èÂàóÈïøÂ∫¶Â∞±Áªü‰∏Ä‰∫Ü\nÊñáÊú¨Â§ÑÁêÜÂÆåÊàê‰∫ÜÔºåÊé•‰∏ãÊù•ÊòØword embeddingÔºåÊääÂçïËØçË°®Á§∫‰∏∫‰∏Ä‰∏™‰ΩéÁª¥ÂêëÈáèÔºõ\nÁÑ∂ËÄåËøôÊ†∑ÂÅöÁöÑËØùÔºåÂ¶ÇÊûúÊòØ10000‰∏™ÂçïËØçÔºåÁª¥Â∫¶Â∞±ÊòØ10000Áª¥ÔºåÁª¥Â∫¶Â§™È´ò‰∫ÜÔºõÂõ†Ê≠§Ë¶ÅÂÅöword embeddingÔºõ\nÂÖ∑‰ΩìÂÅöÊ≥ïÂ∞±ÊòØÊääone-hotÂêëÈáèe_iÂíåÂèÇÊï∞Áü©ÈòµpÁõ∏‰πòÔºõÁü©ÈòµPËΩ¨ÁΩÆÁöÑÂ§ßÂ∞èÊòØd x vÔºõdÊòØËØçÂêëÈáèÁöÑÁª¥Â∫¶ÔºõvÊòØÂ≠óÂÖ∏ÈáåËØçÊ±áÁöÑÊï∞ÈáèÔºõÁªìÊûú‰∏∫x_iÔºõx_iÂ∞±ÊòØ‰∏Ä‰∏™ËØçÂêëÈáèÔºõÂ¶ÇÊûúone-hotÂêëÈáèÁöÑÁ¨¨‰∏âË°å‰∏∫1ÔºõÈÇ£‰πàx_iÂ∞±ÊòØPËΩ¨ÁΩÆÁü©ÈòµÁöÑÁ¨¨‰∏âÂàóÔºàÂÖ∂‰ΩôÂàóÈÉΩ‰∏∫0ÔºâÔºõÊâÄ‰ª•PËΩ¨ÁΩÆÊØè‰∏ÄÂàóÈÉΩÊòØ‰∏Ä‰∏™ËØçÂêëÈáèÔºõÊâÄ‰ª•Áü©ÈòµPÊú¨Ë∫´ÁöÑÊØè‰∏ÄË°åÂ∞±ÊòØ‰∏Ä‰∏™ËØçÂêëÈáèÔºõÂÖ∂Ë°åÊï∞‰∏∫vÔºõÂç≥vocabularyÔºåËØçÊ±áÈáèÔºõÊØè‰∏ÄË°åÂØπÂ∫î‰∏Ä‰∏™ÂçïËØçÔºõÁü©ÈòµÁöÑÂàóÊï∞‰∏∫dÔºõdÊòØÁî®Êà∑ÂÜ≥ÂÆöÁöÑÔºõdÁöÑÂ§ßÂ∞è‰ºöÂÜ≥ÂÆöÊú∫Âô®Â≠¶‰π†Ê®°ÂûãÁöÑË°®Áé∞ÔºõÂ∫îËØ•Áî®xxxÊù•ÈÄâÊã©‰∏Ä‰∏™ÊØîËæÉÂ•ΩÁöÑdÔºõ\nÊàë‰ª¨ÁöÑ‰ªªÂä°ÊòØÁúãËØÑËÆ∫ÊòØÊ≠£Èù¢ÁöÑËøòÊòØË¥üÈù¢ÁöÑÔºõÂèÇÊï∞Áü©ÈòµÊòØ‰ªéËÆ≠ÁªÉÊï∞ÊçÆ‰∏≠Â≠¶‰π†Âá∫Êù•ÁöÑÔºåÊâÄ‰ª•Â≠¶Âá∫Êù•ÁöÑËØçÂêëÈáèÊòØÂ∏¶ÊúâÊÑüÊÉÖËâ≤ÂΩ©ÁöÑÔºõÂÅáËÆæËøô‰∫õËØçÂêëÈáèÈÉΩÊòØ‰∫åÁª¥ÁöÑÔºåÂàôÂèØ‰ª•Âú®Âπ≥Èù¢ÂùêÊ†áÁ≥ª‰∏≠Ê†áÂá∫‰∏ãÈù¢ËØçÂêëÈáè\nkerasÊèê‰æõembeddingÂ±ÇÔºõÁî®Êà∑ÂèØ‰ª•ÊåáÂÆövocabularyÂ§ßÂ∞èÂíådÁöÑÂ§ßÂ∞èÔºõ‰ª•ÂèäÊØè‰∏Ä‰∏™sequenceÁöÑÈïøÂ∫¶ÔºõdÊòØÊ†πÊçÆÁÆóÊ≥ïÈÄâÂá∫Êù•ÁöÑ Âà∞Ëøô‰∏ÄÊ≠•ÔºåÊàë‰ª¨Â∑≤ÁªèÂÆåÊàê‰∫ÜÊñáÊú¨Â§ÑÁêÜÂíåword embedding„ÄÇÊé•‰∏ãÊù•Â∞±ÊòØÁî®Logistic Regression for Binary ClassificationÂÅö‰∫åÂàÜÁ±ªÔºõ\n","permalink":"http://localhost:1313/posts/nlp-2/","summary":"\u003ch3 id=\"text-to-sequence\"\u003eText to Sequence\u003c/h3\u003e\n\u003cp\u003eÊñáÊú¨Â§ÑÁêÜ\u003c/p\u003e\n\u003cp\u003eStep1: Tokenization\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\n\u003cp\u003eTokenization breaks a piece of text down into a list of tokens.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003eHere, a token is a word. (A token can be a character in some applications.)\u003c/p\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003eTokenizationËÆ≤Á©∂ÂæàÂ§öÔºå‰æãÂ¶ÇÊòØÂê¶Â∫îËØ•ÊääÂ§ßÂÜôÊîπÊàêÂ∞èÂÜôÂë¢ÔºüËøõË°åtypo correctionÁ≠âÁ≠â\u003c/p\u003e\n\u003cp\u003e\u003cimg alt=\"image-20250322150322238\" loading=\"lazy\" src=\"./NLP-2.assets/image-20250322150322238.png\"\u003e\u003c/p\u003e\n\u003cp\u003eStep2: Build Dictionary\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\n\u003cp\u003eUse a dictionary (hash table) to count word frequencies.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003eThe dictionary maps word to index.\u003c/p\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003eÂèØ‰ª•È¶ñÂÖàÁªüËÆ°ËØçÈ¢ëÂéªÊéâ‰ΩéÈ¢ëËØçÔºåÁÑ∂ÂêéËÆ©ÊØè‰∏™ËØçÂØπÂ∫î‰∏Ä‰∏™Ê≠£Êï¥Êï∞ÔºõËøôÊ†∑ÁöÑËØùÔºå‰∏ÄÂè•ËØùÂ∞±ÂèØ‰ª•Áî®‰∏Ä‰∏™Ê≠£Êï¥Êï∞ÂàóË°®Ë°®Á§∫ÔºåËøô‰∏™ÂàóË°®Â∞±Âè´sequenceÔºõÂ¶ÇÊûúÂøÖË¶ÅÂ∞±ËøòÂæóÂÅöone-hot encoding„ÄÇ\u003cimg alt=\"image-20250322150620890\" loading=\"lazy\" src=\"./NLP-2.assets/image-20250322150620890.png\"\u003e\u003c/p\u003e\n\u003cp\u003eÁªìÊûú\u003c/p\u003e\n\u003cp\u003e\u003cimg alt=\"image-20250322150754528\" loading=\"lazy\" src=\"./NLP-2.assets/image-20250322150754528.png\"\u003e\u003c/p\u003e\n\u003cp\u003e‰ΩÜÊòØÈïøÂ∫¶‰∏çÁªü‰∏Ä\u003c/p\u003e\n\u003cp\u003eStep4: ÂØπÈΩêsequence\u003c/p\u003e\n\u003cp\u003e\u003cimg alt=\"image-20250322150854986\" loading=\"lazy\" src=\"./NLP-2.assets/image-20250322150854986.png\"\u003e\u003c/p\u003e\n\u003cp\u003eËß£ÂÜ≥ÊñπÊ°àÊòØËøôÊ†∑ÁöÑÔºöÂèØ‰ª•Âõ∫ÂÆöÈïøÂ∫¶‰∏∫wÔºåÂä†ÂÖ•‰∏Ä‰∏™Â∫èÂàóÈïøÂ∫¶Â§™ÈïøÔºåÂ∞±Á†çÊéâÂâçÈù¢ÁöÑËØçÔºåÂè™‰øùÁïôÊúÄÂêéw‰∏™ËØçÔºõÂ¶ÇÊûú‰∏Ä‰∏™Â∫èÂàóÂ§™Áü≠ÔºåÂ∞±ÂÅözero paddingÔºåÁî®0Â°´ÂÖÖ\u003c/p\u003e\n\u003cp\u003e\u003cimg alt=\"image-20250322151030119\" loading=\"lazy\" src=\"./NLP-2.assets/image-20250322151030119.png\"\u003e\u003c/p\u003e\n\u003cp\u003eËøôÊ†∑‰∏ÄÊù•ÔºåÊâÄÊúâÁöÑÂ∫èÂàóÈïøÂ∫¶Â∞±Áªü‰∏Ä‰∫Ü\u003c/p\u003e\n\u003cp\u003e\u003cimg alt=\"image-20250322151117125\" loading=\"lazy\" src=\"./NLP-2.assets/image-20250322151117125.png\"\u003e\u003c/p\u003e\n\u003cp\u003eÊñáÊú¨Â§ÑÁêÜÂÆåÊàê‰∫ÜÔºåÊé•‰∏ãÊù•ÊòØword embeddingÔºåÊääÂçïËØçË°®Á§∫‰∏∫‰∏Ä‰∏™‰ΩéÁª¥ÂêëÈáèÔºõ\u003c/p\u003e\n\u003cp\u003e\u003cimg alt=\"image-20250322151252837\" loading=\"lazy\" src=\"./NLP-2.assets/image-20250322151252837.png\"\u003e\u003c/p\u003e","title":""},{"content":"üëã About me Hello! I‚Äôm Xu Zongsi, a passionate technology enthusiast currently pursuing my Master of Science in Electronic Commerce \u0026amp; Internet Computing at The University of Hong Kong. With a solid background in Software Engineering from the Beijing Institute of Technology, I specialize in emerging areas of artificial intelligence, including machine learning, deep learning, natural language processing, computer vision, and reinforcement learning.\nRecently, I have developed a strong interest in LLM agents, reinforcement learning, and knowledge graphs, particularly inspired by OpenAI\u0026rsquo;s five-step plan towards superintelligence. I aspire to contribute to the advancement of AGI and leverage data science techniques to develop innovative solutions.\nHello! I‚Äôm Xu Zongsi, a passionate technology enthusiast currently pursuing my Master of Science in ECIC at The University of Hong Kong. With a solid background in Software Engineering from the Beijing Institute of Technology, I specialize in emerging areas of artificial intelligence, including machine learning, deep learning, natural language processing, computer vision, and reinforcement learning.\nI have a strong interest in developing LLM agents and knowledge graphs, leveraging data science techniques for innovative solutions. Additionally, I am skilled in software development, aiming to create impactful applications that enhance user experiences.\nThroughout my academic journey, I have been involved in several innovative projects focused on fraud detection, intelligent text processing, and quantum computing applications in deep learning. My programming skills span languages like Python and Java, with experience in frameworks such as PyTorch.\nWhen I‚Äôm not coding, you can find me exploring new technologies, sharing insights on my blog, or engaging in community activities related to cyber security.\nüìö Education üá≠üá∞ The University of Hong Kong 09/2024 - Expected 11/2025 School of Computing and Data Science Master of Science in Electronic Commerce \u0026amp; Internet Computing Relevant Courses: Machine learning for business and e-commerce, Knowledge graphs, Financial fraud analytics, Internet infrastructure technologies, Website engineering, Blockchain and cryptocurrency, etc. üá®üá≥ Beijing Institute of Technology 09/2020 - 06/2024 School of Computer Science \u0026amp; Technology Bachelor of Engineering in Software Engineering, last two years GPA: 3.7/4 Relevant Courses: Reinforcement Learning, Deep Learning and Computer Vision, Artificial Intelligence and Robot Ethics, Almost Human: Mind, Brain and Artificial Intelligence, Mathematical Analysis for Engineering, Linear Algebra, Probability and Mathematical Statistics, etc. Skills: Python, Java, common data structures, design patterns, machine learning basics and algorithms, Linux, PyTorch, and some development tools (git, conda, etc.). üèÜ Awards \u0026amp; Honors Beijing Institute of Technology Undergraduate Scholarship (Top 20% of Grade) 06/2023 3rd Prize of China International \u0026#34;Internet \u0026#43;\u0026#34; College Student\u0026#39;s Innovation Competition 08/2022 Bronze Prize of \u0026#34;Challenge Cup\u0026#34; Capital University Entrepreneurship Competition 05/2022 üíº Project Experience Online Transaction Fraud Detection 09/2024 ‚Äì 01/2025 Independent project, supervised by Dr. Vivien Chan Focused on addressing financial fraud in e-commerce to enhance the accuracy of transaction anomaly detection, while independently managing the entire case study that included data preprocessing, feature engineering, model building, evaluation, and results analysis. Effectively resolved class imbalance issues using SMOTE and ROSE techniques. Built various models including Logistic Regression, Random Forest, XGBoost, and LightGBM, ultimately selecting the LightGBM model to achieve a recall rate of 95.45% and an AUC of 99.84%. Wrote efficient and maintainable code, enhancing model training and data processing efficiency through parallel computing and logging. Multi-Model Intelligent Text Keyword Extraction System 08/2023 ‚Äì 09/2023 Group project, supervised by Associate Prof. Xiaolin Zhao Designed and implemented an intelligent text summary system that automatically extracts keywords from article titles and abstracts, enhancing the understanding and summarization of text information. Participated in the planning of the technical route and built a hybrid model combining extractive and generative approaches, utilizing advanced natural language processing techniques including KeyBERT, Sentence Transformer, BERT, and T5 models. Responsible for data preprocessing and tokenization, as well as the end-to-end implementation and training of the T5 model, optimizing the model architecture and hyperparameters, achieving satisfactory results after only 3 epochs of training. Model evaluation results showed that the Rouge-1, Rouge-2, and Rouge-L metrics reached 0.6345, 0.5038, and 0.5282, respectively, in the third epoch, validating the model\u0026rsquo;s effectiveness in the summarization task. Cambridge University Machine Learning Summer Project 07/2023 ‚Äì 08/2023 Group project, supervised by Prof. Pietro Li√≤ Participated in the Cambridge University deep learning summer project, focusing on deep reinforcement learning; explored multi-agent learning algorithms across different environments. Reproduced the Multi-Agent Deep Deterministic Policy Gradient (MADDPG) algorithm in the Simple Adversary environment and studied the effect of agent numbers on convergence speed and stability, finding optimal stability at 21 agents. Designed and implemented comparative experiments inspired by the Rainbow algorithm, assessing target network strategies versus the Double Deep Q-Network (Double DQN). The results demonstrated that Double DQN significantly enhanced convergence speed, optimizing the overall learning process. Co-authored a group project paper on agent numbers and strategies effectiveness in multi-agent systems, achieving a score of 71% in the summer program (the highest in my group) and a \u0026ldquo;First Class\u0026rdquo; classification in the UK grading system. Deep Learning and Computer Vision Semester Project 09/2022 ‚Äì 12/2022 Independent project, supervised by Associate Prof. Guangyu Gao Designed and implemented a waste classifier using the ResNet model to improve classification accuracy and reduce resource waste. The project also enhanced understanding of transfer learning techniques with ResNet. Collected a dataset of 16 waste categories and preprocessed the images for uniformity and standardization, incorporating data augmentation techniques to enhance the dataset. Conducted experiments using ResNet34 and ResNet50 models through transfer learning, accelerating network convergence by leveraging pretrained weights. During training, techniques such as Batch Normalization and Dropout were applied to mitigate the risk of overfitting. The final model achieved an accuracy of 90% on the training set, while the performance on the test set was 61%, indicating a significant overfitting phenomenon during the training process. üéì Internship Beijing Academy of Quantum Information Science 08/2023 ‚Äì 01/2024 Research Intern at Quantum Computation Department Proposed a quantum convolution kernel design based on variational quantum circuits and developed a universal quantum convolution layer, successfully integrating it into classical CNN architectures such as VGG, GoogLeNet, and ResNet. Developed and evaluated various hybrid models, including a simple model named HQCCNN-2, which achieved 84.45% accuracy on the FashionMNIST dataset, surpassing the traditional CNN\u0026rsquo;s 80.72%. This demonstrates the effectiveness of the quantum convolution layer in improving model performance. Tested on a real quantum computer further validated the effectiveness of the hybrid model, demonstrating the viable integration of quantum computing with deep learning, and highlighting the potential for leveraging quantum properties to enhance model performance. üèÖ Competition Experience China International \u0026#34;Internet \u0026#43;\u0026#34; College Students\u0026#39; Innovation Competition 08/2022 Zhongke Ushield: Deep Learning-based Face Privacy Protection Authentication System Responsible for constructing a localized facial feature extraction engine based on MobileFaceNet, ensuring feature extraction is completed on end devices (such as mobile phones and cameras), guaranteeing that raw data does not leave the domain and is not stored, thus enhancing user privacy protection while improving recognition efficiency. \u0026#34;Challenge Cup\u0026#34; Capital University Entrepreneurship Competition 05/2022 Smart Orchard Responsible for the development of the fruit detection, ripeness prediction, and pest identification system, using deep convolutional neural network (CNN) technology for intelligent monitoring of crop growth conditions. Applied advanced object detection algorithms such as Faster R-CNN and YOLO to achieve high precision in apple detection and ripeness assessment, with an accuracy rate exceeding 90%, significantly enhancing the intelligence level of orchard management. Built and trained a dedicated dataset containing various pest samples, optimizing pest detection accuracy through data preprocessing (such as image normalization and resizing) and data augmentation techniques (like rotation, flipping, and noise addition), enabling the real-time monitoring system to accurately identify over 80% of pests, providing effective scientific maintenance recommendations to help farmers reduce crop losses. üìã Extracurricular Activities Vice President, Cyber Security Club, Beijing Institute of Technology 09/2021-09/2022 Backbone, Media Center of the Student Union of Beijing Institute of Technology 10/2020-06/2021 üì´ Contact üìß zongsi.xu@outlook.com üëî Zongsi (Tristan) Xu üíª github.com/BaizeXS üìç Hong Kong SAR, China ","permalink":"http://localhost:1313/resume/","summary":"Personal resume of Zongsi (Tristan) Xu","title":"Zongsi (Tristan) Xu"},{"content":"‰∏Ä„ÄÅÊï∞ÂÄºÁâπÂæÅ‰∏éÁ±ªÂà´ÁâπÂæÅ Êï∞ÂÄºÁâπÂæÅ (Numeric Features) ÂÖ∑ÊúâÂèØÂä†ÂáèÁöÑÊÑè‰πâÔºå‰∏îÂ≠òÂú®Â§ßÂ∞èÈ°∫Â∫è„ÄÇ ‰æãÂ≠êÔºöÂπ¥ÈæÑ„ÄÅÊ∏©Â∫¶Á≠â„ÄÇÂèØ‰ª•Áõ¥Êé•‰øùÁïôÂÖ∂Êï¥Êï∞ÊàñÊµÆÁÇπÊï∞ÂΩ¢Âºè‰æõÊ®°Âûã‰ΩøÁî®„ÄÇ Á±ªÂà´ÁâπÂæÅ (Categorical Features) Êï∞ÊçÆÂÄºÁ¶ªÊï£Ôºå‰∏çÂÖ∑Â§á‚ÄúÊï∞ÂÄºÂ§ßÂ∞è‚ÄùÈó¥ÁöÑÂèØÊØîÊÑè‰πâ„ÄÇ ‰æãÂ≠êÔºöÂõΩÁ±çÔºàÁæéÂõΩ/‰∏≠ÂõΩ/Âç∞Â∫¶Á≠âÔºâ„ÄÅÊÄßÂà´ÔºàÁî∑/Â•≥ÔºâÁ≠â„ÄÇ ÈóÆÈ¢òÔºöËã•‰ªÖÁî®Êï¥Êï∞Ë°®Á§∫ÔºàÁæéÂõΩ=1, ‰∏≠ÂõΩ=2ÔºâÔºå‰ºöÂºïÂÖ•ÈîôËØØÁöÑÊï∞ÂÄºËøêÁÆóÂÖ≥Á≥ªÔºåÂ¶Ç ‚ÄúÁæéÂõΩ + ‰∏≠ÂõΩ = Âç∞Â∫¶‚Äù„ÄÇ ‰∫å„ÄÅOne-HotÁºñÁ†ÅÁöÑÂä®Êú∫‰∏éÊµÅÁ®ã ‰∏∫‰ªÄ‰πà‰ΩøÁî®One-Hot\nÈÄöËøáÂ∞ÜÁ±ªÂà´Êò†Â∞Ñ‰∏∫ÂêëÈáèÔºåÈÅøÂÖçÊï¥Êï∞ÁºñÁ†ÅÂºïÂÖ•ÁöÑ‰º™Êï∞ÂÄºÂÖ≥Á≥ª„ÄÇ ÂêåÊó∂‰øùÁïôÂêÑÁßçÂèØËÉΩÁ±ªÂà´ÁöÑ‰ø°ÊÅØÔºå‰∏î‰ªÖÂú®ÂØπÂ∫î‰ΩçÁΩÆ‰∏∫1ÔºåÂÖ∂‰ªñ‰ΩçÁΩÆ‰∏∫0„ÄÇ Âª∫Á´ãÊò†Â∞ÑÔºö‰ªéÁ±ªÂà´Âà∞Á¥¢Âºï\n‰∏∫ÊØè‰∏™Á±ªÂà´ÂàÜÈÖç‰∏Ä‰∏™ÂîØ‰∏ÄÁ¥¢ÂºïÔºåÈÄöÂ∏∏‰ªé1ÂºÄÂßã„ÄÇ È¢ÑÁïôÁ¥¢Âºï0Ë°®Á§∫‚ÄúÊú™Áü•‚ÄùÊàñ‚ÄúÁº∫Â§±‚ÄùÔºåÂØπÂ∫îÂÖ®0ÂêëÈáè„ÄÇ ËΩ¨Êç¢‰∏∫One-HotÂêëÈáè\nËã•Á±ªÂà´ÊÄªÊï∞‰∏∫197ÔºåÂàôÁî®197Áª¥ÂêëÈáèË°®Á§∫„ÄÇ ‰æãÂ≠êÔºöÁæéÂõΩ [1, 0, 0, 0, ‚Ä¶]Ôºå ‰∏≠ÂõΩ [0, 1, 0, 0, ‚Ä¶]„ÄÇ Á§∫‰æãÔºöË°®Á§∫‰∏Ä‰∏™‰∫∫ÁöÑÁâπÂæÅ\nÁâπÂæÅÂåÖÂê´ÔºàÂπ¥ÈæÑ, ÊÄßÂà´, ÂõΩÁ±çÔºåÂÖ∂‰∏≠ÂõΩÁ±ç197ÁßçÔºâ Áª¥Â∫¶ÊÄªÂíåÔºö1Áª¥_age + 1Áª¥_gender + 197Áª¥_nationality = 199Áª¥„ÄÇ ‰æãÂ¶Ç (28, Â•≥, ‰∏≠ÂõΩ) ‚Üí [28, 0, 0, 1, 0, ‚Ä¶, 0]„ÄÇ ‰∏â„ÄÅÊñáÊú¨Êï∞ÊçÆÂ§ÑÁêÜÊµÅÁ®ã ÊñáÊú¨Âú®Ëá™ÁÑ∂ËØ≠Ë®ÄÂ§ÑÁêÜÔºàNLPÔºâ‰∏≠‰Ωú‰∏∫Â∏∏ËßÅÁöÑÂéüÂßãËæìÂÖ•ÔºåÈúÄË¶ÅÊï∞ÂÄºÂåñÊâçËÉΩÈÄÅÂÖ•Ê®°Âûã„ÄÇ‰∏ÄËà¨Ê≠•È™§Â¶Ç‰∏ãÔºö\nÂàÜËØç (Tokenization)\nÂ∞ÜÊñáÊú¨ÊãÜÂàÜ‰∏∫‰∏Ä‰∏™‰∏™ÂçïËØçÔºàTokenÔºâ„ÄÇ ‰æãÂ≠êÔºö\u0026quot;... to be or not to be...\u0026quot; ‚Üí [\u0026quot;...\u0026quot;, \u0026quot;to\u0026quot;, \u0026quot;be\u0026quot;, \u0026quot;or\u0026quot;, \u0026quot;not\u0026quot;, \u0026quot;to\u0026quot;, \u0026quot;be\u0026quot;, \u0026quot;...\u0026quot;]„ÄÇ ÁªüËÆ°ËØçÈ¢ë \u0026amp; ÊûÑÂª∫ËØçÂÖ∏\nËØçÈ¢ëÁªüËÆ° Áî®ÂìàÂ∏åË°®/Â≠óÂÖ∏ËÆ∞ÂΩïÊØè‰∏™ÂçïËØçÂá∫Áé∞Ê¨°Êï∞„ÄÇ ÈÅçÂéÜÊñáÊú¨Êó∂ÔºåËã•ÂçïËØçÂ∞öÊú™ÂÖ•Ë°®ÔºåÂàôÊñ∞Âª∫ËÆ∞ÂΩïÔºõËã•Â∑≤Â≠òÂú®ÔºåÂàôËÆ°Êï∞+1„ÄÇ ÊéíÂ∫è‰∏éÁ¥¢Âºï ÊåâËØçÈ¢ëÈôçÂ∫èÊéíÂ∫èÔºåËØçÈ¢ëÊúÄÈ´òÁöÑÂçïËØçÊéíÂú®ÂâçÈù¢„ÄÇ Á¥¢Âºï‰ªé1ÂºÄÂßãÔºå0ÁïôÁªô‚ÄúÊú™Áü•‚Äù„ÄÇ ËØçÂÖ∏ËßÑÊ®°ÔºàvocabularyÔºâÂèØËßÜÈúÄÊ±ÇÊà™Êñ≠Ôºà‰æãÂ¶ÇÂè™‰øùÁïôTop 10kÔºâ„ÄÇ ‰∏∫‰ªÄ‰πàÁßªÈô§‰ΩéÈ¢ëËØç ‰ΩéÈ¢ëËØçÂèØËÉΩÊòØÊãºÂÜôÈîôËØØ„ÄÅÁΩïËßÅ‰∫∫ÂêçÁ≠âÔºåÂØπÊ®°ÂûãÂ∏ÆÂä©ÊúâÈôê„ÄÇ ÂáèÂ∞ëËØçÂÖ∏ËßÑÊ®°ÂèØÈôç‰ΩéËøêÁÆóÂºÄÈîÄ„ÄÅÂä†Âø´Ê®°ÂûãËÆ≠ÁªÉ‰∏éÊé®ÁêÜÈÄüÂ∫¶„ÄÇ Áã¨ÁÉ≠ÁºñÁ†Å (One-Hot Encoding)\nÂ∞ÜÊØè‰∏™ÂçïËØçÊò†Â∞Ñ‰∏∫ËØçÂÖ∏‰∏≠ÁöÑÁ¥¢ÂºïÂêéÔºàÂ¶Ç [2, 4, 1, 8, ‚Ä¶]ÔºâÔºåÂèØËøõ‰∏ÄÊ≠•ËΩ¨Êç¢ÊàêOne-HotÂêëÈáè„ÄÇ One-HotÁª¥Â∫¶ÂèñÂÜ≥‰∫é‰øùÁïô‰∏ãÊù•ÁöÑËØçÂÖ∏Â§ßÂ∞èÔºà‰æãÂ¶Ç1‰∏áÔºâ„ÄÇ Êú™Êî∂ÂΩïÂçïËØçÂèØËÉΩÁõ¥Êé•ÂøΩÁï•ÔºåÊàñÁªü‰∏ÄÁî®Á¥¢Âºï0‰ª£Êõø„ÄÇ Âõõ„ÄÅÊ†∏ÂøÉÊî∂Ëé∑‰∏éÂ∫îÁî® Á±ªÂà´ÁâπÂæÅÂøÖÈúÄÊï∞ÂÄºÂåñÔºö\n‰ΩøÁî®Êï¥Êï∞1,2,3‚Ä¶‰ªÖË°®Á§∫Á±ªÂà´‚ÄúÊ†áËØÜ‚ÄùÔºåÂπ∂‰∏ç‰ª£Ë°®ÂÆÉ‰ª¨ÂèØËøõË°åÊï∞ÂÄºËøêÁÆó„ÄÇ Âõ†Ê≠§ÈúÄË¶ÅOne-HotÁ≠âÁºñÁ†ÅÊñπÂºèÔºåÈÅøÂÖçÊï∞ÂÄºËØØËß£„ÄÇ ÊñáÊú¨Êï∞ÊçÆÈ¢ÑÂ§ÑÁêÜÔºö\nÂàÜËØç„ÄÅËØçÈ¢ëÁªüËÆ°„ÄÅÊûÑÂª∫ËØçÂÖ∏„ÄÅÁ¥¢ÂºïÂåñ„ÄÅOne-HotÊàñÂÖ∂‰ªñÊñπÂºèÔºàÂ¶ÇËØçÂµåÂÖ•ÔºâÊòØÂ∏∏ËßÅÊµÅÁ®ã„ÄÇ Ê≠£Á°ÆÁöÑÊñáÊú¨È¢ÑÂ§ÑÁêÜÂèØÊòæËëóÂΩ±ÂìçÊ®°ÂûãÊÄßËÉΩÂíåÊïàÁéá„ÄÇ ‰øùÁïôÊú™Áü•Á¥¢ÂºïÔºö\n‰øùËØÅÂØπÁº∫Â§±Êï∞ÊçÆÊàñÂ≠óÂÖ∏Â§ñÊñ∞ËØçËÉΩÊúâÂü∫Êú¨ÁöÑË°®Á§∫ÔºåÊèêÂçáÊ®°ÂûãÂÆπÈîôÊÄß„ÄÇ ÂÆûÈôÖ‰ΩøÁî®Ôºö\nÂØπ‰∫éÂ∞èËßÑÊ®°Á±ªÂà´ÂèØÁõ¥Êé•One-HotÁºñÁ†ÅÔºõÂØπ‰∫éËØçÂÖ∏ÂæàÂ§ßÁöÑÂú∫ÊôØÔºåÈÄöÂ∏∏‰ºöËøõ‰∏ÄÊ≠•ËÄÉËôëËØçÂµåÂÖ•ÔºàWord EmbeddingÔºâÊàñÈ¢ÑËÆ≠ÁªÉËØ≠Ë®ÄÊ®°Âûã„ÄÇ ","permalink":"http://localhost:1313/posts/nlp-1/","summary":"\u003ch2 id=\"‰∏ÄÊï∞ÂÄºÁâπÂæÅ‰∏éÁ±ªÂà´ÁâπÂæÅ\"\u003e‰∏Ä„ÄÅÊï∞ÂÄºÁâπÂæÅ‰∏éÁ±ªÂà´ÁâπÂæÅ\u003c/h2\u003e\n\u003col\u003e\n\u003cli\u003e\u003cstrong\u003eÊï∞ÂÄºÁâπÂæÅ (Numeric Features)\u003c/strong\u003e\n\u003cul\u003e\n\u003cli\u003eÂÖ∑ÊúâÂèØÂä†ÂáèÁöÑÊÑè‰πâÔºå‰∏îÂ≠òÂú®Â§ßÂ∞èÈ°∫Â∫è„ÄÇ\u003c/li\u003e\n\u003cli\u003e‰æãÂ≠êÔºöÂπ¥ÈæÑ„ÄÅÊ∏©Â∫¶Á≠â„ÄÇÂèØ‰ª•Áõ¥Êé•‰øùÁïôÂÖ∂Êï¥Êï∞ÊàñÊµÆÁÇπÊï∞ÂΩ¢Âºè‰æõÊ®°Âûã‰ΩøÁî®„ÄÇ\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003eÁ±ªÂà´ÁâπÂæÅ (Categorical Features)\u003c/strong\u003e\n\u003cul\u003e\n\u003cli\u003eÊï∞ÊçÆÂÄºÁ¶ªÊï£Ôºå‰∏çÂÖ∑Â§á‚ÄúÊï∞ÂÄºÂ§ßÂ∞è‚ÄùÈó¥ÁöÑÂèØÊØîÊÑè‰πâ„ÄÇ\u003c/li\u003e\n\u003cli\u003e‰æãÂ≠êÔºöÂõΩÁ±çÔºàÁæéÂõΩ/‰∏≠ÂõΩ/Âç∞Â∫¶Á≠âÔºâ„ÄÅÊÄßÂà´ÔºàÁî∑/Â•≥ÔºâÁ≠â„ÄÇ\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003eÈóÆÈ¢ò\u003c/strong\u003eÔºöËã•‰ªÖÁî®Êï¥Êï∞Ë°®Á§∫ÔºàÁæéÂõΩ=1, ‰∏≠ÂõΩ=2ÔºâÔºå‰ºöÂºïÂÖ•ÈîôËØØÁöÑÊï∞ÂÄºËøêÁÆóÂÖ≥Á≥ªÔºåÂ¶Ç ‚ÄúÁæéÂõΩ + ‰∏≠ÂõΩ = Âç∞Â∫¶‚Äù„ÄÇ\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003c/ol\u003e\n\u003ch2 id=\"‰∫åone-hotÁºñÁ†ÅÁöÑÂä®Êú∫‰∏éÊµÅÁ®ã\"\u003e‰∫å„ÄÅOne-HotÁºñÁ†ÅÁöÑÂä®Êú∫‰∏éÊµÅÁ®ã\u003c/h2\u003e\n\u003col\u003e\n\u003cli\u003e\n\u003cp\u003e\u003cstrong\u003e‰∏∫‰ªÄ‰πà‰ΩøÁî®One-Hot\u003c/strong\u003e\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eÈÄöËøáÂ∞ÜÁ±ªÂà´Êò†Â∞Ñ‰∏∫ÂêëÈáèÔºåÈÅøÂÖçÊï¥Êï∞ÁºñÁ†ÅÂºïÂÖ•ÁöÑ‰º™Êï∞ÂÄºÂÖ≥Á≥ª„ÄÇ\u003c/li\u003e\n\u003cli\u003eÂêåÊó∂‰øùÁïôÂêÑÁßçÂèØËÉΩÁ±ªÂà´ÁöÑ‰ø°ÊÅØÔºå‰∏î‰ªÖÂú®ÂØπÂ∫î‰ΩçÁΩÆ‰∏∫1ÔºåÂÖ∂‰ªñ‰ΩçÁΩÆ‰∏∫0„ÄÇ\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003e\u003cstrong\u003eÂª∫Á´ãÊò†Â∞ÑÔºö‰ªéÁ±ªÂà´Âà∞Á¥¢Âºï\u003c/strong\u003e\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e‰∏∫ÊØè‰∏™Á±ªÂà´ÂàÜÈÖç‰∏Ä‰∏™ÂîØ‰∏ÄÁ¥¢ÂºïÔºåÈÄöÂ∏∏‰ªé1ÂºÄÂßã„ÄÇ\u003c/li\u003e\n\u003cli\u003eÈ¢ÑÁïôÁ¥¢Âºï0Ë°®Á§∫‚ÄúÊú™Áü•‚ÄùÊàñ‚ÄúÁº∫Â§±‚ÄùÔºåÂØπÂ∫îÂÖ®0ÂêëÈáè„ÄÇ\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003e\u003cstrong\u003eËΩ¨Êç¢‰∏∫One-HotÂêëÈáè\u003c/strong\u003e\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eËã•Á±ªÂà´ÊÄªÊï∞‰∏∫197ÔºåÂàôÁî®197Áª¥ÂêëÈáèË°®Á§∫„ÄÇ\u003c/li\u003e\n\u003cli\u003e‰æãÂ≠êÔºöÁæéÂõΩ \u003ccode\u003e[1, 0, 0, 0, ‚Ä¶]\u003c/code\u003eÔºå ‰∏≠ÂõΩ \u003ccode\u003e[0, 1, 0, 0, ‚Ä¶]\u003c/code\u003e„ÄÇ\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003e\u003cstrong\u003eÁ§∫‰æãÔºöË°®Á§∫‰∏Ä‰∏™‰∫∫ÁöÑÁâπÂæÅ\u003c/strong\u003e\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eÁâπÂæÅÂåÖÂê´ÔºàÂπ¥ÈæÑ, ÊÄßÂà´, ÂõΩÁ±çÔºåÂÖ∂‰∏≠ÂõΩÁ±ç197ÁßçÔºâ\u003c/li\u003e\n\u003cli\u003eÁª¥Â∫¶ÊÄªÂíåÔºö1Áª¥_age + 1Áª¥_gender + 197Áª¥_nationality = 199Áª¥„ÄÇ\u003c/li\u003e\n\u003cli\u003e‰æãÂ¶Ç \u003ccode\u003e(28, Â•≥, ‰∏≠ÂõΩ)\u003c/code\u003e ‚Üí \u003ccode\u003e[28, 0, 0, 1, 0, ‚Ä¶, 0]\u003c/code\u003e„ÄÇ\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003c/ol\u003e\n\u003ch2 id=\"‰∏âÊñáÊú¨Êï∞ÊçÆÂ§ÑÁêÜÊµÅÁ®ã\"\u003e‰∏â„ÄÅÊñáÊú¨Êï∞ÊçÆÂ§ÑÁêÜÊµÅÁ®ã\u003c/h2\u003e\n\u003cp\u003eÊñáÊú¨Âú®Ëá™ÁÑ∂ËØ≠Ë®ÄÂ§ÑÁêÜÔºàNLPÔºâ‰∏≠‰Ωú‰∏∫Â∏∏ËßÅÁöÑÂéüÂßãËæìÂÖ•ÔºåÈúÄË¶ÅÊï∞ÂÄºÂåñÊâçËÉΩÈÄÅÂÖ•Ê®°Âûã„ÄÇ‰∏ÄËà¨Ê≠•È™§Â¶Ç‰∏ãÔºö\u003c/p\u003e\n\u003col\u003e\n\u003cli\u003e\n\u003cp\u003e\u003cstrong\u003eÂàÜËØç (Tokenization)\u003c/strong\u003e\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eÂ∞ÜÊñáÊú¨ÊãÜÂàÜ‰∏∫‰∏Ä‰∏™‰∏™ÂçïËØçÔºàTokenÔºâ„ÄÇ\u003c/li\u003e\n\u003cli\u003e‰æãÂ≠êÔºö\u003ccode\u003e\u0026quot;... to be or not to be...\u0026quot;\u003c/code\u003e ‚Üí \u003ccode\u003e[\u0026quot;...\u0026quot;, \u0026quot;to\u0026quot;, \u0026quot;be\u0026quot;, \u0026quot;or\u0026quot;, \u0026quot;not\u0026quot;, \u0026quot;to\u0026quot;, \u0026quot;be\u0026quot;, \u0026quot;...\u0026quot;]\u003c/code\u003e„ÄÇ\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003e\u003cstrong\u003eÁªüËÆ°ËØçÈ¢ë \u0026amp; ÊûÑÂª∫ËØçÂÖ∏\u003c/strong\u003e\u003c/p\u003e","title":""},{"content":"Text to Sequence ÊñáÊú¨Â§ÑÁêÜ\nStep1: Tokenization\nTokenization breaks a piece of text down into a list of tokens.\nHere, a token is a word. (A token can be a character in some applications.)\nTokenizationËÆ≤Á©∂ÂæàÂ§öÔºå‰æãÂ¶ÇÊòØÂê¶Â∫îËØ•ÊääÂ§ßÂÜôÊîπÊàêÂ∞èÂÜôÂë¢ÔºüËøõË°åtypo correctionÁ≠âÁ≠â\nStep2: Build Dictionary\nUse a dictionary (hash table) to count word frequencies.\nThe dictionary maps word to index.\nÂèØ‰ª•È¶ñÂÖàÁªüËÆ°ËØçÈ¢ëÂéªÊéâ‰ΩéÈ¢ëËØçÔºåÁÑ∂ÂêéËÆ©ÊØè‰∏™ËØçÂØπÂ∫î‰∏Ä‰∏™Ê≠£Êï¥Êï∞ÔºõËøôÊ†∑ÁöÑËØùÔºå‰∏ÄÂè•ËØùÂ∞±ÂèØ‰ª•Áî®‰∏Ä‰∏™Ê≠£Êï¥Êï∞ÂàóË°®Ë°®Á§∫ÔºåËøô‰∏™ÂàóË°®Â∞±Âè´sequenceÔºõÂ¶ÇÊûúÂøÖË¶ÅÂ∞±ËøòÂæóÂÅöone-hot encoding„ÄÇ\nÁªìÊûú\n‰ΩÜÊòØÈïøÂ∫¶‰∏çÁªü‰∏Ä\nStep4: ÂØπÈΩêsequence\nËß£ÂÜ≥ÊñπÊ°àÊòØËøôÊ†∑ÁöÑÔºöÂèØ‰ª•Âõ∫ÂÆöÈïøÂ∫¶‰∏∫wÔºåÂä†ÂÖ•‰∏Ä‰∏™Â∫èÂàóÈïøÂ∫¶Â§™ÈïøÔºåÂ∞±Á†çÊéâÂâçÈù¢ÁöÑËØçÔºåÂè™‰øùÁïôÊúÄÂêéw‰∏™ËØçÔºõÂ¶ÇÊûú‰∏Ä‰∏™Â∫èÂàóÂ§™Áü≠ÔºåÂ∞±ÂÅözero paddingÔºåÁî®0Â°´ÂÖÖ\nËøôÊ†∑‰∏ÄÊù•ÔºåÊâÄÊúâÁöÑÂ∫èÂàóÈïøÂ∫¶Â∞±Áªü‰∏Ä‰∫Ü\nÊñáÊú¨Â§ÑÁêÜÂÆåÊàê‰∫ÜÔºåÊé•‰∏ãÊù•ÊòØword embeddingÔºåÊääÂçïËØçË°®Á§∫‰∏∫‰∏Ä‰∏™‰ΩéÁª¥ÂêëÈáèÔºõ\nÁÑ∂ËÄåËøôÊ†∑ÂÅöÁöÑËØùÔºåÂ¶ÇÊûúÊòØ10000‰∏™ÂçïËØçÔºåÁª¥Â∫¶Â∞±ÊòØ10000Áª¥ÔºåÁª¥Â∫¶Â§™È´ò‰∫ÜÔºõÂõ†Ê≠§Ë¶ÅÂÅöword embeddingÔºõ\nÂÖ∑‰ΩìÂÅöÊ≥ïÂ∞±ÊòØÊääone-hotÂêëÈáèe_iÂíåÂèÇÊï∞Áü©ÈòµpÁõ∏‰πòÔºõÁü©ÈòµPËΩ¨ÁΩÆÁöÑÂ§ßÂ∞èÊòØd x vÔºõdÊòØËØçÂêëÈáèÁöÑÁª¥Â∫¶ÔºõvÊòØÂ≠óÂÖ∏ÈáåËØçÊ±áÁöÑÊï∞ÈáèÔºõÁªìÊûú‰∏∫x_iÔºõx_iÂ∞±ÊòØ‰∏Ä‰∏™ËØçÂêëÈáèÔºõÂ¶ÇÊûúone-hotÂêëÈáèÁöÑÁ¨¨‰∏âË°å‰∏∫1ÔºõÈÇ£‰πàx_iÂ∞±ÊòØPËΩ¨ÁΩÆÁü©ÈòµÁöÑÁ¨¨‰∏âÂàóÔºàÂÖ∂‰ΩôÂàóÈÉΩ‰∏∫0ÔºâÔºõÊâÄ‰ª•PËΩ¨ÁΩÆÊØè‰∏ÄÂàóÈÉΩÊòØ‰∏Ä‰∏™ËØçÂêëÈáèÔºõÊâÄ‰ª•Áü©ÈòµPÊú¨Ë∫´ÁöÑÊØè‰∏ÄË°åÂ∞±ÊòØ‰∏Ä‰∏™ËØçÂêëÈáèÔºõÂÖ∂Ë°åÊï∞‰∏∫vÔºõÂç≥vocabularyÔºåËØçÊ±áÈáèÔºõÊØè‰∏ÄË°åÂØπÂ∫î‰∏Ä‰∏™ÂçïËØçÔºõÁü©ÈòµÁöÑÂàóÊï∞‰∏∫dÔºõdÊòØÁî®Êà∑ÂÜ≥ÂÆöÁöÑÔºõdÁöÑÂ§ßÂ∞è‰ºöÂÜ≥ÂÆöÊú∫Âô®Â≠¶‰π†Ê®°ÂûãÁöÑË°®Áé∞ÔºõÂ∫îËØ•Áî®xxxÊù•ÈÄâÊã©‰∏Ä‰∏™ÊØîËæÉÂ•ΩÁöÑdÔºõ\nÊàë‰ª¨ÁöÑ‰ªªÂä°ÊòØÁúãËØÑËÆ∫ÊòØÊ≠£Èù¢ÁöÑËøòÊòØË¥üÈù¢ÁöÑÔºõÂèÇÊï∞Áü©ÈòµÊòØ‰ªéËÆ≠ÁªÉÊï∞ÊçÆ‰∏≠Â≠¶‰π†Âá∫Êù•ÁöÑÔºåÊâÄ‰ª•Â≠¶Âá∫Êù•ÁöÑËØçÂêëÈáèÊòØÂ∏¶ÊúâÊÑüÊÉÖËâ≤ÂΩ©ÁöÑÔºõÂÅáËÆæËøô‰∫õËØçÂêëÈáèÈÉΩÊòØ‰∫åÁª¥ÁöÑÔºåÂàôÂèØ‰ª•Âú®Âπ≥Èù¢ÂùêÊ†áÁ≥ª‰∏≠Ê†áÂá∫‰∏ãÈù¢ËØçÂêëÈáè\nkerasÊèê‰æõembeddingÂ±ÇÔºõÁî®Êà∑ÂèØ‰ª•ÊåáÂÆövocabularyÂ§ßÂ∞èÂíådÁöÑÂ§ßÂ∞èÔºõ‰ª•ÂèäÊØè‰∏Ä‰∏™sequenceÁöÑÈïøÂ∫¶ÔºõdÊòØÊ†πÊçÆÁÆóÊ≥ïÈÄâÂá∫Êù•ÁöÑ Âà∞Ëøô‰∏ÄÊ≠•ÔºåÊàë‰ª¨Â∑≤ÁªèÂÆåÊàê‰∫ÜÊñáÊú¨Â§ÑÁêÜÂíåword embedding„ÄÇÊé•‰∏ãÊù•Â∞±ÊòØÁî®Logistic Regression for Binary ClassificationÂÅö‰∫åÂàÜÁ±ªÔºõ\n","permalink":"http://localhost:1313/posts/nlp-2/","summary":"\u003ch3 id=\"text-to-sequence\"\u003eText to Sequence\u003c/h3\u003e\n\u003cp\u003eÊñáÊú¨Â§ÑÁêÜ\u003c/p\u003e\n\u003cp\u003eStep1: Tokenization\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\n\u003cp\u003eTokenization breaks a piece of text down into a list of tokens.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003eHere, a token is a word. (A token can be a character in some applications.)\u003c/p\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003eTokenizationËÆ≤Á©∂ÂæàÂ§öÔºå‰æãÂ¶ÇÊòØÂê¶Â∫îËØ•ÊääÂ§ßÂÜôÊîπÊàêÂ∞èÂÜôÂë¢ÔºüËøõË°åtypo correctionÁ≠âÁ≠â\u003c/p\u003e\n\u003cp\u003e\u003cimg alt=\"image-20250322150322238\" loading=\"lazy\" src=\"./NLP-2.assets/image-20250322150322238.png\"\u003e\u003c/p\u003e\n\u003cp\u003eStep2: Build Dictionary\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\n\u003cp\u003eUse a dictionary (hash table) to count word frequencies.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003eThe dictionary maps word to index.\u003c/p\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003eÂèØ‰ª•È¶ñÂÖàÁªüËÆ°ËØçÈ¢ëÂéªÊéâ‰ΩéÈ¢ëËØçÔºåÁÑ∂ÂêéËÆ©ÊØè‰∏™ËØçÂØπÂ∫î‰∏Ä‰∏™Ê≠£Êï¥Êï∞ÔºõËøôÊ†∑ÁöÑËØùÔºå‰∏ÄÂè•ËØùÂ∞±ÂèØ‰ª•Áî®‰∏Ä‰∏™Ê≠£Êï¥Êï∞ÂàóË°®Ë°®Á§∫ÔºåËøô‰∏™ÂàóË°®Â∞±Âè´sequenceÔºõÂ¶ÇÊûúÂøÖË¶ÅÂ∞±ËøòÂæóÂÅöone-hot encoding„ÄÇ\u003cimg alt=\"image-20250322150620890\" loading=\"lazy\" src=\"./NLP-2.assets/image-20250322150620890.png\"\u003e\u003c/p\u003e\n\u003cp\u003eÁªìÊûú\u003c/p\u003e\n\u003cp\u003e\u003cimg alt=\"image-20250322150754528\" loading=\"lazy\" src=\"./NLP-2.assets/image-20250322150754528.png\"\u003e\u003c/p\u003e\n\u003cp\u003e‰ΩÜÊòØÈïøÂ∫¶‰∏çÁªü‰∏Ä\u003c/p\u003e\n\u003cp\u003eStep4: ÂØπÈΩêsequence\u003c/p\u003e\n\u003cp\u003e\u003cimg alt=\"image-20250322150854986\" loading=\"lazy\" src=\"./NLP-2.assets/image-20250322150854986.png\"\u003e\u003c/p\u003e\n\u003cp\u003eËß£ÂÜ≥ÊñπÊ°àÊòØËøôÊ†∑ÁöÑÔºöÂèØ‰ª•Âõ∫ÂÆöÈïøÂ∫¶‰∏∫wÔºåÂä†ÂÖ•‰∏Ä‰∏™Â∫èÂàóÈïøÂ∫¶Â§™ÈïøÔºåÂ∞±Á†çÊéâÂâçÈù¢ÁöÑËØçÔºåÂè™‰øùÁïôÊúÄÂêéw‰∏™ËØçÔºõÂ¶ÇÊûú‰∏Ä‰∏™Â∫èÂàóÂ§™Áü≠ÔºåÂ∞±ÂÅözero paddingÔºåÁî®0Â°´ÂÖÖ\u003c/p\u003e\n\u003cp\u003e\u003cimg alt=\"image-20250322151030119\" loading=\"lazy\" src=\"./NLP-2.assets/image-20250322151030119.png\"\u003e\u003c/p\u003e\n\u003cp\u003eËøôÊ†∑‰∏ÄÊù•ÔºåÊâÄÊúâÁöÑÂ∫èÂàóÈïøÂ∫¶Â∞±Áªü‰∏Ä‰∫Ü\u003c/p\u003e\n\u003cp\u003e\u003cimg alt=\"image-20250322151117125\" loading=\"lazy\" src=\"./NLP-2.assets/image-20250322151117125.png\"\u003e\u003c/p\u003e\n\u003cp\u003eÊñáÊú¨Â§ÑÁêÜÂÆåÊàê‰∫ÜÔºåÊé•‰∏ãÊù•ÊòØword embeddingÔºåÊääÂçïËØçË°®Á§∫‰∏∫‰∏Ä‰∏™‰ΩéÁª¥ÂêëÈáèÔºõ\u003c/p\u003e\n\u003cp\u003e\u003cimg alt=\"image-20250322151252837\" loading=\"lazy\" src=\"./NLP-2.assets/image-20250322151252837.png\"\u003e\u003c/p\u003e","title":""},{"content":"üëã About me Hello! I‚Äôm Xu Zongsi, a passionate technology enthusiast currently pursuing my Master of Science in Electronic Commerce \u0026amp; Internet Computing at The University of Hong Kong. With a solid background in Software Engineering from the Beijing Institute of Technology, I specialize in emerging areas of artificial intelligence, including machine learning, deep learning, natural language processing, computer vision, and reinforcement learning.\nRecently, I have developed a strong interest in LLM agents, reinforcement learning, and knowledge graphs, particularly inspired by OpenAI\u0026rsquo;s five-step plan towards superintelligence.\nI aspire to contribute to the advancement of AGI by utilizing a diverse set of skills and techniques to develop innovative solutions.\nHello! I‚Äôm Xu Zongsi, a passionate technology enthusiast currently pursuing my Master of Science in ECIC at The University of Hong Kong. With a solid background in Software Engineering from the Beijing Institute of Technology, I specialize in emerging areas of artificial intelligence, including machine learning, deep learning, natural language processing, computer vision, and reinforcement learning.\nI have a strong interest in developing LLM agents and knowledge graphs, leveraging data science techniques for innovative solutions. Additionally, I am skilled in software development, aiming to create impactful applications that enhance user experiences.\nThroughout my academic journey, I have been involved in several innovative projects focused on fraud detection, intelligent text processing, and quantum computing applications in deep learning. My programming skills span languages like Python and Java, with experience in frameworks such as PyTorch.\nWhen I‚Äôm not coding, you can find me exploring new technologies, sharing insights on my blog, or engaging in community activities related to cyber security.\nüìö Education üá≠üá∞ The University of Hong Kong 09/2024 - Expected 11/2025 School of Computing and Data Science Master of Science in Electronic Commerce \u0026amp; Internet Computing Relevant Courses: Machine learning for business and e-commerce, Knowledge graphs, Financial fraud analytics, Internet infrastructure technologies, Website engineering, Blockchain and cryptocurrency, etc. üá®üá≥ Beijing Institute of Technology 09/2020 - 06/2024 School of Computer Science \u0026amp; Technology Bachelor of Engineering in Software Engineering, last two years GPA: 3.7/4 Relevant Courses: Reinforcement Learning, Deep Learning and Computer Vision, Artificial Intelligence and Robot Ethics, Almost Human: Mind, Brain and Artificial Intelligence, Mathematical Analysis for Engineering, Linear Algebra, Probability and Mathematical Statistics, etc. Skills: Python, Java, common data structures, design patterns, machine learning basics and algorithms, Linux, PyTorch, and some development tools (git, conda, etc.). üèÜ Awards \u0026amp; Honors Beijing Institute of Technology Undergraduate Scholarship (Top 20% of Grade) 06/2023 3rd Prize of China International \u0026#34;Internet \u0026#43;\u0026#34; College Student\u0026#39;s Innovation Competition 08/2022 Bronze Prize of \u0026#34;Challenge Cup\u0026#34; Capital University Entrepreneurship Competition 05/2022 üíº Project Experience Online Transaction Fraud Detection 09/2024 ‚Äì 01/2025 Independent project, supervised by Dr. Vivien Chan Focused on addressing financial fraud in e-commerce to enhance the accuracy of transaction anomaly detection, while independently managing the entire case study that included data preprocessing, feature engineering, model building, evaluation, and results analysis. Effectively resolved class imbalance issues using SMOTE and ROSE techniques. Built various models including Logistic Regression, Random Forest, XGBoost, and LightGBM, ultimately selecting the LightGBM model to achieve a recall rate of 95.45% and an AUC of 99.84%. Wrote efficient and maintainable code, enhancing model training and data processing efficiency through parallel computing and logging. Multi-Model Intelligent Text Keyword Extraction System 08/2023 ‚Äì 09/2023 Group project, supervised by Associate Prof. Xiaolin Zhao Designed and implemented an intelligent text summary system that automatically extracts keywords from article titles and abstracts, enhancing the understanding and summarization of text information. Participated in the planning of the technical route and built a hybrid model combining extractive and generative approaches, utilizing advanced natural language processing techniques including KeyBERT, Sentence Transformer, BERT, and T5 models. Responsible for data preprocessing and tokenization, as well as the end-to-end implementation and training of the T5 model, optimizing the model architecture and hyperparameters, achieving satisfactory results after only 3 epochs of training. Model evaluation results showed that the Rouge-1, Rouge-2, and Rouge-L metrics reached 0.6345, 0.5038, and 0.5282, respectively, in the third epoch, validating the model\u0026rsquo;s effectiveness in the summarization task. Cambridge University Machine Learning Summer Project 07/2023 ‚Äì 08/2023 Group project, supervised by Prof. Pietro Li√≤ Participated in the Cambridge University deep learning summer project, focusing on deep reinforcement learning; explored multi-agent learning algorithms across different environments. Reproduced the Multi-Agent Deep Deterministic Policy Gradient (MADDPG) algorithm in the Simple Adversary environment and studied the effect of agent numbers on convergence speed and stability, finding optimal stability at 21 agents. Designed and implemented comparative experiments inspired by the Rainbow algorithm, assessing target network strategies versus the Double Deep Q-Network (Double DQN). The results demonstrated that Double DQN significantly enhanced convergence speed, optimizing the overall learning process. Co-authored a group project paper on agent numbers and strategies effectiveness in multi-agent systems, achieving a score of 71% in the summer program (the highest in my group) and a \u0026ldquo;First Class\u0026rdquo; classification in the UK grading system. Deep Learning and Computer Vision Semester Project 09/2022 ‚Äì 12/2022 Independent project, supervised by Associate Prof. Guangyu Gao Designed and implemented a waste classifier using the ResNet model to improve classification accuracy and reduce resource waste. The project also enhanced understanding of transfer learning techniques with ResNet. Collected a dataset of 16 waste categories and preprocessed the images for uniformity and standardization, incorporating data augmentation techniques to enhance the dataset. Conducted experiments using ResNet34 and ResNet50 models through transfer learning, accelerating network convergence by leveraging pretrained weights. During training, techniques such as Batch Normalization and Dropout were applied to mitigate the risk of overfitting. The final model achieved an accuracy of 90% on the training set, while the performance on the test set was 61%, indicating a significant overfitting phenomenon during the training process. üéì Internship Beijing Academy of Quantum Information Science 08/2023 ‚Äì 01/2024 Research Intern at Quantum Computation Department Proposed a quantum convolution kernel design based on variational quantum circuits and developed a universal quantum convolution layer, successfully integrating it into classical CNN architectures such as VGG, GoogLeNet, and ResNet. Developed and evaluated various hybrid models, including a simple model named HQCCNN-2, which achieved 84.45% accuracy on the FashionMNIST dataset, surpassing the traditional CNN\u0026rsquo;s 80.72%. This demonstrates the effectiveness of the quantum convolution layer in improving model performance. Tested on a real quantum computer further validated the effectiveness of the hybrid model, demonstrating the viable integration of quantum computing with deep learning, and highlighting the potential for leveraging quantum properties to enhance model performance. üèÖ Competition Experience China International \u0026#34;Internet \u0026#43;\u0026#34; College Students\u0026#39; Innovation Competition 08/2022 Zhongke Ushield: Deep Learning-based Face Privacy Protection Authentication System Responsible for constructing a localized facial feature extraction engine based on MobileFaceNet, ensuring feature extraction is completed on end devices (such as mobile phones and cameras), guaranteeing that raw data does not leave the domain and is not stored, thus enhancing user privacy protection while improving recognition efficiency. \u0026#34;Challenge Cup\u0026#34; Capital University Entrepreneurship Competition 05/2022 Smart Orchard Responsible for the development of the fruit detection, ripeness prediction, and pest identification system, using deep convolutional neural network (CNN) technology for intelligent monitoring of crop growth conditions. Applied advanced object detection algorithms such as Faster R-CNN and YOLO to achieve high precision in apple detection and ripeness assessment, with an accuracy rate exceeding 90%, significantly enhancing the intelligence level of orchard management. Built and trained a dedicated dataset containing various pest samples, optimizing pest detection accuracy through data preprocessing (such as image normalization and resizing) and data augmentation techniques (like rotation, flipping, and noise addition), enabling the real-time monitoring system to accurately identify over 80% of pests, providing effective scientific maintenance recommendations to help farmers reduce crop losses. üìã Extracurricular Activities Vice President, Cyber Security Club, Beijing Institute of Technology 09/2021-09/2022 Backbone, Media Center of the Student Union of Beijing Institute of Technology 10/2020-06/2021 üì´ Contact üìß zongsi.xu@outlook.com üëî Zongsi (Tristan) Xu üíª github.com/BaizeXS üìç Hong Kong SAR, China ","permalink":"http://localhost:1313/resume/","summary":"Personal resume of Zongsi (Tristan) Xu","title":"Zongsi (Tristan) Xu"},{"content":"‰∏Ä„ÄÅÊï∞ÂÄºÁâπÂæÅ‰∏éÁ±ªÂà´ÁâπÂæÅ Êï∞ÂÄºÁâπÂæÅ (Numeric Features) ÂÖ∑ÊúâÂèØÂä†ÂáèÁöÑÊÑè‰πâÔºå‰∏îÂ≠òÂú®Â§ßÂ∞èÈ°∫Â∫è„ÄÇ ‰æãÂ≠êÔºöÂπ¥ÈæÑ„ÄÅÊ∏©Â∫¶Á≠â„ÄÇÂèØ‰ª•Áõ¥Êé•‰øùÁïôÂÖ∂Êï¥Êï∞ÊàñÊµÆÁÇπÊï∞ÂΩ¢Âºè‰æõÊ®°Âûã‰ΩøÁî®„ÄÇ Á±ªÂà´ÁâπÂæÅ (Categorical Features) Êï∞ÊçÆÂÄºÁ¶ªÊï£Ôºå‰∏çÂÖ∑Â§á‚ÄúÊï∞ÂÄºÂ§ßÂ∞è‚ÄùÈó¥ÁöÑÂèØÊØîÊÑè‰πâ„ÄÇ ‰æãÂ≠êÔºöÂõΩÁ±çÔºàÁæéÂõΩ/‰∏≠ÂõΩ/Âç∞Â∫¶Á≠âÔºâ„ÄÅÊÄßÂà´ÔºàÁî∑/Â•≥ÔºâÁ≠â„ÄÇ ÈóÆÈ¢òÔºöËã•‰ªÖÁî®Êï¥Êï∞Ë°®Á§∫ÔºàÁæéÂõΩ=1, ‰∏≠ÂõΩ=2ÔºâÔºå‰ºöÂºïÂÖ•ÈîôËØØÁöÑÊï∞ÂÄºËøêÁÆóÂÖ≥Á≥ªÔºåÂ¶Ç ‚ÄúÁæéÂõΩ + ‰∏≠ÂõΩ = Âç∞Â∫¶‚Äù„ÄÇ ‰∫å„ÄÅOne-HotÁºñÁ†ÅÁöÑÂä®Êú∫‰∏éÊµÅÁ®ã ‰∏∫‰ªÄ‰πà‰ΩøÁî®One-Hot\nÈÄöËøáÂ∞ÜÁ±ªÂà´Êò†Â∞Ñ‰∏∫ÂêëÈáèÔºåÈÅøÂÖçÊï¥Êï∞ÁºñÁ†ÅÂºïÂÖ•ÁöÑ‰º™Êï∞ÂÄºÂÖ≥Á≥ª„ÄÇ ÂêåÊó∂‰øùÁïôÂêÑÁßçÂèØËÉΩÁ±ªÂà´ÁöÑ‰ø°ÊÅØÔºå‰∏î‰ªÖÂú®ÂØπÂ∫î‰ΩçÁΩÆ‰∏∫1ÔºåÂÖ∂‰ªñ‰ΩçÁΩÆ‰∏∫0„ÄÇ Âª∫Á´ãÊò†Â∞ÑÔºö‰ªéÁ±ªÂà´Âà∞Á¥¢Âºï\n‰∏∫ÊØè‰∏™Á±ªÂà´ÂàÜÈÖç‰∏Ä‰∏™ÂîØ‰∏ÄÁ¥¢ÂºïÔºåÈÄöÂ∏∏‰ªé1ÂºÄÂßã„ÄÇ È¢ÑÁïôÁ¥¢Âºï0Ë°®Á§∫‚ÄúÊú™Áü•‚ÄùÊàñ‚ÄúÁº∫Â§±‚ÄùÔºåÂØπÂ∫îÂÖ®0ÂêëÈáè„ÄÇ ËΩ¨Êç¢‰∏∫One-HotÂêëÈáè\nËã•Á±ªÂà´ÊÄªÊï∞‰∏∫197ÔºåÂàôÁî®197Áª¥ÂêëÈáèË°®Á§∫„ÄÇ ‰æãÂ≠êÔºöÁæéÂõΩ [1, 0, 0, 0, ‚Ä¶]Ôºå ‰∏≠ÂõΩ [0, 1, 0, 0, ‚Ä¶]„ÄÇ Á§∫‰æãÔºöË°®Á§∫‰∏Ä‰∏™‰∫∫ÁöÑÁâπÂæÅ\nÁâπÂæÅÂåÖÂê´ÔºàÂπ¥ÈæÑ, ÊÄßÂà´, ÂõΩÁ±çÔºåÂÖ∂‰∏≠ÂõΩÁ±ç197ÁßçÔºâ Áª¥Â∫¶ÊÄªÂíåÔºö1Áª¥_age + 1Áª¥_gender + 197Áª¥_nationality = 199Áª¥„ÄÇ ‰æãÂ¶Ç (28, Â•≥, ‰∏≠ÂõΩ) ‚Üí [28, 0, 0, 1, 0, ‚Ä¶, 0]„ÄÇ ‰∏â„ÄÅÊñáÊú¨Êï∞ÊçÆÂ§ÑÁêÜÊµÅÁ®ã ÊñáÊú¨Âú®Ëá™ÁÑ∂ËØ≠Ë®ÄÂ§ÑÁêÜÔºàNLPÔºâ‰∏≠‰Ωú‰∏∫Â∏∏ËßÅÁöÑÂéüÂßãËæìÂÖ•ÔºåÈúÄË¶ÅÊï∞ÂÄºÂåñÊâçËÉΩÈÄÅÂÖ•Ê®°Âûã„ÄÇ‰∏ÄËà¨Ê≠•È™§Â¶Ç‰∏ãÔºö\nÂàÜËØç (Tokenization)\nÂ∞ÜÊñáÊú¨ÊãÜÂàÜ‰∏∫‰∏Ä‰∏™‰∏™ÂçïËØçÔºàTokenÔºâ„ÄÇ ‰æãÂ≠êÔºö\u0026quot;... to be or not to be...\u0026quot; ‚Üí [\u0026quot;...\u0026quot;, \u0026quot;to\u0026quot;, \u0026quot;be\u0026quot;, \u0026quot;or\u0026quot;, \u0026quot;not\u0026quot;, \u0026quot;to\u0026quot;, \u0026quot;be\u0026quot;, \u0026quot;...\u0026quot;]„ÄÇ ÁªüËÆ°ËØçÈ¢ë \u0026amp; ÊûÑÂª∫ËØçÂÖ∏\nËØçÈ¢ëÁªüËÆ° Áî®ÂìàÂ∏åË°®/Â≠óÂÖ∏ËÆ∞ÂΩïÊØè‰∏™ÂçïËØçÂá∫Áé∞Ê¨°Êï∞„ÄÇ ÈÅçÂéÜÊñáÊú¨Êó∂ÔºåËã•ÂçïËØçÂ∞öÊú™ÂÖ•Ë°®ÔºåÂàôÊñ∞Âª∫ËÆ∞ÂΩïÔºõËã•Â∑≤Â≠òÂú®ÔºåÂàôËÆ°Êï∞+1„ÄÇ ÊéíÂ∫è‰∏éÁ¥¢Âºï ÊåâËØçÈ¢ëÈôçÂ∫èÊéíÂ∫èÔºåËØçÈ¢ëÊúÄÈ´òÁöÑÂçïËØçÊéíÂú®ÂâçÈù¢„ÄÇ Á¥¢Âºï‰ªé1ÂºÄÂßãÔºå0ÁïôÁªô‚ÄúÊú™Áü•‚Äù„ÄÇ ËØçÂÖ∏ËßÑÊ®°ÔºàvocabularyÔºâÂèØËßÜÈúÄÊ±ÇÊà™Êñ≠Ôºà‰æãÂ¶ÇÂè™‰øùÁïôTop 10kÔºâ„ÄÇ ‰∏∫‰ªÄ‰πàÁßªÈô§‰ΩéÈ¢ëËØç ‰ΩéÈ¢ëËØçÂèØËÉΩÊòØÊãºÂÜôÈîôËØØ„ÄÅÁΩïËßÅ‰∫∫ÂêçÁ≠âÔºåÂØπÊ®°ÂûãÂ∏ÆÂä©ÊúâÈôê„ÄÇ ÂáèÂ∞ëËØçÂÖ∏ËßÑÊ®°ÂèØÈôç‰ΩéËøêÁÆóÂºÄÈîÄ„ÄÅÂä†Âø´Ê®°ÂûãËÆ≠ÁªÉ‰∏éÊé®ÁêÜÈÄüÂ∫¶„ÄÇ Áã¨ÁÉ≠ÁºñÁ†Å (One-Hot Encoding)\nÂ∞ÜÊØè‰∏™ÂçïËØçÊò†Â∞Ñ‰∏∫ËØçÂÖ∏‰∏≠ÁöÑÁ¥¢ÂºïÂêéÔºàÂ¶Ç [2, 4, 1, 8, ‚Ä¶]ÔºâÔºåÂèØËøõ‰∏ÄÊ≠•ËΩ¨Êç¢ÊàêOne-HotÂêëÈáè„ÄÇ One-HotÁª¥Â∫¶ÂèñÂÜ≥‰∫é‰øùÁïô‰∏ãÊù•ÁöÑËØçÂÖ∏Â§ßÂ∞èÔºà‰æãÂ¶Ç1‰∏áÔºâ„ÄÇ Êú™Êî∂ÂΩïÂçïËØçÂèØËÉΩÁõ¥Êé•ÂøΩÁï•ÔºåÊàñÁªü‰∏ÄÁî®Á¥¢Âºï0‰ª£Êõø„ÄÇ Âõõ„ÄÅÊ†∏ÂøÉÊî∂Ëé∑‰∏éÂ∫îÁî® Á±ªÂà´ÁâπÂæÅÂøÖÈúÄÊï∞ÂÄºÂåñÔºö\n‰ΩøÁî®Êï¥Êï∞1,2,3‚Ä¶‰ªÖË°®Á§∫Á±ªÂà´‚ÄúÊ†áËØÜ‚ÄùÔºåÂπ∂‰∏ç‰ª£Ë°®ÂÆÉ‰ª¨ÂèØËøõË°åÊï∞ÂÄºËøêÁÆó„ÄÇ Âõ†Ê≠§ÈúÄË¶ÅOne-HotÁ≠âÁºñÁ†ÅÊñπÂºèÔºåÈÅøÂÖçÊï∞ÂÄºËØØËß£„ÄÇ ÊñáÊú¨Êï∞ÊçÆÈ¢ÑÂ§ÑÁêÜÔºö\nÂàÜËØç„ÄÅËØçÈ¢ëÁªüËÆ°„ÄÅÊûÑÂª∫ËØçÂÖ∏„ÄÅÁ¥¢ÂºïÂåñ„ÄÅOne-HotÊàñÂÖ∂‰ªñÊñπÂºèÔºàÂ¶ÇËØçÂµåÂÖ•ÔºâÊòØÂ∏∏ËßÅÊµÅÁ®ã„ÄÇ Ê≠£Á°ÆÁöÑÊñáÊú¨È¢ÑÂ§ÑÁêÜÂèØÊòæËëóÂΩ±ÂìçÊ®°ÂûãÊÄßËÉΩÂíåÊïàÁéá„ÄÇ ‰øùÁïôÊú™Áü•Á¥¢ÂºïÔºö\n‰øùËØÅÂØπÁº∫Â§±Êï∞ÊçÆÊàñÂ≠óÂÖ∏Â§ñÊñ∞ËØçËÉΩÊúâÂü∫Êú¨ÁöÑË°®Á§∫ÔºåÊèêÂçáÊ®°ÂûãÂÆπÈîôÊÄß„ÄÇ ÂÆûÈôÖ‰ΩøÁî®Ôºö\nÂØπ‰∫éÂ∞èËßÑÊ®°Á±ªÂà´ÂèØÁõ¥Êé•One-HotÁºñÁ†ÅÔºõÂØπ‰∫éËØçÂÖ∏ÂæàÂ§ßÁöÑÂú∫ÊôØÔºåÈÄöÂ∏∏‰ºöËøõ‰∏ÄÊ≠•ËÄÉËôëËØçÂµåÂÖ•ÔºàWord EmbeddingÔºâÊàñÈ¢ÑËÆ≠ÁªÉËØ≠Ë®ÄÊ®°Âûã„ÄÇ ","permalink":"http://localhost:1313/posts/nlp-1/","summary":"\u003ch2 id=\"‰∏ÄÊï∞ÂÄºÁâπÂæÅ‰∏éÁ±ªÂà´ÁâπÂæÅ\"\u003e‰∏Ä„ÄÅÊï∞ÂÄºÁâπÂæÅ‰∏éÁ±ªÂà´ÁâπÂæÅ\u003c/h2\u003e\n\u003col\u003e\n\u003cli\u003e\u003cstrong\u003eÊï∞ÂÄºÁâπÂæÅ (Numeric Features)\u003c/strong\u003e\n\u003cul\u003e\n\u003cli\u003eÂÖ∑ÊúâÂèØÂä†ÂáèÁöÑÊÑè‰πâÔºå‰∏îÂ≠òÂú®Â§ßÂ∞èÈ°∫Â∫è„ÄÇ\u003c/li\u003e\n\u003cli\u003e‰æãÂ≠êÔºöÂπ¥ÈæÑ„ÄÅÊ∏©Â∫¶Á≠â„ÄÇÂèØ‰ª•Áõ¥Êé•‰øùÁïôÂÖ∂Êï¥Êï∞ÊàñÊµÆÁÇπÊï∞ÂΩ¢Âºè‰æõÊ®°Âûã‰ΩøÁî®„ÄÇ\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003eÁ±ªÂà´ÁâπÂæÅ (Categorical Features)\u003c/strong\u003e\n\u003cul\u003e\n\u003cli\u003eÊï∞ÊçÆÂÄºÁ¶ªÊï£Ôºå‰∏çÂÖ∑Â§á‚ÄúÊï∞ÂÄºÂ§ßÂ∞è‚ÄùÈó¥ÁöÑÂèØÊØîÊÑè‰πâ„ÄÇ\u003c/li\u003e\n\u003cli\u003e‰æãÂ≠êÔºöÂõΩÁ±çÔºàÁæéÂõΩ/‰∏≠ÂõΩ/Âç∞Â∫¶Á≠âÔºâ„ÄÅÊÄßÂà´ÔºàÁî∑/Â•≥ÔºâÁ≠â„ÄÇ\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003eÈóÆÈ¢ò\u003c/strong\u003eÔºöËã•‰ªÖÁî®Êï¥Êï∞Ë°®Á§∫ÔºàÁæéÂõΩ=1, ‰∏≠ÂõΩ=2ÔºâÔºå‰ºöÂºïÂÖ•ÈîôËØØÁöÑÊï∞ÂÄºËøêÁÆóÂÖ≥Á≥ªÔºåÂ¶Ç ‚ÄúÁæéÂõΩ + ‰∏≠ÂõΩ = Âç∞Â∫¶‚Äù„ÄÇ\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003c/ol\u003e\n\u003ch2 id=\"‰∫åone-hotÁºñÁ†ÅÁöÑÂä®Êú∫‰∏éÊµÅÁ®ã\"\u003e‰∫å„ÄÅOne-HotÁºñÁ†ÅÁöÑÂä®Êú∫‰∏éÊµÅÁ®ã\u003c/h2\u003e\n\u003col\u003e\n\u003cli\u003e\n\u003cp\u003e\u003cstrong\u003e‰∏∫‰ªÄ‰πà‰ΩøÁî®One-Hot\u003c/strong\u003e\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eÈÄöËøáÂ∞ÜÁ±ªÂà´Êò†Â∞Ñ‰∏∫ÂêëÈáèÔºåÈÅøÂÖçÊï¥Êï∞ÁºñÁ†ÅÂºïÂÖ•ÁöÑ‰º™Êï∞ÂÄºÂÖ≥Á≥ª„ÄÇ\u003c/li\u003e\n\u003cli\u003eÂêåÊó∂‰øùÁïôÂêÑÁßçÂèØËÉΩÁ±ªÂà´ÁöÑ‰ø°ÊÅØÔºå‰∏î‰ªÖÂú®ÂØπÂ∫î‰ΩçÁΩÆ‰∏∫1ÔºåÂÖ∂‰ªñ‰ΩçÁΩÆ‰∏∫0„ÄÇ\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003e\u003cstrong\u003eÂª∫Á´ãÊò†Â∞ÑÔºö‰ªéÁ±ªÂà´Âà∞Á¥¢Âºï\u003c/strong\u003e\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e‰∏∫ÊØè‰∏™Á±ªÂà´ÂàÜÈÖç‰∏Ä‰∏™ÂîØ‰∏ÄÁ¥¢ÂºïÔºåÈÄöÂ∏∏‰ªé1ÂºÄÂßã„ÄÇ\u003c/li\u003e\n\u003cli\u003eÈ¢ÑÁïôÁ¥¢Âºï0Ë°®Á§∫‚ÄúÊú™Áü•‚ÄùÊàñ‚ÄúÁº∫Â§±‚ÄùÔºåÂØπÂ∫îÂÖ®0ÂêëÈáè„ÄÇ\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003e\u003cstrong\u003eËΩ¨Êç¢‰∏∫One-HotÂêëÈáè\u003c/strong\u003e\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eËã•Á±ªÂà´ÊÄªÊï∞‰∏∫197ÔºåÂàôÁî®197Áª¥ÂêëÈáèË°®Á§∫„ÄÇ\u003c/li\u003e\n\u003cli\u003e‰æãÂ≠êÔºöÁæéÂõΩ \u003ccode\u003e[1, 0, 0, 0, ‚Ä¶]\u003c/code\u003eÔºå ‰∏≠ÂõΩ \u003ccode\u003e[0, 1, 0, 0, ‚Ä¶]\u003c/code\u003e„ÄÇ\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003e\u003cstrong\u003eÁ§∫‰æãÔºöË°®Á§∫‰∏Ä‰∏™‰∫∫ÁöÑÁâπÂæÅ\u003c/strong\u003e\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eÁâπÂæÅÂåÖÂê´ÔºàÂπ¥ÈæÑ, ÊÄßÂà´, ÂõΩÁ±çÔºåÂÖ∂‰∏≠ÂõΩÁ±ç197ÁßçÔºâ\u003c/li\u003e\n\u003cli\u003eÁª¥Â∫¶ÊÄªÂíåÔºö1Áª¥_age + 1Áª¥_gender + 197Áª¥_nationality = 199Áª¥„ÄÇ\u003c/li\u003e\n\u003cli\u003e‰æãÂ¶Ç \u003ccode\u003e(28, Â•≥, ‰∏≠ÂõΩ)\u003c/code\u003e ‚Üí \u003ccode\u003e[28, 0, 0, 1, 0, ‚Ä¶, 0]\u003c/code\u003e„ÄÇ\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003c/ol\u003e\n\u003ch2 id=\"‰∏âÊñáÊú¨Êï∞ÊçÆÂ§ÑÁêÜÊµÅÁ®ã\"\u003e‰∏â„ÄÅÊñáÊú¨Êï∞ÊçÆÂ§ÑÁêÜÊµÅÁ®ã\u003c/h2\u003e\n\u003cp\u003eÊñáÊú¨Âú®Ëá™ÁÑ∂ËØ≠Ë®ÄÂ§ÑÁêÜÔºàNLPÔºâ‰∏≠‰Ωú‰∏∫Â∏∏ËßÅÁöÑÂéüÂßãËæìÂÖ•ÔºåÈúÄË¶ÅÊï∞ÂÄºÂåñÊâçËÉΩÈÄÅÂÖ•Ê®°Âûã„ÄÇ‰∏ÄËà¨Ê≠•È™§Â¶Ç‰∏ãÔºö\u003c/p\u003e\n\u003col\u003e\n\u003cli\u003e\n\u003cp\u003e\u003cstrong\u003eÂàÜËØç (Tokenization)\u003c/strong\u003e\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eÂ∞ÜÊñáÊú¨ÊãÜÂàÜ‰∏∫‰∏Ä‰∏™‰∏™ÂçïËØçÔºàTokenÔºâ„ÄÇ\u003c/li\u003e\n\u003cli\u003e‰æãÂ≠êÔºö\u003ccode\u003e\u0026quot;... to be or not to be...\u0026quot;\u003c/code\u003e ‚Üí \u003ccode\u003e[\u0026quot;...\u0026quot;, \u0026quot;to\u0026quot;, \u0026quot;be\u0026quot;, \u0026quot;or\u0026quot;, \u0026quot;not\u0026quot;, \u0026quot;to\u0026quot;, \u0026quot;be\u0026quot;, \u0026quot;...\u0026quot;]\u003c/code\u003e„ÄÇ\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003e\u003cstrong\u003eÁªüËÆ°ËØçÈ¢ë \u0026amp; ÊûÑÂª∫ËØçÂÖ∏\u003c/strong\u003e\u003c/p\u003e","title":""},{"content":"Text to Sequence ÊñáÊú¨Â§ÑÁêÜ\nStep1: Tokenization\nTokenization breaks a piece of text down into a list of tokens.\nHere, a token is a word. (A token can be a character in some applications.)\nTokenizationËÆ≤Á©∂ÂæàÂ§öÔºå‰æãÂ¶ÇÊòØÂê¶Â∫îËØ•ÊääÂ§ßÂÜôÊîπÊàêÂ∞èÂÜôÂë¢ÔºüËøõË°åtypo correctionÁ≠âÁ≠â\nStep2: Build Dictionary\nUse a dictionary (hash table) to count word frequencies.\nThe dictionary maps word to index.\nÂèØ‰ª•È¶ñÂÖàÁªüËÆ°ËØçÈ¢ëÂéªÊéâ‰ΩéÈ¢ëËØçÔºåÁÑ∂ÂêéËÆ©ÊØè‰∏™ËØçÂØπÂ∫î‰∏Ä‰∏™Ê≠£Êï¥Êï∞ÔºõËøôÊ†∑ÁöÑËØùÔºå‰∏ÄÂè•ËØùÂ∞±ÂèØ‰ª•Áî®‰∏Ä‰∏™Ê≠£Êï¥Êï∞ÂàóË°®Ë°®Á§∫ÔºåËøô‰∏™ÂàóË°®Â∞±Âè´sequenceÔºõÂ¶ÇÊûúÂøÖË¶ÅÂ∞±ËøòÂæóÂÅöone-hot encoding„ÄÇ\nÁªìÊûú\n‰ΩÜÊòØÈïøÂ∫¶‰∏çÁªü‰∏Ä\nStep4: ÂØπÈΩêsequence\nËß£ÂÜ≥ÊñπÊ°àÊòØËøôÊ†∑ÁöÑÔºöÂèØ‰ª•Âõ∫ÂÆöÈïøÂ∫¶‰∏∫wÔºåÂä†ÂÖ•‰∏Ä‰∏™Â∫èÂàóÈïøÂ∫¶Â§™ÈïøÔºåÂ∞±Á†çÊéâÂâçÈù¢ÁöÑËØçÔºåÂè™‰øùÁïôÊúÄÂêéw‰∏™ËØçÔºõÂ¶ÇÊûú‰∏Ä‰∏™Â∫èÂàóÂ§™Áü≠ÔºåÂ∞±ÂÅözero paddingÔºåÁî®0Â°´ÂÖÖ\nËøôÊ†∑‰∏ÄÊù•ÔºåÊâÄÊúâÁöÑÂ∫èÂàóÈïøÂ∫¶Â∞±Áªü‰∏Ä‰∫Ü\nÊñáÊú¨Â§ÑÁêÜÂÆåÊàê‰∫ÜÔºåÊé•‰∏ãÊù•ÊòØword embeddingÔºåÊääÂçïËØçË°®Á§∫‰∏∫‰∏Ä‰∏™‰ΩéÁª¥ÂêëÈáèÔºõ\nÁÑ∂ËÄåËøôÊ†∑ÂÅöÁöÑËØùÔºåÂ¶ÇÊûúÊòØ10000‰∏™ÂçïËØçÔºåÁª¥Â∫¶Â∞±ÊòØ10000Áª¥ÔºåÁª¥Â∫¶Â§™È´ò‰∫ÜÔºõÂõ†Ê≠§Ë¶ÅÂÅöword embeddingÔºõ\nÂÖ∑‰ΩìÂÅöÊ≥ïÂ∞±ÊòØÊääone-hotÂêëÈáèe_iÂíåÂèÇÊï∞Áü©ÈòµpÁõ∏‰πòÔºõÁü©ÈòµPËΩ¨ÁΩÆÁöÑÂ§ßÂ∞èÊòØd x vÔºõdÊòØËØçÂêëÈáèÁöÑÁª¥Â∫¶ÔºõvÊòØÂ≠óÂÖ∏ÈáåËØçÊ±áÁöÑÊï∞ÈáèÔºõÁªìÊûú‰∏∫x_iÔºõx_iÂ∞±ÊòØ‰∏Ä‰∏™ËØçÂêëÈáèÔºõÂ¶ÇÊûúone-hotÂêëÈáèÁöÑÁ¨¨‰∏âË°å‰∏∫1ÔºõÈÇ£‰πàx_iÂ∞±ÊòØPËΩ¨ÁΩÆÁü©ÈòµÁöÑÁ¨¨‰∏âÂàóÔºàÂÖ∂‰ΩôÂàóÈÉΩ‰∏∫0ÔºâÔºõÊâÄ‰ª•PËΩ¨ÁΩÆÊØè‰∏ÄÂàóÈÉΩÊòØ‰∏Ä‰∏™ËØçÂêëÈáèÔºõÊâÄ‰ª•Áü©ÈòµPÊú¨Ë∫´ÁöÑÊØè‰∏ÄË°åÂ∞±ÊòØ‰∏Ä‰∏™ËØçÂêëÈáèÔºõÂÖ∂Ë°åÊï∞‰∏∫vÔºõÂç≥vocabularyÔºåËØçÊ±áÈáèÔºõÊØè‰∏ÄË°åÂØπÂ∫î‰∏Ä‰∏™ÂçïËØçÔºõÁü©ÈòµÁöÑÂàóÊï∞‰∏∫dÔºõdÊòØÁî®Êà∑ÂÜ≥ÂÆöÁöÑÔºõdÁöÑÂ§ßÂ∞è‰ºöÂÜ≥ÂÆöÊú∫Âô®Â≠¶‰π†Ê®°ÂûãÁöÑË°®Áé∞ÔºõÂ∫îËØ•Áî®xxxÊù•ÈÄâÊã©‰∏Ä‰∏™ÊØîËæÉÂ•ΩÁöÑdÔºõ\nÊàë‰ª¨ÁöÑ‰ªªÂä°ÊòØÁúãËØÑËÆ∫ÊòØÊ≠£Èù¢ÁöÑËøòÊòØË¥üÈù¢ÁöÑÔºõÂèÇÊï∞Áü©ÈòµÊòØ‰ªéËÆ≠ÁªÉÊï∞ÊçÆ‰∏≠Â≠¶‰π†Âá∫Êù•ÁöÑÔºåÊâÄ‰ª•Â≠¶Âá∫Êù•ÁöÑËØçÂêëÈáèÊòØÂ∏¶ÊúâÊÑüÊÉÖËâ≤ÂΩ©ÁöÑÔºõÂÅáËÆæËøô‰∫õËØçÂêëÈáèÈÉΩÊòØ‰∫åÁª¥ÁöÑÔºåÂàôÂèØ‰ª•Âú®Âπ≥Èù¢ÂùêÊ†áÁ≥ª‰∏≠Ê†áÂá∫‰∏ãÈù¢ËØçÂêëÈáè\nkerasÊèê‰æõembeddingÂ±ÇÔºõÁî®Êà∑ÂèØ‰ª•ÊåáÂÆövocabularyÂ§ßÂ∞èÂíådÁöÑÂ§ßÂ∞èÔºõ‰ª•ÂèäÊØè‰∏Ä‰∏™sequenceÁöÑÈïøÂ∫¶ÔºõdÊòØÊ†πÊçÆÁÆóÊ≥ïÈÄâÂá∫Êù•ÁöÑ Âà∞Ëøô‰∏ÄÊ≠•ÔºåÊàë‰ª¨Â∑≤ÁªèÂÆåÊàê‰∫ÜÊñáÊú¨Â§ÑÁêÜÂíåword embedding„ÄÇÊé•‰∏ãÊù•Â∞±ÊòØÁî®Logistic Regression for Binary ClassificationÂÅö‰∫åÂàÜÁ±ªÔºõ\n","permalink":"http://localhost:1313/posts/nlp-2/","summary":"\u003ch3 id=\"text-to-sequence\"\u003eText to Sequence\u003c/h3\u003e\n\u003cp\u003eÊñáÊú¨Â§ÑÁêÜ\u003c/p\u003e\n\u003cp\u003eStep1: Tokenization\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\n\u003cp\u003eTokenization breaks a piece of text down into a list of tokens.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003eHere, a token is a word. (A token can be a character in some applications.)\u003c/p\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003eTokenizationËÆ≤Á©∂ÂæàÂ§öÔºå‰æãÂ¶ÇÊòØÂê¶Â∫îËØ•ÊääÂ§ßÂÜôÊîπÊàêÂ∞èÂÜôÂë¢ÔºüËøõË°åtypo correctionÁ≠âÁ≠â\u003c/p\u003e\n\u003cp\u003e\u003cimg alt=\"image-20250322150322238\" loading=\"lazy\" src=\"./NLP-2.assets/image-20250322150322238.png\"\u003e\u003c/p\u003e\n\u003cp\u003eStep2: Build Dictionary\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\n\u003cp\u003eUse a dictionary (hash table) to count word frequencies.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003eThe dictionary maps word to index.\u003c/p\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003eÂèØ‰ª•È¶ñÂÖàÁªüËÆ°ËØçÈ¢ëÂéªÊéâ‰ΩéÈ¢ëËØçÔºåÁÑ∂ÂêéËÆ©ÊØè‰∏™ËØçÂØπÂ∫î‰∏Ä‰∏™Ê≠£Êï¥Êï∞ÔºõËøôÊ†∑ÁöÑËØùÔºå‰∏ÄÂè•ËØùÂ∞±ÂèØ‰ª•Áî®‰∏Ä‰∏™Ê≠£Êï¥Êï∞ÂàóË°®Ë°®Á§∫ÔºåËøô‰∏™ÂàóË°®Â∞±Âè´sequenceÔºõÂ¶ÇÊûúÂøÖË¶ÅÂ∞±ËøòÂæóÂÅöone-hot encoding„ÄÇ\u003cimg alt=\"image-20250322150620890\" loading=\"lazy\" src=\"./NLP-2.assets/image-20250322150620890.png\"\u003e\u003c/p\u003e\n\u003cp\u003eÁªìÊûú\u003c/p\u003e\n\u003cp\u003e\u003cimg alt=\"image-20250322150754528\" loading=\"lazy\" src=\"./NLP-2.assets/image-20250322150754528.png\"\u003e\u003c/p\u003e\n\u003cp\u003e‰ΩÜÊòØÈïøÂ∫¶‰∏çÁªü‰∏Ä\u003c/p\u003e\n\u003cp\u003eStep4: ÂØπÈΩêsequence\u003c/p\u003e\n\u003cp\u003e\u003cimg alt=\"image-20250322150854986\" loading=\"lazy\" src=\"./NLP-2.assets/image-20250322150854986.png\"\u003e\u003c/p\u003e\n\u003cp\u003eËß£ÂÜ≥ÊñπÊ°àÊòØËøôÊ†∑ÁöÑÔºöÂèØ‰ª•Âõ∫ÂÆöÈïøÂ∫¶‰∏∫wÔºåÂä†ÂÖ•‰∏Ä‰∏™Â∫èÂàóÈïøÂ∫¶Â§™ÈïøÔºåÂ∞±Á†çÊéâÂâçÈù¢ÁöÑËØçÔºåÂè™‰øùÁïôÊúÄÂêéw‰∏™ËØçÔºõÂ¶ÇÊûú‰∏Ä‰∏™Â∫èÂàóÂ§™Áü≠ÔºåÂ∞±ÂÅözero paddingÔºåÁî®0Â°´ÂÖÖ\u003c/p\u003e\n\u003cp\u003e\u003cimg alt=\"image-20250322151030119\" loading=\"lazy\" src=\"./NLP-2.assets/image-20250322151030119.png\"\u003e\u003c/p\u003e\n\u003cp\u003eËøôÊ†∑‰∏ÄÊù•ÔºåÊâÄÊúâÁöÑÂ∫èÂàóÈïøÂ∫¶Â∞±Áªü‰∏Ä‰∫Ü\u003c/p\u003e\n\u003cp\u003e\u003cimg alt=\"image-20250322151117125\" loading=\"lazy\" src=\"./NLP-2.assets/image-20250322151117125.png\"\u003e\u003c/p\u003e\n\u003cp\u003eÊñáÊú¨Â§ÑÁêÜÂÆåÊàê‰∫ÜÔºåÊé•‰∏ãÊù•ÊòØword embeddingÔºåÊääÂçïËØçË°®Á§∫‰∏∫‰∏Ä‰∏™‰ΩéÁª¥ÂêëÈáèÔºõ\u003c/p\u003e\n\u003cp\u003e\u003cimg alt=\"image-20250322151252837\" loading=\"lazy\" src=\"./NLP-2.assets/image-20250322151252837.png\"\u003e\u003c/p\u003e","title":""},{"content":"üëã About me Hello! I‚Äôm Xu Zongsi, a passionate technology enthusiast currently pursuing my Master of Science in Electronic Commerce \u0026amp; Internet Computing at The University of Hong Kong. With a solid background in Software Engineering from the Beijing Institute of Technology, I specialize in emerging areas of artificial intelligence, including machine learning, deep learning, natural language processing, computer vision, and reinforcement learning.\nRecently, inspired by OpenAI\u0026rsquo;s five-step plan towards superintelligence, I have great expectations for AGI and developed a strong interest in LLM agents, multimodal large models, reinforcement learning, and knowledge graphs. I believe there is significant potential in these fields to create innovative solutions, and I hope to contribute my efforts towards that goal.\nI aspire to contribute to the advancement of AGI by utilizing a diverse set of skills and techniques to develop innovative solutions.\nHello! I‚Äôm Xu Zongsi, a passionate technology enthusiast currently pursuing my Master of Science in ECIC at The University of Hong Kong. With a solid background in Software Engineering from the Beijing Institute of Technology, I specialize in emerging areas of artificial intelligence, including machine learning, deep learning, natural language processing, computer vision, and reinforcement learning.\nI have a strong interest in developing LLM agents and knowledge graphs, leveraging data science techniques for innovative solutions. Additionally, I am skilled in software development, aiming to create impactful applications that enhance user experiences.\nThroughout my academic journey, I have been involved in several innovative projects focused on fraud detection, intelligent text processing, and quantum computing applications in deep learning. My programming skills span languages like Python and Java, with experience in frameworks such as PyTorch.\nWhen I‚Äôm not coding, you can find me exploring new technologies, sharing insights on my blog, or engaging in community activities related to cyber security.\nüìö Education üá≠üá∞ The University of Hong Kong 09/2024 - Expected 11/2025 School of Computing and Data Science Master of Science in Electronic Commerce \u0026amp; Internet Computing Relevant Courses: Machine learning for business and e-commerce, Knowledge graphs, Financial fraud analytics, Internet infrastructure technologies, Website engineering, Blockchain and cryptocurrency, etc. üá®üá≥ Beijing Institute of Technology 09/2020 - 06/2024 School of Computer Science \u0026amp; Technology Bachelor of Engineering in Software Engineering, last two years GPA: 3.7/4 Relevant Courses: Reinforcement Learning, Deep Learning and Computer Vision, Artificial Intelligence and Robot Ethics, Almost Human: Mind, Brain and Artificial Intelligence, Mathematical Analysis for Engineering, Linear Algebra, Probability and Mathematical Statistics, etc. Skills: Python, Java, common data structures, design patterns, machine learning basics and algorithms, Linux, PyTorch, and some development tools (git, conda, etc.). üèÜ Awards \u0026amp; Honors Beijing Institute of Technology Undergraduate Scholarship (Top 20% of Grade) 06/2023 3rd Prize of China International \u0026#34;Internet \u0026#43;\u0026#34; College Student\u0026#39;s Innovation Competition 08/2022 Bronze Prize of \u0026#34;Challenge Cup\u0026#34; Capital University Entrepreneurship Competition 05/2022 üíº Project Experience Online Transaction Fraud Detection 09/2024 ‚Äì 01/2025 Independent project, supervised by Dr. Vivien Chan Focused on addressing financial fraud in e-commerce to enhance the accuracy of transaction anomaly detection, while independently managing the entire case study that included data preprocessing, feature engineering, model building, evaluation, and results analysis. Effectively resolved class imbalance issues using SMOTE and ROSE techniques. Built various models including Logistic Regression, Random Forest, XGBoost, and LightGBM, ultimately selecting the LightGBM model to achieve a recall rate of 95.45% and an AUC of 99.84%. Wrote efficient and maintainable code, enhancing model training and data processing efficiency through parallel computing and logging. Multi-Model Intelligent Text Keyword Extraction System 08/2023 ‚Äì 09/2023 Group project, supervised by Associate Prof. Xiaolin Zhao Designed and implemented an intelligent text summary system that automatically extracts keywords from article titles and abstracts, enhancing the understanding and summarization of text information. Participated in the planning of the technical route and built a hybrid model combining extractive and generative approaches, utilizing advanced natural language processing techniques including KeyBERT, Sentence Transformer, BERT, and T5 models. Responsible for data preprocessing and tokenization, as well as the end-to-end implementation and training of the T5 model, optimizing the model architecture and hyperparameters, achieving satisfactory results after only 3 epochs of training. Model evaluation results showed that the Rouge-1, Rouge-2, and Rouge-L metrics reached 0.6345, 0.5038, and 0.5282, respectively, in the third epoch, validating the model\u0026rsquo;s effectiveness in the summarization task. Cambridge University Machine Learning Summer Project 07/2023 ‚Äì 08/2023 Group project, supervised by Prof. Pietro Li√≤ Participated in the Cambridge University deep learning summer project, focusing on deep reinforcement learning; explored multi-agent learning algorithms across different environments. Reproduced the Multi-Agent Deep Deterministic Policy Gradient (MADDPG) algorithm in the Simple Adversary environment and studied the effect of agent numbers on convergence speed and stability, finding optimal stability at 21 agents. Designed and implemented comparative experiments inspired by the Rainbow algorithm, assessing target network strategies versus the Double Deep Q-Network (Double DQN). The results demonstrated that Double DQN significantly enhanced convergence speed, optimizing the overall learning process. Co-authored a group project paper on agent numbers and strategies effectiveness in multi-agent systems, achieving a score of 71% in the summer program (the highest in my group) and a \u0026ldquo;First Class\u0026rdquo; classification in the UK grading system. Deep Learning and Computer Vision Semester Project 09/2022 ‚Äì 12/2022 Independent project, supervised by Associate Prof. Guangyu Gao Designed and implemented a waste classifier using the ResNet model to improve classification accuracy and reduce resource waste. The project also enhanced understanding of transfer learning techniques with ResNet. Collected a dataset of 16 waste categories and preprocessed the images for uniformity and standardization, incorporating data augmentation techniques to enhance the dataset. Conducted experiments using ResNet34 and ResNet50 models through transfer learning, accelerating network convergence by leveraging pretrained weights. During training, techniques such as Batch Normalization and Dropout were applied to mitigate the risk of overfitting. The final model achieved an accuracy of 90% on the training set, while the performance on the test set was 61%, indicating a significant overfitting phenomenon during the training process. üéì Internship Beijing Academy of Quantum Information Science 08/2023 ‚Äì 01/2024 Research Intern at Quantum Computation Department Proposed a quantum convolution kernel design based on variational quantum circuits and developed a universal quantum convolution layer, successfully integrating it into classical CNN architectures such as VGG, GoogLeNet, and ResNet. Developed and evaluated various hybrid models, including a simple model named HQCCNN-2, which achieved 84.45% accuracy on the FashionMNIST dataset, surpassing the traditional CNN\u0026rsquo;s 80.72%. This demonstrates the effectiveness of the quantum convolution layer in improving model performance. Tested on a real quantum computer further validated the effectiveness of the hybrid model, demonstrating the viable integration of quantum computing with deep learning, and highlighting the potential for leveraging quantum properties to enhance model performance. üèÖ Competition Experience China International \u0026#34;Internet \u0026#43;\u0026#34; College Students\u0026#39; Innovation Competition 08/2022 Zhongke Ushield: Deep Learning-based Face Privacy Protection Authentication System Responsible for constructing a localized facial feature extraction engine based on MobileFaceNet, ensuring feature extraction is completed on end devices (such as mobile phones and cameras), guaranteeing that raw data does not leave the domain and is not stored, thus enhancing user privacy protection while improving recognition efficiency. \u0026#34;Challenge Cup\u0026#34; Capital University Entrepreneurship Competition 05/2022 Smart Orchard Responsible for the development of the fruit detection, ripeness prediction, and pest identification system, using deep convolutional neural network (CNN) technology for intelligent monitoring of crop growth conditions. Applied advanced object detection algorithms such as Faster R-CNN and YOLO to achieve high precision in apple detection and ripeness assessment, with an accuracy rate exceeding 90%, significantly enhancing the intelligence level of orchard management. Built and trained a dedicated dataset containing various pest samples, optimizing pest detection accuracy through data preprocessing (such as image normalization and resizing) and data augmentation techniques (like rotation, flipping, and noise addition), enabling the real-time monitoring system to accurately identify over 80% of pests, providing effective scientific maintenance recommendations to help farmers reduce crop losses. üìã Extracurricular Activities Vice President, Cyber Security Club, Beijing Institute of Technology 09/2021-09/2022 Backbone, Media Center of the Student Union of Beijing Institute of Technology 10/2020-06/2021 üì´ Contact üìß zongsi.xu@outlook.com üëî Zongsi (Tristan) Xu üíª github.com/BaizeXS üìç Hong Kong SAR, China ","permalink":"http://localhost:1313/resume/","summary":"Personal resume of Zongsi (Tristan) Xu","title":"Zongsi (Tristan) Xu"},{"content":"‰∏Ä„ÄÅÊï∞ÂÄºÁâπÂæÅ‰∏éÁ±ªÂà´ÁâπÂæÅ Êï∞ÂÄºÁâπÂæÅ (Numeric Features) ÂÖ∑ÊúâÂèØÂä†ÂáèÁöÑÊÑè‰πâÔºå‰∏îÂ≠òÂú®Â§ßÂ∞èÈ°∫Â∫è„ÄÇ ‰æãÂ≠êÔºöÂπ¥ÈæÑ„ÄÅÊ∏©Â∫¶Á≠â„ÄÇÂèØ‰ª•Áõ¥Êé•‰øùÁïôÂÖ∂Êï¥Êï∞ÊàñÊµÆÁÇπÊï∞ÂΩ¢Âºè‰æõÊ®°Âûã‰ΩøÁî®„ÄÇ Á±ªÂà´ÁâπÂæÅ (Categorical Features) Êï∞ÊçÆÂÄºÁ¶ªÊï£Ôºå‰∏çÂÖ∑Â§á‚ÄúÊï∞ÂÄºÂ§ßÂ∞è‚ÄùÈó¥ÁöÑÂèØÊØîÊÑè‰πâ„ÄÇ ‰æãÂ≠êÔºöÂõΩÁ±çÔºàÁæéÂõΩ/‰∏≠ÂõΩ/Âç∞Â∫¶Á≠âÔºâ„ÄÅÊÄßÂà´ÔºàÁî∑/Â•≥ÔºâÁ≠â„ÄÇ ÈóÆÈ¢òÔºöËã•‰ªÖÁî®Êï¥Êï∞Ë°®Á§∫ÔºàÁæéÂõΩ=1, ‰∏≠ÂõΩ=2ÔºâÔºå‰ºöÂºïÂÖ•ÈîôËØØÁöÑÊï∞ÂÄºËøêÁÆóÂÖ≥Á≥ªÔºåÂ¶Ç ‚ÄúÁæéÂõΩ + ‰∏≠ÂõΩ = Âç∞Â∫¶‚Äù„ÄÇ ‰∫å„ÄÅOne-HotÁºñÁ†ÅÁöÑÂä®Êú∫‰∏éÊµÅÁ®ã ‰∏∫‰ªÄ‰πà‰ΩøÁî®One-Hot\nÈÄöËøáÂ∞ÜÁ±ªÂà´Êò†Â∞Ñ‰∏∫ÂêëÈáèÔºåÈÅøÂÖçÊï¥Êï∞ÁºñÁ†ÅÂºïÂÖ•ÁöÑ‰º™Êï∞ÂÄºÂÖ≥Á≥ª„ÄÇ ÂêåÊó∂‰øùÁïôÂêÑÁßçÂèØËÉΩÁ±ªÂà´ÁöÑ‰ø°ÊÅØÔºå‰∏î‰ªÖÂú®ÂØπÂ∫î‰ΩçÁΩÆ‰∏∫1ÔºåÂÖ∂‰ªñ‰ΩçÁΩÆ‰∏∫0„ÄÇ Âª∫Á´ãÊò†Â∞ÑÔºö‰ªéÁ±ªÂà´Âà∞Á¥¢Âºï\n‰∏∫ÊØè‰∏™Á±ªÂà´ÂàÜÈÖç‰∏Ä‰∏™ÂîØ‰∏ÄÁ¥¢ÂºïÔºåÈÄöÂ∏∏‰ªé1ÂºÄÂßã„ÄÇ È¢ÑÁïôÁ¥¢Âºï0Ë°®Á§∫‚ÄúÊú™Áü•‚ÄùÊàñ‚ÄúÁº∫Â§±‚ÄùÔºåÂØπÂ∫îÂÖ®0ÂêëÈáè„ÄÇ ËΩ¨Êç¢‰∏∫One-HotÂêëÈáè\nËã•Á±ªÂà´ÊÄªÊï∞‰∏∫197ÔºåÂàôÁî®197Áª¥ÂêëÈáèË°®Á§∫„ÄÇ ‰æãÂ≠êÔºöÁæéÂõΩ [1, 0, 0, 0, ‚Ä¶]Ôºå ‰∏≠ÂõΩ [0, 1, 0, 0, ‚Ä¶]„ÄÇ Á§∫‰æãÔºöË°®Á§∫‰∏Ä‰∏™‰∫∫ÁöÑÁâπÂæÅ\nÁâπÂæÅÂåÖÂê´ÔºàÂπ¥ÈæÑ, ÊÄßÂà´, ÂõΩÁ±çÔºåÂÖ∂‰∏≠ÂõΩÁ±ç197ÁßçÔºâ Áª¥Â∫¶ÊÄªÂíåÔºö1Áª¥_age + 1Áª¥_gender + 197Áª¥_nationality = 199Áª¥„ÄÇ ‰æãÂ¶Ç (28, Â•≥, ‰∏≠ÂõΩ) ‚Üí [28, 0, 0, 1, 0, ‚Ä¶, 0]„ÄÇ ‰∏â„ÄÅÊñáÊú¨Êï∞ÊçÆÂ§ÑÁêÜÊµÅÁ®ã ÊñáÊú¨Âú®Ëá™ÁÑ∂ËØ≠Ë®ÄÂ§ÑÁêÜÔºàNLPÔºâ‰∏≠‰Ωú‰∏∫Â∏∏ËßÅÁöÑÂéüÂßãËæìÂÖ•ÔºåÈúÄË¶ÅÊï∞ÂÄºÂåñÊâçËÉΩÈÄÅÂÖ•Ê®°Âûã„ÄÇ‰∏ÄËà¨Ê≠•È™§Â¶Ç‰∏ãÔºö\nÂàÜËØç (Tokenization)\nÂ∞ÜÊñáÊú¨ÊãÜÂàÜ‰∏∫‰∏Ä‰∏™‰∏™ÂçïËØçÔºàTokenÔºâ„ÄÇ ‰æãÂ≠êÔºö\u0026quot;... to be or not to be...\u0026quot; ‚Üí [\u0026quot;...\u0026quot;, \u0026quot;to\u0026quot;, \u0026quot;be\u0026quot;, \u0026quot;or\u0026quot;, \u0026quot;not\u0026quot;, \u0026quot;to\u0026quot;, \u0026quot;be\u0026quot;, \u0026quot;...\u0026quot;]„ÄÇ ÁªüËÆ°ËØçÈ¢ë \u0026amp; ÊûÑÂª∫ËØçÂÖ∏\nËØçÈ¢ëÁªüËÆ° Áî®ÂìàÂ∏åË°®/Â≠óÂÖ∏ËÆ∞ÂΩïÊØè‰∏™ÂçïËØçÂá∫Áé∞Ê¨°Êï∞„ÄÇ ÈÅçÂéÜÊñáÊú¨Êó∂ÔºåËã•ÂçïËØçÂ∞öÊú™ÂÖ•Ë°®ÔºåÂàôÊñ∞Âª∫ËÆ∞ÂΩïÔºõËã•Â∑≤Â≠òÂú®ÔºåÂàôËÆ°Êï∞+1„ÄÇ ÊéíÂ∫è‰∏éÁ¥¢Âºï ÊåâËØçÈ¢ëÈôçÂ∫èÊéíÂ∫èÔºåËØçÈ¢ëÊúÄÈ´òÁöÑÂçïËØçÊéíÂú®ÂâçÈù¢„ÄÇ Á¥¢Âºï‰ªé1ÂºÄÂßãÔºå0ÁïôÁªô‚ÄúÊú™Áü•‚Äù„ÄÇ ËØçÂÖ∏ËßÑÊ®°ÔºàvocabularyÔºâÂèØËßÜÈúÄÊ±ÇÊà™Êñ≠Ôºà‰æãÂ¶ÇÂè™‰øùÁïôTop 10kÔºâ„ÄÇ ‰∏∫‰ªÄ‰πàÁßªÈô§‰ΩéÈ¢ëËØç ‰ΩéÈ¢ëËØçÂèØËÉΩÊòØÊãºÂÜôÈîôËØØ„ÄÅÁΩïËßÅ‰∫∫ÂêçÁ≠âÔºåÂØπÊ®°ÂûãÂ∏ÆÂä©ÊúâÈôê„ÄÇ ÂáèÂ∞ëËØçÂÖ∏ËßÑÊ®°ÂèØÈôç‰ΩéËøêÁÆóÂºÄÈîÄ„ÄÅÂä†Âø´Ê®°ÂûãËÆ≠ÁªÉ‰∏éÊé®ÁêÜÈÄüÂ∫¶„ÄÇ Áã¨ÁÉ≠ÁºñÁ†Å (One-Hot Encoding)\nÂ∞ÜÊØè‰∏™ÂçïËØçÊò†Â∞Ñ‰∏∫ËØçÂÖ∏‰∏≠ÁöÑÁ¥¢ÂºïÂêéÔºàÂ¶Ç [2, 4, 1, 8, ‚Ä¶]ÔºâÔºåÂèØËøõ‰∏ÄÊ≠•ËΩ¨Êç¢ÊàêOne-HotÂêëÈáè„ÄÇ One-HotÁª¥Â∫¶ÂèñÂÜ≥‰∫é‰øùÁïô‰∏ãÊù•ÁöÑËØçÂÖ∏Â§ßÂ∞èÔºà‰æãÂ¶Ç1‰∏áÔºâ„ÄÇ Êú™Êî∂ÂΩïÂçïËØçÂèØËÉΩÁõ¥Êé•ÂøΩÁï•ÔºåÊàñÁªü‰∏ÄÁî®Á¥¢Âºï0‰ª£Êõø„ÄÇ Âõõ„ÄÅÊ†∏ÂøÉÊî∂Ëé∑‰∏éÂ∫îÁî® Á±ªÂà´ÁâπÂæÅÂøÖÈúÄÊï∞ÂÄºÂåñÔºö\n‰ΩøÁî®Êï¥Êï∞1,2,3‚Ä¶‰ªÖË°®Á§∫Á±ªÂà´‚ÄúÊ†áËØÜ‚ÄùÔºåÂπ∂‰∏ç‰ª£Ë°®ÂÆÉ‰ª¨ÂèØËøõË°åÊï∞ÂÄºËøêÁÆó„ÄÇ Âõ†Ê≠§ÈúÄË¶ÅOne-HotÁ≠âÁºñÁ†ÅÊñπÂºèÔºåÈÅøÂÖçÊï∞ÂÄºËØØËß£„ÄÇ ÊñáÊú¨Êï∞ÊçÆÈ¢ÑÂ§ÑÁêÜÔºö\nÂàÜËØç„ÄÅËØçÈ¢ëÁªüËÆ°„ÄÅÊûÑÂª∫ËØçÂÖ∏„ÄÅÁ¥¢ÂºïÂåñ„ÄÅOne-HotÊàñÂÖ∂‰ªñÊñπÂºèÔºàÂ¶ÇËØçÂµåÂÖ•ÔºâÊòØÂ∏∏ËßÅÊµÅÁ®ã„ÄÇ Ê≠£Á°ÆÁöÑÊñáÊú¨È¢ÑÂ§ÑÁêÜÂèØÊòæËëóÂΩ±ÂìçÊ®°ÂûãÊÄßËÉΩÂíåÊïàÁéá„ÄÇ ‰øùÁïôÊú™Áü•Á¥¢ÂºïÔºö\n‰øùËØÅÂØπÁº∫Â§±Êï∞ÊçÆÊàñÂ≠óÂÖ∏Â§ñÊñ∞ËØçËÉΩÊúâÂü∫Êú¨ÁöÑË°®Á§∫ÔºåÊèêÂçáÊ®°ÂûãÂÆπÈîôÊÄß„ÄÇ ÂÆûÈôÖ‰ΩøÁî®Ôºö\nÂØπ‰∫éÂ∞èËßÑÊ®°Á±ªÂà´ÂèØÁõ¥Êé•One-HotÁºñÁ†ÅÔºõÂØπ‰∫éËØçÂÖ∏ÂæàÂ§ßÁöÑÂú∫ÊôØÔºåÈÄöÂ∏∏‰ºöËøõ‰∏ÄÊ≠•ËÄÉËôëËØçÂµåÂÖ•ÔºàWord EmbeddingÔºâÊàñÈ¢ÑËÆ≠ÁªÉËØ≠Ë®ÄÊ®°Âûã„ÄÇ ","permalink":"http://localhost:1313/posts/nlp-1/","summary":"\u003ch2 id=\"‰∏ÄÊï∞ÂÄºÁâπÂæÅ‰∏éÁ±ªÂà´ÁâπÂæÅ\"\u003e‰∏Ä„ÄÅÊï∞ÂÄºÁâπÂæÅ‰∏éÁ±ªÂà´ÁâπÂæÅ\u003c/h2\u003e\n\u003col\u003e\n\u003cli\u003e\u003cstrong\u003eÊï∞ÂÄºÁâπÂæÅ (Numeric Features)\u003c/strong\u003e\n\u003cul\u003e\n\u003cli\u003eÂÖ∑ÊúâÂèØÂä†ÂáèÁöÑÊÑè‰πâÔºå‰∏îÂ≠òÂú®Â§ßÂ∞èÈ°∫Â∫è„ÄÇ\u003c/li\u003e\n\u003cli\u003e‰æãÂ≠êÔºöÂπ¥ÈæÑ„ÄÅÊ∏©Â∫¶Á≠â„ÄÇÂèØ‰ª•Áõ¥Êé•‰øùÁïôÂÖ∂Êï¥Êï∞ÊàñÊµÆÁÇπÊï∞ÂΩ¢Âºè‰æõÊ®°Âûã‰ΩøÁî®„ÄÇ\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003eÁ±ªÂà´ÁâπÂæÅ (Categorical Features)\u003c/strong\u003e\n\u003cul\u003e\n\u003cli\u003eÊï∞ÊçÆÂÄºÁ¶ªÊï£Ôºå‰∏çÂÖ∑Â§á‚ÄúÊï∞ÂÄºÂ§ßÂ∞è‚ÄùÈó¥ÁöÑÂèØÊØîÊÑè‰πâ„ÄÇ\u003c/li\u003e\n\u003cli\u003e‰æãÂ≠êÔºöÂõΩÁ±çÔºàÁæéÂõΩ/‰∏≠ÂõΩ/Âç∞Â∫¶Á≠âÔºâ„ÄÅÊÄßÂà´ÔºàÁî∑/Â•≥ÔºâÁ≠â„ÄÇ\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003eÈóÆÈ¢ò\u003c/strong\u003eÔºöËã•‰ªÖÁî®Êï¥Êï∞Ë°®Á§∫ÔºàÁæéÂõΩ=1, ‰∏≠ÂõΩ=2ÔºâÔºå‰ºöÂºïÂÖ•ÈîôËØØÁöÑÊï∞ÂÄºËøêÁÆóÂÖ≥Á≥ªÔºåÂ¶Ç ‚ÄúÁæéÂõΩ + ‰∏≠ÂõΩ = Âç∞Â∫¶‚Äù„ÄÇ\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003c/ol\u003e\n\u003ch2 id=\"‰∫åone-hotÁºñÁ†ÅÁöÑÂä®Êú∫‰∏éÊµÅÁ®ã\"\u003e‰∫å„ÄÅOne-HotÁºñÁ†ÅÁöÑÂä®Êú∫‰∏éÊµÅÁ®ã\u003c/h2\u003e\n\u003col\u003e\n\u003cli\u003e\n\u003cp\u003e\u003cstrong\u003e‰∏∫‰ªÄ‰πà‰ΩøÁî®One-Hot\u003c/strong\u003e\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eÈÄöËøáÂ∞ÜÁ±ªÂà´Êò†Â∞Ñ‰∏∫ÂêëÈáèÔºåÈÅøÂÖçÊï¥Êï∞ÁºñÁ†ÅÂºïÂÖ•ÁöÑ‰º™Êï∞ÂÄºÂÖ≥Á≥ª„ÄÇ\u003c/li\u003e\n\u003cli\u003eÂêåÊó∂‰øùÁïôÂêÑÁßçÂèØËÉΩÁ±ªÂà´ÁöÑ‰ø°ÊÅØÔºå‰∏î‰ªÖÂú®ÂØπÂ∫î‰ΩçÁΩÆ‰∏∫1ÔºåÂÖ∂‰ªñ‰ΩçÁΩÆ‰∏∫0„ÄÇ\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003e\u003cstrong\u003eÂª∫Á´ãÊò†Â∞ÑÔºö‰ªéÁ±ªÂà´Âà∞Á¥¢Âºï\u003c/strong\u003e\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e‰∏∫ÊØè‰∏™Á±ªÂà´ÂàÜÈÖç‰∏Ä‰∏™ÂîØ‰∏ÄÁ¥¢ÂºïÔºåÈÄöÂ∏∏‰ªé1ÂºÄÂßã„ÄÇ\u003c/li\u003e\n\u003cli\u003eÈ¢ÑÁïôÁ¥¢Âºï0Ë°®Á§∫‚ÄúÊú™Áü•‚ÄùÊàñ‚ÄúÁº∫Â§±‚ÄùÔºåÂØπÂ∫îÂÖ®0ÂêëÈáè„ÄÇ\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003e\u003cstrong\u003eËΩ¨Êç¢‰∏∫One-HotÂêëÈáè\u003c/strong\u003e\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eËã•Á±ªÂà´ÊÄªÊï∞‰∏∫197ÔºåÂàôÁî®197Áª¥ÂêëÈáèË°®Á§∫„ÄÇ\u003c/li\u003e\n\u003cli\u003e‰æãÂ≠êÔºöÁæéÂõΩ \u003ccode\u003e[1, 0, 0, 0, ‚Ä¶]\u003c/code\u003eÔºå ‰∏≠ÂõΩ \u003ccode\u003e[0, 1, 0, 0, ‚Ä¶]\u003c/code\u003e„ÄÇ\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003e\u003cstrong\u003eÁ§∫‰æãÔºöË°®Á§∫‰∏Ä‰∏™‰∫∫ÁöÑÁâπÂæÅ\u003c/strong\u003e\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eÁâπÂæÅÂåÖÂê´ÔºàÂπ¥ÈæÑ, ÊÄßÂà´, ÂõΩÁ±çÔºåÂÖ∂‰∏≠ÂõΩÁ±ç197ÁßçÔºâ\u003c/li\u003e\n\u003cli\u003eÁª¥Â∫¶ÊÄªÂíåÔºö1Áª¥_age + 1Áª¥_gender + 197Áª¥_nationality = 199Áª¥„ÄÇ\u003c/li\u003e\n\u003cli\u003e‰æãÂ¶Ç \u003ccode\u003e(28, Â•≥, ‰∏≠ÂõΩ)\u003c/code\u003e ‚Üí \u003ccode\u003e[28, 0, 0, 1, 0, ‚Ä¶, 0]\u003c/code\u003e„ÄÇ\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003c/ol\u003e\n\u003ch2 id=\"‰∏âÊñáÊú¨Êï∞ÊçÆÂ§ÑÁêÜÊµÅÁ®ã\"\u003e‰∏â„ÄÅÊñáÊú¨Êï∞ÊçÆÂ§ÑÁêÜÊµÅÁ®ã\u003c/h2\u003e\n\u003cp\u003eÊñáÊú¨Âú®Ëá™ÁÑ∂ËØ≠Ë®ÄÂ§ÑÁêÜÔºàNLPÔºâ‰∏≠‰Ωú‰∏∫Â∏∏ËßÅÁöÑÂéüÂßãËæìÂÖ•ÔºåÈúÄË¶ÅÊï∞ÂÄºÂåñÊâçËÉΩÈÄÅÂÖ•Ê®°Âûã„ÄÇ‰∏ÄËà¨Ê≠•È™§Â¶Ç‰∏ãÔºö\u003c/p\u003e\n\u003col\u003e\n\u003cli\u003e\n\u003cp\u003e\u003cstrong\u003eÂàÜËØç (Tokenization)\u003c/strong\u003e\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eÂ∞ÜÊñáÊú¨ÊãÜÂàÜ‰∏∫‰∏Ä‰∏™‰∏™ÂçïËØçÔºàTokenÔºâ„ÄÇ\u003c/li\u003e\n\u003cli\u003e‰æãÂ≠êÔºö\u003ccode\u003e\u0026quot;... to be or not to be...\u0026quot;\u003c/code\u003e ‚Üí \u003ccode\u003e[\u0026quot;...\u0026quot;, \u0026quot;to\u0026quot;, \u0026quot;be\u0026quot;, \u0026quot;or\u0026quot;, \u0026quot;not\u0026quot;, \u0026quot;to\u0026quot;, \u0026quot;be\u0026quot;, \u0026quot;...\u0026quot;]\u003c/code\u003e„ÄÇ\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003e\u003cstrong\u003eÁªüËÆ°ËØçÈ¢ë \u0026amp; ÊûÑÂª∫ËØçÂÖ∏\u003c/strong\u003e\u003c/p\u003e","title":""},{"content":"Text to Sequence ÊñáÊú¨Â§ÑÁêÜ\nStep1: Tokenization\nTokenization breaks a piece of text down into a list of tokens.\nHere, a token is a word. (A token can be a character in some applications.)\nTokenizationËÆ≤Á©∂ÂæàÂ§öÔºå‰æãÂ¶ÇÊòØÂê¶Â∫îËØ•ÊääÂ§ßÂÜôÊîπÊàêÂ∞èÂÜôÂë¢ÔºüËøõË°åtypo correctionÁ≠âÁ≠â\nStep2: Build Dictionary\nUse a dictionary (hash table) to count word frequencies.\nThe dictionary maps word to index.\nÂèØ‰ª•È¶ñÂÖàÁªüËÆ°ËØçÈ¢ëÂéªÊéâ‰ΩéÈ¢ëËØçÔºåÁÑ∂ÂêéËÆ©ÊØè‰∏™ËØçÂØπÂ∫î‰∏Ä‰∏™Ê≠£Êï¥Êï∞ÔºõËøôÊ†∑ÁöÑËØùÔºå‰∏ÄÂè•ËØùÂ∞±ÂèØ‰ª•Áî®‰∏Ä‰∏™Ê≠£Êï¥Êï∞ÂàóË°®Ë°®Á§∫ÔºåËøô‰∏™ÂàóË°®Â∞±Âè´sequenceÔºõÂ¶ÇÊûúÂøÖË¶ÅÂ∞±ËøòÂæóÂÅöone-hot encoding„ÄÇ\nÁªìÊûú\n‰ΩÜÊòØÈïøÂ∫¶‰∏çÁªü‰∏Ä\nStep4: ÂØπÈΩêsequence\nËß£ÂÜ≥ÊñπÊ°àÊòØËøôÊ†∑ÁöÑÔºöÂèØ‰ª•Âõ∫ÂÆöÈïøÂ∫¶‰∏∫wÔºåÂä†ÂÖ•‰∏Ä‰∏™Â∫èÂàóÈïøÂ∫¶Â§™ÈïøÔºåÂ∞±Á†çÊéâÂâçÈù¢ÁöÑËØçÔºåÂè™‰øùÁïôÊúÄÂêéw‰∏™ËØçÔºõÂ¶ÇÊûú‰∏Ä‰∏™Â∫èÂàóÂ§™Áü≠ÔºåÂ∞±ÂÅözero paddingÔºåÁî®0Â°´ÂÖÖ\nËøôÊ†∑‰∏ÄÊù•ÔºåÊâÄÊúâÁöÑÂ∫èÂàóÈïøÂ∫¶Â∞±Áªü‰∏Ä‰∫Ü\nÊñáÊú¨Â§ÑÁêÜÂÆåÊàê‰∫ÜÔºåÊé•‰∏ãÊù•ÊòØword embeddingÔºåÊääÂçïËØçË°®Á§∫‰∏∫‰∏Ä‰∏™‰ΩéÁª¥ÂêëÈáèÔºõ\nÁÑ∂ËÄåËøôÊ†∑ÂÅöÁöÑËØùÔºåÂ¶ÇÊûúÊòØ10000‰∏™ÂçïËØçÔºåÁª¥Â∫¶Â∞±ÊòØ10000Áª¥ÔºåÁª¥Â∫¶Â§™È´ò‰∫ÜÔºõÂõ†Ê≠§Ë¶ÅÂÅöword embeddingÔºõ\nÂÖ∑‰ΩìÂÅöÊ≥ïÂ∞±ÊòØÊääone-hotÂêëÈáèe_iÂíåÂèÇÊï∞Áü©ÈòµpÁõ∏‰πòÔºõÁü©ÈòµPËΩ¨ÁΩÆÁöÑÂ§ßÂ∞èÊòØd x vÔºõdÊòØËØçÂêëÈáèÁöÑÁª¥Â∫¶ÔºõvÊòØÂ≠óÂÖ∏ÈáåËØçÊ±áÁöÑÊï∞ÈáèÔºõÁªìÊûú‰∏∫x_iÔºõx_iÂ∞±ÊòØ‰∏Ä‰∏™ËØçÂêëÈáèÔºõÂ¶ÇÊûúone-hotÂêëÈáèÁöÑÁ¨¨‰∏âË°å‰∏∫1ÔºõÈÇ£‰πàx_iÂ∞±ÊòØPËΩ¨ÁΩÆÁü©ÈòµÁöÑÁ¨¨‰∏âÂàóÔºàÂÖ∂‰ΩôÂàóÈÉΩ‰∏∫0ÔºâÔºõÊâÄ‰ª•PËΩ¨ÁΩÆÊØè‰∏ÄÂàóÈÉΩÊòØ‰∏Ä‰∏™ËØçÂêëÈáèÔºõÊâÄ‰ª•Áü©ÈòµPÊú¨Ë∫´ÁöÑÊØè‰∏ÄË°åÂ∞±ÊòØ‰∏Ä‰∏™ËØçÂêëÈáèÔºõÂÖ∂Ë°åÊï∞‰∏∫vÔºõÂç≥vocabularyÔºåËØçÊ±áÈáèÔºõÊØè‰∏ÄË°åÂØπÂ∫î‰∏Ä‰∏™ÂçïËØçÔºõÁü©ÈòµÁöÑÂàóÊï∞‰∏∫dÔºõdÊòØÁî®Êà∑ÂÜ≥ÂÆöÁöÑÔºõdÁöÑÂ§ßÂ∞è‰ºöÂÜ≥ÂÆöÊú∫Âô®Â≠¶‰π†Ê®°ÂûãÁöÑË°®Áé∞ÔºõÂ∫îËØ•Áî®xxxÊù•ÈÄâÊã©‰∏Ä‰∏™ÊØîËæÉÂ•ΩÁöÑdÔºõ\nÊàë‰ª¨ÁöÑ‰ªªÂä°ÊòØÁúãËØÑËÆ∫ÊòØÊ≠£Èù¢ÁöÑËøòÊòØË¥üÈù¢ÁöÑÔºõÂèÇÊï∞Áü©ÈòµÊòØ‰ªéËÆ≠ÁªÉÊï∞ÊçÆ‰∏≠Â≠¶‰π†Âá∫Êù•ÁöÑÔºåÊâÄ‰ª•Â≠¶Âá∫Êù•ÁöÑËØçÂêëÈáèÊòØÂ∏¶ÊúâÊÑüÊÉÖËâ≤ÂΩ©ÁöÑÔºõÂÅáËÆæËøô‰∫õËØçÂêëÈáèÈÉΩÊòØ‰∫åÁª¥ÁöÑÔºåÂàôÂèØ‰ª•Âú®Âπ≥Èù¢ÂùêÊ†áÁ≥ª‰∏≠Ê†áÂá∫‰∏ãÈù¢ËØçÂêëÈáè\nkerasÊèê‰æõembeddingÂ±ÇÔºõÁî®Êà∑ÂèØ‰ª•ÊåáÂÆövocabularyÂ§ßÂ∞èÂíådÁöÑÂ§ßÂ∞èÔºõ‰ª•ÂèäÊØè‰∏Ä‰∏™sequenceÁöÑÈïøÂ∫¶ÔºõdÊòØÊ†πÊçÆÁÆóÊ≥ïÈÄâÂá∫Êù•ÁöÑ Âà∞Ëøô‰∏ÄÊ≠•ÔºåÊàë‰ª¨Â∑≤ÁªèÂÆåÊàê‰∫ÜÊñáÊú¨Â§ÑÁêÜÂíåword embedding„ÄÇÊé•‰∏ãÊù•Â∞±ÊòØÁî®Logistic Regression for Binary ClassificationÂÅö‰∫åÂàÜÁ±ªÔºõ\n","permalink":"http://localhost:1313/posts/nlp-2/","summary":"\u003ch3 id=\"text-to-sequence\"\u003eText to Sequence\u003c/h3\u003e\n\u003cp\u003eÊñáÊú¨Â§ÑÁêÜ\u003c/p\u003e\n\u003cp\u003eStep1: Tokenization\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\n\u003cp\u003eTokenization breaks a piece of text down into a list of tokens.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003eHere, a token is a word. (A token can be a character in some applications.)\u003c/p\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003eTokenizationËÆ≤Á©∂ÂæàÂ§öÔºå‰æãÂ¶ÇÊòØÂê¶Â∫îËØ•ÊääÂ§ßÂÜôÊîπÊàêÂ∞èÂÜôÂë¢ÔºüËøõË°åtypo correctionÁ≠âÁ≠â\u003c/p\u003e\n\u003cp\u003e\u003cimg alt=\"image-20250322150322238\" loading=\"lazy\" src=\"./NLP-2.assets/image-20250322150322238.png\"\u003e\u003c/p\u003e\n\u003cp\u003eStep2: Build Dictionary\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\n\u003cp\u003eUse a dictionary (hash table) to count word frequencies.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003eThe dictionary maps word to index.\u003c/p\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003eÂèØ‰ª•È¶ñÂÖàÁªüËÆ°ËØçÈ¢ëÂéªÊéâ‰ΩéÈ¢ëËØçÔºåÁÑ∂ÂêéËÆ©ÊØè‰∏™ËØçÂØπÂ∫î‰∏Ä‰∏™Ê≠£Êï¥Êï∞ÔºõËøôÊ†∑ÁöÑËØùÔºå‰∏ÄÂè•ËØùÂ∞±ÂèØ‰ª•Áî®‰∏Ä‰∏™Ê≠£Êï¥Êï∞ÂàóË°®Ë°®Á§∫ÔºåËøô‰∏™ÂàóË°®Â∞±Âè´sequenceÔºõÂ¶ÇÊûúÂøÖË¶ÅÂ∞±ËøòÂæóÂÅöone-hot encoding„ÄÇ\u003cimg alt=\"image-20250322150620890\" loading=\"lazy\" src=\"./NLP-2.assets/image-20250322150620890.png\"\u003e\u003c/p\u003e\n\u003cp\u003eÁªìÊûú\u003c/p\u003e\n\u003cp\u003e\u003cimg alt=\"image-20250322150754528\" loading=\"lazy\" src=\"./NLP-2.assets/image-20250322150754528.png\"\u003e\u003c/p\u003e\n\u003cp\u003e‰ΩÜÊòØÈïøÂ∫¶‰∏çÁªü‰∏Ä\u003c/p\u003e\n\u003cp\u003eStep4: ÂØπÈΩêsequence\u003c/p\u003e\n\u003cp\u003e\u003cimg alt=\"image-20250322150854986\" loading=\"lazy\" src=\"./NLP-2.assets/image-20250322150854986.png\"\u003e\u003c/p\u003e\n\u003cp\u003eËß£ÂÜ≥ÊñπÊ°àÊòØËøôÊ†∑ÁöÑÔºöÂèØ‰ª•Âõ∫ÂÆöÈïøÂ∫¶‰∏∫wÔºåÂä†ÂÖ•‰∏Ä‰∏™Â∫èÂàóÈïøÂ∫¶Â§™ÈïøÔºåÂ∞±Á†çÊéâÂâçÈù¢ÁöÑËØçÔºåÂè™‰øùÁïôÊúÄÂêéw‰∏™ËØçÔºõÂ¶ÇÊûú‰∏Ä‰∏™Â∫èÂàóÂ§™Áü≠ÔºåÂ∞±ÂÅözero paddingÔºåÁî®0Â°´ÂÖÖ\u003c/p\u003e\n\u003cp\u003e\u003cimg alt=\"image-20250322151030119\" loading=\"lazy\" src=\"./NLP-2.assets/image-20250322151030119.png\"\u003e\u003c/p\u003e\n\u003cp\u003eËøôÊ†∑‰∏ÄÊù•ÔºåÊâÄÊúâÁöÑÂ∫èÂàóÈïøÂ∫¶Â∞±Áªü‰∏Ä‰∫Ü\u003c/p\u003e\n\u003cp\u003e\u003cimg alt=\"image-20250322151117125\" loading=\"lazy\" src=\"./NLP-2.assets/image-20250322151117125.png\"\u003e\u003c/p\u003e\n\u003cp\u003eÊñáÊú¨Â§ÑÁêÜÂÆåÊàê‰∫ÜÔºåÊé•‰∏ãÊù•ÊòØword embeddingÔºåÊääÂçïËØçË°®Á§∫‰∏∫‰∏Ä‰∏™‰ΩéÁª¥ÂêëÈáèÔºõ\u003c/p\u003e\n\u003cp\u003e\u003cimg alt=\"image-20250322151252837\" loading=\"lazy\" src=\"./NLP-2.assets/image-20250322151252837.png\"\u003e\u003c/p\u003e","title":""},{"content":"üëã About me Hello! I‚Äôm Xu Zongsi, a passionate technology enthusiast currently pursuing my Master of Science in Electronic Commerce \u0026amp; Internet Computing at The University of Hong Kong. With a solid background in Software Engineering from the Beijing Institute of Technology, I specialize in emerging areas of artificial intelligence, including machine learning, deep learning, natural language processing, computer vision, and reinforcement learning.\nRecently, inspired by OpenAI\u0026rsquo;s five-step plan towards superintelligence, I have great expectations for AGI and developed a strong interest in LLM agents, MLLM, reinforcement learning, and knowledge graphs. I believe there is significant potential in these fields to create innovative solutions, and I hope to contribute my efforts towards that goal.\nI aspire to contribute to the advancement of AGI by utilizing a diverse set of skills and techniques to develop innovative solutions.\nHello! I‚Äôm Xu Zongsi, a passionate technology enthusiast currently pursuing my Master of Science in ECIC at The University of Hong Kong. With a solid background in Software Engineering from the Beijing Institute of Technology, I specialize in emerging areas of artificial intelligence, including machine learning, deep learning, natural language processing, computer vision, and reinforcement learning.\nI have a strong interest in developing LLM agents and knowledge graphs, leveraging data science techniques for innovative solutions. Additionally, I am skilled in software development, aiming to create impactful applications that enhance user experiences.\nThroughout my academic journey, I have been involved in several innovative projects focused on fraud detection, intelligent text processing, and quantum computing applications in deep learning. My programming skills span languages like Python and Java, with experience in frameworks such as PyTorch.\nWhen I‚Äôm not coding, you can find me exploring new technologies, sharing insights on my blog, or engaging in community activities related to cyber security.\nüìö Education üá≠üá∞ The University of Hong Kong 09/2024 - Expected 11/2025 School of Computing and Data Science Master of Science in Electronic Commerce \u0026amp; Internet Computing Relevant Courses: Machine learning for business and e-commerce, Knowledge graphs, Financial fraud analytics, Internet infrastructure technologies, Website engineering, Blockchain and cryptocurrency, etc. üá®üá≥ Beijing Institute of Technology 09/2020 - 06/2024 School of Computer Science \u0026amp; Technology Bachelor of Engineering in Software Engineering, last two years GPA: 3.7/4 Relevant Courses: Reinforcement Learning, Deep Learning and Computer Vision, Artificial Intelligence and Robot Ethics, Almost Human: Mind, Brain and Artificial Intelligence, Mathematical Analysis for Engineering, Linear Algebra, Probability and Mathematical Statistics, etc. Skills: Python, Java, common data structures, design patterns, machine learning basics and algorithms, Linux, PyTorch, and some development tools (git, conda, etc.). üèÜ Awards \u0026amp; Honors Beijing Institute of Technology Undergraduate Scholarship (Top 20% of Grade) 06/2023 3rd Prize of China International \u0026#34;Internet \u0026#43;\u0026#34; College Student\u0026#39;s Innovation Competition 08/2022 Bronze Prize of \u0026#34;Challenge Cup\u0026#34; Capital University Entrepreneurship Competition 05/2022 üíº Project Experience Online Transaction Fraud Detection 09/2024 ‚Äì 01/2025 Independent project, supervised by Dr. Vivien Chan Focused on addressing financial fraud in e-commerce to enhance the accuracy of transaction anomaly detection, while independently managing the entire case study that included data preprocessing, feature engineering, model building, evaluation, and results analysis. Effectively resolved class imbalance issues using SMOTE and ROSE techniques. Built various models including Logistic Regression, Random Forest, XGBoost, and LightGBM, ultimately selecting the LightGBM model to achieve a recall rate of 95.45% and an AUC of 99.84%. Wrote efficient and maintainable code, enhancing model training and data processing efficiency through parallel computing and logging. Multi-Model Intelligent Text Keyword Extraction System 08/2023 ‚Äì 09/2023 Group project, supervised by Associate Prof. Xiaolin Zhao Designed and implemented an intelligent text summary system that automatically extracts keywords from article titles and abstracts, enhancing the understanding and summarization of text information. Participated in the planning of the technical route and built a hybrid model combining extractive and generative approaches, utilizing advanced natural language processing techniques including KeyBERT, Sentence Transformer, BERT, and T5 models. Responsible for data preprocessing and tokenization, as well as the end-to-end implementation and training of the T5 model, optimizing the model architecture and hyperparameters, achieving satisfactory results after only 3 epochs of training. Model evaluation results showed that the Rouge-1, Rouge-2, and Rouge-L metrics reached 0.6345, 0.5038, and 0.5282, respectively, in the third epoch, validating the model\u0026rsquo;s effectiveness in the summarization task. Cambridge University Machine Learning Summer Project 07/2023 ‚Äì 08/2023 Group project, supervised by Prof. Pietro Li√≤ Participated in the Cambridge University deep learning summer project, focusing on deep reinforcement learning; explored multi-agent learning algorithms across different environments. Reproduced the Multi-Agent Deep Deterministic Policy Gradient (MADDPG) algorithm in the Simple Adversary environment and studied the effect of agent numbers on convergence speed and stability, finding optimal stability at 21 agents. Designed and implemented comparative experiments inspired by the Rainbow algorithm, assessing target network strategies versus the Double Deep Q-Network (Double DQN). The results demonstrated that Double DQN significantly enhanced convergence speed, optimizing the overall learning process. Co-authored a group project paper on agent numbers and strategies effectiveness in multi-agent systems, achieving a score of 71% in the summer program (the highest in my group) and a \u0026ldquo;First Class\u0026rdquo; classification in the UK grading system. Deep Learning and Computer Vision Semester Project 09/2022 ‚Äì 12/2022 Independent project, supervised by Associate Prof. Guangyu Gao Designed and implemented a waste classifier using the ResNet model to improve classification accuracy and reduce resource waste. The project also enhanced understanding of transfer learning techniques with ResNet. Collected a dataset of 16 waste categories and preprocessed the images for uniformity and standardization, incorporating data augmentation techniques to enhance the dataset. Conducted experiments using ResNet34 and ResNet50 models through transfer learning, accelerating network convergence by leveraging pretrained weights. During training, techniques such as Batch Normalization and Dropout were applied to mitigate the risk of overfitting. The final model achieved an accuracy of 90% on the training set, while the performance on the test set was 61%, indicating a significant overfitting phenomenon during the training process. üéì Internship Beijing Academy of Quantum Information Science 08/2023 ‚Äì 01/2024 Research Intern at Quantum Computation Department Proposed a quantum convolution kernel design based on variational quantum circuits and developed a universal quantum convolution layer, successfully integrating it into classical CNN architectures such as VGG, GoogLeNet, and ResNet. Developed and evaluated various hybrid models, including a simple model named HQCCNN-2, which achieved 84.45% accuracy on the FashionMNIST dataset, surpassing the traditional CNN\u0026rsquo;s 80.72%. This demonstrates the effectiveness of the quantum convolution layer in improving model performance. Tested on a real quantum computer further validated the effectiveness of the hybrid model, demonstrating the viable integration of quantum computing with deep learning, and highlighting the potential for leveraging quantum properties to enhance model performance. üèÖ Competition Experience China International \u0026#34;Internet \u0026#43;\u0026#34; College Students\u0026#39; Innovation Competition 08/2022 Zhongke Ushield: Deep Learning-based Face Privacy Protection Authentication System Responsible for constructing a localized facial feature extraction engine based on MobileFaceNet, ensuring feature extraction is completed on end devices (such as mobile phones and cameras), guaranteeing that raw data does not leave the domain and is not stored, thus enhancing user privacy protection while improving recognition efficiency. \u0026#34;Challenge Cup\u0026#34; Capital University Entrepreneurship Competition 05/2022 Smart Orchard Responsible for the development of the fruit detection, ripeness prediction, and pest identification system, using deep convolutional neural network (CNN) technology for intelligent monitoring of crop growth conditions. Applied advanced object detection algorithms such as Faster R-CNN and YOLO to achieve high precision in apple detection and ripeness assessment, with an accuracy rate exceeding 90%, significantly enhancing the intelligence level of orchard management. Built and trained a dedicated dataset containing various pest samples, optimizing pest detection accuracy through data preprocessing (such as image normalization and resizing) and data augmentation techniques (like rotation, flipping, and noise addition), enabling the real-time monitoring system to accurately identify over 80% of pests, providing effective scientific maintenance recommendations to help farmers reduce crop losses. üìã Extracurricular Activities Vice President, Cyber Security Club, Beijing Institute of Technology 09/2021-09/2022 Backbone, Media Center of the Student Union of Beijing Institute of Technology 10/2020-06/2021 üì´ Contact üìß zongsi.xu@outlook.com üëî Zongsi (Tristan) Xu üíª github.com/BaizeXS üìç Hong Kong SAR, China ","permalink":"http://localhost:1313/resume/","summary":"Personal resume of Zongsi (Tristan) Xu","title":"Zongsi (Tristan) Xu"},{"content":"‰∏Ä„ÄÅÊï∞ÂÄºÁâπÂæÅ‰∏éÁ±ªÂà´ÁâπÂæÅ Êï∞ÂÄºÁâπÂæÅ (Numeric Features) ÂÖ∑ÊúâÂèØÂä†ÂáèÁöÑÊÑè‰πâÔºå‰∏îÂ≠òÂú®Â§ßÂ∞èÈ°∫Â∫è„ÄÇ ‰æãÂ≠êÔºöÂπ¥ÈæÑ„ÄÅÊ∏©Â∫¶Á≠â„ÄÇÂèØ‰ª•Áõ¥Êé•‰øùÁïôÂÖ∂Êï¥Êï∞ÊàñÊµÆÁÇπÊï∞ÂΩ¢Âºè‰æõÊ®°Âûã‰ΩøÁî®„ÄÇ Á±ªÂà´ÁâπÂæÅ (Categorical Features) Êï∞ÊçÆÂÄºÁ¶ªÊï£Ôºå‰∏çÂÖ∑Â§á‚ÄúÊï∞ÂÄºÂ§ßÂ∞è‚ÄùÈó¥ÁöÑÂèØÊØîÊÑè‰πâ„ÄÇ ‰æãÂ≠êÔºöÂõΩÁ±çÔºàÁæéÂõΩ/‰∏≠ÂõΩ/Âç∞Â∫¶Á≠âÔºâ„ÄÅÊÄßÂà´ÔºàÁî∑/Â•≥ÔºâÁ≠â„ÄÇ ÈóÆÈ¢òÔºöËã•‰ªÖÁî®Êï¥Êï∞Ë°®Á§∫ÔºàÁæéÂõΩ=1, ‰∏≠ÂõΩ=2ÔºâÔºå‰ºöÂºïÂÖ•ÈîôËØØÁöÑÊï∞ÂÄºËøêÁÆóÂÖ≥Á≥ªÔºåÂ¶Ç ‚ÄúÁæéÂõΩ + ‰∏≠ÂõΩ = Âç∞Â∫¶‚Äù„ÄÇ ‰∫å„ÄÅOne-HotÁºñÁ†ÅÁöÑÂä®Êú∫‰∏éÊµÅÁ®ã ‰∏∫‰ªÄ‰πà‰ΩøÁî®One-Hot\nÈÄöËøáÂ∞ÜÁ±ªÂà´Êò†Â∞Ñ‰∏∫ÂêëÈáèÔºåÈÅøÂÖçÊï¥Êï∞ÁºñÁ†ÅÂºïÂÖ•ÁöÑ‰º™Êï∞ÂÄºÂÖ≥Á≥ª„ÄÇ ÂêåÊó∂‰øùÁïôÂêÑÁßçÂèØËÉΩÁ±ªÂà´ÁöÑ‰ø°ÊÅØÔºå‰∏î‰ªÖÂú®ÂØπÂ∫î‰ΩçÁΩÆ‰∏∫1ÔºåÂÖ∂‰ªñ‰ΩçÁΩÆ‰∏∫0„ÄÇ Âª∫Á´ãÊò†Â∞ÑÔºö‰ªéÁ±ªÂà´Âà∞Á¥¢Âºï\n‰∏∫ÊØè‰∏™Á±ªÂà´ÂàÜÈÖç‰∏Ä‰∏™ÂîØ‰∏ÄÁ¥¢ÂºïÔºåÈÄöÂ∏∏‰ªé1ÂºÄÂßã„ÄÇ È¢ÑÁïôÁ¥¢Âºï0Ë°®Á§∫‚ÄúÊú™Áü•‚ÄùÊàñ‚ÄúÁº∫Â§±‚ÄùÔºåÂØπÂ∫îÂÖ®0ÂêëÈáè„ÄÇ ËΩ¨Êç¢‰∏∫One-HotÂêëÈáè\nËã•Á±ªÂà´ÊÄªÊï∞‰∏∫197ÔºåÂàôÁî®197Áª¥ÂêëÈáèË°®Á§∫„ÄÇ ‰æãÂ≠êÔºöÁæéÂõΩ [1, 0, 0, 0, ‚Ä¶]Ôºå ‰∏≠ÂõΩ [0, 1, 0, 0, ‚Ä¶]„ÄÇ Á§∫‰æãÔºöË°®Á§∫‰∏Ä‰∏™‰∫∫ÁöÑÁâπÂæÅ\nÁâπÂæÅÂåÖÂê´ÔºàÂπ¥ÈæÑ, ÊÄßÂà´, ÂõΩÁ±çÔºåÂÖ∂‰∏≠ÂõΩÁ±ç197ÁßçÔºâ Áª¥Â∫¶ÊÄªÂíåÔºö1Áª¥_age + 1Áª¥_gender + 197Áª¥_nationality = 199Áª¥„ÄÇ ‰æãÂ¶Ç (28, Â•≥, ‰∏≠ÂõΩ) ‚Üí [28, 0, 0, 1, 0, ‚Ä¶, 0]„ÄÇ ‰∏â„ÄÅÊñáÊú¨Êï∞ÊçÆÂ§ÑÁêÜÊµÅÁ®ã ÊñáÊú¨Âú®Ëá™ÁÑ∂ËØ≠Ë®ÄÂ§ÑÁêÜÔºàNLPÔºâ‰∏≠‰Ωú‰∏∫Â∏∏ËßÅÁöÑÂéüÂßãËæìÂÖ•ÔºåÈúÄË¶ÅÊï∞ÂÄºÂåñÊâçËÉΩÈÄÅÂÖ•Ê®°Âûã„ÄÇ‰∏ÄËà¨Ê≠•È™§Â¶Ç‰∏ãÔºö\nÂàÜËØç (Tokenization)\nÂ∞ÜÊñáÊú¨ÊãÜÂàÜ‰∏∫‰∏Ä‰∏™‰∏™ÂçïËØçÔºàTokenÔºâ„ÄÇ ‰æãÂ≠êÔºö\u0026quot;... to be or not to be...\u0026quot; ‚Üí [\u0026quot;...\u0026quot;, \u0026quot;to\u0026quot;, \u0026quot;be\u0026quot;, \u0026quot;or\u0026quot;, \u0026quot;not\u0026quot;, \u0026quot;to\u0026quot;, \u0026quot;be\u0026quot;, \u0026quot;...\u0026quot;]„ÄÇ ÁªüËÆ°ËØçÈ¢ë \u0026amp; ÊûÑÂª∫ËØçÂÖ∏\nËØçÈ¢ëÁªüËÆ° Áî®ÂìàÂ∏åË°®/Â≠óÂÖ∏ËÆ∞ÂΩïÊØè‰∏™ÂçïËØçÂá∫Áé∞Ê¨°Êï∞„ÄÇ ÈÅçÂéÜÊñáÊú¨Êó∂ÔºåËã•ÂçïËØçÂ∞öÊú™ÂÖ•Ë°®ÔºåÂàôÊñ∞Âª∫ËÆ∞ÂΩïÔºõËã•Â∑≤Â≠òÂú®ÔºåÂàôËÆ°Êï∞+1„ÄÇ ÊéíÂ∫è‰∏éÁ¥¢Âºï ÊåâËØçÈ¢ëÈôçÂ∫èÊéíÂ∫èÔºåËØçÈ¢ëÊúÄÈ´òÁöÑÂçïËØçÊéíÂú®ÂâçÈù¢„ÄÇ Á¥¢Âºï‰ªé1ÂºÄÂßãÔºå0ÁïôÁªô‚ÄúÊú™Áü•‚Äù„ÄÇ ËØçÂÖ∏ËßÑÊ®°ÔºàvocabularyÔºâÂèØËßÜÈúÄÊ±ÇÊà™Êñ≠Ôºà‰æãÂ¶ÇÂè™‰øùÁïôTop 10kÔºâ„ÄÇ ‰∏∫‰ªÄ‰πàÁßªÈô§‰ΩéÈ¢ëËØç ‰ΩéÈ¢ëËØçÂèØËÉΩÊòØÊãºÂÜôÈîôËØØ„ÄÅÁΩïËßÅ‰∫∫ÂêçÁ≠âÔºåÂØπÊ®°ÂûãÂ∏ÆÂä©ÊúâÈôê„ÄÇ ÂáèÂ∞ëËØçÂÖ∏ËßÑÊ®°ÂèØÈôç‰ΩéËøêÁÆóÂºÄÈîÄ„ÄÅÂä†Âø´Ê®°ÂûãËÆ≠ÁªÉ‰∏éÊé®ÁêÜÈÄüÂ∫¶„ÄÇ Áã¨ÁÉ≠ÁºñÁ†Å (One-Hot Encoding)\nÂ∞ÜÊØè‰∏™ÂçïËØçÊò†Â∞Ñ‰∏∫ËØçÂÖ∏‰∏≠ÁöÑÁ¥¢ÂºïÂêéÔºàÂ¶Ç [2, 4, 1, 8, ‚Ä¶]ÔºâÔºåÂèØËøõ‰∏ÄÊ≠•ËΩ¨Êç¢ÊàêOne-HotÂêëÈáè„ÄÇ One-HotÁª¥Â∫¶ÂèñÂÜ≥‰∫é‰øùÁïô‰∏ãÊù•ÁöÑËØçÂÖ∏Â§ßÂ∞èÔºà‰æãÂ¶Ç1‰∏áÔºâ„ÄÇ Êú™Êî∂ÂΩïÂçïËØçÂèØËÉΩÁõ¥Êé•ÂøΩÁï•ÔºåÊàñÁªü‰∏ÄÁî®Á¥¢Âºï0‰ª£Êõø„ÄÇ Âõõ„ÄÅÊ†∏ÂøÉÊî∂Ëé∑‰∏éÂ∫îÁî® Á±ªÂà´ÁâπÂæÅÂøÖÈúÄÊï∞ÂÄºÂåñÔºö\n‰ΩøÁî®Êï¥Êï∞1,2,3‚Ä¶‰ªÖË°®Á§∫Á±ªÂà´‚ÄúÊ†áËØÜ‚ÄùÔºåÂπ∂‰∏ç‰ª£Ë°®ÂÆÉ‰ª¨ÂèØËøõË°åÊï∞ÂÄºËøêÁÆó„ÄÇ Âõ†Ê≠§ÈúÄË¶ÅOne-HotÁ≠âÁºñÁ†ÅÊñπÂºèÔºåÈÅøÂÖçÊï∞ÂÄºËØØËß£„ÄÇ ÊñáÊú¨Êï∞ÊçÆÈ¢ÑÂ§ÑÁêÜÔºö\nÂàÜËØç„ÄÅËØçÈ¢ëÁªüËÆ°„ÄÅÊûÑÂª∫ËØçÂÖ∏„ÄÅÁ¥¢ÂºïÂåñ„ÄÅOne-HotÊàñÂÖ∂‰ªñÊñπÂºèÔºàÂ¶ÇËØçÂµåÂÖ•ÔºâÊòØÂ∏∏ËßÅÊµÅÁ®ã„ÄÇ Ê≠£Á°ÆÁöÑÊñáÊú¨È¢ÑÂ§ÑÁêÜÂèØÊòæËëóÂΩ±ÂìçÊ®°ÂûãÊÄßËÉΩÂíåÊïàÁéá„ÄÇ ‰øùÁïôÊú™Áü•Á¥¢ÂºïÔºö\n‰øùËØÅÂØπÁº∫Â§±Êï∞ÊçÆÊàñÂ≠óÂÖ∏Â§ñÊñ∞ËØçËÉΩÊúâÂü∫Êú¨ÁöÑË°®Á§∫ÔºåÊèêÂçáÊ®°ÂûãÂÆπÈîôÊÄß„ÄÇ ÂÆûÈôÖ‰ΩøÁî®Ôºö\nÂØπ‰∫éÂ∞èËßÑÊ®°Á±ªÂà´ÂèØÁõ¥Êé•One-HotÁºñÁ†ÅÔºõÂØπ‰∫éËØçÂÖ∏ÂæàÂ§ßÁöÑÂú∫ÊôØÔºåÈÄöÂ∏∏‰ºöËøõ‰∏ÄÊ≠•ËÄÉËôëËØçÂµåÂÖ•ÔºàWord EmbeddingÔºâÊàñÈ¢ÑËÆ≠ÁªÉËØ≠Ë®ÄÊ®°Âûã„ÄÇ ","permalink":"http://localhost:1313/posts/nlp-1/","summary":"\u003ch2 id=\"‰∏ÄÊï∞ÂÄºÁâπÂæÅ‰∏éÁ±ªÂà´ÁâπÂæÅ\"\u003e‰∏Ä„ÄÅÊï∞ÂÄºÁâπÂæÅ‰∏éÁ±ªÂà´ÁâπÂæÅ\u003c/h2\u003e\n\u003col\u003e\n\u003cli\u003e\u003cstrong\u003eÊï∞ÂÄºÁâπÂæÅ (Numeric Features)\u003c/strong\u003e\n\u003cul\u003e\n\u003cli\u003eÂÖ∑ÊúâÂèØÂä†ÂáèÁöÑÊÑè‰πâÔºå‰∏îÂ≠òÂú®Â§ßÂ∞èÈ°∫Â∫è„ÄÇ\u003c/li\u003e\n\u003cli\u003e‰æãÂ≠êÔºöÂπ¥ÈæÑ„ÄÅÊ∏©Â∫¶Á≠â„ÄÇÂèØ‰ª•Áõ¥Êé•‰øùÁïôÂÖ∂Êï¥Êï∞ÊàñÊµÆÁÇπÊï∞ÂΩ¢Âºè‰æõÊ®°Âûã‰ΩøÁî®„ÄÇ\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003eÁ±ªÂà´ÁâπÂæÅ (Categorical Features)\u003c/strong\u003e\n\u003cul\u003e\n\u003cli\u003eÊï∞ÊçÆÂÄºÁ¶ªÊï£Ôºå‰∏çÂÖ∑Â§á‚ÄúÊï∞ÂÄºÂ§ßÂ∞è‚ÄùÈó¥ÁöÑÂèØÊØîÊÑè‰πâ„ÄÇ\u003c/li\u003e\n\u003cli\u003e‰æãÂ≠êÔºöÂõΩÁ±çÔºàÁæéÂõΩ/‰∏≠ÂõΩ/Âç∞Â∫¶Á≠âÔºâ„ÄÅÊÄßÂà´ÔºàÁî∑/Â•≥ÔºâÁ≠â„ÄÇ\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003eÈóÆÈ¢ò\u003c/strong\u003eÔºöËã•‰ªÖÁî®Êï¥Êï∞Ë°®Á§∫ÔºàÁæéÂõΩ=1, ‰∏≠ÂõΩ=2ÔºâÔºå‰ºöÂºïÂÖ•ÈîôËØØÁöÑÊï∞ÂÄºËøêÁÆóÂÖ≥Á≥ªÔºåÂ¶Ç ‚ÄúÁæéÂõΩ + ‰∏≠ÂõΩ = Âç∞Â∫¶‚Äù„ÄÇ\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003c/ol\u003e\n\u003ch2 id=\"‰∫åone-hotÁºñÁ†ÅÁöÑÂä®Êú∫‰∏éÊµÅÁ®ã\"\u003e‰∫å„ÄÅOne-HotÁºñÁ†ÅÁöÑÂä®Êú∫‰∏éÊµÅÁ®ã\u003c/h2\u003e\n\u003col\u003e\n\u003cli\u003e\n\u003cp\u003e\u003cstrong\u003e‰∏∫‰ªÄ‰πà‰ΩøÁî®One-Hot\u003c/strong\u003e\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eÈÄöËøáÂ∞ÜÁ±ªÂà´Êò†Â∞Ñ‰∏∫ÂêëÈáèÔºåÈÅøÂÖçÊï¥Êï∞ÁºñÁ†ÅÂºïÂÖ•ÁöÑ‰º™Êï∞ÂÄºÂÖ≥Á≥ª„ÄÇ\u003c/li\u003e\n\u003cli\u003eÂêåÊó∂‰øùÁïôÂêÑÁßçÂèØËÉΩÁ±ªÂà´ÁöÑ‰ø°ÊÅØÔºå‰∏î‰ªÖÂú®ÂØπÂ∫î‰ΩçÁΩÆ‰∏∫1ÔºåÂÖ∂‰ªñ‰ΩçÁΩÆ‰∏∫0„ÄÇ\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003e\u003cstrong\u003eÂª∫Á´ãÊò†Â∞ÑÔºö‰ªéÁ±ªÂà´Âà∞Á¥¢Âºï\u003c/strong\u003e\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e‰∏∫ÊØè‰∏™Á±ªÂà´ÂàÜÈÖç‰∏Ä‰∏™ÂîØ‰∏ÄÁ¥¢ÂºïÔºåÈÄöÂ∏∏‰ªé1ÂºÄÂßã„ÄÇ\u003c/li\u003e\n\u003cli\u003eÈ¢ÑÁïôÁ¥¢Âºï0Ë°®Á§∫‚ÄúÊú™Áü•‚ÄùÊàñ‚ÄúÁº∫Â§±‚ÄùÔºåÂØπÂ∫îÂÖ®0ÂêëÈáè„ÄÇ\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003e\u003cstrong\u003eËΩ¨Êç¢‰∏∫One-HotÂêëÈáè\u003c/strong\u003e\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eËã•Á±ªÂà´ÊÄªÊï∞‰∏∫197ÔºåÂàôÁî®197Áª¥ÂêëÈáèË°®Á§∫„ÄÇ\u003c/li\u003e\n\u003cli\u003e‰æãÂ≠êÔºöÁæéÂõΩ \u003ccode\u003e[1, 0, 0, 0, ‚Ä¶]\u003c/code\u003eÔºå ‰∏≠ÂõΩ \u003ccode\u003e[0, 1, 0, 0, ‚Ä¶]\u003c/code\u003e„ÄÇ\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003e\u003cstrong\u003eÁ§∫‰æãÔºöË°®Á§∫‰∏Ä‰∏™‰∫∫ÁöÑÁâπÂæÅ\u003c/strong\u003e\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eÁâπÂæÅÂåÖÂê´ÔºàÂπ¥ÈæÑ, ÊÄßÂà´, ÂõΩÁ±çÔºåÂÖ∂‰∏≠ÂõΩÁ±ç197ÁßçÔºâ\u003c/li\u003e\n\u003cli\u003eÁª¥Â∫¶ÊÄªÂíåÔºö1Áª¥_age + 1Áª¥_gender + 197Áª¥_nationality = 199Áª¥„ÄÇ\u003c/li\u003e\n\u003cli\u003e‰æãÂ¶Ç \u003ccode\u003e(28, Â•≥, ‰∏≠ÂõΩ)\u003c/code\u003e ‚Üí \u003ccode\u003e[28, 0, 0, 1, 0, ‚Ä¶, 0]\u003c/code\u003e„ÄÇ\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003c/ol\u003e\n\u003ch2 id=\"‰∏âÊñáÊú¨Êï∞ÊçÆÂ§ÑÁêÜÊµÅÁ®ã\"\u003e‰∏â„ÄÅÊñáÊú¨Êï∞ÊçÆÂ§ÑÁêÜÊµÅÁ®ã\u003c/h2\u003e\n\u003cp\u003eÊñáÊú¨Âú®Ëá™ÁÑ∂ËØ≠Ë®ÄÂ§ÑÁêÜÔºàNLPÔºâ‰∏≠‰Ωú‰∏∫Â∏∏ËßÅÁöÑÂéüÂßãËæìÂÖ•ÔºåÈúÄË¶ÅÊï∞ÂÄºÂåñÊâçËÉΩÈÄÅÂÖ•Ê®°Âûã„ÄÇ‰∏ÄËà¨Ê≠•È™§Â¶Ç‰∏ãÔºö\u003c/p\u003e\n\u003col\u003e\n\u003cli\u003e\n\u003cp\u003e\u003cstrong\u003eÂàÜËØç (Tokenization)\u003c/strong\u003e\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eÂ∞ÜÊñáÊú¨ÊãÜÂàÜ‰∏∫‰∏Ä‰∏™‰∏™ÂçïËØçÔºàTokenÔºâ„ÄÇ\u003c/li\u003e\n\u003cli\u003e‰æãÂ≠êÔºö\u003ccode\u003e\u0026quot;... to be or not to be...\u0026quot;\u003c/code\u003e ‚Üí \u003ccode\u003e[\u0026quot;...\u0026quot;, \u0026quot;to\u0026quot;, \u0026quot;be\u0026quot;, \u0026quot;or\u0026quot;, \u0026quot;not\u0026quot;, \u0026quot;to\u0026quot;, \u0026quot;be\u0026quot;, \u0026quot;...\u0026quot;]\u003c/code\u003e„ÄÇ\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003e\u003cstrong\u003eÁªüËÆ°ËØçÈ¢ë \u0026amp; ÊûÑÂª∫ËØçÂÖ∏\u003c/strong\u003e\u003c/p\u003e","title":""},{"content":"Text to Sequence ÊñáÊú¨Â§ÑÁêÜ\nStep1: Tokenization\nTokenization breaks a piece of text down into a list of tokens.\nHere, a token is a word. (A token can be a character in some applications.)\nTokenizationËÆ≤Á©∂ÂæàÂ§öÔºå‰æãÂ¶ÇÊòØÂê¶Â∫îËØ•ÊääÂ§ßÂÜôÊîπÊàêÂ∞èÂÜôÂë¢ÔºüËøõË°åtypo correctionÁ≠âÁ≠â\nStep2: Build Dictionary\nUse a dictionary (hash table) to count word frequencies.\nThe dictionary maps word to index.\nÂèØ‰ª•È¶ñÂÖàÁªüËÆ°ËØçÈ¢ëÂéªÊéâ‰ΩéÈ¢ëËØçÔºåÁÑ∂ÂêéËÆ©ÊØè‰∏™ËØçÂØπÂ∫î‰∏Ä‰∏™Ê≠£Êï¥Êï∞ÔºõËøôÊ†∑ÁöÑËØùÔºå‰∏ÄÂè•ËØùÂ∞±ÂèØ‰ª•Áî®‰∏Ä‰∏™Ê≠£Êï¥Êï∞ÂàóË°®Ë°®Á§∫ÔºåËøô‰∏™ÂàóË°®Â∞±Âè´sequenceÔºõÂ¶ÇÊûúÂøÖË¶ÅÂ∞±ËøòÂæóÂÅöone-hot encoding„ÄÇ\nÁªìÊûú\n‰ΩÜÊòØÈïøÂ∫¶‰∏çÁªü‰∏Ä\nStep4: ÂØπÈΩêsequence\nËß£ÂÜ≥ÊñπÊ°àÊòØËøôÊ†∑ÁöÑÔºöÂèØ‰ª•Âõ∫ÂÆöÈïøÂ∫¶‰∏∫wÔºåÂä†ÂÖ•‰∏Ä‰∏™Â∫èÂàóÈïøÂ∫¶Â§™ÈïøÔºåÂ∞±Á†çÊéâÂâçÈù¢ÁöÑËØçÔºåÂè™‰øùÁïôÊúÄÂêéw‰∏™ËØçÔºõÂ¶ÇÊûú‰∏Ä‰∏™Â∫èÂàóÂ§™Áü≠ÔºåÂ∞±ÂÅözero paddingÔºåÁî®0Â°´ÂÖÖ\nËøôÊ†∑‰∏ÄÊù•ÔºåÊâÄÊúâÁöÑÂ∫èÂàóÈïøÂ∫¶Â∞±Áªü‰∏Ä‰∫Ü\nÊñáÊú¨Â§ÑÁêÜÂÆåÊàê‰∫ÜÔºåÊé•‰∏ãÊù•ÊòØword embeddingÔºåÊääÂçïËØçË°®Á§∫‰∏∫‰∏Ä‰∏™‰ΩéÁª¥ÂêëÈáèÔºõ\nÁÑ∂ËÄåËøôÊ†∑ÂÅöÁöÑËØùÔºåÂ¶ÇÊûúÊòØ10000‰∏™ÂçïËØçÔºåÁª¥Â∫¶Â∞±ÊòØ10000Áª¥ÔºåÁª¥Â∫¶Â§™È´ò‰∫ÜÔºõÂõ†Ê≠§Ë¶ÅÂÅöword embeddingÔºõ\nÂÖ∑‰ΩìÂÅöÊ≥ïÂ∞±ÊòØÊääone-hotÂêëÈáèe_iÂíåÂèÇÊï∞Áü©ÈòµpÁõ∏‰πòÔºõÁü©ÈòµPËΩ¨ÁΩÆÁöÑÂ§ßÂ∞èÊòØd x vÔºõdÊòØËØçÂêëÈáèÁöÑÁª¥Â∫¶ÔºõvÊòØÂ≠óÂÖ∏ÈáåËØçÊ±áÁöÑÊï∞ÈáèÔºõÁªìÊûú‰∏∫x_iÔºõx_iÂ∞±ÊòØ‰∏Ä‰∏™ËØçÂêëÈáèÔºõÂ¶ÇÊûúone-hotÂêëÈáèÁöÑÁ¨¨‰∏âË°å‰∏∫1ÔºõÈÇ£‰πàx_iÂ∞±ÊòØPËΩ¨ÁΩÆÁü©ÈòµÁöÑÁ¨¨‰∏âÂàóÔºàÂÖ∂‰ΩôÂàóÈÉΩ‰∏∫0ÔºâÔºõÊâÄ‰ª•PËΩ¨ÁΩÆÊØè‰∏ÄÂàóÈÉΩÊòØ‰∏Ä‰∏™ËØçÂêëÈáèÔºõÊâÄ‰ª•Áü©ÈòµPÊú¨Ë∫´ÁöÑÊØè‰∏ÄË°åÂ∞±ÊòØ‰∏Ä‰∏™ËØçÂêëÈáèÔºõÂÖ∂Ë°åÊï∞‰∏∫vÔºõÂç≥vocabularyÔºåËØçÊ±áÈáèÔºõÊØè‰∏ÄË°åÂØπÂ∫î‰∏Ä‰∏™ÂçïËØçÔºõÁü©ÈòµÁöÑÂàóÊï∞‰∏∫dÔºõdÊòØÁî®Êà∑ÂÜ≥ÂÆöÁöÑÔºõdÁöÑÂ§ßÂ∞è‰ºöÂÜ≥ÂÆöÊú∫Âô®Â≠¶‰π†Ê®°ÂûãÁöÑË°®Áé∞ÔºõÂ∫îËØ•Áî®xxxÊù•ÈÄâÊã©‰∏Ä‰∏™ÊØîËæÉÂ•ΩÁöÑdÔºõ\nÊàë‰ª¨ÁöÑ‰ªªÂä°ÊòØÁúãËØÑËÆ∫ÊòØÊ≠£Èù¢ÁöÑËøòÊòØË¥üÈù¢ÁöÑÔºõÂèÇÊï∞Áü©ÈòµÊòØ‰ªéËÆ≠ÁªÉÊï∞ÊçÆ‰∏≠Â≠¶‰π†Âá∫Êù•ÁöÑÔºåÊâÄ‰ª•Â≠¶Âá∫Êù•ÁöÑËØçÂêëÈáèÊòØÂ∏¶ÊúâÊÑüÊÉÖËâ≤ÂΩ©ÁöÑÔºõÂÅáËÆæËøô‰∫õËØçÂêëÈáèÈÉΩÊòØ‰∫åÁª¥ÁöÑÔºåÂàôÂèØ‰ª•Âú®Âπ≥Èù¢ÂùêÊ†áÁ≥ª‰∏≠Ê†áÂá∫‰∏ãÈù¢ËØçÂêëÈáè\nkerasÊèê‰æõembeddingÂ±ÇÔºõÁî®Êà∑ÂèØ‰ª•ÊåáÂÆövocabularyÂ§ßÂ∞èÂíådÁöÑÂ§ßÂ∞èÔºõ‰ª•ÂèäÊØè‰∏Ä‰∏™sequenceÁöÑÈïøÂ∫¶ÔºõdÊòØÊ†πÊçÆÁÆóÊ≥ïÈÄâÂá∫Êù•ÁöÑ Âà∞Ëøô‰∏ÄÊ≠•ÔºåÊàë‰ª¨Â∑≤ÁªèÂÆåÊàê‰∫ÜÊñáÊú¨Â§ÑÁêÜÂíåword embedding„ÄÇÊé•‰∏ãÊù•Â∞±ÊòØÁî®Logistic Regression for Binary ClassificationÂÅö‰∫åÂàÜÁ±ªÔºõ\n","permalink":"http://localhost:1313/posts/nlp-2/","summary":"\u003ch3 id=\"text-to-sequence\"\u003eText to Sequence\u003c/h3\u003e\n\u003cp\u003eÊñáÊú¨Â§ÑÁêÜ\u003c/p\u003e\n\u003cp\u003eStep1: Tokenization\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\n\u003cp\u003eTokenization breaks a piece of text down into a list of tokens.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003eHere, a token is a word. (A token can be a character in some applications.)\u003c/p\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003eTokenizationËÆ≤Á©∂ÂæàÂ§öÔºå‰æãÂ¶ÇÊòØÂê¶Â∫îËØ•ÊääÂ§ßÂÜôÊîπÊàêÂ∞èÂÜôÂë¢ÔºüËøõË°åtypo correctionÁ≠âÁ≠â\u003c/p\u003e\n\u003cp\u003e\u003cimg alt=\"image-20250322150322238\" loading=\"lazy\" src=\"./NLP-2.assets/image-20250322150322238.png\"\u003e\u003c/p\u003e\n\u003cp\u003eStep2: Build Dictionary\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\n\u003cp\u003eUse a dictionary (hash table) to count word frequencies.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003eThe dictionary maps word to index.\u003c/p\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003eÂèØ‰ª•È¶ñÂÖàÁªüËÆ°ËØçÈ¢ëÂéªÊéâ‰ΩéÈ¢ëËØçÔºåÁÑ∂ÂêéËÆ©ÊØè‰∏™ËØçÂØπÂ∫î‰∏Ä‰∏™Ê≠£Êï¥Êï∞ÔºõËøôÊ†∑ÁöÑËØùÔºå‰∏ÄÂè•ËØùÂ∞±ÂèØ‰ª•Áî®‰∏Ä‰∏™Ê≠£Êï¥Êï∞ÂàóË°®Ë°®Á§∫ÔºåËøô‰∏™ÂàóË°®Â∞±Âè´sequenceÔºõÂ¶ÇÊûúÂøÖË¶ÅÂ∞±ËøòÂæóÂÅöone-hot encoding„ÄÇ\u003cimg alt=\"image-20250322150620890\" loading=\"lazy\" src=\"./NLP-2.assets/image-20250322150620890.png\"\u003e\u003c/p\u003e\n\u003cp\u003eÁªìÊûú\u003c/p\u003e\n\u003cp\u003e\u003cimg alt=\"image-20250322150754528\" loading=\"lazy\" src=\"./NLP-2.assets/image-20250322150754528.png\"\u003e\u003c/p\u003e\n\u003cp\u003e‰ΩÜÊòØÈïøÂ∫¶‰∏çÁªü‰∏Ä\u003c/p\u003e\n\u003cp\u003eStep4: ÂØπÈΩêsequence\u003c/p\u003e\n\u003cp\u003e\u003cimg alt=\"image-20250322150854986\" loading=\"lazy\" src=\"./NLP-2.assets/image-20250322150854986.png\"\u003e\u003c/p\u003e\n\u003cp\u003eËß£ÂÜ≥ÊñπÊ°àÊòØËøôÊ†∑ÁöÑÔºöÂèØ‰ª•Âõ∫ÂÆöÈïøÂ∫¶‰∏∫wÔºåÂä†ÂÖ•‰∏Ä‰∏™Â∫èÂàóÈïøÂ∫¶Â§™ÈïøÔºåÂ∞±Á†çÊéâÂâçÈù¢ÁöÑËØçÔºåÂè™‰øùÁïôÊúÄÂêéw‰∏™ËØçÔºõÂ¶ÇÊûú‰∏Ä‰∏™Â∫èÂàóÂ§™Áü≠ÔºåÂ∞±ÂÅözero paddingÔºåÁî®0Â°´ÂÖÖ\u003c/p\u003e\n\u003cp\u003e\u003cimg alt=\"image-20250322151030119\" loading=\"lazy\" src=\"./NLP-2.assets/image-20250322151030119.png\"\u003e\u003c/p\u003e\n\u003cp\u003eËøôÊ†∑‰∏ÄÊù•ÔºåÊâÄÊúâÁöÑÂ∫èÂàóÈïøÂ∫¶Â∞±Áªü‰∏Ä‰∫Ü\u003c/p\u003e\n\u003cp\u003e\u003cimg alt=\"image-20250322151117125\" loading=\"lazy\" src=\"./NLP-2.assets/image-20250322151117125.png\"\u003e\u003c/p\u003e\n\u003cp\u003eÊñáÊú¨Â§ÑÁêÜÂÆåÊàê‰∫ÜÔºåÊé•‰∏ãÊù•ÊòØword embeddingÔºåÊääÂçïËØçË°®Á§∫‰∏∫‰∏Ä‰∏™‰ΩéÁª¥ÂêëÈáèÔºõ\u003c/p\u003e\n\u003cp\u003e\u003cimg alt=\"image-20250322151252837\" loading=\"lazy\" src=\"./NLP-2.assets/image-20250322151252837.png\"\u003e\u003c/p\u003e","title":""},{"content":"üëã About me Hello! I‚Äôm Xu Zongsi, a passionate technology enthusiast currently pursuing my Master of Science in Electronic Commerce \u0026amp; Internet Computing at The University of Hong Kong. With a solid background in Software Engineering from the Beijing Institute of Technology, I specialize in emerging areas of artificial intelligence, including machine learning, deep learning, natural language processing, computer vision, and reinforcement learning.\nRecently, inspired by OpenAI\u0026rsquo;s five-step plan towards superintelligence, I have great expectations for AGI and developed a strong interest in LLM agents, MLLM, reinforcement learning, and knowledge graphs. I believe there is significant potential in these fields to create innovative solutions, and I hope to contribute my efforts towards that goal.\nI aspire to contribute to the advancement of AGI by utilizing a diverse set of skills and techniques to develop innovative solutions.\nHello! I‚Äôm Xu Zongsi, a passionate technology enthusiast currently pursuing my Master of Science in ECIC at The University of Hong Kong. With a solid background in Software Engineering from the Beijing Institute of Technology, I specialize in emerging areas of artificial intelligence, including machine learning, deep learning, natural language processing, computer vision, and reinforcement learning.\nI have a strong interest in developing LLM agents and knowledge graphs, leveraging data science techniques for innovative solutions. Additionally, I am skilled in software development, aiming to create impactful applications that enhance user experiences.\nThroughout my academic journey, I have been involved in several innovative projects focused on fraud detection, intelligent text processing, and quantum computing applications in deep learning. My programming skills span languages like Python and Java, with experience in frameworks such as PyTorch.\nWhen I‚Äôm not coding, you can find me exploring new technologies, sharing insights on my blog, or engaging in community activities related to cyber security.\nüìö Education üá≠üá∞ The University of Hong Kong 09/2024 - Expected 11/2025 School of Computing and Data Science Master of Science in Electronic Commerce \u0026amp; Internet Computing Relevant Courses: Machine learning for business and e-commerce, Knowledge graphs, Financial fraud analytics, Internet infrastructure technologies, Website engineering, Blockchain and cryptocurrency, etc. üá®üá≥ Beijing Institute of Technology 09/2020 - 06/2024 School of Computer Science \u0026amp; Technology Bachelor of Engineering in Software Engineering, last two years GPA: 3.7/4 Relevant Courses: Reinforcement Learning, Deep Learning and Computer Vision, Artificial Intelligence and Robot Ethics, Almost Human: Mind, Brain and Artificial Intelligence, Mathematical Analysis for Engineering, Linear Algebra, Probability and Mathematical Statistics, etc. Skills: Python, Java, common data structures, design patterns, machine learning basics and algorithms, Linux, PyTorch, and some development tools (git, conda, etc.). üèÜ Awards \u0026amp; Honors Beijing Institute of Technology Undergraduate Scholarship (Top 20% of Grade) 06/2023 3rd Prize of China International \u0026#34;Internet \u0026#43;\u0026#34; College Student\u0026#39;s Innovation Competition 08/2022 Bronze Prize of \u0026#34;Challenge Cup\u0026#34; Capital University Entrepreneurship Competition 05/2022 üíº Project Experience Online Transaction Fraud Detection 09/2024 ‚Äì 01/2025 Independent project, supervised by Dr. Vivien Chan Focused on addressing financial fraud in e-commerce to enhance the accuracy of transaction anomaly detection, while independently managing the entire case study that included data preprocessing, feature engineering, model building, evaluation, and results analysis. Effectively resolved class imbalance issues using SMOTE and ROSE techniques. Built various models including Logistic Regression, Random Forest, XGBoost, and LightGBM, ultimately selecting the LightGBM model to achieve a recall rate of 95.45% and an AUC of 99.84%. Wrote efficient and maintainable code, enhancing model training and data processing efficiency through parallel computing and logging. Multi-Model Intelligent Text Keyword Extraction System 08/2023 ‚Äì 09/2023 Group project, supervised by Associate Prof. Xiaolin Zhao Designed and implemented an intelligent text summary system that automatically extracts keywords from article titles and abstracts, enhancing the understanding and summarization of text information. Participated in the planning of the technical route and built a hybrid model combining extractive and generative approaches, utilizing advanced natural language processing techniques including KeyBERT, Sentence Transformer, BERT, and T5 models. Responsible for data preprocessing and tokenization, as well as the end-to-end implementation and training of the T5 model, optimizing the model architecture and hyperparameters, achieving satisfactory results after only 3 epochs of training. Model evaluation results showed that the Rouge-1, Rouge-2, and Rouge-L metrics reached 0.6345, 0.5038, and 0.5282, respectively, in the third epoch, validating the model\u0026rsquo;s effectiveness in the summarization task. Cambridge University Machine Learning Summer Project 07/2023 ‚Äì 08/2023 Group project, supervised by Prof. Pietro Li√≤ Participated in the Cambridge University deep learning summer project, focusing on deep reinforcement learning; explored multi-agent learning algorithms across different environments. Reproduced the Multi-Agent Deep Deterministic Policy Gradient (MADDPG) algorithm in the Simple Adversary environment and studied the effect of agent numbers on convergence speed and stability, finding optimal stability at 21 agents. Designed and implemented comparative experiments inspired by the Rainbow algorithm, assessing target network strategies versus the Double Deep Q-Network (Double DQN). The results demonstrated that Double DQN significantly enhanced convergence speed, optimizing the overall learning process. Co-authored a group project paper on agent numbers and strategies effectiveness in multi-agent systems, achieving a score of 71% in the summer program (the highest in my group) and a \u0026ldquo;First Class\u0026rdquo; classification in the UK grading system. Deep Learning and Computer Vision Semester Project 09/2022 ‚Äì 12/2022 Independent project, supervised by Associate Prof. Guangyu Gao Designed and implemented a waste classifier using the ResNet model to improve classification accuracy and reduce resource waste. The project also enhanced understanding of transfer learning techniques with ResNet. Collected a dataset of 16 waste categories and preprocessed the images for uniformity and standardization, incorporating data augmentation techniques to enhance the dataset. Conducted experiments using ResNet34 and ResNet50 models through transfer learning, accelerating network convergence by leveraging pretrained weights. During training, techniques such as Batch Normalization and Dropout were applied to mitigate the risk of overfitting. The final model achieved an accuracy of 90% on the training set, while the performance on the test set was 61%, indicating a significant overfitting phenomenon during the training process. üéì Internship Beijing Academy of Quantum Information Science 08/2023 ‚Äì 01/2024 Research Intern at Quantum Computation Department Proposed a quantum convolution kernel design based on variational quantum circuits and developed a universal quantum convolution layer, successfully integrating it into classical CNN architectures such as VGG, GoogLeNet, and ResNet. Developed and evaluated various hybrid models, including a simple model named HQCCNN-2, which achieved 84.45% accuracy on the FashionMNIST dataset, surpassing the traditional CNN\u0026rsquo;s 80.72%. This demonstrates the effectiveness of the quantum convolution layer in improving model performance. Tested on a real quantum computer further validated the effectiveness of the hybrid model, demonstrating the viable integration of quantum computing with deep learning, and highlighting the potential for leveraging quantum properties to enhance model performance. üèÖ Competition Experience China International \u0026#34;Internet \u0026#43;\u0026#34; College Students\u0026#39; Innovation Competition 08/2022 Zhongke Ushield: Deep Learning-based Face Privacy Protection Authentication System Responsible for constructing a localized facial feature extraction engine based on MobileFaceNet, ensuring feature extraction is completed on end devices (such as mobile phones and cameras), guaranteeing that raw data does not leave the domain and is not stored, thus enhancing user privacy protection while improving recognition efficiency. \u0026#34;Challenge Cup\u0026#34; Capital University Entrepreneurship Competition 05/2022 Smart Orchard Responsible for the development of the fruit detection, ripeness prediction, and pest identification system, using deep convolutional neural network (CNN) technology for intelligent monitoring of crop growth conditions. Applied advanced object detection algorithms such as Faster R-CNN and YOLO to achieve high precision in apple detection and ripeness assessment, with an accuracy rate exceeding 90%, significantly enhancing the intelligence level of orchard management. Built and trained a dedicated dataset containing various pest samples, optimizing pest detection accuracy through data preprocessing (such as image normalization and resizing) and data augmentation techniques (like rotation, flipping, and noise addition), enabling the real-time monitoring system to accurately identify over 80% of pests, providing effective scientific maintenance recommendations to help farmers reduce crop losses. üìã Extracurricular Activities Vice President, Cyber Security Club, Beijing Institute of Technology 09/2021-09/2022 Backbone, Media Center of the Student Union of Beijing Institute of Technology 10/2020-06/2021 üì´ Contact üìß zongsi.xu@outlook.com üëî Zongsi (Tristan) Xu üíª github.com/BaizeXS üìç Hong Kong SAR, China ","permalink":"http://localhost:1313/resume/","summary":"Personal resume of Zongsi (Tristan) Xu","title":"Zongsi (Tristan) Xu"},{"content":"‰∏Ä„ÄÅÊï∞ÂÄºÁâπÂæÅ‰∏éÁ±ªÂà´ÁâπÂæÅ Êï∞ÂÄºÁâπÂæÅ (Numeric Features) ÂÖ∑ÊúâÂèØÂä†ÂáèÁöÑÊÑè‰πâÔºå‰∏îÂ≠òÂú®Â§ßÂ∞èÈ°∫Â∫è„ÄÇ ‰æãÂ≠êÔºöÂπ¥ÈæÑ„ÄÅÊ∏©Â∫¶Á≠â„ÄÇÂèØ‰ª•Áõ¥Êé•‰øùÁïôÂÖ∂Êï¥Êï∞ÊàñÊµÆÁÇπÊï∞ÂΩ¢Âºè‰æõÊ®°Âûã‰ΩøÁî®„ÄÇ Á±ªÂà´ÁâπÂæÅ (Categorical Features) Êï∞ÊçÆÂÄºÁ¶ªÊï£Ôºå‰∏çÂÖ∑Â§á‚ÄúÊï∞ÂÄºÂ§ßÂ∞è‚ÄùÈó¥ÁöÑÂèØÊØîÊÑè‰πâ„ÄÇ ‰æãÂ≠êÔºöÂõΩÁ±çÔºàÁæéÂõΩ/‰∏≠ÂõΩ/Âç∞Â∫¶Á≠âÔºâ„ÄÅÊÄßÂà´ÔºàÁî∑/Â•≥ÔºâÁ≠â„ÄÇ ÈóÆÈ¢òÔºöËã•‰ªÖÁî®Êï¥Êï∞Ë°®Á§∫ÔºàÁæéÂõΩ=1, ‰∏≠ÂõΩ=2ÔºâÔºå‰ºöÂºïÂÖ•ÈîôËØØÁöÑÊï∞ÂÄºËøêÁÆóÂÖ≥Á≥ªÔºåÂ¶Ç ‚ÄúÁæéÂõΩ + ‰∏≠ÂõΩ = Âç∞Â∫¶‚Äù„ÄÇ ‰∫å„ÄÅOne-HotÁºñÁ†ÅÁöÑÂä®Êú∫‰∏éÊµÅÁ®ã ‰∏∫‰ªÄ‰πà‰ΩøÁî®One-Hot\nÈÄöËøáÂ∞ÜÁ±ªÂà´Êò†Â∞Ñ‰∏∫ÂêëÈáèÔºåÈÅøÂÖçÊï¥Êï∞ÁºñÁ†ÅÂºïÂÖ•ÁöÑ‰º™Êï∞ÂÄºÂÖ≥Á≥ª„ÄÇ ÂêåÊó∂‰øùÁïôÂêÑÁßçÂèØËÉΩÁ±ªÂà´ÁöÑ‰ø°ÊÅØÔºå‰∏î‰ªÖÂú®ÂØπÂ∫î‰ΩçÁΩÆ‰∏∫1ÔºåÂÖ∂‰ªñ‰ΩçÁΩÆ‰∏∫0„ÄÇ Âª∫Á´ãÊò†Â∞ÑÔºö‰ªéÁ±ªÂà´Âà∞Á¥¢Âºï\n‰∏∫ÊØè‰∏™Á±ªÂà´ÂàÜÈÖç‰∏Ä‰∏™ÂîØ‰∏ÄÁ¥¢ÂºïÔºåÈÄöÂ∏∏‰ªé1ÂºÄÂßã„ÄÇ È¢ÑÁïôÁ¥¢Âºï0Ë°®Á§∫‚ÄúÊú™Áü•‚ÄùÊàñ‚ÄúÁº∫Â§±‚ÄùÔºåÂØπÂ∫îÂÖ®0ÂêëÈáè„ÄÇ ËΩ¨Êç¢‰∏∫One-HotÂêëÈáè\nËã•Á±ªÂà´ÊÄªÊï∞‰∏∫197ÔºåÂàôÁî®197Áª¥ÂêëÈáèË°®Á§∫„ÄÇ ‰æãÂ≠êÔºöÁæéÂõΩ [1, 0, 0, 0, ‚Ä¶]Ôºå ‰∏≠ÂõΩ [0, 1, 0, 0, ‚Ä¶]„ÄÇ Á§∫‰æãÔºöË°®Á§∫‰∏Ä‰∏™‰∫∫ÁöÑÁâπÂæÅ\nÁâπÂæÅÂåÖÂê´ÔºàÂπ¥ÈæÑ, ÊÄßÂà´, ÂõΩÁ±çÔºåÂÖ∂‰∏≠ÂõΩÁ±ç197ÁßçÔºâ Áª¥Â∫¶ÊÄªÂíåÔºö1Áª¥_age + 1Áª¥_gender + 197Áª¥_nationality = 199Áª¥„ÄÇ ‰æãÂ¶Ç (28, Â•≥, ‰∏≠ÂõΩ) ‚Üí [28, 0, 0, 1, 0, ‚Ä¶, 0]„ÄÇ ‰∏â„ÄÅÊñáÊú¨Êï∞ÊçÆÂ§ÑÁêÜÊµÅÁ®ã ÊñáÊú¨Âú®Ëá™ÁÑ∂ËØ≠Ë®ÄÂ§ÑÁêÜÔºàNLPÔºâ‰∏≠‰Ωú‰∏∫Â∏∏ËßÅÁöÑÂéüÂßãËæìÂÖ•ÔºåÈúÄË¶ÅÊï∞ÂÄºÂåñÊâçËÉΩÈÄÅÂÖ•Ê®°Âûã„ÄÇ‰∏ÄËà¨Ê≠•È™§Â¶Ç‰∏ãÔºö\nÂàÜËØç (Tokenization)\nÂ∞ÜÊñáÊú¨ÊãÜÂàÜ‰∏∫‰∏Ä‰∏™‰∏™ÂçïËØçÔºàTokenÔºâ„ÄÇ ‰æãÂ≠êÔºö\u0026quot;... to be or not to be...\u0026quot; ‚Üí [\u0026quot;...\u0026quot;, \u0026quot;to\u0026quot;, \u0026quot;be\u0026quot;, \u0026quot;or\u0026quot;, \u0026quot;not\u0026quot;, \u0026quot;to\u0026quot;, \u0026quot;be\u0026quot;, \u0026quot;...\u0026quot;]„ÄÇ ÁªüËÆ°ËØçÈ¢ë \u0026amp; ÊûÑÂª∫ËØçÂÖ∏\nËØçÈ¢ëÁªüËÆ° Áî®ÂìàÂ∏åË°®/Â≠óÂÖ∏ËÆ∞ÂΩïÊØè‰∏™ÂçïËØçÂá∫Áé∞Ê¨°Êï∞„ÄÇ ÈÅçÂéÜÊñáÊú¨Êó∂ÔºåËã•ÂçïËØçÂ∞öÊú™ÂÖ•Ë°®ÔºåÂàôÊñ∞Âª∫ËÆ∞ÂΩïÔºõËã•Â∑≤Â≠òÂú®ÔºåÂàôËÆ°Êï∞+1„ÄÇ ÊéíÂ∫è‰∏éÁ¥¢Âºï ÊåâËØçÈ¢ëÈôçÂ∫èÊéíÂ∫èÔºåËØçÈ¢ëÊúÄÈ´òÁöÑÂçïËØçÊéíÂú®ÂâçÈù¢„ÄÇ Á¥¢Âºï‰ªé1ÂºÄÂßãÔºå0ÁïôÁªô‚ÄúÊú™Áü•‚Äù„ÄÇ ËØçÂÖ∏ËßÑÊ®°ÔºàvocabularyÔºâÂèØËßÜÈúÄÊ±ÇÊà™Êñ≠Ôºà‰æãÂ¶ÇÂè™‰øùÁïôTop 10kÔºâ„ÄÇ ‰∏∫‰ªÄ‰πàÁßªÈô§‰ΩéÈ¢ëËØç ‰ΩéÈ¢ëËØçÂèØËÉΩÊòØÊãºÂÜôÈîôËØØ„ÄÅÁΩïËßÅ‰∫∫ÂêçÁ≠âÔºåÂØπÊ®°ÂûãÂ∏ÆÂä©ÊúâÈôê„ÄÇ ÂáèÂ∞ëËØçÂÖ∏ËßÑÊ®°ÂèØÈôç‰ΩéËøêÁÆóÂºÄÈîÄ„ÄÅÂä†Âø´Ê®°ÂûãËÆ≠ÁªÉ‰∏éÊé®ÁêÜÈÄüÂ∫¶„ÄÇ Áã¨ÁÉ≠ÁºñÁ†Å (One-Hot Encoding)\nÂ∞ÜÊØè‰∏™ÂçïËØçÊò†Â∞Ñ‰∏∫ËØçÂÖ∏‰∏≠ÁöÑÁ¥¢ÂºïÂêéÔºàÂ¶Ç [2, 4, 1, 8, ‚Ä¶]ÔºâÔºåÂèØËøõ‰∏ÄÊ≠•ËΩ¨Êç¢ÊàêOne-HotÂêëÈáè„ÄÇ One-HotÁª¥Â∫¶ÂèñÂÜ≥‰∫é‰øùÁïô‰∏ãÊù•ÁöÑËØçÂÖ∏Â§ßÂ∞èÔºà‰æãÂ¶Ç1‰∏áÔºâ„ÄÇ Êú™Êî∂ÂΩïÂçïËØçÂèØËÉΩÁõ¥Êé•ÂøΩÁï•ÔºåÊàñÁªü‰∏ÄÁî®Á¥¢Âºï0‰ª£Êõø„ÄÇ Âõõ„ÄÅÊ†∏ÂøÉÊî∂Ëé∑‰∏éÂ∫îÁî® Á±ªÂà´ÁâπÂæÅÂøÖÈúÄÊï∞ÂÄºÂåñÔºö\n‰ΩøÁî®Êï¥Êï∞1,2,3‚Ä¶‰ªÖË°®Á§∫Á±ªÂà´‚ÄúÊ†áËØÜ‚ÄùÔºåÂπ∂‰∏ç‰ª£Ë°®ÂÆÉ‰ª¨ÂèØËøõË°åÊï∞ÂÄºËøêÁÆó„ÄÇ Âõ†Ê≠§ÈúÄË¶ÅOne-HotÁ≠âÁºñÁ†ÅÊñπÂºèÔºåÈÅøÂÖçÊï∞ÂÄºËØØËß£„ÄÇ ÊñáÊú¨Êï∞ÊçÆÈ¢ÑÂ§ÑÁêÜÔºö\nÂàÜËØç„ÄÅËØçÈ¢ëÁªüËÆ°„ÄÅÊûÑÂª∫ËØçÂÖ∏„ÄÅÁ¥¢ÂºïÂåñ„ÄÅOne-HotÊàñÂÖ∂‰ªñÊñπÂºèÔºàÂ¶ÇËØçÂµåÂÖ•ÔºâÊòØÂ∏∏ËßÅÊµÅÁ®ã„ÄÇ Ê≠£Á°ÆÁöÑÊñáÊú¨È¢ÑÂ§ÑÁêÜÂèØÊòæËëóÂΩ±ÂìçÊ®°ÂûãÊÄßËÉΩÂíåÊïàÁéá„ÄÇ ‰øùÁïôÊú™Áü•Á¥¢ÂºïÔºö\n‰øùËØÅÂØπÁº∫Â§±Êï∞ÊçÆÊàñÂ≠óÂÖ∏Â§ñÊñ∞ËØçËÉΩÊúâÂü∫Êú¨ÁöÑË°®Á§∫ÔºåÊèêÂçáÊ®°ÂûãÂÆπÈîôÊÄß„ÄÇ ÂÆûÈôÖ‰ΩøÁî®Ôºö\nÂØπ‰∫éÂ∞èËßÑÊ®°Á±ªÂà´ÂèØÁõ¥Êé•One-HotÁºñÁ†ÅÔºõÂØπ‰∫éËØçÂÖ∏ÂæàÂ§ßÁöÑÂú∫ÊôØÔºåÈÄöÂ∏∏‰ºöËøõ‰∏ÄÊ≠•ËÄÉËôëËØçÂµåÂÖ•ÔºàWord EmbeddingÔºâÊàñÈ¢ÑËÆ≠ÁªÉËØ≠Ë®ÄÊ®°Âûã„ÄÇ ","permalink":"http://localhost:1313/posts/nlp-1/","summary":"\u003ch2 id=\"‰∏ÄÊï∞ÂÄºÁâπÂæÅ‰∏éÁ±ªÂà´ÁâπÂæÅ\"\u003e‰∏Ä„ÄÅÊï∞ÂÄºÁâπÂæÅ‰∏éÁ±ªÂà´ÁâπÂæÅ\u003c/h2\u003e\n\u003col\u003e\n\u003cli\u003e\u003cstrong\u003eÊï∞ÂÄºÁâπÂæÅ (Numeric Features)\u003c/strong\u003e\n\u003cul\u003e\n\u003cli\u003eÂÖ∑ÊúâÂèØÂä†ÂáèÁöÑÊÑè‰πâÔºå‰∏îÂ≠òÂú®Â§ßÂ∞èÈ°∫Â∫è„ÄÇ\u003c/li\u003e\n\u003cli\u003e‰æãÂ≠êÔºöÂπ¥ÈæÑ„ÄÅÊ∏©Â∫¶Á≠â„ÄÇÂèØ‰ª•Áõ¥Êé•‰øùÁïôÂÖ∂Êï¥Êï∞ÊàñÊµÆÁÇπÊï∞ÂΩ¢Âºè‰æõÊ®°Âûã‰ΩøÁî®„ÄÇ\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003eÁ±ªÂà´ÁâπÂæÅ (Categorical Features)\u003c/strong\u003e\n\u003cul\u003e\n\u003cli\u003eÊï∞ÊçÆÂÄºÁ¶ªÊï£Ôºå‰∏çÂÖ∑Â§á‚ÄúÊï∞ÂÄºÂ§ßÂ∞è‚ÄùÈó¥ÁöÑÂèØÊØîÊÑè‰πâ„ÄÇ\u003c/li\u003e\n\u003cli\u003e‰æãÂ≠êÔºöÂõΩÁ±çÔºàÁæéÂõΩ/‰∏≠ÂõΩ/Âç∞Â∫¶Á≠âÔºâ„ÄÅÊÄßÂà´ÔºàÁî∑/Â•≥ÔºâÁ≠â„ÄÇ\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003eÈóÆÈ¢ò\u003c/strong\u003eÔºöËã•‰ªÖÁî®Êï¥Êï∞Ë°®Á§∫ÔºàÁæéÂõΩ=1, ‰∏≠ÂõΩ=2ÔºâÔºå‰ºöÂºïÂÖ•ÈîôËØØÁöÑÊï∞ÂÄºËøêÁÆóÂÖ≥Á≥ªÔºåÂ¶Ç ‚ÄúÁæéÂõΩ + ‰∏≠ÂõΩ = Âç∞Â∫¶‚Äù„ÄÇ\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003c/ol\u003e\n\u003ch2 id=\"‰∫åone-hotÁºñÁ†ÅÁöÑÂä®Êú∫‰∏éÊµÅÁ®ã\"\u003e‰∫å„ÄÅOne-HotÁºñÁ†ÅÁöÑÂä®Êú∫‰∏éÊµÅÁ®ã\u003c/h2\u003e\n\u003col\u003e\n\u003cli\u003e\n\u003cp\u003e\u003cstrong\u003e‰∏∫‰ªÄ‰πà‰ΩøÁî®One-Hot\u003c/strong\u003e\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eÈÄöËøáÂ∞ÜÁ±ªÂà´Êò†Â∞Ñ‰∏∫ÂêëÈáèÔºåÈÅøÂÖçÊï¥Êï∞ÁºñÁ†ÅÂºïÂÖ•ÁöÑ‰º™Êï∞ÂÄºÂÖ≥Á≥ª„ÄÇ\u003c/li\u003e\n\u003cli\u003eÂêåÊó∂‰øùÁïôÂêÑÁßçÂèØËÉΩÁ±ªÂà´ÁöÑ‰ø°ÊÅØÔºå‰∏î‰ªÖÂú®ÂØπÂ∫î‰ΩçÁΩÆ‰∏∫1ÔºåÂÖ∂‰ªñ‰ΩçÁΩÆ‰∏∫0„ÄÇ\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003e\u003cstrong\u003eÂª∫Á´ãÊò†Â∞ÑÔºö‰ªéÁ±ªÂà´Âà∞Á¥¢Âºï\u003c/strong\u003e\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e‰∏∫ÊØè‰∏™Á±ªÂà´ÂàÜÈÖç‰∏Ä‰∏™ÂîØ‰∏ÄÁ¥¢ÂºïÔºåÈÄöÂ∏∏‰ªé1ÂºÄÂßã„ÄÇ\u003c/li\u003e\n\u003cli\u003eÈ¢ÑÁïôÁ¥¢Âºï0Ë°®Á§∫‚ÄúÊú™Áü•‚ÄùÊàñ‚ÄúÁº∫Â§±‚ÄùÔºåÂØπÂ∫îÂÖ®0ÂêëÈáè„ÄÇ\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003e\u003cstrong\u003eËΩ¨Êç¢‰∏∫One-HotÂêëÈáè\u003c/strong\u003e\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eËã•Á±ªÂà´ÊÄªÊï∞‰∏∫197ÔºåÂàôÁî®197Áª¥ÂêëÈáèË°®Á§∫„ÄÇ\u003c/li\u003e\n\u003cli\u003e‰æãÂ≠êÔºöÁæéÂõΩ \u003ccode\u003e[1, 0, 0, 0, ‚Ä¶]\u003c/code\u003eÔºå ‰∏≠ÂõΩ \u003ccode\u003e[0, 1, 0, 0, ‚Ä¶]\u003c/code\u003e„ÄÇ\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003e\u003cstrong\u003eÁ§∫‰æãÔºöË°®Á§∫‰∏Ä‰∏™‰∫∫ÁöÑÁâπÂæÅ\u003c/strong\u003e\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eÁâπÂæÅÂåÖÂê´ÔºàÂπ¥ÈæÑ, ÊÄßÂà´, ÂõΩÁ±çÔºåÂÖ∂‰∏≠ÂõΩÁ±ç197ÁßçÔºâ\u003c/li\u003e\n\u003cli\u003eÁª¥Â∫¶ÊÄªÂíåÔºö1Áª¥_age + 1Áª¥_gender + 197Áª¥_nationality = 199Áª¥„ÄÇ\u003c/li\u003e\n\u003cli\u003e‰æãÂ¶Ç \u003ccode\u003e(28, Â•≥, ‰∏≠ÂõΩ)\u003c/code\u003e ‚Üí \u003ccode\u003e[28, 0, 0, 1, 0, ‚Ä¶, 0]\u003c/code\u003e„ÄÇ\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003c/ol\u003e\n\u003ch2 id=\"‰∏âÊñáÊú¨Êï∞ÊçÆÂ§ÑÁêÜÊµÅÁ®ã\"\u003e‰∏â„ÄÅÊñáÊú¨Êï∞ÊçÆÂ§ÑÁêÜÊµÅÁ®ã\u003c/h2\u003e\n\u003cp\u003eÊñáÊú¨Âú®Ëá™ÁÑ∂ËØ≠Ë®ÄÂ§ÑÁêÜÔºàNLPÔºâ‰∏≠‰Ωú‰∏∫Â∏∏ËßÅÁöÑÂéüÂßãËæìÂÖ•ÔºåÈúÄË¶ÅÊï∞ÂÄºÂåñÊâçËÉΩÈÄÅÂÖ•Ê®°Âûã„ÄÇ‰∏ÄËà¨Ê≠•È™§Â¶Ç‰∏ãÔºö\u003c/p\u003e\n\u003col\u003e\n\u003cli\u003e\n\u003cp\u003e\u003cstrong\u003eÂàÜËØç (Tokenization)\u003c/strong\u003e\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eÂ∞ÜÊñáÊú¨ÊãÜÂàÜ‰∏∫‰∏Ä‰∏™‰∏™ÂçïËØçÔºàTokenÔºâ„ÄÇ\u003c/li\u003e\n\u003cli\u003e‰æãÂ≠êÔºö\u003ccode\u003e\u0026quot;... to be or not to be...\u0026quot;\u003c/code\u003e ‚Üí \u003ccode\u003e[\u0026quot;...\u0026quot;, \u0026quot;to\u0026quot;, \u0026quot;be\u0026quot;, \u0026quot;or\u0026quot;, \u0026quot;not\u0026quot;, \u0026quot;to\u0026quot;, \u0026quot;be\u0026quot;, \u0026quot;...\u0026quot;]\u003c/code\u003e„ÄÇ\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003e\u003cstrong\u003eÁªüËÆ°ËØçÈ¢ë \u0026amp; ÊûÑÂª∫ËØçÂÖ∏\u003c/strong\u003e\u003c/p\u003e","title":""},{"content":"Text to Sequence ÊñáÊú¨Â§ÑÁêÜ\nStep1: Tokenization\nTokenization breaks a piece of text down into a list of tokens.\nHere, a token is a word. (A token can be a character in some applications.)\nTokenizationËÆ≤Á©∂ÂæàÂ§öÔºå‰æãÂ¶ÇÊòØÂê¶Â∫îËØ•ÊääÂ§ßÂÜôÊîπÊàêÂ∞èÂÜôÂë¢ÔºüËøõË°åtypo correctionÁ≠âÁ≠â\nStep2: Build Dictionary\nUse a dictionary (hash table) to count word frequencies.\nThe dictionary maps word to index.\nÂèØ‰ª•È¶ñÂÖàÁªüËÆ°ËØçÈ¢ëÂéªÊéâ‰ΩéÈ¢ëËØçÔºåÁÑ∂ÂêéËÆ©ÊØè‰∏™ËØçÂØπÂ∫î‰∏Ä‰∏™Ê≠£Êï¥Êï∞ÔºõËøôÊ†∑ÁöÑËØùÔºå‰∏ÄÂè•ËØùÂ∞±ÂèØ‰ª•Áî®‰∏Ä‰∏™Ê≠£Êï¥Êï∞ÂàóË°®Ë°®Á§∫ÔºåËøô‰∏™ÂàóË°®Â∞±Âè´sequenceÔºõÂ¶ÇÊûúÂøÖË¶ÅÂ∞±ËøòÂæóÂÅöone-hot encoding„ÄÇ\nÁªìÊûú\n‰ΩÜÊòØÈïøÂ∫¶‰∏çÁªü‰∏Ä\nStep4: ÂØπÈΩêsequence\nËß£ÂÜ≥ÊñπÊ°àÊòØËøôÊ†∑ÁöÑÔºöÂèØ‰ª•Âõ∫ÂÆöÈïøÂ∫¶‰∏∫wÔºåÂä†ÂÖ•‰∏Ä‰∏™Â∫èÂàóÈïøÂ∫¶Â§™ÈïøÔºåÂ∞±Á†çÊéâÂâçÈù¢ÁöÑËØçÔºåÂè™‰øùÁïôÊúÄÂêéw‰∏™ËØçÔºõÂ¶ÇÊûú‰∏Ä‰∏™Â∫èÂàóÂ§™Áü≠ÔºåÂ∞±ÂÅözero paddingÔºåÁî®0Â°´ÂÖÖ\nËøôÊ†∑‰∏ÄÊù•ÔºåÊâÄÊúâÁöÑÂ∫èÂàóÈïøÂ∫¶Â∞±Áªü‰∏Ä‰∫Ü\nÊñáÊú¨Â§ÑÁêÜÂÆåÊàê‰∫ÜÔºåÊé•‰∏ãÊù•ÊòØword embeddingÔºåÊääÂçïËØçË°®Á§∫‰∏∫‰∏Ä‰∏™‰ΩéÁª¥ÂêëÈáèÔºõ\nÁÑ∂ËÄåËøôÊ†∑ÂÅöÁöÑËØùÔºåÂ¶ÇÊûúÊòØ10000‰∏™ÂçïËØçÔºåÁª¥Â∫¶Â∞±ÊòØ10000Áª¥ÔºåÁª¥Â∫¶Â§™È´ò‰∫ÜÔºõÂõ†Ê≠§Ë¶ÅÂÅöword embeddingÔºõ\nÂÖ∑‰ΩìÂÅöÊ≥ïÂ∞±ÊòØÊääone-hotÂêëÈáèe_iÂíåÂèÇÊï∞Áü©ÈòµpÁõ∏‰πòÔºõÁü©ÈòµPËΩ¨ÁΩÆÁöÑÂ§ßÂ∞èÊòØd x vÔºõdÊòØËØçÂêëÈáèÁöÑÁª¥Â∫¶ÔºõvÊòØÂ≠óÂÖ∏ÈáåËØçÊ±áÁöÑÊï∞ÈáèÔºõÁªìÊûú‰∏∫x_iÔºõx_iÂ∞±ÊòØ‰∏Ä‰∏™ËØçÂêëÈáèÔºõÂ¶ÇÊûúone-hotÂêëÈáèÁöÑÁ¨¨‰∏âË°å‰∏∫1ÔºõÈÇ£‰πàx_iÂ∞±ÊòØPËΩ¨ÁΩÆÁü©ÈòµÁöÑÁ¨¨‰∏âÂàóÔºàÂÖ∂‰ΩôÂàóÈÉΩ‰∏∫0ÔºâÔºõÊâÄ‰ª•PËΩ¨ÁΩÆÊØè‰∏ÄÂàóÈÉΩÊòØ‰∏Ä‰∏™ËØçÂêëÈáèÔºõÊâÄ‰ª•Áü©ÈòµPÊú¨Ë∫´ÁöÑÊØè‰∏ÄË°åÂ∞±ÊòØ‰∏Ä‰∏™ËØçÂêëÈáèÔºõÂÖ∂Ë°åÊï∞‰∏∫vÔºõÂç≥vocabularyÔºåËØçÊ±áÈáèÔºõÊØè‰∏ÄË°åÂØπÂ∫î‰∏Ä‰∏™ÂçïËØçÔºõÁü©ÈòµÁöÑÂàóÊï∞‰∏∫dÔºõdÊòØÁî®Êà∑ÂÜ≥ÂÆöÁöÑÔºõdÁöÑÂ§ßÂ∞è‰ºöÂÜ≥ÂÆöÊú∫Âô®Â≠¶‰π†Ê®°ÂûãÁöÑË°®Áé∞ÔºõÂ∫îËØ•Áî®xxxÊù•ÈÄâÊã©‰∏Ä‰∏™ÊØîËæÉÂ•ΩÁöÑdÔºõ\nÊàë‰ª¨ÁöÑ‰ªªÂä°ÊòØÁúãËØÑËÆ∫ÊòØÊ≠£Èù¢ÁöÑËøòÊòØË¥üÈù¢ÁöÑÔºõÂèÇÊï∞Áü©ÈòµÊòØ‰ªéËÆ≠ÁªÉÊï∞ÊçÆ‰∏≠Â≠¶‰π†Âá∫Êù•ÁöÑÔºåÊâÄ‰ª•Â≠¶Âá∫Êù•ÁöÑËØçÂêëÈáèÊòØÂ∏¶ÊúâÊÑüÊÉÖËâ≤ÂΩ©ÁöÑÔºõÂÅáËÆæËøô‰∫õËØçÂêëÈáèÈÉΩÊòØ‰∫åÁª¥ÁöÑÔºåÂàôÂèØ‰ª•Âú®Âπ≥Èù¢ÂùêÊ†áÁ≥ª‰∏≠Ê†áÂá∫‰∏ãÈù¢ËØçÂêëÈáè\nkerasÊèê‰æõembeddingÂ±ÇÔºõÁî®Êà∑ÂèØ‰ª•ÊåáÂÆövocabularyÂ§ßÂ∞èÂíådÁöÑÂ§ßÂ∞èÔºõ‰ª•ÂèäÊØè‰∏Ä‰∏™sequenceÁöÑÈïøÂ∫¶ÔºõdÊòØÊ†πÊçÆÁÆóÊ≥ïÈÄâÂá∫Êù•ÁöÑ Âà∞Ëøô‰∏ÄÊ≠•ÔºåÊàë‰ª¨Â∑≤ÁªèÂÆåÊàê‰∫ÜÊñáÊú¨Â§ÑÁêÜÂíåword embedding„ÄÇÊé•‰∏ãÊù•Â∞±ÊòØÁî®Logistic Regression for Binary ClassificationÂÅö‰∫åÂàÜÁ±ªÔºõ\n","permalink":"http://localhost:1313/posts/nlp-2/","summary":"\u003ch3 id=\"text-to-sequence\"\u003eText to Sequence\u003c/h3\u003e\n\u003cp\u003eÊñáÊú¨Â§ÑÁêÜ\u003c/p\u003e\n\u003cp\u003eStep1: Tokenization\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\n\u003cp\u003eTokenization breaks a piece of text down into a list of tokens.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003eHere, a token is a word. (A token can be a character in some applications.)\u003c/p\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003eTokenizationËÆ≤Á©∂ÂæàÂ§öÔºå‰æãÂ¶ÇÊòØÂê¶Â∫îËØ•ÊääÂ§ßÂÜôÊîπÊàêÂ∞èÂÜôÂë¢ÔºüËøõË°åtypo correctionÁ≠âÁ≠â\u003c/p\u003e\n\u003cp\u003e\u003cimg alt=\"image-20250322150322238\" loading=\"lazy\" src=\"./NLP-2.assets/image-20250322150322238.png\"\u003e\u003c/p\u003e\n\u003cp\u003eStep2: Build Dictionary\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\n\u003cp\u003eUse a dictionary (hash table) to count word frequencies.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003eThe dictionary maps word to index.\u003c/p\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003eÂèØ‰ª•È¶ñÂÖàÁªüËÆ°ËØçÈ¢ëÂéªÊéâ‰ΩéÈ¢ëËØçÔºåÁÑ∂ÂêéËÆ©ÊØè‰∏™ËØçÂØπÂ∫î‰∏Ä‰∏™Ê≠£Êï¥Êï∞ÔºõËøôÊ†∑ÁöÑËØùÔºå‰∏ÄÂè•ËØùÂ∞±ÂèØ‰ª•Áî®‰∏Ä‰∏™Ê≠£Êï¥Êï∞ÂàóË°®Ë°®Á§∫ÔºåËøô‰∏™ÂàóË°®Â∞±Âè´sequenceÔºõÂ¶ÇÊûúÂøÖË¶ÅÂ∞±ËøòÂæóÂÅöone-hot encoding„ÄÇ\u003cimg alt=\"image-20250322150620890\" loading=\"lazy\" src=\"./NLP-2.assets/image-20250322150620890.png\"\u003e\u003c/p\u003e\n\u003cp\u003eÁªìÊûú\u003c/p\u003e\n\u003cp\u003e\u003cimg alt=\"image-20250322150754528\" loading=\"lazy\" src=\"./NLP-2.assets/image-20250322150754528.png\"\u003e\u003c/p\u003e\n\u003cp\u003e‰ΩÜÊòØÈïøÂ∫¶‰∏çÁªü‰∏Ä\u003c/p\u003e\n\u003cp\u003eStep4: ÂØπÈΩêsequence\u003c/p\u003e\n\u003cp\u003e\u003cimg alt=\"image-20250322150854986\" loading=\"lazy\" src=\"./NLP-2.assets/image-20250322150854986.png\"\u003e\u003c/p\u003e\n\u003cp\u003eËß£ÂÜ≥ÊñπÊ°àÊòØËøôÊ†∑ÁöÑÔºöÂèØ‰ª•Âõ∫ÂÆöÈïøÂ∫¶‰∏∫wÔºåÂä†ÂÖ•‰∏Ä‰∏™Â∫èÂàóÈïøÂ∫¶Â§™ÈïøÔºåÂ∞±Á†çÊéâÂâçÈù¢ÁöÑËØçÔºåÂè™‰øùÁïôÊúÄÂêéw‰∏™ËØçÔºõÂ¶ÇÊûú‰∏Ä‰∏™Â∫èÂàóÂ§™Áü≠ÔºåÂ∞±ÂÅözero paddingÔºåÁî®0Â°´ÂÖÖ\u003c/p\u003e\n\u003cp\u003e\u003cimg alt=\"image-20250322151030119\" loading=\"lazy\" src=\"./NLP-2.assets/image-20250322151030119.png\"\u003e\u003c/p\u003e\n\u003cp\u003eËøôÊ†∑‰∏ÄÊù•ÔºåÊâÄÊúâÁöÑÂ∫èÂàóÈïøÂ∫¶Â∞±Áªü‰∏Ä‰∫Ü\u003c/p\u003e\n\u003cp\u003e\u003cimg alt=\"image-20250322151117125\" loading=\"lazy\" src=\"./NLP-2.assets/image-20250322151117125.png\"\u003e\u003c/p\u003e\n\u003cp\u003eÊñáÊú¨Â§ÑÁêÜÂÆåÊàê‰∫ÜÔºåÊé•‰∏ãÊù•ÊòØword embeddingÔºåÊääÂçïËØçË°®Á§∫‰∏∫‰∏Ä‰∏™‰ΩéÁª¥ÂêëÈáèÔºõ\u003c/p\u003e\n\u003cp\u003e\u003cimg alt=\"image-20250322151252837\" loading=\"lazy\" src=\"./NLP-2.assets/image-20250322151252837.png\"\u003e\u003c/p\u003e","title":""},{"content":"üëã About me Hello! I‚Äôm Xu Zongsi, a passionate technology enthusiast currently pursuing my Master of Science in Electronic Commerce \u0026amp; Internet Computing at The University of Hong Kong. With a solid background in Software Engineering from the Beijing Institute of Technology, I specialize in emerging areas of artificial intelligence, including machine learning, deep learning, natural language processing, computer vision, and reinforcement learning.\nRecently, inspired by OpenAI\u0026rsquo;s five-step plan towards superintelligence, I have great expectations for AGI and developed a strong interest in LLM agents, MLLM, reinforcement learning, and knowledge graphs. I believe there is significant potential in these fields to create innovative solutions, and I hope to contribute my efforts towards that goal.\nThroughout my academic journey, I have been involved in several innovative projects focused on fraud detection, intelligent text processing, and quantum computing applications in deep learning. My programming skills span languages like Python and Java, with experience in frameworks such as PyTorch.\nWhen I‚Äôm not coding, you can find me exploring new technologies, sharing insights on my blog, or engaging in community activities related to cyber security.\nüìö Education üá≠üá∞ The University of Hong Kong 09/2024 - Expected 11/2025 School of Computing and Data Science Master of Science in Electronic Commerce \u0026amp; Internet Computing Relevant Courses: Machine learning for business and e-commerce, Knowledge graphs, Financial fraud analytics, Internet infrastructure technologies, Website engineering, Blockchain and cryptocurrency, etc. üá®üá≥ Beijing Institute of Technology 09/2020 - 06/2024 School of Computer Science \u0026amp; Technology Bachelor of Engineering in Software Engineering, last two years GPA: 3.7/4 Relevant Courses: Reinforcement Learning, Deep Learning and Computer Vision, Artificial Intelligence and Robot Ethics, Almost Human: Mind, Brain and Artificial Intelligence, Mathematical Analysis for Engineering, Linear Algebra, Probability and Mathematical Statistics, etc. Skills: Python, Java, common data structures, design patterns, machine learning basics and algorithms, Linux, PyTorch, and some development tools (git, conda, etc.). üèÜ Awards \u0026amp; Honors Beijing Institute of Technology Undergraduate Scholarship (Top 20% of Grade) 06/2023 3rd Prize of China International \u0026#34;Internet \u0026#43;\u0026#34; College Student\u0026#39;s Innovation Competition 08/2022 Bronze Prize of \u0026#34;Challenge Cup\u0026#34; Capital University Entrepreneurship Competition 05/2022 üíº Project Experience Online Transaction Fraud Detection 09/2024 ‚Äì 01/2025 Independent project, supervised by Dr. Vivien Chan Focused on addressing financial fraud in e-commerce to enhance the accuracy of transaction anomaly detection, while independently managing the entire case study that included data preprocessing, feature engineering, model building, evaluation, and results analysis. Effectively resolved class imbalance issues using SMOTE and ROSE techniques. Built various models including Logistic Regression, Random Forest, XGBoost, and LightGBM, ultimately selecting the LightGBM model to achieve a recall rate of 95.45% and an AUC of 99.84%. Wrote efficient and maintainable code, enhancing model training and data processing efficiency through parallel computing and logging. Multi-Model Intelligent Text Keyword Extraction System 08/2023 ‚Äì 09/2023 Group project, supervised by Associate Prof. Xiaolin Zhao Designed and implemented an intelligent text summary system that automatically extracts keywords from article titles and abstracts, enhancing the understanding and summarization of text information. Participated in the planning of the technical route and built a hybrid model combining extractive and generative approaches, utilizing advanced natural language processing techniques including KeyBERT, Sentence Transformer, BERT, and T5 models. Responsible for data preprocessing and tokenization, as well as the end-to-end implementation and training of the T5 model, optimizing the model architecture and hyperparameters, achieving satisfactory results after only 3 epochs of training. Model evaluation results showed that the Rouge-1, Rouge-2, and Rouge-L metrics reached 0.6345, 0.5038, and 0.5282, respectively, in the third epoch, validating the model\u0026rsquo;s effectiveness in the summarization task. Cambridge University Machine Learning Summer Project 07/2023 ‚Äì 08/2023 Group project, supervised by Prof. Pietro Li√≤ Participated in the Cambridge University deep learning summer project, focusing on deep reinforcement learning; explored multi-agent learning algorithms across different environments. Reproduced the Multi-Agent Deep Deterministic Policy Gradient (MADDPG) algorithm in the Simple Adversary environment and studied the effect of agent numbers on convergence speed and stability, finding optimal stability at 21 agents. Designed and implemented comparative experiments inspired by the Rainbow algorithm, assessing target network strategies versus the Double Deep Q-Network (Double DQN). The results demonstrated that Double DQN significantly enhanced convergence speed, optimizing the overall learning process. Co-authored a group project paper on agent numbers and strategies effectiveness in multi-agent systems, achieving a score of 71% in the summer program (the highest in my group) and a \u0026ldquo;First Class\u0026rdquo; classification in the UK grading system. Deep Learning and Computer Vision Semester Project 09/2022 ‚Äì 12/2022 Independent project, supervised by Associate Prof. Guangyu Gao Designed and implemented a waste classifier using the ResNet model to improve classification accuracy and reduce resource waste. The project also enhanced understanding of transfer learning techniques with ResNet. Collected a dataset of 16 waste categories and preprocessed the images for uniformity and standardization, incorporating data augmentation techniques to enhance the dataset. Conducted experiments using ResNet34 and ResNet50 models through transfer learning, accelerating network convergence by leveraging pretrained weights. During training, techniques such as Batch Normalization and Dropout were applied to mitigate the risk of overfitting. The final model achieved an accuracy of 90% on the training set, while the performance on the test set was 61%, indicating a significant overfitting phenomenon during the training process. üéì Internship Beijing Academy of Quantum Information Science 08/2023 ‚Äì 01/2024 Research Intern at Quantum Computation Department Proposed a quantum convolution kernel design based on variational quantum circuits and developed a universal quantum convolution layer, successfully integrating it into classical CNN architectures such as VGG, GoogLeNet, and ResNet. Developed and evaluated various hybrid models, including a simple model named HQCCNN-2, which achieved 84.45% accuracy on the FashionMNIST dataset, surpassing the traditional CNN\u0026rsquo;s 80.72%. This demonstrates the effectiveness of the quantum convolution layer in improving model performance. Tested on a real quantum computer further validated the effectiveness of the hybrid model, demonstrating the viable integration of quantum computing with deep learning, and highlighting the potential for leveraging quantum properties to enhance model performance. üèÖ Competition Experience China International \u0026#34;Internet \u0026#43;\u0026#34; College Students\u0026#39; Innovation Competition 08/2022 Zhongke Ushield: Deep Learning-based Face Privacy Protection Authentication System Responsible for constructing a localized facial feature extraction engine based on MobileFaceNet, ensuring feature extraction is completed on end devices (such as mobile phones and cameras), guaranteeing that raw data does not leave the domain and is not stored, thus enhancing user privacy protection while improving recognition efficiency. \u0026#34;Challenge Cup\u0026#34; Capital University Entrepreneurship Competition 05/2022 Smart Orchard Responsible for the development of the fruit detection, ripeness prediction, and pest identification system, using deep convolutional neural network (CNN) technology for intelligent monitoring of crop growth conditions. Applied advanced object detection algorithms such as Faster R-CNN and YOLO to achieve high precision in apple detection and ripeness assessment, with an accuracy rate exceeding 90%, significantly enhancing the intelligence level of orchard management. Built and trained a dedicated dataset containing various pest samples, optimizing pest detection accuracy through data preprocessing (such as image normalization and resizing) and data augmentation techniques (like rotation, flipping, and noise addition), enabling the real-time monitoring system to accurately identify over 80% of pests, providing effective scientific maintenance recommendations to help farmers reduce crop losses. üìã Extracurricular Activities Vice President, Cyber Security Club, Beijing Institute of Technology 09/2021-09/2022 Backbone, Media Center of the Student Union of Beijing Institute of Technology 10/2020-06/2021 üì´ Contact üìß zongsi.xu@outlook.com üëî Zongsi (Tristan) Xu üíª github.com/BaizeXS üìç Hong Kong SAR, China ","permalink":"http://localhost:1313/resume/","summary":"Personal resume of Zongsi (Tristan) Xu","title":"Zongsi (Tristan) Xu"},{"content":"‰∏Ä„ÄÅÊï∞ÂÄºÁâπÂæÅ‰∏éÁ±ªÂà´ÁâπÂæÅ Êï∞ÂÄºÁâπÂæÅ (Numeric Features) ÂÖ∑ÊúâÂèØÂä†ÂáèÁöÑÊÑè‰πâÔºå‰∏îÂ≠òÂú®Â§ßÂ∞èÈ°∫Â∫è„ÄÇ ‰æãÂ≠êÔºöÂπ¥ÈæÑ„ÄÅÊ∏©Â∫¶Á≠â„ÄÇÂèØ‰ª•Áõ¥Êé•‰øùÁïôÂÖ∂Êï¥Êï∞ÊàñÊµÆÁÇπÊï∞ÂΩ¢Âºè‰æõÊ®°Âûã‰ΩøÁî®„ÄÇ Á±ªÂà´ÁâπÂæÅ (Categorical Features) Êï∞ÊçÆÂÄºÁ¶ªÊï£Ôºå‰∏çÂÖ∑Â§á‚ÄúÊï∞ÂÄºÂ§ßÂ∞è‚ÄùÈó¥ÁöÑÂèØÊØîÊÑè‰πâ„ÄÇ ‰æãÂ≠êÔºöÂõΩÁ±çÔºàÁæéÂõΩ/‰∏≠ÂõΩ/Âç∞Â∫¶Á≠âÔºâ„ÄÅÊÄßÂà´ÔºàÁî∑/Â•≥ÔºâÁ≠â„ÄÇ ÈóÆÈ¢òÔºöËã•‰ªÖÁî®Êï¥Êï∞Ë°®Á§∫ÔºàÁæéÂõΩ=1, ‰∏≠ÂõΩ=2ÔºâÔºå‰ºöÂºïÂÖ•ÈîôËØØÁöÑÊï∞ÂÄºËøêÁÆóÂÖ≥Á≥ªÔºåÂ¶Ç ‚ÄúÁæéÂõΩ + ‰∏≠ÂõΩ = Âç∞Â∫¶‚Äù„ÄÇ ‰∫å„ÄÅOne-HotÁºñÁ†ÅÁöÑÂä®Êú∫‰∏éÊµÅÁ®ã ‰∏∫‰ªÄ‰πà‰ΩøÁî®One-Hot\nÈÄöËøáÂ∞ÜÁ±ªÂà´Êò†Â∞Ñ‰∏∫ÂêëÈáèÔºåÈÅøÂÖçÊï¥Êï∞ÁºñÁ†ÅÂºïÂÖ•ÁöÑ‰º™Êï∞ÂÄºÂÖ≥Á≥ª„ÄÇ ÂêåÊó∂‰øùÁïôÂêÑÁßçÂèØËÉΩÁ±ªÂà´ÁöÑ‰ø°ÊÅØÔºå‰∏î‰ªÖÂú®ÂØπÂ∫î‰ΩçÁΩÆ‰∏∫1ÔºåÂÖ∂‰ªñ‰ΩçÁΩÆ‰∏∫0„ÄÇ Âª∫Á´ãÊò†Â∞ÑÔºö‰ªéÁ±ªÂà´Âà∞Á¥¢Âºï\n‰∏∫ÊØè‰∏™Á±ªÂà´ÂàÜÈÖç‰∏Ä‰∏™ÂîØ‰∏ÄÁ¥¢ÂºïÔºåÈÄöÂ∏∏‰ªé1ÂºÄÂßã„ÄÇ È¢ÑÁïôÁ¥¢Âºï0Ë°®Á§∫‚ÄúÊú™Áü•‚ÄùÊàñ‚ÄúÁº∫Â§±‚ÄùÔºåÂØπÂ∫îÂÖ®0ÂêëÈáè„ÄÇ ËΩ¨Êç¢‰∏∫One-HotÂêëÈáè\nËã•Á±ªÂà´ÊÄªÊï∞‰∏∫197ÔºåÂàôÁî®197Áª¥ÂêëÈáèË°®Á§∫„ÄÇ ‰æãÂ≠êÔºöÁæéÂõΩ [1, 0, 0, 0, ‚Ä¶]Ôºå ‰∏≠ÂõΩ [0, 1, 0, 0, ‚Ä¶]„ÄÇ Á§∫‰æãÔºöË°®Á§∫‰∏Ä‰∏™‰∫∫ÁöÑÁâπÂæÅ\nÁâπÂæÅÂåÖÂê´ÔºàÂπ¥ÈæÑ, ÊÄßÂà´, ÂõΩÁ±çÔºåÂÖ∂‰∏≠ÂõΩÁ±ç197ÁßçÔºâ Áª¥Â∫¶ÊÄªÂíåÔºö1Áª¥_age + 1Áª¥_gender + 197Áª¥_nationality = 199Áª¥„ÄÇ ‰æãÂ¶Ç (28, Â•≥, ‰∏≠ÂõΩ) ‚Üí [28, 0, 0, 1, 0, ‚Ä¶, 0]„ÄÇ ‰∏â„ÄÅÊñáÊú¨Êï∞ÊçÆÂ§ÑÁêÜÊµÅÁ®ã ÊñáÊú¨Âú®Ëá™ÁÑ∂ËØ≠Ë®ÄÂ§ÑÁêÜÔºàNLPÔºâ‰∏≠‰Ωú‰∏∫Â∏∏ËßÅÁöÑÂéüÂßãËæìÂÖ•ÔºåÈúÄË¶ÅÊï∞ÂÄºÂåñÊâçËÉΩÈÄÅÂÖ•Ê®°Âûã„ÄÇ‰∏ÄËà¨Ê≠•È™§Â¶Ç‰∏ãÔºö\nÂàÜËØç (Tokenization)\nÂ∞ÜÊñáÊú¨ÊãÜÂàÜ‰∏∫‰∏Ä‰∏™‰∏™ÂçïËØçÔºàTokenÔºâ„ÄÇ ‰æãÂ≠êÔºö\u0026quot;... to be or not to be...\u0026quot; ‚Üí [\u0026quot;...\u0026quot;, \u0026quot;to\u0026quot;, \u0026quot;be\u0026quot;, \u0026quot;or\u0026quot;, \u0026quot;not\u0026quot;, \u0026quot;to\u0026quot;, \u0026quot;be\u0026quot;, \u0026quot;...\u0026quot;]„ÄÇ ÁªüËÆ°ËØçÈ¢ë \u0026amp; ÊûÑÂª∫ËØçÂÖ∏\nËØçÈ¢ëÁªüËÆ° Áî®ÂìàÂ∏åË°®/Â≠óÂÖ∏ËÆ∞ÂΩïÊØè‰∏™ÂçïËØçÂá∫Áé∞Ê¨°Êï∞„ÄÇ ÈÅçÂéÜÊñáÊú¨Êó∂ÔºåËã•ÂçïËØçÂ∞öÊú™ÂÖ•Ë°®ÔºåÂàôÊñ∞Âª∫ËÆ∞ÂΩïÔºõËã•Â∑≤Â≠òÂú®ÔºåÂàôËÆ°Êï∞+1„ÄÇ ÊéíÂ∫è‰∏éÁ¥¢Âºï ÊåâËØçÈ¢ëÈôçÂ∫èÊéíÂ∫èÔºåËØçÈ¢ëÊúÄÈ´òÁöÑÂçïËØçÊéíÂú®ÂâçÈù¢„ÄÇ Á¥¢Âºï‰ªé1ÂºÄÂßãÔºå0ÁïôÁªô‚ÄúÊú™Áü•‚Äù„ÄÇ ËØçÂÖ∏ËßÑÊ®°ÔºàvocabularyÔºâÂèØËßÜÈúÄÊ±ÇÊà™Êñ≠Ôºà‰æãÂ¶ÇÂè™‰øùÁïôTop 10kÔºâ„ÄÇ ‰∏∫‰ªÄ‰πàÁßªÈô§‰ΩéÈ¢ëËØç ‰ΩéÈ¢ëËØçÂèØËÉΩÊòØÊãºÂÜôÈîôËØØ„ÄÅÁΩïËßÅ‰∫∫ÂêçÁ≠âÔºåÂØπÊ®°ÂûãÂ∏ÆÂä©ÊúâÈôê„ÄÇ ÂáèÂ∞ëËØçÂÖ∏ËßÑÊ®°ÂèØÈôç‰ΩéËøêÁÆóÂºÄÈîÄ„ÄÅÂä†Âø´Ê®°ÂûãËÆ≠ÁªÉ‰∏éÊé®ÁêÜÈÄüÂ∫¶„ÄÇ Áã¨ÁÉ≠ÁºñÁ†Å (One-Hot Encoding)\nÂ∞ÜÊØè‰∏™ÂçïËØçÊò†Â∞Ñ‰∏∫ËØçÂÖ∏‰∏≠ÁöÑÁ¥¢ÂºïÂêéÔºàÂ¶Ç [2, 4, 1, 8, ‚Ä¶]ÔºâÔºåÂèØËøõ‰∏ÄÊ≠•ËΩ¨Êç¢ÊàêOne-HotÂêëÈáè„ÄÇ One-HotÁª¥Â∫¶ÂèñÂÜ≥‰∫é‰øùÁïô‰∏ãÊù•ÁöÑËØçÂÖ∏Â§ßÂ∞èÔºà‰æãÂ¶Ç1‰∏áÔºâ„ÄÇ Êú™Êî∂ÂΩïÂçïËØçÂèØËÉΩÁõ¥Êé•ÂøΩÁï•ÔºåÊàñÁªü‰∏ÄÁî®Á¥¢Âºï0‰ª£Êõø„ÄÇ Âõõ„ÄÅÊ†∏ÂøÉÊî∂Ëé∑‰∏éÂ∫îÁî® Á±ªÂà´ÁâπÂæÅÂøÖÈúÄÊï∞ÂÄºÂåñÔºö\n‰ΩøÁî®Êï¥Êï∞1,2,3‚Ä¶‰ªÖË°®Á§∫Á±ªÂà´‚ÄúÊ†áËØÜ‚ÄùÔºåÂπ∂‰∏ç‰ª£Ë°®ÂÆÉ‰ª¨ÂèØËøõË°åÊï∞ÂÄºËøêÁÆó„ÄÇ Âõ†Ê≠§ÈúÄË¶ÅOne-HotÁ≠âÁºñÁ†ÅÊñπÂºèÔºåÈÅøÂÖçÊï∞ÂÄºËØØËß£„ÄÇ ÊñáÊú¨Êï∞ÊçÆÈ¢ÑÂ§ÑÁêÜÔºö\nÂàÜËØç„ÄÅËØçÈ¢ëÁªüËÆ°„ÄÅÊûÑÂª∫ËØçÂÖ∏„ÄÅÁ¥¢ÂºïÂåñ„ÄÅOne-HotÊàñÂÖ∂‰ªñÊñπÂºèÔºàÂ¶ÇËØçÂµåÂÖ•ÔºâÊòØÂ∏∏ËßÅÊµÅÁ®ã„ÄÇ Ê≠£Á°ÆÁöÑÊñáÊú¨È¢ÑÂ§ÑÁêÜÂèØÊòæËëóÂΩ±ÂìçÊ®°ÂûãÊÄßËÉΩÂíåÊïàÁéá„ÄÇ ‰øùÁïôÊú™Áü•Á¥¢ÂºïÔºö\n‰øùËØÅÂØπÁº∫Â§±Êï∞ÊçÆÊàñÂ≠óÂÖ∏Â§ñÊñ∞ËØçËÉΩÊúâÂü∫Êú¨ÁöÑË°®Á§∫ÔºåÊèêÂçáÊ®°ÂûãÂÆπÈîôÊÄß„ÄÇ ÂÆûÈôÖ‰ΩøÁî®Ôºö\nÂØπ‰∫éÂ∞èËßÑÊ®°Á±ªÂà´ÂèØÁõ¥Êé•One-HotÁºñÁ†ÅÔºõÂØπ‰∫éËØçÂÖ∏ÂæàÂ§ßÁöÑÂú∫ÊôØÔºåÈÄöÂ∏∏‰ºöËøõ‰∏ÄÊ≠•ËÄÉËôëËØçÂµåÂÖ•ÔºàWord EmbeddingÔºâÊàñÈ¢ÑËÆ≠ÁªÉËØ≠Ë®ÄÊ®°Âûã„ÄÇ ","permalink":"http://localhost:1313/posts/nlp-1/","summary":"\u003ch2 id=\"‰∏ÄÊï∞ÂÄºÁâπÂæÅ‰∏éÁ±ªÂà´ÁâπÂæÅ\"\u003e‰∏Ä„ÄÅÊï∞ÂÄºÁâπÂæÅ‰∏éÁ±ªÂà´ÁâπÂæÅ\u003c/h2\u003e\n\u003col\u003e\n\u003cli\u003e\u003cstrong\u003eÊï∞ÂÄºÁâπÂæÅ (Numeric Features)\u003c/strong\u003e\n\u003cul\u003e\n\u003cli\u003eÂÖ∑ÊúâÂèØÂä†ÂáèÁöÑÊÑè‰πâÔºå‰∏îÂ≠òÂú®Â§ßÂ∞èÈ°∫Â∫è„ÄÇ\u003c/li\u003e\n\u003cli\u003e‰æãÂ≠êÔºöÂπ¥ÈæÑ„ÄÅÊ∏©Â∫¶Á≠â„ÄÇÂèØ‰ª•Áõ¥Êé•‰øùÁïôÂÖ∂Êï¥Êï∞ÊàñÊµÆÁÇπÊï∞ÂΩ¢Âºè‰æõÊ®°Âûã‰ΩøÁî®„ÄÇ\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003eÁ±ªÂà´ÁâπÂæÅ (Categorical Features)\u003c/strong\u003e\n\u003cul\u003e\n\u003cli\u003eÊï∞ÊçÆÂÄºÁ¶ªÊï£Ôºå‰∏çÂÖ∑Â§á‚ÄúÊï∞ÂÄºÂ§ßÂ∞è‚ÄùÈó¥ÁöÑÂèØÊØîÊÑè‰πâ„ÄÇ\u003c/li\u003e\n\u003cli\u003e‰æãÂ≠êÔºöÂõΩÁ±çÔºàÁæéÂõΩ/‰∏≠ÂõΩ/Âç∞Â∫¶Á≠âÔºâ„ÄÅÊÄßÂà´ÔºàÁî∑/Â•≥ÔºâÁ≠â„ÄÇ\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003eÈóÆÈ¢ò\u003c/strong\u003eÔºöËã•‰ªÖÁî®Êï¥Êï∞Ë°®Á§∫ÔºàÁæéÂõΩ=1, ‰∏≠ÂõΩ=2ÔºâÔºå‰ºöÂºïÂÖ•ÈîôËØØÁöÑÊï∞ÂÄºËøêÁÆóÂÖ≥Á≥ªÔºåÂ¶Ç ‚ÄúÁæéÂõΩ + ‰∏≠ÂõΩ = Âç∞Â∫¶‚Äù„ÄÇ\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003c/ol\u003e\n\u003ch2 id=\"‰∫åone-hotÁºñÁ†ÅÁöÑÂä®Êú∫‰∏éÊµÅÁ®ã\"\u003e‰∫å„ÄÅOne-HotÁºñÁ†ÅÁöÑÂä®Êú∫‰∏éÊµÅÁ®ã\u003c/h2\u003e\n\u003col\u003e\n\u003cli\u003e\n\u003cp\u003e\u003cstrong\u003e‰∏∫‰ªÄ‰πà‰ΩøÁî®One-Hot\u003c/strong\u003e\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eÈÄöËøáÂ∞ÜÁ±ªÂà´Êò†Â∞Ñ‰∏∫ÂêëÈáèÔºåÈÅøÂÖçÊï¥Êï∞ÁºñÁ†ÅÂºïÂÖ•ÁöÑ‰º™Êï∞ÂÄºÂÖ≥Á≥ª„ÄÇ\u003c/li\u003e\n\u003cli\u003eÂêåÊó∂‰øùÁïôÂêÑÁßçÂèØËÉΩÁ±ªÂà´ÁöÑ‰ø°ÊÅØÔºå‰∏î‰ªÖÂú®ÂØπÂ∫î‰ΩçÁΩÆ‰∏∫1ÔºåÂÖ∂‰ªñ‰ΩçÁΩÆ‰∏∫0„ÄÇ\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003e\u003cstrong\u003eÂª∫Á´ãÊò†Â∞ÑÔºö‰ªéÁ±ªÂà´Âà∞Á¥¢Âºï\u003c/strong\u003e\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e‰∏∫ÊØè‰∏™Á±ªÂà´ÂàÜÈÖç‰∏Ä‰∏™ÂîØ‰∏ÄÁ¥¢ÂºïÔºåÈÄöÂ∏∏‰ªé1ÂºÄÂßã„ÄÇ\u003c/li\u003e\n\u003cli\u003eÈ¢ÑÁïôÁ¥¢Âºï0Ë°®Á§∫‚ÄúÊú™Áü•‚ÄùÊàñ‚ÄúÁº∫Â§±‚ÄùÔºåÂØπÂ∫îÂÖ®0ÂêëÈáè„ÄÇ\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003e\u003cstrong\u003eËΩ¨Êç¢‰∏∫One-HotÂêëÈáè\u003c/strong\u003e\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eËã•Á±ªÂà´ÊÄªÊï∞‰∏∫197ÔºåÂàôÁî®197Áª¥ÂêëÈáèË°®Á§∫„ÄÇ\u003c/li\u003e\n\u003cli\u003e‰æãÂ≠êÔºöÁæéÂõΩ \u003ccode\u003e[1, 0, 0, 0, ‚Ä¶]\u003c/code\u003eÔºå ‰∏≠ÂõΩ \u003ccode\u003e[0, 1, 0, 0, ‚Ä¶]\u003c/code\u003e„ÄÇ\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003e\u003cstrong\u003eÁ§∫‰æãÔºöË°®Á§∫‰∏Ä‰∏™‰∫∫ÁöÑÁâπÂæÅ\u003c/strong\u003e\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eÁâπÂæÅÂåÖÂê´ÔºàÂπ¥ÈæÑ, ÊÄßÂà´, ÂõΩÁ±çÔºåÂÖ∂‰∏≠ÂõΩÁ±ç197ÁßçÔºâ\u003c/li\u003e\n\u003cli\u003eÁª¥Â∫¶ÊÄªÂíåÔºö1Áª¥_age + 1Áª¥_gender + 197Áª¥_nationality = 199Áª¥„ÄÇ\u003c/li\u003e\n\u003cli\u003e‰æãÂ¶Ç \u003ccode\u003e(28, Â•≥, ‰∏≠ÂõΩ)\u003c/code\u003e ‚Üí \u003ccode\u003e[28, 0, 0, 1, 0, ‚Ä¶, 0]\u003c/code\u003e„ÄÇ\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003c/ol\u003e\n\u003ch2 id=\"‰∏âÊñáÊú¨Êï∞ÊçÆÂ§ÑÁêÜÊµÅÁ®ã\"\u003e‰∏â„ÄÅÊñáÊú¨Êï∞ÊçÆÂ§ÑÁêÜÊµÅÁ®ã\u003c/h2\u003e\n\u003cp\u003eÊñáÊú¨Âú®Ëá™ÁÑ∂ËØ≠Ë®ÄÂ§ÑÁêÜÔºàNLPÔºâ‰∏≠‰Ωú‰∏∫Â∏∏ËßÅÁöÑÂéüÂßãËæìÂÖ•ÔºåÈúÄË¶ÅÊï∞ÂÄºÂåñÊâçËÉΩÈÄÅÂÖ•Ê®°Âûã„ÄÇ‰∏ÄËà¨Ê≠•È™§Â¶Ç‰∏ãÔºö\u003c/p\u003e\n\u003col\u003e\n\u003cli\u003e\n\u003cp\u003e\u003cstrong\u003eÂàÜËØç (Tokenization)\u003c/strong\u003e\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eÂ∞ÜÊñáÊú¨ÊãÜÂàÜ‰∏∫‰∏Ä‰∏™‰∏™ÂçïËØçÔºàTokenÔºâ„ÄÇ\u003c/li\u003e\n\u003cli\u003e‰æãÂ≠êÔºö\u003ccode\u003e\u0026quot;... to be or not to be...\u0026quot;\u003c/code\u003e ‚Üí \u003ccode\u003e[\u0026quot;...\u0026quot;, \u0026quot;to\u0026quot;, \u0026quot;be\u0026quot;, \u0026quot;or\u0026quot;, \u0026quot;not\u0026quot;, \u0026quot;to\u0026quot;, \u0026quot;be\u0026quot;, \u0026quot;...\u0026quot;]\u003c/code\u003e„ÄÇ\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003e\u003cstrong\u003eÁªüËÆ°ËØçÈ¢ë \u0026amp; ÊûÑÂª∫ËØçÂÖ∏\u003c/strong\u003e\u003c/p\u003e","title":""},{"content":"Text to Sequence ÊñáÊú¨Â§ÑÁêÜ\nStep1: Tokenization\nTokenization breaks a piece of text down into a list of tokens.\nHere, a token is a word. (A token can be a character in some applications.)\nTokenizationËÆ≤Á©∂ÂæàÂ§öÔºå‰æãÂ¶ÇÊòØÂê¶Â∫îËØ•ÊääÂ§ßÂÜôÊîπÊàêÂ∞èÂÜôÂë¢ÔºüËøõË°åtypo correctionÁ≠âÁ≠â\nStep2: Build Dictionary\nUse a dictionary (hash table) to count word frequencies.\nThe dictionary maps word to index.\nÂèØ‰ª•È¶ñÂÖàÁªüËÆ°ËØçÈ¢ëÂéªÊéâ‰ΩéÈ¢ëËØçÔºåÁÑ∂ÂêéËÆ©ÊØè‰∏™ËØçÂØπÂ∫î‰∏Ä‰∏™Ê≠£Êï¥Êï∞ÔºõËøôÊ†∑ÁöÑËØùÔºå‰∏ÄÂè•ËØùÂ∞±ÂèØ‰ª•Áî®‰∏Ä‰∏™Ê≠£Êï¥Êï∞ÂàóË°®Ë°®Á§∫ÔºåËøô‰∏™ÂàóË°®Â∞±Âè´sequenceÔºõÂ¶ÇÊûúÂøÖË¶ÅÂ∞±ËøòÂæóÂÅöone-hot encoding„ÄÇ\nÁªìÊûú\n‰ΩÜÊòØÈïøÂ∫¶‰∏çÁªü‰∏Ä\nStep4: ÂØπÈΩêsequence\nËß£ÂÜ≥ÊñπÊ°àÊòØËøôÊ†∑ÁöÑÔºöÂèØ‰ª•Âõ∫ÂÆöÈïøÂ∫¶‰∏∫wÔºåÂä†ÂÖ•‰∏Ä‰∏™Â∫èÂàóÈïøÂ∫¶Â§™ÈïøÔºåÂ∞±Á†çÊéâÂâçÈù¢ÁöÑËØçÔºåÂè™‰øùÁïôÊúÄÂêéw‰∏™ËØçÔºõÂ¶ÇÊûú‰∏Ä‰∏™Â∫èÂàóÂ§™Áü≠ÔºåÂ∞±ÂÅözero paddingÔºåÁî®0Â°´ÂÖÖ\nËøôÊ†∑‰∏ÄÊù•ÔºåÊâÄÊúâÁöÑÂ∫èÂàóÈïøÂ∫¶Â∞±Áªü‰∏Ä‰∫Ü\nÊñáÊú¨Â§ÑÁêÜÂÆåÊàê‰∫ÜÔºåÊé•‰∏ãÊù•ÊòØword embeddingÔºåÊääÂçïËØçË°®Á§∫‰∏∫‰∏Ä‰∏™‰ΩéÁª¥ÂêëÈáèÔºõ\nÁÑ∂ËÄåËøôÊ†∑ÂÅöÁöÑËØùÔºåÂ¶ÇÊûúÊòØ10000‰∏™ÂçïËØçÔºåÁª¥Â∫¶Â∞±ÊòØ10000Áª¥ÔºåÁª¥Â∫¶Â§™È´ò‰∫ÜÔºõÂõ†Ê≠§Ë¶ÅÂÅöword embeddingÔºõ\nÂÖ∑‰ΩìÂÅöÊ≥ïÂ∞±ÊòØÊääone-hotÂêëÈáèe_iÂíåÂèÇÊï∞Áü©ÈòµpÁõ∏‰πòÔºõÁü©ÈòµPËΩ¨ÁΩÆÁöÑÂ§ßÂ∞èÊòØd x vÔºõdÊòØËØçÂêëÈáèÁöÑÁª¥Â∫¶ÔºõvÊòØÂ≠óÂÖ∏ÈáåËØçÊ±áÁöÑÊï∞ÈáèÔºõÁªìÊûú‰∏∫x_iÔºõx_iÂ∞±ÊòØ‰∏Ä‰∏™ËØçÂêëÈáèÔºõÂ¶ÇÊûúone-hotÂêëÈáèÁöÑÁ¨¨‰∏âË°å‰∏∫1ÔºõÈÇ£‰πàx_iÂ∞±ÊòØPËΩ¨ÁΩÆÁü©ÈòµÁöÑÁ¨¨‰∏âÂàóÔºàÂÖ∂‰ΩôÂàóÈÉΩ‰∏∫0ÔºâÔºõÊâÄ‰ª•PËΩ¨ÁΩÆÊØè‰∏ÄÂàóÈÉΩÊòØ‰∏Ä‰∏™ËØçÂêëÈáèÔºõÊâÄ‰ª•Áü©ÈòµPÊú¨Ë∫´ÁöÑÊØè‰∏ÄË°åÂ∞±ÊòØ‰∏Ä‰∏™ËØçÂêëÈáèÔºõÂÖ∂Ë°åÊï∞‰∏∫vÔºõÂç≥vocabularyÔºåËØçÊ±áÈáèÔºõÊØè‰∏ÄË°åÂØπÂ∫î‰∏Ä‰∏™ÂçïËØçÔºõÁü©ÈòµÁöÑÂàóÊï∞‰∏∫dÔºõdÊòØÁî®Êà∑ÂÜ≥ÂÆöÁöÑÔºõdÁöÑÂ§ßÂ∞è‰ºöÂÜ≥ÂÆöÊú∫Âô®Â≠¶‰π†Ê®°ÂûãÁöÑË°®Áé∞ÔºõÂ∫îËØ•Áî®xxxÊù•ÈÄâÊã©‰∏Ä‰∏™ÊØîËæÉÂ•ΩÁöÑdÔºõ\nÊàë‰ª¨ÁöÑ‰ªªÂä°ÊòØÁúãËØÑËÆ∫ÊòØÊ≠£Èù¢ÁöÑËøòÊòØË¥üÈù¢ÁöÑÔºõÂèÇÊï∞Áü©ÈòµÊòØ‰ªéËÆ≠ÁªÉÊï∞ÊçÆ‰∏≠Â≠¶‰π†Âá∫Êù•ÁöÑÔºåÊâÄ‰ª•Â≠¶Âá∫Êù•ÁöÑËØçÂêëÈáèÊòØÂ∏¶ÊúâÊÑüÊÉÖËâ≤ÂΩ©ÁöÑÔºõÂÅáËÆæËøô‰∫õËØçÂêëÈáèÈÉΩÊòØ‰∫åÁª¥ÁöÑÔºåÂàôÂèØ‰ª•Âú®Âπ≥Èù¢ÂùêÊ†áÁ≥ª‰∏≠Ê†áÂá∫‰∏ãÈù¢ËØçÂêëÈáè\nkerasÊèê‰æõembeddingÂ±ÇÔºõÁî®Êà∑ÂèØ‰ª•ÊåáÂÆövocabularyÂ§ßÂ∞èÂíådÁöÑÂ§ßÂ∞èÔºõ‰ª•ÂèäÊØè‰∏Ä‰∏™sequenceÁöÑÈïøÂ∫¶ÔºõdÊòØÊ†πÊçÆÁÆóÊ≥ïÈÄâÂá∫Êù•ÁöÑ Âà∞Ëøô‰∏ÄÊ≠•ÔºåÊàë‰ª¨Â∑≤ÁªèÂÆåÊàê‰∫ÜÊñáÊú¨Â§ÑÁêÜÂíåword embedding„ÄÇÊé•‰∏ãÊù•Â∞±ÊòØÁî®Logistic Regression for Binary ClassificationÂÅö‰∫åÂàÜÁ±ªÔºõ\n","permalink":"http://localhost:1313/posts/nlp-2/","summary":"\u003ch3 id=\"text-to-sequence\"\u003eText to Sequence\u003c/h3\u003e\n\u003cp\u003eÊñáÊú¨Â§ÑÁêÜ\u003c/p\u003e\n\u003cp\u003eStep1: Tokenization\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\n\u003cp\u003eTokenization breaks a piece of text down into a list of tokens.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003eHere, a token is a word. (A token can be a character in some applications.)\u003c/p\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003eTokenizationËÆ≤Á©∂ÂæàÂ§öÔºå‰æãÂ¶ÇÊòØÂê¶Â∫îËØ•ÊääÂ§ßÂÜôÊîπÊàêÂ∞èÂÜôÂë¢ÔºüËøõË°åtypo correctionÁ≠âÁ≠â\u003c/p\u003e\n\u003cp\u003e\u003cimg alt=\"image-20250322150322238\" loading=\"lazy\" src=\"./NLP-2.assets/image-20250322150322238.png\"\u003e\u003c/p\u003e\n\u003cp\u003eStep2: Build Dictionary\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\n\u003cp\u003eUse a dictionary (hash table) to count word frequencies.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003eThe dictionary maps word to index.\u003c/p\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003eÂèØ‰ª•È¶ñÂÖàÁªüËÆ°ËØçÈ¢ëÂéªÊéâ‰ΩéÈ¢ëËØçÔºåÁÑ∂ÂêéËÆ©ÊØè‰∏™ËØçÂØπÂ∫î‰∏Ä‰∏™Ê≠£Êï¥Êï∞ÔºõËøôÊ†∑ÁöÑËØùÔºå‰∏ÄÂè•ËØùÂ∞±ÂèØ‰ª•Áî®‰∏Ä‰∏™Ê≠£Êï¥Êï∞ÂàóË°®Ë°®Á§∫ÔºåËøô‰∏™ÂàóË°®Â∞±Âè´sequenceÔºõÂ¶ÇÊûúÂøÖË¶ÅÂ∞±ËøòÂæóÂÅöone-hot encoding„ÄÇ\u003cimg alt=\"image-20250322150620890\" loading=\"lazy\" src=\"./NLP-2.assets/image-20250322150620890.png\"\u003e\u003c/p\u003e\n\u003cp\u003eÁªìÊûú\u003c/p\u003e\n\u003cp\u003e\u003cimg alt=\"image-20250322150754528\" loading=\"lazy\" src=\"./NLP-2.assets/image-20250322150754528.png\"\u003e\u003c/p\u003e\n\u003cp\u003e‰ΩÜÊòØÈïøÂ∫¶‰∏çÁªü‰∏Ä\u003c/p\u003e\n\u003cp\u003eStep4: ÂØπÈΩêsequence\u003c/p\u003e\n\u003cp\u003e\u003cimg alt=\"image-20250322150854986\" loading=\"lazy\" src=\"./NLP-2.assets/image-20250322150854986.png\"\u003e\u003c/p\u003e\n\u003cp\u003eËß£ÂÜ≥ÊñπÊ°àÊòØËøôÊ†∑ÁöÑÔºöÂèØ‰ª•Âõ∫ÂÆöÈïøÂ∫¶‰∏∫wÔºåÂä†ÂÖ•‰∏Ä‰∏™Â∫èÂàóÈïøÂ∫¶Â§™ÈïøÔºåÂ∞±Á†çÊéâÂâçÈù¢ÁöÑËØçÔºåÂè™‰øùÁïôÊúÄÂêéw‰∏™ËØçÔºõÂ¶ÇÊûú‰∏Ä‰∏™Â∫èÂàóÂ§™Áü≠ÔºåÂ∞±ÂÅözero paddingÔºåÁî®0Â°´ÂÖÖ\u003c/p\u003e\n\u003cp\u003e\u003cimg alt=\"image-20250322151030119\" loading=\"lazy\" src=\"./NLP-2.assets/image-20250322151030119.png\"\u003e\u003c/p\u003e\n\u003cp\u003eËøôÊ†∑‰∏ÄÊù•ÔºåÊâÄÊúâÁöÑÂ∫èÂàóÈïøÂ∫¶Â∞±Áªü‰∏Ä‰∫Ü\u003c/p\u003e\n\u003cp\u003e\u003cimg alt=\"image-20250322151117125\" loading=\"lazy\" src=\"./NLP-2.assets/image-20250322151117125.png\"\u003e\u003c/p\u003e\n\u003cp\u003eÊñáÊú¨Â§ÑÁêÜÂÆåÊàê‰∫ÜÔºåÊé•‰∏ãÊù•ÊòØword embeddingÔºåÊääÂçïËØçË°®Á§∫‰∏∫‰∏Ä‰∏™‰ΩéÁª¥ÂêëÈáèÔºõ\u003c/p\u003e\n\u003cp\u003e\u003cimg alt=\"image-20250322151252837\" loading=\"lazy\" src=\"./NLP-2.assets/image-20250322151252837.png\"\u003e\u003c/p\u003e","title":""},{"content":"üëã About me Hello! I‚Äôm Xu Zongsi, a passionate technology enthusiast currently pursuing my Master of Science in Electronic Commerce \u0026amp; Internet Computing at The University of Hong Kong. With a solid background in Software Engineering from the Beijing Institute of Technology, I specialize in emerging areas of artificial intelligence, including machine learning, deep learning, natural language processing, computer vision, and reinforcement learning.\nRecently, inspired by OpenAI\u0026rsquo;s five-step plan towards superintelligence, I have great expectations for AGI and developed a strong interest in LLM agents, MLLM, reinforcement learning, and knowledge graphs. I believe there is significant potential in these fields to create innovative solutions, and I hope to contribute my efforts towards that goal.\nüìö Education üá≠üá∞ The University of Hong Kong 09/2024 - Expected 11/2025 School of Computing and Data Science Master of Science in Electronic Commerce \u0026amp; Internet Computing Relevant Courses: Machine learning for business and e-commerce, Knowledge graphs, Financial fraud analytics, Internet infrastructure technologies, Website engineering, Blockchain and cryptocurrency, etc. üá®üá≥ Beijing Institute of Technology 09/2020 - 06/2024 School of Computer Science \u0026amp; Technology Bachelor of Engineering in Software Engineering, last two years GPA: 3.7/4 Relevant Courses: Reinforcement Learning, Deep Learning and Computer Vision, Artificial Intelligence and Robot Ethics, Almost Human: Mind, Brain and Artificial Intelligence, Mathematical Analysis for Engineering, Linear Algebra, Probability and Mathematical Statistics, etc. Skills: Python, Java, common data structures, design patterns, machine learning basics and algorithms, Linux, PyTorch, and some development tools (git, conda, etc.). üèÜ Awards \u0026amp; Honors Beijing Institute of Technology Undergraduate Scholarship (Top 20% of Grade) 06/2023 3rd Prize of China International \u0026#34;Internet \u0026#43;\u0026#34; College Student\u0026#39;s Innovation Competition 08/2022 Bronze Prize of \u0026#34;Challenge Cup\u0026#34; Capital University Entrepreneurship Competition 05/2022 üíº Project Experience Online Transaction Fraud Detection 09/2024 ‚Äì 01/2025 Independent project, supervised by Dr. Vivien Chan Focused on addressing financial fraud in e-commerce to enhance the accuracy of transaction anomaly detection, while independently managing the entire case study that included data preprocessing, feature engineering, model building, evaluation, and results analysis. Effectively resolved class imbalance issues using SMOTE and ROSE techniques. Built various models including Logistic Regression, Random Forest, XGBoost, and LightGBM, ultimately selecting the LightGBM model to achieve a recall rate of 95.45% and an AUC of 99.84%. Wrote efficient and maintainable code, enhancing model training and data processing efficiency through parallel computing and logging. Multi-Model Intelligent Text Keyword Extraction System 08/2023 ‚Äì 09/2023 Group project, supervised by Associate Prof. Xiaolin Zhao Designed and implemented an intelligent text summary system that automatically extracts keywords from article titles and abstracts, enhancing the understanding and summarization of text information. Participated in the planning of the technical route and built a hybrid model combining extractive and generative approaches, utilizing advanced natural language processing techniques including KeyBERT, Sentence Transformer, BERT, and T5 models. Responsible for data preprocessing and tokenization, as well as the end-to-end implementation and training of the T5 model, optimizing the model architecture and hyperparameters, achieving satisfactory results after only 3 epochs of training. Model evaluation results showed that the Rouge-1, Rouge-2, and Rouge-L metrics reached 0.6345, 0.5038, and 0.5282, respectively, in the third epoch, validating the model\u0026rsquo;s effectiveness in the summarization task. Cambridge University Machine Learning Summer Project 07/2023 ‚Äì 08/2023 Group project, supervised by Prof. Pietro Li√≤ Participated in the Cambridge University deep learning summer project, focusing on deep reinforcement learning; explored multi-agent learning algorithms across different environments. Reproduced the Multi-Agent Deep Deterministic Policy Gradient (MADDPG) algorithm in the Simple Adversary environment and studied the effect of agent numbers on convergence speed and stability, finding optimal stability at 21 agents. Designed and implemented comparative experiments inspired by the Rainbow algorithm, assessing target network strategies versus the Double Deep Q-Network (Double DQN). The results demonstrated that Double DQN significantly enhanced convergence speed, optimizing the overall learning process. Co-authored a group project paper on agent numbers and strategies effectiveness in multi-agent systems, achieving a score of 71% in the summer program (the highest in my group) and a \u0026ldquo;First Class\u0026rdquo; classification in the UK grading system. Deep Learning and Computer Vision Semester Project 09/2022 ‚Äì 12/2022 Independent project, supervised by Associate Prof. Guangyu Gao Designed and implemented a waste classifier using the ResNet model to improve classification accuracy and reduce resource waste. The project also enhanced understanding of transfer learning techniques with ResNet. Collected a dataset of 16 waste categories and preprocessed the images for uniformity and standardization, incorporating data augmentation techniques to enhance the dataset. Conducted experiments using ResNet34 and ResNet50 models through transfer learning, accelerating network convergence by leveraging pretrained weights. During training, techniques such as Batch Normalization and Dropout were applied to mitigate the risk of overfitting. The final model achieved an accuracy of 90% on the training set, while the performance on the test set was 61%, indicating a significant overfitting phenomenon during the training process. üéì Internship Beijing Academy of Quantum Information Science 08/2023 ‚Äì 01/2024 Research Intern at Quantum Computation Department Proposed a quantum convolution kernel design based on variational quantum circuits and developed a universal quantum convolution layer, successfully integrating it into classical CNN architectures such as VGG, GoogLeNet, and ResNet. Developed and evaluated various hybrid models, including a simple model named HQCCNN-2, which achieved 84.45% accuracy on the FashionMNIST dataset, surpassing the traditional CNN\u0026rsquo;s 80.72%. This demonstrates the effectiveness of the quantum convolution layer in improving model performance. Tested on a real quantum computer further validated the effectiveness of the hybrid model, demonstrating the viable integration of quantum computing with deep learning, and highlighting the potential for leveraging quantum properties to enhance model performance. üèÖ Competition Experience China International \u0026#34;Internet \u0026#43;\u0026#34; College Students\u0026#39; Innovation Competition 08/2022 Zhongke Ushield: Deep Learning-based Face Privacy Protection Authentication System Responsible for constructing a localized facial feature extraction engine based on MobileFaceNet, ensuring feature extraction is completed on end devices (such as mobile phones and cameras), guaranteeing that raw data does not leave the domain and is not stored, thus enhancing user privacy protection while improving recognition efficiency. \u0026#34;Challenge Cup\u0026#34; Capital University Entrepreneurship Competition 05/2022 Smart Orchard Responsible for the development of the fruit detection, ripeness prediction, and pest identification system, using deep convolutional neural network (CNN) technology for intelligent monitoring of crop growth conditions. Applied advanced object detection algorithms such as Faster R-CNN and YOLO to achieve high precision in apple detection and ripeness assessment, with an accuracy rate exceeding 90%, significantly enhancing the intelligence level of orchard management. Built and trained a dedicated dataset containing various pest samples, optimizing pest detection accuracy through data preprocessing (such as image normalization and resizing) and data augmentation techniques (like rotation, flipping, and noise addition), enabling the real-time monitoring system to accurately identify over 80% of pests, providing effective scientific maintenance recommendations to help farmers reduce crop losses. üìã Extracurricular Activities Vice President, Cyber Security Club, Beijing Institute of Technology 09/2021-09/2022 Backbone, Media Center of the Student Union of Beijing Institute of Technology 10/2020-06/2021 üì´ Contact üìß zongsi.xu@outlook.com üëî Zongsi (Tristan) Xu üíª github.com/BaizeXS üìç Hong Kong SAR, China ","permalink":"http://localhost:1313/resume/","summary":"Personal resume of Zongsi (Tristan) Xu","title":"Zongsi (Tristan) Xu"},{"content":"‰∏Ä„ÄÅÊï∞ÂÄºÁâπÂæÅ‰∏éÁ±ªÂà´ÁâπÂæÅ Êï∞ÂÄºÁâπÂæÅ (Numeric Features) ÂÖ∑ÊúâÂèØÂä†ÂáèÁöÑÊÑè‰πâÔºå‰∏îÂ≠òÂú®Â§ßÂ∞èÈ°∫Â∫è„ÄÇ ‰æãÂ≠êÔºöÂπ¥ÈæÑ„ÄÅÊ∏©Â∫¶Á≠â„ÄÇÂèØ‰ª•Áõ¥Êé•‰øùÁïôÂÖ∂Êï¥Êï∞ÊàñÊµÆÁÇπÊï∞ÂΩ¢Âºè‰æõÊ®°Âûã‰ΩøÁî®„ÄÇ Á±ªÂà´ÁâπÂæÅ (Categorical Features) Êï∞ÊçÆÂÄºÁ¶ªÊï£Ôºå‰∏çÂÖ∑Â§á‚ÄúÊï∞ÂÄºÂ§ßÂ∞è‚ÄùÈó¥ÁöÑÂèØÊØîÊÑè‰πâ„ÄÇ ‰æãÂ≠êÔºöÂõΩÁ±çÔºàÁæéÂõΩ/‰∏≠ÂõΩ/Âç∞Â∫¶Á≠âÔºâ„ÄÅÊÄßÂà´ÔºàÁî∑/Â•≥ÔºâÁ≠â„ÄÇ ÈóÆÈ¢òÔºöËã•‰ªÖÁî®Êï¥Êï∞Ë°®Á§∫ÔºàÁæéÂõΩ=1, ‰∏≠ÂõΩ=2ÔºâÔºå‰ºöÂºïÂÖ•ÈîôËØØÁöÑÊï∞ÂÄºËøêÁÆóÂÖ≥Á≥ªÔºåÂ¶Ç ‚ÄúÁæéÂõΩ + ‰∏≠ÂõΩ = Âç∞Â∫¶‚Äù„ÄÇ ‰∫å„ÄÅOne-HotÁºñÁ†ÅÁöÑÂä®Êú∫‰∏éÊµÅÁ®ã ‰∏∫‰ªÄ‰πà‰ΩøÁî®One-Hot\nÈÄöËøáÂ∞ÜÁ±ªÂà´Êò†Â∞Ñ‰∏∫ÂêëÈáèÔºåÈÅøÂÖçÊï¥Êï∞ÁºñÁ†ÅÂºïÂÖ•ÁöÑ‰º™Êï∞ÂÄºÂÖ≥Á≥ª„ÄÇ ÂêåÊó∂‰øùÁïôÂêÑÁßçÂèØËÉΩÁ±ªÂà´ÁöÑ‰ø°ÊÅØÔºå‰∏î‰ªÖÂú®ÂØπÂ∫î‰ΩçÁΩÆ‰∏∫1ÔºåÂÖ∂‰ªñ‰ΩçÁΩÆ‰∏∫0„ÄÇ Âª∫Á´ãÊò†Â∞ÑÔºö‰ªéÁ±ªÂà´Âà∞Á¥¢Âºï\n‰∏∫ÊØè‰∏™Á±ªÂà´ÂàÜÈÖç‰∏Ä‰∏™ÂîØ‰∏ÄÁ¥¢ÂºïÔºåÈÄöÂ∏∏‰ªé1ÂºÄÂßã„ÄÇ È¢ÑÁïôÁ¥¢Âºï0Ë°®Á§∫‚ÄúÊú™Áü•‚ÄùÊàñ‚ÄúÁº∫Â§±‚ÄùÔºåÂØπÂ∫îÂÖ®0ÂêëÈáè„ÄÇ ËΩ¨Êç¢‰∏∫One-HotÂêëÈáè\nËã•Á±ªÂà´ÊÄªÊï∞‰∏∫197ÔºåÂàôÁî®197Áª¥ÂêëÈáèË°®Á§∫„ÄÇ ‰æãÂ≠êÔºöÁæéÂõΩ [1, 0, 0, 0, ‚Ä¶]Ôºå ‰∏≠ÂõΩ [0, 1, 0, 0, ‚Ä¶]„ÄÇ Á§∫‰æãÔºöË°®Á§∫‰∏Ä‰∏™‰∫∫ÁöÑÁâπÂæÅ\nÁâπÂæÅÂåÖÂê´ÔºàÂπ¥ÈæÑ, ÊÄßÂà´, ÂõΩÁ±çÔºåÂÖ∂‰∏≠ÂõΩÁ±ç197ÁßçÔºâ Áª¥Â∫¶ÊÄªÂíåÔºö1Áª¥_age + 1Áª¥_gender + 197Áª¥_nationality = 199Áª¥„ÄÇ ‰æãÂ¶Ç (28, Â•≥, ‰∏≠ÂõΩ) ‚Üí [28, 0, 0, 1, 0, ‚Ä¶, 0]„ÄÇ ‰∏â„ÄÅÊñáÊú¨Êï∞ÊçÆÂ§ÑÁêÜÊµÅÁ®ã ÊñáÊú¨Âú®Ëá™ÁÑ∂ËØ≠Ë®ÄÂ§ÑÁêÜÔºàNLPÔºâ‰∏≠‰Ωú‰∏∫Â∏∏ËßÅÁöÑÂéüÂßãËæìÂÖ•ÔºåÈúÄË¶ÅÊï∞ÂÄºÂåñÊâçËÉΩÈÄÅÂÖ•Ê®°Âûã„ÄÇ‰∏ÄËà¨Ê≠•È™§Â¶Ç‰∏ãÔºö\nÂàÜËØç (Tokenization)\nÂ∞ÜÊñáÊú¨ÊãÜÂàÜ‰∏∫‰∏Ä‰∏™‰∏™ÂçïËØçÔºàTokenÔºâ„ÄÇ ‰æãÂ≠êÔºö\u0026quot;... to be or not to be...\u0026quot; ‚Üí [\u0026quot;...\u0026quot;, \u0026quot;to\u0026quot;, \u0026quot;be\u0026quot;, \u0026quot;or\u0026quot;, \u0026quot;not\u0026quot;, \u0026quot;to\u0026quot;, \u0026quot;be\u0026quot;, \u0026quot;...\u0026quot;]„ÄÇ ÁªüËÆ°ËØçÈ¢ë \u0026amp; ÊûÑÂª∫ËØçÂÖ∏\nËØçÈ¢ëÁªüËÆ° Áî®ÂìàÂ∏åË°®/Â≠óÂÖ∏ËÆ∞ÂΩïÊØè‰∏™ÂçïËØçÂá∫Áé∞Ê¨°Êï∞„ÄÇ ÈÅçÂéÜÊñáÊú¨Êó∂ÔºåËã•ÂçïËØçÂ∞öÊú™ÂÖ•Ë°®ÔºåÂàôÊñ∞Âª∫ËÆ∞ÂΩïÔºõËã•Â∑≤Â≠òÂú®ÔºåÂàôËÆ°Êï∞+1„ÄÇ ÊéíÂ∫è‰∏éÁ¥¢Âºï ÊåâËØçÈ¢ëÈôçÂ∫èÊéíÂ∫èÔºåËØçÈ¢ëÊúÄÈ´òÁöÑÂçïËØçÊéíÂú®ÂâçÈù¢„ÄÇ Á¥¢Âºï‰ªé1ÂºÄÂßãÔºå0ÁïôÁªô‚ÄúÊú™Áü•‚Äù„ÄÇ ËØçÂÖ∏ËßÑÊ®°ÔºàvocabularyÔºâÂèØËßÜÈúÄÊ±ÇÊà™Êñ≠Ôºà‰æãÂ¶ÇÂè™‰øùÁïôTop 10kÔºâ„ÄÇ ‰∏∫‰ªÄ‰πàÁßªÈô§‰ΩéÈ¢ëËØç ‰ΩéÈ¢ëËØçÂèØËÉΩÊòØÊãºÂÜôÈîôËØØ„ÄÅÁΩïËßÅ‰∫∫ÂêçÁ≠âÔºåÂØπÊ®°ÂûãÂ∏ÆÂä©ÊúâÈôê„ÄÇ ÂáèÂ∞ëËØçÂÖ∏ËßÑÊ®°ÂèØÈôç‰ΩéËøêÁÆóÂºÄÈîÄ„ÄÅÂä†Âø´Ê®°ÂûãËÆ≠ÁªÉ‰∏éÊé®ÁêÜÈÄüÂ∫¶„ÄÇ Áã¨ÁÉ≠ÁºñÁ†Å (One-Hot Encoding)\nÂ∞ÜÊØè‰∏™ÂçïËØçÊò†Â∞Ñ‰∏∫ËØçÂÖ∏‰∏≠ÁöÑÁ¥¢ÂºïÂêéÔºàÂ¶Ç [2, 4, 1, 8, ‚Ä¶]ÔºâÔºåÂèØËøõ‰∏ÄÊ≠•ËΩ¨Êç¢ÊàêOne-HotÂêëÈáè„ÄÇ One-HotÁª¥Â∫¶ÂèñÂÜ≥‰∫é‰øùÁïô‰∏ãÊù•ÁöÑËØçÂÖ∏Â§ßÂ∞èÔºà‰æãÂ¶Ç1‰∏áÔºâ„ÄÇ Êú™Êî∂ÂΩïÂçïËØçÂèØËÉΩÁõ¥Êé•ÂøΩÁï•ÔºåÊàñÁªü‰∏ÄÁî®Á¥¢Âºï0‰ª£Êõø„ÄÇ Âõõ„ÄÅÊ†∏ÂøÉÊî∂Ëé∑‰∏éÂ∫îÁî® Á±ªÂà´ÁâπÂæÅÂøÖÈúÄÊï∞ÂÄºÂåñÔºö\n‰ΩøÁî®Êï¥Êï∞1,2,3‚Ä¶‰ªÖË°®Á§∫Á±ªÂà´‚ÄúÊ†áËØÜ‚ÄùÔºåÂπ∂‰∏ç‰ª£Ë°®ÂÆÉ‰ª¨ÂèØËøõË°åÊï∞ÂÄºËøêÁÆó„ÄÇ Âõ†Ê≠§ÈúÄË¶ÅOne-HotÁ≠âÁºñÁ†ÅÊñπÂºèÔºåÈÅøÂÖçÊï∞ÂÄºËØØËß£„ÄÇ ÊñáÊú¨Êï∞ÊçÆÈ¢ÑÂ§ÑÁêÜÔºö\nÂàÜËØç„ÄÅËØçÈ¢ëÁªüËÆ°„ÄÅÊûÑÂª∫ËØçÂÖ∏„ÄÅÁ¥¢ÂºïÂåñ„ÄÅOne-HotÊàñÂÖ∂‰ªñÊñπÂºèÔºàÂ¶ÇËØçÂµåÂÖ•ÔºâÊòØÂ∏∏ËßÅÊµÅÁ®ã„ÄÇ Ê≠£Á°ÆÁöÑÊñáÊú¨È¢ÑÂ§ÑÁêÜÂèØÊòæËëóÂΩ±ÂìçÊ®°ÂûãÊÄßËÉΩÂíåÊïàÁéá„ÄÇ ‰øùÁïôÊú™Áü•Á¥¢ÂºïÔºö\n‰øùËØÅÂØπÁº∫Â§±Êï∞ÊçÆÊàñÂ≠óÂÖ∏Â§ñÊñ∞ËØçËÉΩÊúâÂü∫Êú¨ÁöÑË°®Á§∫ÔºåÊèêÂçáÊ®°ÂûãÂÆπÈîôÊÄß„ÄÇ ÂÆûÈôÖ‰ΩøÁî®Ôºö\nÂØπ‰∫éÂ∞èËßÑÊ®°Á±ªÂà´ÂèØÁõ¥Êé•One-HotÁºñÁ†ÅÔºõÂØπ‰∫éËØçÂÖ∏ÂæàÂ§ßÁöÑÂú∫ÊôØÔºåÈÄöÂ∏∏‰ºöËøõ‰∏ÄÊ≠•ËÄÉËôëËØçÂµåÂÖ•ÔºàWord EmbeddingÔºâÊàñÈ¢ÑËÆ≠ÁªÉËØ≠Ë®ÄÊ®°Âûã„ÄÇ ","permalink":"http://localhost:1313/posts/nlp-1/","summary":"\u003ch2 id=\"‰∏ÄÊï∞ÂÄºÁâπÂæÅ‰∏éÁ±ªÂà´ÁâπÂæÅ\"\u003e‰∏Ä„ÄÅÊï∞ÂÄºÁâπÂæÅ‰∏éÁ±ªÂà´ÁâπÂæÅ\u003c/h2\u003e\n\u003col\u003e\n\u003cli\u003e\u003cstrong\u003eÊï∞ÂÄºÁâπÂæÅ (Numeric Features)\u003c/strong\u003e\n\u003cul\u003e\n\u003cli\u003eÂÖ∑ÊúâÂèØÂä†ÂáèÁöÑÊÑè‰πâÔºå‰∏îÂ≠òÂú®Â§ßÂ∞èÈ°∫Â∫è„ÄÇ\u003c/li\u003e\n\u003cli\u003e‰æãÂ≠êÔºöÂπ¥ÈæÑ„ÄÅÊ∏©Â∫¶Á≠â„ÄÇÂèØ‰ª•Áõ¥Êé•‰øùÁïôÂÖ∂Êï¥Êï∞ÊàñÊµÆÁÇπÊï∞ÂΩ¢Âºè‰æõÊ®°Âûã‰ΩøÁî®„ÄÇ\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003eÁ±ªÂà´ÁâπÂæÅ (Categorical Features)\u003c/strong\u003e\n\u003cul\u003e\n\u003cli\u003eÊï∞ÊçÆÂÄºÁ¶ªÊï£Ôºå‰∏çÂÖ∑Â§á‚ÄúÊï∞ÂÄºÂ§ßÂ∞è‚ÄùÈó¥ÁöÑÂèØÊØîÊÑè‰πâ„ÄÇ\u003c/li\u003e\n\u003cli\u003e‰æãÂ≠êÔºöÂõΩÁ±çÔºàÁæéÂõΩ/‰∏≠ÂõΩ/Âç∞Â∫¶Á≠âÔºâ„ÄÅÊÄßÂà´ÔºàÁî∑/Â•≥ÔºâÁ≠â„ÄÇ\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003eÈóÆÈ¢ò\u003c/strong\u003eÔºöËã•‰ªÖÁî®Êï¥Êï∞Ë°®Á§∫ÔºàÁæéÂõΩ=1, ‰∏≠ÂõΩ=2ÔºâÔºå‰ºöÂºïÂÖ•ÈîôËØØÁöÑÊï∞ÂÄºËøêÁÆóÂÖ≥Á≥ªÔºåÂ¶Ç ‚ÄúÁæéÂõΩ + ‰∏≠ÂõΩ = Âç∞Â∫¶‚Äù„ÄÇ\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003c/ol\u003e\n\u003ch2 id=\"‰∫åone-hotÁºñÁ†ÅÁöÑÂä®Êú∫‰∏éÊµÅÁ®ã\"\u003e‰∫å„ÄÅOne-HotÁºñÁ†ÅÁöÑÂä®Êú∫‰∏éÊµÅÁ®ã\u003c/h2\u003e\n\u003col\u003e\n\u003cli\u003e\n\u003cp\u003e\u003cstrong\u003e‰∏∫‰ªÄ‰πà‰ΩøÁî®One-Hot\u003c/strong\u003e\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eÈÄöËøáÂ∞ÜÁ±ªÂà´Êò†Â∞Ñ‰∏∫ÂêëÈáèÔºåÈÅøÂÖçÊï¥Êï∞ÁºñÁ†ÅÂºïÂÖ•ÁöÑ‰º™Êï∞ÂÄºÂÖ≥Á≥ª„ÄÇ\u003c/li\u003e\n\u003cli\u003eÂêåÊó∂‰øùÁïôÂêÑÁßçÂèØËÉΩÁ±ªÂà´ÁöÑ‰ø°ÊÅØÔºå‰∏î‰ªÖÂú®ÂØπÂ∫î‰ΩçÁΩÆ‰∏∫1ÔºåÂÖ∂‰ªñ‰ΩçÁΩÆ‰∏∫0„ÄÇ\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003e\u003cstrong\u003eÂª∫Á´ãÊò†Â∞ÑÔºö‰ªéÁ±ªÂà´Âà∞Á¥¢Âºï\u003c/strong\u003e\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e‰∏∫ÊØè‰∏™Á±ªÂà´ÂàÜÈÖç‰∏Ä‰∏™ÂîØ‰∏ÄÁ¥¢ÂºïÔºåÈÄöÂ∏∏‰ªé1ÂºÄÂßã„ÄÇ\u003c/li\u003e\n\u003cli\u003eÈ¢ÑÁïôÁ¥¢Âºï0Ë°®Á§∫‚ÄúÊú™Áü•‚ÄùÊàñ‚ÄúÁº∫Â§±‚ÄùÔºåÂØπÂ∫îÂÖ®0ÂêëÈáè„ÄÇ\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003e\u003cstrong\u003eËΩ¨Êç¢‰∏∫One-HotÂêëÈáè\u003c/strong\u003e\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eËã•Á±ªÂà´ÊÄªÊï∞‰∏∫197ÔºåÂàôÁî®197Áª¥ÂêëÈáèË°®Á§∫„ÄÇ\u003c/li\u003e\n\u003cli\u003e‰æãÂ≠êÔºöÁæéÂõΩ \u003ccode\u003e[1, 0, 0, 0, ‚Ä¶]\u003c/code\u003eÔºå ‰∏≠ÂõΩ \u003ccode\u003e[0, 1, 0, 0, ‚Ä¶]\u003c/code\u003e„ÄÇ\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003e\u003cstrong\u003eÁ§∫‰æãÔºöË°®Á§∫‰∏Ä‰∏™‰∫∫ÁöÑÁâπÂæÅ\u003c/strong\u003e\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eÁâπÂæÅÂåÖÂê´ÔºàÂπ¥ÈæÑ, ÊÄßÂà´, ÂõΩÁ±çÔºåÂÖ∂‰∏≠ÂõΩÁ±ç197ÁßçÔºâ\u003c/li\u003e\n\u003cli\u003eÁª¥Â∫¶ÊÄªÂíåÔºö1Áª¥_age + 1Áª¥_gender + 197Áª¥_nationality = 199Áª¥„ÄÇ\u003c/li\u003e\n\u003cli\u003e‰æãÂ¶Ç \u003ccode\u003e(28, Â•≥, ‰∏≠ÂõΩ)\u003c/code\u003e ‚Üí \u003ccode\u003e[28, 0, 0, 1, 0, ‚Ä¶, 0]\u003c/code\u003e„ÄÇ\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003c/ol\u003e\n\u003ch2 id=\"‰∏âÊñáÊú¨Êï∞ÊçÆÂ§ÑÁêÜÊµÅÁ®ã\"\u003e‰∏â„ÄÅÊñáÊú¨Êï∞ÊçÆÂ§ÑÁêÜÊµÅÁ®ã\u003c/h2\u003e\n\u003cp\u003eÊñáÊú¨Âú®Ëá™ÁÑ∂ËØ≠Ë®ÄÂ§ÑÁêÜÔºàNLPÔºâ‰∏≠‰Ωú‰∏∫Â∏∏ËßÅÁöÑÂéüÂßãËæìÂÖ•ÔºåÈúÄË¶ÅÊï∞ÂÄºÂåñÊâçËÉΩÈÄÅÂÖ•Ê®°Âûã„ÄÇ‰∏ÄËà¨Ê≠•È™§Â¶Ç‰∏ãÔºö\u003c/p\u003e\n\u003col\u003e\n\u003cli\u003e\n\u003cp\u003e\u003cstrong\u003eÂàÜËØç (Tokenization)\u003c/strong\u003e\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eÂ∞ÜÊñáÊú¨ÊãÜÂàÜ‰∏∫‰∏Ä‰∏™‰∏™ÂçïËØçÔºàTokenÔºâ„ÄÇ\u003c/li\u003e\n\u003cli\u003e‰æãÂ≠êÔºö\u003ccode\u003e\u0026quot;... to be or not to be...\u0026quot;\u003c/code\u003e ‚Üí \u003ccode\u003e[\u0026quot;...\u0026quot;, \u0026quot;to\u0026quot;, \u0026quot;be\u0026quot;, \u0026quot;or\u0026quot;, \u0026quot;not\u0026quot;, \u0026quot;to\u0026quot;, \u0026quot;be\u0026quot;, \u0026quot;...\u0026quot;]\u003c/code\u003e„ÄÇ\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003e\u003cstrong\u003eÁªüËÆ°ËØçÈ¢ë \u0026amp; ÊûÑÂª∫ËØçÂÖ∏\u003c/strong\u003e\u003c/p\u003e","title":""},{"content":"Text to Sequence ÊñáÊú¨Â§ÑÁêÜ\nStep1: Tokenization\nTokenization breaks a piece of text down into a list of tokens.\nHere, a token is a word. (A token can be a character in some applications.)\nTokenizationËÆ≤Á©∂ÂæàÂ§öÔºå‰æãÂ¶ÇÊòØÂê¶Â∫îËØ•ÊääÂ§ßÂÜôÊîπÊàêÂ∞èÂÜôÂë¢ÔºüËøõË°åtypo correctionÁ≠âÁ≠â\nStep2: Build Dictionary\nUse a dictionary (hash table) to count word frequencies.\nThe dictionary maps word to index.\nÂèØ‰ª•È¶ñÂÖàÁªüËÆ°ËØçÈ¢ëÂéªÊéâ‰ΩéÈ¢ëËØçÔºåÁÑ∂ÂêéËÆ©ÊØè‰∏™ËØçÂØπÂ∫î‰∏Ä‰∏™Ê≠£Êï¥Êï∞ÔºõËøôÊ†∑ÁöÑËØùÔºå‰∏ÄÂè•ËØùÂ∞±ÂèØ‰ª•Áî®‰∏Ä‰∏™Ê≠£Êï¥Êï∞ÂàóË°®Ë°®Á§∫ÔºåËøô‰∏™ÂàóË°®Â∞±Âè´sequenceÔºõÂ¶ÇÊûúÂøÖË¶ÅÂ∞±ËøòÂæóÂÅöone-hot encoding„ÄÇ\nÁªìÊûú\n‰ΩÜÊòØÈïøÂ∫¶‰∏çÁªü‰∏Ä\nStep4: ÂØπÈΩêsequence\nËß£ÂÜ≥ÊñπÊ°àÊòØËøôÊ†∑ÁöÑÔºöÂèØ‰ª•Âõ∫ÂÆöÈïøÂ∫¶‰∏∫wÔºåÂä†ÂÖ•‰∏Ä‰∏™Â∫èÂàóÈïøÂ∫¶Â§™ÈïøÔºåÂ∞±Á†çÊéâÂâçÈù¢ÁöÑËØçÔºåÂè™‰øùÁïôÊúÄÂêéw‰∏™ËØçÔºõÂ¶ÇÊûú‰∏Ä‰∏™Â∫èÂàóÂ§™Áü≠ÔºåÂ∞±ÂÅözero paddingÔºåÁî®0Â°´ÂÖÖ\nËøôÊ†∑‰∏ÄÊù•ÔºåÊâÄÊúâÁöÑÂ∫èÂàóÈïøÂ∫¶Â∞±Áªü‰∏Ä‰∫Ü\nÊñáÊú¨Â§ÑÁêÜÂÆåÊàê‰∫ÜÔºåÊé•‰∏ãÊù•ÊòØword embeddingÔºåÊääÂçïËØçË°®Á§∫‰∏∫‰∏Ä‰∏™‰ΩéÁª¥ÂêëÈáèÔºõ\nÁÑ∂ËÄåËøôÊ†∑ÂÅöÁöÑËØùÔºåÂ¶ÇÊûúÊòØ10000‰∏™ÂçïËØçÔºåÁª¥Â∫¶Â∞±ÊòØ10000Áª¥ÔºåÁª¥Â∫¶Â§™È´ò‰∫ÜÔºõÂõ†Ê≠§Ë¶ÅÂÅöword embeddingÔºõ\nÂÖ∑‰ΩìÂÅöÊ≥ïÂ∞±ÊòØÊääone-hotÂêëÈáèe_iÂíåÂèÇÊï∞Áü©ÈòµpÁõ∏‰πòÔºõÁü©ÈòµPËΩ¨ÁΩÆÁöÑÂ§ßÂ∞èÊòØd x vÔºõdÊòØËØçÂêëÈáèÁöÑÁª¥Â∫¶ÔºõvÊòØÂ≠óÂÖ∏ÈáåËØçÊ±áÁöÑÊï∞ÈáèÔºõÁªìÊûú‰∏∫x_iÔºõx_iÂ∞±ÊòØ‰∏Ä‰∏™ËØçÂêëÈáèÔºõÂ¶ÇÊûúone-hotÂêëÈáèÁöÑÁ¨¨‰∏âË°å‰∏∫1ÔºõÈÇ£‰πàx_iÂ∞±ÊòØPËΩ¨ÁΩÆÁü©ÈòµÁöÑÁ¨¨‰∏âÂàóÔºàÂÖ∂‰ΩôÂàóÈÉΩ‰∏∫0ÔºâÔºõÊâÄ‰ª•PËΩ¨ÁΩÆÊØè‰∏ÄÂàóÈÉΩÊòØ‰∏Ä‰∏™ËØçÂêëÈáèÔºõÊâÄ‰ª•Áü©ÈòµPÊú¨Ë∫´ÁöÑÊØè‰∏ÄË°åÂ∞±ÊòØ‰∏Ä‰∏™ËØçÂêëÈáèÔºõÂÖ∂Ë°åÊï∞‰∏∫vÔºõÂç≥vocabularyÔºåËØçÊ±áÈáèÔºõÊØè‰∏ÄË°åÂØπÂ∫î‰∏Ä‰∏™ÂçïËØçÔºõÁü©ÈòµÁöÑÂàóÊï∞‰∏∫dÔºõdÊòØÁî®Êà∑ÂÜ≥ÂÆöÁöÑÔºõdÁöÑÂ§ßÂ∞è‰ºöÂÜ≥ÂÆöÊú∫Âô®Â≠¶‰π†Ê®°ÂûãÁöÑË°®Áé∞ÔºõÂ∫îËØ•Áî®xxxÊù•ÈÄâÊã©‰∏Ä‰∏™ÊØîËæÉÂ•ΩÁöÑdÔºõ\nÊàë‰ª¨ÁöÑ‰ªªÂä°ÊòØÁúãËØÑËÆ∫ÊòØÊ≠£Èù¢ÁöÑËøòÊòØË¥üÈù¢ÁöÑÔºõÂèÇÊï∞Áü©ÈòµÊòØ‰ªéËÆ≠ÁªÉÊï∞ÊçÆ‰∏≠Â≠¶‰π†Âá∫Êù•ÁöÑÔºåÊâÄ‰ª•Â≠¶Âá∫Êù•ÁöÑËØçÂêëÈáèÊòØÂ∏¶ÊúâÊÑüÊÉÖËâ≤ÂΩ©ÁöÑÔºõÂÅáËÆæËøô‰∫õËØçÂêëÈáèÈÉΩÊòØ‰∫åÁª¥ÁöÑÔºåÂàôÂèØ‰ª•Âú®Âπ≥Èù¢ÂùêÊ†áÁ≥ª‰∏≠Ê†áÂá∫‰∏ãÈù¢ËØçÂêëÈáè\nkerasÊèê‰æõembeddingÂ±ÇÔºõÁî®Êà∑ÂèØ‰ª•ÊåáÂÆövocabularyÂ§ßÂ∞èÂíådÁöÑÂ§ßÂ∞èÔºõ‰ª•ÂèäÊØè‰∏Ä‰∏™sequenceÁöÑÈïøÂ∫¶ÔºõdÊòØÊ†πÊçÆÁÆóÊ≥ïÈÄâÂá∫Êù•ÁöÑ Âà∞Ëøô‰∏ÄÊ≠•ÔºåÊàë‰ª¨Â∑≤ÁªèÂÆåÊàê‰∫ÜÊñáÊú¨Â§ÑÁêÜÂíåword embedding„ÄÇÊé•‰∏ãÊù•Â∞±ÊòØÁî®Logistic Regression for Binary ClassificationÂÅö‰∫åÂàÜÁ±ªÔºõ\n","permalink":"http://localhost:1313/posts/nlp-2/","summary":"\u003ch3 id=\"text-to-sequence\"\u003eText to Sequence\u003c/h3\u003e\n\u003cp\u003eÊñáÊú¨Â§ÑÁêÜ\u003c/p\u003e\n\u003cp\u003eStep1: Tokenization\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\n\u003cp\u003eTokenization breaks a piece of text down into a list of tokens.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003eHere, a token is a word. (A token can be a character in some applications.)\u003c/p\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003eTokenizationËÆ≤Á©∂ÂæàÂ§öÔºå‰æãÂ¶ÇÊòØÂê¶Â∫îËØ•ÊääÂ§ßÂÜôÊîπÊàêÂ∞èÂÜôÂë¢ÔºüËøõË°åtypo correctionÁ≠âÁ≠â\u003c/p\u003e\n\u003cp\u003e\u003cimg alt=\"image-20250322150322238\" loading=\"lazy\" src=\"./NLP-2.assets/image-20250322150322238.png\"\u003e\u003c/p\u003e\n\u003cp\u003eStep2: Build Dictionary\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\n\u003cp\u003eUse a dictionary (hash table) to count word frequencies.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003eThe dictionary maps word to index.\u003c/p\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003eÂèØ‰ª•È¶ñÂÖàÁªüËÆ°ËØçÈ¢ëÂéªÊéâ‰ΩéÈ¢ëËØçÔºåÁÑ∂ÂêéËÆ©ÊØè‰∏™ËØçÂØπÂ∫î‰∏Ä‰∏™Ê≠£Êï¥Êï∞ÔºõËøôÊ†∑ÁöÑËØùÔºå‰∏ÄÂè•ËØùÂ∞±ÂèØ‰ª•Áî®‰∏Ä‰∏™Ê≠£Êï¥Êï∞ÂàóË°®Ë°®Á§∫ÔºåËøô‰∏™ÂàóË°®Â∞±Âè´sequenceÔºõÂ¶ÇÊûúÂøÖË¶ÅÂ∞±ËøòÂæóÂÅöone-hot encoding„ÄÇ\u003cimg alt=\"image-20250322150620890\" loading=\"lazy\" src=\"./NLP-2.assets/image-20250322150620890.png\"\u003e\u003c/p\u003e\n\u003cp\u003eÁªìÊûú\u003c/p\u003e\n\u003cp\u003e\u003cimg alt=\"image-20250322150754528\" loading=\"lazy\" src=\"./NLP-2.assets/image-20250322150754528.png\"\u003e\u003c/p\u003e\n\u003cp\u003e‰ΩÜÊòØÈïøÂ∫¶‰∏çÁªü‰∏Ä\u003c/p\u003e\n\u003cp\u003eStep4: ÂØπÈΩêsequence\u003c/p\u003e\n\u003cp\u003e\u003cimg alt=\"image-20250322150854986\" loading=\"lazy\" src=\"./NLP-2.assets/image-20250322150854986.png\"\u003e\u003c/p\u003e\n\u003cp\u003eËß£ÂÜ≥ÊñπÊ°àÊòØËøôÊ†∑ÁöÑÔºöÂèØ‰ª•Âõ∫ÂÆöÈïøÂ∫¶‰∏∫wÔºåÂä†ÂÖ•‰∏Ä‰∏™Â∫èÂàóÈïøÂ∫¶Â§™ÈïøÔºåÂ∞±Á†çÊéâÂâçÈù¢ÁöÑËØçÔºåÂè™‰øùÁïôÊúÄÂêéw‰∏™ËØçÔºõÂ¶ÇÊûú‰∏Ä‰∏™Â∫èÂàóÂ§™Áü≠ÔºåÂ∞±ÂÅözero paddingÔºåÁî®0Â°´ÂÖÖ\u003c/p\u003e\n\u003cp\u003e\u003cimg alt=\"image-20250322151030119\" loading=\"lazy\" src=\"./NLP-2.assets/image-20250322151030119.png\"\u003e\u003c/p\u003e\n\u003cp\u003eËøôÊ†∑‰∏ÄÊù•ÔºåÊâÄÊúâÁöÑÂ∫èÂàóÈïøÂ∫¶Â∞±Áªü‰∏Ä‰∫Ü\u003c/p\u003e\n\u003cp\u003e\u003cimg alt=\"image-20250322151117125\" loading=\"lazy\" src=\"./NLP-2.assets/image-20250322151117125.png\"\u003e\u003c/p\u003e\n\u003cp\u003eÊñáÊú¨Â§ÑÁêÜÂÆåÊàê‰∫ÜÔºåÊé•‰∏ãÊù•ÊòØword embeddingÔºåÊääÂçïËØçË°®Á§∫‰∏∫‰∏Ä‰∏™‰ΩéÁª¥ÂêëÈáèÔºõ\u003c/p\u003e\n\u003cp\u003e\u003cimg alt=\"image-20250322151252837\" loading=\"lazy\" src=\"./NLP-2.assets/image-20250322151252837.png\"\u003e\u003c/p\u003e","title":""},{"content":"üëã About me Hello! I‚Äôm Xu Zongsi, a passionate technology enthusiast currently pursuing my Master of Science in Electronic Commerce \u0026amp; Internet Computing at The University of Hong Kong. With a solid background in Software Engineering from the Beijing Institute of Technology, I specialize in emerging areas of artificial intelligence, including machine learning, deep learning, natural language processing, computer vision, and reinforcement learning.\nRecently, inspired by OpenAI\u0026rsquo;s five-step plan towards superintelligence, I have great expectations for AGI and developed a strong interest in LLM agents, MLLM, reinforcement learning, and knowledge graphs. I believe there is significant potential in these fields to create innovative solutions, and I hope to contribute my efforts towards that goal.\nüìö Education üá≠üá∞ The University of Hong Kong 09/2024 - Expected 11/2025 School of Computing and Data Science Master of Science in Electronic Commerce \u0026amp; Internet Computing Relevant Courses: Machine learning for business and e-commerce, Knowledge graphs, Financial fraud analytics, Internet infrastructure technologies, Website engineering, Blockchain and cryptocurrency, etc. üá®üá≥ Beijing Institute of Technology 09/2020 - 06/2024 School of Computer Science \u0026amp; Technology Bachelor of Engineering in Software Engineering, last two years GPA: 3.7/4 Relevant Courses: Reinforcement Learning, Deep Learning and Computer Vision, Artificial Intelligence and Robot Ethics, Almost Human: Mind, Brain and Artificial Intelligence, Mathematical Analysis for Engineering, Linear Algebra, Probability and Mathematical Statistics, etc. Skills: Python, Java, common data structures, design patterns, machine learning basics and algorithms, Linux, PyTorch, and some development tools (git, conda, etc.). üèÜ Awards \u0026amp; Honors Beijing Institute of Technology Undergraduate Scholarship (Top 20% of Grade) 06/2023 3rd Prize of China International \u0026#34;Internet \u0026#43;\u0026#34; College Student\u0026#39;s Innovation Competition 08/2022 Bronze Prize of \u0026#34;Challenge Cup\u0026#34; Capital University Entrepreneurship Competition 05/2022 üíº Project Experience Online Transaction Fraud Detection 09/2024 ‚Äì 01/2025 Independent project, supervised by Dr. Vivien Chan Focused on addressing financial fraud in e-commerce to enhance the accuracy of transaction anomaly detection, while independently managing the entire case study that included data preprocessing, feature engineering, model building, evaluation, and results analysis. Effectively resolved class imbalance issues using SMOTE and ROSE techniques. Built various models including Logistic Regression, Random Forest, XGBoost, and LightGBM, ultimately selecting the LightGBM model to achieve a recall rate of 95.45% and an AUC of 99.84%. Wrote efficient and maintainable code, enhancing model training and data processing efficiency through parallel computing and logging. Multi-Model Intelligent Text Keyword Extraction System 08/2023 ‚Äì 09/2023 Group project, supervised by Associate Prof. Xiaolin Zhao Designed and implemented an intelligent text summary system that automatically extracts keywords from article titles and abstracts, enhancing the understanding and summarization of text information. Participated in the planning of the technical route and built a hybrid model combining extractive and generative approaches, utilizing advanced natural language processing techniques including KeyBERT, Sentence Transformer, BERT, and T5 models. Responsible for data preprocessing and tokenization, as well as the end-to-end implementation and training of the T5 model, optimizing the model architecture and hyperparameters, achieving satisfactory results after only 3 epochs of training. Model evaluation results showed that the Rouge-1, Rouge-2, and Rouge-L metrics reached 0.6345, 0.5038, and 0.5282, respectively, in the third epoch, validating the model\u0026rsquo;s effectiveness in the summarization task. Cambridge University Machine Learning Summer Project 07/2023 ‚Äì 08/2023 Group project, supervised by Prof. Pietro Li√≤ Participated in the Cambridge University deep learning summer project, focusing on deep reinforcement learning; explored multi-agent learning algorithms across different environments. Reproduced the Multi-Agent Deep Deterministic Policy Gradient (MADDPG) algorithm in the Simple Adversary environment and studied the effect of agent numbers on convergence speed and stability, finding optimal stability at 21 agents. Designed and implemented comparative experiments inspired by the Rainbow algorithm, assessing target network strategies versus the Double Deep Q-Network (Double DQN). The results demonstrated that Double DQN significantly enhanced convergence speed, optimizing the overall learning process. Co-authored a group project paper on agent numbers and strategies effectiveness in multi-agent systems, achieving a score of 71% in the summer program (the highest in my group) and a \u0026ldquo;First Class\u0026rdquo; classification in the UK grading system. Deep Learning and Computer Vision Semester Project 09/2022 ‚Äì 12/2022 Independent project, supervised by Associate Prof. Guangyu Gao Designed and implemented a waste classifier using the ResNet model to improve classification accuracy and reduce resource waste. The project also enhanced understanding of transfer learning techniques with ResNet. Collected a dataset of 16 waste categories and preprocessed the images for uniformity and standardization, incorporating data augmentation techniques to enhance the dataset. Conducted experiments using ResNet34 and ResNet50 models through transfer learning, accelerating network convergence by leveraging pretrained weights. During training, techniques such as Batch Normalization and Dropout were applied to mitigate the risk of overfitting. The final model achieved an accuracy of 90% on the training set, while the performance on the test set was 61%, indicating a significant overfitting phenomenon during the training process. üéì Internship Beijing Academy of Quantum Information Science 08/2023 ‚Äì 01/2024 Research Intern at Quantum Computation Department Proposed a quantum convolution kernel design based on variational quantum circuits and developed a universal quantum convolution layer, successfully integrating it into classical CNN architectures such as VGG, GoogLeNet, and ResNet. Developed and evaluated various hybrid models, including a simple model named HQCCNN-2, which achieved 84.45% accuracy on the FashionMNIST dataset, surpassing the traditional CNN\u0026rsquo;s 80.72%. This demonstrates the effectiveness of the quantum convolution layer in improving model performance. Tested on a real quantum computer further validated the effectiveness of the hybrid model, demonstrating the viable integration of quantum computing with deep learning, and highlighting the potential for leveraging quantum properties to enhance model performance. üèÖ Competition Experience China International \u0026#34;Internet \u0026#43;\u0026#34; College Students\u0026#39; Innovation Competition 08/2022 Zhongke Ushield: Deep Learning-based Face Privacy Protection Authentication System Responsible for constructing a localized facial feature extraction engine based on MobileFaceNet, ensuring feature extraction is completed on end devices (such as mobile phones and cameras), guaranteeing that raw data does not leave the domain and is not stored, thus enhancing user privacy protection while improving recognition efficiency. \u0026#34;Challenge Cup\u0026#34; Capital University Entrepreneurship Competition 05/2022 Smart Orchard Responsible for the development of the fruit detection, ripeness prediction, and pest identification system, using deep convolutional neural network (CNN) technology for intelligent monitoring of crop growth conditions. Applied advanced object detection algorithms such as Faster R-CNN and YOLO to achieve high precision in apple detection and ripeness assessment, with an accuracy rate exceeding 90%, significantly enhancing the intelligence level of orchard management. Built and trained a dedicated dataset containing various pest samples, optimizing pest detection accuracy through data preprocessing (such as image normalization and resizing) and data augmentation techniques (like rotation, flipping, and noise addition), enabling the real-time monitoring system to accurately identify over 80% of pests, providing effective scientific maintenance recommendations to help farmers reduce crop losses. üìã Extracurricular Activities Vice President, Cyber Security Club, Beijing Institute of Technology 09/2021-09/2022 Backbone, Media Center of the Student Union of Beijing Institute of Technology 10/2020-06/2021 üì´ Contact üìß zongsi.xu@outlook.com üëî Zongsi (Tristan) Xu üíª github.com/BaizeXS üìç Hong Kong SAR, China ","permalink":"http://localhost:1313/resume/","summary":"Personal resume of Zongsi (Tristan) Xu","title":"Zongsi (Tristan) Xu"},{"content":"‰∏Ä„ÄÅÊï∞ÂÄºÁâπÂæÅ‰∏éÁ±ªÂà´ÁâπÂæÅ Êï∞ÂÄºÁâπÂæÅ (Numeric Features) ÂÖ∑ÊúâÂèØÂä†ÂáèÁöÑÊÑè‰πâÔºå‰∏îÂ≠òÂú®Â§ßÂ∞èÈ°∫Â∫è„ÄÇ ‰æãÂ≠êÔºöÂπ¥ÈæÑ„ÄÅÊ∏©Â∫¶Á≠â„ÄÇÂèØ‰ª•Áõ¥Êé•‰øùÁïôÂÖ∂Êï¥Êï∞ÊàñÊµÆÁÇπÊï∞ÂΩ¢Âºè‰æõÊ®°Âûã‰ΩøÁî®„ÄÇ Á±ªÂà´ÁâπÂæÅ (Categorical Features) Êï∞ÊçÆÂÄºÁ¶ªÊï£Ôºå‰∏çÂÖ∑Â§á‚ÄúÊï∞ÂÄºÂ§ßÂ∞è‚ÄùÈó¥ÁöÑÂèØÊØîÊÑè‰πâ„ÄÇ ‰æãÂ≠êÔºöÂõΩÁ±çÔºàÁæéÂõΩ/‰∏≠ÂõΩ/Âç∞Â∫¶Á≠âÔºâ„ÄÅÊÄßÂà´ÔºàÁî∑/Â•≥ÔºâÁ≠â„ÄÇ ÈóÆÈ¢òÔºöËã•‰ªÖÁî®Êï¥Êï∞Ë°®Á§∫ÔºàÁæéÂõΩ=1, ‰∏≠ÂõΩ=2ÔºâÔºå‰ºöÂºïÂÖ•ÈîôËØØÁöÑÊï∞ÂÄºËøêÁÆóÂÖ≥Á≥ªÔºåÂ¶Ç ‚ÄúÁæéÂõΩ + ‰∏≠ÂõΩ = Âç∞Â∫¶‚Äù„ÄÇ ‰∫å„ÄÅOne-HotÁºñÁ†ÅÁöÑÂä®Êú∫‰∏éÊµÅÁ®ã ‰∏∫‰ªÄ‰πà‰ΩøÁî®One-Hot\nÈÄöËøáÂ∞ÜÁ±ªÂà´Êò†Â∞Ñ‰∏∫ÂêëÈáèÔºåÈÅøÂÖçÊï¥Êï∞ÁºñÁ†ÅÂºïÂÖ•ÁöÑ‰º™Êï∞ÂÄºÂÖ≥Á≥ª„ÄÇ ÂêåÊó∂‰øùÁïôÂêÑÁßçÂèØËÉΩÁ±ªÂà´ÁöÑ‰ø°ÊÅØÔºå‰∏î‰ªÖÂú®ÂØπÂ∫î‰ΩçÁΩÆ‰∏∫1ÔºåÂÖ∂‰ªñ‰ΩçÁΩÆ‰∏∫0„ÄÇ Âª∫Á´ãÊò†Â∞ÑÔºö‰ªéÁ±ªÂà´Âà∞Á¥¢Âºï\n‰∏∫ÊØè‰∏™Á±ªÂà´ÂàÜÈÖç‰∏Ä‰∏™ÂîØ‰∏ÄÁ¥¢ÂºïÔºåÈÄöÂ∏∏‰ªé1ÂºÄÂßã„ÄÇ È¢ÑÁïôÁ¥¢Âºï0Ë°®Á§∫‚ÄúÊú™Áü•‚ÄùÊàñ‚ÄúÁº∫Â§±‚ÄùÔºåÂØπÂ∫îÂÖ®0ÂêëÈáè„ÄÇ ËΩ¨Êç¢‰∏∫One-HotÂêëÈáè\nËã•Á±ªÂà´ÊÄªÊï∞‰∏∫197ÔºåÂàôÁî®197Áª¥ÂêëÈáèË°®Á§∫„ÄÇ ‰æãÂ≠êÔºöÁæéÂõΩ [1, 0, 0, 0, ‚Ä¶]Ôºå ‰∏≠ÂõΩ [0, 1, 0, 0, ‚Ä¶]„ÄÇ Á§∫‰æãÔºöË°®Á§∫‰∏Ä‰∏™‰∫∫ÁöÑÁâπÂæÅ\nÁâπÂæÅÂåÖÂê´ÔºàÂπ¥ÈæÑ, ÊÄßÂà´, ÂõΩÁ±çÔºåÂÖ∂‰∏≠ÂõΩÁ±ç197ÁßçÔºâ Áª¥Â∫¶ÊÄªÂíåÔºö1Áª¥_age + 1Áª¥_gender + 197Áª¥_nationality = 199Áª¥„ÄÇ ‰æãÂ¶Ç (28, Â•≥, ‰∏≠ÂõΩ) ‚Üí [28, 0, 0, 1, 0, ‚Ä¶, 0]„ÄÇ ‰∏â„ÄÅÊñáÊú¨Êï∞ÊçÆÂ§ÑÁêÜÊµÅÁ®ã ÊñáÊú¨Âú®Ëá™ÁÑ∂ËØ≠Ë®ÄÂ§ÑÁêÜÔºàNLPÔºâ‰∏≠‰Ωú‰∏∫Â∏∏ËßÅÁöÑÂéüÂßãËæìÂÖ•ÔºåÈúÄË¶ÅÊï∞ÂÄºÂåñÊâçËÉΩÈÄÅÂÖ•Ê®°Âûã„ÄÇ‰∏ÄËà¨Ê≠•È™§Â¶Ç‰∏ãÔºö\nÂàÜËØç (Tokenization)\nÂ∞ÜÊñáÊú¨ÊãÜÂàÜ‰∏∫‰∏Ä‰∏™‰∏™ÂçïËØçÔºàTokenÔºâ„ÄÇ ‰æãÂ≠êÔºö\u0026quot;... to be or not to be...\u0026quot; ‚Üí [\u0026quot;...\u0026quot;, \u0026quot;to\u0026quot;, \u0026quot;be\u0026quot;, \u0026quot;or\u0026quot;, \u0026quot;not\u0026quot;, \u0026quot;to\u0026quot;, \u0026quot;be\u0026quot;, \u0026quot;...\u0026quot;]„ÄÇ ÁªüËÆ°ËØçÈ¢ë \u0026amp; ÊûÑÂª∫ËØçÂÖ∏\nËØçÈ¢ëÁªüËÆ° Áî®ÂìàÂ∏åË°®/Â≠óÂÖ∏ËÆ∞ÂΩïÊØè‰∏™ÂçïËØçÂá∫Áé∞Ê¨°Êï∞„ÄÇ ÈÅçÂéÜÊñáÊú¨Êó∂ÔºåËã•ÂçïËØçÂ∞öÊú™ÂÖ•Ë°®ÔºåÂàôÊñ∞Âª∫ËÆ∞ÂΩïÔºõËã•Â∑≤Â≠òÂú®ÔºåÂàôËÆ°Êï∞+1„ÄÇ ÊéíÂ∫è‰∏éÁ¥¢Âºï ÊåâËØçÈ¢ëÈôçÂ∫èÊéíÂ∫èÔºåËØçÈ¢ëÊúÄÈ´òÁöÑÂçïËØçÊéíÂú®ÂâçÈù¢„ÄÇ Á¥¢Âºï‰ªé1ÂºÄÂßãÔºå0ÁïôÁªô‚ÄúÊú™Áü•‚Äù„ÄÇ ËØçÂÖ∏ËßÑÊ®°ÔºàvocabularyÔºâÂèØËßÜÈúÄÊ±ÇÊà™Êñ≠Ôºà‰æãÂ¶ÇÂè™‰øùÁïôTop 10kÔºâ„ÄÇ ‰∏∫‰ªÄ‰πàÁßªÈô§‰ΩéÈ¢ëËØç ‰ΩéÈ¢ëËØçÂèØËÉΩÊòØÊãºÂÜôÈîôËØØ„ÄÅÁΩïËßÅ‰∫∫ÂêçÁ≠âÔºåÂØπÊ®°ÂûãÂ∏ÆÂä©ÊúâÈôê„ÄÇ ÂáèÂ∞ëËØçÂÖ∏ËßÑÊ®°ÂèØÈôç‰ΩéËøêÁÆóÂºÄÈîÄ„ÄÅÂä†Âø´Ê®°ÂûãËÆ≠ÁªÉ‰∏éÊé®ÁêÜÈÄüÂ∫¶„ÄÇ Áã¨ÁÉ≠ÁºñÁ†Å (One-Hot Encoding)\nÂ∞ÜÊØè‰∏™ÂçïËØçÊò†Â∞Ñ‰∏∫ËØçÂÖ∏‰∏≠ÁöÑÁ¥¢ÂºïÂêéÔºàÂ¶Ç [2, 4, 1, 8, ‚Ä¶]ÔºâÔºåÂèØËøõ‰∏ÄÊ≠•ËΩ¨Êç¢ÊàêOne-HotÂêëÈáè„ÄÇ One-HotÁª¥Â∫¶ÂèñÂÜ≥‰∫é‰øùÁïô‰∏ãÊù•ÁöÑËØçÂÖ∏Â§ßÂ∞èÔºà‰æãÂ¶Ç1‰∏áÔºâ„ÄÇ Êú™Êî∂ÂΩïÂçïËØçÂèØËÉΩÁõ¥Êé•ÂøΩÁï•ÔºåÊàñÁªü‰∏ÄÁî®Á¥¢Âºï0‰ª£Êõø„ÄÇ Âõõ„ÄÅÊ†∏ÂøÉÊî∂Ëé∑‰∏éÂ∫îÁî® Á±ªÂà´ÁâπÂæÅÂøÖÈúÄÊï∞ÂÄºÂåñÔºö\n‰ΩøÁî®Êï¥Êï∞1,2,3‚Ä¶‰ªÖË°®Á§∫Á±ªÂà´‚ÄúÊ†áËØÜ‚ÄùÔºåÂπ∂‰∏ç‰ª£Ë°®ÂÆÉ‰ª¨ÂèØËøõË°åÊï∞ÂÄºËøêÁÆó„ÄÇ Âõ†Ê≠§ÈúÄË¶ÅOne-HotÁ≠âÁºñÁ†ÅÊñπÂºèÔºåÈÅøÂÖçÊï∞ÂÄºËØØËß£„ÄÇ ÊñáÊú¨Êï∞ÊçÆÈ¢ÑÂ§ÑÁêÜÔºö\nÂàÜËØç„ÄÅËØçÈ¢ëÁªüËÆ°„ÄÅÊûÑÂª∫ËØçÂÖ∏„ÄÅÁ¥¢ÂºïÂåñ„ÄÅOne-HotÊàñÂÖ∂‰ªñÊñπÂºèÔºàÂ¶ÇËØçÂµåÂÖ•ÔºâÊòØÂ∏∏ËßÅÊµÅÁ®ã„ÄÇ Ê≠£Á°ÆÁöÑÊñáÊú¨È¢ÑÂ§ÑÁêÜÂèØÊòæËëóÂΩ±ÂìçÊ®°ÂûãÊÄßËÉΩÂíåÊïàÁéá„ÄÇ ‰øùÁïôÊú™Áü•Á¥¢ÂºïÔºö\n‰øùËØÅÂØπÁº∫Â§±Êï∞ÊçÆÊàñÂ≠óÂÖ∏Â§ñÊñ∞ËØçËÉΩÊúâÂü∫Êú¨ÁöÑË°®Á§∫ÔºåÊèêÂçáÊ®°ÂûãÂÆπÈîôÊÄß„ÄÇ ÂÆûÈôÖ‰ΩøÁî®Ôºö\nÂØπ‰∫éÂ∞èËßÑÊ®°Á±ªÂà´ÂèØÁõ¥Êé•One-HotÁºñÁ†ÅÔºõÂØπ‰∫éËØçÂÖ∏ÂæàÂ§ßÁöÑÂú∫ÊôØÔºåÈÄöÂ∏∏‰ºöËøõ‰∏ÄÊ≠•ËÄÉËôëËØçÂµåÂÖ•ÔºàWord EmbeddingÔºâÊàñÈ¢ÑËÆ≠ÁªÉËØ≠Ë®ÄÊ®°Âûã„ÄÇ ","permalink":"http://localhost:1313/posts/nlp-1/","summary":"\u003ch2 id=\"‰∏ÄÊï∞ÂÄºÁâπÂæÅ‰∏éÁ±ªÂà´ÁâπÂæÅ\"\u003e‰∏Ä„ÄÅÊï∞ÂÄºÁâπÂæÅ‰∏éÁ±ªÂà´ÁâπÂæÅ\u003c/h2\u003e\n\u003col\u003e\n\u003cli\u003e\u003cstrong\u003eÊï∞ÂÄºÁâπÂæÅ (Numeric Features)\u003c/strong\u003e\n\u003cul\u003e\n\u003cli\u003eÂÖ∑ÊúâÂèØÂä†ÂáèÁöÑÊÑè‰πâÔºå‰∏îÂ≠òÂú®Â§ßÂ∞èÈ°∫Â∫è„ÄÇ\u003c/li\u003e\n\u003cli\u003e‰æãÂ≠êÔºöÂπ¥ÈæÑ„ÄÅÊ∏©Â∫¶Á≠â„ÄÇÂèØ‰ª•Áõ¥Êé•‰øùÁïôÂÖ∂Êï¥Êï∞ÊàñÊµÆÁÇπÊï∞ÂΩ¢Âºè‰æõÊ®°Âûã‰ΩøÁî®„ÄÇ\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003eÁ±ªÂà´ÁâπÂæÅ (Categorical Features)\u003c/strong\u003e\n\u003cul\u003e\n\u003cli\u003eÊï∞ÊçÆÂÄºÁ¶ªÊï£Ôºå‰∏çÂÖ∑Â§á‚ÄúÊï∞ÂÄºÂ§ßÂ∞è‚ÄùÈó¥ÁöÑÂèØÊØîÊÑè‰πâ„ÄÇ\u003c/li\u003e\n\u003cli\u003e‰æãÂ≠êÔºöÂõΩÁ±çÔºàÁæéÂõΩ/‰∏≠ÂõΩ/Âç∞Â∫¶Á≠âÔºâ„ÄÅÊÄßÂà´ÔºàÁî∑/Â•≥ÔºâÁ≠â„ÄÇ\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003eÈóÆÈ¢ò\u003c/strong\u003eÔºöËã•‰ªÖÁî®Êï¥Êï∞Ë°®Á§∫ÔºàÁæéÂõΩ=1, ‰∏≠ÂõΩ=2ÔºâÔºå‰ºöÂºïÂÖ•ÈîôËØØÁöÑÊï∞ÂÄºËøêÁÆóÂÖ≥Á≥ªÔºåÂ¶Ç ‚ÄúÁæéÂõΩ + ‰∏≠ÂõΩ = Âç∞Â∫¶‚Äù„ÄÇ\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003c/ol\u003e\n\u003ch2 id=\"‰∫åone-hotÁºñÁ†ÅÁöÑÂä®Êú∫‰∏éÊµÅÁ®ã\"\u003e‰∫å„ÄÅOne-HotÁºñÁ†ÅÁöÑÂä®Êú∫‰∏éÊµÅÁ®ã\u003c/h2\u003e\n\u003col\u003e\n\u003cli\u003e\n\u003cp\u003e\u003cstrong\u003e‰∏∫‰ªÄ‰πà‰ΩøÁî®One-Hot\u003c/strong\u003e\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eÈÄöËøáÂ∞ÜÁ±ªÂà´Êò†Â∞Ñ‰∏∫ÂêëÈáèÔºåÈÅøÂÖçÊï¥Êï∞ÁºñÁ†ÅÂºïÂÖ•ÁöÑ‰º™Êï∞ÂÄºÂÖ≥Á≥ª„ÄÇ\u003c/li\u003e\n\u003cli\u003eÂêåÊó∂‰øùÁïôÂêÑÁßçÂèØËÉΩÁ±ªÂà´ÁöÑ‰ø°ÊÅØÔºå‰∏î‰ªÖÂú®ÂØπÂ∫î‰ΩçÁΩÆ‰∏∫1ÔºåÂÖ∂‰ªñ‰ΩçÁΩÆ‰∏∫0„ÄÇ\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003e\u003cstrong\u003eÂª∫Á´ãÊò†Â∞ÑÔºö‰ªéÁ±ªÂà´Âà∞Á¥¢Âºï\u003c/strong\u003e\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e‰∏∫ÊØè‰∏™Á±ªÂà´ÂàÜÈÖç‰∏Ä‰∏™ÂîØ‰∏ÄÁ¥¢ÂºïÔºåÈÄöÂ∏∏‰ªé1ÂºÄÂßã„ÄÇ\u003c/li\u003e\n\u003cli\u003eÈ¢ÑÁïôÁ¥¢Âºï0Ë°®Á§∫‚ÄúÊú™Áü•‚ÄùÊàñ‚ÄúÁº∫Â§±‚ÄùÔºåÂØπÂ∫îÂÖ®0ÂêëÈáè„ÄÇ\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003e\u003cstrong\u003eËΩ¨Êç¢‰∏∫One-HotÂêëÈáè\u003c/strong\u003e\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eËã•Á±ªÂà´ÊÄªÊï∞‰∏∫197ÔºåÂàôÁî®197Áª¥ÂêëÈáèË°®Á§∫„ÄÇ\u003c/li\u003e\n\u003cli\u003e‰æãÂ≠êÔºöÁæéÂõΩ \u003ccode\u003e[1, 0, 0, 0, ‚Ä¶]\u003c/code\u003eÔºå ‰∏≠ÂõΩ \u003ccode\u003e[0, 1, 0, 0, ‚Ä¶]\u003c/code\u003e„ÄÇ\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003e\u003cstrong\u003eÁ§∫‰æãÔºöË°®Á§∫‰∏Ä‰∏™‰∫∫ÁöÑÁâπÂæÅ\u003c/strong\u003e\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eÁâπÂæÅÂåÖÂê´ÔºàÂπ¥ÈæÑ, ÊÄßÂà´, ÂõΩÁ±çÔºåÂÖ∂‰∏≠ÂõΩÁ±ç197ÁßçÔºâ\u003c/li\u003e\n\u003cli\u003eÁª¥Â∫¶ÊÄªÂíåÔºö1Áª¥_age + 1Áª¥_gender + 197Áª¥_nationality = 199Áª¥„ÄÇ\u003c/li\u003e\n\u003cli\u003e‰æãÂ¶Ç \u003ccode\u003e(28, Â•≥, ‰∏≠ÂõΩ)\u003c/code\u003e ‚Üí \u003ccode\u003e[28, 0, 0, 1, 0, ‚Ä¶, 0]\u003c/code\u003e„ÄÇ\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003c/ol\u003e\n\u003ch2 id=\"‰∏âÊñáÊú¨Êï∞ÊçÆÂ§ÑÁêÜÊµÅÁ®ã\"\u003e‰∏â„ÄÅÊñáÊú¨Êï∞ÊçÆÂ§ÑÁêÜÊµÅÁ®ã\u003c/h2\u003e\n\u003cp\u003eÊñáÊú¨Âú®Ëá™ÁÑ∂ËØ≠Ë®ÄÂ§ÑÁêÜÔºàNLPÔºâ‰∏≠‰Ωú‰∏∫Â∏∏ËßÅÁöÑÂéüÂßãËæìÂÖ•ÔºåÈúÄË¶ÅÊï∞ÂÄºÂåñÊâçËÉΩÈÄÅÂÖ•Ê®°Âûã„ÄÇ‰∏ÄËà¨Ê≠•È™§Â¶Ç‰∏ãÔºö\u003c/p\u003e\n\u003col\u003e\n\u003cli\u003e\n\u003cp\u003e\u003cstrong\u003eÂàÜËØç (Tokenization)\u003c/strong\u003e\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eÂ∞ÜÊñáÊú¨ÊãÜÂàÜ‰∏∫‰∏Ä‰∏™‰∏™ÂçïËØçÔºàTokenÔºâ„ÄÇ\u003c/li\u003e\n\u003cli\u003e‰æãÂ≠êÔºö\u003ccode\u003e\u0026quot;... to be or not to be...\u0026quot;\u003c/code\u003e ‚Üí \u003ccode\u003e[\u0026quot;...\u0026quot;, \u0026quot;to\u0026quot;, \u0026quot;be\u0026quot;, \u0026quot;or\u0026quot;, \u0026quot;not\u0026quot;, \u0026quot;to\u0026quot;, \u0026quot;be\u0026quot;, \u0026quot;...\u0026quot;]\u003c/code\u003e„ÄÇ\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003e\u003cstrong\u003eÁªüËÆ°ËØçÈ¢ë \u0026amp; ÊûÑÂª∫ËØçÂÖ∏\u003c/strong\u003e\u003c/p\u003e","title":""},{"content":"Text to Sequence ÊñáÊú¨Â§ÑÁêÜ\nStep1: Tokenization\nTokenization breaks a piece of text down into a list of tokens.\nHere, a token is a word. (A token can be a character in some applications.)\nTokenizationËÆ≤Á©∂ÂæàÂ§öÔºå‰æãÂ¶ÇÊòØÂê¶Â∫îËØ•ÊääÂ§ßÂÜôÊîπÊàêÂ∞èÂÜôÂë¢ÔºüËøõË°åtypo correctionÁ≠âÁ≠â\nStep2: Build Dictionary\nUse a dictionary (hash table) to count word frequencies.\nThe dictionary maps word to index.\nÂèØ‰ª•È¶ñÂÖàÁªüËÆ°ËØçÈ¢ëÂéªÊéâ‰ΩéÈ¢ëËØçÔºåÁÑ∂ÂêéËÆ©ÊØè‰∏™ËØçÂØπÂ∫î‰∏Ä‰∏™Ê≠£Êï¥Êï∞ÔºõËøôÊ†∑ÁöÑËØùÔºå‰∏ÄÂè•ËØùÂ∞±ÂèØ‰ª•Áî®‰∏Ä‰∏™Ê≠£Êï¥Êï∞ÂàóË°®Ë°®Á§∫ÔºåËøô‰∏™ÂàóË°®Â∞±Âè´sequenceÔºõÂ¶ÇÊûúÂøÖË¶ÅÂ∞±ËøòÂæóÂÅöone-hot encoding„ÄÇ\nÁªìÊûú\n‰ΩÜÊòØÈïøÂ∫¶‰∏çÁªü‰∏Ä\nStep4: ÂØπÈΩêsequence\nËß£ÂÜ≥ÊñπÊ°àÊòØËøôÊ†∑ÁöÑÔºöÂèØ‰ª•Âõ∫ÂÆöÈïøÂ∫¶‰∏∫wÔºåÂä†ÂÖ•‰∏Ä‰∏™Â∫èÂàóÈïøÂ∫¶Â§™ÈïøÔºåÂ∞±Á†çÊéâÂâçÈù¢ÁöÑËØçÔºåÂè™‰øùÁïôÊúÄÂêéw‰∏™ËØçÔºõÂ¶ÇÊûú‰∏Ä‰∏™Â∫èÂàóÂ§™Áü≠ÔºåÂ∞±ÂÅözero paddingÔºåÁî®0Â°´ÂÖÖ\nËøôÊ†∑‰∏ÄÊù•ÔºåÊâÄÊúâÁöÑÂ∫èÂàóÈïøÂ∫¶Â∞±Áªü‰∏Ä‰∫Ü\nÊñáÊú¨Â§ÑÁêÜÂÆåÊàê‰∫ÜÔºåÊé•‰∏ãÊù•ÊòØword embeddingÔºåÊääÂçïËØçË°®Á§∫‰∏∫‰∏Ä‰∏™‰ΩéÁª¥ÂêëÈáèÔºõ\nÁÑ∂ËÄåËøôÊ†∑ÂÅöÁöÑËØùÔºåÂ¶ÇÊûúÊòØ10000‰∏™ÂçïËØçÔºåÁª¥Â∫¶Â∞±ÊòØ10000Áª¥ÔºåÁª¥Â∫¶Â§™È´ò‰∫ÜÔºõÂõ†Ê≠§Ë¶ÅÂÅöword embeddingÔºõ\nÂÖ∑‰ΩìÂÅöÊ≥ïÂ∞±ÊòØÊääone-hotÂêëÈáèe_iÂíåÂèÇÊï∞Áü©ÈòµpÁõ∏‰πòÔºõÁü©ÈòµPËΩ¨ÁΩÆÁöÑÂ§ßÂ∞èÊòØd x vÔºõdÊòØËØçÂêëÈáèÁöÑÁª¥Â∫¶ÔºõvÊòØÂ≠óÂÖ∏ÈáåËØçÊ±áÁöÑÊï∞ÈáèÔºõÁªìÊûú‰∏∫x_iÔºõx_iÂ∞±ÊòØ‰∏Ä‰∏™ËØçÂêëÈáèÔºõÂ¶ÇÊûúone-hotÂêëÈáèÁöÑÁ¨¨‰∏âË°å‰∏∫1ÔºõÈÇ£‰πàx_iÂ∞±ÊòØPËΩ¨ÁΩÆÁü©ÈòµÁöÑÁ¨¨‰∏âÂàóÔºàÂÖ∂‰ΩôÂàóÈÉΩ‰∏∫0ÔºâÔºõÊâÄ‰ª•PËΩ¨ÁΩÆÊØè‰∏ÄÂàóÈÉΩÊòØ‰∏Ä‰∏™ËØçÂêëÈáèÔºõÊâÄ‰ª•Áü©ÈòµPÊú¨Ë∫´ÁöÑÊØè‰∏ÄË°åÂ∞±ÊòØ‰∏Ä‰∏™ËØçÂêëÈáèÔºõÂÖ∂Ë°åÊï∞‰∏∫vÔºõÂç≥vocabularyÔºåËØçÊ±áÈáèÔºõÊØè‰∏ÄË°åÂØπÂ∫î‰∏Ä‰∏™ÂçïËØçÔºõÁü©ÈòµÁöÑÂàóÊï∞‰∏∫dÔºõdÊòØÁî®Êà∑ÂÜ≥ÂÆöÁöÑÔºõdÁöÑÂ§ßÂ∞è‰ºöÂÜ≥ÂÆöÊú∫Âô®Â≠¶‰π†Ê®°ÂûãÁöÑË°®Áé∞ÔºõÂ∫îËØ•Áî®xxxÊù•ÈÄâÊã©‰∏Ä‰∏™ÊØîËæÉÂ•ΩÁöÑdÔºõ\nÊàë‰ª¨ÁöÑ‰ªªÂä°ÊòØÁúãËØÑËÆ∫ÊòØÊ≠£Èù¢ÁöÑËøòÊòØË¥üÈù¢ÁöÑÔºõÂèÇÊï∞Áü©ÈòµÊòØ‰ªéËÆ≠ÁªÉÊï∞ÊçÆ‰∏≠Â≠¶‰π†Âá∫Êù•ÁöÑÔºåÊâÄ‰ª•Â≠¶Âá∫Êù•ÁöÑËØçÂêëÈáèÊòØÂ∏¶ÊúâÊÑüÊÉÖËâ≤ÂΩ©ÁöÑÔºõÂÅáËÆæËøô‰∫õËØçÂêëÈáèÈÉΩÊòØ‰∫åÁª¥ÁöÑÔºåÂàôÂèØ‰ª•Âú®Âπ≥Èù¢ÂùêÊ†áÁ≥ª‰∏≠Ê†áÂá∫‰∏ãÈù¢ËØçÂêëÈáè\nkerasÊèê‰æõembeddingÂ±ÇÔºõÁî®Êà∑ÂèØ‰ª•ÊåáÂÆövocabularyÂ§ßÂ∞èÂíådÁöÑÂ§ßÂ∞èÔºõ‰ª•ÂèäÊØè‰∏Ä‰∏™sequenceÁöÑÈïøÂ∫¶ÔºõdÊòØÊ†πÊçÆÁÆóÊ≥ïÈÄâÂá∫Êù•ÁöÑ Âà∞Ëøô‰∏ÄÊ≠•ÔºåÊàë‰ª¨Â∑≤ÁªèÂÆåÊàê‰∫ÜÊñáÊú¨Â§ÑÁêÜÂíåword embedding„ÄÇÊé•‰∏ãÊù•Â∞±ÊòØÁî®Logistic Regression for Binary ClassificationÂÅö‰∫åÂàÜÁ±ªÔºõ\n","permalink":"http://localhost:1313/posts/nlp-2/","summary":"\u003ch3 id=\"text-to-sequence\"\u003eText to Sequence\u003c/h3\u003e\n\u003cp\u003eÊñáÊú¨Â§ÑÁêÜ\u003c/p\u003e\n\u003cp\u003eStep1: Tokenization\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\n\u003cp\u003eTokenization breaks a piece of text down into a list of tokens.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003eHere, a token is a word. (A token can be a character in some applications.)\u003c/p\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003eTokenizationËÆ≤Á©∂ÂæàÂ§öÔºå‰æãÂ¶ÇÊòØÂê¶Â∫îËØ•ÊääÂ§ßÂÜôÊîπÊàêÂ∞èÂÜôÂë¢ÔºüËøõË°åtypo correctionÁ≠âÁ≠â\u003c/p\u003e\n\u003cp\u003e\u003cimg alt=\"image-20250322150322238\" loading=\"lazy\" src=\"./NLP-2.assets/image-20250322150322238.png\"\u003e\u003c/p\u003e\n\u003cp\u003eStep2: Build Dictionary\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\n\u003cp\u003eUse a dictionary (hash table) to count word frequencies.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003eThe dictionary maps word to index.\u003c/p\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003eÂèØ‰ª•È¶ñÂÖàÁªüËÆ°ËØçÈ¢ëÂéªÊéâ‰ΩéÈ¢ëËØçÔºåÁÑ∂ÂêéËÆ©ÊØè‰∏™ËØçÂØπÂ∫î‰∏Ä‰∏™Ê≠£Êï¥Êï∞ÔºõËøôÊ†∑ÁöÑËØùÔºå‰∏ÄÂè•ËØùÂ∞±ÂèØ‰ª•Áî®‰∏Ä‰∏™Ê≠£Êï¥Êï∞ÂàóË°®Ë°®Á§∫ÔºåËøô‰∏™ÂàóË°®Â∞±Âè´sequenceÔºõÂ¶ÇÊûúÂøÖË¶ÅÂ∞±ËøòÂæóÂÅöone-hot encoding„ÄÇ\u003cimg alt=\"image-20250322150620890\" loading=\"lazy\" src=\"./NLP-2.assets/image-20250322150620890.png\"\u003e\u003c/p\u003e\n\u003cp\u003eÁªìÊûú\u003c/p\u003e\n\u003cp\u003e\u003cimg alt=\"image-20250322150754528\" loading=\"lazy\" src=\"./NLP-2.assets/image-20250322150754528.png\"\u003e\u003c/p\u003e\n\u003cp\u003e‰ΩÜÊòØÈïøÂ∫¶‰∏çÁªü‰∏Ä\u003c/p\u003e\n\u003cp\u003eStep4: ÂØπÈΩêsequence\u003c/p\u003e\n\u003cp\u003e\u003cimg alt=\"image-20250322150854986\" loading=\"lazy\" src=\"./NLP-2.assets/image-20250322150854986.png\"\u003e\u003c/p\u003e\n\u003cp\u003eËß£ÂÜ≥ÊñπÊ°àÊòØËøôÊ†∑ÁöÑÔºöÂèØ‰ª•Âõ∫ÂÆöÈïøÂ∫¶‰∏∫wÔºåÂä†ÂÖ•‰∏Ä‰∏™Â∫èÂàóÈïøÂ∫¶Â§™ÈïøÔºåÂ∞±Á†çÊéâÂâçÈù¢ÁöÑËØçÔºåÂè™‰øùÁïôÊúÄÂêéw‰∏™ËØçÔºõÂ¶ÇÊûú‰∏Ä‰∏™Â∫èÂàóÂ§™Áü≠ÔºåÂ∞±ÂÅözero paddingÔºåÁî®0Â°´ÂÖÖ\u003c/p\u003e\n\u003cp\u003e\u003cimg alt=\"image-20250322151030119\" loading=\"lazy\" src=\"./NLP-2.assets/image-20250322151030119.png\"\u003e\u003c/p\u003e\n\u003cp\u003eËøôÊ†∑‰∏ÄÊù•ÔºåÊâÄÊúâÁöÑÂ∫èÂàóÈïøÂ∫¶Â∞±Áªü‰∏Ä‰∫Ü\u003c/p\u003e\n\u003cp\u003e\u003cimg alt=\"image-20250322151117125\" loading=\"lazy\" src=\"./NLP-2.assets/image-20250322151117125.png\"\u003e\u003c/p\u003e\n\u003cp\u003eÊñáÊú¨Â§ÑÁêÜÂÆåÊàê‰∫ÜÔºåÊé•‰∏ãÊù•ÊòØword embeddingÔºåÊääÂçïËØçË°®Á§∫‰∏∫‰∏Ä‰∏™‰ΩéÁª¥ÂêëÈáèÔºõ\u003c/p\u003e\n\u003cp\u003e\u003cimg alt=\"image-20250322151252837\" loading=\"lazy\" src=\"./NLP-2.assets/image-20250322151252837.png\"\u003e\u003c/p\u003e","title":""},{"content":"üëã About me Hello! I‚Äôm Xu Zongsi, a passionate technology enthusiast currently pursuing my Master of Science in ECIC at The University of Hong Kong. With a solid background in Software Engineering from the Beijing Institute of Technology, I specialize in emerging areas of artificial intelligence, including machine learning, deep learning, natural language processing, computer vision, and reinforcement learning.\nRecently, inspired by OpenAI\u0026rsquo;s five-step plan towards superintelligence, I have great expectations for AGI and developed a strong interest in LLM agents, MLLM, reinforcement learning, and knowledge graphs. I believe there is significant potential in these fields to create innovative solutions, and I hope to contribute my efforts towards that goal.\nüìö Education üá≠üá∞ The University of Hong Kong 09/2024 - Expected 11/2025 School of Computing and Data Science Master of Science in Electronic Commerce \u0026amp; Internet Computing Relevant Courses: Machine learning for business and e-commerce, Knowledge graphs, Financial fraud analytics, Internet infrastructure technologies, Website engineering, Blockchain and cryptocurrency, etc. üá®üá≥ Beijing Institute of Technology 09/2020 - 06/2024 School of Computer Science \u0026amp; Technology Bachelor of Engineering in Software Engineering, last two years GPA: 3.7/4 Relevant Courses: Reinforcement Learning, Deep Learning and Computer Vision, Artificial Intelligence and Robot Ethics, Almost Human: Mind, Brain and Artificial Intelligence, Mathematical Analysis for Engineering, Linear Algebra, Probability and Mathematical Statistics, etc. Skills: Python, Java, common data structures, design patterns, machine learning basics and algorithms, Linux, PyTorch, and some development tools (git, conda, etc.). üèÜ Awards \u0026amp; Honors Beijing Institute of Technology Undergraduate Scholarship (Top 20% of Grade) 06/2023 3rd Prize of China International \u0026#34;Internet \u0026#43;\u0026#34; College Student\u0026#39;s Innovation Competition 08/2022 Bronze Prize of \u0026#34;Challenge Cup\u0026#34; Capital University Entrepreneurship Competition 05/2022 üíº Project Experience Online Transaction Fraud Detection 09/2024 ‚Äì 01/2025 Independent project, supervised by Dr. Vivien Chan Focused on addressing financial fraud in e-commerce to enhance the accuracy of transaction anomaly detection, while independently managing the entire case study that included data preprocessing, feature engineering, model building, evaluation, and results analysis. Effectively resolved class imbalance issues using SMOTE and ROSE techniques. Built various models including Logistic Regression, Random Forest, XGBoost, and LightGBM, ultimately selecting the LightGBM model to achieve a recall rate of 95.45% and an AUC of 99.84%. Wrote efficient and maintainable code, enhancing model training and data processing efficiency through parallel computing and logging. Multi-Model Intelligent Text Keyword Extraction System 08/2023 ‚Äì 09/2023 Group project, supervised by Associate Prof. Xiaolin Zhao Designed and implemented an intelligent text summary system that automatically extracts keywords from article titles and abstracts, enhancing the understanding and summarization of text information. Participated in the planning of the technical route and built a hybrid model combining extractive and generative approaches, utilizing advanced natural language processing techniques including KeyBERT, Sentence Transformer, BERT, and T5 models. Responsible for data preprocessing and tokenization, as well as the end-to-end implementation and training of the T5 model, optimizing the model architecture and hyperparameters, achieving satisfactory results after only 3 epochs of training. Model evaluation results showed that the Rouge-1, Rouge-2, and Rouge-L metrics reached 0.6345, 0.5038, and 0.5282, respectively, in the third epoch, validating the model\u0026rsquo;s effectiveness in the summarization task. Cambridge University Machine Learning Summer Project 07/2023 ‚Äì 08/2023 Group project, supervised by Prof. Pietro Li√≤ Participated in the Cambridge University deep learning summer project, focusing on deep reinforcement learning; explored multi-agent learning algorithms across different environments. Reproduced the Multi-Agent Deep Deterministic Policy Gradient (MADDPG) algorithm in the Simple Adversary environment and studied the effect of agent numbers on convergence speed and stability, finding optimal stability at 21 agents. Designed and implemented comparative experiments inspired by the Rainbow algorithm, assessing target network strategies versus the Double Deep Q-Network (Double DQN). The results demonstrated that Double DQN significantly enhanced convergence speed, optimizing the overall learning process. Co-authored a group project paper on agent numbers and strategies effectiveness in multi-agent systems, achieving a score of 71% in the summer program (the highest in my group) and a \u0026ldquo;First Class\u0026rdquo; classification in the UK grading system. Deep Learning and Computer Vision Semester Project 09/2022 ‚Äì 12/2022 Independent project, supervised by Associate Prof. Guangyu Gao Designed and implemented a waste classifier using the ResNet model to improve classification accuracy and reduce resource waste. The project also enhanced understanding of transfer learning techniques with ResNet. Collected a dataset of 16 waste categories and preprocessed the images for uniformity and standardization, incorporating data augmentation techniques to enhance the dataset. Conducted experiments using ResNet34 and ResNet50 models through transfer learning, accelerating network convergence by leveraging pretrained weights. During training, techniques such as Batch Normalization and Dropout were applied to mitigate the risk of overfitting. The final model achieved an accuracy of 90% on the training set, while the performance on the test set was 61%, indicating a significant overfitting phenomenon during the training process. üéì Internship Beijing Academy of Quantum Information Science 08/2023 ‚Äì 01/2024 Research Intern at Quantum Computation Department Proposed a quantum convolution kernel design based on variational quantum circuits and developed a universal quantum convolution layer, successfully integrating it into classical CNN architectures such as VGG, GoogLeNet, and ResNet. Developed and evaluated various hybrid models, including a simple model named HQCCNN-2, which achieved 84.45% accuracy on the FashionMNIST dataset, surpassing the traditional CNN\u0026rsquo;s 80.72%. This demonstrates the effectiveness of the quantum convolution layer in improving model performance. Tested on a real quantum computer further validated the effectiveness of the hybrid model, demonstrating the viable integration of quantum computing with deep learning, and highlighting the potential for leveraging quantum properties to enhance model performance. üèÖ Competition Experience China International \u0026#34;Internet \u0026#43;\u0026#34; College Students\u0026#39; Innovation Competition 08/2022 Zhongke Ushield: Deep Learning-based Face Privacy Protection Authentication System Responsible for constructing a localized facial feature extraction engine based on MobileFaceNet, ensuring feature extraction is completed on end devices (such as mobile phones and cameras), guaranteeing that raw data does not leave the domain and is not stored, thus enhancing user privacy protection while improving recognition efficiency. \u0026#34;Challenge Cup\u0026#34; Capital University Entrepreneurship Competition 05/2022 Smart Orchard Responsible for the development of the fruit detection, ripeness prediction, and pest identification system, using deep convolutional neural network (CNN) technology for intelligent monitoring of crop growth conditions. Applied advanced object detection algorithms such as Faster R-CNN and YOLO to achieve high precision in apple detection and ripeness assessment, with an accuracy rate exceeding 90%, significantly enhancing the intelligence level of orchard management. Built and trained a dedicated dataset containing various pest samples, optimizing pest detection accuracy through data preprocessing (such as image normalization and resizing) and data augmentation techniques (like rotation, flipping, and noise addition), enabling the real-time monitoring system to accurately identify over 80% of pests, providing effective scientific maintenance recommendations to help farmers reduce crop losses. üìã Extracurricular Activities Vice President, Cyber Security Club, Beijing Institute of Technology 09/2021-09/2022 Backbone, Media Center of the Student Union of Beijing Institute of Technology 10/2020-06/2021 üì´ Contact üìß zongsi.xu@outlook.com üëî Zongsi (Tristan) Xu üíª github.com/BaizeXS üìç Hong Kong SAR, China ","permalink":"http://localhost:1313/resume/","summary":"Personal resume of Zongsi (Tristan) Xu","title":"Zongsi (Tristan) Xu"},{"content":"‰∏Ä„ÄÅÊï∞ÂÄºÁâπÂæÅ‰∏éÁ±ªÂà´ÁâπÂæÅ Êï∞ÂÄºÁâπÂæÅ (Numeric Features) ÂÖ∑ÊúâÂèØÂä†ÂáèÁöÑÊÑè‰πâÔºå‰∏îÂ≠òÂú®Â§ßÂ∞èÈ°∫Â∫è„ÄÇ ‰æãÂ≠êÔºöÂπ¥ÈæÑ„ÄÅÊ∏©Â∫¶Á≠â„ÄÇÂèØ‰ª•Áõ¥Êé•‰øùÁïôÂÖ∂Êï¥Êï∞ÊàñÊµÆÁÇπÊï∞ÂΩ¢Âºè‰æõÊ®°Âûã‰ΩøÁî®„ÄÇ Á±ªÂà´ÁâπÂæÅ (Categorical Features) Êï∞ÊçÆÂÄºÁ¶ªÊï£Ôºå‰∏çÂÖ∑Â§á‚ÄúÊï∞ÂÄºÂ§ßÂ∞è‚ÄùÈó¥ÁöÑÂèØÊØîÊÑè‰πâ„ÄÇ ‰æãÂ≠êÔºöÂõΩÁ±çÔºàÁæéÂõΩ/‰∏≠ÂõΩ/Âç∞Â∫¶Á≠âÔºâ„ÄÅÊÄßÂà´ÔºàÁî∑/Â•≥ÔºâÁ≠â„ÄÇ ÈóÆÈ¢òÔºöËã•‰ªÖÁî®Êï¥Êï∞Ë°®Á§∫ÔºàÁæéÂõΩ=1, ‰∏≠ÂõΩ=2ÔºâÔºå‰ºöÂºïÂÖ•ÈîôËØØÁöÑÊï∞ÂÄºËøêÁÆóÂÖ≥Á≥ªÔºåÂ¶Ç ‚ÄúÁæéÂõΩ + ‰∏≠ÂõΩ = Âç∞Â∫¶‚Äù„ÄÇ ‰∫å„ÄÅOne-HotÁºñÁ†ÅÁöÑÂä®Êú∫‰∏éÊµÅÁ®ã ‰∏∫‰ªÄ‰πà‰ΩøÁî®One-Hot\nÈÄöËøáÂ∞ÜÁ±ªÂà´Êò†Â∞Ñ‰∏∫ÂêëÈáèÔºåÈÅøÂÖçÊï¥Êï∞ÁºñÁ†ÅÂºïÂÖ•ÁöÑ‰º™Êï∞ÂÄºÂÖ≥Á≥ª„ÄÇ ÂêåÊó∂‰øùÁïôÂêÑÁßçÂèØËÉΩÁ±ªÂà´ÁöÑ‰ø°ÊÅØÔºå‰∏î‰ªÖÂú®ÂØπÂ∫î‰ΩçÁΩÆ‰∏∫1ÔºåÂÖ∂‰ªñ‰ΩçÁΩÆ‰∏∫0„ÄÇ Âª∫Á´ãÊò†Â∞ÑÔºö‰ªéÁ±ªÂà´Âà∞Á¥¢Âºï\n‰∏∫ÊØè‰∏™Á±ªÂà´ÂàÜÈÖç‰∏Ä‰∏™ÂîØ‰∏ÄÁ¥¢ÂºïÔºåÈÄöÂ∏∏‰ªé1ÂºÄÂßã„ÄÇ È¢ÑÁïôÁ¥¢Âºï0Ë°®Á§∫‚ÄúÊú™Áü•‚ÄùÊàñ‚ÄúÁº∫Â§±‚ÄùÔºåÂØπÂ∫îÂÖ®0ÂêëÈáè„ÄÇ ËΩ¨Êç¢‰∏∫One-HotÂêëÈáè\nËã•Á±ªÂà´ÊÄªÊï∞‰∏∫197ÔºåÂàôÁî®197Áª¥ÂêëÈáèË°®Á§∫„ÄÇ ‰æãÂ≠êÔºöÁæéÂõΩ [1, 0, 0, 0, ‚Ä¶]Ôºå ‰∏≠ÂõΩ [0, 1, 0, 0, ‚Ä¶]„ÄÇ Á§∫‰æãÔºöË°®Á§∫‰∏Ä‰∏™‰∫∫ÁöÑÁâπÂæÅ\nÁâπÂæÅÂåÖÂê´ÔºàÂπ¥ÈæÑ, ÊÄßÂà´, ÂõΩÁ±çÔºåÂÖ∂‰∏≠ÂõΩÁ±ç197ÁßçÔºâ Áª¥Â∫¶ÊÄªÂíåÔºö1Áª¥_age + 1Áª¥_gender + 197Áª¥_nationality = 199Áª¥„ÄÇ ‰æãÂ¶Ç (28, Â•≥, ‰∏≠ÂõΩ) ‚Üí [28, 0, 0, 1, 0, ‚Ä¶, 0]„ÄÇ ‰∏â„ÄÅÊñáÊú¨Êï∞ÊçÆÂ§ÑÁêÜÊµÅÁ®ã ÊñáÊú¨Âú®Ëá™ÁÑ∂ËØ≠Ë®ÄÂ§ÑÁêÜÔºàNLPÔºâ‰∏≠‰Ωú‰∏∫Â∏∏ËßÅÁöÑÂéüÂßãËæìÂÖ•ÔºåÈúÄË¶ÅÊï∞ÂÄºÂåñÊâçËÉΩÈÄÅÂÖ•Ê®°Âûã„ÄÇ‰∏ÄËà¨Ê≠•È™§Â¶Ç‰∏ãÔºö\nÂàÜËØç (Tokenization)\nÂ∞ÜÊñáÊú¨ÊãÜÂàÜ‰∏∫‰∏Ä‰∏™‰∏™ÂçïËØçÔºàTokenÔºâ„ÄÇ ‰æãÂ≠êÔºö\u0026quot;... to be or not to be...\u0026quot; ‚Üí [\u0026quot;...\u0026quot;, \u0026quot;to\u0026quot;, \u0026quot;be\u0026quot;, \u0026quot;or\u0026quot;, \u0026quot;not\u0026quot;, \u0026quot;to\u0026quot;, \u0026quot;be\u0026quot;, \u0026quot;...\u0026quot;]„ÄÇ ÁªüËÆ°ËØçÈ¢ë \u0026amp; ÊûÑÂª∫ËØçÂÖ∏\nËØçÈ¢ëÁªüËÆ° Áî®ÂìàÂ∏åË°®/Â≠óÂÖ∏ËÆ∞ÂΩïÊØè‰∏™ÂçïËØçÂá∫Áé∞Ê¨°Êï∞„ÄÇ ÈÅçÂéÜÊñáÊú¨Êó∂ÔºåËã•ÂçïËØçÂ∞öÊú™ÂÖ•Ë°®ÔºåÂàôÊñ∞Âª∫ËÆ∞ÂΩïÔºõËã•Â∑≤Â≠òÂú®ÔºåÂàôËÆ°Êï∞+1„ÄÇ ÊéíÂ∫è‰∏éÁ¥¢Âºï ÊåâËØçÈ¢ëÈôçÂ∫èÊéíÂ∫èÔºåËØçÈ¢ëÊúÄÈ´òÁöÑÂçïËØçÊéíÂú®ÂâçÈù¢„ÄÇ Á¥¢Âºï‰ªé1ÂºÄÂßãÔºå0ÁïôÁªô‚ÄúÊú™Áü•‚Äù„ÄÇ ËØçÂÖ∏ËßÑÊ®°ÔºàvocabularyÔºâÂèØËßÜÈúÄÊ±ÇÊà™Êñ≠Ôºà‰æãÂ¶ÇÂè™‰øùÁïôTop 10kÔºâ„ÄÇ ‰∏∫‰ªÄ‰πàÁßªÈô§‰ΩéÈ¢ëËØç ‰ΩéÈ¢ëËØçÂèØËÉΩÊòØÊãºÂÜôÈîôËØØ„ÄÅÁΩïËßÅ‰∫∫ÂêçÁ≠âÔºåÂØπÊ®°ÂûãÂ∏ÆÂä©ÊúâÈôê„ÄÇ ÂáèÂ∞ëËØçÂÖ∏ËßÑÊ®°ÂèØÈôç‰ΩéËøêÁÆóÂºÄÈîÄ„ÄÅÂä†Âø´Ê®°ÂûãËÆ≠ÁªÉ‰∏éÊé®ÁêÜÈÄüÂ∫¶„ÄÇ Áã¨ÁÉ≠ÁºñÁ†Å (One-Hot Encoding)\nÂ∞ÜÊØè‰∏™ÂçïËØçÊò†Â∞Ñ‰∏∫ËØçÂÖ∏‰∏≠ÁöÑÁ¥¢ÂºïÂêéÔºàÂ¶Ç [2, 4, 1, 8, ‚Ä¶]ÔºâÔºåÂèØËøõ‰∏ÄÊ≠•ËΩ¨Êç¢ÊàêOne-HotÂêëÈáè„ÄÇ One-HotÁª¥Â∫¶ÂèñÂÜ≥‰∫é‰øùÁïô‰∏ãÊù•ÁöÑËØçÂÖ∏Â§ßÂ∞èÔºà‰æãÂ¶Ç1‰∏áÔºâ„ÄÇ Êú™Êî∂ÂΩïÂçïËØçÂèØËÉΩÁõ¥Êé•ÂøΩÁï•ÔºåÊàñÁªü‰∏ÄÁî®Á¥¢Âºï0‰ª£Êõø„ÄÇ Âõõ„ÄÅÊ†∏ÂøÉÊî∂Ëé∑‰∏éÂ∫îÁî® Á±ªÂà´ÁâπÂæÅÂøÖÈúÄÊï∞ÂÄºÂåñÔºö\n‰ΩøÁî®Êï¥Êï∞1,2,3‚Ä¶‰ªÖË°®Á§∫Á±ªÂà´‚ÄúÊ†áËØÜ‚ÄùÔºåÂπ∂‰∏ç‰ª£Ë°®ÂÆÉ‰ª¨ÂèØËøõË°åÊï∞ÂÄºËøêÁÆó„ÄÇ Âõ†Ê≠§ÈúÄË¶ÅOne-HotÁ≠âÁºñÁ†ÅÊñπÂºèÔºåÈÅøÂÖçÊï∞ÂÄºËØØËß£„ÄÇ ÊñáÊú¨Êï∞ÊçÆÈ¢ÑÂ§ÑÁêÜÔºö\nÂàÜËØç„ÄÅËØçÈ¢ëÁªüËÆ°„ÄÅÊûÑÂª∫ËØçÂÖ∏„ÄÅÁ¥¢ÂºïÂåñ„ÄÅOne-HotÊàñÂÖ∂‰ªñÊñπÂºèÔºàÂ¶ÇËØçÂµåÂÖ•ÔºâÊòØÂ∏∏ËßÅÊµÅÁ®ã„ÄÇ Ê≠£Á°ÆÁöÑÊñáÊú¨È¢ÑÂ§ÑÁêÜÂèØÊòæËëóÂΩ±ÂìçÊ®°ÂûãÊÄßËÉΩÂíåÊïàÁéá„ÄÇ ‰øùÁïôÊú™Áü•Á¥¢ÂºïÔºö\n‰øùËØÅÂØπÁº∫Â§±Êï∞ÊçÆÊàñÂ≠óÂÖ∏Â§ñÊñ∞ËØçËÉΩÊúâÂü∫Êú¨ÁöÑË°®Á§∫ÔºåÊèêÂçáÊ®°ÂûãÂÆπÈîôÊÄß„ÄÇ ÂÆûÈôÖ‰ΩøÁî®Ôºö\nÂØπ‰∫éÂ∞èËßÑÊ®°Á±ªÂà´ÂèØÁõ¥Êé•One-HotÁºñÁ†ÅÔºõÂØπ‰∫éËØçÂÖ∏ÂæàÂ§ßÁöÑÂú∫ÊôØÔºåÈÄöÂ∏∏‰ºöËøõ‰∏ÄÊ≠•ËÄÉËôëËØçÂµåÂÖ•ÔºàWord EmbeddingÔºâÊàñÈ¢ÑËÆ≠ÁªÉËØ≠Ë®ÄÊ®°Âûã„ÄÇ ","permalink":"http://localhost:1313/posts/nlp-1/","summary":"\u003ch2 id=\"‰∏ÄÊï∞ÂÄºÁâπÂæÅ‰∏éÁ±ªÂà´ÁâπÂæÅ\"\u003e‰∏Ä„ÄÅÊï∞ÂÄºÁâπÂæÅ‰∏éÁ±ªÂà´ÁâπÂæÅ\u003c/h2\u003e\n\u003col\u003e\n\u003cli\u003e\u003cstrong\u003eÊï∞ÂÄºÁâπÂæÅ (Numeric Features)\u003c/strong\u003e\n\u003cul\u003e\n\u003cli\u003eÂÖ∑ÊúâÂèØÂä†ÂáèÁöÑÊÑè‰πâÔºå‰∏îÂ≠òÂú®Â§ßÂ∞èÈ°∫Â∫è„ÄÇ\u003c/li\u003e\n\u003cli\u003e‰æãÂ≠êÔºöÂπ¥ÈæÑ„ÄÅÊ∏©Â∫¶Á≠â„ÄÇÂèØ‰ª•Áõ¥Êé•‰øùÁïôÂÖ∂Êï¥Êï∞ÊàñÊµÆÁÇπÊï∞ÂΩ¢Âºè‰æõÊ®°Âûã‰ΩøÁî®„ÄÇ\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003eÁ±ªÂà´ÁâπÂæÅ (Categorical Features)\u003c/strong\u003e\n\u003cul\u003e\n\u003cli\u003eÊï∞ÊçÆÂÄºÁ¶ªÊï£Ôºå‰∏çÂÖ∑Â§á‚ÄúÊï∞ÂÄºÂ§ßÂ∞è‚ÄùÈó¥ÁöÑÂèØÊØîÊÑè‰πâ„ÄÇ\u003c/li\u003e\n\u003cli\u003e‰æãÂ≠êÔºöÂõΩÁ±çÔºàÁæéÂõΩ/‰∏≠ÂõΩ/Âç∞Â∫¶Á≠âÔºâ„ÄÅÊÄßÂà´ÔºàÁî∑/Â•≥ÔºâÁ≠â„ÄÇ\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003eÈóÆÈ¢ò\u003c/strong\u003eÔºöËã•‰ªÖÁî®Êï¥Êï∞Ë°®Á§∫ÔºàÁæéÂõΩ=1, ‰∏≠ÂõΩ=2ÔºâÔºå‰ºöÂºïÂÖ•ÈîôËØØÁöÑÊï∞ÂÄºËøêÁÆóÂÖ≥Á≥ªÔºåÂ¶Ç ‚ÄúÁæéÂõΩ + ‰∏≠ÂõΩ = Âç∞Â∫¶‚Äù„ÄÇ\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003c/ol\u003e\n\u003ch2 id=\"‰∫åone-hotÁºñÁ†ÅÁöÑÂä®Êú∫‰∏éÊµÅÁ®ã\"\u003e‰∫å„ÄÅOne-HotÁºñÁ†ÅÁöÑÂä®Êú∫‰∏éÊµÅÁ®ã\u003c/h2\u003e\n\u003col\u003e\n\u003cli\u003e\n\u003cp\u003e\u003cstrong\u003e‰∏∫‰ªÄ‰πà‰ΩøÁî®One-Hot\u003c/strong\u003e\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eÈÄöËøáÂ∞ÜÁ±ªÂà´Êò†Â∞Ñ‰∏∫ÂêëÈáèÔºåÈÅøÂÖçÊï¥Êï∞ÁºñÁ†ÅÂºïÂÖ•ÁöÑ‰º™Êï∞ÂÄºÂÖ≥Á≥ª„ÄÇ\u003c/li\u003e\n\u003cli\u003eÂêåÊó∂‰øùÁïôÂêÑÁßçÂèØËÉΩÁ±ªÂà´ÁöÑ‰ø°ÊÅØÔºå‰∏î‰ªÖÂú®ÂØπÂ∫î‰ΩçÁΩÆ‰∏∫1ÔºåÂÖ∂‰ªñ‰ΩçÁΩÆ‰∏∫0„ÄÇ\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003e\u003cstrong\u003eÂª∫Á´ãÊò†Â∞ÑÔºö‰ªéÁ±ªÂà´Âà∞Á¥¢Âºï\u003c/strong\u003e\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e‰∏∫ÊØè‰∏™Á±ªÂà´ÂàÜÈÖç‰∏Ä‰∏™ÂîØ‰∏ÄÁ¥¢ÂºïÔºåÈÄöÂ∏∏‰ªé1ÂºÄÂßã„ÄÇ\u003c/li\u003e\n\u003cli\u003eÈ¢ÑÁïôÁ¥¢Âºï0Ë°®Á§∫‚ÄúÊú™Áü•‚ÄùÊàñ‚ÄúÁº∫Â§±‚ÄùÔºåÂØπÂ∫îÂÖ®0ÂêëÈáè„ÄÇ\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003e\u003cstrong\u003eËΩ¨Êç¢‰∏∫One-HotÂêëÈáè\u003c/strong\u003e\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eËã•Á±ªÂà´ÊÄªÊï∞‰∏∫197ÔºåÂàôÁî®197Áª¥ÂêëÈáèË°®Á§∫„ÄÇ\u003c/li\u003e\n\u003cli\u003e‰æãÂ≠êÔºöÁæéÂõΩ \u003ccode\u003e[1, 0, 0, 0, ‚Ä¶]\u003c/code\u003eÔºå ‰∏≠ÂõΩ \u003ccode\u003e[0, 1, 0, 0, ‚Ä¶]\u003c/code\u003e„ÄÇ\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003e\u003cstrong\u003eÁ§∫‰æãÔºöË°®Á§∫‰∏Ä‰∏™‰∫∫ÁöÑÁâπÂæÅ\u003c/strong\u003e\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eÁâπÂæÅÂåÖÂê´ÔºàÂπ¥ÈæÑ, ÊÄßÂà´, ÂõΩÁ±çÔºåÂÖ∂‰∏≠ÂõΩÁ±ç197ÁßçÔºâ\u003c/li\u003e\n\u003cli\u003eÁª¥Â∫¶ÊÄªÂíåÔºö1Áª¥_age + 1Áª¥_gender + 197Áª¥_nationality = 199Áª¥„ÄÇ\u003c/li\u003e\n\u003cli\u003e‰æãÂ¶Ç \u003ccode\u003e(28, Â•≥, ‰∏≠ÂõΩ)\u003c/code\u003e ‚Üí \u003ccode\u003e[28, 0, 0, 1, 0, ‚Ä¶, 0]\u003c/code\u003e„ÄÇ\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003c/ol\u003e\n\u003ch2 id=\"‰∏âÊñáÊú¨Êï∞ÊçÆÂ§ÑÁêÜÊµÅÁ®ã\"\u003e‰∏â„ÄÅÊñáÊú¨Êï∞ÊçÆÂ§ÑÁêÜÊµÅÁ®ã\u003c/h2\u003e\n\u003cp\u003eÊñáÊú¨Âú®Ëá™ÁÑ∂ËØ≠Ë®ÄÂ§ÑÁêÜÔºàNLPÔºâ‰∏≠‰Ωú‰∏∫Â∏∏ËßÅÁöÑÂéüÂßãËæìÂÖ•ÔºåÈúÄË¶ÅÊï∞ÂÄºÂåñÊâçËÉΩÈÄÅÂÖ•Ê®°Âûã„ÄÇ‰∏ÄËà¨Ê≠•È™§Â¶Ç‰∏ãÔºö\u003c/p\u003e\n\u003col\u003e\n\u003cli\u003e\n\u003cp\u003e\u003cstrong\u003eÂàÜËØç (Tokenization)\u003c/strong\u003e\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eÂ∞ÜÊñáÊú¨ÊãÜÂàÜ‰∏∫‰∏Ä‰∏™‰∏™ÂçïËØçÔºàTokenÔºâ„ÄÇ\u003c/li\u003e\n\u003cli\u003e‰æãÂ≠êÔºö\u003ccode\u003e\u0026quot;... to be or not to be...\u0026quot;\u003c/code\u003e ‚Üí \u003ccode\u003e[\u0026quot;...\u0026quot;, \u0026quot;to\u0026quot;, \u0026quot;be\u0026quot;, \u0026quot;or\u0026quot;, \u0026quot;not\u0026quot;, \u0026quot;to\u0026quot;, \u0026quot;be\u0026quot;, \u0026quot;...\u0026quot;]\u003c/code\u003e„ÄÇ\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003e\u003cstrong\u003eÁªüËÆ°ËØçÈ¢ë \u0026amp; ÊûÑÂª∫ËØçÂÖ∏\u003c/strong\u003e\u003c/p\u003e","title":""},{"content":"Text to Sequence ÊñáÊú¨Â§ÑÁêÜ\nStep1: Tokenization\nTokenization breaks a piece of text down into a list of tokens.\nHere, a token is a word. (A token can be a character in some applications.)\nTokenizationËÆ≤Á©∂ÂæàÂ§öÔºå‰æãÂ¶ÇÊòØÂê¶Â∫îËØ•ÊääÂ§ßÂÜôÊîπÊàêÂ∞èÂÜôÂë¢ÔºüËøõË°åtypo correctionÁ≠âÁ≠â\nStep2: Build Dictionary\nUse a dictionary (hash table) to count word frequencies.\nThe dictionary maps word to index.\nÂèØ‰ª•È¶ñÂÖàÁªüËÆ°ËØçÈ¢ëÂéªÊéâ‰ΩéÈ¢ëËØçÔºåÁÑ∂ÂêéËÆ©ÊØè‰∏™ËØçÂØπÂ∫î‰∏Ä‰∏™Ê≠£Êï¥Êï∞ÔºõËøôÊ†∑ÁöÑËØùÔºå‰∏ÄÂè•ËØùÂ∞±ÂèØ‰ª•Áî®‰∏Ä‰∏™Ê≠£Êï¥Êï∞ÂàóË°®Ë°®Á§∫ÔºåËøô‰∏™ÂàóË°®Â∞±Âè´sequenceÔºõÂ¶ÇÊûúÂøÖË¶ÅÂ∞±ËøòÂæóÂÅöone-hot encoding„ÄÇ\nÁªìÊûú\n‰ΩÜÊòØÈïøÂ∫¶‰∏çÁªü‰∏Ä\nStep4: ÂØπÈΩêsequence\nËß£ÂÜ≥ÊñπÊ°àÊòØËøôÊ†∑ÁöÑÔºöÂèØ‰ª•Âõ∫ÂÆöÈïøÂ∫¶‰∏∫wÔºåÂä†ÂÖ•‰∏Ä‰∏™Â∫èÂàóÈïøÂ∫¶Â§™ÈïøÔºåÂ∞±Á†çÊéâÂâçÈù¢ÁöÑËØçÔºåÂè™‰øùÁïôÊúÄÂêéw‰∏™ËØçÔºõÂ¶ÇÊûú‰∏Ä‰∏™Â∫èÂàóÂ§™Áü≠ÔºåÂ∞±ÂÅözero paddingÔºåÁî®0Â°´ÂÖÖ\nËøôÊ†∑‰∏ÄÊù•ÔºåÊâÄÊúâÁöÑÂ∫èÂàóÈïøÂ∫¶Â∞±Áªü‰∏Ä‰∫Ü\nÊñáÊú¨Â§ÑÁêÜÂÆåÊàê‰∫ÜÔºåÊé•‰∏ãÊù•ÊòØword embeddingÔºåÊääÂçïËØçË°®Á§∫‰∏∫‰∏Ä‰∏™‰ΩéÁª¥ÂêëÈáèÔºõ\nÁÑ∂ËÄåËøôÊ†∑ÂÅöÁöÑËØùÔºåÂ¶ÇÊûúÊòØ10000‰∏™ÂçïËØçÔºåÁª¥Â∫¶Â∞±ÊòØ10000Áª¥ÔºåÁª¥Â∫¶Â§™È´ò‰∫ÜÔºõÂõ†Ê≠§Ë¶ÅÂÅöword embeddingÔºõ\nÂÖ∑‰ΩìÂÅöÊ≥ïÂ∞±ÊòØÊääone-hotÂêëÈáèe_iÂíåÂèÇÊï∞Áü©ÈòµpÁõ∏‰πòÔºõÁü©ÈòµPËΩ¨ÁΩÆÁöÑÂ§ßÂ∞èÊòØd x vÔºõdÊòØËØçÂêëÈáèÁöÑÁª¥Â∫¶ÔºõvÊòØÂ≠óÂÖ∏ÈáåËØçÊ±áÁöÑÊï∞ÈáèÔºõÁªìÊûú‰∏∫x_iÔºõx_iÂ∞±ÊòØ‰∏Ä‰∏™ËØçÂêëÈáèÔºõÂ¶ÇÊûúone-hotÂêëÈáèÁöÑÁ¨¨‰∏âË°å‰∏∫1ÔºõÈÇ£‰πàx_iÂ∞±ÊòØPËΩ¨ÁΩÆÁü©ÈòµÁöÑÁ¨¨‰∏âÂàóÔºàÂÖ∂‰ΩôÂàóÈÉΩ‰∏∫0ÔºâÔºõÊâÄ‰ª•PËΩ¨ÁΩÆÊØè‰∏ÄÂàóÈÉΩÊòØ‰∏Ä‰∏™ËØçÂêëÈáèÔºõÊâÄ‰ª•Áü©ÈòµPÊú¨Ë∫´ÁöÑÊØè‰∏ÄË°åÂ∞±ÊòØ‰∏Ä‰∏™ËØçÂêëÈáèÔºõÂÖ∂Ë°åÊï∞‰∏∫vÔºõÂç≥vocabularyÔºåËØçÊ±áÈáèÔºõÊØè‰∏ÄË°åÂØπÂ∫î‰∏Ä‰∏™ÂçïËØçÔºõÁü©ÈòµÁöÑÂàóÊï∞‰∏∫dÔºõdÊòØÁî®Êà∑ÂÜ≥ÂÆöÁöÑÔºõdÁöÑÂ§ßÂ∞è‰ºöÂÜ≥ÂÆöÊú∫Âô®Â≠¶‰π†Ê®°ÂûãÁöÑË°®Áé∞ÔºõÂ∫îËØ•Áî®xxxÊù•ÈÄâÊã©‰∏Ä‰∏™ÊØîËæÉÂ•ΩÁöÑdÔºõ\nÊàë‰ª¨ÁöÑ‰ªªÂä°ÊòØÁúãËØÑËÆ∫ÊòØÊ≠£Èù¢ÁöÑËøòÊòØË¥üÈù¢ÁöÑÔºõÂèÇÊï∞Áü©ÈòµÊòØ‰ªéËÆ≠ÁªÉÊï∞ÊçÆ‰∏≠Â≠¶‰π†Âá∫Êù•ÁöÑÔºåÊâÄ‰ª•Â≠¶Âá∫Êù•ÁöÑËØçÂêëÈáèÊòØÂ∏¶ÊúâÊÑüÊÉÖËâ≤ÂΩ©ÁöÑÔºõÂÅáËÆæËøô‰∫õËØçÂêëÈáèÈÉΩÊòØ‰∫åÁª¥ÁöÑÔºåÂàôÂèØ‰ª•Âú®Âπ≥Èù¢ÂùêÊ†áÁ≥ª‰∏≠Ê†áÂá∫‰∏ãÈù¢ËØçÂêëÈáè\nkerasÊèê‰æõembeddingÂ±ÇÔºõÁî®Êà∑ÂèØ‰ª•ÊåáÂÆövocabularyÂ§ßÂ∞èÂíådÁöÑÂ§ßÂ∞èÔºõ‰ª•ÂèäÊØè‰∏Ä‰∏™sequenceÁöÑÈïøÂ∫¶ÔºõdÊòØÊ†πÊçÆÁÆóÊ≥ïÈÄâÂá∫Êù•ÁöÑ Âà∞Ëøô‰∏ÄÊ≠•ÔºåÊàë‰ª¨Â∑≤ÁªèÂÆåÊàê‰∫ÜÊñáÊú¨Â§ÑÁêÜÂíåword embedding„ÄÇÊé•‰∏ãÊù•Â∞±ÊòØÁî®Logistic Regression for Binary ClassificationÂÅö‰∫åÂàÜÁ±ªÔºõ\n","permalink":"http://localhost:1313/posts/nlp-2/","summary":"\u003ch3 id=\"text-to-sequence\"\u003eText to Sequence\u003c/h3\u003e\n\u003cp\u003eÊñáÊú¨Â§ÑÁêÜ\u003c/p\u003e\n\u003cp\u003eStep1: Tokenization\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\n\u003cp\u003eTokenization breaks a piece of text down into a list of tokens.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003eHere, a token is a word. (A token can be a character in some applications.)\u003c/p\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003eTokenizationËÆ≤Á©∂ÂæàÂ§öÔºå‰æãÂ¶ÇÊòØÂê¶Â∫îËØ•ÊääÂ§ßÂÜôÊîπÊàêÂ∞èÂÜôÂë¢ÔºüËøõË°åtypo correctionÁ≠âÁ≠â\u003c/p\u003e\n\u003cp\u003e\u003cimg alt=\"image-20250322150322238\" loading=\"lazy\" src=\"./NLP-2.assets/image-20250322150322238.png\"\u003e\u003c/p\u003e\n\u003cp\u003eStep2: Build Dictionary\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\n\u003cp\u003eUse a dictionary (hash table) to count word frequencies.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003eThe dictionary maps word to index.\u003c/p\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003eÂèØ‰ª•È¶ñÂÖàÁªüËÆ°ËØçÈ¢ëÂéªÊéâ‰ΩéÈ¢ëËØçÔºåÁÑ∂ÂêéËÆ©ÊØè‰∏™ËØçÂØπÂ∫î‰∏Ä‰∏™Ê≠£Êï¥Êï∞ÔºõËøôÊ†∑ÁöÑËØùÔºå‰∏ÄÂè•ËØùÂ∞±ÂèØ‰ª•Áî®‰∏Ä‰∏™Ê≠£Êï¥Êï∞ÂàóË°®Ë°®Á§∫ÔºåËøô‰∏™ÂàóË°®Â∞±Âè´sequenceÔºõÂ¶ÇÊûúÂøÖË¶ÅÂ∞±ËøòÂæóÂÅöone-hot encoding„ÄÇ\u003cimg alt=\"image-20250322150620890\" loading=\"lazy\" src=\"./NLP-2.assets/image-20250322150620890.png\"\u003e\u003c/p\u003e\n\u003cp\u003eÁªìÊûú\u003c/p\u003e\n\u003cp\u003e\u003cimg alt=\"image-20250322150754528\" loading=\"lazy\" src=\"./NLP-2.assets/image-20250322150754528.png\"\u003e\u003c/p\u003e\n\u003cp\u003e‰ΩÜÊòØÈïøÂ∫¶‰∏çÁªü‰∏Ä\u003c/p\u003e\n\u003cp\u003eStep4: ÂØπÈΩêsequence\u003c/p\u003e\n\u003cp\u003e\u003cimg alt=\"image-20250322150854986\" loading=\"lazy\" src=\"./NLP-2.assets/image-20250322150854986.png\"\u003e\u003c/p\u003e\n\u003cp\u003eËß£ÂÜ≥ÊñπÊ°àÊòØËøôÊ†∑ÁöÑÔºöÂèØ‰ª•Âõ∫ÂÆöÈïøÂ∫¶‰∏∫wÔºåÂä†ÂÖ•‰∏Ä‰∏™Â∫èÂàóÈïøÂ∫¶Â§™ÈïøÔºåÂ∞±Á†çÊéâÂâçÈù¢ÁöÑËØçÔºåÂè™‰øùÁïôÊúÄÂêéw‰∏™ËØçÔºõÂ¶ÇÊûú‰∏Ä‰∏™Â∫èÂàóÂ§™Áü≠ÔºåÂ∞±ÂÅözero paddingÔºåÁî®0Â°´ÂÖÖ\u003c/p\u003e\n\u003cp\u003e\u003cimg alt=\"image-20250322151030119\" loading=\"lazy\" src=\"./NLP-2.assets/image-20250322151030119.png\"\u003e\u003c/p\u003e\n\u003cp\u003eËøôÊ†∑‰∏ÄÊù•ÔºåÊâÄÊúâÁöÑÂ∫èÂàóÈïøÂ∫¶Â∞±Áªü‰∏Ä‰∫Ü\u003c/p\u003e\n\u003cp\u003e\u003cimg alt=\"image-20250322151117125\" loading=\"lazy\" src=\"./NLP-2.assets/image-20250322151117125.png\"\u003e\u003c/p\u003e\n\u003cp\u003eÊñáÊú¨Â§ÑÁêÜÂÆåÊàê‰∫ÜÔºåÊé•‰∏ãÊù•ÊòØword embeddingÔºåÊääÂçïËØçË°®Á§∫‰∏∫‰∏Ä‰∏™‰ΩéÁª¥ÂêëÈáèÔºõ\u003c/p\u003e\n\u003cp\u003e\u003cimg alt=\"image-20250322151252837\" loading=\"lazy\" src=\"./NLP-2.assets/image-20250322151252837.png\"\u003e\u003c/p\u003e","title":""},{"content":"üëã About me Recently, inspired by OpenAI\u0026rsquo;s five-step plan towards superintelligence, I have great expectations for AGI and developed a strong interest in LLM agents, MLLM, reinforcement learning, and knowledge graphs. I believe there is significant potential in these fields to create innovative solutions, and I hope to contribute my efforts towards that goal.\nüìö Education üá≠üá∞ The University of Hong Kong 09/2024 - Expected 11/2025 School of Computing and Data Science Master of Science in Electronic Commerce \u0026amp; Internet Computing Relevant Courses: Machine learning for business and e-commerce, Knowledge graphs, Financial fraud analytics, Internet infrastructure technologies, Website engineering, Blockchain and cryptocurrency, etc. üá®üá≥ Beijing Institute of Technology 09/2020 - 06/2024 School of Computer Science \u0026amp; Technology Bachelor of Engineering in Software Engineering, last two years GPA: 3.7/4 Relevant Courses: Reinforcement Learning, Deep Learning and Computer Vision, Artificial Intelligence and Robot Ethics, Almost Human: Mind, Brain and Artificial Intelligence, Mathematical Analysis for Engineering, Linear Algebra, Probability and Mathematical Statistics, etc. Skills: Python, Java, common data structures, design patterns, machine learning basics and algorithms, Linux, PyTorch, and some development tools (git, conda, etc.). üèÜ Awards \u0026amp; Honors Beijing Institute of Technology Undergraduate Scholarship (Top 20% of Grade) 06/2023 3rd Prize of China International \u0026#34;Internet \u0026#43;\u0026#34; College Student\u0026#39;s Innovation Competition 08/2022 Bronze Prize of \u0026#34;Challenge Cup\u0026#34; Capital University Entrepreneurship Competition 05/2022 üíº Project Experience Online Transaction Fraud Detection 09/2024 ‚Äì 01/2025 Independent project, supervised by Dr. Vivien Chan Focused on addressing financial fraud in e-commerce to enhance the accuracy of transaction anomaly detection, while independently managing the entire case study that included data preprocessing, feature engineering, model building, evaluation, and results analysis. Effectively resolved class imbalance issues using SMOTE and ROSE techniques. Built various models including Logistic Regression, Random Forest, XGBoost, and LightGBM, ultimately selecting the LightGBM model to achieve a recall rate of 95.45% and an AUC of 99.84%. Wrote efficient and maintainable code, enhancing model training and data processing efficiency through parallel computing and logging. Multi-Model Intelligent Text Keyword Extraction System 08/2023 ‚Äì 09/2023 Group project, supervised by Associate Prof. Xiaolin Zhao Designed and implemented an intelligent text summary system that automatically extracts keywords from article titles and abstracts, enhancing the understanding and summarization of text information. Participated in the planning of the technical route and built a hybrid model combining extractive and generative approaches, utilizing advanced natural language processing techniques including KeyBERT, Sentence Transformer, BERT, and T5 models. Responsible for data preprocessing and tokenization, as well as the end-to-end implementation and training of the T5 model, optimizing the model architecture and hyperparameters, achieving satisfactory results after only 3 epochs of training. Model evaluation results showed that the Rouge-1, Rouge-2, and Rouge-L metrics reached 0.6345, 0.5038, and 0.5282, respectively, in the third epoch, validating the model\u0026rsquo;s effectiveness in the summarization task. Cambridge University Machine Learning Summer Project 07/2023 ‚Äì 08/2023 Group project, supervised by Prof. Pietro Li√≤ Participated in the Cambridge University deep learning summer project, focusing on deep reinforcement learning; explored multi-agent learning algorithms across different environments. Reproduced the Multi-Agent Deep Deterministic Policy Gradient (MADDPG) algorithm in the Simple Adversary environment and studied the effect of agent numbers on convergence speed and stability, finding optimal stability at 21 agents. Designed and implemented comparative experiments inspired by the Rainbow algorithm, assessing target network strategies versus the Double Deep Q-Network (Double DQN). The results demonstrated that Double DQN significantly enhanced convergence speed, optimizing the overall learning process. Co-authored a group project paper on agent numbers and strategies effectiveness in multi-agent systems, achieving a score of 71% in the summer program (the highest in my group) and a \u0026ldquo;First Class\u0026rdquo; classification in the UK grading system. Deep Learning and Computer Vision Semester Project 09/2022 ‚Äì 12/2022 Independent project, supervised by Associate Prof. Guangyu Gao Designed and implemented a waste classifier using the ResNet model to improve classification accuracy and reduce resource waste. The project also enhanced understanding of transfer learning techniques with ResNet. Collected a dataset of 16 waste categories and preprocessed the images for uniformity and standardization, incorporating data augmentation techniques to enhance the dataset. Conducted experiments using ResNet34 and ResNet50 models through transfer learning, accelerating network convergence by leveraging pretrained weights. During training, techniques such as Batch Normalization and Dropout were applied to mitigate the risk of overfitting. The final model achieved an accuracy of 90% on the training set, while the performance on the test set was 61%, indicating a significant overfitting phenomenon during the training process. üéì Internship Beijing Academy of Quantum Information Science 08/2023 ‚Äì 01/2024 Research Intern at Quantum Computation Department Proposed a quantum convolution kernel design based on variational quantum circuits and developed a universal quantum convolution layer, successfully integrating it into classical CNN architectures such as VGG, GoogLeNet, and ResNet. Developed and evaluated various hybrid models, including a simple model named HQCCNN-2, which achieved 84.45% accuracy on the FashionMNIST dataset, surpassing the traditional CNN\u0026rsquo;s 80.72%. This demonstrates the effectiveness of the quantum convolution layer in improving model performance. Tested on a real quantum computer further validated the effectiveness of the hybrid model, demonstrating the viable integration of quantum computing with deep learning, and highlighting the potential for leveraging quantum properties to enhance model performance. üèÖ Competition Experience China International \u0026#34;Internet \u0026#43;\u0026#34; College Students\u0026#39; Innovation Competition 08/2022 Zhongke Ushield: Deep Learning-based Face Privacy Protection Authentication System Responsible for constructing a localized facial feature extraction engine based on MobileFaceNet, ensuring feature extraction is completed on end devices (such as mobile phones and cameras), guaranteeing that raw data does not leave the domain and is not stored, thus enhancing user privacy protection while improving recognition efficiency. \u0026#34;Challenge Cup\u0026#34; Capital University Entrepreneurship Competition 05/2022 Smart Orchard Responsible for the development of the fruit detection, ripeness prediction, and pest identification system, using deep convolutional neural network (CNN) technology for intelligent monitoring of crop growth conditions. Applied advanced object detection algorithms such as Faster R-CNN and YOLO to achieve high precision in apple detection and ripeness assessment, with an accuracy rate exceeding 90%, significantly enhancing the intelligence level of orchard management. Built and trained a dedicated dataset containing various pest samples, optimizing pest detection accuracy through data preprocessing (such as image normalization and resizing) and data augmentation techniques (like rotation, flipping, and noise addition), enabling the real-time monitoring system to accurately identify over 80% of pests, providing effective scientific maintenance recommendations to help farmers reduce crop losses. üìã Extracurricular Activities Vice President, Cyber Security Club, Beijing Institute of Technology 09/2021-09/2022 Backbone, Media Center of the Student Union of Beijing Institute of Technology 10/2020-06/2021 üì´ Contact üìß zongsi.xu@outlook.com üëî Zongsi (Tristan) Xu üíª github.com/BaizeXS üìç Hong Kong SAR, China ","permalink":"http://localhost:1313/resume/","summary":"Personal resume of Zongsi (Tristan) Xu","title":"Zongsi (Tristan) Xu"},{"content":"‰∏Ä„ÄÅÊï∞ÂÄºÁâπÂæÅ‰∏éÁ±ªÂà´ÁâπÂæÅ Êï∞ÂÄºÁâπÂæÅ (Numeric Features) ÂÖ∑ÊúâÂèØÂä†ÂáèÁöÑÊÑè‰πâÔºå‰∏îÂ≠òÂú®Â§ßÂ∞èÈ°∫Â∫è„ÄÇ ‰æãÂ≠êÔºöÂπ¥ÈæÑ„ÄÅÊ∏©Â∫¶Á≠â„ÄÇÂèØ‰ª•Áõ¥Êé•‰øùÁïôÂÖ∂Êï¥Êï∞ÊàñÊµÆÁÇπÊï∞ÂΩ¢Âºè‰æõÊ®°Âûã‰ΩøÁî®„ÄÇ Á±ªÂà´ÁâπÂæÅ (Categorical Features) Êï∞ÊçÆÂÄºÁ¶ªÊï£Ôºå‰∏çÂÖ∑Â§á‚ÄúÊï∞ÂÄºÂ§ßÂ∞è‚ÄùÈó¥ÁöÑÂèØÊØîÊÑè‰πâ„ÄÇ ‰æãÂ≠êÔºöÂõΩÁ±çÔºàÁæéÂõΩ/‰∏≠ÂõΩ/Âç∞Â∫¶Á≠âÔºâ„ÄÅÊÄßÂà´ÔºàÁî∑/Â•≥ÔºâÁ≠â„ÄÇ ÈóÆÈ¢òÔºöËã•‰ªÖÁî®Êï¥Êï∞Ë°®Á§∫ÔºàÁæéÂõΩ=1, ‰∏≠ÂõΩ=2ÔºâÔºå‰ºöÂºïÂÖ•ÈîôËØØÁöÑÊï∞ÂÄºËøêÁÆóÂÖ≥Á≥ªÔºåÂ¶Ç ‚ÄúÁæéÂõΩ + ‰∏≠ÂõΩ = Âç∞Â∫¶‚Äù„ÄÇ ‰∫å„ÄÅOne-HotÁºñÁ†ÅÁöÑÂä®Êú∫‰∏éÊµÅÁ®ã ‰∏∫‰ªÄ‰πà‰ΩøÁî®One-Hot\nÈÄöËøáÂ∞ÜÁ±ªÂà´Êò†Â∞Ñ‰∏∫ÂêëÈáèÔºåÈÅøÂÖçÊï¥Êï∞ÁºñÁ†ÅÂºïÂÖ•ÁöÑ‰º™Êï∞ÂÄºÂÖ≥Á≥ª„ÄÇ ÂêåÊó∂‰øùÁïôÂêÑÁßçÂèØËÉΩÁ±ªÂà´ÁöÑ‰ø°ÊÅØÔºå‰∏î‰ªÖÂú®ÂØπÂ∫î‰ΩçÁΩÆ‰∏∫1ÔºåÂÖ∂‰ªñ‰ΩçÁΩÆ‰∏∫0„ÄÇ Âª∫Á´ãÊò†Â∞ÑÔºö‰ªéÁ±ªÂà´Âà∞Á¥¢Âºï\n‰∏∫ÊØè‰∏™Á±ªÂà´ÂàÜÈÖç‰∏Ä‰∏™ÂîØ‰∏ÄÁ¥¢ÂºïÔºåÈÄöÂ∏∏‰ªé1ÂºÄÂßã„ÄÇ È¢ÑÁïôÁ¥¢Âºï0Ë°®Á§∫‚ÄúÊú™Áü•‚ÄùÊàñ‚ÄúÁº∫Â§±‚ÄùÔºåÂØπÂ∫îÂÖ®0ÂêëÈáè„ÄÇ ËΩ¨Êç¢‰∏∫One-HotÂêëÈáè\nËã•Á±ªÂà´ÊÄªÊï∞‰∏∫197ÔºåÂàôÁî®197Áª¥ÂêëÈáèË°®Á§∫„ÄÇ ‰æãÂ≠êÔºöÁæéÂõΩ [1, 0, 0, 0, ‚Ä¶]Ôºå ‰∏≠ÂõΩ [0, 1, 0, 0, ‚Ä¶]„ÄÇ Á§∫‰æãÔºöË°®Á§∫‰∏Ä‰∏™‰∫∫ÁöÑÁâπÂæÅ\nÁâπÂæÅÂåÖÂê´ÔºàÂπ¥ÈæÑ, ÊÄßÂà´, ÂõΩÁ±çÔºåÂÖ∂‰∏≠ÂõΩÁ±ç197ÁßçÔºâ Áª¥Â∫¶ÊÄªÂíåÔºö1Áª¥_age + 1Áª¥_gender + 197Áª¥_nationality = 199Áª¥„ÄÇ ‰æãÂ¶Ç (28, Â•≥, ‰∏≠ÂõΩ) ‚Üí [28, 0, 0, 1, 0, ‚Ä¶, 0]„ÄÇ ‰∏â„ÄÅÊñáÊú¨Êï∞ÊçÆÂ§ÑÁêÜÊµÅÁ®ã ÊñáÊú¨Âú®Ëá™ÁÑ∂ËØ≠Ë®ÄÂ§ÑÁêÜÔºàNLPÔºâ‰∏≠‰Ωú‰∏∫Â∏∏ËßÅÁöÑÂéüÂßãËæìÂÖ•ÔºåÈúÄË¶ÅÊï∞ÂÄºÂåñÊâçËÉΩÈÄÅÂÖ•Ê®°Âûã„ÄÇ‰∏ÄËà¨Ê≠•È™§Â¶Ç‰∏ãÔºö\nÂàÜËØç (Tokenization)\nÂ∞ÜÊñáÊú¨ÊãÜÂàÜ‰∏∫‰∏Ä‰∏™‰∏™ÂçïËØçÔºàTokenÔºâ„ÄÇ ‰æãÂ≠êÔºö\u0026quot;... to be or not to be...\u0026quot; ‚Üí [\u0026quot;...\u0026quot;, \u0026quot;to\u0026quot;, \u0026quot;be\u0026quot;, \u0026quot;or\u0026quot;, \u0026quot;not\u0026quot;, \u0026quot;to\u0026quot;, \u0026quot;be\u0026quot;, \u0026quot;...\u0026quot;]„ÄÇ ÁªüËÆ°ËØçÈ¢ë \u0026amp; ÊûÑÂª∫ËØçÂÖ∏\nËØçÈ¢ëÁªüËÆ° Áî®ÂìàÂ∏åË°®/Â≠óÂÖ∏ËÆ∞ÂΩïÊØè‰∏™ÂçïËØçÂá∫Áé∞Ê¨°Êï∞„ÄÇ ÈÅçÂéÜÊñáÊú¨Êó∂ÔºåËã•ÂçïËØçÂ∞öÊú™ÂÖ•Ë°®ÔºåÂàôÊñ∞Âª∫ËÆ∞ÂΩïÔºõËã•Â∑≤Â≠òÂú®ÔºåÂàôËÆ°Êï∞+1„ÄÇ ÊéíÂ∫è‰∏éÁ¥¢Âºï ÊåâËØçÈ¢ëÈôçÂ∫èÊéíÂ∫èÔºåËØçÈ¢ëÊúÄÈ´òÁöÑÂçïËØçÊéíÂú®ÂâçÈù¢„ÄÇ Á¥¢Âºï‰ªé1ÂºÄÂßãÔºå0ÁïôÁªô‚ÄúÊú™Áü•‚Äù„ÄÇ ËØçÂÖ∏ËßÑÊ®°ÔºàvocabularyÔºâÂèØËßÜÈúÄÊ±ÇÊà™Êñ≠Ôºà‰æãÂ¶ÇÂè™‰øùÁïôTop 10kÔºâ„ÄÇ ‰∏∫‰ªÄ‰πàÁßªÈô§‰ΩéÈ¢ëËØç ‰ΩéÈ¢ëËØçÂèØËÉΩÊòØÊãºÂÜôÈîôËØØ„ÄÅÁΩïËßÅ‰∫∫ÂêçÁ≠âÔºåÂØπÊ®°ÂûãÂ∏ÆÂä©ÊúâÈôê„ÄÇ ÂáèÂ∞ëËØçÂÖ∏ËßÑÊ®°ÂèØÈôç‰ΩéËøêÁÆóÂºÄÈîÄ„ÄÅÂä†Âø´Ê®°ÂûãËÆ≠ÁªÉ‰∏éÊé®ÁêÜÈÄüÂ∫¶„ÄÇ Áã¨ÁÉ≠ÁºñÁ†Å (One-Hot Encoding)\nÂ∞ÜÊØè‰∏™ÂçïËØçÊò†Â∞Ñ‰∏∫ËØçÂÖ∏‰∏≠ÁöÑÁ¥¢ÂºïÂêéÔºàÂ¶Ç [2, 4, 1, 8, ‚Ä¶]ÔºâÔºåÂèØËøõ‰∏ÄÊ≠•ËΩ¨Êç¢ÊàêOne-HotÂêëÈáè„ÄÇ One-HotÁª¥Â∫¶ÂèñÂÜ≥‰∫é‰øùÁïô‰∏ãÊù•ÁöÑËØçÂÖ∏Â§ßÂ∞èÔºà‰æãÂ¶Ç1‰∏áÔºâ„ÄÇ Êú™Êî∂ÂΩïÂçïËØçÂèØËÉΩÁõ¥Êé•ÂøΩÁï•ÔºåÊàñÁªü‰∏ÄÁî®Á¥¢Âºï0‰ª£Êõø„ÄÇ Âõõ„ÄÅÊ†∏ÂøÉÊî∂Ëé∑‰∏éÂ∫îÁî® Á±ªÂà´ÁâπÂæÅÂøÖÈúÄÊï∞ÂÄºÂåñÔºö\n‰ΩøÁî®Êï¥Êï∞1,2,3‚Ä¶‰ªÖË°®Á§∫Á±ªÂà´‚ÄúÊ†áËØÜ‚ÄùÔºåÂπ∂‰∏ç‰ª£Ë°®ÂÆÉ‰ª¨ÂèØËøõË°åÊï∞ÂÄºËøêÁÆó„ÄÇ Âõ†Ê≠§ÈúÄË¶ÅOne-HotÁ≠âÁºñÁ†ÅÊñπÂºèÔºåÈÅøÂÖçÊï∞ÂÄºËØØËß£„ÄÇ ÊñáÊú¨Êï∞ÊçÆÈ¢ÑÂ§ÑÁêÜÔºö\nÂàÜËØç„ÄÅËØçÈ¢ëÁªüËÆ°„ÄÅÊûÑÂª∫ËØçÂÖ∏„ÄÅÁ¥¢ÂºïÂåñ„ÄÅOne-HotÊàñÂÖ∂‰ªñÊñπÂºèÔºàÂ¶ÇËØçÂµåÂÖ•ÔºâÊòØÂ∏∏ËßÅÊµÅÁ®ã„ÄÇ Ê≠£Á°ÆÁöÑÊñáÊú¨È¢ÑÂ§ÑÁêÜÂèØÊòæËëóÂΩ±ÂìçÊ®°ÂûãÊÄßËÉΩÂíåÊïàÁéá„ÄÇ ‰øùÁïôÊú™Áü•Á¥¢ÂºïÔºö\n‰øùËØÅÂØπÁº∫Â§±Êï∞ÊçÆÊàñÂ≠óÂÖ∏Â§ñÊñ∞ËØçËÉΩÊúâÂü∫Êú¨ÁöÑË°®Á§∫ÔºåÊèêÂçáÊ®°ÂûãÂÆπÈîôÊÄß„ÄÇ ÂÆûÈôÖ‰ΩøÁî®Ôºö\nÂØπ‰∫éÂ∞èËßÑÊ®°Á±ªÂà´ÂèØÁõ¥Êé•One-HotÁºñÁ†ÅÔºõÂØπ‰∫éËØçÂÖ∏ÂæàÂ§ßÁöÑÂú∫ÊôØÔºåÈÄöÂ∏∏‰ºöËøõ‰∏ÄÊ≠•ËÄÉËôëËØçÂµåÂÖ•ÔºàWord EmbeddingÔºâÊàñÈ¢ÑËÆ≠ÁªÉËØ≠Ë®ÄÊ®°Âûã„ÄÇ ","permalink":"http://localhost:1313/posts/nlp-1/","summary":"\u003ch2 id=\"‰∏ÄÊï∞ÂÄºÁâπÂæÅ‰∏éÁ±ªÂà´ÁâπÂæÅ\"\u003e‰∏Ä„ÄÅÊï∞ÂÄºÁâπÂæÅ‰∏éÁ±ªÂà´ÁâπÂæÅ\u003c/h2\u003e\n\u003col\u003e\n\u003cli\u003e\u003cstrong\u003eÊï∞ÂÄºÁâπÂæÅ (Numeric Features)\u003c/strong\u003e\n\u003cul\u003e\n\u003cli\u003eÂÖ∑ÊúâÂèØÂä†ÂáèÁöÑÊÑè‰πâÔºå‰∏îÂ≠òÂú®Â§ßÂ∞èÈ°∫Â∫è„ÄÇ\u003c/li\u003e\n\u003cli\u003e‰æãÂ≠êÔºöÂπ¥ÈæÑ„ÄÅÊ∏©Â∫¶Á≠â„ÄÇÂèØ‰ª•Áõ¥Êé•‰øùÁïôÂÖ∂Êï¥Êï∞ÊàñÊµÆÁÇπÊï∞ÂΩ¢Âºè‰æõÊ®°Âûã‰ΩøÁî®„ÄÇ\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003eÁ±ªÂà´ÁâπÂæÅ (Categorical Features)\u003c/strong\u003e\n\u003cul\u003e\n\u003cli\u003eÊï∞ÊçÆÂÄºÁ¶ªÊï£Ôºå‰∏çÂÖ∑Â§á‚ÄúÊï∞ÂÄºÂ§ßÂ∞è‚ÄùÈó¥ÁöÑÂèØÊØîÊÑè‰πâ„ÄÇ\u003c/li\u003e\n\u003cli\u003e‰æãÂ≠êÔºöÂõΩÁ±çÔºàÁæéÂõΩ/‰∏≠ÂõΩ/Âç∞Â∫¶Á≠âÔºâ„ÄÅÊÄßÂà´ÔºàÁî∑/Â•≥ÔºâÁ≠â„ÄÇ\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003eÈóÆÈ¢ò\u003c/strong\u003eÔºöËã•‰ªÖÁî®Êï¥Êï∞Ë°®Á§∫ÔºàÁæéÂõΩ=1, ‰∏≠ÂõΩ=2ÔºâÔºå‰ºöÂºïÂÖ•ÈîôËØØÁöÑÊï∞ÂÄºËøêÁÆóÂÖ≥Á≥ªÔºåÂ¶Ç ‚ÄúÁæéÂõΩ + ‰∏≠ÂõΩ = Âç∞Â∫¶‚Äù„ÄÇ\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003c/ol\u003e\n\u003ch2 id=\"‰∫åone-hotÁºñÁ†ÅÁöÑÂä®Êú∫‰∏éÊµÅÁ®ã\"\u003e‰∫å„ÄÅOne-HotÁºñÁ†ÅÁöÑÂä®Êú∫‰∏éÊµÅÁ®ã\u003c/h2\u003e\n\u003col\u003e\n\u003cli\u003e\n\u003cp\u003e\u003cstrong\u003e‰∏∫‰ªÄ‰πà‰ΩøÁî®One-Hot\u003c/strong\u003e\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eÈÄöËøáÂ∞ÜÁ±ªÂà´Êò†Â∞Ñ‰∏∫ÂêëÈáèÔºåÈÅøÂÖçÊï¥Êï∞ÁºñÁ†ÅÂºïÂÖ•ÁöÑ‰º™Êï∞ÂÄºÂÖ≥Á≥ª„ÄÇ\u003c/li\u003e\n\u003cli\u003eÂêåÊó∂‰øùÁïôÂêÑÁßçÂèØËÉΩÁ±ªÂà´ÁöÑ‰ø°ÊÅØÔºå‰∏î‰ªÖÂú®ÂØπÂ∫î‰ΩçÁΩÆ‰∏∫1ÔºåÂÖ∂‰ªñ‰ΩçÁΩÆ‰∏∫0„ÄÇ\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003e\u003cstrong\u003eÂª∫Á´ãÊò†Â∞ÑÔºö‰ªéÁ±ªÂà´Âà∞Á¥¢Âºï\u003c/strong\u003e\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e‰∏∫ÊØè‰∏™Á±ªÂà´ÂàÜÈÖç‰∏Ä‰∏™ÂîØ‰∏ÄÁ¥¢ÂºïÔºåÈÄöÂ∏∏‰ªé1ÂºÄÂßã„ÄÇ\u003c/li\u003e\n\u003cli\u003eÈ¢ÑÁïôÁ¥¢Âºï0Ë°®Á§∫‚ÄúÊú™Áü•‚ÄùÊàñ‚ÄúÁº∫Â§±‚ÄùÔºåÂØπÂ∫îÂÖ®0ÂêëÈáè„ÄÇ\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003e\u003cstrong\u003eËΩ¨Êç¢‰∏∫One-HotÂêëÈáè\u003c/strong\u003e\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eËã•Á±ªÂà´ÊÄªÊï∞‰∏∫197ÔºåÂàôÁî®197Áª¥ÂêëÈáèË°®Á§∫„ÄÇ\u003c/li\u003e\n\u003cli\u003e‰æãÂ≠êÔºöÁæéÂõΩ \u003ccode\u003e[1, 0, 0, 0, ‚Ä¶]\u003c/code\u003eÔºå ‰∏≠ÂõΩ \u003ccode\u003e[0, 1, 0, 0, ‚Ä¶]\u003c/code\u003e„ÄÇ\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003e\u003cstrong\u003eÁ§∫‰æãÔºöË°®Á§∫‰∏Ä‰∏™‰∫∫ÁöÑÁâπÂæÅ\u003c/strong\u003e\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eÁâπÂæÅÂåÖÂê´ÔºàÂπ¥ÈæÑ, ÊÄßÂà´, ÂõΩÁ±çÔºåÂÖ∂‰∏≠ÂõΩÁ±ç197ÁßçÔºâ\u003c/li\u003e\n\u003cli\u003eÁª¥Â∫¶ÊÄªÂíåÔºö1Áª¥_age + 1Áª¥_gender + 197Áª¥_nationality = 199Áª¥„ÄÇ\u003c/li\u003e\n\u003cli\u003e‰æãÂ¶Ç \u003ccode\u003e(28, Â•≥, ‰∏≠ÂõΩ)\u003c/code\u003e ‚Üí \u003ccode\u003e[28, 0, 0, 1, 0, ‚Ä¶, 0]\u003c/code\u003e„ÄÇ\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003c/ol\u003e\n\u003ch2 id=\"‰∏âÊñáÊú¨Êï∞ÊçÆÂ§ÑÁêÜÊµÅÁ®ã\"\u003e‰∏â„ÄÅÊñáÊú¨Êï∞ÊçÆÂ§ÑÁêÜÊµÅÁ®ã\u003c/h2\u003e\n\u003cp\u003eÊñáÊú¨Âú®Ëá™ÁÑ∂ËØ≠Ë®ÄÂ§ÑÁêÜÔºàNLPÔºâ‰∏≠‰Ωú‰∏∫Â∏∏ËßÅÁöÑÂéüÂßãËæìÂÖ•ÔºåÈúÄË¶ÅÊï∞ÂÄºÂåñÊâçËÉΩÈÄÅÂÖ•Ê®°Âûã„ÄÇ‰∏ÄËà¨Ê≠•È™§Â¶Ç‰∏ãÔºö\u003c/p\u003e\n\u003col\u003e\n\u003cli\u003e\n\u003cp\u003e\u003cstrong\u003eÂàÜËØç (Tokenization)\u003c/strong\u003e\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eÂ∞ÜÊñáÊú¨ÊãÜÂàÜ‰∏∫‰∏Ä‰∏™‰∏™ÂçïËØçÔºàTokenÔºâ„ÄÇ\u003c/li\u003e\n\u003cli\u003e‰æãÂ≠êÔºö\u003ccode\u003e\u0026quot;... to be or not to be...\u0026quot;\u003c/code\u003e ‚Üí \u003ccode\u003e[\u0026quot;...\u0026quot;, \u0026quot;to\u0026quot;, \u0026quot;be\u0026quot;, \u0026quot;or\u0026quot;, \u0026quot;not\u0026quot;, \u0026quot;to\u0026quot;, \u0026quot;be\u0026quot;, \u0026quot;...\u0026quot;]\u003c/code\u003e„ÄÇ\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003e\u003cstrong\u003eÁªüËÆ°ËØçÈ¢ë \u0026amp; ÊûÑÂª∫ËØçÂÖ∏\u003c/strong\u003e\u003c/p\u003e","title":""},{"content":"Text to Sequence ÊñáÊú¨Â§ÑÁêÜ\nStep1: Tokenization\nTokenization breaks a piece of text down into a list of tokens.\nHere, a token is a word. (A token can be a character in some applications.)\nTokenizationËÆ≤Á©∂ÂæàÂ§öÔºå‰æãÂ¶ÇÊòØÂê¶Â∫îËØ•ÊääÂ§ßÂÜôÊîπÊàêÂ∞èÂÜôÂë¢ÔºüËøõË°åtypo correctionÁ≠âÁ≠â\nStep2: Build Dictionary\nUse a dictionary (hash table) to count word frequencies.\nThe dictionary maps word to index.\nÂèØ‰ª•È¶ñÂÖàÁªüËÆ°ËØçÈ¢ëÂéªÊéâ‰ΩéÈ¢ëËØçÔºåÁÑ∂ÂêéËÆ©ÊØè‰∏™ËØçÂØπÂ∫î‰∏Ä‰∏™Ê≠£Êï¥Êï∞ÔºõËøôÊ†∑ÁöÑËØùÔºå‰∏ÄÂè•ËØùÂ∞±ÂèØ‰ª•Áî®‰∏Ä‰∏™Ê≠£Êï¥Êï∞ÂàóË°®Ë°®Á§∫ÔºåËøô‰∏™ÂàóË°®Â∞±Âè´sequenceÔºõÂ¶ÇÊûúÂøÖË¶ÅÂ∞±ËøòÂæóÂÅöone-hot encoding„ÄÇ\nÁªìÊûú\n‰ΩÜÊòØÈïøÂ∫¶‰∏çÁªü‰∏Ä\nStep4: ÂØπÈΩêsequence\nËß£ÂÜ≥ÊñπÊ°àÊòØËøôÊ†∑ÁöÑÔºöÂèØ‰ª•Âõ∫ÂÆöÈïøÂ∫¶‰∏∫wÔºåÂä†ÂÖ•‰∏Ä‰∏™Â∫èÂàóÈïøÂ∫¶Â§™ÈïøÔºåÂ∞±Á†çÊéâÂâçÈù¢ÁöÑËØçÔºåÂè™‰øùÁïôÊúÄÂêéw‰∏™ËØçÔºõÂ¶ÇÊûú‰∏Ä‰∏™Â∫èÂàóÂ§™Áü≠ÔºåÂ∞±ÂÅözero paddingÔºåÁî®0Â°´ÂÖÖ\nËøôÊ†∑‰∏ÄÊù•ÔºåÊâÄÊúâÁöÑÂ∫èÂàóÈïøÂ∫¶Â∞±Áªü‰∏Ä‰∫Ü\nÊñáÊú¨Â§ÑÁêÜÂÆåÊàê‰∫ÜÔºåÊé•‰∏ãÊù•ÊòØword embeddingÔºåÊääÂçïËØçË°®Á§∫‰∏∫‰∏Ä‰∏™‰ΩéÁª¥ÂêëÈáèÔºõ\nÁÑ∂ËÄåËøôÊ†∑ÂÅöÁöÑËØùÔºåÂ¶ÇÊûúÊòØ10000‰∏™ÂçïËØçÔºåÁª¥Â∫¶Â∞±ÊòØ10000Áª¥ÔºåÁª¥Â∫¶Â§™È´ò‰∫ÜÔºõÂõ†Ê≠§Ë¶ÅÂÅöword embeddingÔºõ\nÂÖ∑‰ΩìÂÅöÊ≥ïÂ∞±ÊòØÊääone-hotÂêëÈáèe_iÂíåÂèÇÊï∞Áü©ÈòµpÁõ∏‰πòÔºõÁü©ÈòµPËΩ¨ÁΩÆÁöÑÂ§ßÂ∞èÊòØd x vÔºõdÊòØËØçÂêëÈáèÁöÑÁª¥Â∫¶ÔºõvÊòØÂ≠óÂÖ∏ÈáåËØçÊ±áÁöÑÊï∞ÈáèÔºõÁªìÊûú‰∏∫x_iÔºõx_iÂ∞±ÊòØ‰∏Ä‰∏™ËØçÂêëÈáèÔºõÂ¶ÇÊûúone-hotÂêëÈáèÁöÑÁ¨¨‰∏âË°å‰∏∫1ÔºõÈÇ£‰πàx_iÂ∞±ÊòØPËΩ¨ÁΩÆÁü©ÈòµÁöÑÁ¨¨‰∏âÂàóÔºàÂÖ∂‰ΩôÂàóÈÉΩ‰∏∫0ÔºâÔºõÊâÄ‰ª•PËΩ¨ÁΩÆÊØè‰∏ÄÂàóÈÉΩÊòØ‰∏Ä‰∏™ËØçÂêëÈáèÔºõÊâÄ‰ª•Áü©ÈòµPÊú¨Ë∫´ÁöÑÊØè‰∏ÄË°åÂ∞±ÊòØ‰∏Ä‰∏™ËØçÂêëÈáèÔºõÂÖ∂Ë°åÊï∞‰∏∫vÔºõÂç≥vocabularyÔºåËØçÊ±áÈáèÔºõÊØè‰∏ÄË°åÂØπÂ∫î‰∏Ä‰∏™ÂçïËØçÔºõÁü©ÈòµÁöÑÂàóÊï∞‰∏∫dÔºõdÊòØÁî®Êà∑ÂÜ≥ÂÆöÁöÑÔºõdÁöÑÂ§ßÂ∞è‰ºöÂÜ≥ÂÆöÊú∫Âô®Â≠¶‰π†Ê®°ÂûãÁöÑË°®Áé∞ÔºõÂ∫îËØ•Áî®xxxÊù•ÈÄâÊã©‰∏Ä‰∏™ÊØîËæÉÂ•ΩÁöÑdÔºõ\nÊàë‰ª¨ÁöÑ‰ªªÂä°ÊòØÁúãËØÑËÆ∫ÊòØÊ≠£Èù¢ÁöÑËøòÊòØË¥üÈù¢ÁöÑÔºõÂèÇÊï∞Áü©ÈòµÊòØ‰ªéËÆ≠ÁªÉÊï∞ÊçÆ‰∏≠Â≠¶‰π†Âá∫Êù•ÁöÑÔºåÊâÄ‰ª•Â≠¶Âá∫Êù•ÁöÑËØçÂêëÈáèÊòØÂ∏¶ÊúâÊÑüÊÉÖËâ≤ÂΩ©ÁöÑÔºõÂÅáËÆæËøô‰∫õËØçÂêëÈáèÈÉΩÊòØ‰∫åÁª¥ÁöÑÔºåÂàôÂèØ‰ª•Âú®Âπ≥Èù¢ÂùêÊ†áÁ≥ª‰∏≠Ê†áÂá∫‰∏ãÈù¢ËØçÂêëÈáè\nkerasÊèê‰æõembeddingÂ±ÇÔºõÁî®Êà∑ÂèØ‰ª•ÊåáÂÆövocabularyÂ§ßÂ∞èÂíådÁöÑÂ§ßÂ∞èÔºõ‰ª•ÂèäÊØè‰∏Ä‰∏™sequenceÁöÑÈïøÂ∫¶ÔºõdÊòØÊ†πÊçÆÁÆóÊ≥ïÈÄâÂá∫Êù•ÁöÑ Âà∞Ëøô‰∏ÄÊ≠•ÔºåÊàë‰ª¨Â∑≤ÁªèÂÆåÊàê‰∫ÜÊñáÊú¨Â§ÑÁêÜÂíåword embedding„ÄÇÊé•‰∏ãÊù•Â∞±ÊòØÁî®Logistic Regression for Binary ClassificationÂÅö‰∫åÂàÜÁ±ªÔºõ\n","permalink":"http://localhost:1313/posts/nlp-2/","summary":"\u003ch3 id=\"text-to-sequence\"\u003eText to Sequence\u003c/h3\u003e\n\u003cp\u003eÊñáÊú¨Â§ÑÁêÜ\u003c/p\u003e\n\u003cp\u003eStep1: Tokenization\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\n\u003cp\u003eTokenization breaks a piece of text down into a list of tokens.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003eHere, a token is a word. (A token can be a character in some applications.)\u003c/p\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003eTokenizationËÆ≤Á©∂ÂæàÂ§öÔºå‰æãÂ¶ÇÊòØÂê¶Â∫îËØ•ÊääÂ§ßÂÜôÊîπÊàêÂ∞èÂÜôÂë¢ÔºüËøõË°åtypo correctionÁ≠âÁ≠â\u003c/p\u003e\n\u003cp\u003e\u003cimg alt=\"image-20250322150322238\" loading=\"lazy\" src=\"./NLP-2.assets/image-20250322150322238.png\"\u003e\u003c/p\u003e\n\u003cp\u003eStep2: Build Dictionary\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\n\u003cp\u003eUse a dictionary (hash table) to count word frequencies.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003eThe dictionary maps word to index.\u003c/p\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003eÂèØ‰ª•È¶ñÂÖàÁªüËÆ°ËØçÈ¢ëÂéªÊéâ‰ΩéÈ¢ëËØçÔºåÁÑ∂ÂêéËÆ©ÊØè‰∏™ËØçÂØπÂ∫î‰∏Ä‰∏™Ê≠£Êï¥Êï∞ÔºõËøôÊ†∑ÁöÑËØùÔºå‰∏ÄÂè•ËØùÂ∞±ÂèØ‰ª•Áî®‰∏Ä‰∏™Ê≠£Êï¥Êï∞ÂàóË°®Ë°®Á§∫ÔºåËøô‰∏™ÂàóË°®Â∞±Âè´sequenceÔºõÂ¶ÇÊûúÂøÖË¶ÅÂ∞±ËøòÂæóÂÅöone-hot encoding„ÄÇ\u003cimg alt=\"image-20250322150620890\" loading=\"lazy\" src=\"./NLP-2.assets/image-20250322150620890.png\"\u003e\u003c/p\u003e\n\u003cp\u003eÁªìÊûú\u003c/p\u003e\n\u003cp\u003e\u003cimg alt=\"image-20250322150754528\" loading=\"lazy\" src=\"./NLP-2.assets/image-20250322150754528.png\"\u003e\u003c/p\u003e\n\u003cp\u003e‰ΩÜÊòØÈïøÂ∫¶‰∏çÁªü‰∏Ä\u003c/p\u003e\n\u003cp\u003eStep4: ÂØπÈΩêsequence\u003c/p\u003e\n\u003cp\u003e\u003cimg alt=\"image-20250322150854986\" loading=\"lazy\" src=\"./NLP-2.assets/image-20250322150854986.png\"\u003e\u003c/p\u003e\n\u003cp\u003eËß£ÂÜ≥ÊñπÊ°àÊòØËøôÊ†∑ÁöÑÔºöÂèØ‰ª•Âõ∫ÂÆöÈïøÂ∫¶‰∏∫wÔºåÂä†ÂÖ•‰∏Ä‰∏™Â∫èÂàóÈïøÂ∫¶Â§™ÈïøÔºåÂ∞±Á†çÊéâÂâçÈù¢ÁöÑËØçÔºåÂè™‰øùÁïôÊúÄÂêéw‰∏™ËØçÔºõÂ¶ÇÊûú‰∏Ä‰∏™Â∫èÂàóÂ§™Áü≠ÔºåÂ∞±ÂÅözero paddingÔºåÁî®0Â°´ÂÖÖ\u003c/p\u003e\n\u003cp\u003e\u003cimg alt=\"image-20250322151030119\" loading=\"lazy\" src=\"./NLP-2.assets/image-20250322151030119.png\"\u003e\u003c/p\u003e\n\u003cp\u003eËøôÊ†∑‰∏ÄÊù•ÔºåÊâÄÊúâÁöÑÂ∫èÂàóÈïøÂ∫¶Â∞±Áªü‰∏Ä‰∫Ü\u003c/p\u003e\n\u003cp\u003e\u003cimg alt=\"image-20250322151117125\" loading=\"lazy\" src=\"./NLP-2.assets/image-20250322151117125.png\"\u003e\u003c/p\u003e\n\u003cp\u003eÊñáÊú¨Â§ÑÁêÜÂÆåÊàê‰∫ÜÔºåÊé•‰∏ãÊù•ÊòØword embeddingÔºåÊääÂçïËØçË°®Á§∫‰∏∫‰∏Ä‰∏™‰ΩéÁª¥ÂêëÈáèÔºõ\u003c/p\u003e\n\u003cp\u003e\u003cimg alt=\"image-20250322151252837\" loading=\"lazy\" src=\"./NLP-2.assets/image-20250322151252837.png\"\u003e\u003c/p\u003e","title":""},{"content":"üëã About me Recently, inspired by OpenAI\u0026rsquo;s five-step plan towards superintelligence, I have great expectations for AGI and developed a strong interest in LLM agents, MLLM, reinforcement learning, and knowledge graphs. I believe there is significant potential in these fields to create innovative solutions, and I hope to contribute my efforts towards that goal.\nüìö Education üá≠üá∞ The University of Hong Kong 09/2024 - Expected 11/2025 School of Computing and Data Science Master of Science in Electronic Commerce \u0026amp; Internet Computing Relevant Courses: Machine learning for business and e-commerce, Knowledge graphs, Financial fraud analytics, Internet infrastructure technologies, Website engineering, Blockchain and cryptocurrency, etc. üá®üá≥ Beijing Institute of Technology 09/2020 - 06/2024 School of Computer Science \u0026amp; Technology Bachelor of Engineering in Software Engineering, last two years GPA: 3.7/4 Relevant Courses: Reinforcement Learning, Deep Learning and Computer Vision, Artificial Intelligence and Robot Ethics, Almost Human: Mind, Brain and Artificial Intelligence, Mathematical Analysis for Engineering, Linear Algebra, Probability and Mathematical Statistics, etc. Skills: Python, Java, common data structures, design patterns, machine learning basics and algorithms, Linux, PyTorch, and some development tools (git, conda, etc.). üèÜ Awards \u0026amp; Honors Beijing Institute of Technology Undergraduate Scholarship (Top 20% of Grade) 06/2023 3rd Prize of China International \u0026#34;Internet \u0026#43;\u0026#34; College Student\u0026#39;s Innovation Competition 08/2022 Bronze Prize of \u0026#34;Challenge Cup\u0026#34; Capital University Entrepreneurship Competition 05/2022 üíº Project Experience Online Transaction Fraud Detection 09/2024 ‚Äì 01/2025 Independent project, supervised by Dr. Vivien Chan Focused on addressing financial fraud in e-commerce to enhance the accuracy of transaction anomaly detection, while independently managing the entire case study that included data preprocessing, feature engineering, model building, evaluation, and results analysis. Effectively resolved class imbalance issues using SMOTE and ROSE techniques. Built various models including Logistic Regression, Random Forest, XGBoost, and LightGBM, ultimately selecting the LightGBM model to achieve a recall rate of 95.45% and an AUC of 99.84%. Wrote efficient and maintainable code, enhancing model training and data processing efficiency through parallel computing and logging. Multi-Model Intelligent Text Keyword Extraction System 08/2023 ‚Äì 09/2023 Group project, supervised by Associate Prof. Xiaolin Zhao Designed and implemented an intelligent text summary system that automatically extracts keywords from article titles and abstracts, enhancing the understanding and summarization of text information. Participated in the planning of the technical route and built a hybrid model combining extractive and generative approaches, utilizing advanced natural language processing techniques including KeyBERT, Sentence Transformer, BERT, and T5 models. Responsible for data preprocessing and tokenization, as well as the end-to-end implementation and training of the T5 model, optimizing the model architecture and hyperparameters, achieving satisfactory results after only 3 epochs of training. Model evaluation results showed that the Rouge-1, Rouge-2, and Rouge-L metrics reached 0.6345, 0.5038, and 0.5282, respectively, in the third epoch, validating the model\u0026rsquo;s effectiveness in the summarization task. Cambridge University Machine Learning Summer Project 07/2023 ‚Äì 08/2023 Group project, supervised by Prof. Pietro Li√≤ Participated in the Cambridge University deep learning summer project, focusing on deep reinforcement learning; explored multi-agent learning algorithms across different environments. Reproduced the Multi-Agent Deep Deterministic Policy Gradient (MADDPG) algorithm in the Simple Adversary environment and studied the effect of agent numbers on convergence speed and stability, finding optimal stability at 21 agents. Designed and implemented comparative experiments inspired by the Rainbow algorithm, assessing target network strategies versus the Double Deep Q-Network (Double DQN). The results demonstrated that Double DQN significantly enhanced convergence speed, optimizing the overall learning process. Co-authored a group project paper on agent numbers and strategies effectiveness in multi-agent systems, achieving a score of 71% in the summer program (the highest in my group) and a \u0026ldquo;First Class\u0026rdquo; classification in the UK grading system. Deep Learning and Computer Vision Semester Project 09/2022 ‚Äì 12/2022 Independent project, supervised by Associate Prof. Guangyu Gao Designed and implemented a waste classifier using the ResNet model to improve classification accuracy and reduce resource waste. The project also enhanced understanding of transfer learning techniques with ResNet. Collected a dataset of 16 waste categories and preprocessed the images for uniformity and standardization, incorporating data augmentation techniques to enhance the dataset. Conducted experiments using ResNet34 and ResNet50 models through transfer learning, accelerating network convergence by leveraging pretrained weights. During training, techniques such as Batch Normalization and Dropout were applied to mitigate the risk of overfitting. The final model achieved an accuracy of 90% on the training set, while the performance on the test set was 61%, indicating a significant overfitting phenomenon during the training process. üéì Internship Beijing Academy of Quantum Information Science 08/2023 ‚Äì 01/2024 Research Intern at Quantum Computation Department Proposed a quantum convolution kernel design based on variational quantum circuits and developed a universal quantum convolution layer, successfully integrating it into classical CNN architectures such as VGG, GoogLeNet, and ResNet. Developed and evaluated various hybrid models, including a simple model named HQCCNN-2, which achieved 84.45% accuracy on the FashionMNIST dataset, surpassing the traditional CNN\u0026rsquo;s 80.72%. This demonstrates the effectiveness of the quantum convolution layer in improving model performance. Tested on a real quantum computer further validated the effectiveness of the hybrid model, demonstrating the viable integration of quantum computing with deep learning, and highlighting the potential for leveraging quantum properties to enhance model performance. üèÖ Competition Experience China International \u0026#34;Internet \u0026#43;\u0026#34; College Students\u0026#39; Innovation Competition 08/2022 Zhongke Ushield: Deep Learning-based Face Privacy Protection Authentication System Responsible for constructing a localized facial feature extraction engine based on MobileFaceNet, ensuring feature extraction is completed on end devices (such as mobile phones and cameras), guaranteeing that raw data does not leave the domain and is not stored, thus enhancing user privacy protection while improving recognition efficiency. \u0026#34;Challenge Cup\u0026#34; Capital University Entrepreneurship Competition 05/2022 Smart Orchard Responsible for the development of the fruit detection, ripeness prediction, and pest identification system, using deep convolutional neural network (CNN) technology for intelligent monitoring of crop growth conditions. Applied advanced object detection algorithms such as Faster R-CNN and YOLO to achieve high precision in apple detection and ripeness assessment, with an accuracy rate exceeding 90%, significantly enhancing the intelligence level of orchard management. Built and trained a dedicated dataset containing various pest samples, optimizing pest detection accuracy through data preprocessing (such as image normalization and resizing) and data augmentation techniques (like rotation, flipping, and noise addition), enabling the real-time monitoring system to accurately identify over 80% of pests, providing effective scientific maintenance recommendations to help farmers reduce crop losses. üìã Extracurricular Activities Vice President, Cyber Security Club, Beijing Institute of Technology 09/2021-09/2022 Backbone, Media Center of the Student Union of Beijing Institute of Technology 10/2020-06/2021 üì´ Contact üìß zongsi.xu@outlook.com üëî Zongsi (Tristan) Xu üíª github.com/BaizeXS üìç Hong Kong SAR, China ","permalink":"http://localhost:1313/resume/","summary":"Personal resume of Zongsi (Tristan) Xu","title":"Zongsi (Tristan) Xu"},{"content":"‰∏Ä„ÄÅÊï∞ÂÄºÁâπÂæÅ‰∏éÁ±ªÂà´ÁâπÂæÅ Êï∞ÂÄºÁâπÂæÅ (Numeric Features) ÂÖ∑ÊúâÂèØÂä†ÂáèÁöÑÊÑè‰πâÔºå‰∏îÂ≠òÂú®Â§ßÂ∞èÈ°∫Â∫è„ÄÇ ‰æãÂ≠êÔºöÂπ¥ÈæÑ„ÄÅÊ∏©Â∫¶Á≠â„ÄÇÂèØ‰ª•Áõ¥Êé•‰øùÁïôÂÖ∂Êï¥Êï∞ÊàñÊµÆÁÇπÊï∞ÂΩ¢Âºè‰æõÊ®°Âûã‰ΩøÁî®„ÄÇ Á±ªÂà´ÁâπÂæÅ (Categorical Features) Êï∞ÊçÆÂÄºÁ¶ªÊï£Ôºå‰∏çÂÖ∑Â§á‚ÄúÊï∞ÂÄºÂ§ßÂ∞è‚ÄùÈó¥ÁöÑÂèØÊØîÊÑè‰πâ„ÄÇ ‰æãÂ≠êÔºöÂõΩÁ±çÔºàÁæéÂõΩ/‰∏≠ÂõΩ/Âç∞Â∫¶Á≠âÔºâ„ÄÅÊÄßÂà´ÔºàÁî∑/Â•≥ÔºâÁ≠â„ÄÇ ÈóÆÈ¢òÔºöËã•‰ªÖÁî®Êï¥Êï∞Ë°®Á§∫ÔºàÁæéÂõΩ=1, ‰∏≠ÂõΩ=2ÔºâÔºå‰ºöÂºïÂÖ•ÈîôËØØÁöÑÊï∞ÂÄºËøêÁÆóÂÖ≥Á≥ªÔºåÂ¶Ç ‚ÄúÁæéÂõΩ + ‰∏≠ÂõΩ = Âç∞Â∫¶‚Äù„ÄÇ ‰∫å„ÄÅOne-HotÁºñÁ†ÅÁöÑÂä®Êú∫‰∏éÊµÅÁ®ã ‰∏∫‰ªÄ‰πà‰ΩøÁî®One-Hot\nÈÄöËøáÂ∞ÜÁ±ªÂà´Êò†Â∞Ñ‰∏∫ÂêëÈáèÔºåÈÅøÂÖçÊï¥Êï∞ÁºñÁ†ÅÂºïÂÖ•ÁöÑ‰º™Êï∞ÂÄºÂÖ≥Á≥ª„ÄÇ ÂêåÊó∂‰øùÁïôÂêÑÁßçÂèØËÉΩÁ±ªÂà´ÁöÑ‰ø°ÊÅØÔºå‰∏î‰ªÖÂú®ÂØπÂ∫î‰ΩçÁΩÆ‰∏∫1ÔºåÂÖ∂‰ªñ‰ΩçÁΩÆ‰∏∫0„ÄÇ Âª∫Á´ãÊò†Â∞ÑÔºö‰ªéÁ±ªÂà´Âà∞Á¥¢Âºï\n‰∏∫ÊØè‰∏™Á±ªÂà´ÂàÜÈÖç‰∏Ä‰∏™ÂîØ‰∏ÄÁ¥¢ÂºïÔºåÈÄöÂ∏∏‰ªé1ÂºÄÂßã„ÄÇ È¢ÑÁïôÁ¥¢Âºï0Ë°®Á§∫‚ÄúÊú™Áü•‚ÄùÊàñ‚ÄúÁº∫Â§±‚ÄùÔºåÂØπÂ∫îÂÖ®0ÂêëÈáè„ÄÇ ËΩ¨Êç¢‰∏∫One-HotÂêëÈáè\nËã•Á±ªÂà´ÊÄªÊï∞‰∏∫197ÔºåÂàôÁî®197Áª¥ÂêëÈáèË°®Á§∫„ÄÇ ‰æãÂ≠êÔºöÁæéÂõΩ [1, 0, 0, 0, ‚Ä¶]Ôºå ‰∏≠ÂõΩ [0, 1, 0, 0, ‚Ä¶]„ÄÇ Á§∫‰æãÔºöË°®Á§∫‰∏Ä‰∏™‰∫∫ÁöÑÁâπÂæÅ\nÁâπÂæÅÂåÖÂê´ÔºàÂπ¥ÈæÑ, ÊÄßÂà´, ÂõΩÁ±çÔºåÂÖ∂‰∏≠ÂõΩÁ±ç197ÁßçÔºâ Áª¥Â∫¶ÊÄªÂíåÔºö1Áª¥_age + 1Áª¥_gender + 197Áª¥_nationality = 199Áª¥„ÄÇ ‰æãÂ¶Ç (28, Â•≥, ‰∏≠ÂõΩ) ‚Üí [28, 0, 0, 1, 0, ‚Ä¶, 0]„ÄÇ ‰∏â„ÄÅÊñáÊú¨Êï∞ÊçÆÂ§ÑÁêÜÊµÅÁ®ã ÊñáÊú¨Âú®Ëá™ÁÑ∂ËØ≠Ë®ÄÂ§ÑÁêÜÔºàNLPÔºâ‰∏≠‰Ωú‰∏∫Â∏∏ËßÅÁöÑÂéüÂßãËæìÂÖ•ÔºåÈúÄË¶ÅÊï∞ÂÄºÂåñÊâçËÉΩÈÄÅÂÖ•Ê®°Âûã„ÄÇ‰∏ÄËà¨Ê≠•È™§Â¶Ç‰∏ãÔºö\nÂàÜËØç (Tokenization)\nÂ∞ÜÊñáÊú¨ÊãÜÂàÜ‰∏∫‰∏Ä‰∏™‰∏™ÂçïËØçÔºàTokenÔºâ„ÄÇ ‰æãÂ≠êÔºö\u0026quot;... to be or not to be...\u0026quot; ‚Üí [\u0026quot;...\u0026quot;, \u0026quot;to\u0026quot;, \u0026quot;be\u0026quot;, \u0026quot;or\u0026quot;, \u0026quot;not\u0026quot;, \u0026quot;to\u0026quot;, \u0026quot;be\u0026quot;, \u0026quot;...\u0026quot;]„ÄÇ ÁªüËÆ°ËØçÈ¢ë \u0026amp; ÊûÑÂª∫ËØçÂÖ∏\nËØçÈ¢ëÁªüËÆ° Áî®ÂìàÂ∏åË°®/Â≠óÂÖ∏ËÆ∞ÂΩïÊØè‰∏™ÂçïËØçÂá∫Áé∞Ê¨°Êï∞„ÄÇ ÈÅçÂéÜÊñáÊú¨Êó∂ÔºåËã•ÂçïËØçÂ∞öÊú™ÂÖ•Ë°®ÔºåÂàôÊñ∞Âª∫ËÆ∞ÂΩïÔºõËã•Â∑≤Â≠òÂú®ÔºåÂàôËÆ°Êï∞+1„ÄÇ ÊéíÂ∫è‰∏éÁ¥¢Âºï ÊåâËØçÈ¢ëÈôçÂ∫èÊéíÂ∫èÔºåËØçÈ¢ëÊúÄÈ´òÁöÑÂçïËØçÊéíÂú®ÂâçÈù¢„ÄÇ Á¥¢Âºï‰ªé1ÂºÄÂßãÔºå0ÁïôÁªô‚ÄúÊú™Áü•‚Äù„ÄÇ ËØçÂÖ∏ËßÑÊ®°ÔºàvocabularyÔºâÂèØËßÜÈúÄÊ±ÇÊà™Êñ≠Ôºà‰æãÂ¶ÇÂè™‰øùÁïôTop 10kÔºâ„ÄÇ ‰∏∫‰ªÄ‰πàÁßªÈô§‰ΩéÈ¢ëËØç ‰ΩéÈ¢ëËØçÂèØËÉΩÊòØÊãºÂÜôÈîôËØØ„ÄÅÁΩïËßÅ‰∫∫ÂêçÁ≠âÔºåÂØπÊ®°ÂûãÂ∏ÆÂä©ÊúâÈôê„ÄÇ ÂáèÂ∞ëËØçÂÖ∏ËßÑÊ®°ÂèØÈôç‰ΩéËøêÁÆóÂºÄÈîÄ„ÄÅÂä†Âø´Ê®°ÂûãËÆ≠ÁªÉ‰∏éÊé®ÁêÜÈÄüÂ∫¶„ÄÇ Áã¨ÁÉ≠ÁºñÁ†Å (One-Hot Encoding)\nÂ∞ÜÊØè‰∏™ÂçïËØçÊò†Â∞Ñ‰∏∫ËØçÂÖ∏‰∏≠ÁöÑÁ¥¢ÂºïÂêéÔºàÂ¶Ç [2, 4, 1, 8, ‚Ä¶]ÔºâÔºåÂèØËøõ‰∏ÄÊ≠•ËΩ¨Êç¢ÊàêOne-HotÂêëÈáè„ÄÇ One-HotÁª¥Â∫¶ÂèñÂÜ≥‰∫é‰øùÁïô‰∏ãÊù•ÁöÑËØçÂÖ∏Â§ßÂ∞èÔºà‰æãÂ¶Ç1‰∏áÔºâ„ÄÇ Êú™Êî∂ÂΩïÂçïËØçÂèØËÉΩÁõ¥Êé•ÂøΩÁï•ÔºåÊàñÁªü‰∏ÄÁî®Á¥¢Âºï0‰ª£Êõø„ÄÇ Âõõ„ÄÅÊ†∏ÂøÉÊî∂Ëé∑‰∏éÂ∫îÁî® Á±ªÂà´ÁâπÂæÅÂøÖÈúÄÊï∞ÂÄºÂåñÔºö\n‰ΩøÁî®Êï¥Êï∞1,2,3‚Ä¶‰ªÖË°®Á§∫Á±ªÂà´‚ÄúÊ†áËØÜ‚ÄùÔºåÂπ∂‰∏ç‰ª£Ë°®ÂÆÉ‰ª¨ÂèØËøõË°åÊï∞ÂÄºËøêÁÆó„ÄÇ Âõ†Ê≠§ÈúÄË¶ÅOne-HotÁ≠âÁºñÁ†ÅÊñπÂºèÔºåÈÅøÂÖçÊï∞ÂÄºËØØËß£„ÄÇ ÊñáÊú¨Êï∞ÊçÆÈ¢ÑÂ§ÑÁêÜÔºö\nÂàÜËØç„ÄÅËØçÈ¢ëÁªüËÆ°„ÄÅÊûÑÂª∫ËØçÂÖ∏„ÄÅÁ¥¢ÂºïÂåñ„ÄÅOne-HotÊàñÂÖ∂‰ªñÊñπÂºèÔºàÂ¶ÇËØçÂµåÂÖ•ÔºâÊòØÂ∏∏ËßÅÊµÅÁ®ã„ÄÇ Ê≠£Á°ÆÁöÑÊñáÊú¨È¢ÑÂ§ÑÁêÜÂèØÊòæËëóÂΩ±ÂìçÊ®°ÂûãÊÄßËÉΩÂíåÊïàÁéá„ÄÇ ‰øùÁïôÊú™Áü•Á¥¢ÂºïÔºö\n‰øùËØÅÂØπÁº∫Â§±Êï∞ÊçÆÊàñÂ≠óÂÖ∏Â§ñÊñ∞ËØçËÉΩÊúâÂü∫Êú¨ÁöÑË°®Á§∫ÔºåÊèêÂçáÊ®°ÂûãÂÆπÈîôÊÄß„ÄÇ ÂÆûÈôÖ‰ΩøÁî®Ôºö\nÂØπ‰∫éÂ∞èËßÑÊ®°Á±ªÂà´ÂèØÁõ¥Êé•One-HotÁºñÁ†ÅÔºõÂØπ‰∫éËØçÂÖ∏ÂæàÂ§ßÁöÑÂú∫ÊôØÔºåÈÄöÂ∏∏‰ºöËøõ‰∏ÄÊ≠•ËÄÉËôëËØçÂµåÂÖ•ÔºàWord EmbeddingÔºâÊàñÈ¢ÑËÆ≠ÁªÉËØ≠Ë®ÄÊ®°Âûã„ÄÇ ","permalink":"http://localhost:1313/posts/nlp-1/","summary":"\u003ch2 id=\"‰∏ÄÊï∞ÂÄºÁâπÂæÅ‰∏éÁ±ªÂà´ÁâπÂæÅ\"\u003e‰∏Ä„ÄÅÊï∞ÂÄºÁâπÂæÅ‰∏éÁ±ªÂà´ÁâπÂæÅ\u003c/h2\u003e\n\u003col\u003e\n\u003cli\u003e\u003cstrong\u003eÊï∞ÂÄºÁâπÂæÅ (Numeric Features)\u003c/strong\u003e\n\u003cul\u003e\n\u003cli\u003eÂÖ∑ÊúâÂèØÂä†ÂáèÁöÑÊÑè‰πâÔºå‰∏îÂ≠òÂú®Â§ßÂ∞èÈ°∫Â∫è„ÄÇ\u003c/li\u003e\n\u003cli\u003e‰æãÂ≠êÔºöÂπ¥ÈæÑ„ÄÅÊ∏©Â∫¶Á≠â„ÄÇÂèØ‰ª•Áõ¥Êé•‰øùÁïôÂÖ∂Êï¥Êï∞ÊàñÊµÆÁÇπÊï∞ÂΩ¢Âºè‰æõÊ®°Âûã‰ΩøÁî®„ÄÇ\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003eÁ±ªÂà´ÁâπÂæÅ (Categorical Features)\u003c/strong\u003e\n\u003cul\u003e\n\u003cli\u003eÊï∞ÊçÆÂÄºÁ¶ªÊï£Ôºå‰∏çÂÖ∑Â§á‚ÄúÊï∞ÂÄºÂ§ßÂ∞è‚ÄùÈó¥ÁöÑÂèØÊØîÊÑè‰πâ„ÄÇ\u003c/li\u003e\n\u003cli\u003e‰æãÂ≠êÔºöÂõΩÁ±çÔºàÁæéÂõΩ/‰∏≠ÂõΩ/Âç∞Â∫¶Á≠âÔºâ„ÄÅÊÄßÂà´ÔºàÁî∑/Â•≥ÔºâÁ≠â„ÄÇ\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003eÈóÆÈ¢ò\u003c/strong\u003eÔºöËã•‰ªÖÁî®Êï¥Êï∞Ë°®Á§∫ÔºàÁæéÂõΩ=1, ‰∏≠ÂõΩ=2ÔºâÔºå‰ºöÂºïÂÖ•ÈîôËØØÁöÑÊï∞ÂÄºËøêÁÆóÂÖ≥Á≥ªÔºåÂ¶Ç ‚ÄúÁæéÂõΩ + ‰∏≠ÂõΩ = Âç∞Â∫¶‚Äù„ÄÇ\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003c/ol\u003e\n\u003ch2 id=\"‰∫åone-hotÁºñÁ†ÅÁöÑÂä®Êú∫‰∏éÊµÅÁ®ã\"\u003e‰∫å„ÄÅOne-HotÁºñÁ†ÅÁöÑÂä®Êú∫‰∏éÊµÅÁ®ã\u003c/h2\u003e\n\u003col\u003e\n\u003cli\u003e\n\u003cp\u003e\u003cstrong\u003e‰∏∫‰ªÄ‰πà‰ΩøÁî®One-Hot\u003c/strong\u003e\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eÈÄöËøáÂ∞ÜÁ±ªÂà´Êò†Â∞Ñ‰∏∫ÂêëÈáèÔºåÈÅøÂÖçÊï¥Êï∞ÁºñÁ†ÅÂºïÂÖ•ÁöÑ‰º™Êï∞ÂÄºÂÖ≥Á≥ª„ÄÇ\u003c/li\u003e\n\u003cli\u003eÂêåÊó∂‰øùÁïôÂêÑÁßçÂèØËÉΩÁ±ªÂà´ÁöÑ‰ø°ÊÅØÔºå‰∏î‰ªÖÂú®ÂØπÂ∫î‰ΩçÁΩÆ‰∏∫1ÔºåÂÖ∂‰ªñ‰ΩçÁΩÆ‰∏∫0„ÄÇ\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003e\u003cstrong\u003eÂª∫Á´ãÊò†Â∞ÑÔºö‰ªéÁ±ªÂà´Âà∞Á¥¢Âºï\u003c/strong\u003e\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e‰∏∫ÊØè‰∏™Á±ªÂà´ÂàÜÈÖç‰∏Ä‰∏™ÂîØ‰∏ÄÁ¥¢ÂºïÔºåÈÄöÂ∏∏‰ªé1ÂºÄÂßã„ÄÇ\u003c/li\u003e\n\u003cli\u003eÈ¢ÑÁïôÁ¥¢Âºï0Ë°®Á§∫‚ÄúÊú™Áü•‚ÄùÊàñ‚ÄúÁº∫Â§±‚ÄùÔºåÂØπÂ∫îÂÖ®0ÂêëÈáè„ÄÇ\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003e\u003cstrong\u003eËΩ¨Êç¢‰∏∫One-HotÂêëÈáè\u003c/strong\u003e\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eËã•Á±ªÂà´ÊÄªÊï∞‰∏∫197ÔºåÂàôÁî®197Áª¥ÂêëÈáèË°®Á§∫„ÄÇ\u003c/li\u003e\n\u003cli\u003e‰æãÂ≠êÔºöÁæéÂõΩ \u003ccode\u003e[1, 0, 0, 0, ‚Ä¶]\u003c/code\u003eÔºå ‰∏≠ÂõΩ \u003ccode\u003e[0, 1, 0, 0, ‚Ä¶]\u003c/code\u003e„ÄÇ\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003e\u003cstrong\u003eÁ§∫‰æãÔºöË°®Á§∫‰∏Ä‰∏™‰∫∫ÁöÑÁâπÂæÅ\u003c/strong\u003e\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eÁâπÂæÅÂåÖÂê´ÔºàÂπ¥ÈæÑ, ÊÄßÂà´, ÂõΩÁ±çÔºåÂÖ∂‰∏≠ÂõΩÁ±ç197ÁßçÔºâ\u003c/li\u003e\n\u003cli\u003eÁª¥Â∫¶ÊÄªÂíåÔºö1Áª¥_age + 1Áª¥_gender + 197Áª¥_nationality = 199Áª¥„ÄÇ\u003c/li\u003e\n\u003cli\u003e‰æãÂ¶Ç \u003ccode\u003e(28, Â•≥, ‰∏≠ÂõΩ)\u003c/code\u003e ‚Üí \u003ccode\u003e[28, 0, 0, 1, 0, ‚Ä¶, 0]\u003c/code\u003e„ÄÇ\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003c/ol\u003e\n\u003ch2 id=\"‰∏âÊñáÊú¨Êï∞ÊçÆÂ§ÑÁêÜÊµÅÁ®ã\"\u003e‰∏â„ÄÅÊñáÊú¨Êï∞ÊçÆÂ§ÑÁêÜÊµÅÁ®ã\u003c/h2\u003e\n\u003cp\u003eÊñáÊú¨Âú®Ëá™ÁÑ∂ËØ≠Ë®ÄÂ§ÑÁêÜÔºàNLPÔºâ‰∏≠‰Ωú‰∏∫Â∏∏ËßÅÁöÑÂéüÂßãËæìÂÖ•ÔºåÈúÄË¶ÅÊï∞ÂÄºÂåñÊâçËÉΩÈÄÅÂÖ•Ê®°Âûã„ÄÇ‰∏ÄËà¨Ê≠•È™§Â¶Ç‰∏ãÔºö\u003c/p\u003e\n\u003col\u003e\n\u003cli\u003e\n\u003cp\u003e\u003cstrong\u003eÂàÜËØç (Tokenization)\u003c/strong\u003e\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eÂ∞ÜÊñáÊú¨ÊãÜÂàÜ‰∏∫‰∏Ä‰∏™‰∏™ÂçïËØçÔºàTokenÔºâ„ÄÇ\u003c/li\u003e\n\u003cli\u003e‰æãÂ≠êÔºö\u003ccode\u003e\u0026quot;... to be or not to be...\u0026quot;\u003c/code\u003e ‚Üí \u003ccode\u003e[\u0026quot;...\u0026quot;, \u0026quot;to\u0026quot;, \u0026quot;be\u0026quot;, \u0026quot;or\u0026quot;, \u0026quot;not\u0026quot;, \u0026quot;to\u0026quot;, \u0026quot;be\u0026quot;, \u0026quot;...\u0026quot;]\u003c/code\u003e„ÄÇ\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003e\u003cstrong\u003eÁªüËÆ°ËØçÈ¢ë \u0026amp; ÊûÑÂª∫ËØçÂÖ∏\u003c/strong\u003e\u003c/p\u003e","title":""},{"content":"Text to Sequence ÊñáÊú¨Â§ÑÁêÜ\nStep1: Tokenization\nTokenization breaks a piece of text down into a list of tokens.\nHere, a token is a word. (A token can be a character in some applications.)\nTokenizationËÆ≤Á©∂ÂæàÂ§öÔºå‰æãÂ¶ÇÊòØÂê¶Â∫îËØ•ÊääÂ§ßÂÜôÊîπÊàêÂ∞èÂÜôÂë¢ÔºüËøõË°åtypo correctionÁ≠âÁ≠â\nStep2: Build Dictionary\nUse a dictionary (hash table) to count word frequencies.\nThe dictionary maps word to index.\nÂèØ‰ª•È¶ñÂÖàÁªüËÆ°ËØçÈ¢ëÂéªÊéâ‰ΩéÈ¢ëËØçÔºåÁÑ∂ÂêéËÆ©ÊØè‰∏™ËØçÂØπÂ∫î‰∏Ä‰∏™Ê≠£Êï¥Êï∞ÔºõËøôÊ†∑ÁöÑËØùÔºå‰∏ÄÂè•ËØùÂ∞±ÂèØ‰ª•Áî®‰∏Ä‰∏™Ê≠£Êï¥Êï∞ÂàóË°®Ë°®Á§∫ÔºåËøô‰∏™ÂàóË°®Â∞±Âè´sequenceÔºõÂ¶ÇÊûúÂøÖË¶ÅÂ∞±ËøòÂæóÂÅöone-hot encoding„ÄÇ\nÁªìÊûú\n‰ΩÜÊòØÈïøÂ∫¶‰∏çÁªü‰∏Ä\nStep4: ÂØπÈΩêsequence\nËß£ÂÜ≥ÊñπÊ°àÊòØËøôÊ†∑ÁöÑÔºöÂèØ‰ª•Âõ∫ÂÆöÈïøÂ∫¶‰∏∫wÔºåÂä†ÂÖ•‰∏Ä‰∏™Â∫èÂàóÈïøÂ∫¶Â§™ÈïøÔºåÂ∞±Á†çÊéâÂâçÈù¢ÁöÑËØçÔºåÂè™‰øùÁïôÊúÄÂêéw‰∏™ËØçÔºõÂ¶ÇÊûú‰∏Ä‰∏™Â∫èÂàóÂ§™Áü≠ÔºåÂ∞±ÂÅözero paddingÔºåÁî®0Â°´ÂÖÖ\nËøôÊ†∑‰∏ÄÊù•ÔºåÊâÄÊúâÁöÑÂ∫èÂàóÈïøÂ∫¶Â∞±Áªü‰∏Ä‰∫Ü\nÊñáÊú¨Â§ÑÁêÜÂÆåÊàê‰∫ÜÔºåÊé•‰∏ãÊù•ÊòØword embeddingÔºåÊääÂçïËØçË°®Á§∫‰∏∫‰∏Ä‰∏™‰ΩéÁª¥ÂêëÈáèÔºõ\nÁÑ∂ËÄåËøôÊ†∑ÂÅöÁöÑËØùÔºåÂ¶ÇÊûúÊòØ10000‰∏™ÂçïËØçÔºåÁª¥Â∫¶Â∞±ÊòØ10000Áª¥ÔºåÁª¥Â∫¶Â§™È´ò‰∫ÜÔºõÂõ†Ê≠§Ë¶ÅÂÅöword embeddingÔºõ\nÂÖ∑‰ΩìÂÅöÊ≥ïÂ∞±ÊòØÊääone-hotÂêëÈáèe_iÂíåÂèÇÊï∞Áü©ÈòµpÁõ∏‰πòÔºõÁü©ÈòµPËΩ¨ÁΩÆÁöÑÂ§ßÂ∞èÊòØd x vÔºõdÊòØËØçÂêëÈáèÁöÑÁª¥Â∫¶ÔºõvÊòØÂ≠óÂÖ∏ÈáåËØçÊ±áÁöÑÊï∞ÈáèÔºõÁªìÊûú‰∏∫x_iÔºõx_iÂ∞±ÊòØ‰∏Ä‰∏™ËØçÂêëÈáèÔºõÂ¶ÇÊûúone-hotÂêëÈáèÁöÑÁ¨¨‰∏âË°å‰∏∫1ÔºõÈÇ£‰πàx_iÂ∞±ÊòØPËΩ¨ÁΩÆÁü©ÈòµÁöÑÁ¨¨‰∏âÂàóÔºàÂÖ∂‰ΩôÂàóÈÉΩ‰∏∫0ÔºâÔºõÊâÄ‰ª•PËΩ¨ÁΩÆÊØè‰∏ÄÂàóÈÉΩÊòØ‰∏Ä‰∏™ËØçÂêëÈáèÔºõÊâÄ‰ª•Áü©ÈòµPÊú¨Ë∫´ÁöÑÊØè‰∏ÄË°åÂ∞±ÊòØ‰∏Ä‰∏™ËØçÂêëÈáèÔºõÂÖ∂Ë°åÊï∞‰∏∫vÔºõÂç≥vocabularyÔºåËØçÊ±áÈáèÔºõÊØè‰∏ÄË°åÂØπÂ∫î‰∏Ä‰∏™ÂçïËØçÔºõÁü©ÈòµÁöÑÂàóÊï∞‰∏∫dÔºõdÊòØÁî®Êà∑ÂÜ≥ÂÆöÁöÑÔºõdÁöÑÂ§ßÂ∞è‰ºöÂÜ≥ÂÆöÊú∫Âô®Â≠¶‰π†Ê®°ÂûãÁöÑË°®Áé∞ÔºõÂ∫îËØ•Áî®xxxÊù•ÈÄâÊã©‰∏Ä‰∏™ÊØîËæÉÂ•ΩÁöÑdÔºõ\nÊàë‰ª¨ÁöÑ‰ªªÂä°ÊòØÁúãËØÑËÆ∫ÊòØÊ≠£Èù¢ÁöÑËøòÊòØË¥üÈù¢ÁöÑÔºõÂèÇÊï∞Áü©ÈòµÊòØ‰ªéËÆ≠ÁªÉÊï∞ÊçÆ‰∏≠Â≠¶‰π†Âá∫Êù•ÁöÑÔºåÊâÄ‰ª•Â≠¶Âá∫Êù•ÁöÑËØçÂêëÈáèÊòØÂ∏¶ÊúâÊÑüÊÉÖËâ≤ÂΩ©ÁöÑÔºõÂÅáËÆæËøô‰∫õËØçÂêëÈáèÈÉΩÊòØ‰∫åÁª¥ÁöÑÔºåÂàôÂèØ‰ª•Âú®Âπ≥Èù¢ÂùêÊ†áÁ≥ª‰∏≠Ê†áÂá∫‰∏ãÈù¢ËØçÂêëÈáè\nkerasÊèê‰æõembeddingÂ±ÇÔºõÁî®Êà∑ÂèØ‰ª•ÊåáÂÆövocabularyÂ§ßÂ∞èÂíådÁöÑÂ§ßÂ∞èÔºõ‰ª•ÂèäÊØè‰∏Ä‰∏™sequenceÁöÑÈïøÂ∫¶ÔºõdÊòØÊ†πÊçÆÁÆóÊ≥ïÈÄâÂá∫Êù•ÁöÑ Âà∞Ëøô‰∏ÄÊ≠•ÔºåÊàë‰ª¨Â∑≤ÁªèÂÆåÊàê‰∫ÜÊñáÊú¨Â§ÑÁêÜÂíåword embedding„ÄÇÊé•‰∏ãÊù•Â∞±ÊòØÁî®Logistic Regression for Binary ClassificationÂÅö‰∫åÂàÜÁ±ªÔºõ\n","permalink":"http://localhost:1313/posts/nlp-2/","summary":"\u003ch3 id=\"text-to-sequence\"\u003eText to Sequence\u003c/h3\u003e\n\u003cp\u003eÊñáÊú¨Â§ÑÁêÜ\u003c/p\u003e\n\u003cp\u003eStep1: Tokenization\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\n\u003cp\u003eTokenization breaks a piece of text down into a list of tokens.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003eHere, a token is a word. (A token can be a character in some applications.)\u003c/p\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003eTokenizationËÆ≤Á©∂ÂæàÂ§öÔºå‰æãÂ¶ÇÊòØÂê¶Â∫îËØ•ÊääÂ§ßÂÜôÊîπÊàêÂ∞èÂÜôÂë¢ÔºüËøõË°åtypo correctionÁ≠âÁ≠â\u003c/p\u003e\n\u003cp\u003e\u003cimg alt=\"image-20250322150322238\" loading=\"lazy\" src=\"./NLP-2.assets/image-20250322150322238.png\"\u003e\u003c/p\u003e\n\u003cp\u003eStep2: Build Dictionary\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\n\u003cp\u003eUse a dictionary (hash table) to count word frequencies.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003eThe dictionary maps word to index.\u003c/p\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003eÂèØ‰ª•È¶ñÂÖàÁªüËÆ°ËØçÈ¢ëÂéªÊéâ‰ΩéÈ¢ëËØçÔºåÁÑ∂ÂêéËÆ©ÊØè‰∏™ËØçÂØπÂ∫î‰∏Ä‰∏™Ê≠£Êï¥Êï∞ÔºõËøôÊ†∑ÁöÑËØùÔºå‰∏ÄÂè•ËØùÂ∞±ÂèØ‰ª•Áî®‰∏Ä‰∏™Ê≠£Êï¥Êï∞ÂàóË°®Ë°®Á§∫ÔºåËøô‰∏™ÂàóË°®Â∞±Âè´sequenceÔºõÂ¶ÇÊûúÂøÖË¶ÅÂ∞±ËøòÂæóÂÅöone-hot encoding„ÄÇ\u003cimg alt=\"image-20250322150620890\" loading=\"lazy\" src=\"./NLP-2.assets/image-20250322150620890.png\"\u003e\u003c/p\u003e\n\u003cp\u003eÁªìÊûú\u003c/p\u003e\n\u003cp\u003e\u003cimg alt=\"image-20250322150754528\" loading=\"lazy\" src=\"./NLP-2.assets/image-20250322150754528.png\"\u003e\u003c/p\u003e\n\u003cp\u003e‰ΩÜÊòØÈïøÂ∫¶‰∏çÁªü‰∏Ä\u003c/p\u003e\n\u003cp\u003eStep4: ÂØπÈΩêsequence\u003c/p\u003e\n\u003cp\u003e\u003cimg alt=\"image-20250322150854986\" loading=\"lazy\" src=\"./NLP-2.assets/image-20250322150854986.png\"\u003e\u003c/p\u003e\n\u003cp\u003eËß£ÂÜ≥ÊñπÊ°àÊòØËøôÊ†∑ÁöÑÔºöÂèØ‰ª•Âõ∫ÂÆöÈïøÂ∫¶‰∏∫wÔºåÂä†ÂÖ•‰∏Ä‰∏™Â∫èÂàóÈïøÂ∫¶Â§™ÈïøÔºåÂ∞±Á†çÊéâÂâçÈù¢ÁöÑËØçÔºåÂè™‰øùÁïôÊúÄÂêéw‰∏™ËØçÔºõÂ¶ÇÊûú‰∏Ä‰∏™Â∫èÂàóÂ§™Áü≠ÔºåÂ∞±ÂÅözero paddingÔºåÁî®0Â°´ÂÖÖ\u003c/p\u003e\n\u003cp\u003e\u003cimg alt=\"image-20250322151030119\" loading=\"lazy\" src=\"./NLP-2.assets/image-20250322151030119.png\"\u003e\u003c/p\u003e\n\u003cp\u003eËøôÊ†∑‰∏ÄÊù•ÔºåÊâÄÊúâÁöÑÂ∫èÂàóÈïøÂ∫¶Â∞±Áªü‰∏Ä‰∫Ü\u003c/p\u003e\n\u003cp\u003e\u003cimg alt=\"image-20250322151117125\" loading=\"lazy\" src=\"./NLP-2.assets/image-20250322151117125.png\"\u003e\u003c/p\u003e\n\u003cp\u003eÊñáÊú¨Â§ÑÁêÜÂÆåÊàê‰∫ÜÔºåÊé•‰∏ãÊù•ÊòØword embeddingÔºåÊääÂçïËØçË°®Á§∫‰∏∫‰∏Ä‰∏™‰ΩéÁª¥ÂêëÈáèÔºõ\u003c/p\u003e\n\u003cp\u003e\u003cimg alt=\"image-20250322151252837\" loading=\"lazy\" src=\"./NLP-2.assets/image-20250322151252837.png\"\u003e\u003c/p\u003e","title":""},{"content":"üëã About me Recently, inspired by OpenAI\u0026rsquo;s five-step plan towards superintelligence, I have great expectations for AGI and developed a strong interest in LLM agents, MLLM, reinforcement learning, and knowledge graphs. I believe there is significant potential in these fields to create innovative solutions, and I hope to contribute my efforts towards that goal.\nüìö Education üá≠üá∞ The University of Hong Kong 09/2024 - Expected 11/2025 School of Computing and Data Science Master of Science in Electronic Commerce \u0026amp; Internet Computing Relevant Courses: Machine learning for business and e-commerce, Knowledge graphs, Financial fraud analytics, Internet infrastructure technologies, Website engineering, Blockchain and cryptocurrency, etc. üá®üá≥ Beijing Institute of Technology 09/2020 - 06/2024 School of Computer Science \u0026amp; Technology Bachelor of Engineering in Software Engineering, last two years GPA: 3.7/4 Relevant Courses: Reinforcement Learning, Deep Learning and Computer Vision, Artificial Intelligence and Robot Ethics, Almost Human: Mind, Brain and Artificial Intelligence, Mathematical Analysis for Engineering, Linear Algebra, Probability and Mathematical Statistics, etc. Skills: Python, Java, common data structures, design patterns, machine learning basics and algorithms, Linux, PyTorch, and some development tools (git, conda, etc.). üèÜ Awards \u0026amp; Honors Beijing Institute of Technology Undergraduate Scholarship (Top 20% of Grade) 06/2023 3rd Prize of China International \u0026#34;Internet \u0026#43;\u0026#34; College Student\u0026#39;s Innovation Competition 08/2022 Bronze Prize of \u0026#34;Challenge Cup\u0026#34; Capital University Entrepreneurship Competition 05/2022 üíº Project Experience Online Transaction Fraud Detection 09/2024 ‚Äì 01/2025 Independent project, supervised by Dr. Vivien Chan Focused on addressing financial fraud in e-commerce to enhance the accuracy of transaction anomaly detection, while independently managing the entire case study that included data preprocessing, feature engineering, model building, evaluation, and results analysis. Effectively resolved class imbalance issues using SMOTE and ROSE techniques. Built various models including Logistic Regression, Random Forest, XGBoost, and LightGBM, ultimately selecting the LightGBM model to achieve a recall rate of 95.45% and an AUC of 99.84%. Wrote efficient and maintainable code, enhancing model training and data processing efficiency through parallel computing and logging. Multi-Model Intelligent Text Keyword Extraction System 08/2023 ‚Äì 09/2023 Group project, supervised by Associate Prof. Xiaolin Zhao Designed and implemented an intelligent text summary system that automatically extracts keywords from article titles and abstracts, enhancing the understanding and summarization of text information. Participated in the planning of the technical route and built a hybrid model combining extractive and generative approaches, utilizing advanced natural language processing techniques including KeyBERT, Sentence Transformer, BERT, and T5 models. Responsible for data preprocessing and tokenization, as well as the end-to-end implementation and training of the T5 model, optimizing the model architecture and hyperparameters, achieving satisfactory results after only 3 epochs of training. Model evaluation results showed that the Rouge-1, Rouge-2, and Rouge-L metrics reached 0.6345, 0.5038, and 0.5282, respectively, in the third epoch, validating the model\u0026rsquo;s effectiveness in the summarization task. Cambridge University Machine Learning Summer Project 07/2023 ‚Äì 08/2023 Group project, supervised by Prof. Pietro Li√≤ Participated in the Cambridge University deep learning summer project, focusing on deep reinforcement learning; explored multi-agent learning algorithms across different environments. Reproduced the Multi-Agent Deep Deterministic Policy Gradient (MADDPG) algorithm in the Simple Adversary environment and studied the effect of agent numbers on convergence speed and stability, finding optimal stability at 21 agents. Designed and implemented comparative experiments inspired by the Rainbow algorithm, assessing target network strategies versus the Double Deep Q-Network (Double DQN). The results demonstrated that Double DQN significantly enhanced convergence speed, optimizing the overall learning process. Co-authored a group project paper on agent numbers and strategies effectiveness in multi-agent systems, achieving a score of 71% in the summer program (the highest in my group) and a \u0026ldquo;First Class\u0026rdquo; classification in the UK grading system. Deep Learning and Computer Vision Semester Project 09/2022 ‚Äì 12/2022 Independent project, supervised by Associate Prof. Guangyu Gao Designed and implemented a waste classifier using the ResNet model to improve classification accuracy and reduce resource waste. The project also enhanced understanding of transfer learning techniques with ResNet. Collected a dataset of 16 waste categories and preprocessed the images for uniformity and standardization, incorporating data augmentation techniques to enhance the dataset. Conducted experiments using ResNet34 and ResNet50 models through transfer learning, accelerating network convergence by leveraging pretrained weights. During training, techniques such as Batch Normalization and Dropout were applied to mitigate the risk of overfitting. The final model achieved an accuracy of 90% on the training set, while the performance on the test set was 61%, indicating a significant overfitting phenomenon during the training process. üéì Internship Beijing Academy of Quantum Information Science 08/2023 ‚Äì 01/2024 Research Intern at Quantum Computation Department Proposed a quantum convolution kernel design based on variational quantum circuits and developed a universal quantum convolution layer, successfully integrating it into classical CNN architectures such as VGG, GoogLeNet, and ResNet. Developed and evaluated various hybrid models, including a simple model named HQCCNN-2, which achieved 84.45% accuracy on the FashionMNIST dataset, surpassing the traditional CNN\u0026rsquo;s 80.72%. This demonstrates the effectiveness of the quantum convolution layer in improving model performance. Tested on a real quantum computer further validated the effectiveness of the hybrid model, demonstrating the viable integration of quantum computing with deep learning, and highlighting the potential for leveraging quantum properties to enhance model performance. üèÖ Competition Experience China International \u0026#34;Internet \u0026#43;\u0026#34; College Students\u0026#39; Innovation Competition 08/2022 Zhongke Ushield: Deep Learning-based Face Privacy Protection Authentication System Responsible for constructing a localized facial feature extraction engine based on MobileFaceNet, ensuring feature extraction is completed on end devices (such as mobile phones and cameras), guaranteeing that raw data does not leave the domain and is not stored, thus enhancing user privacy protection while improving recognition efficiency. \u0026#34;Challenge Cup\u0026#34; Capital University Entrepreneurship Competition 05/2022 Smart Orchard Responsible for the development of the fruit detection, ripeness prediction, and pest identification system, using deep convolutional neural network (CNN) technology for intelligent monitoring of crop growth conditions. Applied advanced object detection algorithms such as Faster R-CNN and YOLO to achieve high precision in apple detection and ripeness assessment, with an accuracy rate exceeding 90%, significantly enhancing the intelligence level of orchard management. Built and trained a dedicated dataset containing various pest samples, optimizing pest detection accuracy through data preprocessing (such as image normalization and resizing) and data augmentation techniques (like rotation, flipping, and noise addition), enabling the real-time monitoring system to accurately identify over 80% of pests, providing effective scientific maintenance recommendations to help farmers reduce crop losses. üìã Extracurricular Activities Vice President, Cyber Security Club, Beijing Institute of Technology 09/2021-09/2022 Backbone, Media Center of the Student Union of Beijing Institute of Technology 10/2020-06/2021 üì´ Contact üìß zongsi.xu@outlook.com üëî Zongsi (Tristan) Xu üíª github.com/BaizeXS üìç Hong Kong SAR, China ","permalink":"http://localhost:1313/resume/","summary":"Personal resume of Zongsi (Tristan) Xu","title":"Zongsi (Tristan) Xu"},{"content":"‰∏Ä„ÄÅÊï∞ÂÄºÁâπÂæÅ‰∏éÁ±ªÂà´ÁâπÂæÅ Êï∞ÂÄºÁâπÂæÅ (Numeric Features) ÂÖ∑ÊúâÂèØÂä†ÂáèÁöÑÊÑè‰πâÔºå‰∏îÂ≠òÂú®Â§ßÂ∞èÈ°∫Â∫è„ÄÇ ‰æãÂ≠êÔºöÂπ¥ÈæÑ„ÄÅÊ∏©Â∫¶Á≠â„ÄÇÂèØ‰ª•Áõ¥Êé•‰øùÁïôÂÖ∂Êï¥Êï∞ÊàñÊµÆÁÇπÊï∞ÂΩ¢Âºè‰æõÊ®°Âûã‰ΩøÁî®„ÄÇ Á±ªÂà´ÁâπÂæÅ (Categorical Features) Êï∞ÊçÆÂÄºÁ¶ªÊï£Ôºå‰∏çÂÖ∑Â§á‚ÄúÊï∞ÂÄºÂ§ßÂ∞è‚ÄùÈó¥ÁöÑÂèØÊØîÊÑè‰πâ„ÄÇ ‰æãÂ≠êÔºöÂõΩÁ±çÔºàÁæéÂõΩ/‰∏≠ÂõΩ/Âç∞Â∫¶Á≠âÔºâ„ÄÅÊÄßÂà´ÔºàÁî∑/Â•≥ÔºâÁ≠â„ÄÇ ÈóÆÈ¢òÔºöËã•‰ªÖÁî®Êï¥Êï∞Ë°®Á§∫ÔºàÁæéÂõΩ=1, ‰∏≠ÂõΩ=2ÔºâÔºå‰ºöÂºïÂÖ•ÈîôËØØÁöÑÊï∞ÂÄºËøêÁÆóÂÖ≥Á≥ªÔºåÂ¶Ç ‚ÄúÁæéÂõΩ + ‰∏≠ÂõΩ = Âç∞Â∫¶‚Äù„ÄÇ ‰∫å„ÄÅOne-HotÁºñÁ†ÅÁöÑÂä®Êú∫‰∏éÊµÅÁ®ã ‰∏∫‰ªÄ‰πà‰ΩøÁî®One-Hot\nÈÄöËøáÂ∞ÜÁ±ªÂà´Êò†Â∞Ñ‰∏∫ÂêëÈáèÔºåÈÅøÂÖçÊï¥Êï∞ÁºñÁ†ÅÂºïÂÖ•ÁöÑ‰º™Êï∞ÂÄºÂÖ≥Á≥ª„ÄÇ ÂêåÊó∂‰øùÁïôÂêÑÁßçÂèØËÉΩÁ±ªÂà´ÁöÑ‰ø°ÊÅØÔºå‰∏î‰ªÖÂú®ÂØπÂ∫î‰ΩçÁΩÆ‰∏∫1ÔºåÂÖ∂‰ªñ‰ΩçÁΩÆ‰∏∫0„ÄÇ Âª∫Á´ãÊò†Â∞ÑÔºö‰ªéÁ±ªÂà´Âà∞Á¥¢Âºï\n‰∏∫ÊØè‰∏™Á±ªÂà´ÂàÜÈÖç‰∏Ä‰∏™ÂîØ‰∏ÄÁ¥¢ÂºïÔºåÈÄöÂ∏∏‰ªé1ÂºÄÂßã„ÄÇ È¢ÑÁïôÁ¥¢Âºï0Ë°®Á§∫‚ÄúÊú™Áü•‚ÄùÊàñ‚ÄúÁº∫Â§±‚ÄùÔºåÂØπÂ∫îÂÖ®0ÂêëÈáè„ÄÇ ËΩ¨Êç¢‰∏∫One-HotÂêëÈáè\nËã•Á±ªÂà´ÊÄªÊï∞‰∏∫197ÔºåÂàôÁî®197Áª¥ÂêëÈáèË°®Á§∫„ÄÇ ‰æãÂ≠êÔºöÁæéÂõΩ [1, 0, 0, 0, ‚Ä¶]Ôºå ‰∏≠ÂõΩ [0, 1, 0, 0, ‚Ä¶]„ÄÇ Á§∫‰æãÔºöË°®Á§∫‰∏Ä‰∏™‰∫∫ÁöÑÁâπÂæÅ\nÁâπÂæÅÂåÖÂê´ÔºàÂπ¥ÈæÑ, ÊÄßÂà´, ÂõΩÁ±çÔºåÂÖ∂‰∏≠ÂõΩÁ±ç197ÁßçÔºâ Áª¥Â∫¶ÊÄªÂíåÔºö1Áª¥_age + 1Áª¥_gender + 197Áª¥_nationality = 199Áª¥„ÄÇ ‰æãÂ¶Ç (28, Â•≥, ‰∏≠ÂõΩ) ‚Üí [28, 0, 0, 1, 0, ‚Ä¶, 0]„ÄÇ ‰∏â„ÄÅÊñáÊú¨Êï∞ÊçÆÂ§ÑÁêÜÊµÅÁ®ã ÊñáÊú¨Âú®Ëá™ÁÑ∂ËØ≠Ë®ÄÂ§ÑÁêÜÔºàNLPÔºâ‰∏≠‰Ωú‰∏∫Â∏∏ËßÅÁöÑÂéüÂßãËæìÂÖ•ÔºåÈúÄË¶ÅÊï∞ÂÄºÂåñÊâçËÉΩÈÄÅÂÖ•Ê®°Âûã„ÄÇ‰∏ÄËà¨Ê≠•È™§Â¶Ç‰∏ãÔºö\nÂàÜËØç (Tokenization)\nÂ∞ÜÊñáÊú¨ÊãÜÂàÜ‰∏∫‰∏Ä‰∏™‰∏™ÂçïËØçÔºàTokenÔºâ„ÄÇ ‰æãÂ≠êÔºö\u0026quot;... to be or not to be...\u0026quot; ‚Üí [\u0026quot;...\u0026quot;, \u0026quot;to\u0026quot;, \u0026quot;be\u0026quot;, \u0026quot;or\u0026quot;, \u0026quot;not\u0026quot;, \u0026quot;to\u0026quot;, \u0026quot;be\u0026quot;, \u0026quot;...\u0026quot;]„ÄÇ ÁªüËÆ°ËØçÈ¢ë \u0026amp; ÊûÑÂª∫ËØçÂÖ∏\nËØçÈ¢ëÁªüËÆ° Áî®ÂìàÂ∏åË°®/Â≠óÂÖ∏ËÆ∞ÂΩïÊØè‰∏™ÂçïËØçÂá∫Áé∞Ê¨°Êï∞„ÄÇ ÈÅçÂéÜÊñáÊú¨Êó∂ÔºåËã•ÂçïËØçÂ∞öÊú™ÂÖ•Ë°®ÔºåÂàôÊñ∞Âª∫ËÆ∞ÂΩïÔºõËã•Â∑≤Â≠òÂú®ÔºåÂàôËÆ°Êï∞+1„ÄÇ ÊéíÂ∫è‰∏éÁ¥¢Âºï ÊåâËØçÈ¢ëÈôçÂ∫èÊéíÂ∫èÔºåËØçÈ¢ëÊúÄÈ´òÁöÑÂçïËØçÊéíÂú®ÂâçÈù¢„ÄÇ Á¥¢Âºï‰ªé1ÂºÄÂßãÔºå0ÁïôÁªô‚ÄúÊú™Áü•‚Äù„ÄÇ ËØçÂÖ∏ËßÑÊ®°ÔºàvocabularyÔºâÂèØËßÜÈúÄÊ±ÇÊà™Êñ≠Ôºà‰æãÂ¶ÇÂè™‰øùÁïôTop 10kÔºâ„ÄÇ ‰∏∫‰ªÄ‰πàÁßªÈô§‰ΩéÈ¢ëËØç ‰ΩéÈ¢ëËØçÂèØËÉΩÊòØÊãºÂÜôÈîôËØØ„ÄÅÁΩïËßÅ‰∫∫ÂêçÁ≠âÔºåÂØπÊ®°ÂûãÂ∏ÆÂä©ÊúâÈôê„ÄÇ ÂáèÂ∞ëËØçÂÖ∏ËßÑÊ®°ÂèØÈôç‰ΩéËøêÁÆóÂºÄÈîÄ„ÄÅÂä†Âø´Ê®°ÂûãËÆ≠ÁªÉ‰∏éÊé®ÁêÜÈÄüÂ∫¶„ÄÇ Áã¨ÁÉ≠ÁºñÁ†Å (One-Hot Encoding)\nÂ∞ÜÊØè‰∏™ÂçïËØçÊò†Â∞Ñ‰∏∫ËØçÂÖ∏‰∏≠ÁöÑÁ¥¢ÂºïÂêéÔºàÂ¶Ç [2, 4, 1, 8, ‚Ä¶]ÔºâÔºåÂèØËøõ‰∏ÄÊ≠•ËΩ¨Êç¢ÊàêOne-HotÂêëÈáè„ÄÇ One-HotÁª¥Â∫¶ÂèñÂÜ≥‰∫é‰øùÁïô‰∏ãÊù•ÁöÑËØçÂÖ∏Â§ßÂ∞èÔºà‰æãÂ¶Ç1‰∏áÔºâ„ÄÇ Êú™Êî∂ÂΩïÂçïËØçÂèØËÉΩÁõ¥Êé•ÂøΩÁï•ÔºåÊàñÁªü‰∏ÄÁî®Á¥¢Âºï0‰ª£Êõø„ÄÇ Âõõ„ÄÅÊ†∏ÂøÉÊî∂Ëé∑‰∏éÂ∫îÁî® Á±ªÂà´ÁâπÂæÅÂøÖÈúÄÊï∞ÂÄºÂåñÔºö\n‰ΩøÁî®Êï¥Êï∞1,2,3‚Ä¶‰ªÖË°®Á§∫Á±ªÂà´‚ÄúÊ†áËØÜ‚ÄùÔºåÂπ∂‰∏ç‰ª£Ë°®ÂÆÉ‰ª¨ÂèØËøõË°åÊï∞ÂÄºËøêÁÆó„ÄÇ Âõ†Ê≠§ÈúÄË¶ÅOne-HotÁ≠âÁºñÁ†ÅÊñπÂºèÔºåÈÅøÂÖçÊï∞ÂÄºËØØËß£„ÄÇ ÊñáÊú¨Êï∞ÊçÆÈ¢ÑÂ§ÑÁêÜÔºö\nÂàÜËØç„ÄÅËØçÈ¢ëÁªüËÆ°„ÄÅÊûÑÂª∫ËØçÂÖ∏„ÄÅÁ¥¢ÂºïÂåñ„ÄÅOne-HotÊàñÂÖ∂‰ªñÊñπÂºèÔºàÂ¶ÇËØçÂµåÂÖ•ÔºâÊòØÂ∏∏ËßÅÊµÅÁ®ã„ÄÇ Ê≠£Á°ÆÁöÑÊñáÊú¨È¢ÑÂ§ÑÁêÜÂèØÊòæËëóÂΩ±ÂìçÊ®°ÂûãÊÄßËÉΩÂíåÊïàÁéá„ÄÇ ‰øùÁïôÊú™Áü•Á¥¢ÂºïÔºö\n‰øùËØÅÂØπÁº∫Â§±Êï∞ÊçÆÊàñÂ≠óÂÖ∏Â§ñÊñ∞ËØçËÉΩÊúâÂü∫Êú¨ÁöÑË°®Á§∫ÔºåÊèêÂçáÊ®°ÂûãÂÆπÈîôÊÄß„ÄÇ ÂÆûÈôÖ‰ΩøÁî®Ôºö\nÂØπ‰∫éÂ∞èËßÑÊ®°Á±ªÂà´ÂèØÁõ¥Êé•One-HotÁºñÁ†ÅÔºõÂØπ‰∫éËØçÂÖ∏ÂæàÂ§ßÁöÑÂú∫ÊôØÔºåÈÄöÂ∏∏‰ºöËøõ‰∏ÄÊ≠•ËÄÉËôëËØçÂµåÂÖ•ÔºàWord EmbeddingÔºâÊàñÈ¢ÑËÆ≠ÁªÉËØ≠Ë®ÄÊ®°Âûã„ÄÇ ","permalink":"http://localhost:1313/posts/nlp-1/","summary":"\u003ch2 id=\"‰∏ÄÊï∞ÂÄºÁâπÂæÅ‰∏éÁ±ªÂà´ÁâπÂæÅ\"\u003e‰∏Ä„ÄÅÊï∞ÂÄºÁâπÂæÅ‰∏éÁ±ªÂà´ÁâπÂæÅ\u003c/h2\u003e\n\u003col\u003e\n\u003cli\u003e\u003cstrong\u003eÊï∞ÂÄºÁâπÂæÅ (Numeric Features)\u003c/strong\u003e\n\u003cul\u003e\n\u003cli\u003eÂÖ∑ÊúâÂèØÂä†ÂáèÁöÑÊÑè‰πâÔºå‰∏îÂ≠òÂú®Â§ßÂ∞èÈ°∫Â∫è„ÄÇ\u003c/li\u003e\n\u003cli\u003e‰æãÂ≠êÔºöÂπ¥ÈæÑ„ÄÅÊ∏©Â∫¶Á≠â„ÄÇÂèØ‰ª•Áõ¥Êé•‰øùÁïôÂÖ∂Êï¥Êï∞ÊàñÊµÆÁÇπÊï∞ÂΩ¢Âºè‰æõÊ®°Âûã‰ΩøÁî®„ÄÇ\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003eÁ±ªÂà´ÁâπÂæÅ (Categorical Features)\u003c/strong\u003e\n\u003cul\u003e\n\u003cli\u003eÊï∞ÊçÆÂÄºÁ¶ªÊï£Ôºå‰∏çÂÖ∑Â§á‚ÄúÊï∞ÂÄºÂ§ßÂ∞è‚ÄùÈó¥ÁöÑÂèØÊØîÊÑè‰πâ„ÄÇ\u003c/li\u003e\n\u003cli\u003e‰æãÂ≠êÔºöÂõΩÁ±çÔºàÁæéÂõΩ/‰∏≠ÂõΩ/Âç∞Â∫¶Á≠âÔºâ„ÄÅÊÄßÂà´ÔºàÁî∑/Â•≥ÔºâÁ≠â„ÄÇ\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003eÈóÆÈ¢ò\u003c/strong\u003eÔºöËã•‰ªÖÁî®Êï¥Êï∞Ë°®Á§∫ÔºàÁæéÂõΩ=1, ‰∏≠ÂõΩ=2ÔºâÔºå‰ºöÂºïÂÖ•ÈîôËØØÁöÑÊï∞ÂÄºËøêÁÆóÂÖ≥Á≥ªÔºåÂ¶Ç ‚ÄúÁæéÂõΩ + ‰∏≠ÂõΩ = Âç∞Â∫¶‚Äù„ÄÇ\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003c/ol\u003e\n\u003ch2 id=\"‰∫åone-hotÁºñÁ†ÅÁöÑÂä®Êú∫‰∏éÊµÅÁ®ã\"\u003e‰∫å„ÄÅOne-HotÁºñÁ†ÅÁöÑÂä®Êú∫‰∏éÊµÅÁ®ã\u003c/h2\u003e\n\u003col\u003e\n\u003cli\u003e\n\u003cp\u003e\u003cstrong\u003e‰∏∫‰ªÄ‰πà‰ΩøÁî®One-Hot\u003c/strong\u003e\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eÈÄöËøáÂ∞ÜÁ±ªÂà´Êò†Â∞Ñ‰∏∫ÂêëÈáèÔºåÈÅøÂÖçÊï¥Êï∞ÁºñÁ†ÅÂºïÂÖ•ÁöÑ‰º™Êï∞ÂÄºÂÖ≥Á≥ª„ÄÇ\u003c/li\u003e\n\u003cli\u003eÂêåÊó∂‰øùÁïôÂêÑÁßçÂèØËÉΩÁ±ªÂà´ÁöÑ‰ø°ÊÅØÔºå‰∏î‰ªÖÂú®ÂØπÂ∫î‰ΩçÁΩÆ‰∏∫1ÔºåÂÖ∂‰ªñ‰ΩçÁΩÆ‰∏∫0„ÄÇ\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003e\u003cstrong\u003eÂª∫Á´ãÊò†Â∞ÑÔºö‰ªéÁ±ªÂà´Âà∞Á¥¢Âºï\u003c/strong\u003e\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e‰∏∫ÊØè‰∏™Á±ªÂà´ÂàÜÈÖç‰∏Ä‰∏™ÂîØ‰∏ÄÁ¥¢ÂºïÔºåÈÄöÂ∏∏‰ªé1ÂºÄÂßã„ÄÇ\u003c/li\u003e\n\u003cli\u003eÈ¢ÑÁïôÁ¥¢Âºï0Ë°®Á§∫‚ÄúÊú™Áü•‚ÄùÊàñ‚ÄúÁº∫Â§±‚ÄùÔºåÂØπÂ∫îÂÖ®0ÂêëÈáè„ÄÇ\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003e\u003cstrong\u003eËΩ¨Êç¢‰∏∫One-HotÂêëÈáè\u003c/strong\u003e\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eËã•Á±ªÂà´ÊÄªÊï∞‰∏∫197ÔºåÂàôÁî®197Áª¥ÂêëÈáèË°®Á§∫„ÄÇ\u003c/li\u003e\n\u003cli\u003e‰æãÂ≠êÔºöÁæéÂõΩ \u003ccode\u003e[1, 0, 0, 0, ‚Ä¶]\u003c/code\u003eÔºå ‰∏≠ÂõΩ \u003ccode\u003e[0, 1, 0, 0, ‚Ä¶]\u003c/code\u003e„ÄÇ\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003e\u003cstrong\u003eÁ§∫‰æãÔºöË°®Á§∫‰∏Ä‰∏™‰∫∫ÁöÑÁâπÂæÅ\u003c/strong\u003e\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eÁâπÂæÅÂåÖÂê´ÔºàÂπ¥ÈæÑ, ÊÄßÂà´, ÂõΩÁ±çÔºåÂÖ∂‰∏≠ÂõΩÁ±ç197ÁßçÔºâ\u003c/li\u003e\n\u003cli\u003eÁª¥Â∫¶ÊÄªÂíåÔºö1Áª¥_age + 1Áª¥_gender + 197Áª¥_nationality = 199Áª¥„ÄÇ\u003c/li\u003e\n\u003cli\u003e‰æãÂ¶Ç \u003ccode\u003e(28, Â•≥, ‰∏≠ÂõΩ)\u003c/code\u003e ‚Üí \u003ccode\u003e[28, 0, 0, 1, 0, ‚Ä¶, 0]\u003c/code\u003e„ÄÇ\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003c/ol\u003e\n\u003ch2 id=\"‰∏âÊñáÊú¨Êï∞ÊçÆÂ§ÑÁêÜÊµÅÁ®ã\"\u003e‰∏â„ÄÅÊñáÊú¨Êï∞ÊçÆÂ§ÑÁêÜÊµÅÁ®ã\u003c/h2\u003e\n\u003cp\u003eÊñáÊú¨Âú®Ëá™ÁÑ∂ËØ≠Ë®ÄÂ§ÑÁêÜÔºàNLPÔºâ‰∏≠‰Ωú‰∏∫Â∏∏ËßÅÁöÑÂéüÂßãËæìÂÖ•ÔºåÈúÄË¶ÅÊï∞ÂÄºÂåñÊâçËÉΩÈÄÅÂÖ•Ê®°Âûã„ÄÇ‰∏ÄËà¨Ê≠•È™§Â¶Ç‰∏ãÔºö\u003c/p\u003e\n\u003col\u003e\n\u003cli\u003e\n\u003cp\u003e\u003cstrong\u003eÂàÜËØç (Tokenization)\u003c/strong\u003e\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eÂ∞ÜÊñáÊú¨ÊãÜÂàÜ‰∏∫‰∏Ä‰∏™‰∏™ÂçïËØçÔºàTokenÔºâ„ÄÇ\u003c/li\u003e\n\u003cli\u003e‰æãÂ≠êÔºö\u003ccode\u003e\u0026quot;... to be or not to be...\u0026quot;\u003c/code\u003e ‚Üí \u003ccode\u003e[\u0026quot;...\u0026quot;, \u0026quot;to\u0026quot;, \u0026quot;be\u0026quot;, \u0026quot;or\u0026quot;, \u0026quot;not\u0026quot;, \u0026quot;to\u0026quot;, \u0026quot;be\u0026quot;, \u0026quot;...\u0026quot;]\u003c/code\u003e„ÄÇ\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003e\u003cstrong\u003eÁªüËÆ°ËØçÈ¢ë \u0026amp; ÊûÑÂª∫ËØçÂÖ∏\u003c/strong\u003e\u003c/p\u003e","title":""},{"content":"Text to Sequence ÊñáÊú¨Â§ÑÁêÜ\nStep1: Tokenization\nTokenization breaks a piece of text down into a list of tokens.\nHere, a token is a word. (A token can be a character in some applications.)\nTokenizationËÆ≤Á©∂ÂæàÂ§öÔºå‰æãÂ¶ÇÊòØÂê¶Â∫îËØ•ÊääÂ§ßÂÜôÊîπÊàêÂ∞èÂÜôÂë¢ÔºüËøõË°åtypo correctionÁ≠âÁ≠â\nStep2: Build Dictionary\nUse a dictionary (hash table) to count word frequencies.\nThe dictionary maps word to index.\nÂèØ‰ª•È¶ñÂÖàÁªüËÆ°ËØçÈ¢ëÂéªÊéâ‰ΩéÈ¢ëËØçÔºåÁÑ∂ÂêéËÆ©ÊØè‰∏™ËØçÂØπÂ∫î‰∏Ä‰∏™Ê≠£Êï¥Êï∞ÔºõËøôÊ†∑ÁöÑËØùÔºå‰∏ÄÂè•ËØùÂ∞±ÂèØ‰ª•Áî®‰∏Ä‰∏™Ê≠£Êï¥Êï∞ÂàóË°®Ë°®Á§∫ÔºåËøô‰∏™ÂàóË°®Â∞±Âè´sequenceÔºõÂ¶ÇÊûúÂøÖË¶ÅÂ∞±ËøòÂæóÂÅöone-hot encoding„ÄÇ\nÁªìÊûú\n‰ΩÜÊòØÈïøÂ∫¶‰∏çÁªü‰∏Ä\nStep4: ÂØπÈΩêsequence\nËß£ÂÜ≥ÊñπÊ°àÊòØËøôÊ†∑ÁöÑÔºöÂèØ‰ª•Âõ∫ÂÆöÈïøÂ∫¶‰∏∫wÔºåÂä†ÂÖ•‰∏Ä‰∏™Â∫èÂàóÈïøÂ∫¶Â§™ÈïøÔºåÂ∞±Á†çÊéâÂâçÈù¢ÁöÑËØçÔºåÂè™‰øùÁïôÊúÄÂêéw‰∏™ËØçÔºõÂ¶ÇÊûú‰∏Ä‰∏™Â∫èÂàóÂ§™Áü≠ÔºåÂ∞±ÂÅözero paddingÔºåÁî®0Â°´ÂÖÖ\nËøôÊ†∑‰∏ÄÊù•ÔºåÊâÄÊúâÁöÑÂ∫èÂàóÈïøÂ∫¶Â∞±Áªü‰∏Ä‰∫Ü\nÊñáÊú¨Â§ÑÁêÜÂÆåÊàê‰∫ÜÔºåÊé•‰∏ãÊù•ÊòØword embeddingÔºåÊääÂçïËØçË°®Á§∫‰∏∫‰∏Ä‰∏™‰ΩéÁª¥ÂêëÈáèÔºõ\nÁÑ∂ËÄåËøôÊ†∑ÂÅöÁöÑËØùÔºåÂ¶ÇÊûúÊòØ10000‰∏™ÂçïËØçÔºåÁª¥Â∫¶Â∞±ÊòØ10000Áª¥ÔºåÁª¥Â∫¶Â§™È´ò‰∫ÜÔºõÂõ†Ê≠§Ë¶ÅÂÅöword embeddingÔºõ\nÂÖ∑‰ΩìÂÅöÊ≥ïÂ∞±ÊòØÊääone-hotÂêëÈáèe_iÂíåÂèÇÊï∞Áü©ÈòµpÁõ∏‰πòÔºõÁü©ÈòµPËΩ¨ÁΩÆÁöÑÂ§ßÂ∞èÊòØd x vÔºõdÊòØËØçÂêëÈáèÁöÑÁª¥Â∫¶ÔºõvÊòØÂ≠óÂÖ∏ÈáåËØçÊ±áÁöÑÊï∞ÈáèÔºõÁªìÊûú‰∏∫x_iÔºõx_iÂ∞±ÊòØ‰∏Ä‰∏™ËØçÂêëÈáèÔºõÂ¶ÇÊûúone-hotÂêëÈáèÁöÑÁ¨¨‰∏âË°å‰∏∫1ÔºõÈÇ£‰πàx_iÂ∞±ÊòØPËΩ¨ÁΩÆÁü©ÈòµÁöÑÁ¨¨‰∏âÂàóÔºàÂÖ∂‰ΩôÂàóÈÉΩ‰∏∫0ÔºâÔºõÊâÄ‰ª•PËΩ¨ÁΩÆÊØè‰∏ÄÂàóÈÉΩÊòØ‰∏Ä‰∏™ËØçÂêëÈáèÔºõÊâÄ‰ª•Áü©ÈòµPÊú¨Ë∫´ÁöÑÊØè‰∏ÄË°åÂ∞±ÊòØ‰∏Ä‰∏™ËØçÂêëÈáèÔºõÂÖ∂Ë°åÊï∞‰∏∫vÔºõÂç≥vocabularyÔºåËØçÊ±áÈáèÔºõÊØè‰∏ÄË°åÂØπÂ∫î‰∏Ä‰∏™ÂçïËØçÔºõÁü©ÈòµÁöÑÂàóÊï∞‰∏∫dÔºõdÊòØÁî®Êà∑ÂÜ≥ÂÆöÁöÑÔºõdÁöÑÂ§ßÂ∞è‰ºöÂÜ≥ÂÆöÊú∫Âô®Â≠¶‰π†Ê®°ÂûãÁöÑË°®Áé∞ÔºõÂ∫îËØ•Áî®xxxÊù•ÈÄâÊã©‰∏Ä‰∏™ÊØîËæÉÂ•ΩÁöÑdÔºõ\nÊàë‰ª¨ÁöÑ‰ªªÂä°ÊòØÁúãËØÑËÆ∫ÊòØÊ≠£Èù¢ÁöÑËøòÊòØË¥üÈù¢ÁöÑÔºõÂèÇÊï∞Áü©ÈòµÊòØ‰ªéËÆ≠ÁªÉÊï∞ÊçÆ‰∏≠Â≠¶‰π†Âá∫Êù•ÁöÑÔºåÊâÄ‰ª•Â≠¶Âá∫Êù•ÁöÑËØçÂêëÈáèÊòØÂ∏¶ÊúâÊÑüÊÉÖËâ≤ÂΩ©ÁöÑÔºõÂÅáËÆæËøô‰∫õËØçÂêëÈáèÈÉΩÊòØ‰∫åÁª¥ÁöÑÔºåÂàôÂèØ‰ª•Âú®Âπ≥Èù¢ÂùêÊ†áÁ≥ª‰∏≠Ê†áÂá∫‰∏ãÈù¢ËØçÂêëÈáè\nkerasÊèê‰æõembeddingÂ±ÇÔºõÁî®Êà∑ÂèØ‰ª•ÊåáÂÆövocabularyÂ§ßÂ∞èÂíådÁöÑÂ§ßÂ∞èÔºõ‰ª•ÂèäÊØè‰∏Ä‰∏™sequenceÁöÑÈïøÂ∫¶ÔºõdÊòØÊ†πÊçÆÁÆóÊ≥ïÈÄâÂá∫Êù•ÁöÑ Âà∞Ëøô‰∏ÄÊ≠•ÔºåÊàë‰ª¨Â∑≤ÁªèÂÆåÊàê‰∫ÜÊñáÊú¨Â§ÑÁêÜÂíåword embedding„ÄÇÊé•‰∏ãÊù•Â∞±ÊòØÁî®Logistic Regression for Binary ClassificationÂÅö‰∫åÂàÜÁ±ªÔºõ\n","permalink":"http://localhost:1313/posts/nlp-2/","summary":"\u003ch3 id=\"text-to-sequence\"\u003eText to Sequence\u003c/h3\u003e\n\u003cp\u003eÊñáÊú¨Â§ÑÁêÜ\u003c/p\u003e\n\u003cp\u003eStep1: Tokenization\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\n\u003cp\u003eTokenization breaks a piece of text down into a list of tokens.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003eHere, a token is a word. (A token can be a character in some applications.)\u003c/p\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003eTokenizationËÆ≤Á©∂ÂæàÂ§öÔºå‰æãÂ¶ÇÊòØÂê¶Â∫îËØ•ÊääÂ§ßÂÜôÊîπÊàêÂ∞èÂÜôÂë¢ÔºüËøõË°åtypo correctionÁ≠âÁ≠â\u003c/p\u003e\n\u003cp\u003e\u003cimg alt=\"image-20250322150322238\" loading=\"lazy\" src=\"./NLP-2.assets/image-20250322150322238.png\"\u003e\u003c/p\u003e\n\u003cp\u003eStep2: Build Dictionary\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\n\u003cp\u003eUse a dictionary (hash table) to count word frequencies.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003eThe dictionary maps word to index.\u003c/p\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003eÂèØ‰ª•È¶ñÂÖàÁªüËÆ°ËØçÈ¢ëÂéªÊéâ‰ΩéÈ¢ëËØçÔºåÁÑ∂ÂêéËÆ©ÊØè‰∏™ËØçÂØπÂ∫î‰∏Ä‰∏™Ê≠£Êï¥Êï∞ÔºõËøôÊ†∑ÁöÑËØùÔºå‰∏ÄÂè•ËØùÂ∞±ÂèØ‰ª•Áî®‰∏Ä‰∏™Ê≠£Êï¥Êï∞ÂàóË°®Ë°®Á§∫ÔºåËøô‰∏™ÂàóË°®Â∞±Âè´sequenceÔºõÂ¶ÇÊûúÂøÖË¶ÅÂ∞±ËøòÂæóÂÅöone-hot encoding„ÄÇ\u003cimg alt=\"image-20250322150620890\" loading=\"lazy\" src=\"./NLP-2.assets/image-20250322150620890.png\"\u003e\u003c/p\u003e\n\u003cp\u003eÁªìÊûú\u003c/p\u003e\n\u003cp\u003e\u003cimg alt=\"image-20250322150754528\" loading=\"lazy\" src=\"./NLP-2.assets/image-20250322150754528.png\"\u003e\u003c/p\u003e\n\u003cp\u003e‰ΩÜÊòØÈïøÂ∫¶‰∏çÁªü‰∏Ä\u003c/p\u003e\n\u003cp\u003eStep4: ÂØπÈΩêsequence\u003c/p\u003e\n\u003cp\u003e\u003cimg alt=\"image-20250322150854986\" loading=\"lazy\" src=\"./NLP-2.assets/image-20250322150854986.png\"\u003e\u003c/p\u003e\n\u003cp\u003eËß£ÂÜ≥ÊñπÊ°àÊòØËøôÊ†∑ÁöÑÔºöÂèØ‰ª•Âõ∫ÂÆöÈïøÂ∫¶‰∏∫wÔºåÂä†ÂÖ•‰∏Ä‰∏™Â∫èÂàóÈïøÂ∫¶Â§™ÈïøÔºåÂ∞±Á†çÊéâÂâçÈù¢ÁöÑËØçÔºåÂè™‰øùÁïôÊúÄÂêéw‰∏™ËØçÔºõÂ¶ÇÊûú‰∏Ä‰∏™Â∫èÂàóÂ§™Áü≠ÔºåÂ∞±ÂÅözero paddingÔºåÁî®0Â°´ÂÖÖ\u003c/p\u003e\n\u003cp\u003e\u003cimg alt=\"image-20250322151030119\" loading=\"lazy\" src=\"./NLP-2.assets/image-20250322151030119.png\"\u003e\u003c/p\u003e\n\u003cp\u003eËøôÊ†∑‰∏ÄÊù•ÔºåÊâÄÊúâÁöÑÂ∫èÂàóÈïøÂ∫¶Â∞±Áªü‰∏Ä‰∫Ü\u003c/p\u003e\n\u003cp\u003e\u003cimg alt=\"image-20250322151117125\" loading=\"lazy\" src=\"./NLP-2.assets/image-20250322151117125.png\"\u003e\u003c/p\u003e\n\u003cp\u003eÊñáÊú¨Â§ÑÁêÜÂÆåÊàê‰∫ÜÔºåÊé•‰∏ãÊù•ÊòØword embeddingÔºåÊääÂçïËØçË°®Á§∫‰∏∫‰∏Ä‰∏™‰ΩéÁª¥ÂêëÈáèÔºõ\u003c/p\u003e\n\u003cp\u003e\u003cimg alt=\"image-20250322151252837\" loading=\"lazy\" src=\"./NLP-2.assets/image-20250322151252837.png\"\u003e\u003c/p\u003e","title":""},{"content":"üëã About me Recently, inspired by OpenAI\u0026rsquo;s five-step plan towards superintelligence, I have great expectations for AGI and developed a strong interest in LLM agents, MLLM, reinforcement learning, and knowledge graphs. I believe there is significant potential in these fields to create innovative solutions, and I hope to contribute my efforts towards that goal.\nüìö Education üá≠üá∞ The University of Hong Kong 09/2024 - Expected 11/2025 School of Computing and Data Science Master of Science in Electronic Commerce \u0026amp; Internet Computing Relevant Courses: Machine learning for business and e-commerce, Knowledge graphs, Financial fraud analytics, Internet infrastructure technologies, Website engineering, Blockchain and cryptocurrency, etc. üá®üá≥ Beijing Institute of Technology 09/2020 - 06/2024 School of Computer Science \u0026amp; Technology Bachelor of Engineering in Software Engineering, last two years GPA: 3.7/4 Relevant Courses: Reinforcement Learning, Deep Learning and Computer Vision, Artificial Intelligence and Robot Ethics, Almost Human: Mind, Brain and Artificial Intelligence, Mathematical Analysis for Engineering, Linear Algebra, Probability and Mathematical Statistics, etc. Skills: Python, Java, common data structures, design patterns, machine learning basics and algorithms, Linux, PyTorch, and some development tools (git, conda, etc.). üèÜ Awards \u0026amp; Honors Beijing Institute of Technology Undergraduate Scholarship (Top 20% of Grade) 06/2023 3rd Prize of China International \u0026#34;Internet \u0026#43;\u0026#34; College Student\u0026#39;s Innovation Competition 08/2022 Bronze Prize of \u0026#34;Challenge Cup\u0026#34; Capital University Entrepreneurship Competition 05/2022 üíº Project Experience Online Transaction Fraud Detection 09/2024 ‚Äì 01/2025 Independent project, supervised by Dr. Vivien Chan Focused on addressing financial fraud in e-commerce to enhance the accuracy of transaction anomaly detection, while independently managing the entire case study that included data preprocessing, feature engineering, model building, evaluation, and results analysis. Effectively resolved class imbalance issues using SMOTE and ROSE techniques. Built various models including Logistic Regression, Random Forest, XGBoost, and LightGBM, ultimately selecting the LightGBM model to achieve a recall rate of 95.45% and an AUC of 99.84%. Wrote efficient and maintainable code, enhancing model training and data processing efficiency through parallel computing and logging. Multi-Model Intelligent Text Keyword Extraction System 08/2023 ‚Äì 09/2023 Group project, supervised by Associate Prof. Xiaolin Zhao Designed and implemented an intelligent text summary system that automatically extracts keywords from article titles and abstracts, enhancing the understanding and summarization of text information. Participated in the planning of the technical route and built a hybrid model combining extractive and generative approaches, utilizing advanced natural language processing techniques including KeyBERT, Sentence Transformer, BERT, and T5 models. Responsible for data preprocessing and tokenization, as well as the end-to-end implementation and training of the T5 model, optimizing the model architecture and hyperparameters, achieving satisfactory results after only 3 epochs of training. Model evaluation results showed that the Rouge-1, Rouge-2, and Rouge-L metrics reached 0.6345, 0.5038, and 0.5282, respectively, in the third epoch, validating the model\u0026rsquo;s effectiveness in the summarization task. Cambridge University Machine Learning Summer Project 07/2023 ‚Äì 08/2023 Group project, supervised by Prof. Pietro Li√≤ Participated in the Cambridge University deep learning summer project, focusing on deep reinforcement learning; explored multi-agent learning algorithms across different environments. Reproduced the Multi-Agent Deep Deterministic Policy Gradient (MADDPG) algorithm in the Simple Adversary environment and studied the effect of agent numbers on convergence speed and stability, finding optimal stability at 21 agents. Designed and implemented comparative experiments inspired by the Rainbow algorithm, assessing target network strategies versus the Double Deep Q-Network (Double DQN). The results demonstrated that Double DQN significantly enhanced convergence speed, optimizing the overall learning process. Co-authored a group project paper on agent numbers and strategies effectiveness in multi-agent systems, achieving a score of 71% in the summer program (the highest in my group) and a \u0026ldquo;First Class\u0026rdquo; classification in the UK grading system. Deep Learning and Computer Vision Semester Project 09/2022 ‚Äì 12/2022 Independent project, supervised by Associate Prof. Guangyu Gao Designed and implemented a waste classifier using the ResNet model to improve classification accuracy and reduce resource waste. The project also enhanced understanding of transfer learning techniques with ResNet. Collected a dataset of 16 waste categories and preprocessed the images for uniformity and standardization, incorporating data augmentation techniques to enhance the dataset. Conducted experiments using ResNet34 and ResNet50 models through transfer learning, accelerating network convergence by leveraging pretrained weights. During training, techniques such as Batch Normalization and Dropout were applied to mitigate the risk of overfitting. The final model achieved an accuracy of 90% on the training set, while the performance on the test set was 61%, indicating a significant overfitting phenomenon during the training process. üéì Internship Beijing Academy of Quantum Information Science 08/2023 ‚Äì 01/2024 Research Intern at Quantum Computation Department Proposed a quantum convolution kernel design based on variational quantum circuits and developed a universal quantum convolution layer, successfully integrating it into classical CNN architectures such as VGG, GoogLeNet, and ResNet. Developed and evaluated various hybrid models, including a simple model named HQCCNN-2, which achieved 84.45% accuracy on the FashionMNIST dataset, surpassing the traditional CNN\u0026rsquo;s 80.72%. This demonstrates the effectiveness of the quantum convolution layer in improving model performance. Tested on a real quantum computer further validated the effectiveness of the hybrid model, demonstrating the viable integration of quantum computing with deep learning, and highlighting the potential for leveraging quantum properties to enhance model performance. üèÖ Competition Experience China International \u0026#34;Internet \u0026#43;\u0026#34; College Students\u0026#39; Innovation Competition 08/2022 Zhongke Ushield: Deep Learning-based Face Privacy Protection Authentication System Responsible for constructing a localized facial feature extraction engine based on MobileFaceNet, ensuring feature extraction is completed on end devices (such as mobile phones and cameras), guaranteeing that raw data does not leave the domain and is not stored, thus enhancing user privacy protection while improving recognition efficiency. \u0026#34;Challenge Cup\u0026#34; Capital University Entrepreneurship Competition 05/2022 Smart Orchard Responsible for the development of the fruit detection, ripeness prediction, and pest identification system, using deep convolutional neural network (CNN) technology for intelligent monitoring of crop growth conditions. Applied advanced object detection algorithms such as Faster R-CNN and YOLO to achieve high precision in apple detection and ripeness assessment, with an accuracy rate exceeding 90%, significantly enhancing the intelligence level of orchard management. Built and trained a dedicated dataset containing various pest samples, optimizing pest detection accuracy through data preprocessing (such as image normalization and resizing) and data augmentation techniques (like rotation, flipping, and noise addition), enabling the real-time monitoring system to accurately identify over 80% of pests, providing effective scientific maintenance recommendations to help farmers reduce crop losses. üìã Extracurricular Activities Vice President, Cyber Security Club, Beijing Institute of Technology 09/2021-09/2022 Backbone, Media Center of the Student Union of Beijing Institute of Technology 10/2020-06/2021 üì´ Contact üìß zongsi.xu@outlook.com üëî Zongsi (Tristan) Xu üíª github.com/BaizeXS üìç Hong Kong SAR, China ","permalink":"http://localhost:1313/resume/","summary":"Personal resume of Zongsi (Tristan) Xu","title":"Zongsi (Tristan) Xu"},{"content":"‰∏Ä„ÄÅÊï∞ÂÄºÁâπÂæÅ‰∏éÁ±ªÂà´ÁâπÂæÅ Êï∞ÂÄºÁâπÂæÅ (Numeric Features) ÂÖ∑ÊúâÂèØÂä†ÂáèÁöÑÊÑè‰πâÔºå‰∏îÂ≠òÂú®Â§ßÂ∞èÈ°∫Â∫è„ÄÇ ‰æãÂ≠êÔºöÂπ¥ÈæÑ„ÄÅÊ∏©Â∫¶Á≠â„ÄÇÂèØ‰ª•Áõ¥Êé•‰øùÁïôÂÖ∂Êï¥Êï∞ÊàñÊµÆÁÇπÊï∞ÂΩ¢Âºè‰æõÊ®°Âûã‰ΩøÁî®„ÄÇ Á±ªÂà´ÁâπÂæÅ (Categorical Features) Êï∞ÊçÆÂÄºÁ¶ªÊï£Ôºå‰∏çÂÖ∑Â§á‚ÄúÊï∞ÂÄºÂ§ßÂ∞è‚ÄùÈó¥ÁöÑÂèØÊØîÊÑè‰πâ„ÄÇ ‰æãÂ≠êÔºöÂõΩÁ±çÔºàÁæéÂõΩ/‰∏≠ÂõΩ/Âç∞Â∫¶Á≠âÔºâ„ÄÅÊÄßÂà´ÔºàÁî∑/Â•≥ÔºâÁ≠â„ÄÇ ÈóÆÈ¢òÔºöËã•‰ªÖÁî®Êï¥Êï∞Ë°®Á§∫ÔºàÁæéÂõΩ=1, ‰∏≠ÂõΩ=2ÔºâÔºå‰ºöÂºïÂÖ•ÈîôËØØÁöÑÊï∞ÂÄºËøêÁÆóÂÖ≥Á≥ªÔºåÂ¶Ç ‚ÄúÁæéÂõΩ + ‰∏≠ÂõΩ = Âç∞Â∫¶‚Äù„ÄÇ ‰∫å„ÄÅOne-HotÁºñÁ†ÅÁöÑÂä®Êú∫‰∏éÊµÅÁ®ã ‰∏∫‰ªÄ‰πà‰ΩøÁî®One-Hot\nÈÄöËøáÂ∞ÜÁ±ªÂà´Êò†Â∞Ñ‰∏∫ÂêëÈáèÔºåÈÅøÂÖçÊï¥Êï∞ÁºñÁ†ÅÂºïÂÖ•ÁöÑ‰º™Êï∞ÂÄºÂÖ≥Á≥ª„ÄÇ ÂêåÊó∂‰øùÁïôÂêÑÁßçÂèØËÉΩÁ±ªÂà´ÁöÑ‰ø°ÊÅØÔºå‰∏î‰ªÖÂú®ÂØπÂ∫î‰ΩçÁΩÆ‰∏∫1ÔºåÂÖ∂‰ªñ‰ΩçÁΩÆ‰∏∫0„ÄÇ Âª∫Á´ãÊò†Â∞ÑÔºö‰ªéÁ±ªÂà´Âà∞Á¥¢Âºï\n‰∏∫ÊØè‰∏™Á±ªÂà´ÂàÜÈÖç‰∏Ä‰∏™ÂîØ‰∏ÄÁ¥¢ÂºïÔºåÈÄöÂ∏∏‰ªé1ÂºÄÂßã„ÄÇ È¢ÑÁïôÁ¥¢Âºï0Ë°®Á§∫‚ÄúÊú™Áü•‚ÄùÊàñ‚ÄúÁº∫Â§±‚ÄùÔºåÂØπÂ∫îÂÖ®0ÂêëÈáè„ÄÇ ËΩ¨Êç¢‰∏∫One-HotÂêëÈáè\nËã•Á±ªÂà´ÊÄªÊï∞‰∏∫197ÔºåÂàôÁî®197Áª¥ÂêëÈáèË°®Á§∫„ÄÇ ‰æãÂ≠êÔºöÁæéÂõΩ [1, 0, 0, 0, ‚Ä¶]Ôºå ‰∏≠ÂõΩ [0, 1, 0, 0, ‚Ä¶]„ÄÇ Á§∫‰æãÔºöË°®Á§∫‰∏Ä‰∏™‰∫∫ÁöÑÁâπÂæÅ\nÁâπÂæÅÂåÖÂê´ÔºàÂπ¥ÈæÑ, ÊÄßÂà´, ÂõΩÁ±çÔºåÂÖ∂‰∏≠ÂõΩÁ±ç197ÁßçÔºâ Áª¥Â∫¶ÊÄªÂíåÔºö1Áª¥_age + 1Áª¥_gender + 197Áª¥_nationality = 199Áª¥„ÄÇ ‰æãÂ¶Ç (28, Â•≥, ‰∏≠ÂõΩ) ‚Üí [28, 0, 0, 1, 0, ‚Ä¶, 0]„ÄÇ ‰∏â„ÄÅÊñáÊú¨Êï∞ÊçÆÂ§ÑÁêÜÊµÅÁ®ã ÊñáÊú¨Âú®Ëá™ÁÑ∂ËØ≠Ë®ÄÂ§ÑÁêÜÔºàNLPÔºâ‰∏≠‰Ωú‰∏∫Â∏∏ËßÅÁöÑÂéüÂßãËæìÂÖ•ÔºåÈúÄË¶ÅÊï∞ÂÄºÂåñÊâçËÉΩÈÄÅÂÖ•Ê®°Âûã„ÄÇ‰∏ÄËà¨Ê≠•È™§Â¶Ç‰∏ãÔºö\nÂàÜËØç (Tokenization)\nÂ∞ÜÊñáÊú¨ÊãÜÂàÜ‰∏∫‰∏Ä‰∏™‰∏™ÂçïËØçÔºàTokenÔºâ„ÄÇ ‰æãÂ≠êÔºö\u0026quot;... to be or not to be...\u0026quot; ‚Üí [\u0026quot;...\u0026quot;, \u0026quot;to\u0026quot;, \u0026quot;be\u0026quot;, \u0026quot;or\u0026quot;, \u0026quot;not\u0026quot;, \u0026quot;to\u0026quot;, \u0026quot;be\u0026quot;, \u0026quot;...\u0026quot;]„ÄÇ ÁªüËÆ°ËØçÈ¢ë \u0026amp; ÊûÑÂª∫ËØçÂÖ∏\nËØçÈ¢ëÁªüËÆ° Áî®ÂìàÂ∏åË°®/Â≠óÂÖ∏ËÆ∞ÂΩïÊØè‰∏™ÂçïËØçÂá∫Áé∞Ê¨°Êï∞„ÄÇ ÈÅçÂéÜÊñáÊú¨Êó∂ÔºåËã•ÂçïËØçÂ∞öÊú™ÂÖ•Ë°®ÔºåÂàôÊñ∞Âª∫ËÆ∞ÂΩïÔºõËã•Â∑≤Â≠òÂú®ÔºåÂàôËÆ°Êï∞+1„ÄÇ ÊéíÂ∫è‰∏éÁ¥¢Âºï ÊåâËØçÈ¢ëÈôçÂ∫èÊéíÂ∫èÔºåËØçÈ¢ëÊúÄÈ´òÁöÑÂçïËØçÊéíÂú®ÂâçÈù¢„ÄÇ Á¥¢Âºï‰ªé1ÂºÄÂßãÔºå0ÁïôÁªô‚ÄúÊú™Áü•‚Äù„ÄÇ ËØçÂÖ∏ËßÑÊ®°ÔºàvocabularyÔºâÂèØËßÜÈúÄÊ±ÇÊà™Êñ≠Ôºà‰æãÂ¶ÇÂè™‰øùÁïôTop 10kÔºâ„ÄÇ ‰∏∫‰ªÄ‰πàÁßªÈô§‰ΩéÈ¢ëËØç ‰ΩéÈ¢ëËØçÂèØËÉΩÊòØÊãºÂÜôÈîôËØØ„ÄÅÁΩïËßÅ‰∫∫ÂêçÁ≠âÔºåÂØπÊ®°ÂûãÂ∏ÆÂä©ÊúâÈôê„ÄÇ ÂáèÂ∞ëËØçÂÖ∏ËßÑÊ®°ÂèØÈôç‰ΩéËøêÁÆóÂºÄÈîÄ„ÄÅÂä†Âø´Ê®°ÂûãËÆ≠ÁªÉ‰∏éÊé®ÁêÜÈÄüÂ∫¶„ÄÇ Áã¨ÁÉ≠ÁºñÁ†Å (One-Hot Encoding)\nÂ∞ÜÊØè‰∏™ÂçïËØçÊò†Â∞Ñ‰∏∫ËØçÂÖ∏‰∏≠ÁöÑÁ¥¢ÂºïÂêéÔºàÂ¶Ç [2, 4, 1, 8, ‚Ä¶]ÔºâÔºåÂèØËøõ‰∏ÄÊ≠•ËΩ¨Êç¢ÊàêOne-HotÂêëÈáè„ÄÇ One-HotÁª¥Â∫¶ÂèñÂÜ≥‰∫é‰øùÁïô‰∏ãÊù•ÁöÑËØçÂÖ∏Â§ßÂ∞èÔºà‰æãÂ¶Ç1‰∏áÔºâ„ÄÇ Êú™Êî∂ÂΩïÂçïËØçÂèØËÉΩÁõ¥Êé•ÂøΩÁï•ÔºåÊàñÁªü‰∏ÄÁî®Á¥¢Âºï0‰ª£Êõø„ÄÇ Âõõ„ÄÅÊ†∏ÂøÉÊî∂Ëé∑‰∏éÂ∫îÁî® Á±ªÂà´ÁâπÂæÅÂøÖÈúÄÊï∞ÂÄºÂåñÔºö\n‰ΩøÁî®Êï¥Êï∞1,2,3‚Ä¶‰ªÖË°®Á§∫Á±ªÂà´‚ÄúÊ†áËØÜ‚ÄùÔºåÂπ∂‰∏ç‰ª£Ë°®ÂÆÉ‰ª¨ÂèØËøõË°åÊï∞ÂÄºËøêÁÆó„ÄÇ Âõ†Ê≠§ÈúÄË¶ÅOne-HotÁ≠âÁºñÁ†ÅÊñπÂºèÔºåÈÅøÂÖçÊï∞ÂÄºËØØËß£„ÄÇ ÊñáÊú¨Êï∞ÊçÆÈ¢ÑÂ§ÑÁêÜÔºö\nÂàÜËØç„ÄÅËØçÈ¢ëÁªüËÆ°„ÄÅÊûÑÂª∫ËØçÂÖ∏„ÄÅÁ¥¢ÂºïÂåñ„ÄÅOne-HotÊàñÂÖ∂‰ªñÊñπÂºèÔºàÂ¶ÇËØçÂµåÂÖ•ÔºâÊòØÂ∏∏ËßÅÊµÅÁ®ã„ÄÇ Ê≠£Á°ÆÁöÑÊñáÊú¨È¢ÑÂ§ÑÁêÜÂèØÊòæËëóÂΩ±ÂìçÊ®°ÂûãÊÄßËÉΩÂíåÊïàÁéá„ÄÇ ‰øùÁïôÊú™Áü•Á¥¢ÂºïÔºö\n‰øùËØÅÂØπÁº∫Â§±Êï∞ÊçÆÊàñÂ≠óÂÖ∏Â§ñÊñ∞ËØçËÉΩÊúâÂü∫Êú¨ÁöÑË°®Á§∫ÔºåÊèêÂçáÊ®°ÂûãÂÆπÈîôÊÄß„ÄÇ ÂÆûÈôÖ‰ΩøÁî®Ôºö\nÂØπ‰∫éÂ∞èËßÑÊ®°Á±ªÂà´ÂèØÁõ¥Êé•One-HotÁºñÁ†ÅÔºõÂØπ‰∫éËØçÂÖ∏ÂæàÂ§ßÁöÑÂú∫ÊôØÔºåÈÄöÂ∏∏‰ºöËøõ‰∏ÄÊ≠•ËÄÉËôëËØçÂµåÂÖ•ÔºàWord EmbeddingÔºâÊàñÈ¢ÑËÆ≠ÁªÉËØ≠Ë®ÄÊ®°Âûã„ÄÇ ","permalink":"http://localhost:1313/posts/nlp-1/","summary":"\u003ch2 id=\"‰∏ÄÊï∞ÂÄºÁâπÂæÅ‰∏éÁ±ªÂà´ÁâπÂæÅ\"\u003e‰∏Ä„ÄÅÊï∞ÂÄºÁâπÂæÅ‰∏éÁ±ªÂà´ÁâπÂæÅ\u003c/h2\u003e\n\u003col\u003e\n\u003cli\u003e\u003cstrong\u003eÊï∞ÂÄºÁâπÂæÅ (Numeric Features)\u003c/strong\u003e\n\u003cul\u003e\n\u003cli\u003eÂÖ∑ÊúâÂèØÂä†ÂáèÁöÑÊÑè‰πâÔºå‰∏îÂ≠òÂú®Â§ßÂ∞èÈ°∫Â∫è„ÄÇ\u003c/li\u003e\n\u003cli\u003e‰æãÂ≠êÔºöÂπ¥ÈæÑ„ÄÅÊ∏©Â∫¶Á≠â„ÄÇÂèØ‰ª•Áõ¥Êé•‰øùÁïôÂÖ∂Êï¥Êï∞ÊàñÊµÆÁÇπÊï∞ÂΩ¢Âºè‰æõÊ®°Âûã‰ΩøÁî®„ÄÇ\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003eÁ±ªÂà´ÁâπÂæÅ (Categorical Features)\u003c/strong\u003e\n\u003cul\u003e\n\u003cli\u003eÊï∞ÊçÆÂÄºÁ¶ªÊï£Ôºå‰∏çÂÖ∑Â§á‚ÄúÊï∞ÂÄºÂ§ßÂ∞è‚ÄùÈó¥ÁöÑÂèØÊØîÊÑè‰πâ„ÄÇ\u003c/li\u003e\n\u003cli\u003e‰æãÂ≠êÔºöÂõΩÁ±çÔºàÁæéÂõΩ/‰∏≠ÂõΩ/Âç∞Â∫¶Á≠âÔºâ„ÄÅÊÄßÂà´ÔºàÁî∑/Â•≥ÔºâÁ≠â„ÄÇ\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003eÈóÆÈ¢ò\u003c/strong\u003eÔºöËã•‰ªÖÁî®Êï¥Êï∞Ë°®Á§∫ÔºàÁæéÂõΩ=1, ‰∏≠ÂõΩ=2ÔºâÔºå‰ºöÂºïÂÖ•ÈîôËØØÁöÑÊï∞ÂÄºËøêÁÆóÂÖ≥Á≥ªÔºåÂ¶Ç ‚ÄúÁæéÂõΩ + ‰∏≠ÂõΩ = Âç∞Â∫¶‚Äù„ÄÇ\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003c/ol\u003e\n\u003ch2 id=\"‰∫åone-hotÁºñÁ†ÅÁöÑÂä®Êú∫‰∏éÊµÅÁ®ã\"\u003e‰∫å„ÄÅOne-HotÁºñÁ†ÅÁöÑÂä®Êú∫‰∏éÊµÅÁ®ã\u003c/h2\u003e\n\u003col\u003e\n\u003cli\u003e\n\u003cp\u003e\u003cstrong\u003e‰∏∫‰ªÄ‰πà‰ΩøÁî®One-Hot\u003c/strong\u003e\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eÈÄöËøáÂ∞ÜÁ±ªÂà´Êò†Â∞Ñ‰∏∫ÂêëÈáèÔºåÈÅøÂÖçÊï¥Êï∞ÁºñÁ†ÅÂºïÂÖ•ÁöÑ‰º™Êï∞ÂÄºÂÖ≥Á≥ª„ÄÇ\u003c/li\u003e\n\u003cli\u003eÂêåÊó∂‰øùÁïôÂêÑÁßçÂèØËÉΩÁ±ªÂà´ÁöÑ‰ø°ÊÅØÔºå‰∏î‰ªÖÂú®ÂØπÂ∫î‰ΩçÁΩÆ‰∏∫1ÔºåÂÖ∂‰ªñ‰ΩçÁΩÆ‰∏∫0„ÄÇ\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003e\u003cstrong\u003eÂª∫Á´ãÊò†Â∞ÑÔºö‰ªéÁ±ªÂà´Âà∞Á¥¢Âºï\u003c/strong\u003e\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e‰∏∫ÊØè‰∏™Á±ªÂà´ÂàÜÈÖç‰∏Ä‰∏™ÂîØ‰∏ÄÁ¥¢ÂºïÔºåÈÄöÂ∏∏‰ªé1ÂºÄÂßã„ÄÇ\u003c/li\u003e\n\u003cli\u003eÈ¢ÑÁïôÁ¥¢Âºï0Ë°®Á§∫‚ÄúÊú™Áü•‚ÄùÊàñ‚ÄúÁº∫Â§±‚ÄùÔºåÂØπÂ∫îÂÖ®0ÂêëÈáè„ÄÇ\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003e\u003cstrong\u003eËΩ¨Êç¢‰∏∫One-HotÂêëÈáè\u003c/strong\u003e\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eËã•Á±ªÂà´ÊÄªÊï∞‰∏∫197ÔºåÂàôÁî®197Áª¥ÂêëÈáèË°®Á§∫„ÄÇ\u003c/li\u003e\n\u003cli\u003e‰æãÂ≠êÔºöÁæéÂõΩ \u003ccode\u003e[1, 0, 0, 0, ‚Ä¶]\u003c/code\u003eÔºå ‰∏≠ÂõΩ \u003ccode\u003e[0, 1, 0, 0, ‚Ä¶]\u003c/code\u003e„ÄÇ\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003e\u003cstrong\u003eÁ§∫‰æãÔºöË°®Á§∫‰∏Ä‰∏™‰∫∫ÁöÑÁâπÂæÅ\u003c/strong\u003e\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eÁâπÂæÅÂåÖÂê´ÔºàÂπ¥ÈæÑ, ÊÄßÂà´, ÂõΩÁ±çÔºåÂÖ∂‰∏≠ÂõΩÁ±ç197ÁßçÔºâ\u003c/li\u003e\n\u003cli\u003eÁª¥Â∫¶ÊÄªÂíåÔºö1Áª¥_age + 1Áª¥_gender + 197Áª¥_nationality = 199Áª¥„ÄÇ\u003c/li\u003e\n\u003cli\u003e‰æãÂ¶Ç \u003ccode\u003e(28, Â•≥, ‰∏≠ÂõΩ)\u003c/code\u003e ‚Üí \u003ccode\u003e[28, 0, 0, 1, 0, ‚Ä¶, 0]\u003c/code\u003e„ÄÇ\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003c/ol\u003e\n\u003ch2 id=\"‰∏âÊñáÊú¨Êï∞ÊçÆÂ§ÑÁêÜÊµÅÁ®ã\"\u003e‰∏â„ÄÅÊñáÊú¨Êï∞ÊçÆÂ§ÑÁêÜÊµÅÁ®ã\u003c/h2\u003e\n\u003cp\u003eÊñáÊú¨Âú®Ëá™ÁÑ∂ËØ≠Ë®ÄÂ§ÑÁêÜÔºàNLPÔºâ‰∏≠‰Ωú‰∏∫Â∏∏ËßÅÁöÑÂéüÂßãËæìÂÖ•ÔºåÈúÄË¶ÅÊï∞ÂÄºÂåñÊâçËÉΩÈÄÅÂÖ•Ê®°Âûã„ÄÇ‰∏ÄËà¨Ê≠•È™§Â¶Ç‰∏ãÔºö\u003c/p\u003e\n\u003col\u003e\n\u003cli\u003e\n\u003cp\u003e\u003cstrong\u003eÂàÜËØç (Tokenization)\u003c/strong\u003e\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eÂ∞ÜÊñáÊú¨ÊãÜÂàÜ‰∏∫‰∏Ä‰∏™‰∏™ÂçïËØçÔºàTokenÔºâ„ÄÇ\u003c/li\u003e\n\u003cli\u003e‰æãÂ≠êÔºö\u003ccode\u003e\u0026quot;... to be or not to be...\u0026quot;\u003c/code\u003e ‚Üí \u003ccode\u003e[\u0026quot;...\u0026quot;, \u0026quot;to\u0026quot;, \u0026quot;be\u0026quot;, \u0026quot;or\u0026quot;, \u0026quot;not\u0026quot;, \u0026quot;to\u0026quot;, \u0026quot;be\u0026quot;, \u0026quot;...\u0026quot;]\u003c/code\u003e„ÄÇ\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003e\u003cstrong\u003eÁªüËÆ°ËØçÈ¢ë \u0026amp; ÊûÑÂª∫ËØçÂÖ∏\u003c/strong\u003e\u003c/p\u003e","title":""},{"content":"Text to Sequence ÊñáÊú¨Â§ÑÁêÜ\nStep1: Tokenization\nTokenization breaks a piece of text down into a list of tokens.\nHere, a token is a word. (A token can be a character in some applications.)\nTokenizationËÆ≤Á©∂ÂæàÂ§öÔºå‰æãÂ¶ÇÊòØÂê¶Â∫îËØ•ÊääÂ§ßÂÜôÊîπÊàêÂ∞èÂÜôÂë¢ÔºüËøõË°åtypo correctionÁ≠âÁ≠â\nStep2: Build Dictionary\nUse a dictionary (hash table) to count word frequencies.\nThe dictionary maps word to index.\nÂèØ‰ª•È¶ñÂÖàÁªüËÆ°ËØçÈ¢ëÂéªÊéâ‰ΩéÈ¢ëËØçÔºåÁÑ∂ÂêéËÆ©ÊØè‰∏™ËØçÂØπÂ∫î‰∏Ä‰∏™Ê≠£Êï¥Êï∞ÔºõËøôÊ†∑ÁöÑËØùÔºå‰∏ÄÂè•ËØùÂ∞±ÂèØ‰ª•Áî®‰∏Ä‰∏™Ê≠£Êï¥Êï∞ÂàóË°®Ë°®Á§∫ÔºåËøô‰∏™ÂàóË°®Â∞±Âè´sequenceÔºõÂ¶ÇÊûúÂøÖË¶ÅÂ∞±ËøòÂæóÂÅöone-hot encoding„ÄÇ\nÁªìÊûú\n‰ΩÜÊòØÈïøÂ∫¶‰∏çÁªü‰∏Ä\nStep4: ÂØπÈΩêsequence\nËß£ÂÜ≥ÊñπÊ°àÊòØËøôÊ†∑ÁöÑÔºöÂèØ‰ª•Âõ∫ÂÆöÈïøÂ∫¶‰∏∫wÔºåÂä†ÂÖ•‰∏Ä‰∏™Â∫èÂàóÈïøÂ∫¶Â§™ÈïøÔºåÂ∞±Á†çÊéâÂâçÈù¢ÁöÑËØçÔºåÂè™‰øùÁïôÊúÄÂêéw‰∏™ËØçÔºõÂ¶ÇÊûú‰∏Ä‰∏™Â∫èÂàóÂ§™Áü≠ÔºåÂ∞±ÂÅözero paddingÔºåÁî®0Â°´ÂÖÖ\nËøôÊ†∑‰∏ÄÊù•ÔºåÊâÄÊúâÁöÑÂ∫èÂàóÈïøÂ∫¶Â∞±Áªü‰∏Ä‰∫Ü\nÊñáÊú¨Â§ÑÁêÜÂÆåÊàê‰∫ÜÔºåÊé•‰∏ãÊù•ÊòØword embeddingÔºåÊääÂçïËØçË°®Á§∫‰∏∫‰∏Ä‰∏™‰ΩéÁª¥ÂêëÈáèÔºõ\nÁÑ∂ËÄåËøôÊ†∑ÂÅöÁöÑËØùÔºåÂ¶ÇÊûúÊòØ10000‰∏™ÂçïËØçÔºåÁª¥Â∫¶Â∞±ÊòØ10000Áª¥ÔºåÁª¥Â∫¶Â§™È´ò‰∫ÜÔºõÂõ†Ê≠§Ë¶ÅÂÅöword embeddingÔºõ\nÂÖ∑‰ΩìÂÅöÊ≥ïÂ∞±ÊòØÊääone-hotÂêëÈáèe_iÂíåÂèÇÊï∞Áü©ÈòµpÁõ∏‰πòÔºõÁü©ÈòµPËΩ¨ÁΩÆÁöÑÂ§ßÂ∞èÊòØd x vÔºõdÊòØËØçÂêëÈáèÁöÑÁª¥Â∫¶ÔºõvÊòØÂ≠óÂÖ∏ÈáåËØçÊ±áÁöÑÊï∞ÈáèÔºõÁªìÊûú‰∏∫x_iÔºõx_iÂ∞±ÊòØ‰∏Ä‰∏™ËØçÂêëÈáèÔºõÂ¶ÇÊûúone-hotÂêëÈáèÁöÑÁ¨¨‰∏âË°å‰∏∫1ÔºõÈÇ£‰πàx_iÂ∞±ÊòØPËΩ¨ÁΩÆÁü©ÈòµÁöÑÁ¨¨‰∏âÂàóÔºàÂÖ∂‰ΩôÂàóÈÉΩ‰∏∫0ÔºâÔºõÊâÄ‰ª•PËΩ¨ÁΩÆÊØè‰∏ÄÂàóÈÉΩÊòØ‰∏Ä‰∏™ËØçÂêëÈáèÔºõÊâÄ‰ª•Áü©ÈòµPÊú¨Ë∫´ÁöÑÊØè‰∏ÄË°åÂ∞±ÊòØ‰∏Ä‰∏™ËØçÂêëÈáèÔºõÂÖ∂Ë°åÊï∞‰∏∫vÔºõÂç≥vocabularyÔºåËØçÊ±áÈáèÔºõÊØè‰∏ÄË°åÂØπÂ∫î‰∏Ä‰∏™ÂçïËØçÔºõÁü©ÈòµÁöÑÂàóÊï∞‰∏∫dÔºõdÊòØÁî®Êà∑ÂÜ≥ÂÆöÁöÑÔºõdÁöÑÂ§ßÂ∞è‰ºöÂÜ≥ÂÆöÊú∫Âô®Â≠¶‰π†Ê®°ÂûãÁöÑË°®Áé∞ÔºõÂ∫îËØ•Áî®xxxÊù•ÈÄâÊã©‰∏Ä‰∏™ÊØîËæÉÂ•ΩÁöÑdÔºõ\nÊàë‰ª¨ÁöÑ‰ªªÂä°ÊòØÁúãËØÑËÆ∫ÊòØÊ≠£Èù¢ÁöÑËøòÊòØË¥üÈù¢ÁöÑÔºõÂèÇÊï∞Áü©ÈòµÊòØ‰ªéËÆ≠ÁªÉÊï∞ÊçÆ‰∏≠Â≠¶‰π†Âá∫Êù•ÁöÑÔºåÊâÄ‰ª•Â≠¶Âá∫Êù•ÁöÑËØçÂêëÈáèÊòØÂ∏¶ÊúâÊÑüÊÉÖËâ≤ÂΩ©ÁöÑÔºõÂÅáËÆæËøô‰∫õËØçÂêëÈáèÈÉΩÊòØ‰∫åÁª¥ÁöÑÔºåÂàôÂèØ‰ª•Âú®Âπ≥Èù¢ÂùêÊ†áÁ≥ª‰∏≠Ê†áÂá∫‰∏ãÈù¢ËØçÂêëÈáè\nkerasÊèê‰æõembeddingÂ±ÇÔºõÁî®Êà∑ÂèØ‰ª•ÊåáÂÆövocabularyÂ§ßÂ∞èÂíådÁöÑÂ§ßÂ∞èÔºõ‰ª•ÂèäÊØè‰∏Ä‰∏™sequenceÁöÑÈïøÂ∫¶ÔºõdÊòØÊ†πÊçÆÁÆóÊ≥ïÈÄâÂá∫Êù•ÁöÑ Âà∞Ëøô‰∏ÄÊ≠•ÔºåÊàë‰ª¨Â∑≤ÁªèÂÆåÊàê‰∫ÜÊñáÊú¨Â§ÑÁêÜÂíåword embedding„ÄÇÊé•‰∏ãÊù•Â∞±ÊòØÁî®Logistic Regression for Binary ClassificationÂÅö‰∫åÂàÜÁ±ªÔºõ\n","permalink":"http://localhost:1313/posts/nlp-2/","summary":"\u003ch3 id=\"text-to-sequence\"\u003eText to Sequence\u003c/h3\u003e\n\u003cp\u003eÊñáÊú¨Â§ÑÁêÜ\u003c/p\u003e\n\u003cp\u003eStep1: Tokenization\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\n\u003cp\u003eTokenization breaks a piece of text down into a list of tokens.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003eHere, a token is a word. (A token can be a character in some applications.)\u003c/p\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003eTokenizationËÆ≤Á©∂ÂæàÂ§öÔºå‰æãÂ¶ÇÊòØÂê¶Â∫îËØ•ÊääÂ§ßÂÜôÊîπÊàêÂ∞èÂÜôÂë¢ÔºüËøõË°åtypo correctionÁ≠âÁ≠â\u003c/p\u003e\n\u003cp\u003e\u003cimg alt=\"image-20250322150322238\" loading=\"lazy\" src=\"./NLP-2.assets/image-20250322150322238.png\"\u003e\u003c/p\u003e\n\u003cp\u003eStep2: Build Dictionary\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\n\u003cp\u003eUse a dictionary (hash table) to count word frequencies.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003eThe dictionary maps word to index.\u003c/p\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003eÂèØ‰ª•È¶ñÂÖàÁªüËÆ°ËØçÈ¢ëÂéªÊéâ‰ΩéÈ¢ëËØçÔºåÁÑ∂ÂêéËÆ©ÊØè‰∏™ËØçÂØπÂ∫î‰∏Ä‰∏™Ê≠£Êï¥Êï∞ÔºõËøôÊ†∑ÁöÑËØùÔºå‰∏ÄÂè•ËØùÂ∞±ÂèØ‰ª•Áî®‰∏Ä‰∏™Ê≠£Êï¥Êï∞ÂàóË°®Ë°®Á§∫ÔºåËøô‰∏™ÂàóË°®Â∞±Âè´sequenceÔºõÂ¶ÇÊûúÂøÖË¶ÅÂ∞±ËøòÂæóÂÅöone-hot encoding„ÄÇ\u003cimg alt=\"image-20250322150620890\" loading=\"lazy\" src=\"./NLP-2.assets/image-20250322150620890.png\"\u003e\u003c/p\u003e\n\u003cp\u003eÁªìÊûú\u003c/p\u003e\n\u003cp\u003e\u003cimg alt=\"image-20250322150754528\" loading=\"lazy\" src=\"./NLP-2.assets/image-20250322150754528.png\"\u003e\u003c/p\u003e\n\u003cp\u003e‰ΩÜÊòØÈïøÂ∫¶‰∏çÁªü‰∏Ä\u003c/p\u003e\n\u003cp\u003eStep4: ÂØπÈΩêsequence\u003c/p\u003e\n\u003cp\u003e\u003cimg alt=\"image-20250322150854986\" loading=\"lazy\" src=\"./NLP-2.assets/image-20250322150854986.png\"\u003e\u003c/p\u003e\n\u003cp\u003eËß£ÂÜ≥ÊñπÊ°àÊòØËøôÊ†∑ÁöÑÔºöÂèØ‰ª•Âõ∫ÂÆöÈïøÂ∫¶‰∏∫wÔºåÂä†ÂÖ•‰∏Ä‰∏™Â∫èÂàóÈïøÂ∫¶Â§™ÈïøÔºåÂ∞±Á†çÊéâÂâçÈù¢ÁöÑËØçÔºåÂè™‰øùÁïôÊúÄÂêéw‰∏™ËØçÔºõÂ¶ÇÊûú‰∏Ä‰∏™Â∫èÂàóÂ§™Áü≠ÔºåÂ∞±ÂÅözero paddingÔºåÁî®0Â°´ÂÖÖ\u003c/p\u003e\n\u003cp\u003e\u003cimg alt=\"image-20250322151030119\" loading=\"lazy\" src=\"./NLP-2.assets/image-20250322151030119.png\"\u003e\u003c/p\u003e\n\u003cp\u003eËøôÊ†∑‰∏ÄÊù•ÔºåÊâÄÊúâÁöÑÂ∫èÂàóÈïøÂ∫¶Â∞±Áªü‰∏Ä‰∫Ü\u003c/p\u003e\n\u003cp\u003e\u003cimg alt=\"image-20250322151117125\" loading=\"lazy\" src=\"./NLP-2.assets/image-20250322151117125.png\"\u003e\u003c/p\u003e\n\u003cp\u003eÊñáÊú¨Â§ÑÁêÜÂÆåÊàê‰∫ÜÔºåÊé•‰∏ãÊù•ÊòØword embeddingÔºåÊääÂçïËØçË°®Á§∫‰∏∫‰∏Ä‰∏™‰ΩéÁª¥ÂêëÈáèÔºõ\u003c/p\u003e\n\u003cp\u003e\u003cimg alt=\"image-20250322151252837\" loading=\"lazy\" src=\"./NLP-2.assets/image-20250322151252837.png\"\u003e\u003c/p\u003e","title":""},{"content":"üëã About me Hello! I\u0026rsquo;m Xu Zongsi, a passionate technology enthusiast currently pursuing my Master of Science in ECIC at The University of Hong Kong. With a solid background in Software Engineering from the Beijing Institute of Technology, I specialize in emerging areas of artificial intelligence, including machine learning, deep learning, natural language processing, computer vision, and reinforcement learning.\nRecently, inspired by OpenAI\u0026rsquo;s five-step plan towards superintelligence, I have great expectations for AGI and developed a strong interest in LLM agents, MLLM, reinforcement learning, and knowledge graphs. I believe there is significant potential in these fields to create innovative solutions, and I hope to contribute my efforts towards that goal.\nüìö Education üá≠üá∞ The University of Hong Kong 09/2024 - Expected 11/2025 School of Computing and Data Science Master of Science in Electronic Commerce \u0026amp; Internet Computing Relevant Courses: Machine learning for business and e-commerce, Knowledge graphs, Financial fraud analytics, Internet infrastructure technologies, Website engineering, Blockchain and cryptocurrency, etc. üá®üá≥ Beijing Institute of Technology 09/2020 - 06/2024 School of Computer Science \u0026amp; Technology Bachelor of Engineering in Software Engineering, last two years GPA: 3.7/4 Relevant Courses: Reinforcement Learning, Deep Learning and Computer Vision, Artificial Intelligence and Robot Ethics, Almost Human: Mind, Brain and Artificial Intelligence, Mathematical Analysis for Engineering, Linear Algebra, Probability and Mathematical Statistics, etc. Skills: Python, Java, common data structures, design patterns, machine learning basics and algorithms, Linux, PyTorch, and some development tools (git, conda, etc.). üèÜ Awards \u0026amp; Honors Beijing Institute of Technology Undergraduate Scholarship (Top 20% of Grade) 06/2023 3rd Prize of China International \u0026#34;Internet \u0026#43;\u0026#34; College Student\u0026#39;s Innovation Competition 08/2022 Bronze Prize of \u0026#34;Challenge Cup\u0026#34; Capital University Entrepreneurship Competition 05/2022 üíº Project Experience Online Transaction Fraud Detection 09/2024 ‚Äì 01/2025 Independent project, supervised by Dr. Vivien Chan Focused on addressing financial fraud in e-commerce to enhance the accuracy of transaction anomaly detection, while independently managing the entire case study that included data preprocessing, feature engineering, model building, evaluation, and results analysis. Effectively resolved class imbalance issues using SMOTE and ROSE techniques. Built various models including Logistic Regression, Random Forest, XGBoost, and LightGBM, ultimately selecting the LightGBM model to achieve a recall rate of 95.45% and an AUC of 99.84%. Wrote efficient and maintainable code, enhancing model training and data processing efficiency through parallel computing and logging. Multi-Model Intelligent Text Keyword Extraction System 08/2023 ‚Äì 09/2023 Group project, supervised by Associate Prof. Xiaolin Zhao Designed and implemented an intelligent text summary system that automatically extracts keywords from article titles and abstracts, enhancing the understanding and summarization of text information. Participated in the planning of the technical route and built a hybrid model combining extractive and generative approaches, utilizing advanced natural language processing techniques including KeyBERT, Sentence Transformer, BERT, and T5 models. Responsible for data preprocessing and tokenization, as well as the end-to-end implementation and training of the T5 model, optimizing the model architecture and hyperparameters, achieving satisfactory results after only 3 epochs of training. Model evaluation results showed that the Rouge-1, Rouge-2, and Rouge-L metrics reached 0.6345, 0.5038, and 0.5282, respectively, in the third epoch, validating the model\u0026rsquo;s effectiveness in the summarization task. Cambridge University Machine Learning Summer Project 07/2023 ‚Äì 08/2023 Group project, supervised by Prof. Pietro Li√≤ Participated in the Cambridge University deep learning summer project, focusing on deep reinforcement learning; explored multi-agent learning algorithms across different environments. Reproduced the Multi-Agent Deep Deterministic Policy Gradient (MADDPG) algorithm in the Simple Adversary environment and studied the effect of agent numbers on convergence speed and stability, finding optimal stability at 21 agents. Designed and implemented comparative experiments inspired by the Rainbow algorithm, assessing target network strategies versus the Double Deep Q-Network (Double DQN). The results demonstrated that Double DQN significantly enhanced convergence speed, optimizing the overall learning process. Co-authored a group project paper on agent numbers and strategies effectiveness in multi-agent systems, achieving a score of 71% in the summer program (the highest in my group) and a \u0026ldquo;First Class\u0026rdquo; classification in the UK grading system. Deep Learning and Computer Vision Semester Project 09/2022 ‚Äì 12/2022 Independent project, supervised by Associate Prof. Guangyu Gao Designed and implemented a waste classifier using the ResNet model to improve classification accuracy and reduce resource waste. The project also enhanced understanding of transfer learning techniques with ResNet. Collected a dataset of 16 waste categories and preprocessed the images for uniformity and standardization, incorporating data augmentation techniques to enhance the dataset. Conducted experiments using ResNet34 and ResNet50 models through transfer learning, accelerating network convergence by leveraging pretrained weights. During training, techniques such as Batch Normalization and Dropout were applied to mitigate the risk of overfitting. The final model achieved an accuracy of 90% on the training set, while the performance on the test set was 61%, indicating a significant overfitting phenomenon during the training process. üéì Internship Beijing Academy of Quantum Information Science 08/2023 ‚Äì 01/2024 Research Intern at Quantum Computation Department Proposed a quantum convolution kernel design based on variational quantum circuits and developed a universal quantum convolution layer, successfully integrating it into classical CNN architectures such as VGG, GoogLeNet, and ResNet. Developed and evaluated various hybrid models, including a simple model named HQCCNN-2, which achieved 84.45% accuracy on the FashionMNIST dataset, surpassing the traditional CNN\u0026rsquo;s 80.72%. This demonstrates the effectiveness of the quantum convolution layer in improving model performance. Tested on a real quantum computer further validated the effectiveness of the hybrid model, demonstrating the viable integration of quantum computing with deep learning, and highlighting the potential for leveraging quantum properties to enhance model performance. üèÖ Competition Experience China International \u0026#34;Internet \u0026#43;\u0026#34; College Students\u0026#39; Innovation Competition 08/2022 Zhongke Ushield: Deep Learning-based Face Privacy Protection Authentication System Responsible for constructing a localized facial feature extraction engine based on MobileFaceNet, ensuring feature extraction is completed on end devices (such as mobile phones and cameras), guaranteeing that raw data does not leave the domain and is not stored, thus enhancing user privacy protection while improving recognition efficiency. \u0026#34;Challenge Cup\u0026#34; Capital University Entrepreneurship Competition 05/2022 Smart Orchard Responsible for the development of the fruit detection, ripeness prediction, and pest identification system, using deep convolutional neural network (CNN) technology for intelligent monitoring of crop growth conditions. Applied advanced object detection algorithms such as Faster R-CNN and YOLO to achieve high precision in apple detection and ripeness assessment, with an accuracy rate exceeding 90%, significantly enhancing the intelligence level of orchard management. Built and trained a dedicated dataset containing various pest samples, optimizing pest detection accuracy through data preprocessing (such as image normalization and resizing) and data augmentation techniques (like rotation, flipping, and noise addition), enabling the real-time monitoring system to accurately identify over 80% of pests, providing effective scientific maintenance recommendations to help farmers reduce crop losses. üìã Extracurricular Activities Vice President, Cyber Security Club, Beijing Institute of Technology 09/2021-09/2022 Backbone, Media Center of the Student Union of Beijing Institute of Technology 10/2020-06/2021 üì´ Contact üìß zongsi.xu@outlook.com üëî Zongsi (Tristan) Xu üíª github.com/BaizeXS üìç Hong Kong SAR, China ","permalink":"http://localhost:1313/resume/","summary":"Personal resume of Zongsi (Tristan) Xu","title":"Zongsi (Tristan) Xu"},{"content":"‰∏Ä„ÄÅÊï∞ÂÄºÁâπÂæÅ‰∏éÁ±ªÂà´ÁâπÂæÅ Êï∞ÂÄºÁâπÂæÅ (Numeric Features) ÂÖ∑ÊúâÂèØÂä†ÂáèÁöÑÊÑè‰πâÔºå‰∏îÂ≠òÂú®Â§ßÂ∞èÈ°∫Â∫è„ÄÇ ‰æãÂ≠êÔºöÂπ¥ÈæÑ„ÄÅÊ∏©Â∫¶Á≠â„ÄÇÂèØ‰ª•Áõ¥Êé•‰øùÁïôÂÖ∂Êï¥Êï∞ÊàñÊµÆÁÇπÊï∞ÂΩ¢Âºè‰æõÊ®°Âûã‰ΩøÁî®„ÄÇ Á±ªÂà´ÁâπÂæÅ (Categorical Features) Êï∞ÊçÆÂÄºÁ¶ªÊï£Ôºå‰∏çÂÖ∑Â§á‚ÄúÊï∞ÂÄºÂ§ßÂ∞è‚ÄùÈó¥ÁöÑÂèØÊØîÊÑè‰πâ„ÄÇ ‰æãÂ≠êÔºöÂõΩÁ±çÔºàÁæéÂõΩ/‰∏≠ÂõΩ/Âç∞Â∫¶Á≠âÔºâ„ÄÅÊÄßÂà´ÔºàÁî∑/Â•≥ÔºâÁ≠â„ÄÇ ÈóÆÈ¢òÔºöËã•‰ªÖÁî®Êï¥Êï∞Ë°®Á§∫ÔºàÁæéÂõΩ=1, ‰∏≠ÂõΩ=2ÔºâÔºå‰ºöÂºïÂÖ•ÈîôËØØÁöÑÊï∞ÂÄºËøêÁÆóÂÖ≥Á≥ªÔºåÂ¶Ç ‚ÄúÁæéÂõΩ + ‰∏≠ÂõΩ = Âç∞Â∫¶‚Äù„ÄÇ ‰∫å„ÄÅOne-HotÁºñÁ†ÅÁöÑÂä®Êú∫‰∏éÊµÅÁ®ã ‰∏∫‰ªÄ‰πà‰ΩøÁî®One-Hot\nÈÄöËøáÂ∞ÜÁ±ªÂà´Êò†Â∞Ñ‰∏∫ÂêëÈáèÔºåÈÅøÂÖçÊï¥Êï∞ÁºñÁ†ÅÂºïÂÖ•ÁöÑ‰º™Êï∞ÂÄºÂÖ≥Á≥ª„ÄÇ ÂêåÊó∂‰øùÁïôÂêÑÁßçÂèØËÉΩÁ±ªÂà´ÁöÑ‰ø°ÊÅØÔºå‰∏î‰ªÖÂú®ÂØπÂ∫î‰ΩçÁΩÆ‰∏∫1ÔºåÂÖ∂‰ªñ‰ΩçÁΩÆ‰∏∫0„ÄÇ Âª∫Á´ãÊò†Â∞ÑÔºö‰ªéÁ±ªÂà´Âà∞Á¥¢Âºï\n‰∏∫ÊØè‰∏™Á±ªÂà´ÂàÜÈÖç‰∏Ä‰∏™ÂîØ‰∏ÄÁ¥¢ÂºïÔºåÈÄöÂ∏∏‰ªé1ÂºÄÂßã„ÄÇ È¢ÑÁïôÁ¥¢Âºï0Ë°®Á§∫‚ÄúÊú™Áü•‚ÄùÊàñ‚ÄúÁº∫Â§±‚ÄùÔºåÂØπÂ∫îÂÖ®0ÂêëÈáè„ÄÇ ËΩ¨Êç¢‰∏∫One-HotÂêëÈáè\nËã•Á±ªÂà´ÊÄªÊï∞‰∏∫197ÔºåÂàôÁî®197Áª¥ÂêëÈáèË°®Á§∫„ÄÇ ‰æãÂ≠êÔºöÁæéÂõΩ [1, 0, 0, 0, ‚Ä¶]Ôºå ‰∏≠ÂõΩ [0, 1, 0, 0, ‚Ä¶]„ÄÇ Á§∫‰æãÔºöË°®Á§∫‰∏Ä‰∏™‰∫∫ÁöÑÁâπÂæÅ\nÁâπÂæÅÂåÖÂê´ÔºàÂπ¥ÈæÑ, ÊÄßÂà´, ÂõΩÁ±çÔºåÂÖ∂‰∏≠ÂõΩÁ±ç197ÁßçÔºâ Áª¥Â∫¶ÊÄªÂíåÔºö1Áª¥_age + 1Áª¥_gender + 197Áª¥_nationality = 199Áª¥„ÄÇ ‰æãÂ¶Ç (28, Â•≥, ‰∏≠ÂõΩ) ‚Üí [28, 0, 0, 1, 0, ‚Ä¶, 0]„ÄÇ ‰∏â„ÄÅÊñáÊú¨Êï∞ÊçÆÂ§ÑÁêÜÊµÅÁ®ã ÊñáÊú¨Âú®Ëá™ÁÑ∂ËØ≠Ë®ÄÂ§ÑÁêÜÔºàNLPÔºâ‰∏≠‰Ωú‰∏∫Â∏∏ËßÅÁöÑÂéüÂßãËæìÂÖ•ÔºåÈúÄË¶ÅÊï∞ÂÄºÂåñÊâçËÉΩÈÄÅÂÖ•Ê®°Âûã„ÄÇ‰∏ÄËà¨Ê≠•È™§Â¶Ç‰∏ãÔºö\nÂàÜËØç (Tokenization)\nÂ∞ÜÊñáÊú¨ÊãÜÂàÜ‰∏∫‰∏Ä‰∏™‰∏™ÂçïËØçÔºàTokenÔºâ„ÄÇ ‰æãÂ≠êÔºö\u0026quot;... to be or not to be...\u0026quot; ‚Üí [\u0026quot;...\u0026quot;, \u0026quot;to\u0026quot;, \u0026quot;be\u0026quot;, \u0026quot;or\u0026quot;, \u0026quot;not\u0026quot;, \u0026quot;to\u0026quot;, \u0026quot;be\u0026quot;, \u0026quot;...\u0026quot;]„ÄÇ ÁªüËÆ°ËØçÈ¢ë \u0026amp; ÊûÑÂª∫ËØçÂÖ∏\nËØçÈ¢ëÁªüËÆ° Áî®ÂìàÂ∏åË°®/Â≠óÂÖ∏ËÆ∞ÂΩïÊØè‰∏™ÂçïËØçÂá∫Áé∞Ê¨°Êï∞„ÄÇ ÈÅçÂéÜÊñáÊú¨Êó∂ÔºåËã•ÂçïËØçÂ∞öÊú™ÂÖ•Ë°®ÔºåÂàôÊñ∞Âª∫ËÆ∞ÂΩïÔºõËã•Â∑≤Â≠òÂú®ÔºåÂàôËÆ°Êï∞+1„ÄÇ ÊéíÂ∫è‰∏éÁ¥¢Âºï ÊåâËØçÈ¢ëÈôçÂ∫èÊéíÂ∫èÔºåËØçÈ¢ëÊúÄÈ´òÁöÑÂçïËØçÊéíÂú®ÂâçÈù¢„ÄÇ Á¥¢Âºï‰ªé1ÂºÄÂßãÔºå0ÁïôÁªô‚ÄúÊú™Áü•‚Äù„ÄÇ ËØçÂÖ∏ËßÑÊ®°ÔºàvocabularyÔºâÂèØËßÜÈúÄÊ±ÇÊà™Êñ≠Ôºà‰æãÂ¶ÇÂè™‰øùÁïôTop 10kÔºâ„ÄÇ ‰∏∫‰ªÄ‰πàÁßªÈô§‰ΩéÈ¢ëËØç ‰ΩéÈ¢ëËØçÂèØËÉΩÊòØÊãºÂÜôÈîôËØØ„ÄÅÁΩïËßÅ‰∫∫ÂêçÁ≠âÔºåÂØπÊ®°ÂûãÂ∏ÆÂä©ÊúâÈôê„ÄÇ ÂáèÂ∞ëËØçÂÖ∏ËßÑÊ®°ÂèØÈôç‰ΩéËøêÁÆóÂºÄÈîÄ„ÄÅÂä†Âø´Ê®°ÂûãËÆ≠ÁªÉ‰∏éÊé®ÁêÜÈÄüÂ∫¶„ÄÇ Áã¨ÁÉ≠ÁºñÁ†Å (One-Hot Encoding)\nÂ∞ÜÊØè‰∏™ÂçïËØçÊò†Â∞Ñ‰∏∫ËØçÂÖ∏‰∏≠ÁöÑÁ¥¢ÂºïÂêéÔºàÂ¶Ç [2, 4, 1, 8, ‚Ä¶]ÔºâÔºåÂèØËøõ‰∏ÄÊ≠•ËΩ¨Êç¢ÊàêOne-HotÂêëÈáè„ÄÇ One-HotÁª¥Â∫¶ÂèñÂÜ≥‰∫é‰øùÁïô‰∏ãÊù•ÁöÑËØçÂÖ∏Â§ßÂ∞èÔºà‰æãÂ¶Ç1‰∏áÔºâ„ÄÇ Êú™Êî∂ÂΩïÂçïËØçÂèØËÉΩÁõ¥Êé•ÂøΩÁï•ÔºåÊàñÁªü‰∏ÄÁî®Á¥¢Âºï0‰ª£Êõø„ÄÇ Âõõ„ÄÅÊ†∏ÂøÉÊî∂Ëé∑‰∏éÂ∫îÁî® Á±ªÂà´ÁâπÂæÅÂøÖÈúÄÊï∞ÂÄºÂåñÔºö\n‰ΩøÁî®Êï¥Êï∞1,2,3‚Ä¶‰ªÖË°®Á§∫Á±ªÂà´‚ÄúÊ†áËØÜ‚ÄùÔºåÂπ∂‰∏ç‰ª£Ë°®ÂÆÉ‰ª¨ÂèØËøõË°åÊï∞ÂÄºËøêÁÆó„ÄÇ Âõ†Ê≠§ÈúÄË¶ÅOne-HotÁ≠âÁºñÁ†ÅÊñπÂºèÔºåÈÅøÂÖçÊï∞ÂÄºËØØËß£„ÄÇ ÊñáÊú¨Êï∞ÊçÆÈ¢ÑÂ§ÑÁêÜÔºö\nÂàÜËØç„ÄÅËØçÈ¢ëÁªüËÆ°„ÄÅÊûÑÂª∫ËØçÂÖ∏„ÄÅÁ¥¢ÂºïÂåñ„ÄÅOne-HotÊàñÂÖ∂‰ªñÊñπÂºèÔºàÂ¶ÇËØçÂµåÂÖ•ÔºâÊòØÂ∏∏ËßÅÊµÅÁ®ã„ÄÇ Ê≠£Á°ÆÁöÑÊñáÊú¨È¢ÑÂ§ÑÁêÜÂèØÊòæËëóÂΩ±ÂìçÊ®°ÂûãÊÄßËÉΩÂíåÊïàÁéá„ÄÇ ‰øùÁïôÊú™Áü•Á¥¢ÂºïÔºö\n‰øùËØÅÂØπÁº∫Â§±Êï∞ÊçÆÊàñÂ≠óÂÖ∏Â§ñÊñ∞ËØçËÉΩÊúâÂü∫Êú¨ÁöÑË°®Á§∫ÔºåÊèêÂçáÊ®°ÂûãÂÆπÈîôÊÄß„ÄÇ ÂÆûÈôÖ‰ΩøÁî®Ôºö\nÂØπ‰∫éÂ∞èËßÑÊ®°Á±ªÂà´ÂèØÁõ¥Êé•One-HotÁºñÁ†ÅÔºõÂØπ‰∫éËØçÂÖ∏ÂæàÂ§ßÁöÑÂú∫ÊôØÔºåÈÄöÂ∏∏‰ºöËøõ‰∏ÄÊ≠•ËÄÉËôëËØçÂµåÂÖ•ÔºàWord EmbeddingÔºâÊàñÈ¢ÑËÆ≠ÁªÉËØ≠Ë®ÄÊ®°Âûã„ÄÇ ","permalink":"http://localhost:1313/posts/nlp-1/","summary":"\u003ch2 id=\"‰∏ÄÊï∞ÂÄºÁâπÂæÅ‰∏éÁ±ªÂà´ÁâπÂæÅ\"\u003e‰∏Ä„ÄÅÊï∞ÂÄºÁâπÂæÅ‰∏éÁ±ªÂà´ÁâπÂæÅ\u003c/h2\u003e\n\u003col\u003e\n\u003cli\u003e\u003cstrong\u003eÊï∞ÂÄºÁâπÂæÅ (Numeric Features)\u003c/strong\u003e\n\u003cul\u003e\n\u003cli\u003eÂÖ∑ÊúâÂèØÂä†ÂáèÁöÑÊÑè‰πâÔºå‰∏îÂ≠òÂú®Â§ßÂ∞èÈ°∫Â∫è„ÄÇ\u003c/li\u003e\n\u003cli\u003e‰æãÂ≠êÔºöÂπ¥ÈæÑ„ÄÅÊ∏©Â∫¶Á≠â„ÄÇÂèØ‰ª•Áõ¥Êé•‰øùÁïôÂÖ∂Êï¥Êï∞ÊàñÊµÆÁÇπÊï∞ÂΩ¢Âºè‰æõÊ®°Âûã‰ΩøÁî®„ÄÇ\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003eÁ±ªÂà´ÁâπÂæÅ (Categorical Features)\u003c/strong\u003e\n\u003cul\u003e\n\u003cli\u003eÊï∞ÊçÆÂÄºÁ¶ªÊï£Ôºå‰∏çÂÖ∑Â§á‚ÄúÊï∞ÂÄºÂ§ßÂ∞è‚ÄùÈó¥ÁöÑÂèØÊØîÊÑè‰πâ„ÄÇ\u003c/li\u003e\n\u003cli\u003e‰æãÂ≠êÔºöÂõΩÁ±çÔºàÁæéÂõΩ/‰∏≠ÂõΩ/Âç∞Â∫¶Á≠âÔºâ„ÄÅÊÄßÂà´ÔºàÁî∑/Â•≥ÔºâÁ≠â„ÄÇ\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003eÈóÆÈ¢ò\u003c/strong\u003eÔºöËã•‰ªÖÁî®Êï¥Êï∞Ë°®Á§∫ÔºàÁæéÂõΩ=1, ‰∏≠ÂõΩ=2ÔºâÔºå‰ºöÂºïÂÖ•ÈîôËØØÁöÑÊï∞ÂÄºËøêÁÆóÂÖ≥Á≥ªÔºåÂ¶Ç ‚ÄúÁæéÂõΩ + ‰∏≠ÂõΩ = Âç∞Â∫¶‚Äù„ÄÇ\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003c/ol\u003e\n\u003ch2 id=\"‰∫åone-hotÁºñÁ†ÅÁöÑÂä®Êú∫‰∏éÊµÅÁ®ã\"\u003e‰∫å„ÄÅOne-HotÁºñÁ†ÅÁöÑÂä®Êú∫‰∏éÊµÅÁ®ã\u003c/h2\u003e\n\u003col\u003e\n\u003cli\u003e\n\u003cp\u003e\u003cstrong\u003e‰∏∫‰ªÄ‰πà‰ΩøÁî®One-Hot\u003c/strong\u003e\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eÈÄöËøáÂ∞ÜÁ±ªÂà´Êò†Â∞Ñ‰∏∫ÂêëÈáèÔºåÈÅøÂÖçÊï¥Êï∞ÁºñÁ†ÅÂºïÂÖ•ÁöÑ‰º™Êï∞ÂÄºÂÖ≥Á≥ª„ÄÇ\u003c/li\u003e\n\u003cli\u003eÂêåÊó∂‰øùÁïôÂêÑÁßçÂèØËÉΩÁ±ªÂà´ÁöÑ‰ø°ÊÅØÔºå‰∏î‰ªÖÂú®ÂØπÂ∫î‰ΩçÁΩÆ‰∏∫1ÔºåÂÖ∂‰ªñ‰ΩçÁΩÆ‰∏∫0„ÄÇ\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003e\u003cstrong\u003eÂª∫Á´ãÊò†Â∞ÑÔºö‰ªéÁ±ªÂà´Âà∞Á¥¢Âºï\u003c/strong\u003e\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e‰∏∫ÊØè‰∏™Á±ªÂà´ÂàÜÈÖç‰∏Ä‰∏™ÂîØ‰∏ÄÁ¥¢ÂºïÔºåÈÄöÂ∏∏‰ªé1ÂºÄÂßã„ÄÇ\u003c/li\u003e\n\u003cli\u003eÈ¢ÑÁïôÁ¥¢Âºï0Ë°®Á§∫‚ÄúÊú™Áü•‚ÄùÊàñ‚ÄúÁº∫Â§±‚ÄùÔºåÂØπÂ∫îÂÖ®0ÂêëÈáè„ÄÇ\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003e\u003cstrong\u003eËΩ¨Êç¢‰∏∫One-HotÂêëÈáè\u003c/strong\u003e\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eËã•Á±ªÂà´ÊÄªÊï∞‰∏∫197ÔºåÂàôÁî®197Áª¥ÂêëÈáèË°®Á§∫„ÄÇ\u003c/li\u003e\n\u003cli\u003e‰æãÂ≠êÔºöÁæéÂõΩ \u003ccode\u003e[1, 0, 0, 0, ‚Ä¶]\u003c/code\u003eÔºå ‰∏≠ÂõΩ \u003ccode\u003e[0, 1, 0, 0, ‚Ä¶]\u003c/code\u003e„ÄÇ\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003e\u003cstrong\u003eÁ§∫‰æãÔºöË°®Á§∫‰∏Ä‰∏™‰∫∫ÁöÑÁâπÂæÅ\u003c/strong\u003e\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eÁâπÂæÅÂåÖÂê´ÔºàÂπ¥ÈæÑ, ÊÄßÂà´, ÂõΩÁ±çÔºåÂÖ∂‰∏≠ÂõΩÁ±ç197ÁßçÔºâ\u003c/li\u003e\n\u003cli\u003eÁª¥Â∫¶ÊÄªÂíåÔºö1Áª¥_age + 1Áª¥_gender + 197Áª¥_nationality = 199Áª¥„ÄÇ\u003c/li\u003e\n\u003cli\u003e‰æãÂ¶Ç \u003ccode\u003e(28, Â•≥, ‰∏≠ÂõΩ)\u003c/code\u003e ‚Üí \u003ccode\u003e[28, 0, 0, 1, 0, ‚Ä¶, 0]\u003c/code\u003e„ÄÇ\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003c/ol\u003e\n\u003ch2 id=\"‰∏âÊñáÊú¨Êï∞ÊçÆÂ§ÑÁêÜÊµÅÁ®ã\"\u003e‰∏â„ÄÅÊñáÊú¨Êï∞ÊçÆÂ§ÑÁêÜÊµÅÁ®ã\u003c/h2\u003e\n\u003cp\u003eÊñáÊú¨Âú®Ëá™ÁÑ∂ËØ≠Ë®ÄÂ§ÑÁêÜÔºàNLPÔºâ‰∏≠‰Ωú‰∏∫Â∏∏ËßÅÁöÑÂéüÂßãËæìÂÖ•ÔºåÈúÄË¶ÅÊï∞ÂÄºÂåñÊâçËÉΩÈÄÅÂÖ•Ê®°Âûã„ÄÇ‰∏ÄËà¨Ê≠•È™§Â¶Ç‰∏ãÔºö\u003c/p\u003e\n\u003col\u003e\n\u003cli\u003e\n\u003cp\u003e\u003cstrong\u003eÂàÜËØç (Tokenization)\u003c/strong\u003e\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eÂ∞ÜÊñáÊú¨ÊãÜÂàÜ‰∏∫‰∏Ä‰∏™‰∏™ÂçïËØçÔºàTokenÔºâ„ÄÇ\u003c/li\u003e\n\u003cli\u003e‰æãÂ≠êÔºö\u003ccode\u003e\u0026quot;... to be or not to be...\u0026quot;\u003c/code\u003e ‚Üí \u003ccode\u003e[\u0026quot;...\u0026quot;, \u0026quot;to\u0026quot;, \u0026quot;be\u0026quot;, \u0026quot;or\u0026quot;, \u0026quot;not\u0026quot;, \u0026quot;to\u0026quot;, \u0026quot;be\u0026quot;, \u0026quot;...\u0026quot;]\u003c/code\u003e„ÄÇ\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003e\u003cstrong\u003eÁªüËÆ°ËØçÈ¢ë \u0026amp; ÊûÑÂª∫ËØçÂÖ∏\u003c/strong\u003e\u003c/p\u003e","title":""},{"content":"Text to Sequence ÊñáÊú¨Â§ÑÁêÜ\nStep1: Tokenization\nTokenization breaks a piece of text down into a list of tokens.\nHere, a token is a word. (A token can be a character in some applications.)\nTokenizationËÆ≤Á©∂ÂæàÂ§öÔºå‰æãÂ¶ÇÊòØÂê¶Â∫îËØ•ÊääÂ§ßÂÜôÊîπÊàêÂ∞èÂÜôÂë¢ÔºüËøõË°åtypo correctionÁ≠âÁ≠â\nStep2: Build Dictionary\nUse a dictionary (hash table) to count word frequencies.\nThe dictionary maps word to index.\nÂèØ‰ª•È¶ñÂÖàÁªüËÆ°ËØçÈ¢ëÂéªÊéâ‰ΩéÈ¢ëËØçÔºåÁÑ∂ÂêéËÆ©ÊØè‰∏™ËØçÂØπÂ∫î‰∏Ä‰∏™Ê≠£Êï¥Êï∞ÔºõËøôÊ†∑ÁöÑËØùÔºå‰∏ÄÂè•ËØùÂ∞±ÂèØ‰ª•Áî®‰∏Ä‰∏™Ê≠£Êï¥Êï∞ÂàóË°®Ë°®Á§∫ÔºåËøô‰∏™ÂàóË°®Â∞±Âè´sequenceÔºõÂ¶ÇÊûúÂøÖË¶ÅÂ∞±ËøòÂæóÂÅöone-hot encoding„ÄÇ\nÁªìÊûú\n‰ΩÜÊòØÈïøÂ∫¶‰∏çÁªü‰∏Ä\nStep4: ÂØπÈΩêsequence\nËß£ÂÜ≥ÊñπÊ°àÊòØËøôÊ†∑ÁöÑÔºöÂèØ‰ª•Âõ∫ÂÆöÈïøÂ∫¶‰∏∫wÔºåÂä†ÂÖ•‰∏Ä‰∏™Â∫èÂàóÈïøÂ∫¶Â§™ÈïøÔºåÂ∞±Á†çÊéâÂâçÈù¢ÁöÑËØçÔºåÂè™‰øùÁïôÊúÄÂêéw‰∏™ËØçÔºõÂ¶ÇÊûú‰∏Ä‰∏™Â∫èÂàóÂ§™Áü≠ÔºåÂ∞±ÂÅözero paddingÔºåÁî®0Â°´ÂÖÖ\nËøôÊ†∑‰∏ÄÊù•ÔºåÊâÄÊúâÁöÑÂ∫èÂàóÈïøÂ∫¶Â∞±Áªü‰∏Ä‰∫Ü\nÊñáÊú¨Â§ÑÁêÜÂÆåÊàê‰∫ÜÔºåÊé•‰∏ãÊù•ÊòØword embeddingÔºåÊääÂçïËØçË°®Á§∫‰∏∫‰∏Ä‰∏™‰ΩéÁª¥ÂêëÈáèÔºõ\nÁÑ∂ËÄåËøôÊ†∑ÂÅöÁöÑËØùÔºåÂ¶ÇÊûúÊòØ10000‰∏™ÂçïËØçÔºåÁª¥Â∫¶Â∞±ÊòØ10000Áª¥ÔºåÁª¥Â∫¶Â§™È´ò‰∫ÜÔºõÂõ†Ê≠§Ë¶ÅÂÅöword embeddingÔºõ\nÂÖ∑‰ΩìÂÅöÊ≥ïÂ∞±ÊòØÊääone-hotÂêëÈáèe_iÂíåÂèÇÊï∞Áü©ÈòµpÁõ∏‰πòÔºõÁü©ÈòµPËΩ¨ÁΩÆÁöÑÂ§ßÂ∞èÊòØd x vÔºõdÊòØËØçÂêëÈáèÁöÑÁª¥Â∫¶ÔºõvÊòØÂ≠óÂÖ∏ÈáåËØçÊ±áÁöÑÊï∞ÈáèÔºõÁªìÊûú‰∏∫x_iÔºõx_iÂ∞±ÊòØ‰∏Ä‰∏™ËØçÂêëÈáèÔºõÂ¶ÇÊûúone-hotÂêëÈáèÁöÑÁ¨¨‰∏âË°å‰∏∫1ÔºõÈÇ£‰πàx_iÂ∞±ÊòØPËΩ¨ÁΩÆÁü©ÈòµÁöÑÁ¨¨‰∏âÂàóÔºàÂÖ∂‰ΩôÂàóÈÉΩ‰∏∫0ÔºâÔºõÊâÄ‰ª•PËΩ¨ÁΩÆÊØè‰∏ÄÂàóÈÉΩÊòØ‰∏Ä‰∏™ËØçÂêëÈáèÔºõÊâÄ‰ª•Áü©ÈòµPÊú¨Ë∫´ÁöÑÊØè‰∏ÄË°åÂ∞±ÊòØ‰∏Ä‰∏™ËØçÂêëÈáèÔºõÂÖ∂Ë°åÊï∞‰∏∫vÔºõÂç≥vocabularyÔºåËØçÊ±áÈáèÔºõÊØè‰∏ÄË°åÂØπÂ∫î‰∏Ä‰∏™ÂçïËØçÔºõÁü©ÈòµÁöÑÂàóÊï∞‰∏∫dÔºõdÊòØÁî®Êà∑ÂÜ≥ÂÆöÁöÑÔºõdÁöÑÂ§ßÂ∞è‰ºöÂÜ≥ÂÆöÊú∫Âô®Â≠¶‰π†Ê®°ÂûãÁöÑË°®Áé∞ÔºõÂ∫îËØ•Áî®xxxÊù•ÈÄâÊã©‰∏Ä‰∏™ÊØîËæÉÂ•ΩÁöÑdÔºõ\nÊàë‰ª¨ÁöÑ‰ªªÂä°ÊòØÁúãËØÑËÆ∫ÊòØÊ≠£Èù¢ÁöÑËøòÊòØË¥üÈù¢ÁöÑÔºõÂèÇÊï∞Áü©ÈòµÊòØ‰ªéËÆ≠ÁªÉÊï∞ÊçÆ‰∏≠Â≠¶‰π†Âá∫Êù•ÁöÑÔºåÊâÄ‰ª•Â≠¶Âá∫Êù•ÁöÑËØçÂêëÈáèÊòØÂ∏¶ÊúâÊÑüÊÉÖËâ≤ÂΩ©ÁöÑÔºõÂÅáËÆæËøô‰∫õËØçÂêëÈáèÈÉΩÊòØ‰∫åÁª¥ÁöÑÔºåÂàôÂèØ‰ª•Âú®Âπ≥Èù¢ÂùêÊ†áÁ≥ª‰∏≠Ê†áÂá∫‰∏ãÈù¢ËØçÂêëÈáè\nkerasÊèê‰æõembeddingÂ±ÇÔºõÁî®Êà∑ÂèØ‰ª•ÊåáÂÆövocabularyÂ§ßÂ∞èÂíådÁöÑÂ§ßÂ∞èÔºõ‰ª•ÂèäÊØè‰∏Ä‰∏™sequenceÁöÑÈïøÂ∫¶ÔºõdÊòØÊ†πÊçÆÁÆóÊ≥ïÈÄâÂá∫Êù•ÁöÑ Âà∞Ëøô‰∏ÄÊ≠•ÔºåÊàë‰ª¨Â∑≤ÁªèÂÆåÊàê‰∫ÜÊñáÊú¨Â§ÑÁêÜÂíåword embedding„ÄÇÊé•‰∏ãÊù•Â∞±ÊòØÁî®Logistic Regression for Binary ClassificationÂÅö‰∫åÂàÜÁ±ªÔºõ\n","permalink":"http://localhost:1313/posts/nlp-2/","summary":"\u003ch3 id=\"text-to-sequence\"\u003eText to Sequence\u003c/h3\u003e\n\u003cp\u003eÊñáÊú¨Â§ÑÁêÜ\u003c/p\u003e\n\u003cp\u003eStep1: Tokenization\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\n\u003cp\u003eTokenization breaks a piece of text down into a list of tokens.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003eHere, a token is a word. (A token can be a character in some applications.)\u003c/p\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003eTokenizationËÆ≤Á©∂ÂæàÂ§öÔºå‰æãÂ¶ÇÊòØÂê¶Â∫îËØ•ÊääÂ§ßÂÜôÊîπÊàêÂ∞èÂÜôÂë¢ÔºüËøõË°åtypo correctionÁ≠âÁ≠â\u003c/p\u003e\n\u003cp\u003e\u003cimg alt=\"image-20250322150322238\" loading=\"lazy\" src=\"./NLP-2.assets/image-20250322150322238.png\"\u003e\u003c/p\u003e\n\u003cp\u003eStep2: Build Dictionary\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\n\u003cp\u003eUse a dictionary (hash table) to count word frequencies.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003eThe dictionary maps word to index.\u003c/p\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003eÂèØ‰ª•È¶ñÂÖàÁªüËÆ°ËØçÈ¢ëÂéªÊéâ‰ΩéÈ¢ëËØçÔºåÁÑ∂ÂêéËÆ©ÊØè‰∏™ËØçÂØπÂ∫î‰∏Ä‰∏™Ê≠£Êï¥Êï∞ÔºõËøôÊ†∑ÁöÑËØùÔºå‰∏ÄÂè•ËØùÂ∞±ÂèØ‰ª•Áî®‰∏Ä‰∏™Ê≠£Êï¥Êï∞ÂàóË°®Ë°®Á§∫ÔºåËøô‰∏™ÂàóË°®Â∞±Âè´sequenceÔºõÂ¶ÇÊûúÂøÖË¶ÅÂ∞±ËøòÂæóÂÅöone-hot encoding„ÄÇ\u003cimg alt=\"image-20250322150620890\" loading=\"lazy\" src=\"./NLP-2.assets/image-20250322150620890.png\"\u003e\u003c/p\u003e\n\u003cp\u003eÁªìÊûú\u003c/p\u003e\n\u003cp\u003e\u003cimg alt=\"image-20250322150754528\" loading=\"lazy\" src=\"./NLP-2.assets/image-20250322150754528.png\"\u003e\u003c/p\u003e\n\u003cp\u003e‰ΩÜÊòØÈïøÂ∫¶‰∏çÁªü‰∏Ä\u003c/p\u003e\n\u003cp\u003eStep4: ÂØπÈΩêsequence\u003c/p\u003e\n\u003cp\u003e\u003cimg alt=\"image-20250322150854986\" loading=\"lazy\" src=\"./NLP-2.assets/image-20250322150854986.png\"\u003e\u003c/p\u003e\n\u003cp\u003eËß£ÂÜ≥ÊñπÊ°àÊòØËøôÊ†∑ÁöÑÔºöÂèØ‰ª•Âõ∫ÂÆöÈïøÂ∫¶‰∏∫wÔºåÂä†ÂÖ•‰∏Ä‰∏™Â∫èÂàóÈïøÂ∫¶Â§™ÈïøÔºåÂ∞±Á†çÊéâÂâçÈù¢ÁöÑËØçÔºåÂè™‰øùÁïôÊúÄÂêéw‰∏™ËØçÔºõÂ¶ÇÊûú‰∏Ä‰∏™Â∫èÂàóÂ§™Áü≠ÔºåÂ∞±ÂÅözero paddingÔºåÁî®0Â°´ÂÖÖ\u003c/p\u003e\n\u003cp\u003e\u003cimg alt=\"image-20250322151030119\" loading=\"lazy\" src=\"./NLP-2.assets/image-20250322151030119.png\"\u003e\u003c/p\u003e\n\u003cp\u003eËøôÊ†∑‰∏ÄÊù•ÔºåÊâÄÊúâÁöÑÂ∫èÂàóÈïøÂ∫¶Â∞±Áªü‰∏Ä‰∫Ü\u003c/p\u003e\n\u003cp\u003e\u003cimg alt=\"image-20250322151117125\" loading=\"lazy\" src=\"./NLP-2.assets/image-20250322151117125.png\"\u003e\u003c/p\u003e\n\u003cp\u003eÊñáÊú¨Â§ÑÁêÜÂÆåÊàê‰∫ÜÔºåÊé•‰∏ãÊù•ÊòØword embeddingÔºåÊääÂçïËØçË°®Á§∫‰∏∫‰∏Ä‰∏™‰ΩéÁª¥ÂêëÈáèÔºõ\u003c/p\u003e\n\u003cp\u003e\u003cimg alt=\"image-20250322151252837\" loading=\"lazy\" src=\"./NLP-2.assets/image-20250322151252837.png\"\u003e\u003c/p\u003e","title":""},{"content":"üëã About me Hello! I\u0026rsquo;m Xu Zongsi, a passionate technology enthusiast currently pursuing my Master of Science in ECIC at The University of Hong Kong. With a solid background in Software Engineering from the Beijing Institute of Technology, I specialize in emerging areas of artificial intelligence, including machine learning, deep learning, natural language processing, computer vision, and reinforcement learning.\nRecently, inspired by OpenAI\u0026rsquo;s five-step plan towards superintelligence, I have great expectations for AGI and developed a strong interest in LLM agents, MLLM, reinforcement learning, and knowledge graphs. I believe there is significant potential in these fields to create innovative solutions, and I hope to contribute my efforts towards that goal.\nüìö Education üá≠üá∞ The University of Hong Kong 09/2024 - Expected 11/2025 School of Computing and Data Science Master of Science in Electronic Commerce \u0026amp; Internet Computing Relevant Courses: Machine learning for business and e-commerce, Knowledge graphs, Financial fraud analytics, Internet infrastructure technologies, Website engineering, Blockchain and cryptocurrency, etc. üá®üá≥ Beijing Institute of Technology 09/2020 - 06/2024 School of Computer Science \u0026amp; Technology Bachelor of Engineering in Software Engineering, last two years GPA: 3.7/4 Relevant Courses: Reinforcement Learning, Deep Learning and Computer Vision, Artificial Intelligence and Robot Ethics, Almost Human: Mind, Brain and Artificial Intelligence, Mathematical Analysis for Engineering, Linear Algebra, Probability and Mathematical Statistics, etc. Skills: Python, Java, common data structures, design patterns, machine learning basics and algorithms, Linux, PyTorch, and some development tools (git, conda, etc.). üèÜ Awards \u0026amp; Honors Beijing Institute of Technology Undergraduate Scholarship (Top 20% of Grade) 06/2023 3rd Prize of China International \u0026#34;Internet \u0026#43;\u0026#34; College Student\u0026#39;s Innovation Competition 08/2022 Bronze Prize of \u0026#34;Challenge Cup\u0026#34; Capital University Entrepreneurship Competition 05/2022 üíº Project Experience Online Transaction Fraud Detection 09/2024 ‚Äì 01/2025 Independent project, supervised by Dr. Vivien Chan Focused on addressing financial fraud in e-commerce to enhance the accuracy of transaction anomaly detection, while independently managing the entire case study that included data preprocessing, feature engineering, model building, evaluation, and results analysis. Effectively resolved class imbalance issues using SMOTE and ROSE techniques. Built various models including Logistic Regression, Random Forest, XGBoost, and LightGBM, ultimately selecting the LightGBM model to achieve a recall rate of 95.45% and an AUC of 99.84%. Wrote efficient and maintainable code, enhancing model training and data processing efficiency through parallel computing and logging. Multi-Model Intelligent Text Keyword Extraction System 08/2023 ‚Äì 09/2023 Group project, supervised by Associate Prof. Xiaolin Zhao Designed and implemented an intelligent text summary system that automatically extracts keywords from article titles and abstracts, enhancing the understanding and summarization of text information. Participated in the planning of the technical route and built a hybrid model combining extractive and generative approaches, utilizing advanced natural language processing techniques including KeyBERT, Sentence Transformer, BERT, and T5 models. Responsible for data preprocessing and tokenization, as well as the end-to-end implementation and training of the T5 model, optimizing the model architecture and hyperparameters, achieving satisfactory results after only 3 epochs of training. Model evaluation results showed that the Rouge-1, Rouge-2, and Rouge-L metrics reached 0.6345, 0.5038, and 0.5282, respectively, in the third epoch, validating the model\u0026rsquo;s effectiveness in the summarization task. Cambridge University Machine Learning Summer Project 07/2023 ‚Äì 08/2023 Group project, supervised by Prof. Pietro Li√≤ Participated in the Cambridge University deep learning summer project, focusing on deep reinforcement learning; explored multi-agent learning algorithms across different environments. Reproduced the Multi-Agent Deep Deterministic Policy Gradient (MADDPG) algorithm in the Simple Adversary environment and studied the effect of agent numbers on convergence speed and stability, finding optimal stability at 21 agents. Designed and implemented comparative experiments inspired by the Rainbow algorithm, assessing target network strategies versus the Double Deep Q-Network (Double DQN). The results demonstrated that Double DQN significantly enhanced convergence speed, optimizing the overall learning process. Co-authored a group project paper on agent numbers and strategies effectiveness in multi-agent systems, achieving a score of 71% in the summer program (the highest in my group) and a \u0026ldquo;First Class\u0026rdquo; classification in the UK grading system. Deep Learning and Computer Vision Semester Project 09/2022 ‚Äì 12/2022 Independent project, supervised by Associate Prof. Guangyu Gao Designed and implemented a waste classifier using the ResNet model to improve classification accuracy and reduce resource waste. The project also enhanced understanding of transfer learning techniques with ResNet. Collected a dataset of 16 waste categories and preprocessed the images for uniformity and standardization, incorporating data augmentation techniques to enhance the dataset. Conducted experiments using ResNet34 and ResNet50 models through transfer learning, accelerating network convergence by leveraging pretrained weights. During training, techniques such as Batch Normalization and Dropout were applied to mitigate the risk of overfitting. The final model achieved an accuracy of 90% on the training set, while the performance on the test set was 61%, indicating a significant overfitting phenomenon during the training process. üéì Internship Beijing Academy of Quantum Information Science 08/2023 ‚Äì 01/2024 Research Intern at Quantum Computation Department Proposed a quantum convolution kernel design based on variational quantum circuits and developed a universal quantum convolution layer, successfully integrating it into classical CNN architectures such as VGG, GoogLeNet, and ResNet. Developed and evaluated various hybrid models, including a simple model named HQCCNN-2, which achieved 84.45% accuracy on the FashionMNIST dataset, surpassing the traditional CNN\u0026rsquo;s 80.72%. This demonstrates the effectiveness of the quantum convolution layer in improving model performance. Tested on a real quantum computer further validated the effectiveness of the hybrid model, demonstrating the viable integration of quantum computing with deep learning, and highlighting the potential for leveraging quantum properties to enhance model performance. üèÖ Competition Experience China International \u0026#34;Internet \u0026#43;\u0026#34; College Students\u0026#39; Innovation Competition 08/2022 Zhongke Ushield: Deep Learning-based Face Privacy Protection Authentication System Responsible for constructing a localized facial feature extraction engine based on MobileFaceNet, ensuring feature extraction is completed on end devices (such as mobile phones and cameras), guaranteeing that raw data does not leave the domain and is not stored, thus enhancing user privacy protection while improving recognition efficiency. \u0026#34;Challenge Cup\u0026#34; Capital University Entrepreneurship Competition 05/2022 Smart Orchard Responsible for the development of the fruit detection, ripeness prediction, and pest identification system, using deep convolutional neural network (CNN) technology for intelligent monitoring of crop growth conditions. Applied advanced object detection algorithms such as Faster R-CNN and YOLO to achieve high precision in apple detection and ripeness assessment, with an accuracy rate exceeding 90%, significantly enhancing the intelligence level of orchard management. Built and trained a dedicated dataset containing various pest samples, optimizing pest detection accuracy through data preprocessing (such as image normalization and resizing) and data augmentation techniques (like rotation, flipping, and noise addition), enabling the real-time monitoring system to accurately identify over 80% of pests, providing effective scientific maintenance recommendations to help farmers reduce crop losses. üìã Extracurricular Activities Vice President, Cyber Security Club, Beijing Institute of Technology 09/2021-09/2022 Backbone, Media Center of the Student Union of Beijing Institute of Technology 10/2020-06/2021 üì´ Contact üìß zongsi.xu@outlook.com üëî Zongsi (Tristan) Xu üíª github.com/BaizeXS üìç Hong Kong SAR, China ","permalink":"http://localhost:1313/resume/","summary":"Personal resume of Zongsi (Tristan) Xu","title":"Zongsi (Tristan) Xu"},{"content":"‰∏Ä„ÄÅÊï∞ÂÄºÁâπÂæÅ‰∏éÁ±ªÂà´ÁâπÂæÅ Êï∞ÂÄºÁâπÂæÅ (Numeric Features) ÂÖ∑ÊúâÂèØÂä†ÂáèÁöÑÊÑè‰πâÔºå‰∏îÂ≠òÂú®Â§ßÂ∞èÈ°∫Â∫è„ÄÇ ‰æãÂ≠êÔºöÂπ¥ÈæÑ„ÄÅÊ∏©Â∫¶Á≠â„ÄÇÂèØ‰ª•Áõ¥Êé•‰øùÁïôÂÖ∂Êï¥Êï∞ÊàñÊµÆÁÇπÊï∞ÂΩ¢Âºè‰æõÊ®°Âûã‰ΩøÁî®„ÄÇ Á±ªÂà´ÁâπÂæÅ (Categorical Features) Êï∞ÊçÆÂÄºÁ¶ªÊï£Ôºå‰∏çÂÖ∑Â§á‚ÄúÊï∞ÂÄºÂ§ßÂ∞è‚ÄùÈó¥ÁöÑÂèØÊØîÊÑè‰πâ„ÄÇ ‰æãÂ≠êÔºöÂõΩÁ±çÔºàÁæéÂõΩ/‰∏≠ÂõΩ/Âç∞Â∫¶Á≠âÔºâ„ÄÅÊÄßÂà´ÔºàÁî∑/Â•≥ÔºâÁ≠â„ÄÇ ÈóÆÈ¢òÔºöËã•‰ªÖÁî®Êï¥Êï∞Ë°®Á§∫ÔºàÁæéÂõΩ=1, ‰∏≠ÂõΩ=2ÔºâÔºå‰ºöÂºïÂÖ•ÈîôËØØÁöÑÊï∞ÂÄºËøêÁÆóÂÖ≥Á≥ªÔºåÂ¶Ç ‚ÄúÁæéÂõΩ + ‰∏≠ÂõΩ = Âç∞Â∫¶‚Äù„ÄÇ ‰∫å„ÄÅOne-HotÁºñÁ†ÅÁöÑÂä®Êú∫‰∏éÊµÅÁ®ã ‰∏∫‰ªÄ‰πà‰ΩøÁî®One-Hot\nÈÄöËøáÂ∞ÜÁ±ªÂà´Êò†Â∞Ñ‰∏∫ÂêëÈáèÔºåÈÅøÂÖçÊï¥Êï∞ÁºñÁ†ÅÂºïÂÖ•ÁöÑ‰º™Êï∞ÂÄºÂÖ≥Á≥ª„ÄÇ ÂêåÊó∂‰øùÁïôÂêÑÁßçÂèØËÉΩÁ±ªÂà´ÁöÑ‰ø°ÊÅØÔºå‰∏î‰ªÖÂú®ÂØπÂ∫î‰ΩçÁΩÆ‰∏∫1ÔºåÂÖ∂‰ªñ‰ΩçÁΩÆ‰∏∫0„ÄÇ Âª∫Á´ãÊò†Â∞ÑÔºö‰ªéÁ±ªÂà´Âà∞Á¥¢Âºï\n‰∏∫ÊØè‰∏™Á±ªÂà´ÂàÜÈÖç‰∏Ä‰∏™ÂîØ‰∏ÄÁ¥¢ÂºïÔºåÈÄöÂ∏∏‰ªé1ÂºÄÂßã„ÄÇ È¢ÑÁïôÁ¥¢Âºï0Ë°®Á§∫‚ÄúÊú™Áü•‚ÄùÊàñ‚ÄúÁº∫Â§±‚ÄùÔºåÂØπÂ∫îÂÖ®0ÂêëÈáè„ÄÇ ËΩ¨Êç¢‰∏∫One-HotÂêëÈáè\nËã•Á±ªÂà´ÊÄªÊï∞‰∏∫197ÔºåÂàôÁî®197Áª¥ÂêëÈáèË°®Á§∫„ÄÇ ‰æãÂ≠êÔºöÁæéÂõΩ [1, 0, 0, 0, ‚Ä¶]Ôºå ‰∏≠ÂõΩ [0, 1, 0, 0, ‚Ä¶]„ÄÇ Á§∫‰æãÔºöË°®Á§∫‰∏Ä‰∏™‰∫∫ÁöÑÁâπÂæÅ\nÁâπÂæÅÂåÖÂê´ÔºàÂπ¥ÈæÑ, ÊÄßÂà´, ÂõΩÁ±çÔºåÂÖ∂‰∏≠ÂõΩÁ±ç197ÁßçÔºâ Áª¥Â∫¶ÊÄªÂíåÔºö1Áª¥_age + 1Áª¥_gender + 197Áª¥_nationality = 199Áª¥„ÄÇ ‰æãÂ¶Ç (28, Â•≥, ‰∏≠ÂõΩ) ‚Üí [28, 0, 0, 1, 0, ‚Ä¶, 0]„ÄÇ ‰∏â„ÄÅÊñáÊú¨Êï∞ÊçÆÂ§ÑÁêÜÊµÅÁ®ã ÊñáÊú¨Âú®Ëá™ÁÑ∂ËØ≠Ë®ÄÂ§ÑÁêÜÔºàNLPÔºâ‰∏≠‰Ωú‰∏∫Â∏∏ËßÅÁöÑÂéüÂßãËæìÂÖ•ÔºåÈúÄË¶ÅÊï∞ÂÄºÂåñÊâçËÉΩÈÄÅÂÖ•Ê®°Âûã„ÄÇ‰∏ÄËà¨Ê≠•È™§Â¶Ç‰∏ãÔºö\nÂàÜËØç (Tokenization)\nÂ∞ÜÊñáÊú¨ÊãÜÂàÜ‰∏∫‰∏Ä‰∏™‰∏™ÂçïËØçÔºàTokenÔºâ„ÄÇ ‰æãÂ≠êÔºö\u0026quot;... to be or not to be...\u0026quot; ‚Üí [\u0026quot;...\u0026quot;, \u0026quot;to\u0026quot;, \u0026quot;be\u0026quot;, \u0026quot;or\u0026quot;, \u0026quot;not\u0026quot;, \u0026quot;to\u0026quot;, \u0026quot;be\u0026quot;, \u0026quot;...\u0026quot;]„ÄÇ ÁªüËÆ°ËØçÈ¢ë \u0026amp; ÊûÑÂª∫ËØçÂÖ∏\nËØçÈ¢ëÁªüËÆ° Áî®ÂìàÂ∏åË°®/Â≠óÂÖ∏ËÆ∞ÂΩïÊØè‰∏™ÂçïËØçÂá∫Áé∞Ê¨°Êï∞„ÄÇ ÈÅçÂéÜÊñáÊú¨Êó∂ÔºåËã•ÂçïËØçÂ∞öÊú™ÂÖ•Ë°®ÔºåÂàôÊñ∞Âª∫ËÆ∞ÂΩïÔºõËã•Â∑≤Â≠òÂú®ÔºåÂàôËÆ°Êï∞+1„ÄÇ ÊéíÂ∫è‰∏éÁ¥¢Âºï ÊåâËØçÈ¢ëÈôçÂ∫èÊéíÂ∫èÔºåËØçÈ¢ëÊúÄÈ´òÁöÑÂçïËØçÊéíÂú®ÂâçÈù¢„ÄÇ Á¥¢Âºï‰ªé1ÂºÄÂßãÔºå0ÁïôÁªô‚ÄúÊú™Áü•‚Äù„ÄÇ ËØçÂÖ∏ËßÑÊ®°ÔºàvocabularyÔºâÂèØËßÜÈúÄÊ±ÇÊà™Êñ≠Ôºà‰æãÂ¶ÇÂè™‰øùÁïôTop 10kÔºâ„ÄÇ ‰∏∫‰ªÄ‰πàÁßªÈô§‰ΩéÈ¢ëËØç ‰ΩéÈ¢ëËØçÂèØËÉΩÊòØÊãºÂÜôÈîôËØØ„ÄÅÁΩïËßÅ‰∫∫ÂêçÁ≠âÔºåÂØπÊ®°ÂûãÂ∏ÆÂä©ÊúâÈôê„ÄÇ ÂáèÂ∞ëËØçÂÖ∏ËßÑÊ®°ÂèØÈôç‰ΩéËøêÁÆóÂºÄÈîÄ„ÄÅÂä†Âø´Ê®°ÂûãËÆ≠ÁªÉ‰∏éÊé®ÁêÜÈÄüÂ∫¶„ÄÇ Áã¨ÁÉ≠ÁºñÁ†Å (One-Hot Encoding)\nÂ∞ÜÊØè‰∏™ÂçïËØçÊò†Â∞Ñ‰∏∫ËØçÂÖ∏‰∏≠ÁöÑÁ¥¢ÂºïÂêéÔºàÂ¶Ç [2, 4, 1, 8, ‚Ä¶]ÔºâÔºåÂèØËøõ‰∏ÄÊ≠•ËΩ¨Êç¢ÊàêOne-HotÂêëÈáè„ÄÇ One-HotÁª¥Â∫¶ÂèñÂÜ≥‰∫é‰øùÁïô‰∏ãÊù•ÁöÑËØçÂÖ∏Â§ßÂ∞èÔºà‰æãÂ¶Ç1‰∏áÔºâ„ÄÇ Êú™Êî∂ÂΩïÂçïËØçÂèØËÉΩÁõ¥Êé•ÂøΩÁï•ÔºåÊàñÁªü‰∏ÄÁî®Á¥¢Âºï0‰ª£Êõø„ÄÇ Âõõ„ÄÅÊ†∏ÂøÉÊî∂Ëé∑‰∏éÂ∫îÁî® Á±ªÂà´ÁâπÂæÅÂøÖÈúÄÊï∞ÂÄºÂåñÔºö\n‰ΩøÁî®Êï¥Êï∞1,2,3‚Ä¶‰ªÖË°®Á§∫Á±ªÂà´‚ÄúÊ†áËØÜ‚ÄùÔºåÂπ∂‰∏ç‰ª£Ë°®ÂÆÉ‰ª¨ÂèØËøõË°åÊï∞ÂÄºËøêÁÆó„ÄÇ Âõ†Ê≠§ÈúÄË¶ÅOne-HotÁ≠âÁºñÁ†ÅÊñπÂºèÔºåÈÅøÂÖçÊï∞ÂÄºËØØËß£„ÄÇ ÊñáÊú¨Êï∞ÊçÆÈ¢ÑÂ§ÑÁêÜÔºö\nÂàÜËØç„ÄÅËØçÈ¢ëÁªüËÆ°„ÄÅÊûÑÂª∫ËØçÂÖ∏„ÄÅÁ¥¢ÂºïÂåñ„ÄÅOne-HotÊàñÂÖ∂‰ªñÊñπÂºèÔºàÂ¶ÇËØçÂµåÂÖ•ÔºâÊòØÂ∏∏ËßÅÊµÅÁ®ã„ÄÇ Ê≠£Á°ÆÁöÑÊñáÊú¨È¢ÑÂ§ÑÁêÜÂèØÊòæËëóÂΩ±ÂìçÊ®°ÂûãÊÄßËÉΩÂíåÊïàÁéá„ÄÇ ‰øùÁïôÊú™Áü•Á¥¢ÂºïÔºö\n‰øùËØÅÂØπÁº∫Â§±Êï∞ÊçÆÊàñÂ≠óÂÖ∏Â§ñÊñ∞ËØçËÉΩÊúâÂü∫Êú¨ÁöÑË°®Á§∫ÔºåÊèêÂçáÊ®°ÂûãÂÆπÈîôÊÄß„ÄÇ ÂÆûÈôÖ‰ΩøÁî®Ôºö\nÂØπ‰∫éÂ∞èËßÑÊ®°Á±ªÂà´ÂèØÁõ¥Êé•One-HotÁºñÁ†ÅÔºõÂØπ‰∫éËØçÂÖ∏ÂæàÂ§ßÁöÑÂú∫ÊôØÔºåÈÄöÂ∏∏‰ºöËøõ‰∏ÄÊ≠•ËÄÉËôëËØçÂµåÂÖ•ÔºàWord EmbeddingÔºâÊàñÈ¢ÑËÆ≠ÁªÉËØ≠Ë®ÄÊ®°Âûã„ÄÇ ","permalink":"http://localhost:1313/posts/nlp-1/","summary":"\u003ch2 id=\"‰∏ÄÊï∞ÂÄºÁâπÂæÅ‰∏éÁ±ªÂà´ÁâπÂæÅ\"\u003e‰∏Ä„ÄÅÊï∞ÂÄºÁâπÂæÅ‰∏éÁ±ªÂà´ÁâπÂæÅ\u003c/h2\u003e\n\u003col\u003e\n\u003cli\u003e\u003cstrong\u003eÊï∞ÂÄºÁâπÂæÅ (Numeric Features)\u003c/strong\u003e\n\u003cul\u003e\n\u003cli\u003eÂÖ∑ÊúâÂèØÂä†ÂáèÁöÑÊÑè‰πâÔºå‰∏îÂ≠òÂú®Â§ßÂ∞èÈ°∫Â∫è„ÄÇ\u003c/li\u003e\n\u003cli\u003e‰æãÂ≠êÔºöÂπ¥ÈæÑ„ÄÅÊ∏©Â∫¶Á≠â„ÄÇÂèØ‰ª•Áõ¥Êé•‰øùÁïôÂÖ∂Êï¥Êï∞ÊàñÊµÆÁÇπÊï∞ÂΩ¢Âºè‰æõÊ®°Âûã‰ΩøÁî®„ÄÇ\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003eÁ±ªÂà´ÁâπÂæÅ (Categorical Features)\u003c/strong\u003e\n\u003cul\u003e\n\u003cli\u003eÊï∞ÊçÆÂÄºÁ¶ªÊï£Ôºå‰∏çÂÖ∑Â§á‚ÄúÊï∞ÂÄºÂ§ßÂ∞è‚ÄùÈó¥ÁöÑÂèØÊØîÊÑè‰πâ„ÄÇ\u003c/li\u003e\n\u003cli\u003e‰æãÂ≠êÔºöÂõΩÁ±çÔºàÁæéÂõΩ/‰∏≠ÂõΩ/Âç∞Â∫¶Á≠âÔºâ„ÄÅÊÄßÂà´ÔºàÁî∑/Â•≥ÔºâÁ≠â„ÄÇ\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003eÈóÆÈ¢ò\u003c/strong\u003eÔºöËã•‰ªÖÁî®Êï¥Êï∞Ë°®Á§∫ÔºàÁæéÂõΩ=1, ‰∏≠ÂõΩ=2ÔºâÔºå‰ºöÂºïÂÖ•ÈîôËØØÁöÑÊï∞ÂÄºËøêÁÆóÂÖ≥Á≥ªÔºåÂ¶Ç ‚ÄúÁæéÂõΩ + ‰∏≠ÂõΩ = Âç∞Â∫¶‚Äù„ÄÇ\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003c/ol\u003e\n\u003ch2 id=\"‰∫åone-hotÁºñÁ†ÅÁöÑÂä®Êú∫‰∏éÊµÅÁ®ã\"\u003e‰∫å„ÄÅOne-HotÁºñÁ†ÅÁöÑÂä®Êú∫‰∏éÊµÅÁ®ã\u003c/h2\u003e\n\u003col\u003e\n\u003cli\u003e\n\u003cp\u003e\u003cstrong\u003e‰∏∫‰ªÄ‰πà‰ΩøÁî®One-Hot\u003c/strong\u003e\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eÈÄöËøáÂ∞ÜÁ±ªÂà´Êò†Â∞Ñ‰∏∫ÂêëÈáèÔºåÈÅøÂÖçÊï¥Êï∞ÁºñÁ†ÅÂºïÂÖ•ÁöÑ‰º™Êï∞ÂÄºÂÖ≥Á≥ª„ÄÇ\u003c/li\u003e\n\u003cli\u003eÂêåÊó∂‰øùÁïôÂêÑÁßçÂèØËÉΩÁ±ªÂà´ÁöÑ‰ø°ÊÅØÔºå‰∏î‰ªÖÂú®ÂØπÂ∫î‰ΩçÁΩÆ‰∏∫1ÔºåÂÖ∂‰ªñ‰ΩçÁΩÆ‰∏∫0„ÄÇ\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003e\u003cstrong\u003eÂª∫Á´ãÊò†Â∞ÑÔºö‰ªéÁ±ªÂà´Âà∞Á¥¢Âºï\u003c/strong\u003e\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e‰∏∫ÊØè‰∏™Á±ªÂà´ÂàÜÈÖç‰∏Ä‰∏™ÂîØ‰∏ÄÁ¥¢ÂºïÔºåÈÄöÂ∏∏‰ªé1ÂºÄÂßã„ÄÇ\u003c/li\u003e\n\u003cli\u003eÈ¢ÑÁïôÁ¥¢Âºï0Ë°®Á§∫‚ÄúÊú™Áü•‚ÄùÊàñ‚ÄúÁº∫Â§±‚ÄùÔºåÂØπÂ∫îÂÖ®0ÂêëÈáè„ÄÇ\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003e\u003cstrong\u003eËΩ¨Êç¢‰∏∫One-HotÂêëÈáè\u003c/strong\u003e\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eËã•Á±ªÂà´ÊÄªÊï∞‰∏∫197ÔºåÂàôÁî®197Áª¥ÂêëÈáèË°®Á§∫„ÄÇ\u003c/li\u003e\n\u003cli\u003e‰æãÂ≠êÔºöÁæéÂõΩ \u003ccode\u003e[1, 0, 0, 0, ‚Ä¶]\u003c/code\u003eÔºå ‰∏≠ÂõΩ \u003ccode\u003e[0, 1, 0, 0, ‚Ä¶]\u003c/code\u003e„ÄÇ\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003e\u003cstrong\u003eÁ§∫‰æãÔºöË°®Á§∫‰∏Ä‰∏™‰∫∫ÁöÑÁâπÂæÅ\u003c/strong\u003e\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eÁâπÂæÅÂåÖÂê´ÔºàÂπ¥ÈæÑ, ÊÄßÂà´, ÂõΩÁ±çÔºåÂÖ∂‰∏≠ÂõΩÁ±ç197ÁßçÔºâ\u003c/li\u003e\n\u003cli\u003eÁª¥Â∫¶ÊÄªÂíåÔºö1Áª¥_age + 1Áª¥_gender + 197Áª¥_nationality = 199Áª¥„ÄÇ\u003c/li\u003e\n\u003cli\u003e‰æãÂ¶Ç \u003ccode\u003e(28, Â•≥, ‰∏≠ÂõΩ)\u003c/code\u003e ‚Üí \u003ccode\u003e[28, 0, 0, 1, 0, ‚Ä¶, 0]\u003c/code\u003e„ÄÇ\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003c/ol\u003e\n\u003ch2 id=\"‰∏âÊñáÊú¨Êï∞ÊçÆÂ§ÑÁêÜÊµÅÁ®ã\"\u003e‰∏â„ÄÅÊñáÊú¨Êï∞ÊçÆÂ§ÑÁêÜÊµÅÁ®ã\u003c/h2\u003e\n\u003cp\u003eÊñáÊú¨Âú®Ëá™ÁÑ∂ËØ≠Ë®ÄÂ§ÑÁêÜÔºàNLPÔºâ‰∏≠‰Ωú‰∏∫Â∏∏ËßÅÁöÑÂéüÂßãËæìÂÖ•ÔºåÈúÄË¶ÅÊï∞ÂÄºÂåñÊâçËÉΩÈÄÅÂÖ•Ê®°Âûã„ÄÇ‰∏ÄËà¨Ê≠•È™§Â¶Ç‰∏ãÔºö\u003c/p\u003e\n\u003col\u003e\n\u003cli\u003e\n\u003cp\u003e\u003cstrong\u003eÂàÜËØç (Tokenization)\u003c/strong\u003e\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eÂ∞ÜÊñáÊú¨ÊãÜÂàÜ‰∏∫‰∏Ä‰∏™‰∏™ÂçïËØçÔºàTokenÔºâ„ÄÇ\u003c/li\u003e\n\u003cli\u003e‰æãÂ≠êÔºö\u003ccode\u003e\u0026quot;... to be or not to be...\u0026quot;\u003c/code\u003e ‚Üí \u003ccode\u003e[\u0026quot;...\u0026quot;, \u0026quot;to\u0026quot;, \u0026quot;be\u0026quot;, \u0026quot;or\u0026quot;, \u0026quot;not\u0026quot;, \u0026quot;to\u0026quot;, \u0026quot;be\u0026quot;, \u0026quot;...\u0026quot;]\u003c/code\u003e„ÄÇ\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003e\u003cstrong\u003eÁªüËÆ°ËØçÈ¢ë \u0026amp; ÊûÑÂª∫ËØçÂÖ∏\u003c/strong\u003e\u003c/p\u003e","title":""},{"content":"Text to Sequence ÊñáÊú¨Â§ÑÁêÜ\nStep1: Tokenization\nTokenization breaks a piece of text down into a list of tokens.\nHere, a token is a word. (A token can be a character in some applications.)\nTokenizationËÆ≤Á©∂ÂæàÂ§öÔºå‰æãÂ¶ÇÊòØÂê¶Â∫îËØ•ÊääÂ§ßÂÜôÊîπÊàêÂ∞èÂÜôÂë¢ÔºüËøõË°åtypo correctionÁ≠âÁ≠â\nStep2: Build Dictionary\nUse a dictionary (hash table) to count word frequencies.\nThe dictionary maps word to index.\nÂèØ‰ª•È¶ñÂÖàÁªüËÆ°ËØçÈ¢ëÂéªÊéâ‰ΩéÈ¢ëËØçÔºåÁÑ∂ÂêéËÆ©ÊØè‰∏™ËØçÂØπÂ∫î‰∏Ä‰∏™Ê≠£Êï¥Êï∞ÔºõËøôÊ†∑ÁöÑËØùÔºå‰∏ÄÂè•ËØùÂ∞±ÂèØ‰ª•Áî®‰∏Ä‰∏™Ê≠£Êï¥Êï∞ÂàóË°®Ë°®Á§∫ÔºåËøô‰∏™ÂàóË°®Â∞±Âè´sequenceÔºõÂ¶ÇÊûúÂøÖË¶ÅÂ∞±ËøòÂæóÂÅöone-hot encoding„ÄÇ\nÁªìÊûú\n‰ΩÜÊòØÈïøÂ∫¶‰∏çÁªü‰∏Ä\nStep4: ÂØπÈΩêsequence\nËß£ÂÜ≥ÊñπÊ°àÊòØËøôÊ†∑ÁöÑÔºöÂèØ‰ª•Âõ∫ÂÆöÈïøÂ∫¶‰∏∫wÔºåÂä†ÂÖ•‰∏Ä‰∏™Â∫èÂàóÈïøÂ∫¶Â§™ÈïøÔºåÂ∞±Á†çÊéâÂâçÈù¢ÁöÑËØçÔºåÂè™‰øùÁïôÊúÄÂêéw‰∏™ËØçÔºõÂ¶ÇÊûú‰∏Ä‰∏™Â∫èÂàóÂ§™Áü≠ÔºåÂ∞±ÂÅözero paddingÔºåÁî®0Â°´ÂÖÖ\nËøôÊ†∑‰∏ÄÊù•ÔºåÊâÄÊúâÁöÑÂ∫èÂàóÈïøÂ∫¶Â∞±Áªü‰∏Ä‰∫Ü\nÊñáÊú¨Â§ÑÁêÜÂÆåÊàê‰∫ÜÔºåÊé•‰∏ãÊù•ÊòØword embeddingÔºåÊääÂçïËØçË°®Á§∫‰∏∫‰∏Ä‰∏™‰ΩéÁª¥ÂêëÈáèÔºõ\nÁÑ∂ËÄåËøôÊ†∑ÂÅöÁöÑËØùÔºåÂ¶ÇÊûúÊòØ10000‰∏™ÂçïËØçÔºåÁª¥Â∫¶Â∞±ÊòØ10000Áª¥ÔºåÁª¥Â∫¶Â§™È´ò‰∫ÜÔºõÂõ†Ê≠§Ë¶ÅÂÅöword embeddingÔºõ\nÂÖ∑‰ΩìÂÅöÊ≥ïÂ∞±ÊòØÊääone-hotÂêëÈáèe_iÂíåÂèÇÊï∞Áü©ÈòµpÁõ∏‰πòÔºõÁü©ÈòµPËΩ¨ÁΩÆÁöÑÂ§ßÂ∞èÊòØd x vÔºõdÊòØËØçÂêëÈáèÁöÑÁª¥Â∫¶ÔºõvÊòØÂ≠óÂÖ∏ÈáåËØçÊ±áÁöÑÊï∞ÈáèÔºõÁªìÊûú‰∏∫x_iÔºõx_iÂ∞±ÊòØ‰∏Ä‰∏™ËØçÂêëÈáèÔºõÂ¶ÇÊûúone-hotÂêëÈáèÁöÑÁ¨¨‰∏âË°å‰∏∫1ÔºõÈÇ£‰πàx_iÂ∞±ÊòØPËΩ¨ÁΩÆÁü©ÈòµÁöÑÁ¨¨‰∏âÂàóÔºàÂÖ∂‰ΩôÂàóÈÉΩ‰∏∫0ÔºâÔºõÊâÄ‰ª•PËΩ¨ÁΩÆÊØè‰∏ÄÂàóÈÉΩÊòØ‰∏Ä‰∏™ËØçÂêëÈáèÔºõÊâÄ‰ª•Áü©ÈòµPÊú¨Ë∫´ÁöÑÊØè‰∏ÄË°åÂ∞±ÊòØ‰∏Ä‰∏™ËØçÂêëÈáèÔºõÂÖ∂Ë°åÊï∞‰∏∫vÔºõÂç≥vocabularyÔºåËØçÊ±áÈáèÔºõÊØè‰∏ÄË°åÂØπÂ∫î‰∏Ä‰∏™ÂçïËØçÔºõÁü©ÈòµÁöÑÂàóÊï∞‰∏∫dÔºõdÊòØÁî®Êà∑ÂÜ≥ÂÆöÁöÑÔºõdÁöÑÂ§ßÂ∞è‰ºöÂÜ≥ÂÆöÊú∫Âô®Â≠¶‰π†Ê®°ÂûãÁöÑË°®Áé∞ÔºõÂ∫îËØ•Áî®xxxÊù•ÈÄâÊã©‰∏Ä‰∏™ÊØîËæÉÂ•ΩÁöÑdÔºõ\nÊàë‰ª¨ÁöÑ‰ªªÂä°ÊòØÁúãËØÑËÆ∫ÊòØÊ≠£Èù¢ÁöÑËøòÊòØË¥üÈù¢ÁöÑÔºõÂèÇÊï∞Áü©ÈòµÊòØ‰ªéËÆ≠ÁªÉÊï∞ÊçÆ‰∏≠Â≠¶‰π†Âá∫Êù•ÁöÑÔºåÊâÄ‰ª•Â≠¶Âá∫Êù•ÁöÑËØçÂêëÈáèÊòØÂ∏¶ÊúâÊÑüÊÉÖËâ≤ÂΩ©ÁöÑÔºõÂÅáËÆæËøô‰∫õËØçÂêëÈáèÈÉΩÊòØ‰∫åÁª¥ÁöÑÔºåÂàôÂèØ‰ª•Âú®Âπ≥Èù¢ÂùêÊ†áÁ≥ª‰∏≠Ê†áÂá∫‰∏ãÈù¢ËØçÂêëÈáè\nkerasÊèê‰æõembeddingÂ±ÇÔºõÁî®Êà∑ÂèØ‰ª•ÊåáÂÆövocabularyÂ§ßÂ∞èÂíådÁöÑÂ§ßÂ∞èÔºõ‰ª•ÂèäÊØè‰∏Ä‰∏™sequenceÁöÑÈïøÂ∫¶ÔºõdÊòØÊ†πÊçÆÁÆóÊ≥ïÈÄâÂá∫Êù•ÁöÑ Âà∞Ëøô‰∏ÄÊ≠•ÔºåÊàë‰ª¨Â∑≤ÁªèÂÆåÊàê‰∫ÜÊñáÊú¨Â§ÑÁêÜÂíåword embedding„ÄÇÊé•‰∏ãÊù•Â∞±ÊòØÁî®Logistic Regression for Binary ClassificationÂÅö‰∫åÂàÜÁ±ªÔºõ\n","permalink":"http://localhost:1313/posts/nlp-2/","summary":"\u003ch3 id=\"text-to-sequence\"\u003eText to Sequence\u003c/h3\u003e\n\u003cp\u003eÊñáÊú¨Â§ÑÁêÜ\u003c/p\u003e\n\u003cp\u003eStep1: Tokenization\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\n\u003cp\u003eTokenization breaks a piece of text down into a list of tokens.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003eHere, a token is a word. (A token can be a character in some applications.)\u003c/p\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003eTokenizationËÆ≤Á©∂ÂæàÂ§öÔºå‰æãÂ¶ÇÊòØÂê¶Â∫îËØ•ÊääÂ§ßÂÜôÊîπÊàêÂ∞èÂÜôÂë¢ÔºüËøõË°åtypo correctionÁ≠âÁ≠â\u003c/p\u003e\n\u003cp\u003e\u003cimg alt=\"image-20250322150322238\" loading=\"lazy\" src=\"./NLP-2.assets/image-20250322150322238.png\"\u003e\u003c/p\u003e\n\u003cp\u003eStep2: Build Dictionary\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\n\u003cp\u003eUse a dictionary (hash table) to count word frequencies.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003eThe dictionary maps word to index.\u003c/p\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003eÂèØ‰ª•È¶ñÂÖàÁªüËÆ°ËØçÈ¢ëÂéªÊéâ‰ΩéÈ¢ëËØçÔºåÁÑ∂ÂêéËÆ©ÊØè‰∏™ËØçÂØπÂ∫î‰∏Ä‰∏™Ê≠£Êï¥Êï∞ÔºõËøôÊ†∑ÁöÑËØùÔºå‰∏ÄÂè•ËØùÂ∞±ÂèØ‰ª•Áî®‰∏Ä‰∏™Ê≠£Êï¥Êï∞ÂàóË°®Ë°®Á§∫ÔºåËøô‰∏™ÂàóË°®Â∞±Âè´sequenceÔºõÂ¶ÇÊûúÂøÖË¶ÅÂ∞±ËøòÂæóÂÅöone-hot encoding„ÄÇ\u003cimg alt=\"image-20250322150620890\" loading=\"lazy\" src=\"./NLP-2.assets/image-20250322150620890.png\"\u003e\u003c/p\u003e\n\u003cp\u003eÁªìÊûú\u003c/p\u003e\n\u003cp\u003e\u003cimg alt=\"image-20250322150754528\" loading=\"lazy\" src=\"./NLP-2.assets/image-20250322150754528.png\"\u003e\u003c/p\u003e\n\u003cp\u003e‰ΩÜÊòØÈïøÂ∫¶‰∏çÁªü‰∏Ä\u003c/p\u003e\n\u003cp\u003eStep4: ÂØπÈΩêsequence\u003c/p\u003e\n\u003cp\u003e\u003cimg alt=\"image-20250322150854986\" loading=\"lazy\" src=\"./NLP-2.assets/image-20250322150854986.png\"\u003e\u003c/p\u003e\n\u003cp\u003eËß£ÂÜ≥ÊñπÊ°àÊòØËøôÊ†∑ÁöÑÔºöÂèØ‰ª•Âõ∫ÂÆöÈïøÂ∫¶‰∏∫wÔºåÂä†ÂÖ•‰∏Ä‰∏™Â∫èÂàóÈïøÂ∫¶Â§™ÈïøÔºåÂ∞±Á†çÊéâÂâçÈù¢ÁöÑËØçÔºåÂè™‰øùÁïôÊúÄÂêéw‰∏™ËØçÔºõÂ¶ÇÊûú‰∏Ä‰∏™Â∫èÂàóÂ§™Áü≠ÔºåÂ∞±ÂÅözero paddingÔºåÁî®0Â°´ÂÖÖ\u003c/p\u003e\n\u003cp\u003e\u003cimg alt=\"image-20250322151030119\" loading=\"lazy\" src=\"./NLP-2.assets/image-20250322151030119.png\"\u003e\u003c/p\u003e\n\u003cp\u003eËøôÊ†∑‰∏ÄÊù•ÔºåÊâÄÊúâÁöÑÂ∫èÂàóÈïøÂ∫¶Â∞±Áªü‰∏Ä‰∫Ü\u003c/p\u003e\n\u003cp\u003e\u003cimg alt=\"image-20250322151117125\" loading=\"lazy\" src=\"./NLP-2.assets/image-20250322151117125.png\"\u003e\u003c/p\u003e\n\u003cp\u003eÊñáÊú¨Â§ÑÁêÜÂÆåÊàê‰∫ÜÔºåÊé•‰∏ãÊù•ÊòØword embeddingÔºåÊääÂçïËØçË°®Á§∫‰∏∫‰∏Ä‰∏™‰ΩéÁª¥ÂêëÈáèÔºõ\u003c/p\u003e\n\u003cp\u003e\u003cimg alt=\"image-20250322151252837\" loading=\"lazy\" src=\"./NLP-2.assets/image-20250322151252837.png\"\u003e\u003c/p\u003e","title":""},{"content":"üëã About me Hello! I\u0026rsquo;m Xu Zongsi, a passionate technology enthusiast currently pursuing my Master of Science in ECIC at The University of Hong Kong. With a solid background in Software Engineering from the Beijing Institute of Technology, I specialize in emerging areas of artificial intelligence, including machine learning, deep learning, natural language processing, computer vision, and reinforcement learning.\nRecently, inspired by OpenAI\u0026rsquo;s five-step plan towards superintelligence, I have great expectations for AGI and developed a strong interest in LLM agents, MLLM, reinforcement learning, and knowledge graphs. I believe there is significant potential in these fields to create innovative solutions, and I hope to contribute my efforts towards that goal.\nüìö Education üá≠üá∞ The University of Hong Kong 09/2024 - Expected 11/2025 School of Computing and Data Science Master of Science in Electronic Commerce \u0026amp; Internet Computing Relevant Courses: Machine learning for business and e-commerce, Knowledge graphs, Financial fraud analytics, Internet infrastructure technologies, Website engineering, Blockchain and cryptocurrency, etc. üá®üá≥ Beijing Institute of Technology 09/2020 - 06/2024 School of Computer Science \u0026amp; Technology Bachelor of Engineering in Software Engineering, last two years GPA: 3.7/4 Relevant Courses: Reinforcement Learning, Deep Learning and Computer Vision, Artificial Intelligence and Robot Ethics, Almost Human: Mind, Brain and Artificial Intelligence, Mathematical Analysis for Engineering, Linear Algebra, Probability and Mathematical Statistics, etc. Skills: Python, Java, common data structures, design patterns, machine learning basics and algorithms, Linux, PyTorch, and some development tools (git, conda, etc.). üèÜ Awards \u0026amp; Honors Beijing Institute of Technology Undergraduate Scholarship (Top 20% of Grade) 06/2023 3rd Prize of China International \u0026#34;Internet \u0026#43;\u0026#34; College Student\u0026#39;s Innovation Competition 08/2022 Bronze Prize of \u0026#34;Challenge Cup\u0026#34; Capital University Entrepreneurship Competition 05/2022 üíº Project Experience Online Transaction Fraud Detection 09/2024 ‚Äì 01/2025 Independent project, supervised by Dr. Vivien Chan Focused on addressing financial fraud in e-commerce to enhance the accuracy of transaction anomaly detection, while independently managing the entire case study that included data preprocessing, feature engineering, model building, evaluation, and results analysis. Effectively resolved class imbalance issues using SMOTE and ROSE techniques. Built various models including Logistic Regression, Random Forest, XGBoost, and LightGBM, ultimately selecting the LightGBM model to achieve a recall rate of 95.45% and an AUC of 99.84%. Wrote efficient and maintainable code, enhancing model training and data processing efficiency through parallel computing and logging. Multi-Model Intelligent Text Keyword Extraction System 08/2023 ‚Äì 09/2023 Group project, supervised by Associate Prof. Xiaolin Zhao Designed and implemented an intelligent text summary system that automatically extracts keywords from article titles and abstracts, enhancing the understanding and summarization of text information. Participated in the planning of the technical route and built a hybrid model combining extractive and generative approaches, utilizing advanced natural language processing techniques including KeyBERT, Sentence Transformer, BERT, and T5 models. Responsible for data preprocessing and tokenization, as well as the end-to-end implementation and training of the T5 model, optimizing the model architecture and hyperparameters, achieving satisfactory results after only 3 epochs of training. Model evaluation results showed that the Rouge-1, Rouge-2, and Rouge-L metrics reached 0.6345, 0.5038, and 0.5282, respectively, in the third epoch, validating the model\u0026rsquo;s effectiveness in the summarization task. Cambridge University Machine Learning Summer Project 07/2023 ‚Äì 08/2023 Group project, supervised by Prof. Pietro Li√≤ Participated in the Cambridge University deep learning summer project, focusing on deep reinforcement learning; explored multi-agent learning algorithms across different environments. Reproduced the Multi-Agent Deep Deterministic Policy Gradient (MADDPG) algorithm in the Simple Adversary environment and studied the effect of agent numbers on convergence speed and stability, finding optimal stability at 21 agents. Designed and implemented comparative experiments inspired by the Rainbow algorithm, assessing target network strategies versus the Double Deep Q-Network (Double DQN). The results demonstrated that Double DQN significantly enhanced convergence speed, optimizing the overall learning process. Co-authored a group project paper on agent numbers and strategies effectiveness in multi-agent systems, achieving a score of 71% in the summer program (the highest in my group) and a \u0026ldquo;First Class\u0026rdquo; classification in the UK grading system. Deep Learning and Computer Vision Semester Project 09/2022 ‚Äì 12/2022 Independent project, supervised by Associate Prof. Guangyu Gao Designed and implemented a waste classifier using the ResNet model to improve classification accuracy and reduce resource waste. The project also enhanced understanding of transfer learning techniques with ResNet. Collected a dataset of 16 waste categories and preprocessed the images for uniformity and standardization, incorporating data augmentation techniques to enhance the dataset. Conducted experiments using ResNet34 and ResNet50 models through transfer learning, accelerating network convergence by leveraging pretrained weights. During training, techniques such as Batch Normalization and Dropout were applied to mitigate the risk of overfitting. The final model achieved an accuracy of 90% on the training set, while the performance on the test set was 61%, indicating a significant overfitting phenomenon during the training process. üéì Internship Beijing Academy of Quantum Information Science 08/2023 ‚Äì 01/2024 Research Intern at Quantum Computation Department Proposed a quantum convolution kernel design based on variational quantum circuits and developed a universal quantum convolution layer, successfully integrating it into classical CNN architectures such as VGG, GoogLeNet, and ResNet. Developed and evaluated various hybrid models, including a simple model named HQCCNN-2, which achieved 84.45% accuracy on the FashionMNIST dataset, surpassing the traditional CNN\u0026rsquo;s 80.72%. This demonstrates the effectiveness of the quantum convolution layer in improving model performance. Tested on a real quantum computer further validated the effectiveness of the hybrid model, demonstrating the viable integration of quantum computing with deep learning, and highlighting the potential for leveraging quantum properties to enhance model performance. üèÖ Competition Experience China International \u0026#34;Internet \u0026#43;\u0026#34; College Students\u0026#39; Innovation Competition 08/2022 Zhongke Ushield: Deep Learning-based Face Privacy Protection Authentication System Responsible for constructing a localized facial feature extraction engine based on MobileFaceNet, ensuring feature extraction is completed on end devices (such as mobile phones and cameras), guaranteeing that raw data does not leave the domain and is not stored, thus enhancing user privacy protection while improving recognition efficiency. \u0026#34;Challenge Cup\u0026#34; Capital University Entrepreneurship Competition 05/2022 Smart Orchard Responsible for the development of the fruit detection, ripeness prediction, and pest identification system, using deep convolutional neural network (CNN) technology for intelligent monitoring of crop growth conditions. Applied advanced object detection algorithms such as Faster R-CNN and YOLO to achieve high precision in apple detection and ripeness assessment, with an accuracy rate exceeding 90%, significantly enhancing the intelligence level of orchard management. Built and trained a dedicated dataset containing various pest samples, optimizing pest detection accuracy through data preprocessing (such as image normalization and resizing) and data augmentation techniques (like rotation, flipping, and noise addition), enabling the real-time monitoring system to accurately identify over 80% of pests, providing effective scientific maintenance recommendations to help farmers reduce crop losses. üìã Extracurricular Activities Vice President, Cyber Security Club, Beijing Institute of Technology 09/2021-09/2022 Backbone, Media Center of the Student Union of Beijing Institute of Technology 10/2020-06/2021 üì´ Contact üìß zongsi.xu@outlook.com üëî Zongsi (Tristan) Xu üíª github.com/BaizeXS üìç Hong Kong SAR, China ","permalink":"http://localhost:1313/resume/","summary":"Personal resume of Zongsi (Tristan) Xu","title":"Zongsi (Tristan) Xu"},{"content":"‰∏Ä„ÄÅÊï∞ÂÄºÁâπÂæÅ‰∏éÁ±ªÂà´ÁâπÂæÅ Êï∞ÂÄºÁâπÂæÅ (Numeric Features) ÂÖ∑ÊúâÂèØÂä†ÂáèÁöÑÊÑè‰πâÔºå‰∏îÂ≠òÂú®Â§ßÂ∞èÈ°∫Â∫è„ÄÇ ‰æãÂ≠êÔºöÂπ¥ÈæÑ„ÄÅÊ∏©Â∫¶Á≠â„ÄÇÂèØ‰ª•Áõ¥Êé•‰øùÁïôÂÖ∂Êï¥Êï∞ÊàñÊµÆÁÇπÊï∞ÂΩ¢Âºè‰æõÊ®°Âûã‰ΩøÁî®„ÄÇ Á±ªÂà´ÁâπÂæÅ (Categorical Features) Êï∞ÊçÆÂÄºÁ¶ªÊï£Ôºå‰∏çÂÖ∑Â§á‚ÄúÊï∞ÂÄºÂ§ßÂ∞è‚ÄùÈó¥ÁöÑÂèØÊØîÊÑè‰πâ„ÄÇ ‰æãÂ≠êÔºöÂõΩÁ±çÔºàÁæéÂõΩ/‰∏≠ÂõΩ/Âç∞Â∫¶Á≠âÔºâ„ÄÅÊÄßÂà´ÔºàÁî∑/Â•≥ÔºâÁ≠â„ÄÇ ÈóÆÈ¢òÔºöËã•‰ªÖÁî®Êï¥Êï∞Ë°®Á§∫ÔºàÁæéÂõΩ=1, ‰∏≠ÂõΩ=2ÔºâÔºå‰ºöÂºïÂÖ•ÈîôËØØÁöÑÊï∞ÂÄºËøêÁÆóÂÖ≥Á≥ªÔºåÂ¶Ç ‚ÄúÁæéÂõΩ + ‰∏≠ÂõΩ = Âç∞Â∫¶‚Äù„ÄÇ ‰∫å„ÄÅOne-HotÁºñÁ†ÅÁöÑÂä®Êú∫‰∏éÊµÅÁ®ã ‰∏∫‰ªÄ‰πà‰ΩøÁî®One-Hot\nÈÄöËøáÂ∞ÜÁ±ªÂà´Êò†Â∞Ñ‰∏∫ÂêëÈáèÔºåÈÅøÂÖçÊï¥Êï∞ÁºñÁ†ÅÂºïÂÖ•ÁöÑ‰º™Êï∞ÂÄºÂÖ≥Á≥ª„ÄÇ ÂêåÊó∂‰øùÁïôÂêÑÁßçÂèØËÉΩÁ±ªÂà´ÁöÑ‰ø°ÊÅØÔºå‰∏î‰ªÖÂú®ÂØπÂ∫î‰ΩçÁΩÆ‰∏∫1ÔºåÂÖ∂‰ªñ‰ΩçÁΩÆ‰∏∫0„ÄÇ Âª∫Á´ãÊò†Â∞ÑÔºö‰ªéÁ±ªÂà´Âà∞Á¥¢Âºï\n‰∏∫ÊØè‰∏™Á±ªÂà´ÂàÜÈÖç‰∏Ä‰∏™ÂîØ‰∏ÄÁ¥¢ÂºïÔºåÈÄöÂ∏∏‰ªé1ÂºÄÂßã„ÄÇ È¢ÑÁïôÁ¥¢Âºï0Ë°®Á§∫‚ÄúÊú™Áü•‚ÄùÊàñ‚ÄúÁº∫Â§±‚ÄùÔºåÂØπÂ∫îÂÖ®0ÂêëÈáè„ÄÇ ËΩ¨Êç¢‰∏∫One-HotÂêëÈáè\nËã•Á±ªÂà´ÊÄªÊï∞‰∏∫197ÔºåÂàôÁî®197Áª¥ÂêëÈáèË°®Á§∫„ÄÇ ‰æãÂ≠êÔºöÁæéÂõΩ [1, 0, 0, 0, ‚Ä¶]Ôºå ‰∏≠ÂõΩ [0, 1, 0, 0, ‚Ä¶]„ÄÇ Á§∫‰æãÔºöË°®Á§∫‰∏Ä‰∏™‰∫∫ÁöÑÁâπÂæÅ\nÁâπÂæÅÂåÖÂê´ÔºàÂπ¥ÈæÑ, ÊÄßÂà´, ÂõΩÁ±çÔºåÂÖ∂‰∏≠ÂõΩÁ±ç197ÁßçÔºâ Áª¥Â∫¶ÊÄªÂíåÔºö1Áª¥_age + 1Áª¥_gender + 197Áª¥_nationality = 199Áª¥„ÄÇ ‰æãÂ¶Ç (28, Â•≥, ‰∏≠ÂõΩ) ‚Üí [28, 0, 0, 1, 0, ‚Ä¶, 0]„ÄÇ ‰∏â„ÄÅÊñáÊú¨Êï∞ÊçÆÂ§ÑÁêÜÊµÅÁ®ã ÊñáÊú¨Âú®Ëá™ÁÑ∂ËØ≠Ë®ÄÂ§ÑÁêÜÔºàNLPÔºâ‰∏≠‰Ωú‰∏∫Â∏∏ËßÅÁöÑÂéüÂßãËæìÂÖ•ÔºåÈúÄË¶ÅÊï∞ÂÄºÂåñÊâçËÉΩÈÄÅÂÖ•Ê®°Âûã„ÄÇ‰∏ÄËà¨Ê≠•È™§Â¶Ç‰∏ãÔºö\nÂàÜËØç (Tokenization)\nÂ∞ÜÊñáÊú¨ÊãÜÂàÜ‰∏∫‰∏Ä‰∏™‰∏™ÂçïËØçÔºàTokenÔºâ„ÄÇ ‰æãÂ≠êÔºö\u0026quot;... to be or not to be...\u0026quot; ‚Üí [\u0026quot;...\u0026quot;, \u0026quot;to\u0026quot;, \u0026quot;be\u0026quot;, \u0026quot;or\u0026quot;, \u0026quot;not\u0026quot;, \u0026quot;to\u0026quot;, \u0026quot;be\u0026quot;, \u0026quot;...\u0026quot;]„ÄÇ ÁªüËÆ°ËØçÈ¢ë \u0026amp; ÊûÑÂª∫ËØçÂÖ∏\nËØçÈ¢ëÁªüËÆ° Áî®ÂìàÂ∏åË°®/Â≠óÂÖ∏ËÆ∞ÂΩïÊØè‰∏™ÂçïËØçÂá∫Áé∞Ê¨°Êï∞„ÄÇ ÈÅçÂéÜÊñáÊú¨Êó∂ÔºåËã•ÂçïËØçÂ∞öÊú™ÂÖ•Ë°®ÔºåÂàôÊñ∞Âª∫ËÆ∞ÂΩïÔºõËã•Â∑≤Â≠òÂú®ÔºåÂàôËÆ°Êï∞+1„ÄÇ ÊéíÂ∫è‰∏éÁ¥¢Âºï ÊåâËØçÈ¢ëÈôçÂ∫èÊéíÂ∫èÔºåËØçÈ¢ëÊúÄÈ´òÁöÑÂçïËØçÊéíÂú®ÂâçÈù¢„ÄÇ Á¥¢Âºï‰ªé1ÂºÄÂßãÔºå0ÁïôÁªô‚ÄúÊú™Áü•‚Äù„ÄÇ ËØçÂÖ∏ËßÑÊ®°ÔºàvocabularyÔºâÂèØËßÜÈúÄÊ±ÇÊà™Êñ≠Ôºà‰æãÂ¶ÇÂè™‰øùÁïôTop 10kÔºâ„ÄÇ ‰∏∫‰ªÄ‰πàÁßªÈô§‰ΩéÈ¢ëËØç ‰ΩéÈ¢ëËØçÂèØËÉΩÊòØÊãºÂÜôÈîôËØØ„ÄÅÁΩïËßÅ‰∫∫ÂêçÁ≠âÔºåÂØπÊ®°ÂûãÂ∏ÆÂä©ÊúâÈôê„ÄÇ ÂáèÂ∞ëËØçÂÖ∏ËßÑÊ®°ÂèØÈôç‰ΩéËøêÁÆóÂºÄÈîÄ„ÄÅÂä†Âø´Ê®°ÂûãËÆ≠ÁªÉ‰∏éÊé®ÁêÜÈÄüÂ∫¶„ÄÇ Áã¨ÁÉ≠ÁºñÁ†Å (One-Hot Encoding)\nÂ∞ÜÊØè‰∏™ÂçïËØçÊò†Â∞Ñ‰∏∫ËØçÂÖ∏‰∏≠ÁöÑÁ¥¢ÂºïÂêéÔºàÂ¶Ç [2, 4, 1, 8, ‚Ä¶]ÔºâÔºåÂèØËøõ‰∏ÄÊ≠•ËΩ¨Êç¢ÊàêOne-HotÂêëÈáè„ÄÇ One-HotÁª¥Â∫¶ÂèñÂÜ≥‰∫é‰øùÁïô‰∏ãÊù•ÁöÑËØçÂÖ∏Â§ßÂ∞èÔºà‰æãÂ¶Ç1‰∏áÔºâ„ÄÇ Êú™Êî∂ÂΩïÂçïËØçÂèØËÉΩÁõ¥Êé•ÂøΩÁï•ÔºåÊàñÁªü‰∏ÄÁî®Á¥¢Âºï0‰ª£Êõø„ÄÇ Âõõ„ÄÅÊ†∏ÂøÉÊî∂Ëé∑‰∏éÂ∫îÁî® Á±ªÂà´ÁâπÂæÅÂøÖÈúÄÊï∞ÂÄºÂåñÔºö\n‰ΩøÁî®Êï¥Êï∞1,2,3‚Ä¶‰ªÖË°®Á§∫Á±ªÂà´‚ÄúÊ†áËØÜ‚ÄùÔºåÂπ∂‰∏ç‰ª£Ë°®ÂÆÉ‰ª¨ÂèØËøõË°åÊï∞ÂÄºËøêÁÆó„ÄÇ Âõ†Ê≠§ÈúÄË¶ÅOne-HotÁ≠âÁºñÁ†ÅÊñπÂºèÔºåÈÅøÂÖçÊï∞ÂÄºËØØËß£„ÄÇ ÊñáÊú¨Êï∞ÊçÆÈ¢ÑÂ§ÑÁêÜÔºö\nÂàÜËØç„ÄÅËØçÈ¢ëÁªüËÆ°„ÄÅÊûÑÂª∫ËØçÂÖ∏„ÄÅÁ¥¢ÂºïÂåñ„ÄÅOne-HotÊàñÂÖ∂‰ªñÊñπÂºèÔºàÂ¶ÇËØçÂµåÂÖ•ÔºâÊòØÂ∏∏ËßÅÊµÅÁ®ã„ÄÇ Ê≠£Á°ÆÁöÑÊñáÊú¨È¢ÑÂ§ÑÁêÜÂèØÊòæËëóÂΩ±ÂìçÊ®°ÂûãÊÄßËÉΩÂíåÊïàÁéá„ÄÇ ‰øùÁïôÊú™Áü•Á¥¢ÂºïÔºö\n‰øùËØÅÂØπÁº∫Â§±Êï∞ÊçÆÊàñÂ≠óÂÖ∏Â§ñÊñ∞ËØçËÉΩÊúâÂü∫Êú¨ÁöÑË°®Á§∫ÔºåÊèêÂçáÊ®°ÂûãÂÆπÈîôÊÄß„ÄÇ ÂÆûÈôÖ‰ΩøÁî®Ôºö\nÂØπ‰∫éÂ∞èËßÑÊ®°Á±ªÂà´ÂèØÁõ¥Êé•One-HotÁºñÁ†ÅÔºõÂØπ‰∫éËØçÂÖ∏ÂæàÂ§ßÁöÑÂú∫ÊôØÔºåÈÄöÂ∏∏‰ºöËøõ‰∏ÄÊ≠•ËÄÉËôëËØçÂµåÂÖ•ÔºàWord EmbeddingÔºâÊàñÈ¢ÑËÆ≠ÁªÉËØ≠Ë®ÄÊ®°Âûã„ÄÇ ","permalink":"http://localhost:1313/posts/nlp-1/","summary":"\u003ch2 id=\"‰∏ÄÊï∞ÂÄºÁâπÂæÅ‰∏éÁ±ªÂà´ÁâπÂæÅ\"\u003e‰∏Ä„ÄÅÊï∞ÂÄºÁâπÂæÅ‰∏éÁ±ªÂà´ÁâπÂæÅ\u003c/h2\u003e\n\u003col\u003e\n\u003cli\u003e\u003cstrong\u003eÊï∞ÂÄºÁâπÂæÅ (Numeric Features)\u003c/strong\u003e\n\u003cul\u003e\n\u003cli\u003eÂÖ∑ÊúâÂèØÂä†ÂáèÁöÑÊÑè‰πâÔºå‰∏îÂ≠òÂú®Â§ßÂ∞èÈ°∫Â∫è„ÄÇ\u003c/li\u003e\n\u003cli\u003e‰æãÂ≠êÔºöÂπ¥ÈæÑ„ÄÅÊ∏©Â∫¶Á≠â„ÄÇÂèØ‰ª•Áõ¥Êé•‰øùÁïôÂÖ∂Êï¥Êï∞ÊàñÊµÆÁÇπÊï∞ÂΩ¢Âºè‰æõÊ®°Âûã‰ΩøÁî®„ÄÇ\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003eÁ±ªÂà´ÁâπÂæÅ (Categorical Features)\u003c/strong\u003e\n\u003cul\u003e\n\u003cli\u003eÊï∞ÊçÆÂÄºÁ¶ªÊï£Ôºå‰∏çÂÖ∑Â§á‚ÄúÊï∞ÂÄºÂ§ßÂ∞è‚ÄùÈó¥ÁöÑÂèØÊØîÊÑè‰πâ„ÄÇ\u003c/li\u003e\n\u003cli\u003e‰æãÂ≠êÔºöÂõΩÁ±çÔºàÁæéÂõΩ/‰∏≠ÂõΩ/Âç∞Â∫¶Á≠âÔºâ„ÄÅÊÄßÂà´ÔºàÁî∑/Â•≥ÔºâÁ≠â„ÄÇ\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003eÈóÆÈ¢ò\u003c/strong\u003eÔºöËã•‰ªÖÁî®Êï¥Êï∞Ë°®Á§∫ÔºàÁæéÂõΩ=1, ‰∏≠ÂõΩ=2ÔºâÔºå‰ºöÂºïÂÖ•ÈîôËØØÁöÑÊï∞ÂÄºËøêÁÆóÂÖ≥Á≥ªÔºåÂ¶Ç ‚ÄúÁæéÂõΩ + ‰∏≠ÂõΩ = Âç∞Â∫¶‚Äù„ÄÇ\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003c/ol\u003e\n\u003ch2 id=\"‰∫åone-hotÁºñÁ†ÅÁöÑÂä®Êú∫‰∏éÊµÅÁ®ã\"\u003e‰∫å„ÄÅOne-HotÁºñÁ†ÅÁöÑÂä®Êú∫‰∏éÊµÅÁ®ã\u003c/h2\u003e\n\u003col\u003e\n\u003cli\u003e\n\u003cp\u003e\u003cstrong\u003e‰∏∫‰ªÄ‰πà‰ΩøÁî®One-Hot\u003c/strong\u003e\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eÈÄöËøáÂ∞ÜÁ±ªÂà´Êò†Â∞Ñ‰∏∫ÂêëÈáèÔºåÈÅøÂÖçÊï¥Êï∞ÁºñÁ†ÅÂºïÂÖ•ÁöÑ‰º™Êï∞ÂÄºÂÖ≥Á≥ª„ÄÇ\u003c/li\u003e\n\u003cli\u003eÂêåÊó∂‰øùÁïôÂêÑÁßçÂèØËÉΩÁ±ªÂà´ÁöÑ‰ø°ÊÅØÔºå‰∏î‰ªÖÂú®ÂØπÂ∫î‰ΩçÁΩÆ‰∏∫1ÔºåÂÖ∂‰ªñ‰ΩçÁΩÆ‰∏∫0„ÄÇ\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003e\u003cstrong\u003eÂª∫Á´ãÊò†Â∞ÑÔºö‰ªéÁ±ªÂà´Âà∞Á¥¢Âºï\u003c/strong\u003e\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e‰∏∫ÊØè‰∏™Á±ªÂà´ÂàÜÈÖç‰∏Ä‰∏™ÂîØ‰∏ÄÁ¥¢ÂºïÔºåÈÄöÂ∏∏‰ªé1ÂºÄÂßã„ÄÇ\u003c/li\u003e\n\u003cli\u003eÈ¢ÑÁïôÁ¥¢Âºï0Ë°®Á§∫‚ÄúÊú™Áü•‚ÄùÊàñ‚ÄúÁº∫Â§±‚ÄùÔºåÂØπÂ∫îÂÖ®0ÂêëÈáè„ÄÇ\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003e\u003cstrong\u003eËΩ¨Êç¢‰∏∫One-HotÂêëÈáè\u003c/strong\u003e\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eËã•Á±ªÂà´ÊÄªÊï∞‰∏∫197ÔºåÂàôÁî®197Áª¥ÂêëÈáèË°®Á§∫„ÄÇ\u003c/li\u003e\n\u003cli\u003e‰æãÂ≠êÔºöÁæéÂõΩ \u003ccode\u003e[1, 0, 0, 0, ‚Ä¶]\u003c/code\u003eÔºå ‰∏≠ÂõΩ \u003ccode\u003e[0, 1, 0, 0, ‚Ä¶]\u003c/code\u003e„ÄÇ\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003e\u003cstrong\u003eÁ§∫‰æãÔºöË°®Á§∫‰∏Ä‰∏™‰∫∫ÁöÑÁâπÂæÅ\u003c/strong\u003e\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eÁâπÂæÅÂåÖÂê´ÔºàÂπ¥ÈæÑ, ÊÄßÂà´, ÂõΩÁ±çÔºåÂÖ∂‰∏≠ÂõΩÁ±ç197ÁßçÔºâ\u003c/li\u003e\n\u003cli\u003eÁª¥Â∫¶ÊÄªÂíåÔºö1Áª¥_age + 1Áª¥_gender + 197Áª¥_nationality = 199Áª¥„ÄÇ\u003c/li\u003e\n\u003cli\u003e‰æãÂ¶Ç \u003ccode\u003e(28, Â•≥, ‰∏≠ÂõΩ)\u003c/code\u003e ‚Üí \u003ccode\u003e[28, 0, 0, 1, 0, ‚Ä¶, 0]\u003c/code\u003e„ÄÇ\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003c/ol\u003e\n\u003ch2 id=\"‰∏âÊñáÊú¨Êï∞ÊçÆÂ§ÑÁêÜÊµÅÁ®ã\"\u003e‰∏â„ÄÅÊñáÊú¨Êï∞ÊçÆÂ§ÑÁêÜÊµÅÁ®ã\u003c/h2\u003e\n\u003cp\u003eÊñáÊú¨Âú®Ëá™ÁÑ∂ËØ≠Ë®ÄÂ§ÑÁêÜÔºàNLPÔºâ‰∏≠‰Ωú‰∏∫Â∏∏ËßÅÁöÑÂéüÂßãËæìÂÖ•ÔºåÈúÄË¶ÅÊï∞ÂÄºÂåñÊâçËÉΩÈÄÅÂÖ•Ê®°Âûã„ÄÇ‰∏ÄËà¨Ê≠•È™§Â¶Ç‰∏ãÔºö\u003c/p\u003e\n\u003col\u003e\n\u003cli\u003e\n\u003cp\u003e\u003cstrong\u003eÂàÜËØç (Tokenization)\u003c/strong\u003e\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eÂ∞ÜÊñáÊú¨ÊãÜÂàÜ‰∏∫‰∏Ä‰∏™‰∏™ÂçïËØçÔºàTokenÔºâ„ÄÇ\u003c/li\u003e\n\u003cli\u003e‰æãÂ≠êÔºö\u003ccode\u003e\u0026quot;... to be or not to be...\u0026quot;\u003c/code\u003e ‚Üí \u003ccode\u003e[\u0026quot;...\u0026quot;, \u0026quot;to\u0026quot;, \u0026quot;be\u0026quot;, \u0026quot;or\u0026quot;, \u0026quot;not\u0026quot;, \u0026quot;to\u0026quot;, \u0026quot;be\u0026quot;, \u0026quot;...\u0026quot;]\u003c/code\u003e„ÄÇ\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003e\u003cstrong\u003eÁªüËÆ°ËØçÈ¢ë \u0026amp; ÊûÑÂª∫ËØçÂÖ∏\u003c/strong\u003e\u003c/p\u003e","title":""},{"content":"Text to Sequence ÊñáÊú¨Â§ÑÁêÜ\nStep1: Tokenization\nTokenization breaks a piece of text down into a list of tokens.\nHere, a token is a word. (A token can be a character in some applications.)\nTokenizationËÆ≤Á©∂ÂæàÂ§öÔºå‰æãÂ¶ÇÊòØÂê¶Â∫îËØ•ÊääÂ§ßÂÜôÊîπÊàêÂ∞èÂÜôÂë¢ÔºüËøõË°åtypo correctionÁ≠âÁ≠â\nStep2: Build Dictionary\nUse a dictionary (hash table) to count word frequencies.\nThe dictionary maps word to index.\nÂèØ‰ª•È¶ñÂÖàÁªüËÆ°ËØçÈ¢ëÂéªÊéâ‰ΩéÈ¢ëËØçÔºåÁÑ∂ÂêéËÆ©ÊØè‰∏™ËØçÂØπÂ∫î‰∏Ä‰∏™Ê≠£Êï¥Êï∞ÔºõËøôÊ†∑ÁöÑËØùÔºå‰∏ÄÂè•ËØùÂ∞±ÂèØ‰ª•Áî®‰∏Ä‰∏™Ê≠£Êï¥Êï∞ÂàóË°®Ë°®Á§∫ÔºåËøô‰∏™ÂàóË°®Â∞±Âè´sequenceÔºõÂ¶ÇÊûúÂøÖË¶ÅÂ∞±ËøòÂæóÂÅöone-hot encoding„ÄÇ\nÁªìÊûú\n‰ΩÜÊòØÈïøÂ∫¶‰∏çÁªü‰∏Ä\nStep4: ÂØπÈΩêsequence\nËß£ÂÜ≥ÊñπÊ°àÊòØËøôÊ†∑ÁöÑÔºöÂèØ‰ª•Âõ∫ÂÆöÈïøÂ∫¶‰∏∫wÔºåÂä†ÂÖ•‰∏Ä‰∏™Â∫èÂàóÈïøÂ∫¶Â§™ÈïøÔºåÂ∞±Á†çÊéâÂâçÈù¢ÁöÑËØçÔºåÂè™‰øùÁïôÊúÄÂêéw‰∏™ËØçÔºõÂ¶ÇÊûú‰∏Ä‰∏™Â∫èÂàóÂ§™Áü≠ÔºåÂ∞±ÂÅözero paddingÔºåÁî®0Â°´ÂÖÖ\nËøôÊ†∑‰∏ÄÊù•ÔºåÊâÄÊúâÁöÑÂ∫èÂàóÈïøÂ∫¶Â∞±Áªü‰∏Ä‰∫Ü\nÊñáÊú¨Â§ÑÁêÜÂÆåÊàê‰∫ÜÔºåÊé•‰∏ãÊù•ÊòØword embeddingÔºåÊääÂçïËØçË°®Á§∫‰∏∫‰∏Ä‰∏™‰ΩéÁª¥ÂêëÈáèÔºõ\nÁÑ∂ËÄåËøôÊ†∑ÂÅöÁöÑËØùÔºåÂ¶ÇÊûúÊòØ10000‰∏™ÂçïËØçÔºåÁª¥Â∫¶Â∞±ÊòØ10000Áª¥ÔºåÁª¥Â∫¶Â§™È´ò‰∫ÜÔºõÂõ†Ê≠§Ë¶ÅÂÅöword embeddingÔºõ\nÂÖ∑‰ΩìÂÅöÊ≥ïÂ∞±ÊòØÊääone-hotÂêëÈáèe_iÂíåÂèÇÊï∞Áü©ÈòµpÁõ∏‰πòÔºõÁü©ÈòµPËΩ¨ÁΩÆÁöÑÂ§ßÂ∞èÊòØd x vÔºõdÊòØËØçÂêëÈáèÁöÑÁª¥Â∫¶ÔºõvÊòØÂ≠óÂÖ∏ÈáåËØçÊ±áÁöÑÊï∞ÈáèÔºõÁªìÊûú‰∏∫x_iÔºõx_iÂ∞±ÊòØ‰∏Ä‰∏™ËØçÂêëÈáèÔºõÂ¶ÇÊûúone-hotÂêëÈáèÁöÑÁ¨¨‰∏âË°å‰∏∫1ÔºõÈÇ£‰πàx_iÂ∞±ÊòØPËΩ¨ÁΩÆÁü©ÈòµÁöÑÁ¨¨‰∏âÂàóÔºàÂÖ∂‰ΩôÂàóÈÉΩ‰∏∫0ÔºâÔºõÊâÄ‰ª•PËΩ¨ÁΩÆÊØè‰∏ÄÂàóÈÉΩÊòØ‰∏Ä‰∏™ËØçÂêëÈáèÔºõÊâÄ‰ª•Áü©ÈòµPÊú¨Ë∫´ÁöÑÊØè‰∏ÄË°åÂ∞±ÊòØ‰∏Ä‰∏™ËØçÂêëÈáèÔºõÂÖ∂Ë°åÊï∞‰∏∫vÔºõÂç≥vocabularyÔºåËØçÊ±áÈáèÔºõÊØè‰∏ÄË°åÂØπÂ∫î‰∏Ä‰∏™ÂçïËØçÔºõÁü©ÈòµÁöÑÂàóÊï∞‰∏∫dÔºõdÊòØÁî®Êà∑ÂÜ≥ÂÆöÁöÑÔºõdÁöÑÂ§ßÂ∞è‰ºöÂÜ≥ÂÆöÊú∫Âô®Â≠¶‰π†Ê®°ÂûãÁöÑË°®Áé∞ÔºõÂ∫îËØ•Áî®xxxÊù•ÈÄâÊã©‰∏Ä‰∏™ÊØîËæÉÂ•ΩÁöÑdÔºõ\nÊàë‰ª¨ÁöÑ‰ªªÂä°ÊòØÁúãËØÑËÆ∫ÊòØÊ≠£Èù¢ÁöÑËøòÊòØË¥üÈù¢ÁöÑÔºõÂèÇÊï∞Áü©ÈòµÊòØ‰ªéËÆ≠ÁªÉÊï∞ÊçÆ‰∏≠Â≠¶‰π†Âá∫Êù•ÁöÑÔºåÊâÄ‰ª•Â≠¶Âá∫Êù•ÁöÑËØçÂêëÈáèÊòØÂ∏¶ÊúâÊÑüÊÉÖËâ≤ÂΩ©ÁöÑÔºõÂÅáËÆæËøô‰∫õËØçÂêëÈáèÈÉΩÊòØ‰∫åÁª¥ÁöÑÔºåÂàôÂèØ‰ª•Âú®Âπ≥Èù¢ÂùêÊ†áÁ≥ª‰∏≠Ê†áÂá∫‰∏ãÈù¢ËØçÂêëÈáè\nkerasÊèê‰æõembeddingÂ±ÇÔºõÁî®Êà∑ÂèØ‰ª•ÊåáÂÆövocabularyÂ§ßÂ∞èÂíådÁöÑÂ§ßÂ∞èÔºõ‰ª•ÂèäÊØè‰∏Ä‰∏™sequenceÁöÑÈïøÂ∫¶ÔºõdÊòØÊ†πÊçÆÁÆóÊ≥ïÈÄâÂá∫Êù•ÁöÑ Âà∞Ëøô‰∏ÄÊ≠•ÔºåÊàë‰ª¨Â∑≤ÁªèÂÆåÊàê‰∫ÜÊñáÊú¨Â§ÑÁêÜÂíåword embedding„ÄÇÊé•‰∏ãÊù•Â∞±ÊòØÁî®Logistic Regression for Binary ClassificationÂÅö‰∫åÂàÜÁ±ªÔºõ\n","permalink":"http://localhost:1313/posts/nlp-2/","summary":"\u003ch3 id=\"text-to-sequence\"\u003eText to Sequence\u003c/h3\u003e\n\u003cp\u003eÊñáÊú¨Â§ÑÁêÜ\u003c/p\u003e\n\u003cp\u003eStep1: Tokenization\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\n\u003cp\u003eTokenization breaks a piece of text down into a list of tokens.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003eHere, a token is a word. (A token can be a character in some applications.)\u003c/p\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003eTokenizationËÆ≤Á©∂ÂæàÂ§öÔºå‰æãÂ¶ÇÊòØÂê¶Â∫îËØ•ÊääÂ§ßÂÜôÊîπÊàêÂ∞èÂÜôÂë¢ÔºüËøõË°åtypo correctionÁ≠âÁ≠â\u003c/p\u003e\n\u003cp\u003e\u003cimg alt=\"image-20250322150322238\" loading=\"lazy\" src=\"./NLP-2.assets/image-20250322150322238.png\"\u003e\u003c/p\u003e\n\u003cp\u003eStep2: Build Dictionary\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\n\u003cp\u003eUse a dictionary (hash table) to count word frequencies.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003eThe dictionary maps word to index.\u003c/p\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003eÂèØ‰ª•È¶ñÂÖàÁªüËÆ°ËØçÈ¢ëÂéªÊéâ‰ΩéÈ¢ëËØçÔºåÁÑ∂ÂêéËÆ©ÊØè‰∏™ËØçÂØπÂ∫î‰∏Ä‰∏™Ê≠£Êï¥Êï∞ÔºõËøôÊ†∑ÁöÑËØùÔºå‰∏ÄÂè•ËØùÂ∞±ÂèØ‰ª•Áî®‰∏Ä‰∏™Ê≠£Êï¥Êï∞ÂàóË°®Ë°®Á§∫ÔºåËøô‰∏™ÂàóË°®Â∞±Âè´sequenceÔºõÂ¶ÇÊûúÂøÖË¶ÅÂ∞±ËøòÂæóÂÅöone-hot encoding„ÄÇ\u003cimg alt=\"image-20250322150620890\" loading=\"lazy\" src=\"./NLP-2.assets/image-20250322150620890.png\"\u003e\u003c/p\u003e\n\u003cp\u003eÁªìÊûú\u003c/p\u003e\n\u003cp\u003e\u003cimg alt=\"image-20250322150754528\" loading=\"lazy\" src=\"./NLP-2.assets/image-20250322150754528.png\"\u003e\u003c/p\u003e\n\u003cp\u003e‰ΩÜÊòØÈïøÂ∫¶‰∏çÁªü‰∏Ä\u003c/p\u003e\n\u003cp\u003eStep4: ÂØπÈΩêsequence\u003c/p\u003e\n\u003cp\u003e\u003cimg alt=\"image-20250322150854986\" loading=\"lazy\" src=\"./NLP-2.assets/image-20250322150854986.png\"\u003e\u003c/p\u003e\n\u003cp\u003eËß£ÂÜ≥ÊñπÊ°àÊòØËøôÊ†∑ÁöÑÔºöÂèØ‰ª•Âõ∫ÂÆöÈïøÂ∫¶‰∏∫wÔºåÂä†ÂÖ•‰∏Ä‰∏™Â∫èÂàóÈïøÂ∫¶Â§™ÈïøÔºåÂ∞±Á†çÊéâÂâçÈù¢ÁöÑËØçÔºåÂè™‰øùÁïôÊúÄÂêéw‰∏™ËØçÔºõÂ¶ÇÊûú‰∏Ä‰∏™Â∫èÂàóÂ§™Áü≠ÔºåÂ∞±ÂÅözero paddingÔºåÁî®0Â°´ÂÖÖ\u003c/p\u003e\n\u003cp\u003e\u003cimg alt=\"image-20250322151030119\" loading=\"lazy\" src=\"./NLP-2.assets/image-20250322151030119.png\"\u003e\u003c/p\u003e\n\u003cp\u003eËøôÊ†∑‰∏ÄÊù•ÔºåÊâÄÊúâÁöÑÂ∫èÂàóÈïøÂ∫¶Â∞±Áªü‰∏Ä‰∫Ü\u003c/p\u003e\n\u003cp\u003e\u003cimg alt=\"image-20250322151117125\" loading=\"lazy\" src=\"./NLP-2.assets/image-20250322151117125.png\"\u003e\u003c/p\u003e\n\u003cp\u003eÊñáÊú¨Â§ÑÁêÜÂÆåÊàê‰∫ÜÔºåÊé•‰∏ãÊù•ÊòØword embeddingÔºåÊääÂçïËØçË°®Á§∫‰∏∫‰∏Ä‰∏™‰ΩéÁª¥ÂêëÈáèÔºõ\u003c/p\u003e\n\u003cp\u003e\u003cimg alt=\"image-20250322151252837\" loading=\"lazy\" src=\"./NLP-2.assets/image-20250322151252837.png\"\u003e\u003c/p\u003e","title":""},{"content":"üëã About me Hello! I\u0026rsquo;m Xu Zongsi, a passionate technology enthusiast currently pursuing my Master of Science in ECIC at The University of Hong Kong. With a solid background in Software Engineering from the Beijing Institute of Technology, I specialize in emerging areas of artificial intelligence, including machine learning, deep learning, natural language processing, computer vision, and reinforcement learning.\nRecently, inspired by OpenAI\u0026rsquo;s five-step plan towards superintelligence, I have great expectations for AGI and developed a strong interest in LLM agents, MLLM, reinforcement learning, and knowledge graphs. I believe there is significant potential in these fields to create innovative solutions, and I hope to contribute my efforts towards that goal.\nüìö Education üá≠üá∞ The University of Hong Kong 09/2024 - Expected 11/2025 School of Computing and Data Science Master of Science in Electronic Commerce \u0026amp; Internet Computing Relevant Courses: Machine learning for business and e-commerce, Knowledge graphs, Financial fraud analytics, Internet infrastructure technologies, Website engineering, Blockchain and cryptocurrency, etc. üá®üá≥ Beijing Institute of Technology 09/2020 - 06/2024 School of Computer Science \u0026amp; Technology Bachelor of Engineering in Software Engineering, last two years GPA: 3.7/4 Relevant Courses: Reinforcement Learning, Deep Learning and Computer Vision, Artificial Intelligence and Robot Ethics, Almost Human: Mind, Brain and Artificial Intelligence, Mathematical Analysis for Engineering, Linear Algebra, Probability and Mathematical Statistics, etc. Skills: Python, Java, common data structures, design patterns, machine learning basics and algorithms, Linux, PyTorch, and some development tools (git, conda, etc.). üèÜ Awards \u0026amp; Honors Beijing Institute of Technology Undergraduate Scholarship (Top 20% of Grade) 06/2023 3rd Prize of China International \u0026#34;Internet \u0026#43;\u0026#34; College Student\u0026#39;s Innovation Competition 08/2022 Bronze Prize of \u0026#34;Challenge Cup\u0026#34; Capital University Entrepreneurship Competition 05/2022 üíº Project Experience Online Transaction Fraud Detection 09/2024 ‚Äì 01/2025 Independent project, supervised by Dr. Vivien Chan Focused on addressing financial fraud in e-commerce to enhance the accuracy of transaction anomaly detection, while independently managing the entire case study that included data preprocessing, feature engineering, model building, evaluation, and results analysis. Effectively resolved class imbalance issues using SMOTE and ROSE techniques. Built various models including Logistic Regression, Random Forest, XGBoost, and LightGBM, ultimately selecting the LightGBM model to achieve a recall rate of 95.45% and an AUC of 99.84%. Wrote efficient and maintainable code, enhancing model training and data processing efficiency through parallel computing and logging. Multi-Model Intelligent Text Keyword Extraction System 08/2023 ‚Äì 09/2023 Group project, supervised by Associate Prof. Xiaolin Zhao Designed and implemented an intelligent text summary system that automatically extracts keywords from article titles and abstracts, enhancing the understanding and summarization of text information. Participated in the planning of the technical route and built a hybrid model combining extractive and generative approaches, utilizing advanced natural language processing techniques including KeyBERT, Sentence Transformer, BERT, and T5 models. Responsible for data preprocessing and tokenization, as well as the end-to-end implementation and training of the T5 model, optimizing the model architecture and hyperparameters, achieving satisfactory results after only 3 epochs of training. Model evaluation results showed that the Rouge-1, Rouge-2, and Rouge-L metrics reached 0.6345, 0.5038, and 0.5282, respectively, in the third epoch, validating the model\u0026rsquo;s effectiveness in the summarization task. Cambridge University Machine Learning Summer Project 07/2023 ‚Äì 08/2023 Group project, supervised by Prof. Pietro Li√≤ Participated in the Cambridge University deep learning summer project, focusing on deep reinforcement learning; explored multi-agent learning algorithms across different environments. Reproduced the Multi-Agent Deep Deterministic Policy Gradient (MADDPG) algorithm in the Simple Adversary environment and studied the effect of agent numbers on convergence speed and stability, finding optimal stability at 21 agents. Designed and implemented comparative experiments inspired by the Rainbow algorithm, assessing target network strategies versus the Double Deep Q-Network (Double DQN). The results demonstrated that Double DQN significantly enhanced convergence speed, optimizing the overall learning process. Co-authored a group project paper on agent numbers and strategies effectiveness in multi-agent systems, achieving a score of 71% in the summer program (the highest in my group) and a \u0026ldquo;First Class\u0026rdquo; classification in the UK grading system. Deep Learning and Computer Vision Semester Project 09/2022 ‚Äì 12/2022 Independent project, supervised by Associate Prof. Guangyu Gao Designed and implemented a waste classifier using the ResNet model to improve classification accuracy and reduce resource waste. The project also enhanced understanding of transfer learning techniques with ResNet. Collected a dataset of 16 waste categories and preprocessed the images for uniformity and standardization, incorporating data augmentation techniques to enhance the dataset. Conducted experiments using ResNet34 and ResNet50 models through transfer learning, accelerating network convergence by leveraging pretrained weights. During training, techniques such as Batch Normalization and Dropout were applied to mitigate the risk of overfitting. The final model achieved an accuracy of 90% on the training set, while the performance on the test set was 61%, indicating a significant overfitting phenomenon during the training process. üéì Internship Beijing Academy of Quantum Information Science 08/2023 ‚Äì 01/2024 Research Intern at Quantum Computation Department Proposed a quantum convolution kernel design based on variational quantum circuits and developed a universal quantum convolution layer, successfully integrating it into classical CNN architectures such as VGG, GoogLeNet, and ResNet. Developed and evaluated various hybrid models, including a simple model named HQCCNN-2, which achieved 84.45% accuracy on the FashionMNIST dataset, surpassing the traditional CNN\u0026rsquo;s 80.72%. This demonstrates the effectiveness of the quantum convolution layer in improving model performance. Tested on a real quantum computer further validated the effectiveness of the hybrid model, demonstrating the viable integration of quantum computing with deep learning, and highlighting the potential for leveraging quantum properties to enhance model performance. üèÖ Competition Experience China International \u0026#34;Internet \u0026#43;\u0026#34; College Students\u0026#39; Innovation Competition 08/2022 Zhongke Ushield: Deep Learning-based Face Privacy Protection Authentication System Responsible for constructing a localized facial feature extraction engine based on MobileFaceNet, ensuring feature extraction is completed on end devices (such as mobile phones and cameras), guaranteeing that raw data does not leave the domain and is not stored, thus enhancing user privacy protection while improving recognition efficiency. \u0026#34;Challenge Cup\u0026#34; Capital University Entrepreneurship Competition 05/2022 Smart Orchard Responsible for the development of the fruit detection, ripeness prediction, and pest identification system, using deep convolutional neural network (CNN) technology for intelligent monitoring of crop growth conditions. Applied advanced object detection algorithms such as Faster R-CNN and YOLO to achieve high precision in apple detection and ripeness assessment, with an accuracy rate exceeding 90%, significantly enhancing the intelligence level of orchard management. Built and trained a dedicated dataset containing various pest samples, optimizing pest detection accuracy through data preprocessing (such as image normalization and resizing) and data augmentation techniques (like rotation, flipping, and noise addition), enabling the real-time monitoring system to accurately identify over 80% of pests, providing effective scientific maintenance recommendations to help farmers reduce crop losses. üìã Extracurricular Activities Vice President, Cyber Security Club, Beijing Institute of Technology 09/2021-09/2022 Backbone, Media Center of the Student Union of Beijing Institute of Technology 10/2020-06/2021 üì´ Contact üìß zongsi.xu@outlook.com üëî Zongsi (Tristan) Xu üíª github.com/BaizeXS üìç Hong Kong SAR, China ","permalink":"http://localhost:1313/resume/","summary":"Personal resume of Zongsi (Tristan) Xu","title":"Zongsi (Tristan) Xu"},{"content":"‰∏Ä„ÄÅÊï∞ÂÄºÁâπÂæÅ‰∏éÁ±ªÂà´ÁâπÂæÅ Êï∞ÂÄºÁâπÂæÅ (Numeric Features) ÂÖ∑ÊúâÂèØÂä†ÂáèÁöÑÊÑè‰πâÔºå‰∏îÂ≠òÂú®Â§ßÂ∞èÈ°∫Â∫è„ÄÇ ‰æãÂ≠êÔºöÂπ¥ÈæÑ„ÄÅÊ∏©Â∫¶Á≠â„ÄÇÂèØ‰ª•Áõ¥Êé•‰øùÁïôÂÖ∂Êï¥Êï∞ÊàñÊµÆÁÇπÊï∞ÂΩ¢Âºè‰æõÊ®°Âûã‰ΩøÁî®„ÄÇ Á±ªÂà´ÁâπÂæÅ (Categorical Features) Êï∞ÊçÆÂÄºÁ¶ªÊï£Ôºå‰∏çÂÖ∑Â§á‚ÄúÊï∞ÂÄºÂ§ßÂ∞è‚ÄùÈó¥ÁöÑÂèØÊØîÊÑè‰πâ„ÄÇ ‰æãÂ≠êÔºöÂõΩÁ±çÔºàÁæéÂõΩ/‰∏≠ÂõΩ/Âç∞Â∫¶Á≠âÔºâ„ÄÅÊÄßÂà´ÔºàÁî∑/Â•≥ÔºâÁ≠â„ÄÇ ÈóÆÈ¢òÔºöËã•‰ªÖÁî®Êï¥Êï∞Ë°®Á§∫ÔºàÁæéÂõΩ=1, ‰∏≠ÂõΩ=2ÔºâÔºå‰ºöÂºïÂÖ•ÈîôËØØÁöÑÊï∞ÂÄºËøêÁÆóÂÖ≥Á≥ªÔºåÂ¶Ç ‚ÄúÁæéÂõΩ + ‰∏≠ÂõΩ = Âç∞Â∫¶‚Äù„ÄÇ ‰∫å„ÄÅOne-HotÁºñÁ†ÅÁöÑÂä®Êú∫‰∏éÊµÅÁ®ã ‰∏∫‰ªÄ‰πà‰ΩøÁî®One-Hot\nÈÄöËøáÂ∞ÜÁ±ªÂà´Êò†Â∞Ñ‰∏∫ÂêëÈáèÔºåÈÅøÂÖçÊï¥Êï∞ÁºñÁ†ÅÂºïÂÖ•ÁöÑ‰º™Êï∞ÂÄºÂÖ≥Á≥ª„ÄÇ ÂêåÊó∂‰øùÁïôÂêÑÁßçÂèØËÉΩÁ±ªÂà´ÁöÑ‰ø°ÊÅØÔºå‰∏î‰ªÖÂú®ÂØπÂ∫î‰ΩçÁΩÆ‰∏∫1ÔºåÂÖ∂‰ªñ‰ΩçÁΩÆ‰∏∫0„ÄÇ Âª∫Á´ãÊò†Â∞ÑÔºö‰ªéÁ±ªÂà´Âà∞Á¥¢Âºï\n‰∏∫ÊØè‰∏™Á±ªÂà´ÂàÜÈÖç‰∏Ä‰∏™ÂîØ‰∏ÄÁ¥¢ÂºïÔºåÈÄöÂ∏∏‰ªé1ÂºÄÂßã„ÄÇ È¢ÑÁïôÁ¥¢Âºï0Ë°®Á§∫‚ÄúÊú™Áü•‚ÄùÊàñ‚ÄúÁº∫Â§±‚ÄùÔºåÂØπÂ∫îÂÖ®0ÂêëÈáè„ÄÇ ËΩ¨Êç¢‰∏∫One-HotÂêëÈáè\nËã•Á±ªÂà´ÊÄªÊï∞‰∏∫197ÔºåÂàôÁî®197Áª¥ÂêëÈáèË°®Á§∫„ÄÇ ‰æãÂ≠êÔºöÁæéÂõΩ [1, 0, 0, 0, ‚Ä¶]Ôºå ‰∏≠ÂõΩ [0, 1, 0, 0, ‚Ä¶]„ÄÇ Á§∫‰æãÔºöË°®Á§∫‰∏Ä‰∏™‰∫∫ÁöÑÁâπÂæÅ\nÁâπÂæÅÂåÖÂê´ÔºàÂπ¥ÈæÑ, ÊÄßÂà´, ÂõΩÁ±çÔºåÂÖ∂‰∏≠ÂõΩÁ±ç197ÁßçÔºâ Áª¥Â∫¶ÊÄªÂíåÔºö1Áª¥_age + 1Áª¥_gender + 197Áª¥_nationality = 199Áª¥„ÄÇ ‰æãÂ¶Ç (28, Â•≥, ‰∏≠ÂõΩ) ‚Üí [28, 0, 0, 1, 0, ‚Ä¶, 0]„ÄÇ ‰∏â„ÄÅÊñáÊú¨Êï∞ÊçÆÂ§ÑÁêÜÊµÅÁ®ã ÊñáÊú¨Âú®Ëá™ÁÑ∂ËØ≠Ë®ÄÂ§ÑÁêÜÔºàNLPÔºâ‰∏≠‰Ωú‰∏∫Â∏∏ËßÅÁöÑÂéüÂßãËæìÂÖ•ÔºåÈúÄË¶ÅÊï∞ÂÄºÂåñÊâçËÉΩÈÄÅÂÖ•Ê®°Âûã„ÄÇ‰∏ÄËà¨Ê≠•È™§Â¶Ç‰∏ãÔºö\nÂàÜËØç (Tokenization)\nÂ∞ÜÊñáÊú¨ÊãÜÂàÜ‰∏∫‰∏Ä‰∏™‰∏™ÂçïËØçÔºàTokenÔºâ„ÄÇ ‰æãÂ≠êÔºö\u0026quot;... to be or not to be...\u0026quot; ‚Üí [\u0026quot;...\u0026quot;, \u0026quot;to\u0026quot;, \u0026quot;be\u0026quot;, \u0026quot;or\u0026quot;, \u0026quot;not\u0026quot;, \u0026quot;to\u0026quot;, \u0026quot;be\u0026quot;, \u0026quot;...\u0026quot;]„ÄÇ ÁªüËÆ°ËØçÈ¢ë \u0026amp; ÊûÑÂª∫ËØçÂÖ∏\nËØçÈ¢ëÁªüËÆ° Áî®ÂìàÂ∏åË°®/Â≠óÂÖ∏ËÆ∞ÂΩïÊØè‰∏™ÂçïËØçÂá∫Áé∞Ê¨°Êï∞„ÄÇ ÈÅçÂéÜÊñáÊú¨Êó∂ÔºåËã•ÂçïËØçÂ∞öÊú™ÂÖ•Ë°®ÔºåÂàôÊñ∞Âª∫ËÆ∞ÂΩïÔºõËã•Â∑≤Â≠òÂú®ÔºåÂàôËÆ°Êï∞+1„ÄÇ ÊéíÂ∫è‰∏éÁ¥¢Âºï ÊåâËØçÈ¢ëÈôçÂ∫èÊéíÂ∫èÔºåËØçÈ¢ëÊúÄÈ´òÁöÑÂçïËØçÊéíÂú®ÂâçÈù¢„ÄÇ Á¥¢Âºï‰ªé1ÂºÄÂßãÔºå0ÁïôÁªô‚ÄúÊú™Áü•‚Äù„ÄÇ ËØçÂÖ∏ËßÑÊ®°ÔºàvocabularyÔºâÂèØËßÜÈúÄÊ±ÇÊà™Êñ≠Ôºà‰æãÂ¶ÇÂè™‰øùÁïôTop 10kÔºâ„ÄÇ ‰∏∫‰ªÄ‰πàÁßªÈô§‰ΩéÈ¢ëËØç ‰ΩéÈ¢ëËØçÂèØËÉΩÊòØÊãºÂÜôÈîôËØØ„ÄÅÁΩïËßÅ‰∫∫ÂêçÁ≠âÔºåÂØπÊ®°ÂûãÂ∏ÆÂä©ÊúâÈôê„ÄÇ ÂáèÂ∞ëËØçÂÖ∏ËßÑÊ®°ÂèØÈôç‰ΩéËøêÁÆóÂºÄÈîÄ„ÄÅÂä†Âø´Ê®°ÂûãËÆ≠ÁªÉ‰∏éÊé®ÁêÜÈÄüÂ∫¶„ÄÇ Áã¨ÁÉ≠ÁºñÁ†Å (One-Hot Encoding)\nÂ∞ÜÊØè‰∏™ÂçïËØçÊò†Â∞Ñ‰∏∫ËØçÂÖ∏‰∏≠ÁöÑÁ¥¢ÂºïÂêéÔºàÂ¶Ç [2, 4, 1, 8, ‚Ä¶]ÔºâÔºåÂèØËøõ‰∏ÄÊ≠•ËΩ¨Êç¢ÊàêOne-HotÂêëÈáè„ÄÇ One-HotÁª¥Â∫¶ÂèñÂÜ≥‰∫é‰øùÁïô‰∏ãÊù•ÁöÑËØçÂÖ∏Â§ßÂ∞èÔºà‰æãÂ¶Ç1‰∏áÔºâ„ÄÇ Êú™Êî∂ÂΩïÂçïËØçÂèØËÉΩÁõ¥Êé•ÂøΩÁï•ÔºåÊàñÁªü‰∏ÄÁî®Á¥¢Âºï0‰ª£Êõø„ÄÇ Âõõ„ÄÅÊ†∏ÂøÉÊî∂Ëé∑‰∏éÂ∫îÁî® Á±ªÂà´ÁâπÂæÅÂøÖÈúÄÊï∞ÂÄºÂåñÔºö\n‰ΩøÁî®Êï¥Êï∞1,2,3‚Ä¶‰ªÖË°®Á§∫Á±ªÂà´‚ÄúÊ†áËØÜ‚ÄùÔºåÂπ∂‰∏ç‰ª£Ë°®ÂÆÉ‰ª¨ÂèØËøõË°åÊï∞ÂÄºËøêÁÆó„ÄÇ Âõ†Ê≠§ÈúÄË¶ÅOne-HotÁ≠âÁºñÁ†ÅÊñπÂºèÔºåÈÅøÂÖçÊï∞ÂÄºËØØËß£„ÄÇ ÊñáÊú¨Êï∞ÊçÆÈ¢ÑÂ§ÑÁêÜÔºö\nÂàÜËØç„ÄÅËØçÈ¢ëÁªüËÆ°„ÄÅÊûÑÂª∫ËØçÂÖ∏„ÄÅÁ¥¢ÂºïÂåñ„ÄÅOne-HotÊàñÂÖ∂‰ªñÊñπÂºèÔºàÂ¶ÇËØçÂµåÂÖ•ÔºâÊòØÂ∏∏ËßÅÊµÅÁ®ã„ÄÇ Ê≠£Á°ÆÁöÑÊñáÊú¨È¢ÑÂ§ÑÁêÜÂèØÊòæËëóÂΩ±ÂìçÊ®°ÂûãÊÄßËÉΩÂíåÊïàÁéá„ÄÇ ‰øùÁïôÊú™Áü•Á¥¢ÂºïÔºö\n‰øùËØÅÂØπÁº∫Â§±Êï∞ÊçÆÊàñÂ≠óÂÖ∏Â§ñÊñ∞ËØçËÉΩÊúâÂü∫Êú¨ÁöÑË°®Á§∫ÔºåÊèêÂçáÊ®°ÂûãÂÆπÈîôÊÄß„ÄÇ ÂÆûÈôÖ‰ΩøÁî®Ôºö\nÂØπ‰∫éÂ∞èËßÑÊ®°Á±ªÂà´ÂèØÁõ¥Êé•One-HotÁºñÁ†ÅÔºõÂØπ‰∫éËØçÂÖ∏ÂæàÂ§ßÁöÑÂú∫ÊôØÔºåÈÄöÂ∏∏‰ºöËøõ‰∏ÄÊ≠•ËÄÉËôëËØçÂµåÂÖ•ÔºàWord EmbeddingÔºâÊàñÈ¢ÑËÆ≠ÁªÉËØ≠Ë®ÄÊ®°Âûã„ÄÇ ","permalink":"http://localhost:1313/posts/nlp-1/","summary":"\u003ch2 id=\"‰∏ÄÊï∞ÂÄºÁâπÂæÅ‰∏éÁ±ªÂà´ÁâπÂæÅ\"\u003e‰∏Ä„ÄÅÊï∞ÂÄºÁâπÂæÅ‰∏éÁ±ªÂà´ÁâπÂæÅ\u003c/h2\u003e\n\u003col\u003e\n\u003cli\u003e\u003cstrong\u003eÊï∞ÂÄºÁâπÂæÅ (Numeric Features)\u003c/strong\u003e\n\u003cul\u003e\n\u003cli\u003eÂÖ∑ÊúâÂèØÂä†ÂáèÁöÑÊÑè‰πâÔºå‰∏îÂ≠òÂú®Â§ßÂ∞èÈ°∫Â∫è„ÄÇ\u003c/li\u003e\n\u003cli\u003e‰æãÂ≠êÔºöÂπ¥ÈæÑ„ÄÅÊ∏©Â∫¶Á≠â„ÄÇÂèØ‰ª•Áõ¥Êé•‰øùÁïôÂÖ∂Êï¥Êï∞ÊàñÊµÆÁÇπÊï∞ÂΩ¢Âºè‰æõÊ®°Âûã‰ΩøÁî®„ÄÇ\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003eÁ±ªÂà´ÁâπÂæÅ (Categorical Features)\u003c/strong\u003e\n\u003cul\u003e\n\u003cli\u003eÊï∞ÊçÆÂÄºÁ¶ªÊï£Ôºå‰∏çÂÖ∑Â§á‚ÄúÊï∞ÂÄºÂ§ßÂ∞è‚ÄùÈó¥ÁöÑÂèØÊØîÊÑè‰πâ„ÄÇ\u003c/li\u003e\n\u003cli\u003e‰æãÂ≠êÔºöÂõΩÁ±çÔºàÁæéÂõΩ/‰∏≠ÂõΩ/Âç∞Â∫¶Á≠âÔºâ„ÄÅÊÄßÂà´ÔºàÁî∑/Â•≥ÔºâÁ≠â„ÄÇ\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003eÈóÆÈ¢ò\u003c/strong\u003eÔºöËã•‰ªÖÁî®Êï¥Êï∞Ë°®Á§∫ÔºàÁæéÂõΩ=1, ‰∏≠ÂõΩ=2ÔºâÔºå‰ºöÂºïÂÖ•ÈîôËØØÁöÑÊï∞ÂÄºËøêÁÆóÂÖ≥Á≥ªÔºåÂ¶Ç ‚ÄúÁæéÂõΩ + ‰∏≠ÂõΩ = Âç∞Â∫¶‚Äù„ÄÇ\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003c/ol\u003e\n\u003ch2 id=\"‰∫åone-hotÁºñÁ†ÅÁöÑÂä®Êú∫‰∏éÊµÅÁ®ã\"\u003e‰∫å„ÄÅOne-HotÁºñÁ†ÅÁöÑÂä®Êú∫‰∏éÊµÅÁ®ã\u003c/h2\u003e\n\u003col\u003e\n\u003cli\u003e\n\u003cp\u003e\u003cstrong\u003e‰∏∫‰ªÄ‰πà‰ΩøÁî®One-Hot\u003c/strong\u003e\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eÈÄöËøáÂ∞ÜÁ±ªÂà´Êò†Â∞Ñ‰∏∫ÂêëÈáèÔºåÈÅøÂÖçÊï¥Êï∞ÁºñÁ†ÅÂºïÂÖ•ÁöÑ‰º™Êï∞ÂÄºÂÖ≥Á≥ª„ÄÇ\u003c/li\u003e\n\u003cli\u003eÂêåÊó∂‰øùÁïôÂêÑÁßçÂèØËÉΩÁ±ªÂà´ÁöÑ‰ø°ÊÅØÔºå‰∏î‰ªÖÂú®ÂØπÂ∫î‰ΩçÁΩÆ‰∏∫1ÔºåÂÖ∂‰ªñ‰ΩçÁΩÆ‰∏∫0„ÄÇ\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003e\u003cstrong\u003eÂª∫Á´ãÊò†Â∞ÑÔºö‰ªéÁ±ªÂà´Âà∞Á¥¢Âºï\u003c/strong\u003e\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e‰∏∫ÊØè‰∏™Á±ªÂà´ÂàÜÈÖç‰∏Ä‰∏™ÂîØ‰∏ÄÁ¥¢ÂºïÔºåÈÄöÂ∏∏‰ªé1ÂºÄÂßã„ÄÇ\u003c/li\u003e\n\u003cli\u003eÈ¢ÑÁïôÁ¥¢Âºï0Ë°®Á§∫‚ÄúÊú™Áü•‚ÄùÊàñ‚ÄúÁº∫Â§±‚ÄùÔºåÂØπÂ∫îÂÖ®0ÂêëÈáè„ÄÇ\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003e\u003cstrong\u003eËΩ¨Êç¢‰∏∫One-HotÂêëÈáè\u003c/strong\u003e\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eËã•Á±ªÂà´ÊÄªÊï∞‰∏∫197ÔºåÂàôÁî®197Áª¥ÂêëÈáèË°®Á§∫„ÄÇ\u003c/li\u003e\n\u003cli\u003e‰æãÂ≠êÔºöÁæéÂõΩ \u003ccode\u003e[1, 0, 0, 0, ‚Ä¶]\u003c/code\u003eÔºå ‰∏≠ÂõΩ \u003ccode\u003e[0, 1, 0, 0, ‚Ä¶]\u003c/code\u003e„ÄÇ\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003e\u003cstrong\u003eÁ§∫‰æãÔºöË°®Á§∫‰∏Ä‰∏™‰∫∫ÁöÑÁâπÂæÅ\u003c/strong\u003e\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eÁâπÂæÅÂåÖÂê´ÔºàÂπ¥ÈæÑ, ÊÄßÂà´, ÂõΩÁ±çÔºåÂÖ∂‰∏≠ÂõΩÁ±ç197ÁßçÔºâ\u003c/li\u003e\n\u003cli\u003eÁª¥Â∫¶ÊÄªÂíåÔºö1Áª¥_age + 1Áª¥_gender + 197Áª¥_nationality = 199Áª¥„ÄÇ\u003c/li\u003e\n\u003cli\u003e‰æãÂ¶Ç \u003ccode\u003e(28, Â•≥, ‰∏≠ÂõΩ)\u003c/code\u003e ‚Üí \u003ccode\u003e[28, 0, 0, 1, 0, ‚Ä¶, 0]\u003c/code\u003e„ÄÇ\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003c/ol\u003e\n\u003ch2 id=\"‰∏âÊñáÊú¨Êï∞ÊçÆÂ§ÑÁêÜÊµÅÁ®ã\"\u003e‰∏â„ÄÅÊñáÊú¨Êï∞ÊçÆÂ§ÑÁêÜÊµÅÁ®ã\u003c/h2\u003e\n\u003cp\u003eÊñáÊú¨Âú®Ëá™ÁÑ∂ËØ≠Ë®ÄÂ§ÑÁêÜÔºàNLPÔºâ‰∏≠‰Ωú‰∏∫Â∏∏ËßÅÁöÑÂéüÂßãËæìÂÖ•ÔºåÈúÄË¶ÅÊï∞ÂÄºÂåñÊâçËÉΩÈÄÅÂÖ•Ê®°Âûã„ÄÇ‰∏ÄËà¨Ê≠•È™§Â¶Ç‰∏ãÔºö\u003c/p\u003e\n\u003col\u003e\n\u003cli\u003e\n\u003cp\u003e\u003cstrong\u003eÂàÜËØç (Tokenization)\u003c/strong\u003e\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eÂ∞ÜÊñáÊú¨ÊãÜÂàÜ‰∏∫‰∏Ä‰∏™‰∏™ÂçïËØçÔºàTokenÔºâ„ÄÇ\u003c/li\u003e\n\u003cli\u003e‰æãÂ≠êÔºö\u003ccode\u003e\u0026quot;... to be or not to be...\u0026quot;\u003c/code\u003e ‚Üí \u003ccode\u003e[\u0026quot;...\u0026quot;, \u0026quot;to\u0026quot;, \u0026quot;be\u0026quot;, \u0026quot;or\u0026quot;, \u0026quot;not\u0026quot;, \u0026quot;to\u0026quot;, \u0026quot;be\u0026quot;, \u0026quot;...\u0026quot;]\u003c/code\u003e„ÄÇ\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003e\u003cstrong\u003eÁªüËÆ°ËØçÈ¢ë \u0026amp; ÊûÑÂª∫ËØçÂÖ∏\u003c/strong\u003e\u003c/p\u003e","title":""},{"content":"Text to Sequence ÊñáÊú¨Â§ÑÁêÜ\nStep1: Tokenization\nTokenization breaks a piece of text down into a list of tokens.\nHere, a token is a word. (A token can be a character in some applications.)\nTokenizationËÆ≤Á©∂ÂæàÂ§öÔºå‰æãÂ¶ÇÊòØÂê¶Â∫îËØ•ÊääÂ§ßÂÜôÊîπÊàêÂ∞èÂÜôÂë¢ÔºüËøõË°åtypo correctionÁ≠âÁ≠â\nStep2: Build Dictionary\nUse a dictionary (hash table) to count word frequencies.\nThe dictionary maps word to index.\nÂèØ‰ª•È¶ñÂÖàÁªüËÆ°ËØçÈ¢ëÂéªÊéâ‰ΩéÈ¢ëËØçÔºåÁÑ∂ÂêéËÆ©ÊØè‰∏™ËØçÂØπÂ∫î‰∏Ä‰∏™Ê≠£Êï¥Êï∞ÔºõËøôÊ†∑ÁöÑËØùÔºå‰∏ÄÂè•ËØùÂ∞±ÂèØ‰ª•Áî®‰∏Ä‰∏™Ê≠£Êï¥Êï∞ÂàóË°®Ë°®Á§∫ÔºåËøô‰∏™ÂàóË°®Â∞±Âè´sequenceÔºõÂ¶ÇÊûúÂøÖË¶ÅÂ∞±ËøòÂæóÂÅöone-hot encoding„ÄÇ\nÁªìÊûú\n‰ΩÜÊòØÈïøÂ∫¶‰∏çÁªü‰∏Ä\nStep4: ÂØπÈΩêsequence\nËß£ÂÜ≥ÊñπÊ°àÊòØËøôÊ†∑ÁöÑÔºöÂèØ‰ª•Âõ∫ÂÆöÈïøÂ∫¶‰∏∫wÔºåÂä†ÂÖ•‰∏Ä‰∏™Â∫èÂàóÈïøÂ∫¶Â§™ÈïøÔºåÂ∞±Á†çÊéâÂâçÈù¢ÁöÑËØçÔºåÂè™‰øùÁïôÊúÄÂêéw‰∏™ËØçÔºõÂ¶ÇÊûú‰∏Ä‰∏™Â∫èÂàóÂ§™Áü≠ÔºåÂ∞±ÂÅözero paddingÔºåÁî®0Â°´ÂÖÖ\nËøôÊ†∑‰∏ÄÊù•ÔºåÊâÄÊúâÁöÑÂ∫èÂàóÈïøÂ∫¶Â∞±Áªü‰∏Ä‰∫Ü\nÊñáÊú¨Â§ÑÁêÜÂÆåÊàê‰∫ÜÔºåÊé•‰∏ãÊù•ÊòØword embeddingÔºåÊääÂçïËØçË°®Á§∫‰∏∫‰∏Ä‰∏™‰ΩéÁª¥ÂêëÈáèÔºõ\nÁÑ∂ËÄåËøôÊ†∑ÂÅöÁöÑËØùÔºåÂ¶ÇÊûúÊòØ10000‰∏™ÂçïËØçÔºåÁª¥Â∫¶Â∞±ÊòØ10000Áª¥ÔºåÁª¥Â∫¶Â§™È´ò‰∫ÜÔºõÂõ†Ê≠§Ë¶ÅÂÅöword embeddingÔºõ\nÂÖ∑‰ΩìÂÅöÊ≥ïÂ∞±ÊòØÊääone-hotÂêëÈáèe_iÂíåÂèÇÊï∞Áü©ÈòµpÁõ∏‰πòÔºõÁü©ÈòµPËΩ¨ÁΩÆÁöÑÂ§ßÂ∞èÊòØd x vÔºõdÊòØËØçÂêëÈáèÁöÑÁª¥Â∫¶ÔºõvÊòØÂ≠óÂÖ∏ÈáåËØçÊ±áÁöÑÊï∞ÈáèÔºõÁªìÊûú‰∏∫x_iÔºõx_iÂ∞±ÊòØ‰∏Ä‰∏™ËØçÂêëÈáèÔºõÂ¶ÇÊûúone-hotÂêëÈáèÁöÑÁ¨¨‰∏âË°å‰∏∫1ÔºõÈÇ£‰πàx_iÂ∞±ÊòØPËΩ¨ÁΩÆÁü©ÈòµÁöÑÁ¨¨‰∏âÂàóÔºàÂÖ∂‰ΩôÂàóÈÉΩ‰∏∫0ÔºâÔºõÊâÄ‰ª•PËΩ¨ÁΩÆÊØè‰∏ÄÂàóÈÉΩÊòØ‰∏Ä‰∏™ËØçÂêëÈáèÔºõÊâÄ‰ª•Áü©ÈòµPÊú¨Ë∫´ÁöÑÊØè‰∏ÄË°åÂ∞±ÊòØ‰∏Ä‰∏™ËØçÂêëÈáèÔºõÂÖ∂Ë°åÊï∞‰∏∫vÔºõÂç≥vocabularyÔºåËØçÊ±áÈáèÔºõÊØè‰∏ÄË°åÂØπÂ∫î‰∏Ä‰∏™ÂçïËØçÔºõÁü©ÈòµÁöÑÂàóÊï∞‰∏∫dÔºõdÊòØÁî®Êà∑ÂÜ≥ÂÆöÁöÑÔºõdÁöÑÂ§ßÂ∞è‰ºöÂÜ≥ÂÆöÊú∫Âô®Â≠¶‰π†Ê®°ÂûãÁöÑË°®Áé∞ÔºõÂ∫îËØ•Áî®xxxÊù•ÈÄâÊã©‰∏Ä‰∏™ÊØîËæÉÂ•ΩÁöÑdÔºõ\nÊàë‰ª¨ÁöÑ‰ªªÂä°ÊòØÁúãËØÑËÆ∫ÊòØÊ≠£Èù¢ÁöÑËøòÊòØË¥üÈù¢ÁöÑÔºõÂèÇÊï∞Áü©ÈòµÊòØ‰ªéËÆ≠ÁªÉÊï∞ÊçÆ‰∏≠Â≠¶‰π†Âá∫Êù•ÁöÑÔºåÊâÄ‰ª•Â≠¶Âá∫Êù•ÁöÑËØçÂêëÈáèÊòØÂ∏¶ÊúâÊÑüÊÉÖËâ≤ÂΩ©ÁöÑÔºõÂÅáËÆæËøô‰∫õËØçÂêëÈáèÈÉΩÊòØ‰∫åÁª¥ÁöÑÔºåÂàôÂèØ‰ª•Âú®Âπ≥Èù¢ÂùêÊ†áÁ≥ª‰∏≠Ê†áÂá∫‰∏ãÈù¢ËØçÂêëÈáè\nkerasÊèê‰æõembeddingÂ±ÇÔºõÁî®Êà∑ÂèØ‰ª•ÊåáÂÆövocabularyÂ§ßÂ∞èÂíådÁöÑÂ§ßÂ∞èÔºõ‰ª•ÂèäÊØè‰∏Ä‰∏™sequenceÁöÑÈïøÂ∫¶ÔºõdÊòØÊ†πÊçÆÁÆóÊ≥ïÈÄâÂá∫Êù•ÁöÑ Âà∞Ëøô‰∏ÄÊ≠•ÔºåÊàë‰ª¨Â∑≤ÁªèÂÆåÊàê‰∫ÜÊñáÊú¨Â§ÑÁêÜÂíåword embedding„ÄÇÊé•‰∏ãÊù•Â∞±ÊòØÁî®Logistic Regression for Binary ClassificationÂÅö‰∫åÂàÜÁ±ªÔºõ\n","permalink":"http://localhost:1313/posts/nlp-2/","summary":"\u003ch3 id=\"text-to-sequence\"\u003eText to Sequence\u003c/h3\u003e\n\u003cp\u003eÊñáÊú¨Â§ÑÁêÜ\u003c/p\u003e\n\u003cp\u003eStep1: Tokenization\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\n\u003cp\u003eTokenization breaks a piece of text down into a list of tokens.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003eHere, a token is a word. (A token can be a character in some applications.)\u003c/p\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003eTokenizationËÆ≤Á©∂ÂæàÂ§öÔºå‰æãÂ¶ÇÊòØÂê¶Â∫îËØ•ÊääÂ§ßÂÜôÊîπÊàêÂ∞èÂÜôÂë¢ÔºüËøõË°åtypo correctionÁ≠âÁ≠â\u003c/p\u003e\n\u003cp\u003e\u003cimg alt=\"image-20250322150322238\" loading=\"lazy\" src=\"./NLP-2.assets/image-20250322150322238.png\"\u003e\u003c/p\u003e\n\u003cp\u003eStep2: Build Dictionary\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\n\u003cp\u003eUse a dictionary (hash table) to count word frequencies.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003eThe dictionary maps word to index.\u003c/p\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003eÂèØ‰ª•È¶ñÂÖàÁªüËÆ°ËØçÈ¢ëÂéªÊéâ‰ΩéÈ¢ëËØçÔºåÁÑ∂ÂêéËÆ©ÊØè‰∏™ËØçÂØπÂ∫î‰∏Ä‰∏™Ê≠£Êï¥Êï∞ÔºõËøôÊ†∑ÁöÑËØùÔºå‰∏ÄÂè•ËØùÂ∞±ÂèØ‰ª•Áî®‰∏Ä‰∏™Ê≠£Êï¥Êï∞ÂàóË°®Ë°®Á§∫ÔºåËøô‰∏™ÂàóË°®Â∞±Âè´sequenceÔºõÂ¶ÇÊûúÂøÖË¶ÅÂ∞±ËøòÂæóÂÅöone-hot encoding„ÄÇ\u003cimg alt=\"image-20250322150620890\" loading=\"lazy\" src=\"./NLP-2.assets/image-20250322150620890.png\"\u003e\u003c/p\u003e\n\u003cp\u003eÁªìÊûú\u003c/p\u003e\n\u003cp\u003e\u003cimg alt=\"image-20250322150754528\" loading=\"lazy\" src=\"./NLP-2.assets/image-20250322150754528.png\"\u003e\u003c/p\u003e\n\u003cp\u003e‰ΩÜÊòØÈïøÂ∫¶‰∏çÁªü‰∏Ä\u003c/p\u003e\n\u003cp\u003eStep4: ÂØπÈΩêsequence\u003c/p\u003e\n\u003cp\u003e\u003cimg alt=\"image-20250322150854986\" loading=\"lazy\" src=\"./NLP-2.assets/image-20250322150854986.png\"\u003e\u003c/p\u003e\n\u003cp\u003eËß£ÂÜ≥ÊñπÊ°àÊòØËøôÊ†∑ÁöÑÔºöÂèØ‰ª•Âõ∫ÂÆöÈïøÂ∫¶‰∏∫wÔºåÂä†ÂÖ•‰∏Ä‰∏™Â∫èÂàóÈïøÂ∫¶Â§™ÈïøÔºåÂ∞±Á†çÊéâÂâçÈù¢ÁöÑËØçÔºåÂè™‰øùÁïôÊúÄÂêéw‰∏™ËØçÔºõÂ¶ÇÊûú‰∏Ä‰∏™Â∫èÂàóÂ§™Áü≠ÔºåÂ∞±ÂÅözero paddingÔºåÁî®0Â°´ÂÖÖ\u003c/p\u003e\n\u003cp\u003e\u003cimg alt=\"image-20250322151030119\" loading=\"lazy\" src=\"./NLP-2.assets/image-20250322151030119.png\"\u003e\u003c/p\u003e\n\u003cp\u003eËøôÊ†∑‰∏ÄÊù•ÔºåÊâÄÊúâÁöÑÂ∫èÂàóÈïøÂ∫¶Â∞±Áªü‰∏Ä‰∫Ü\u003c/p\u003e\n\u003cp\u003e\u003cimg alt=\"image-20250322151117125\" loading=\"lazy\" src=\"./NLP-2.assets/image-20250322151117125.png\"\u003e\u003c/p\u003e\n\u003cp\u003eÊñáÊú¨Â§ÑÁêÜÂÆåÊàê‰∫ÜÔºåÊé•‰∏ãÊù•ÊòØword embeddingÔºåÊääÂçïËØçË°®Á§∫‰∏∫‰∏Ä‰∏™‰ΩéÁª¥ÂêëÈáèÔºõ\u003c/p\u003e\n\u003cp\u003e\u003cimg alt=\"image-20250322151252837\" loading=\"lazy\" src=\"./NLP-2.assets/image-20250322151252837.png\"\u003e\u003c/p\u003e","title":""},{"content":"üëã About me Hello! I\u0026rsquo;m Xu Zongsi, a passionate technology enthusiast currently pursuing my Master of Science in ECIC at The University of Hong Kong. With a solid background in Software Engineering from the Beijing Institute of Technology, I specialize in emerging areas of artificial intelligence, including machine learning, deep learning, natural language processing, computer vision, and reinforcement learning.\nRecently, inspired by OpenAI\u0026rsquo;s five-step plan towards superintelligence, I have great expectations for AGI and developed a strong interest in LLM agents, MLLM, reinforcement learning, and knowledge graphs. I believe there is significant potential in these fields to create innovative solutions, and I hope to contribute my efforts towards that goal.\nüìö Education üá≠üá∞ The University of Hong Kong 09/2024 - Expected 11/2025 School of Computing and Data Science Master of Science in Electronic Commerce \u0026amp; Internet Computing Relevant Courses: Machine learning for business and e-commerce, Knowledge graphs, Financial fraud analytics, Internet infrastructure technologies, Website engineering, Blockchain and cryptocurrency, etc. üá®üá≥ Beijing Institute of Technology 09/2020 - 06/2024 School of Computer Science \u0026amp; Technology Bachelor of Engineering in Software Engineering, last two years GPA: 3.7/4 Relevant Courses: Reinforcement Learning, Deep Learning and Computer Vision, Artificial Intelligence and Robot Ethics, Almost Human: Mind, Brain and Artificial Intelligence, Mathematical Analysis for Engineering, Linear Algebra, Probability and Mathematical Statistics, etc. Skills: Python, Java, common data structures, design patterns, machine learning basics and algorithms, Linux, PyTorch, and some development tools (git, conda, etc.). üèÜ Awards \u0026amp; Honors Beijing Institute of Technology Undergraduate Scholarship (Top 20% of Grade) 06/2023 3rd Prize of China International \u0026#34;Internet \u0026#43;\u0026#34; College Student\u0026#39;s Innovation Competition 08/2022 Bronze Prize of \u0026#34;Challenge Cup\u0026#34; Capital University Entrepreneurship Competition 05/2022 üíº Project Experience üîç Online Transaction Fraud Detection 09/2024 ‚Äì 01/2025 Independent project, supervised by Dr. Vivien Chan Focused on addressing financial fraud in e-commerce to enhance the accuracy of transaction anomaly detection, while independently managing the entire case study that included data preprocessing, feature engineering, model building, evaluation, and results analysis. Effectively resolved class imbalance issues using SMOTE and ROSE techniques. Built various models including Logistic Regression, Random Forest, XGBoost, and LightGBM, ultimately selecting the LightGBM model to achieve a recall rate of 95.45% and an AUC of 99.84%. Wrote efficient and maintainable code, enhancing model training and data processing efficiency through parallel computing and logging. ü§ñ Multi-Model Intelligent Text Keyword Extraction System 08/2023 ‚Äì 09/2023 Group project, supervised by Associate Prof. Xiaolin Zhao Designed and implemented an intelligent text summary system that automatically extracts keywords from article titles and abstracts, enhancing the understanding and summarization of text information. Participated in the planning of the technical route and built a hybrid model combining extractive and generative approaches, utilizing advanced natural language processing techniques including KeyBERT, Sentence Transformer, BERT, and T5 models. Responsible for data preprocessing and tokenization, as well as the end-to-end implementation and training of the T5 model, optimizing the model architecture and hyperparameters, achieving satisfactory results after only 3 epochs of training. Model evaluation results showed that the Rouge-1, Rouge-2, and Rouge-L metrics reached 0.6345, 0.5038, and 0.5282, respectively, in the third epoch, validating the model\u0026rsquo;s effectiveness in the summarization task. üéì Cambridge University Machine Learning Summer Project 07/2023 ‚Äì 08/2023 Group project, supervised by Prof. Pietro Li√≤ Participated in the Cambridge University deep learning summer project, focusing on deep reinforcement learning; explored multi-agent learning algorithms across different environments. Reproduced the Multi-Agent Deep Deterministic Policy Gradient (MADDPG) algorithm in the Simple Adversary environment and studied the effect of agent numbers on convergence speed and stability, finding optimal stability at 21 agents. Designed and implemented comparative experiments inspired by the Rainbow algorithm, assessing target network strategies versus the Double Deep Q-Network (Double DQN). The results demonstrated that Double DQN significantly enhanced convergence speed, optimizing the overall learning process. Co-authored a group project paper on agent numbers and strategies effectiveness in multi-agent systems, achieving a score of 71% in the summer program (the highest in my group) and a \u0026ldquo;First Class\u0026rdquo; classification in the UK grading system. üëÅÔ∏è Deep Learning and Computer Vision Semester Project 09/2022 ‚Äì 12/2022 Independent project, supervised by Associate Prof. Guangyu Gao Designed and implemented a waste classifier using the ResNet model to improve classification accuracy and reduce resource waste. The project also enhanced understanding of transfer learning techniques with ResNet. Collected a dataset of 16 waste categories and preprocessed the images for uniformity and standardization, incorporating data augmentation techniques to enhance the dataset. Conducted experiments using ResNet34 and ResNet50 models through transfer learning, accelerating network convergence by leveraging pretrained weights. During training, techniques such as Batch Normalization and Dropout were applied to mitigate the risk of overfitting. The final model achieved an accuracy of 90% on the training set, while the performance on the test set was 61%, indicating a significant overfitting phenomenon during the training process. üéì Internship ‚öõÔ∏è Beijing Academy of Quantum Information Science 08/2023 ‚Äì 01/2024 Research Intern at Quantum Computation Department Proposed a quantum convolution kernel design based on variational quantum circuits and developed a universal quantum convolution layer, successfully integrating it into classical CNN architectures such as VGG, GoogLeNet, and ResNet. Developed and evaluated various hybrid models, including a simple model named HQCCNN-2, which achieved 84.45% accuracy on the FashionMNIST dataset, surpassing the traditional CNN\u0026rsquo;s 80.72%. This demonstrates the effectiveness of the quantum convolution layer in improving model performance. Tested on a real quantum computer further validated the effectiveness of the hybrid model, demonstrating the viable integration of quantum computing with deep learning, and highlighting the potential for leveraging quantum properties to enhance model performance. üèÖ Competition Experience ü•â China International \u0026#34;Internet \u0026#43;\u0026#34; College Students\u0026#39; Innovation Competition 08/2022 üõ°Ô∏è Zhongke Ushield: Deep Learning-based Face Privacy Protection Authentication System Responsible for constructing a localized facial feature extraction engine based on MobileFaceNet, ensuring feature extraction is completed on end devices (such as mobile phones and cameras), guaranteeing that raw data does not leave the domain and is not stored, thus enhancing user privacy protection while improving recognition efficiency. ü•â \u0026#34;Challenge Cup\u0026#34; Capital University Entrepreneurship Competition 05/2022 üå≥ Smart Orchard Responsible for the development of the fruit detection, ripeness prediction, and pest identification system, using deep convolutional neural network (CNN) technology for intelligent monitoring of crop growth conditions. Applied advanced object detection algorithms such as Faster R-CNN and YOLO to achieve high precision in apple detection and ripeness assessment, with an accuracy rate exceeding 90%, significantly enhancing the intelligence level of orchard management. Built and trained a dedicated dataset containing various pest samples, optimizing pest detection accuracy through data preprocessing (such as image normalization and resizing) and data augmentation techniques (like rotation, flipping, and noise addition), enabling the real-time monitoring system to accurately identify over 80% of pests, providing effective scientific maintenance recommendations to help farmers reduce crop losses. üìã Extracurricular Activities Vice President, Cyber Security Club, Beijing Institute of Technology 09/2021-09/2022 Backbone, Media Center of the Student Union of Beijing Institute of Technology 10/2020-06/2021 üì´ Contact üìß zongsi.xu@outlook.com üëî Zongsi (Tristan) Xu üíª github.com/BaizeXS üìç Hong Kong SAR, China ","permalink":"http://localhost:1313/resume/","summary":"Personal resume of Zongsi (Tristan) Xu","title":"Zongsi (Tristan) Xu"},{"content":"‰∏Ä„ÄÅÊï∞ÂÄºÁâπÂæÅ‰∏éÁ±ªÂà´ÁâπÂæÅ Êï∞ÂÄºÁâπÂæÅ (Numeric Features) ÂÖ∑ÊúâÂèØÂä†ÂáèÁöÑÊÑè‰πâÔºå‰∏îÂ≠òÂú®Â§ßÂ∞èÈ°∫Â∫è„ÄÇ ‰æãÂ≠êÔºöÂπ¥ÈæÑ„ÄÅÊ∏©Â∫¶Á≠â„ÄÇÂèØ‰ª•Áõ¥Êé•‰øùÁïôÂÖ∂Êï¥Êï∞ÊàñÊµÆÁÇπÊï∞ÂΩ¢Âºè‰æõÊ®°Âûã‰ΩøÁî®„ÄÇ Á±ªÂà´ÁâπÂæÅ (Categorical Features) Êï∞ÊçÆÂÄºÁ¶ªÊï£Ôºå‰∏çÂÖ∑Â§á‚ÄúÊï∞ÂÄºÂ§ßÂ∞è‚ÄùÈó¥ÁöÑÂèØÊØîÊÑè‰πâ„ÄÇ ‰æãÂ≠êÔºöÂõΩÁ±çÔºàÁæéÂõΩ/‰∏≠ÂõΩ/Âç∞Â∫¶Á≠âÔºâ„ÄÅÊÄßÂà´ÔºàÁî∑/Â•≥ÔºâÁ≠â„ÄÇ ÈóÆÈ¢òÔºöËã•‰ªÖÁî®Êï¥Êï∞Ë°®Á§∫ÔºàÁæéÂõΩ=1, ‰∏≠ÂõΩ=2ÔºâÔºå‰ºöÂºïÂÖ•ÈîôËØØÁöÑÊï∞ÂÄºËøêÁÆóÂÖ≥Á≥ªÔºåÂ¶Ç ‚ÄúÁæéÂõΩ + ‰∏≠ÂõΩ = Âç∞Â∫¶‚Äù„ÄÇ ‰∫å„ÄÅOne-HotÁºñÁ†ÅÁöÑÂä®Êú∫‰∏éÊµÅÁ®ã ‰∏∫‰ªÄ‰πà‰ΩøÁî®One-Hot\nÈÄöËøáÂ∞ÜÁ±ªÂà´Êò†Â∞Ñ‰∏∫ÂêëÈáèÔºåÈÅøÂÖçÊï¥Êï∞ÁºñÁ†ÅÂºïÂÖ•ÁöÑ‰º™Êï∞ÂÄºÂÖ≥Á≥ª„ÄÇ ÂêåÊó∂‰øùÁïôÂêÑÁßçÂèØËÉΩÁ±ªÂà´ÁöÑ‰ø°ÊÅØÔºå‰∏î‰ªÖÂú®ÂØπÂ∫î‰ΩçÁΩÆ‰∏∫1ÔºåÂÖ∂‰ªñ‰ΩçÁΩÆ‰∏∫0„ÄÇ Âª∫Á´ãÊò†Â∞ÑÔºö‰ªéÁ±ªÂà´Âà∞Á¥¢Âºï\n‰∏∫ÊØè‰∏™Á±ªÂà´ÂàÜÈÖç‰∏Ä‰∏™ÂîØ‰∏ÄÁ¥¢ÂºïÔºåÈÄöÂ∏∏‰ªé1ÂºÄÂßã„ÄÇ È¢ÑÁïôÁ¥¢Âºï0Ë°®Á§∫‚ÄúÊú™Áü•‚ÄùÊàñ‚ÄúÁº∫Â§±‚ÄùÔºåÂØπÂ∫îÂÖ®0ÂêëÈáè„ÄÇ ËΩ¨Êç¢‰∏∫One-HotÂêëÈáè\nËã•Á±ªÂà´ÊÄªÊï∞‰∏∫197ÔºåÂàôÁî®197Áª¥ÂêëÈáèË°®Á§∫„ÄÇ ‰æãÂ≠êÔºöÁæéÂõΩ [1, 0, 0, 0, ‚Ä¶]Ôºå ‰∏≠ÂõΩ [0, 1, 0, 0, ‚Ä¶]„ÄÇ Á§∫‰æãÔºöË°®Á§∫‰∏Ä‰∏™‰∫∫ÁöÑÁâπÂæÅ\nÁâπÂæÅÂåÖÂê´ÔºàÂπ¥ÈæÑ, ÊÄßÂà´, ÂõΩÁ±çÔºåÂÖ∂‰∏≠ÂõΩÁ±ç197ÁßçÔºâ Áª¥Â∫¶ÊÄªÂíåÔºö1Áª¥_age + 1Áª¥_gender + 197Áª¥_nationality = 199Áª¥„ÄÇ ‰æãÂ¶Ç (28, Â•≥, ‰∏≠ÂõΩ) ‚Üí [28, 0, 0, 1, 0, ‚Ä¶, 0]„ÄÇ ‰∏â„ÄÅÊñáÊú¨Êï∞ÊçÆÂ§ÑÁêÜÊµÅÁ®ã ÊñáÊú¨Âú®Ëá™ÁÑ∂ËØ≠Ë®ÄÂ§ÑÁêÜÔºàNLPÔºâ‰∏≠‰Ωú‰∏∫Â∏∏ËßÅÁöÑÂéüÂßãËæìÂÖ•ÔºåÈúÄË¶ÅÊï∞ÂÄºÂåñÊâçËÉΩÈÄÅÂÖ•Ê®°Âûã„ÄÇ‰∏ÄËà¨Ê≠•È™§Â¶Ç‰∏ãÔºö\nÂàÜËØç (Tokenization)\nÂ∞ÜÊñáÊú¨ÊãÜÂàÜ‰∏∫‰∏Ä‰∏™‰∏™ÂçïËØçÔºàTokenÔºâ„ÄÇ ‰æãÂ≠êÔºö\u0026quot;... to be or not to be...\u0026quot; ‚Üí [\u0026quot;...\u0026quot;, \u0026quot;to\u0026quot;, \u0026quot;be\u0026quot;, \u0026quot;or\u0026quot;, \u0026quot;not\u0026quot;, \u0026quot;to\u0026quot;, \u0026quot;be\u0026quot;, \u0026quot;...\u0026quot;]„ÄÇ ÁªüËÆ°ËØçÈ¢ë \u0026amp; ÊûÑÂª∫ËØçÂÖ∏\nËØçÈ¢ëÁªüËÆ° Áî®ÂìàÂ∏åË°®/Â≠óÂÖ∏ËÆ∞ÂΩïÊØè‰∏™ÂçïËØçÂá∫Áé∞Ê¨°Êï∞„ÄÇ ÈÅçÂéÜÊñáÊú¨Êó∂ÔºåËã•ÂçïËØçÂ∞öÊú™ÂÖ•Ë°®ÔºåÂàôÊñ∞Âª∫ËÆ∞ÂΩïÔºõËã•Â∑≤Â≠òÂú®ÔºåÂàôËÆ°Êï∞+1„ÄÇ ÊéíÂ∫è‰∏éÁ¥¢Âºï ÊåâËØçÈ¢ëÈôçÂ∫èÊéíÂ∫èÔºåËØçÈ¢ëÊúÄÈ´òÁöÑÂçïËØçÊéíÂú®ÂâçÈù¢„ÄÇ Á¥¢Âºï‰ªé1ÂºÄÂßãÔºå0ÁïôÁªô‚ÄúÊú™Áü•‚Äù„ÄÇ ËØçÂÖ∏ËßÑÊ®°ÔºàvocabularyÔºâÂèØËßÜÈúÄÊ±ÇÊà™Êñ≠Ôºà‰æãÂ¶ÇÂè™‰øùÁïôTop 10kÔºâ„ÄÇ ‰∏∫‰ªÄ‰πàÁßªÈô§‰ΩéÈ¢ëËØç ‰ΩéÈ¢ëËØçÂèØËÉΩÊòØÊãºÂÜôÈîôËØØ„ÄÅÁΩïËßÅ‰∫∫ÂêçÁ≠âÔºåÂØπÊ®°ÂûãÂ∏ÆÂä©ÊúâÈôê„ÄÇ ÂáèÂ∞ëËØçÂÖ∏ËßÑÊ®°ÂèØÈôç‰ΩéËøêÁÆóÂºÄÈîÄ„ÄÅÂä†Âø´Ê®°ÂûãËÆ≠ÁªÉ‰∏éÊé®ÁêÜÈÄüÂ∫¶„ÄÇ Áã¨ÁÉ≠ÁºñÁ†Å (One-Hot Encoding)\nÂ∞ÜÊØè‰∏™ÂçïËØçÊò†Â∞Ñ‰∏∫ËØçÂÖ∏‰∏≠ÁöÑÁ¥¢ÂºïÂêéÔºàÂ¶Ç [2, 4, 1, 8, ‚Ä¶]ÔºâÔºåÂèØËøõ‰∏ÄÊ≠•ËΩ¨Êç¢ÊàêOne-HotÂêëÈáè„ÄÇ One-HotÁª¥Â∫¶ÂèñÂÜ≥‰∫é‰øùÁïô‰∏ãÊù•ÁöÑËØçÂÖ∏Â§ßÂ∞èÔºà‰æãÂ¶Ç1‰∏áÔºâ„ÄÇ Êú™Êî∂ÂΩïÂçïËØçÂèØËÉΩÁõ¥Êé•ÂøΩÁï•ÔºåÊàñÁªü‰∏ÄÁî®Á¥¢Âºï0‰ª£Êõø„ÄÇ Âõõ„ÄÅÊ†∏ÂøÉÊî∂Ëé∑‰∏éÂ∫îÁî® Á±ªÂà´ÁâπÂæÅÂøÖÈúÄÊï∞ÂÄºÂåñÔºö\n‰ΩøÁî®Êï¥Êï∞1,2,3‚Ä¶‰ªÖË°®Á§∫Á±ªÂà´‚ÄúÊ†áËØÜ‚ÄùÔºåÂπ∂‰∏ç‰ª£Ë°®ÂÆÉ‰ª¨ÂèØËøõË°åÊï∞ÂÄºËøêÁÆó„ÄÇ Âõ†Ê≠§ÈúÄË¶ÅOne-HotÁ≠âÁºñÁ†ÅÊñπÂºèÔºåÈÅøÂÖçÊï∞ÂÄºËØØËß£„ÄÇ ÊñáÊú¨Êï∞ÊçÆÈ¢ÑÂ§ÑÁêÜÔºö\nÂàÜËØç„ÄÅËØçÈ¢ëÁªüËÆ°„ÄÅÊûÑÂª∫ËØçÂÖ∏„ÄÅÁ¥¢ÂºïÂåñ„ÄÅOne-HotÊàñÂÖ∂‰ªñÊñπÂºèÔºàÂ¶ÇËØçÂµåÂÖ•ÔºâÊòØÂ∏∏ËßÅÊµÅÁ®ã„ÄÇ Ê≠£Á°ÆÁöÑÊñáÊú¨È¢ÑÂ§ÑÁêÜÂèØÊòæËëóÂΩ±ÂìçÊ®°ÂûãÊÄßËÉΩÂíåÊïàÁéá„ÄÇ ‰øùÁïôÊú™Áü•Á¥¢ÂºïÔºö\n‰øùËØÅÂØπÁº∫Â§±Êï∞ÊçÆÊàñÂ≠óÂÖ∏Â§ñÊñ∞ËØçËÉΩÊúâÂü∫Êú¨ÁöÑË°®Á§∫ÔºåÊèêÂçáÊ®°ÂûãÂÆπÈîôÊÄß„ÄÇ ÂÆûÈôÖ‰ΩøÁî®Ôºö\nÂØπ‰∫éÂ∞èËßÑÊ®°Á±ªÂà´ÂèØÁõ¥Êé•One-HotÁºñÁ†ÅÔºõÂØπ‰∫éËØçÂÖ∏ÂæàÂ§ßÁöÑÂú∫ÊôØÔºåÈÄöÂ∏∏‰ºöËøõ‰∏ÄÊ≠•ËÄÉËôëËØçÂµåÂÖ•ÔºàWord EmbeddingÔºâÊàñÈ¢ÑËÆ≠ÁªÉËØ≠Ë®ÄÊ®°Âûã„ÄÇ ","permalink":"http://localhost:1313/posts/nlp-1/","summary":"\u003ch2 id=\"‰∏ÄÊï∞ÂÄºÁâπÂæÅ‰∏éÁ±ªÂà´ÁâπÂæÅ\"\u003e‰∏Ä„ÄÅÊï∞ÂÄºÁâπÂæÅ‰∏éÁ±ªÂà´ÁâπÂæÅ\u003c/h2\u003e\n\u003col\u003e\n\u003cli\u003e\u003cstrong\u003eÊï∞ÂÄºÁâπÂæÅ (Numeric Features)\u003c/strong\u003e\n\u003cul\u003e\n\u003cli\u003eÂÖ∑ÊúâÂèØÂä†ÂáèÁöÑÊÑè‰πâÔºå‰∏îÂ≠òÂú®Â§ßÂ∞èÈ°∫Â∫è„ÄÇ\u003c/li\u003e\n\u003cli\u003e‰æãÂ≠êÔºöÂπ¥ÈæÑ„ÄÅÊ∏©Â∫¶Á≠â„ÄÇÂèØ‰ª•Áõ¥Êé•‰øùÁïôÂÖ∂Êï¥Êï∞ÊàñÊµÆÁÇπÊï∞ÂΩ¢Âºè‰æõÊ®°Âûã‰ΩøÁî®„ÄÇ\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003eÁ±ªÂà´ÁâπÂæÅ (Categorical Features)\u003c/strong\u003e\n\u003cul\u003e\n\u003cli\u003eÊï∞ÊçÆÂÄºÁ¶ªÊï£Ôºå‰∏çÂÖ∑Â§á‚ÄúÊï∞ÂÄºÂ§ßÂ∞è‚ÄùÈó¥ÁöÑÂèØÊØîÊÑè‰πâ„ÄÇ\u003c/li\u003e\n\u003cli\u003e‰æãÂ≠êÔºöÂõΩÁ±çÔºàÁæéÂõΩ/‰∏≠ÂõΩ/Âç∞Â∫¶Á≠âÔºâ„ÄÅÊÄßÂà´ÔºàÁî∑/Â•≥ÔºâÁ≠â„ÄÇ\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003eÈóÆÈ¢ò\u003c/strong\u003eÔºöËã•‰ªÖÁî®Êï¥Êï∞Ë°®Á§∫ÔºàÁæéÂõΩ=1, ‰∏≠ÂõΩ=2ÔºâÔºå‰ºöÂºïÂÖ•ÈîôËØØÁöÑÊï∞ÂÄºËøêÁÆóÂÖ≥Á≥ªÔºåÂ¶Ç ‚ÄúÁæéÂõΩ + ‰∏≠ÂõΩ = Âç∞Â∫¶‚Äù„ÄÇ\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003c/ol\u003e\n\u003ch2 id=\"‰∫åone-hotÁºñÁ†ÅÁöÑÂä®Êú∫‰∏éÊµÅÁ®ã\"\u003e‰∫å„ÄÅOne-HotÁºñÁ†ÅÁöÑÂä®Êú∫‰∏éÊµÅÁ®ã\u003c/h2\u003e\n\u003col\u003e\n\u003cli\u003e\n\u003cp\u003e\u003cstrong\u003e‰∏∫‰ªÄ‰πà‰ΩøÁî®One-Hot\u003c/strong\u003e\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eÈÄöËøáÂ∞ÜÁ±ªÂà´Êò†Â∞Ñ‰∏∫ÂêëÈáèÔºåÈÅøÂÖçÊï¥Êï∞ÁºñÁ†ÅÂºïÂÖ•ÁöÑ‰º™Êï∞ÂÄºÂÖ≥Á≥ª„ÄÇ\u003c/li\u003e\n\u003cli\u003eÂêåÊó∂‰øùÁïôÂêÑÁßçÂèØËÉΩÁ±ªÂà´ÁöÑ‰ø°ÊÅØÔºå‰∏î‰ªÖÂú®ÂØπÂ∫î‰ΩçÁΩÆ‰∏∫1ÔºåÂÖ∂‰ªñ‰ΩçÁΩÆ‰∏∫0„ÄÇ\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003e\u003cstrong\u003eÂª∫Á´ãÊò†Â∞ÑÔºö‰ªéÁ±ªÂà´Âà∞Á¥¢Âºï\u003c/strong\u003e\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e‰∏∫ÊØè‰∏™Á±ªÂà´ÂàÜÈÖç‰∏Ä‰∏™ÂîØ‰∏ÄÁ¥¢ÂºïÔºåÈÄöÂ∏∏‰ªé1ÂºÄÂßã„ÄÇ\u003c/li\u003e\n\u003cli\u003eÈ¢ÑÁïôÁ¥¢Âºï0Ë°®Á§∫‚ÄúÊú™Áü•‚ÄùÊàñ‚ÄúÁº∫Â§±‚ÄùÔºåÂØπÂ∫îÂÖ®0ÂêëÈáè„ÄÇ\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003e\u003cstrong\u003eËΩ¨Êç¢‰∏∫One-HotÂêëÈáè\u003c/strong\u003e\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eËã•Á±ªÂà´ÊÄªÊï∞‰∏∫197ÔºåÂàôÁî®197Áª¥ÂêëÈáèË°®Á§∫„ÄÇ\u003c/li\u003e\n\u003cli\u003e‰æãÂ≠êÔºöÁæéÂõΩ \u003ccode\u003e[1, 0, 0, 0, ‚Ä¶]\u003c/code\u003eÔºå ‰∏≠ÂõΩ \u003ccode\u003e[0, 1, 0, 0, ‚Ä¶]\u003c/code\u003e„ÄÇ\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003e\u003cstrong\u003eÁ§∫‰æãÔºöË°®Á§∫‰∏Ä‰∏™‰∫∫ÁöÑÁâπÂæÅ\u003c/strong\u003e\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eÁâπÂæÅÂåÖÂê´ÔºàÂπ¥ÈæÑ, ÊÄßÂà´, ÂõΩÁ±çÔºåÂÖ∂‰∏≠ÂõΩÁ±ç197ÁßçÔºâ\u003c/li\u003e\n\u003cli\u003eÁª¥Â∫¶ÊÄªÂíåÔºö1Áª¥_age + 1Áª¥_gender + 197Áª¥_nationality = 199Áª¥„ÄÇ\u003c/li\u003e\n\u003cli\u003e‰æãÂ¶Ç \u003ccode\u003e(28, Â•≥, ‰∏≠ÂõΩ)\u003c/code\u003e ‚Üí \u003ccode\u003e[28, 0, 0, 1, 0, ‚Ä¶, 0]\u003c/code\u003e„ÄÇ\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003c/ol\u003e\n\u003ch2 id=\"‰∏âÊñáÊú¨Êï∞ÊçÆÂ§ÑÁêÜÊµÅÁ®ã\"\u003e‰∏â„ÄÅÊñáÊú¨Êï∞ÊçÆÂ§ÑÁêÜÊµÅÁ®ã\u003c/h2\u003e\n\u003cp\u003eÊñáÊú¨Âú®Ëá™ÁÑ∂ËØ≠Ë®ÄÂ§ÑÁêÜÔºàNLPÔºâ‰∏≠‰Ωú‰∏∫Â∏∏ËßÅÁöÑÂéüÂßãËæìÂÖ•ÔºåÈúÄË¶ÅÊï∞ÂÄºÂåñÊâçËÉΩÈÄÅÂÖ•Ê®°Âûã„ÄÇ‰∏ÄËà¨Ê≠•È™§Â¶Ç‰∏ãÔºö\u003c/p\u003e\n\u003col\u003e\n\u003cli\u003e\n\u003cp\u003e\u003cstrong\u003eÂàÜËØç (Tokenization)\u003c/strong\u003e\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eÂ∞ÜÊñáÊú¨ÊãÜÂàÜ‰∏∫‰∏Ä‰∏™‰∏™ÂçïËØçÔºàTokenÔºâ„ÄÇ\u003c/li\u003e\n\u003cli\u003e‰æãÂ≠êÔºö\u003ccode\u003e\u0026quot;... to be or not to be...\u0026quot;\u003c/code\u003e ‚Üí \u003ccode\u003e[\u0026quot;...\u0026quot;, \u0026quot;to\u0026quot;, \u0026quot;be\u0026quot;, \u0026quot;or\u0026quot;, \u0026quot;not\u0026quot;, \u0026quot;to\u0026quot;, \u0026quot;be\u0026quot;, \u0026quot;...\u0026quot;]\u003c/code\u003e„ÄÇ\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003e\u003cstrong\u003eÁªüËÆ°ËØçÈ¢ë \u0026amp; ÊûÑÂª∫ËØçÂÖ∏\u003c/strong\u003e\u003c/p\u003e","title":""},{"content":"Text to Sequence ÊñáÊú¨Â§ÑÁêÜ\nStep1: Tokenization\nTokenization breaks a piece of text down into a list of tokens.\nHere, a token is a word. (A token can be a character in some applications.)\nTokenizationËÆ≤Á©∂ÂæàÂ§öÔºå‰æãÂ¶ÇÊòØÂê¶Â∫îËØ•ÊääÂ§ßÂÜôÊîπÊàêÂ∞èÂÜôÂë¢ÔºüËøõË°åtypo correctionÁ≠âÁ≠â\nStep2: Build Dictionary\nUse a dictionary (hash table) to count word frequencies.\nThe dictionary maps word to index.\nÂèØ‰ª•È¶ñÂÖàÁªüËÆ°ËØçÈ¢ëÂéªÊéâ‰ΩéÈ¢ëËØçÔºåÁÑ∂ÂêéËÆ©ÊØè‰∏™ËØçÂØπÂ∫î‰∏Ä‰∏™Ê≠£Êï¥Êï∞ÔºõËøôÊ†∑ÁöÑËØùÔºå‰∏ÄÂè•ËØùÂ∞±ÂèØ‰ª•Áî®‰∏Ä‰∏™Ê≠£Êï¥Êï∞ÂàóË°®Ë°®Á§∫ÔºåËøô‰∏™ÂàóË°®Â∞±Âè´sequenceÔºõÂ¶ÇÊûúÂøÖË¶ÅÂ∞±ËøòÂæóÂÅöone-hot encoding„ÄÇ\nÁªìÊûú\n‰ΩÜÊòØÈïøÂ∫¶‰∏çÁªü‰∏Ä\nStep4: ÂØπÈΩêsequence\nËß£ÂÜ≥ÊñπÊ°àÊòØËøôÊ†∑ÁöÑÔºöÂèØ‰ª•Âõ∫ÂÆöÈïøÂ∫¶‰∏∫wÔºåÂä†ÂÖ•‰∏Ä‰∏™Â∫èÂàóÈïøÂ∫¶Â§™ÈïøÔºåÂ∞±Á†çÊéâÂâçÈù¢ÁöÑËØçÔºåÂè™‰øùÁïôÊúÄÂêéw‰∏™ËØçÔºõÂ¶ÇÊûú‰∏Ä‰∏™Â∫èÂàóÂ§™Áü≠ÔºåÂ∞±ÂÅözero paddingÔºåÁî®0Â°´ÂÖÖ\nËøôÊ†∑‰∏ÄÊù•ÔºåÊâÄÊúâÁöÑÂ∫èÂàóÈïøÂ∫¶Â∞±Áªü‰∏Ä‰∫Ü\nÊñáÊú¨Â§ÑÁêÜÂÆåÊàê‰∫ÜÔºåÊé•‰∏ãÊù•ÊòØword embeddingÔºåÊääÂçïËØçË°®Á§∫‰∏∫‰∏Ä‰∏™‰ΩéÁª¥ÂêëÈáèÔºõ\nÁÑ∂ËÄåËøôÊ†∑ÂÅöÁöÑËØùÔºåÂ¶ÇÊûúÊòØ10000‰∏™ÂçïËØçÔºåÁª¥Â∫¶Â∞±ÊòØ10000Áª¥ÔºåÁª¥Â∫¶Â§™È´ò‰∫ÜÔºõÂõ†Ê≠§Ë¶ÅÂÅöword embeddingÔºõ\nÂÖ∑‰ΩìÂÅöÊ≥ïÂ∞±ÊòØÊääone-hotÂêëÈáèe_iÂíåÂèÇÊï∞Áü©ÈòµpÁõ∏‰πòÔºõÁü©ÈòµPËΩ¨ÁΩÆÁöÑÂ§ßÂ∞èÊòØd x vÔºõdÊòØËØçÂêëÈáèÁöÑÁª¥Â∫¶ÔºõvÊòØÂ≠óÂÖ∏ÈáåËØçÊ±áÁöÑÊï∞ÈáèÔºõÁªìÊûú‰∏∫x_iÔºõx_iÂ∞±ÊòØ‰∏Ä‰∏™ËØçÂêëÈáèÔºõÂ¶ÇÊûúone-hotÂêëÈáèÁöÑÁ¨¨‰∏âË°å‰∏∫1ÔºõÈÇ£‰πàx_iÂ∞±ÊòØPËΩ¨ÁΩÆÁü©ÈòµÁöÑÁ¨¨‰∏âÂàóÔºàÂÖ∂‰ΩôÂàóÈÉΩ‰∏∫0ÔºâÔºõÊâÄ‰ª•PËΩ¨ÁΩÆÊØè‰∏ÄÂàóÈÉΩÊòØ‰∏Ä‰∏™ËØçÂêëÈáèÔºõÊâÄ‰ª•Áü©ÈòµPÊú¨Ë∫´ÁöÑÊØè‰∏ÄË°åÂ∞±ÊòØ‰∏Ä‰∏™ËØçÂêëÈáèÔºõÂÖ∂Ë°åÊï∞‰∏∫vÔºõÂç≥vocabularyÔºåËØçÊ±áÈáèÔºõÊØè‰∏ÄË°åÂØπÂ∫î‰∏Ä‰∏™ÂçïËØçÔºõÁü©ÈòµÁöÑÂàóÊï∞‰∏∫dÔºõdÊòØÁî®Êà∑ÂÜ≥ÂÆöÁöÑÔºõdÁöÑÂ§ßÂ∞è‰ºöÂÜ≥ÂÆöÊú∫Âô®Â≠¶‰π†Ê®°ÂûãÁöÑË°®Áé∞ÔºõÂ∫îËØ•Áî®xxxÊù•ÈÄâÊã©‰∏Ä‰∏™ÊØîËæÉÂ•ΩÁöÑdÔºõ\nÊàë‰ª¨ÁöÑ‰ªªÂä°ÊòØÁúãËØÑËÆ∫ÊòØÊ≠£Èù¢ÁöÑËøòÊòØË¥üÈù¢ÁöÑÔºõÂèÇÊï∞Áü©ÈòµÊòØ‰ªéËÆ≠ÁªÉÊï∞ÊçÆ‰∏≠Â≠¶‰π†Âá∫Êù•ÁöÑÔºåÊâÄ‰ª•Â≠¶Âá∫Êù•ÁöÑËØçÂêëÈáèÊòØÂ∏¶ÊúâÊÑüÊÉÖËâ≤ÂΩ©ÁöÑÔºõÂÅáËÆæËøô‰∫õËØçÂêëÈáèÈÉΩÊòØ‰∫åÁª¥ÁöÑÔºåÂàôÂèØ‰ª•Âú®Âπ≥Èù¢ÂùêÊ†áÁ≥ª‰∏≠Ê†áÂá∫‰∏ãÈù¢ËØçÂêëÈáè\nkerasÊèê‰æõembeddingÂ±ÇÔºõÁî®Êà∑ÂèØ‰ª•ÊåáÂÆövocabularyÂ§ßÂ∞èÂíådÁöÑÂ§ßÂ∞èÔºõ‰ª•ÂèäÊØè‰∏Ä‰∏™sequenceÁöÑÈïøÂ∫¶ÔºõdÊòØÊ†πÊçÆÁÆóÊ≥ïÈÄâÂá∫Êù•ÁöÑ Âà∞Ëøô‰∏ÄÊ≠•ÔºåÊàë‰ª¨Â∑≤ÁªèÂÆåÊàê‰∫ÜÊñáÊú¨Â§ÑÁêÜÂíåword embedding„ÄÇÊé•‰∏ãÊù•Â∞±ÊòØÁî®Logistic Regression for Binary ClassificationÂÅö‰∫åÂàÜÁ±ªÔºõ\n","permalink":"http://localhost:1313/posts/nlp-2/","summary":"\u003ch3 id=\"text-to-sequence\"\u003eText to Sequence\u003c/h3\u003e\n\u003cp\u003eÊñáÊú¨Â§ÑÁêÜ\u003c/p\u003e\n\u003cp\u003eStep1: Tokenization\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\n\u003cp\u003eTokenization breaks a piece of text down into a list of tokens.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003eHere, a token is a word. (A token can be a character in some applications.)\u003c/p\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003eTokenizationËÆ≤Á©∂ÂæàÂ§öÔºå‰æãÂ¶ÇÊòØÂê¶Â∫îËØ•ÊääÂ§ßÂÜôÊîπÊàêÂ∞èÂÜôÂë¢ÔºüËøõË°åtypo correctionÁ≠âÁ≠â\u003c/p\u003e\n\u003cp\u003e\u003cimg alt=\"image-20250322150322238\" loading=\"lazy\" src=\"./NLP-2.assets/image-20250322150322238.png\"\u003e\u003c/p\u003e\n\u003cp\u003eStep2: Build Dictionary\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\n\u003cp\u003eUse a dictionary (hash table) to count word frequencies.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003eThe dictionary maps word to index.\u003c/p\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003eÂèØ‰ª•È¶ñÂÖàÁªüËÆ°ËØçÈ¢ëÂéªÊéâ‰ΩéÈ¢ëËØçÔºåÁÑ∂ÂêéËÆ©ÊØè‰∏™ËØçÂØπÂ∫î‰∏Ä‰∏™Ê≠£Êï¥Êï∞ÔºõËøôÊ†∑ÁöÑËØùÔºå‰∏ÄÂè•ËØùÂ∞±ÂèØ‰ª•Áî®‰∏Ä‰∏™Ê≠£Êï¥Êï∞ÂàóË°®Ë°®Á§∫ÔºåËøô‰∏™ÂàóË°®Â∞±Âè´sequenceÔºõÂ¶ÇÊûúÂøÖË¶ÅÂ∞±ËøòÂæóÂÅöone-hot encoding„ÄÇ\u003cimg alt=\"image-20250322150620890\" loading=\"lazy\" src=\"./NLP-2.assets/image-20250322150620890.png\"\u003e\u003c/p\u003e\n\u003cp\u003eÁªìÊûú\u003c/p\u003e\n\u003cp\u003e\u003cimg alt=\"image-20250322150754528\" loading=\"lazy\" src=\"./NLP-2.assets/image-20250322150754528.png\"\u003e\u003c/p\u003e\n\u003cp\u003e‰ΩÜÊòØÈïøÂ∫¶‰∏çÁªü‰∏Ä\u003c/p\u003e\n\u003cp\u003eStep4: ÂØπÈΩêsequence\u003c/p\u003e\n\u003cp\u003e\u003cimg alt=\"image-20250322150854986\" loading=\"lazy\" src=\"./NLP-2.assets/image-20250322150854986.png\"\u003e\u003c/p\u003e\n\u003cp\u003eËß£ÂÜ≥ÊñπÊ°àÊòØËøôÊ†∑ÁöÑÔºöÂèØ‰ª•Âõ∫ÂÆöÈïøÂ∫¶‰∏∫wÔºåÂä†ÂÖ•‰∏Ä‰∏™Â∫èÂàóÈïøÂ∫¶Â§™ÈïøÔºåÂ∞±Á†çÊéâÂâçÈù¢ÁöÑËØçÔºåÂè™‰øùÁïôÊúÄÂêéw‰∏™ËØçÔºõÂ¶ÇÊûú‰∏Ä‰∏™Â∫èÂàóÂ§™Áü≠ÔºåÂ∞±ÂÅözero paddingÔºåÁî®0Â°´ÂÖÖ\u003c/p\u003e\n\u003cp\u003e\u003cimg alt=\"image-20250322151030119\" loading=\"lazy\" src=\"./NLP-2.assets/image-20250322151030119.png\"\u003e\u003c/p\u003e\n\u003cp\u003eËøôÊ†∑‰∏ÄÊù•ÔºåÊâÄÊúâÁöÑÂ∫èÂàóÈïøÂ∫¶Â∞±Áªü‰∏Ä‰∫Ü\u003c/p\u003e\n\u003cp\u003e\u003cimg alt=\"image-20250322151117125\" loading=\"lazy\" src=\"./NLP-2.assets/image-20250322151117125.png\"\u003e\u003c/p\u003e\n\u003cp\u003eÊñáÊú¨Â§ÑÁêÜÂÆåÊàê‰∫ÜÔºåÊé•‰∏ãÊù•ÊòØword embeddingÔºåÊääÂçïËØçË°®Á§∫‰∏∫‰∏Ä‰∏™‰ΩéÁª¥ÂêëÈáèÔºõ\u003c/p\u003e\n\u003cp\u003e\u003cimg alt=\"image-20250322151252837\" loading=\"lazy\" src=\"./NLP-2.assets/image-20250322151252837.png\"\u003e\u003c/p\u003e","title":""},{"content":"üëã About me Hello! I\u0026rsquo;m Xu Zongsi, a passionate technology enthusiast currently pursuing my Master of Science in ECIC at The University of Hong Kong. With a solid background in Software Engineering from the Beijing Institute of Technology, I specialize in emerging areas of artificial intelligence, including machine learning, deep learning, natural language processing, computer vision, and reinforcement learning.\nRecently, inspired by OpenAI\u0026rsquo;s five-step plan towards superintelligence, I have great expectations for AGI and developed a strong interest in LLM agents, MLLM, reinforcement learning, and knowledge graphs. I believe there is significant potential in these fields to create innovative solutions, and I hope to contribute my efforts towards that goal.\nüìö Education üá≠üá∞ The University of Hong Kong 09/2024 - Expected 11/2025 School of Computing and Data Science Master of Science in Electronic Commerce \u0026amp; Internet Computing Relevant Courses: Machine learning for business and e-commerce, Knowledge graphs, Financial fraud analytics, Internet infrastructure technologies, Website engineering, Blockchain and cryptocurrency, etc. üá®üá≥ Beijing Institute of Technology 09/2020 - 06/2024 School of Computer Science \u0026amp; Technology Bachelor of Engineering in Software Engineering, last two years GPA: 3.7/4 Relevant Courses: Reinforcement Learning, Deep Learning and Computer Vision, Artificial Intelligence and Robot Ethics, Almost Human: Mind, Brain and Artificial Intelligence, Mathematical Analysis for Engineering, Linear Algebra, Probability and Mathematical Statistics, etc. Skills: Python, Java, common data structures, design patterns, machine learning basics and algorithms, Linux, PyTorch, and some development tools (git, conda, etc.). üèÜ Awards \u0026amp; Honors Beijing Institute of Technology Undergraduate Scholarship (Top 20% of Grade) 06/2023 3rd Prize of China International \u0026#34;Internet \u0026#43;\u0026#34; College Student\u0026#39;s Innovation Competition 08/2022 Bronze Prize of \u0026#34;Challenge Cup\u0026#34; Capital University Entrepreneurship Competition 05/2022 üíº Project Experience üîç Online Transaction Fraud Detection 09/2024 ‚Äì 01/2025 Independent project, supervised by Dr. Vivien Chan Focused on addressing financial fraud in e-commerce to enhance the accuracy of transaction anomaly detection, while independently managing the entire case study that included data preprocessing, feature engineering, model building, evaluation, and results analysis. Effectively resolved class imbalance issues using SMOTE and ROSE techniques. Built various models including Logistic Regression, Random Forest, XGBoost, and LightGBM, ultimately selecting the LightGBM model to achieve a recall rate of 95.45% and an AUC of 99.84%. Wrote efficient and maintainable code, enhancing model training and data processing efficiency through parallel computing and logging. ü§ñ Multi-Model Intelligent Text Keyword Extraction System 08/2023 ‚Äì 09/2023 Group project, supervised by Associate Prof. Xiaolin Zhao Designed and implemented an intelligent text summary system that automatically extracts keywords from article titles and abstracts, enhancing the understanding and summarization of text information. Participated in the planning of the technical route and built a hybrid model combining extractive and generative approaches, utilizing advanced natural language processing techniques including KeyBERT, Sentence Transformer, BERT, and T5 models. Responsible for data preprocessing and tokenization, as well as the end-to-end implementation and training of the T5 model, optimizing the model architecture and hyperparameters, achieving satisfactory results after only 3 epochs of training. Model evaluation results showed that the Rouge-1, Rouge-2, and Rouge-L metrics reached 0.6345, 0.5038, and 0.5282, respectively, in the third epoch, validating the model\u0026rsquo;s effectiveness in the summarization task. üéì Cambridge University Machine Learning Summer Project 07/2023 ‚Äì 08/2023 Group project, supervised by Prof. Pietro Li√≤ Participated in the Cambridge University deep learning summer project, focusing on deep reinforcement learning; explored multi-agent learning algorithms across different environments. Reproduced the Multi-Agent Deep Deterministic Policy Gradient (MADDPG) algorithm in the Simple Adversary environment and studied the effect of agent numbers on convergence speed and stability, finding optimal stability at 21 agents. Designed and implemented comparative experiments inspired by the Rainbow algorithm, assessing target network strategies versus the Double Deep Q-Network (Double DQN). The results demonstrated that Double DQN significantly enhanced convergence speed, optimizing the overall learning process. Co-authored a group project paper on agent numbers and strategies effectiveness in multi-agent systems, achieving a score of 71% in the summer program (the highest in my group) and a \u0026ldquo;First Class\u0026rdquo; classification in the UK grading system. üëÅÔ∏è Deep Learning and Computer Vision Semester Project 09/2022 ‚Äì 12/2022 Independent project, supervised by Associate Prof. Guangyu Gao Designed and implemented a waste classifier using the ResNet model to improve classification accuracy and reduce resource waste. The project also enhanced understanding of transfer learning techniques with ResNet. Collected a dataset of 16 waste categories and preprocessed the images for uniformity and standardization, incorporating data augmentation techniques to enhance the dataset. Conducted experiments using ResNet34 and ResNet50 models through transfer learning, accelerating network convergence by leveraging pretrained weights. During training, techniques such as Batch Normalization and Dropout were applied to mitigate the risk of overfitting. The final model achieved an accuracy of 90% on the training set, while the performance on the test set was 61%, indicating a significant overfitting phenomenon during the training process. üéì Internship ‚öõÔ∏è Beijing Academy of Quantum Information Science 08/2023 ‚Äì 01/2024 Research Intern at Quantum Computation Department Proposed a quantum convolution kernel design based on variational quantum circuits and developed a universal quantum convolution layer, successfully integrating it into classical CNN architectures such as VGG, GoogLeNet, and ResNet. Developed and evaluated various hybrid models, including a simple model named HQCCNN-2, which achieved 84.45% accuracy on the FashionMNIST dataset, surpassing the traditional CNN\u0026rsquo;s 80.72%. This demonstrates the effectiveness of the quantum convolution layer in improving model performance. Tested on a real quantum computer further validated the effectiveness of the hybrid model, demonstrating the viable integration of quantum computing with deep learning, and highlighting the potential for leveraging quantum properties to enhance model performance. üèÖ Competition Experience ü•â China International \u0026#34;Internet \u0026#43;\u0026#34; College Students\u0026#39; Innovation Competition 08/2022 üõ°Ô∏è Zhongke Ushield: Deep Learning-based Face Privacy Protection Authentication System Responsible for constructing a localized facial feature extraction engine based on MobileFaceNet, ensuring feature extraction is completed on end devices (such as mobile phones and cameras), guaranteeing that raw data does not leave the domain and is not stored, thus enhancing user privacy protection while improving recognition efficiency. ü•â \u0026#34;Challenge Cup\u0026#34; Capital University Entrepreneurship Competition 05/2022 üå≥ Smart Orchard Responsible for the development of the fruit detection, ripeness prediction, and pest identification system, using deep convolutional neural network (CNN) technology for intelligent monitoring of crop growth conditions. Applied advanced object detection algorithms such as Faster R-CNN and YOLO to achieve high precision in apple detection and ripeness assessment, with an accuracy rate exceeding 90%, significantly enhancing the intelligence level of orchard management. Built and trained a dedicated dataset containing various pest samples, optimizing pest detection accuracy through data preprocessing (such as image normalization and resizing) and data augmentation techniques (like rotation, flipping, and noise addition), enabling the real-time monitoring system to accurately identify over 80% of pests, providing effective scientific maintenance recommendations to help farmers reduce crop losses. üìã Extracurricular Activities Vice President, Cyber Security Club, Beijing Institute of Technology 09/2021-09/2022 Backbone, Media Center of the Student Union of Beijing Institute of Technology 10/2020-06/2021 üì´ Contact üìß zongsi.xu@outlook.com üëî Zongsi (Tristan) Xu üíª github.com/BaizeXS üìç Hong Kong SAR, China ","permalink":"http://localhost:1313/resume/","summary":"Personal resume of Zongsi (Tristan) Xu","title":"Zongsi (Tristan) Xu"},{"content":"‰∏Ä„ÄÅÊï∞ÂÄºÁâπÂæÅ‰∏éÁ±ªÂà´ÁâπÂæÅ Êï∞ÂÄºÁâπÂæÅ (Numeric Features) ÂÖ∑ÊúâÂèØÂä†ÂáèÁöÑÊÑè‰πâÔºå‰∏îÂ≠òÂú®Â§ßÂ∞èÈ°∫Â∫è„ÄÇ ‰æãÂ≠êÔºöÂπ¥ÈæÑ„ÄÅÊ∏©Â∫¶Á≠â„ÄÇÂèØ‰ª•Áõ¥Êé•‰øùÁïôÂÖ∂Êï¥Êï∞ÊàñÊµÆÁÇπÊï∞ÂΩ¢Âºè‰æõÊ®°Âûã‰ΩøÁî®„ÄÇ Á±ªÂà´ÁâπÂæÅ (Categorical Features) Êï∞ÊçÆÂÄºÁ¶ªÊï£Ôºå‰∏çÂÖ∑Â§á‚ÄúÊï∞ÂÄºÂ§ßÂ∞è‚ÄùÈó¥ÁöÑÂèØÊØîÊÑè‰πâ„ÄÇ ‰æãÂ≠êÔºöÂõΩÁ±çÔºàÁæéÂõΩ/‰∏≠ÂõΩ/Âç∞Â∫¶Á≠âÔºâ„ÄÅÊÄßÂà´ÔºàÁî∑/Â•≥ÔºâÁ≠â„ÄÇ ÈóÆÈ¢òÔºöËã•‰ªÖÁî®Êï¥Êï∞Ë°®Á§∫ÔºàÁæéÂõΩ=1, ‰∏≠ÂõΩ=2ÔºâÔºå‰ºöÂºïÂÖ•ÈîôËØØÁöÑÊï∞ÂÄºËøêÁÆóÂÖ≥Á≥ªÔºåÂ¶Ç ‚ÄúÁæéÂõΩ + ‰∏≠ÂõΩ = Âç∞Â∫¶‚Äù„ÄÇ ‰∫å„ÄÅOne-HotÁºñÁ†ÅÁöÑÂä®Êú∫‰∏éÊµÅÁ®ã ‰∏∫‰ªÄ‰πà‰ΩøÁî®One-Hot\nÈÄöËøáÂ∞ÜÁ±ªÂà´Êò†Â∞Ñ‰∏∫ÂêëÈáèÔºåÈÅøÂÖçÊï¥Êï∞ÁºñÁ†ÅÂºïÂÖ•ÁöÑ‰º™Êï∞ÂÄºÂÖ≥Á≥ª„ÄÇ ÂêåÊó∂‰øùÁïôÂêÑÁßçÂèØËÉΩÁ±ªÂà´ÁöÑ‰ø°ÊÅØÔºå‰∏î‰ªÖÂú®ÂØπÂ∫î‰ΩçÁΩÆ‰∏∫1ÔºåÂÖ∂‰ªñ‰ΩçÁΩÆ‰∏∫0„ÄÇ Âª∫Á´ãÊò†Â∞ÑÔºö‰ªéÁ±ªÂà´Âà∞Á¥¢Âºï\n‰∏∫ÊØè‰∏™Á±ªÂà´ÂàÜÈÖç‰∏Ä‰∏™ÂîØ‰∏ÄÁ¥¢ÂºïÔºåÈÄöÂ∏∏‰ªé1ÂºÄÂßã„ÄÇ È¢ÑÁïôÁ¥¢Âºï0Ë°®Á§∫‚ÄúÊú™Áü•‚ÄùÊàñ‚ÄúÁº∫Â§±‚ÄùÔºåÂØπÂ∫îÂÖ®0ÂêëÈáè„ÄÇ ËΩ¨Êç¢‰∏∫One-HotÂêëÈáè\nËã•Á±ªÂà´ÊÄªÊï∞‰∏∫197ÔºåÂàôÁî®197Áª¥ÂêëÈáèË°®Á§∫„ÄÇ ‰æãÂ≠êÔºöÁæéÂõΩ [1, 0, 0, 0, ‚Ä¶]Ôºå ‰∏≠ÂõΩ [0, 1, 0, 0, ‚Ä¶]„ÄÇ Á§∫‰æãÔºöË°®Á§∫‰∏Ä‰∏™‰∫∫ÁöÑÁâπÂæÅ\nÁâπÂæÅÂåÖÂê´ÔºàÂπ¥ÈæÑ, ÊÄßÂà´, ÂõΩÁ±çÔºåÂÖ∂‰∏≠ÂõΩÁ±ç197ÁßçÔºâ Áª¥Â∫¶ÊÄªÂíåÔºö1Áª¥_age + 1Áª¥_gender + 197Áª¥_nationality = 199Áª¥„ÄÇ ‰æãÂ¶Ç (28, Â•≥, ‰∏≠ÂõΩ) ‚Üí [28, 0, 0, 1, 0, ‚Ä¶, 0]„ÄÇ ‰∏â„ÄÅÊñáÊú¨Êï∞ÊçÆÂ§ÑÁêÜÊµÅÁ®ã ÊñáÊú¨Âú®Ëá™ÁÑ∂ËØ≠Ë®ÄÂ§ÑÁêÜÔºàNLPÔºâ‰∏≠‰Ωú‰∏∫Â∏∏ËßÅÁöÑÂéüÂßãËæìÂÖ•ÔºåÈúÄË¶ÅÊï∞ÂÄºÂåñÊâçËÉΩÈÄÅÂÖ•Ê®°Âûã„ÄÇ‰∏ÄËà¨Ê≠•È™§Â¶Ç‰∏ãÔºö\nÂàÜËØç (Tokenization)\nÂ∞ÜÊñáÊú¨ÊãÜÂàÜ‰∏∫‰∏Ä‰∏™‰∏™ÂçïËØçÔºàTokenÔºâ„ÄÇ ‰æãÂ≠êÔºö\u0026quot;... to be or not to be...\u0026quot; ‚Üí [\u0026quot;...\u0026quot;, \u0026quot;to\u0026quot;, \u0026quot;be\u0026quot;, \u0026quot;or\u0026quot;, \u0026quot;not\u0026quot;, \u0026quot;to\u0026quot;, \u0026quot;be\u0026quot;, \u0026quot;...\u0026quot;]„ÄÇ ÁªüËÆ°ËØçÈ¢ë \u0026amp; ÊûÑÂª∫ËØçÂÖ∏\nËØçÈ¢ëÁªüËÆ° Áî®ÂìàÂ∏åË°®/Â≠óÂÖ∏ËÆ∞ÂΩïÊØè‰∏™ÂçïËØçÂá∫Áé∞Ê¨°Êï∞„ÄÇ ÈÅçÂéÜÊñáÊú¨Êó∂ÔºåËã•ÂçïËØçÂ∞öÊú™ÂÖ•Ë°®ÔºåÂàôÊñ∞Âª∫ËÆ∞ÂΩïÔºõËã•Â∑≤Â≠òÂú®ÔºåÂàôËÆ°Êï∞+1„ÄÇ ÊéíÂ∫è‰∏éÁ¥¢Âºï ÊåâËØçÈ¢ëÈôçÂ∫èÊéíÂ∫èÔºåËØçÈ¢ëÊúÄÈ´òÁöÑÂçïËØçÊéíÂú®ÂâçÈù¢„ÄÇ Á¥¢Âºï‰ªé1ÂºÄÂßãÔºå0ÁïôÁªô‚ÄúÊú™Áü•‚Äù„ÄÇ ËØçÂÖ∏ËßÑÊ®°ÔºàvocabularyÔºâÂèØËßÜÈúÄÊ±ÇÊà™Êñ≠Ôºà‰æãÂ¶ÇÂè™‰øùÁïôTop 10kÔºâ„ÄÇ ‰∏∫‰ªÄ‰πàÁßªÈô§‰ΩéÈ¢ëËØç ‰ΩéÈ¢ëËØçÂèØËÉΩÊòØÊãºÂÜôÈîôËØØ„ÄÅÁΩïËßÅ‰∫∫ÂêçÁ≠âÔºåÂØπÊ®°ÂûãÂ∏ÆÂä©ÊúâÈôê„ÄÇ ÂáèÂ∞ëËØçÂÖ∏ËßÑÊ®°ÂèØÈôç‰ΩéËøêÁÆóÂºÄÈîÄ„ÄÅÂä†Âø´Ê®°ÂûãËÆ≠ÁªÉ‰∏éÊé®ÁêÜÈÄüÂ∫¶„ÄÇ Áã¨ÁÉ≠ÁºñÁ†Å (One-Hot Encoding)\nÂ∞ÜÊØè‰∏™ÂçïËØçÊò†Â∞Ñ‰∏∫ËØçÂÖ∏‰∏≠ÁöÑÁ¥¢ÂºïÂêéÔºàÂ¶Ç [2, 4, 1, 8, ‚Ä¶]ÔºâÔºåÂèØËøõ‰∏ÄÊ≠•ËΩ¨Êç¢ÊàêOne-HotÂêëÈáè„ÄÇ One-HotÁª¥Â∫¶ÂèñÂÜ≥‰∫é‰øùÁïô‰∏ãÊù•ÁöÑËØçÂÖ∏Â§ßÂ∞èÔºà‰æãÂ¶Ç1‰∏áÔºâ„ÄÇ Êú™Êî∂ÂΩïÂçïËØçÂèØËÉΩÁõ¥Êé•ÂøΩÁï•ÔºåÊàñÁªü‰∏ÄÁî®Á¥¢Âºï0‰ª£Êõø„ÄÇ Âõõ„ÄÅÊ†∏ÂøÉÊî∂Ëé∑‰∏éÂ∫îÁî® Á±ªÂà´ÁâπÂæÅÂøÖÈúÄÊï∞ÂÄºÂåñÔºö\n‰ΩøÁî®Êï¥Êï∞1,2,3‚Ä¶‰ªÖË°®Á§∫Á±ªÂà´‚ÄúÊ†áËØÜ‚ÄùÔºåÂπ∂‰∏ç‰ª£Ë°®ÂÆÉ‰ª¨ÂèØËøõË°åÊï∞ÂÄºËøêÁÆó„ÄÇ Âõ†Ê≠§ÈúÄË¶ÅOne-HotÁ≠âÁºñÁ†ÅÊñπÂºèÔºåÈÅøÂÖçÊï∞ÂÄºËØØËß£„ÄÇ ÊñáÊú¨Êï∞ÊçÆÈ¢ÑÂ§ÑÁêÜÔºö\nÂàÜËØç„ÄÅËØçÈ¢ëÁªüËÆ°„ÄÅÊûÑÂª∫ËØçÂÖ∏„ÄÅÁ¥¢ÂºïÂåñ„ÄÅOne-HotÊàñÂÖ∂‰ªñÊñπÂºèÔºàÂ¶ÇËØçÂµåÂÖ•ÔºâÊòØÂ∏∏ËßÅÊµÅÁ®ã„ÄÇ Ê≠£Á°ÆÁöÑÊñáÊú¨È¢ÑÂ§ÑÁêÜÂèØÊòæËëóÂΩ±ÂìçÊ®°ÂûãÊÄßËÉΩÂíåÊïàÁéá„ÄÇ ‰øùÁïôÊú™Áü•Á¥¢ÂºïÔºö\n‰øùËØÅÂØπÁº∫Â§±Êï∞ÊçÆÊàñÂ≠óÂÖ∏Â§ñÊñ∞ËØçËÉΩÊúâÂü∫Êú¨ÁöÑË°®Á§∫ÔºåÊèêÂçáÊ®°ÂûãÂÆπÈîôÊÄß„ÄÇ ÂÆûÈôÖ‰ΩøÁî®Ôºö\nÂØπ‰∫éÂ∞èËßÑÊ®°Á±ªÂà´ÂèØÁõ¥Êé•One-HotÁºñÁ†ÅÔºõÂØπ‰∫éËØçÂÖ∏ÂæàÂ§ßÁöÑÂú∫ÊôØÔºåÈÄöÂ∏∏‰ºöËøõ‰∏ÄÊ≠•ËÄÉËôëËØçÂµåÂÖ•ÔºàWord EmbeddingÔºâÊàñÈ¢ÑËÆ≠ÁªÉËØ≠Ë®ÄÊ®°Âûã„ÄÇ ","permalink":"http://localhost:1313/posts/nlp-1/","summary":"\u003ch2 id=\"‰∏ÄÊï∞ÂÄºÁâπÂæÅ‰∏éÁ±ªÂà´ÁâπÂæÅ\"\u003e‰∏Ä„ÄÅÊï∞ÂÄºÁâπÂæÅ‰∏éÁ±ªÂà´ÁâπÂæÅ\u003c/h2\u003e\n\u003col\u003e\n\u003cli\u003e\u003cstrong\u003eÊï∞ÂÄºÁâπÂæÅ (Numeric Features)\u003c/strong\u003e\n\u003cul\u003e\n\u003cli\u003eÂÖ∑ÊúâÂèØÂä†ÂáèÁöÑÊÑè‰πâÔºå‰∏îÂ≠òÂú®Â§ßÂ∞èÈ°∫Â∫è„ÄÇ\u003c/li\u003e\n\u003cli\u003e‰æãÂ≠êÔºöÂπ¥ÈæÑ„ÄÅÊ∏©Â∫¶Á≠â„ÄÇÂèØ‰ª•Áõ¥Êé•‰øùÁïôÂÖ∂Êï¥Êï∞ÊàñÊµÆÁÇπÊï∞ÂΩ¢Âºè‰æõÊ®°Âûã‰ΩøÁî®„ÄÇ\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003eÁ±ªÂà´ÁâπÂæÅ (Categorical Features)\u003c/strong\u003e\n\u003cul\u003e\n\u003cli\u003eÊï∞ÊçÆÂÄºÁ¶ªÊï£Ôºå‰∏çÂÖ∑Â§á‚ÄúÊï∞ÂÄºÂ§ßÂ∞è‚ÄùÈó¥ÁöÑÂèØÊØîÊÑè‰πâ„ÄÇ\u003c/li\u003e\n\u003cli\u003e‰æãÂ≠êÔºöÂõΩÁ±çÔºàÁæéÂõΩ/‰∏≠ÂõΩ/Âç∞Â∫¶Á≠âÔºâ„ÄÅÊÄßÂà´ÔºàÁî∑/Â•≥ÔºâÁ≠â„ÄÇ\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003eÈóÆÈ¢ò\u003c/strong\u003eÔºöËã•‰ªÖÁî®Êï¥Êï∞Ë°®Á§∫ÔºàÁæéÂõΩ=1, ‰∏≠ÂõΩ=2ÔºâÔºå‰ºöÂºïÂÖ•ÈîôËØØÁöÑÊï∞ÂÄºËøêÁÆóÂÖ≥Á≥ªÔºåÂ¶Ç ‚ÄúÁæéÂõΩ + ‰∏≠ÂõΩ = Âç∞Â∫¶‚Äù„ÄÇ\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003c/ol\u003e\n\u003ch2 id=\"‰∫åone-hotÁºñÁ†ÅÁöÑÂä®Êú∫‰∏éÊµÅÁ®ã\"\u003e‰∫å„ÄÅOne-HotÁºñÁ†ÅÁöÑÂä®Êú∫‰∏éÊµÅÁ®ã\u003c/h2\u003e\n\u003col\u003e\n\u003cli\u003e\n\u003cp\u003e\u003cstrong\u003e‰∏∫‰ªÄ‰πà‰ΩøÁî®One-Hot\u003c/strong\u003e\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eÈÄöËøáÂ∞ÜÁ±ªÂà´Êò†Â∞Ñ‰∏∫ÂêëÈáèÔºåÈÅøÂÖçÊï¥Êï∞ÁºñÁ†ÅÂºïÂÖ•ÁöÑ‰º™Êï∞ÂÄºÂÖ≥Á≥ª„ÄÇ\u003c/li\u003e\n\u003cli\u003eÂêåÊó∂‰øùÁïôÂêÑÁßçÂèØËÉΩÁ±ªÂà´ÁöÑ‰ø°ÊÅØÔºå‰∏î‰ªÖÂú®ÂØπÂ∫î‰ΩçÁΩÆ‰∏∫1ÔºåÂÖ∂‰ªñ‰ΩçÁΩÆ‰∏∫0„ÄÇ\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003e\u003cstrong\u003eÂª∫Á´ãÊò†Â∞ÑÔºö‰ªéÁ±ªÂà´Âà∞Á¥¢Âºï\u003c/strong\u003e\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e‰∏∫ÊØè‰∏™Á±ªÂà´ÂàÜÈÖç‰∏Ä‰∏™ÂîØ‰∏ÄÁ¥¢ÂºïÔºåÈÄöÂ∏∏‰ªé1ÂºÄÂßã„ÄÇ\u003c/li\u003e\n\u003cli\u003eÈ¢ÑÁïôÁ¥¢Âºï0Ë°®Á§∫‚ÄúÊú™Áü•‚ÄùÊàñ‚ÄúÁº∫Â§±‚ÄùÔºåÂØπÂ∫îÂÖ®0ÂêëÈáè„ÄÇ\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003e\u003cstrong\u003eËΩ¨Êç¢‰∏∫One-HotÂêëÈáè\u003c/strong\u003e\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eËã•Á±ªÂà´ÊÄªÊï∞‰∏∫197ÔºåÂàôÁî®197Áª¥ÂêëÈáèË°®Á§∫„ÄÇ\u003c/li\u003e\n\u003cli\u003e‰æãÂ≠êÔºöÁæéÂõΩ \u003ccode\u003e[1, 0, 0, 0, ‚Ä¶]\u003c/code\u003eÔºå ‰∏≠ÂõΩ \u003ccode\u003e[0, 1, 0, 0, ‚Ä¶]\u003c/code\u003e„ÄÇ\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003e\u003cstrong\u003eÁ§∫‰æãÔºöË°®Á§∫‰∏Ä‰∏™‰∫∫ÁöÑÁâπÂæÅ\u003c/strong\u003e\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eÁâπÂæÅÂåÖÂê´ÔºàÂπ¥ÈæÑ, ÊÄßÂà´, ÂõΩÁ±çÔºåÂÖ∂‰∏≠ÂõΩÁ±ç197ÁßçÔºâ\u003c/li\u003e\n\u003cli\u003eÁª¥Â∫¶ÊÄªÂíåÔºö1Áª¥_age + 1Áª¥_gender + 197Áª¥_nationality = 199Áª¥„ÄÇ\u003c/li\u003e\n\u003cli\u003e‰æãÂ¶Ç \u003ccode\u003e(28, Â•≥, ‰∏≠ÂõΩ)\u003c/code\u003e ‚Üí \u003ccode\u003e[28, 0, 0, 1, 0, ‚Ä¶, 0]\u003c/code\u003e„ÄÇ\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003c/ol\u003e\n\u003ch2 id=\"‰∏âÊñáÊú¨Êï∞ÊçÆÂ§ÑÁêÜÊµÅÁ®ã\"\u003e‰∏â„ÄÅÊñáÊú¨Êï∞ÊçÆÂ§ÑÁêÜÊµÅÁ®ã\u003c/h2\u003e\n\u003cp\u003eÊñáÊú¨Âú®Ëá™ÁÑ∂ËØ≠Ë®ÄÂ§ÑÁêÜÔºàNLPÔºâ‰∏≠‰Ωú‰∏∫Â∏∏ËßÅÁöÑÂéüÂßãËæìÂÖ•ÔºåÈúÄË¶ÅÊï∞ÂÄºÂåñÊâçËÉΩÈÄÅÂÖ•Ê®°Âûã„ÄÇ‰∏ÄËà¨Ê≠•È™§Â¶Ç‰∏ãÔºö\u003c/p\u003e\n\u003col\u003e\n\u003cli\u003e\n\u003cp\u003e\u003cstrong\u003eÂàÜËØç (Tokenization)\u003c/strong\u003e\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eÂ∞ÜÊñáÊú¨ÊãÜÂàÜ‰∏∫‰∏Ä‰∏™‰∏™ÂçïËØçÔºàTokenÔºâ„ÄÇ\u003c/li\u003e\n\u003cli\u003e‰æãÂ≠êÔºö\u003ccode\u003e\u0026quot;... to be or not to be...\u0026quot;\u003c/code\u003e ‚Üí \u003ccode\u003e[\u0026quot;...\u0026quot;, \u0026quot;to\u0026quot;, \u0026quot;be\u0026quot;, \u0026quot;or\u0026quot;, \u0026quot;not\u0026quot;, \u0026quot;to\u0026quot;, \u0026quot;be\u0026quot;, \u0026quot;...\u0026quot;]\u003c/code\u003e„ÄÇ\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003e\u003cstrong\u003eÁªüËÆ°ËØçÈ¢ë \u0026amp; ÊûÑÂª∫ËØçÂÖ∏\u003c/strong\u003e\u003c/p\u003e","title":""},{"content":"Text to Sequence ÊñáÊú¨Â§ÑÁêÜ\nStep1: Tokenization\nTokenization breaks a piece of text down into a list of tokens.\nHere, a token is a word. (A token can be a character in some applications.)\nTokenizationËÆ≤Á©∂ÂæàÂ§öÔºå‰æãÂ¶ÇÊòØÂê¶Â∫îËØ•ÊääÂ§ßÂÜôÊîπÊàêÂ∞èÂÜôÂë¢ÔºüËøõË°åtypo correctionÁ≠âÁ≠â\nStep2: Build Dictionary\nUse a dictionary (hash table) to count word frequencies.\nThe dictionary maps word to index.\nÂèØ‰ª•È¶ñÂÖàÁªüËÆ°ËØçÈ¢ëÂéªÊéâ‰ΩéÈ¢ëËØçÔºåÁÑ∂ÂêéËÆ©ÊØè‰∏™ËØçÂØπÂ∫î‰∏Ä‰∏™Ê≠£Êï¥Êï∞ÔºõËøôÊ†∑ÁöÑËØùÔºå‰∏ÄÂè•ËØùÂ∞±ÂèØ‰ª•Áî®‰∏Ä‰∏™Ê≠£Êï¥Êï∞ÂàóË°®Ë°®Á§∫ÔºåËøô‰∏™ÂàóË°®Â∞±Âè´sequenceÔºõÂ¶ÇÊûúÂøÖË¶ÅÂ∞±ËøòÂæóÂÅöone-hot encoding„ÄÇ\nÁªìÊûú\n‰ΩÜÊòØÈïøÂ∫¶‰∏çÁªü‰∏Ä\nStep4: ÂØπÈΩêsequence\nËß£ÂÜ≥ÊñπÊ°àÊòØËøôÊ†∑ÁöÑÔºöÂèØ‰ª•Âõ∫ÂÆöÈïøÂ∫¶‰∏∫wÔºåÂä†ÂÖ•‰∏Ä‰∏™Â∫èÂàóÈïøÂ∫¶Â§™ÈïøÔºåÂ∞±Á†çÊéâÂâçÈù¢ÁöÑËØçÔºåÂè™‰øùÁïôÊúÄÂêéw‰∏™ËØçÔºõÂ¶ÇÊûú‰∏Ä‰∏™Â∫èÂàóÂ§™Áü≠ÔºåÂ∞±ÂÅözero paddingÔºåÁî®0Â°´ÂÖÖ\nËøôÊ†∑‰∏ÄÊù•ÔºåÊâÄÊúâÁöÑÂ∫èÂàóÈïøÂ∫¶Â∞±Áªü‰∏Ä‰∫Ü\nÊñáÊú¨Â§ÑÁêÜÂÆåÊàê‰∫ÜÔºåÊé•‰∏ãÊù•ÊòØword embeddingÔºåÊääÂçïËØçË°®Á§∫‰∏∫‰∏Ä‰∏™‰ΩéÁª¥ÂêëÈáèÔºõ\nÁÑ∂ËÄåËøôÊ†∑ÂÅöÁöÑËØùÔºåÂ¶ÇÊûúÊòØ10000‰∏™ÂçïËØçÔºåÁª¥Â∫¶Â∞±ÊòØ10000Áª¥ÔºåÁª¥Â∫¶Â§™È´ò‰∫ÜÔºõÂõ†Ê≠§Ë¶ÅÂÅöword embeddingÔºõ\nÂÖ∑‰ΩìÂÅöÊ≥ïÂ∞±ÊòØÊääone-hotÂêëÈáèe_iÂíåÂèÇÊï∞Áü©ÈòµpÁõ∏‰πòÔºõÁü©ÈòµPËΩ¨ÁΩÆÁöÑÂ§ßÂ∞èÊòØd x vÔºõdÊòØËØçÂêëÈáèÁöÑÁª¥Â∫¶ÔºõvÊòØÂ≠óÂÖ∏ÈáåËØçÊ±áÁöÑÊï∞ÈáèÔºõÁªìÊûú‰∏∫x_iÔºõx_iÂ∞±ÊòØ‰∏Ä‰∏™ËØçÂêëÈáèÔºõÂ¶ÇÊûúone-hotÂêëÈáèÁöÑÁ¨¨‰∏âË°å‰∏∫1ÔºõÈÇ£‰πàx_iÂ∞±ÊòØPËΩ¨ÁΩÆÁü©ÈòµÁöÑÁ¨¨‰∏âÂàóÔºàÂÖ∂‰ΩôÂàóÈÉΩ‰∏∫0ÔºâÔºõÊâÄ‰ª•PËΩ¨ÁΩÆÊØè‰∏ÄÂàóÈÉΩÊòØ‰∏Ä‰∏™ËØçÂêëÈáèÔºõÊâÄ‰ª•Áü©ÈòµPÊú¨Ë∫´ÁöÑÊØè‰∏ÄË°åÂ∞±ÊòØ‰∏Ä‰∏™ËØçÂêëÈáèÔºõÂÖ∂Ë°åÊï∞‰∏∫vÔºõÂç≥vocabularyÔºåËØçÊ±áÈáèÔºõÊØè‰∏ÄË°åÂØπÂ∫î‰∏Ä‰∏™ÂçïËØçÔºõÁü©ÈòµÁöÑÂàóÊï∞‰∏∫dÔºõdÊòØÁî®Êà∑ÂÜ≥ÂÆöÁöÑÔºõdÁöÑÂ§ßÂ∞è‰ºöÂÜ≥ÂÆöÊú∫Âô®Â≠¶‰π†Ê®°ÂûãÁöÑË°®Áé∞ÔºõÂ∫îËØ•Áî®xxxÊù•ÈÄâÊã©‰∏Ä‰∏™ÊØîËæÉÂ•ΩÁöÑdÔºõ\nÊàë‰ª¨ÁöÑ‰ªªÂä°ÊòØÁúãËØÑËÆ∫ÊòØÊ≠£Èù¢ÁöÑËøòÊòØË¥üÈù¢ÁöÑÔºõÂèÇÊï∞Áü©ÈòµÊòØ‰ªéËÆ≠ÁªÉÊï∞ÊçÆ‰∏≠Â≠¶‰π†Âá∫Êù•ÁöÑÔºåÊâÄ‰ª•Â≠¶Âá∫Êù•ÁöÑËØçÂêëÈáèÊòØÂ∏¶ÊúâÊÑüÊÉÖËâ≤ÂΩ©ÁöÑÔºõÂÅáËÆæËøô‰∫õËØçÂêëÈáèÈÉΩÊòØ‰∫åÁª¥ÁöÑÔºåÂàôÂèØ‰ª•Âú®Âπ≥Èù¢ÂùêÊ†áÁ≥ª‰∏≠Ê†áÂá∫‰∏ãÈù¢ËØçÂêëÈáè\nkerasÊèê‰æõembeddingÂ±ÇÔºõÁî®Êà∑ÂèØ‰ª•ÊåáÂÆövocabularyÂ§ßÂ∞èÂíådÁöÑÂ§ßÂ∞èÔºõ‰ª•ÂèäÊØè‰∏Ä‰∏™sequenceÁöÑÈïøÂ∫¶ÔºõdÊòØÊ†πÊçÆÁÆóÊ≥ïÈÄâÂá∫Êù•ÁöÑ Âà∞Ëøô‰∏ÄÊ≠•ÔºåÊàë‰ª¨Â∑≤ÁªèÂÆåÊàê‰∫ÜÊñáÊú¨Â§ÑÁêÜÂíåword embedding„ÄÇÊé•‰∏ãÊù•Â∞±ÊòØÁî®Logistic Regression for Binary ClassificationÂÅö‰∫åÂàÜÁ±ªÔºõ\n","permalink":"http://localhost:1313/posts/nlp-2/","summary":"\u003ch3 id=\"text-to-sequence\"\u003eText to Sequence\u003c/h3\u003e\n\u003cp\u003eÊñáÊú¨Â§ÑÁêÜ\u003c/p\u003e\n\u003cp\u003eStep1: Tokenization\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\n\u003cp\u003eTokenization breaks a piece of text down into a list of tokens.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003eHere, a token is a word. (A token can be a character in some applications.)\u003c/p\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003eTokenizationËÆ≤Á©∂ÂæàÂ§öÔºå‰æãÂ¶ÇÊòØÂê¶Â∫îËØ•ÊääÂ§ßÂÜôÊîπÊàêÂ∞èÂÜôÂë¢ÔºüËøõË°åtypo correctionÁ≠âÁ≠â\u003c/p\u003e\n\u003cp\u003e\u003cimg alt=\"image-20250322150322238\" loading=\"lazy\" src=\"./NLP-2.assets/image-20250322150322238.png\"\u003e\u003c/p\u003e\n\u003cp\u003eStep2: Build Dictionary\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\n\u003cp\u003eUse a dictionary (hash table) to count word frequencies.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003eThe dictionary maps word to index.\u003c/p\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003eÂèØ‰ª•È¶ñÂÖàÁªüËÆ°ËØçÈ¢ëÂéªÊéâ‰ΩéÈ¢ëËØçÔºåÁÑ∂ÂêéËÆ©ÊØè‰∏™ËØçÂØπÂ∫î‰∏Ä‰∏™Ê≠£Êï¥Êï∞ÔºõËøôÊ†∑ÁöÑËØùÔºå‰∏ÄÂè•ËØùÂ∞±ÂèØ‰ª•Áî®‰∏Ä‰∏™Ê≠£Êï¥Êï∞ÂàóË°®Ë°®Á§∫ÔºåËøô‰∏™ÂàóË°®Â∞±Âè´sequenceÔºõÂ¶ÇÊûúÂøÖË¶ÅÂ∞±ËøòÂæóÂÅöone-hot encoding„ÄÇ\u003cimg alt=\"image-20250322150620890\" loading=\"lazy\" src=\"./NLP-2.assets/image-20250322150620890.png\"\u003e\u003c/p\u003e\n\u003cp\u003eÁªìÊûú\u003c/p\u003e\n\u003cp\u003e\u003cimg alt=\"image-20250322150754528\" loading=\"lazy\" src=\"./NLP-2.assets/image-20250322150754528.png\"\u003e\u003c/p\u003e\n\u003cp\u003e‰ΩÜÊòØÈïøÂ∫¶‰∏çÁªü‰∏Ä\u003c/p\u003e\n\u003cp\u003eStep4: ÂØπÈΩêsequence\u003c/p\u003e\n\u003cp\u003e\u003cimg alt=\"image-20250322150854986\" loading=\"lazy\" src=\"./NLP-2.assets/image-20250322150854986.png\"\u003e\u003c/p\u003e\n\u003cp\u003eËß£ÂÜ≥ÊñπÊ°àÊòØËøôÊ†∑ÁöÑÔºöÂèØ‰ª•Âõ∫ÂÆöÈïøÂ∫¶‰∏∫wÔºåÂä†ÂÖ•‰∏Ä‰∏™Â∫èÂàóÈïøÂ∫¶Â§™ÈïøÔºåÂ∞±Á†çÊéâÂâçÈù¢ÁöÑËØçÔºåÂè™‰øùÁïôÊúÄÂêéw‰∏™ËØçÔºõÂ¶ÇÊûú‰∏Ä‰∏™Â∫èÂàóÂ§™Áü≠ÔºåÂ∞±ÂÅözero paddingÔºåÁî®0Â°´ÂÖÖ\u003c/p\u003e\n\u003cp\u003e\u003cimg alt=\"image-20250322151030119\" loading=\"lazy\" src=\"./NLP-2.assets/image-20250322151030119.png\"\u003e\u003c/p\u003e\n\u003cp\u003eËøôÊ†∑‰∏ÄÊù•ÔºåÊâÄÊúâÁöÑÂ∫èÂàóÈïøÂ∫¶Â∞±Áªü‰∏Ä‰∫Ü\u003c/p\u003e\n\u003cp\u003e\u003cimg alt=\"image-20250322151117125\" loading=\"lazy\" src=\"./NLP-2.assets/image-20250322151117125.png\"\u003e\u003c/p\u003e\n\u003cp\u003eÊñáÊú¨Â§ÑÁêÜÂÆåÊàê‰∫ÜÔºåÊé•‰∏ãÊù•ÊòØword embeddingÔºåÊääÂçïËØçË°®Á§∫‰∏∫‰∏Ä‰∏™‰ΩéÁª¥ÂêëÈáèÔºõ\u003c/p\u003e\n\u003cp\u003e\u003cimg alt=\"image-20250322151252837\" loading=\"lazy\" src=\"./NLP-2.assets/image-20250322151252837.png\"\u003e\u003c/p\u003e","title":""},{"content":"üëã About me Hello! I\u0026rsquo;m Xu Zongsi, a passionate technology enthusiast currently pursuing my Master of Science in ECIC at The University of Hong Kong. With a solid background in Software Engineering from the Beijing Institute of Technology, I specialize in emerging areas of artificial intelligence, including machine learning, deep learning, natural language processing, computer vision, and reinforcement learning.\nRecently, inspired by OpenAI\u0026rsquo;s five-step plan towards superintelligence, I have great expectations for AGI and developed a strong interest in LLM agents, MLLM, reinforcement learning, and knowledge graphs. I believe there is significant potential in these fields to create innovative solutions, and I hope to contribute my efforts towards that goal.\nüìö Education üá≠üá∞ The University of Hong Kong 09/2024 - Expected 11/2025 School of Computing and Data Science Master of Science in Electronic Commerce \u0026amp; Internet Computing Relevant Courses: Machine learning for business and e-commerce, Knowledge graphs, Financial fraud analytics, Internet infrastructure technologies, Website engineering, Blockchain and cryptocurrency, etc. üá®üá≥ Beijing Institute of Technology 09/2020 - 06/2024 School of Computer Science \u0026amp; Technology Bachelor of Engineering in Software Engineering, last two years GPA: 3.7/4 Relevant Courses: Reinforcement Learning, Deep Learning and Computer Vision, Artificial Intelligence and Robot Ethics, Almost Human: Mind, Brain and Artificial Intelligence, Mathematical Analysis for Engineering, Linear Algebra, Probability and Mathematical Statistics, etc. Skills: Python, Java, common data structures, design patterns, machine learning basics and algorithms, Linux, PyTorch, and some development tools (git, conda, etc.). üèÜ Awards \u0026amp; Honors Beijing Institute of Technology Undergraduate Scholarship (Top 20% of Grade) 06/2023 3rd Prize of China International \u0026#34;Internet \u0026#43;\u0026#34; College Student\u0026#39;s Innovation Competition 08/2022 Bronze Prize of \u0026#34;Challenge Cup\u0026#34; Capital University Entrepreneurship Competition 05/2022 üíº Project Experience üîç Online Transaction Fraud Detection 09/2024 ‚Äì 01/2025 Independent project, supervised by Dr. Vivien Chan Focused on addressing financial fraud in e-commerce to enhance the accuracy of transaction anomaly detection, while independently managing the entire case study that included data preprocessing, feature engineering, model building, evaluation, and results analysis. Effectively resolved class imbalance issues using SMOTE and ROSE techniques. Built various models including Logistic Regression, Random Forest, XGBoost, and LightGBM, ultimately selecting the LightGBM model to achieve a recall rate of 95.45% and an AUC of 99.84%. Wrote efficient and maintainable code, enhancing model training and data processing efficiency through parallel computing and logging. ü§ñ Multi-Model Intelligent Text Keyword Extraction System 08/2023 ‚Äì 09/2023 Group project, supervised by Associate Prof. Xiaolin Zhao Designed and implemented an intelligent text summary system that automatically extracts keywords from article titles and abstracts, enhancing the understanding and summarization of text information. Participated in the planning of the technical route and built a hybrid model combining extractive and generative approaches, utilizing advanced natural language processing techniques including KeyBERT, Sentence Transformer, BERT, and T5 models. Responsible for data preprocessing and tokenization, as well as the end-to-end implementation and training of the T5 model, optimizing the model architecture and hyperparameters, achieving satisfactory results after only 3 epochs of training. Model evaluation results showed that the Rouge-1, Rouge-2, and Rouge-L metrics reached 0.6345, 0.5038, and 0.5282, respectively, in the third epoch, validating the model\u0026rsquo;s effectiveness in the summarization task. üéì Cambridge University Machine Learning Summer Project 07/2023 ‚Äì 08/2023 Group project, supervised by Prof. Pietro Li√≤ Participated in the Cambridge University deep learning summer project, focusing on deep reinforcement learning; explored multi-agent learning algorithms across different environments. Reproduced the Multi-Agent Deep Deterministic Policy Gradient (MADDPG) algorithm in the Simple Adversary environment and studied the effect of agent numbers on convergence speed and stability, finding optimal stability at 21 agents. Designed and implemented comparative experiments inspired by the Rainbow algorithm, assessing target network strategies versus the Double Deep Q-Network (Double DQN). The results demonstrated that Double DQN significantly enhanced convergence speed, optimizing the overall learning process. Co-authored a group project paper on agent numbers and strategies effectiveness in multi-agent systems, achieving a score of 71% in the summer program (the highest in my group) and a \u0026ldquo;First Class\u0026rdquo; classification in the UK grading system. üëÅÔ∏è Deep Learning and Computer Vision Semester Project 09/2022 ‚Äì 12/2022 Independent project, supervised by Associate Prof. Guangyu Gao Designed and implemented a waste classifier using the ResNet model to improve classification accuracy and reduce resource waste. The project also enhanced understanding of transfer learning techniques with ResNet. Collected a dataset of 16 waste categories and preprocessed the images for uniformity and standardization, incorporating data augmentation techniques to enhance the dataset. Conducted experiments using ResNet34 and ResNet50 models through transfer learning, accelerating network convergence by leveraging pretrained weights. During training, techniques such as Batch Normalization and Dropout were applied to mitigate the risk of overfitting. The final model achieved an accuracy of 90% on the training set, while the performance on the test set was 61%, indicating a significant overfitting phenomenon during the training process. üéì Internship ‚öõÔ∏è Beijing Academy of Quantum Information Science 08/2023 ‚Äì 01/2024 Research Intern at Quantum Computation Department Proposed a quantum convolution kernel design based on variational quantum circuits and developed a universal quantum convolution layer, successfully integrating it into classical CNN architectures such as VGG, GoogLeNet, and ResNet. Developed and evaluated various hybrid models, including a simple model named HQCCNN-2, which achieved 84.45% accuracy on the FashionMNIST dataset, surpassing the traditional CNN\u0026rsquo;s 80.72%. This demonstrates the effectiveness of the quantum convolution layer in improving model performance. Tested on a real quantum computer further validated the effectiveness of the hybrid model, demonstrating the viable integration of quantum computing with deep learning, and highlighting the potential for leveraging quantum properties to enhance model performance. üèÖ Competition Experience ü•â China International \u0026#34;Internet \u0026#43;\u0026#34; College Students\u0026#39; Innovation Competition 08/2022 üõ°Ô∏è Zhongke Ushield: Deep Learning-based Face Privacy Protection Authentication System Responsible for constructing a localized facial feature extraction engine based on MobileFaceNet, ensuring feature extraction is completed on end devices (such as mobile phones and cameras), guaranteeing that raw data does not leave the domain and is not stored, thus enhancing user privacy protection while improving recognition efficiency. ü•â \u0026#34;Challenge Cup\u0026#34; Capital University Entrepreneurship Competition 05/2022 üå≥ Smart Orchard Responsible for the development of the fruit detection, ripeness prediction, and pest identification system, using deep convolutional neural network (CNN) technology for intelligent monitoring of crop growth conditions. Applied advanced object detection algorithms such as Faster R-CNN and YOLO to achieve high precision in apple detection and ripeness assessment, with an accuracy rate exceeding 90%, significantly enhancing the intelligence level of orchard management. Built and trained a dedicated dataset containing various pest samples, optimizing pest detection accuracy through data preprocessing (such as image normalization and resizing) and data augmentation techniques (like rotation, flipping, and noise addition), enabling the real-time monitoring system to accurately identify over 80% of pests, providing effective scientific maintenance recommendations to help farmers reduce crop losses. üìã Extracurricular Activities Vice President, Cyber Security Club, Beijing Institute of Technology 09/2021-09/2022 Backbone, Media Center of the Student Union of Beijing Institute of Technology 10/2020-06/2021 üì´ Contact üìß zongsi.xu@outlook.com üëî Zongsi (Tristan) Xu üíª github.com/BaizeXS üìç Hong Kong SAR, China ","permalink":"http://localhost:1313/resume/","summary":"Personal resume of Zongsi (Tristan) Xu","title":"Zongsi (Tristan) Xu"},{"content":"‰∏Ä„ÄÅÊï∞ÂÄºÁâπÂæÅ‰∏éÁ±ªÂà´ÁâπÂæÅ Êï∞ÂÄºÁâπÂæÅ (Numeric Features) ÂÖ∑ÊúâÂèØÂä†ÂáèÁöÑÊÑè‰πâÔºå‰∏îÂ≠òÂú®Â§ßÂ∞èÈ°∫Â∫è„ÄÇ ‰æãÂ≠êÔºöÂπ¥ÈæÑ„ÄÅÊ∏©Â∫¶Á≠â„ÄÇÂèØ‰ª•Áõ¥Êé•‰øùÁïôÂÖ∂Êï¥Êï∞ÊàñÊµÆÁÇπÊï∞ÂΩ¢Âºè‰æõÊ®°Âûã‰ΩøÁî®„ÄÇ Á±ªÂà´ÁâπÂæÅ (Categorical Features) Êï∞ÊçÆÂÄºÁ¶ªÊï£Ôºå‰∏çÂÖ∑Â§á‚ÄúÊï∞ÂÄºÂ§ßÂ∞è‚ÄùÈó¥ÁöÑÂèØÊØîÊÑè‰πâ„ÄÇ ‰æãÂ≠êÔºöÂõΩÁ±çÔºàÁæéÂõΩ/‰∏≠ÂõΩ/Âç∞Â∫¶Á≠âÔºâ„ÄÅÊÄßÂà´ÔºàÁî∑/Â•≥ÔºâÁ≠â„ÄÇ ÈóÆÈ¢òÔºöËã•‰ªÖÁî®Êï¥Êï∞Ë°®Á§∫ÔºàÁæéÂõΩ=1, ‰∏≠ÂõΩ=2ÔºâÔºå‰ºöÂºïÂÖ•ÈîôËØØÁöÑÊï∞ÂÄºËøêÁÆóÂÖ≥Á≥ªÔºåÂ¶Ç ‚ÄúÁæéÂõΩ + ‰∏≠ÂõΩ = Âç∞Â∫¶‚Äù„ÄÇ ‰∫å„ÄÅOne-HotÁºñÁ†ÅÁöÑÂä®Êú∫‰∏éÊµÅÁ®ã ‰∏∫‰ªÄ‰πà‰ΩøÁî®One-Hot\nÈÄöËøáÂ∞ÜÁ±ªÂà´Êò†Â∞Ñ‰∏∫ÂêëÈáèÔºåÈÅøÂÖçÊï¥Êï∞ÁºñÁ†ÅÂºïÂÖ•ÁöÑ‰º™Êï∞ÂÄºÂÖ≥Á≥ª„ÄÇ ÂêåÊó∂‰øùÁïôÂêÑÁßçÂèØËÉΩÁ±ªÂà´ÁöÑ‰ø°ÊÅØÔºå‰∏î‰ªÖÂú®ÂØπÂ∫î‰ΩçÁΩÆ‰∏∫1ÔºåÂÖ∂‰ªñ‰ΩçÁΩÆ‰∏∫0„ÄÇ Âª∫Á´ãÊò†Â∞ÑÔºö‰ªéÁ±ªÂà´Âà∞Á¥¢Âºï\n‰∏∫ÊØè‰∏™Á±ªÂà´ÂàÜÈÖç‰∏Ä‰∏™ÂîØ‰∏ÄÁ¥¢ÂºïÔºåÈÄöÂ∏∏‰ªé1ÂºÄÂßã„ÄÇ È¢ÑÁïôÁ¥¢Âºï0Ë°®Á§∫‚ÄúÊú™Áü•‚ÄùÊàñ‚ÄúÁº∫Â§±‚ÄùÔºåÂØπÂ∫îÂÖ®0ÂêëÈáè„ÄÇ ËΩ¨Êç¢‰∏∫One-HotÂêëÈáè\nËã•Á±ªÂà´ÊÄªÊï∞‰∏∫197ÔºåÂàôÁî®197Áª¥ÂêëÈáèË°®Á§∫„ÄÇ ‰æãÂ≠êÔºöÁæéÂõΩ [1, 0, 0, 0, ‚Ä¶]Ôºå ‰∏≠ÂõΩ [0, 1, 0, 0, ‚Ä¶]„ÄÇ Á§∫‰æãÔºöË°®Á§∫‰∏Ä‰∏™‰∫∫ÁöÑÁâπÂæÅ\nÁâπÂæÅÂåÖÂê´ÔºàÂπ¥ÈæÑ, ÊÄßÂà´, ÂõΩÁ±çÔºåÂÖ∂‰∏≠ÂõΩÁ±ç197ÁßçÔºâ Áª¥Â∫¶ÊÄªÂíåÔºö1Áª¥_age + 1Áª¥_gender + 197Áª¥_nationality = 199Áª¥„ÄÇ ‰æãÂ¶Ç (28, Â•≥, ‰∏≠ÂõΩ) ‚Üí [28, 0, 0, 1, 0, ‚Ä¶, 0]„ÄÇ ‰∏â„ÄÅÊñáÊú¨Êï∞ÊçÆÂ§ÑÁêÜÊµÅÁ®ã ÊñáÊú¨Âú®Ëá™ÁÑ∂ËØ≠Ë®ÄÂ§ÑÁêÜÔºàNLPÔºâ‰∏≠‰Ωú‰∏∫Â∏∏ËßÅÁöÑÂéüÂßãËæìÂÖ•ÔºåÈúÄË¶ÅÊï∞ÂÄºÂåñÊâçËÉΩÈÄÅÂÖ•Ê®°Âûã„ÄÇ‰∏ÄËà¨Ê≠•È™§Â¶Ç‰∏ãÔºö\nÂàÜËØç (Tokenization)\nÂ∞ÜÊñáÊú¨ÊãÜÂàÜ‰∏∫‰∏Ä‰∏™‰∏™ÂçïËØçÔºàTokenÔºâ„ÄÇ ‰æãÂ≠êÔºö\u0026quot;... to be or not to be...\u0026quot; ‚Üí [\u0026quot;...\u0026quot;, \u0026quot;to\u0026quot;, \u0026quot;be\u0026quot;, \u0026quot;or\u0026quot;, \u0026quot;not\u0026quot;, \u0026quot;to\u0026quot;, \u0026quot;be\u0026quot;, \u0026quot;...\u0026quot;]„ÄÇ ÁªüËÆ°ËØçÈ¢ë \u0026amp; ÊûÑÂª∫ËØçÂÖ∏\nËØçÈ¢ëÁªüËÆ° Áî®ÂìàÂ∏åË°®/Â≠óÂÖ∏ËÆ∞ÂΩïÊØè‰∏™ÂçïËØçÂá∫Áé∞Ê¨°Êï∞„ÄÇ ÈÅçÂéÜÊñáÊú¨Êó∂ÔºåËã•ÂçïËØçÂ∞öÊú™ÂÖ•Ë°®ÔºåÂàôÊñ∞Âª∫ËÆ∞ÂΩïÔºõËã•Â∑≤Â≠òÂú®ÔºåÂàôËÆ°Êï∞+1„ÄÇ ÊéíÂ∫è‰∏éÁ¥¢Âºï ÊåâËØçÈ¢ëÈôçÂ∫èÊéíÂ∫èÔºåËØçÈ¢ëÊúÄÈ´òÁöÑÂçïËØçÊéíÂú®ÂâçÈù¢„ÄÇ Á¥¢Âºï‰ªé1ÂºÄÂßãÔºå0ÁïôÁªô‚ÄúÊú™Áü•‚Äù„ÄÇ ËØçÂÖ∏ËßÑÊ®°ÔºàvocabularyÔºâÂèØËßÜÈúÄÊ±ÇÊà™Êñ≠Ôºà‰æãÂ¶ÇÂè™‰øùÁïôTop 10kÔºâ„ÄÇ ‰∏∫‰ªÄ‰πàÁßªÈô§‰ΩéÈ¢ëËØç ‰ΩéÈ¢ëËØçÂèØËÉΩÊòØÊãºÂÜôÈîôËØØ„ÄÅÁΩïËßÅ‰∫∫ÂêçÁ≠âÔºåÂØπÊ®°ÂûãÂ∏ÆÂä©ÊúâÈôê„ÄÇ ÂáèÂ∞ëËØçÂÖ∏ËßÑÊ®°ÂèØÈôç‰ΩéËøêÁÆóÂºÄÈîÄ„ÄÅÂä†Âø´Ê®°ÂûãËÆ≠ÁªÉ‰∏éÊé®ÁêÜÈÄüÂ∫¶„ÄÇ Áã¨ÁÉ≠ÁºñÁ†Å (One-Hot Encoding)\nÂ∞ÜÊØè‰∏™ÂçïËØçÊò†Â∞Ñ‰∏∫ËØçÂÖ∏‰∏≠ÁöÑÁ¥¢ÂºïÂêéÔºàÂ¶Ç [2, 4, 1, 8, ‚Ä¶]ÔºâÔºåÂèØËøõ‰∏ÄÊ≠•ËΩ¨Êç¢ÊàêOne-HotÂêëÈáè„ÄÇ One-HotÁª¥Â∫¶ÂèñÂÜ≥‰∫é‰øùÁïô‰∏ãÊù•ÁöÑËØçÂÖ∏Â§ßÂ∞èÔºà‰æãÂ¶Ç1‰∏áÔºâ„ÄÇ Êú™Êî∂ÂΩïÂçïËØçÂèØËÉΩÁõ¥Êé•ÂøΩÁï•ÔºåÊàñÁªü‰∏ÄÁî®Á¥¢Âºï0‰ª£Êõø„ÄÇ Âõõ„ÄÅÊ†∏ÂøÉÊî∂Ëé∑‰∏éÂ∫îÁî® Á±ªÂà´ÁâπÂæÅÂøÖÈúÄÊï∞ÂÄºÂåñÔºö\n‰ΩøÁî®Êï¥Êï∞1,2,3‚Ä¶‰ªÖË°®Á§∫Á±ªÂà´‚ÄúÊ†áËØÜ‚ÄùÔºåÂπ∂‰∏ç‰ª£Ë°®ÂÆÉ‰ª¨ÂèØËøõË°åÊï∞ÂÄºËøêÁÆó„ÄÇ Âõ†Ê≠§ÈúÄË¶ÅOne-HotÁ≠âÁºñÁ†ÅÊñπÂºèÔºåÈÅøÂÖçÊï∞ÂÄºËØØËß£„ÄÇ ÊñáÊú¨Êï∞ÊçÆÈ¢ÑÂ§ÑÁêÜÔºö\nÂàÜËØç„ÄÅËØçÈ¢ëÁªüËÆ°„ÄÅÊûÑÂª∫ËØçÂÖ∏„ÄÅÁ¥¢ÂºïÂåñ„ÄÅOne-HotÊàñÂÖ∂‰ªñÊñπÂºèÔºàÂ¶ÇËØçÂµåÂÖ•ÔºâÊòØÂ∏∏ËßÅÊµÅÁ®ã„ÄÇ Ê≠£Á°ÆÁöÑÊñáÊú¨È¢ÑÂ§ÑÁêÜÂèØÊòæËëóÂΩ±ÂìçÊ®°ÂûãÊÄßËÉΩÂíåÊïàÁéá„ÄÇ ‰øùÁïôÊú™Áü•Á¥¢ÂºïÔºö\n‰øùËØÅÂØπÁº∫Â§±Êï∞ÊçÆÊàñÂ≠óÂÖ∏Â§ñÊñ∞ËØçËÉΩÊúâÂü∫Êú¨ÁöÑË°®Á§∫ÔºåÊèêÂçáÊ®°ÂûãÂÆπÈîôÊÄß„ÄÇ ÂÆûÈôÖ‰ΩøÁî®Ôºö\nÂØπ‰∫éÂ∞èËßÑÊ®°Á±ªÂà´ÂèØÁõ¥Êé•One-HotÁºñÁ†ÅÔºõÂØπ‰∫éËØçÂÖ∏ÂæàÂ§ßÁöÑÂú∫ÊôØÔºåÈÄöÂ∏∏‰ºöËøõ‰∏ÄÊ≠•ËÄÉËôëËØçÂµåÂÖ•ÔºàWord EmbeddingÔºâÊàñÈ¢ÑËÆ≠ÁªÉËØ≠Ë®ÄÊ®°Âûã„ÄÇ ","permalink":"http://localhost:1313/posts/nlp-1/","summary":"\u003ch2 id=\"‰∏ÄÊï∞ÂÄºÁâπÂæÅ‰∏éÁ±ªÂà´ÁâπÂæÅ\"\u003e‰∏Ä„ÄÅÊï∞ÂÄºÁâπÂæÅ‰∏éÁ±ªÂà´ÁâπÂæÅ\u003c/h2\u003e\n\u003col\u003e\n\u003cli\u003e\u003cstrong\u003eÊï∞ÂÄºÁâπÂæÅ (Numeric Features)\u003c/strong\u003e\n\u003cul\u003e\n\u003cli\u003eÂÖ∑ÊúâÂèØÂä†ÂáèÁöÑÊÑè‰πâÔºå‰∏îÂ≠òÂú®Â§ßÂ∞èÈ°∫Â∫è„ÄÇ\u003c/li\u003e\n\u003cli\u003e‰æãÂ≠êÔºöÂπ¥ÈæÑ„ÄÅÊ∏©Â∫¶Á≠â„ÄÇÂèØ‰ª•Áõ¥Êé•‰øùÁïôÂÖ∂Êï¥Êï∞ÊàñÊµÆÁÇπÊï∞ÂΩ¢Âºè‰æõÊ®°Âûã‰ΩøÁî®„ÄÇ\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003eÁ±ªÂà´ÁâπÂæÅ (Categorical Features)\u003c/strong\u003e\n\u003cul\u003e\n\u003cli\u003eÊï∞ÊçÆÂÄºÁ¶ªÊï£Ôºå‰∏çÂÖ∑Â§á‚ÄúÊï∞ÂÄºÂ§ßÂ∞è‚ÄùÈó¥ÁöÑÂèØÊØîÊÑè‰πâ„ÄÇ\u003c/li\u003e\n\u003cli\u003e‰æãÂ≠êÔºöÂõΩÁ±çÔºàÁæéÂõΩ/‰∏≠ÂõΩ/Âç∞Â∫¶Á≠âÔºâ„ÄÅÊÄßÂà´ÔºàÁî∑/Â•≥ÔºâÁ≠â„ÄÇ\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003eÈóÆÈ¢ò\u003c/strong\u003eÔºöËã•‰ªÖÁî®Êï¥Êï∞Ë°®Á§∫ÔºàÁæéÂõΩ=1, ‰∏≠ÂõΩ=2ÔºâÔºå‰ºöÂºïÂÖ•ÈîôËØØÁöÑÊï∞ÂÄºËøêÁÆóÂÖ≥Á≥ªÔºåÂ¶Ç ‚ÄúÁæéÂõΩ + ‰∏≠ÂõΩ = Âç∞Â∫¶‚Äù„ÄÇ\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003c/ol\u003e\n\u003ch2 id=\"‰∫åone-hotÁºñÁ†ÅÁöÑÂä®Êú∫‰∏éÊµÅÁ®ã\"\u003e‰∫å„ÄÅOne-HotÁºñÁ†ÅÁöÑÂä®Êú∫‰∏éÊµÅÁ®ã\u003c/h2\u003e\n\u003col\u003e\n\u003cli\u003e\n\u003cp\u003e\u003cstrong\u003e‰∏∫‰ªÄ‰πà‰ΩøÁî®One-Hot\u003c/strong\u003e\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eÈÄöËøáÂ∞ÜÁ±ªÂà´Êò†Â∞Ñ‰∏∫ÂêëÈáèÔºåÈÅøÂÖçÊï¥Êï∞ÁºñÁ†ÅÂºïÂÖ•ÁöÑ‰º™Êï∞ÂÄºÂÖ≥Á≥ª„ÄÇ\u003c/li\u003e\n\u003cli\u003eÂêåÊó∂‰øùÁïôÂêÑÁßçÂèØËÉΩÁ±ªÂà´ÁöÑ‰ø°ÊÅØÔºå‰∏î‰ªÖÂú®ÂØπÂ∫î‰ΩçÁΩÆ‰∏∫1ÔºåÂÖ∂‰ªñ‰ΩçÁΩÆ‰∏∫0„ÄÇ\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003e\u003cstrong\u003eÂª∫Á´ãÊò†Â∞ÑÔºö‰ªéÁ±ªÂà´Âà∞Á¥¢Âºï\u003c/strong\u003e\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e‰∏∫ÊØè‰∏™Á±ªÂà´ÂàÜÈÖç‰∏Ä‰∏™ÂîØ‰∏ÄÁ¥¢ÂºïÔºåÈÄöÂ∏∏‰ªé1ÂºÄÂßã„ÄÇ\u003c/li\u003e\n\u003cli\u003eÈ¢ÑÁïôÁ¥¢Âºï0Ë°®Á§∫‚ÄúÊú™Áü•‚ÄùÊàñ‚ÄúÁº∫Â§±‚ÄùÔºåÂØπÂ∫îÂÖ®0ÂêëÈáè„ÄÇ\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003e\u003cstrong\u003eËΩ¨Êç¢‰∏∫One-HotÂêëÈáè\u003c/strong\u003e\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eËã•Á±ªÂà´ÊÄªÊï∞‰∏∫197ÔºåÂàôÁî®197Áª¥ÂêëÈáèË°®Á§∫„ÄÇ\u003c/li\u003e\n\u003cli\u003e‰æãÂ≠êÔºöÁæéÂõΩ \u003ccode\u003e[1, 0, 0, 0, ‚Ä¶]\u003c/code\u003eÔºå ‰∏≠ÂõΩ \u003ccode\u003e[0, 1, 0, 0, ‚Ä¶]\u003c/code\u003e„ÄÇ\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003e\u003cstrong\u003eÁ§∫‰æãÔºöË°®Á§∫‰∏Ä‰∏™‰∫∫ÁöÑÁâπÂæÅ\u003c/strong\u003e\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eÁâπÂæÅÂåÖÂê´ÔºàÂπ¥ÈæÑ, ÊÄßÂà´, ÂõΩÁ±çÔºåÂÖ∂‰∏≠ÂõΩÁ±ç197ÁßçÔºâ\u003c/li\u003e\n\u003cli\u003eÁª¥Â∫¶ÊÄªÂíåÔºö1Áª¥_age + 1Áª¥_gender + 197Áª¥_nationality = 199Áª¥„ÄÇ\u003c/li\u003e\n\u003cli\u003e‰æãÂ¶Ç \u003ccode\u003e(28, Â•≥, ‰∏≠ÂõΩ)\u003c/code\u003e ‚Üí \u003ccode\u003e[28, 0, 0, 1, 0, ‚Ä¶, 0]\u003c/code\u003e„ÄÇ\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003c/ol\u003e\n\u003ch2 id=\"‰∏âÊñáÊú¨Êï∞ÊçÆÂ§ÑÁêÜÊµÅÁ®ã\"\u003e‰∏â„ÄÅÊñáÊú¨Êï∞ÊçÆÂ§ÑÁêÜÊµÅÁ®ã\u003c/h2\u003e\n\u003cp\u003eÊñáÊú¨Âú®Ëá™ÁÑ∂ËØ≠Ë®ÄÂ§ÑÁêÜÔºàNLPÔºâ‰∏≠‰Ωú‰∏∫Â∏∏ËßÅÁöÑÂéüÂßãËæìÂÖ•ÔºåÈúÄË¶ÅÊï∞ÂÄºÂåñÊâçËÉΩÈÄÅÂÖ•Ê®°Âûã„ÄÇ‰∏ÄËà¨Ê≠•È™§Â¶Ç‰∏ãÔºö\u003c/p\u003e\n\u003col\u003e\n\u003cli\u003e\n\u003cp\u003e\u003cstrong\u003eÂàÜËØç (Tokenization)\u003c/strong\u003e\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eÂ∞ÜÊñáÊú¨ÊãÜÂàÜ‰∏∫‰∏Ä‰∏™‰∏™ÂçïËØçÔºàTokenÔºâ„ÄÇ\u003c/li\u003e\n\u003cli\u003e‰æãÂ≠êÔºö\u003ccode\u003e\u0026quot;... to be or not to be...\u0026quot;\u003c/code\u003e ‚Üí \u003ccode\u003e[\u0026quot;...\u0026quot;, \u0026quot;to\u0026quot;, \u0026quot;be\u0026quot;, \u0026quot;or\u0026quot;, \u0026quot;not\u0026quot;, \u0026quot;to\u0026quot;, \u0026quot;be\u0026quot;, \u0026quot;...\u0026quot;]\u003c/code\u003e„ÄÇ\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003e\u003cstrong\u003eÁªüËÆ°ËØçÈ¢ë \u0026amp; ÊûÑÂª∫ËØçÂÖ∏\u003c/strong\u003e\u003c/p\u003e","title":""},{"content":"Text to Sequence ÊñáÊú¨Â§ÑÁêÜ\nStep1: Tokenization\nTokenization breaks a piece of text down into a list of tokens.\nHere, a token is a word. (A token can be a character in some applications.)\nTokenizationËÆ≤Á©∂ÂæàÂ§öÔºå‰æãÂ¶ÇÊòØÂê¶Â∫îËØ•ÊääÂ§ßÂÜôÊîπÊàêÂ∞èÂÜôÂë¢ÔºüËøõË°åtypo correctionÁ≠âÁ≠â\nStep2: Build Dictionary\nUse a dictionary (hash table) to count word frequencies.\nThe dictionary maps word to index.\nÂèØ‰ª•È¶ñÂÖàÁªüËÆ°ËØçÈ¢ëÂéªÊéâ‰ΩéÈ¢ëËØçÔºåÁÑ∂ÂêéËÆ©ÊØè‰∏™ËØçÂØπÂ∫î‰∏Ä‰∏™Ê≠£Êï¥Êï∞ÔºõËøôÊ†∑ÁöÑËØùÔºå‰∏ÄÂè•ËØùÂ∞±ÂèØ‰ª•Áî®‰∏Ä‰∏™Ê≠£Êï¥Êï∞ÂàóË°®Ë°®Á§∫ÔºåËøô‰∏™ÂàóË°®Â∞±Âè´sequenceÔºõÂ¶ÇÊûúÂøÖË¶ÅÂ∞±ËøòÂæóÂÅöone-hot encoding„ÄÇ\nÁªìÊûú\n‰ΩÜÊòØÈïøÂ∫¶‰∏çÁªü‰∏Ä\nStep4: ÂØπÈΩêsequence\nËß£ÂÜ≥ÊñπÊ°àÊòØËøôÊ†∑ÁöÑÔºöÂèØ‰ª•Âõ∫ÂÆöÈïøÂ∫¶‰∏∫wÔºåÂä†ÂÖ•‰∏Ä‰∏™Â∫èÂàóÈïøÂ∫¶Â§™ÈïøÔºåÂ∞±Á†çÊéâÂâçÈù¢ÁöÑËØçÔºåÂè™‰øùÁïôÊúÄÂêéw‰∏™ËØçÔºõÂ¶ÇÊûú‰∏Ä‰∏™Â∫èÂàóÂ§™Áü≠ÔºåÂ∞±ÂÅözero paddingÔºåÁî®0Â°´ÂÖÖ\nËøôÊ†∑‰∏ÄÊù•ÔºåÊâÄÊúâÁöÑÂ∫èÂàóÈïøÂ∫¶Â∞±Áªü‰∏Ä‰∫Ü\nÊñáÊú¨Â§ÑÁêÜÂÆåÊàê‰∫ÜÔºåÊé•‰∏ãÊù•ÊòØword embeddingÔºåÊääÂçïËØçË°®Á§∫‰∏∫‰∏Ä‰∏™‰ΩéÁª¥ÂêëÈáèÔºõ\nÁÑ∂ËÄåËøôÊ†∑ÂÅöÁöÑËØùÔºåÂ¶ÇÊûúÊòØ10000‰∏™ÂçïËØçÔºåÁª¥Â∫¶Â∞±ÊòØ10000Áª¥ÔºåÁª¥Â∫¶Â§™È´ò‰∫ÜÔºõÂõ†Ê≠§Ë¶ÅÂÅöword embeddingÔºõ\nÂÖ∑‰ΩìÂÅöÊ≥ïÂ∞±ÊòØÊääone-hotÂêëÈáèe_iÂíåÂèÇÊï∞Áü©ÈòµpÁõ∏‰πòÔºõÁü©ÈòµPËΩ¨ÁΩÆÁöÑÂ§ßÂ∞èÊòØd x vÔºõdÊòØËØçÂêëÈáèÁöÑÁª¥Â∫¶ÔºõvÊòØÂ≠óÂÖ∏ÈáåËØçÊ±áÁöÑÊï∞ÈáèÔºõÁªìÊûú‰∏∫x_iÔºõx_iÂ∞±ÊòØ‰∏Ä‰∏™ËØçÂêëÈáèÔºõÂ¶ÇÊûúone-hotÂêëÈáèÁöÑÁ¨¨‰∏âË°å‰∏∫1ÔºõÈÇ£‰πàx_iÂ∞±ÊòØPËΩ¨ÁΩÆÁü©ÈòµÁöÑÁ¨¨‰∏âÂàóÔºàÂÖ∂‰ΩôÂàóÈÉΩ‰∏∫0ÔºâÔºõÊâÄ‰ª•PËΩ¨ÁΩÆÊØè‰∏ÄÂàóÈÉΩÊòØ‰∏Ä‰∏™ËØçÂêëÈáèÔºõÊâÄ‰ª•Áü©ÈòµPÊú¨Ë∫´ÁöÑÊØè‰∏ÄË°åÂ∞±ÊòØ‰∏Ä‰∏™ËØçÂêëÈáèÔºõÂÖ∂Ë°åÊï∞‰∏∫vÔºõÂç≥vocabularyÔºåËØçÊ±áÈáèÔºõÊØè‰∏ÄË°åÂØπÂ∫î‰∏Ä‰∏™ÂçïËØçÔºõÁü©ÈòµÁöÑÂàóÊï∞‰∏∫dÔºõdÊòØÁî®Êà∑ÂÜ≥ÂÆöÁöÑÔºõdÁöÑÂ§ßÂ∞è‰ºöÂÜ≥ÂÆöÊú∫Âô®Â≠¶‰π†Ê®°ÂûãÁöÑË°®Áé∞ÔºõÂ∫îËØ•Áî®xxxÊù•ÈÄâÊã©‰∏Ä‰∏™ÊØîËæÉÂ•ΩÁöÑdÔºõ\nÊàë‰ª¨ÁöÑ‰ªªÂä°ÊòØÁúãËØÑËÆ∫ÊòØÊ≠£Èù¢ÁöÑËøòÊòØË¥üÈù¢ÁöÑÔºõÂèÇÊï∞Áü©ÈòµÊòØ‰ªéËÆ≠ÁªÉÊï∞ÊçÆ‰∏≠Â≠¶‰π†Âá∫Êù•ÁöÑÔºåÊâÄ‰ª•Â≠¶Âá∫Êù•ÁöÑËØçÂêëÈáèÊòØÂ∏¶ÊúâÊÑüÊÉÖËâ≤ÂΩ©ÁöÑÔºõÂÅáËÆæËøô‰∫õËØçÂêëÈáèÈÉΩÊòØ‰∫åÁª¥ÁöÑÔºåÂàôÂèØ‰ª•Âú®Âπ≥Èù¢ÂùêÊ†áÁ≥ª‰∏≠Ê†áÂá∫‰∏ãÈù¢ËØçÂêëÈáè\nkerasÊèê‰æõembeddingÂ±ÇÔºõÁî®Êà∑ÂèØ‰ª•ÊåáÂÆövocabularyÂ§ßÂ∞èÂíådÁöÑÂ§ßÂ∞èÔºõ‰ª•ÂèäÊØè‰∏Ä‰∏™sequenceÁöÑÈïøÂ∫¶ÔºõdÊòØÊ†πÊçÆÁÆóÊ≥ïÈÄâÂá∫Êù•ÁöÑ Âà∞Ëøô‰∏ÄÊ≠•ÔºåÊàë‰ª¨Â∑≤ÁªèÂÆåÊàê‰∫ÜÊñáÊú¨Â§ÑÁêÜÂíåword embedding„ÄÇÊé•‰∏ãÊù•Â∞±ÊòØÁî®Logistic Regression for Binary ClassificationÂÅö‰∫åÂàÜÁ±ªÔºõ\n","permalink":"http://localhost:1313/posts/nlp-2/","summary":"\u003ch3 id=\"text-to-sequence\"\u003eText to Sequence\u003c/h3\u003e\n\u003cp\u003eÊñáÊú¨Â§ÑÁêÜ\u003c/p\u003e\n\u003cp\u003eStep1: Tokenization\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\n\u003cp\u003eTokenization breaks a piece of text down into a list of tokens.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003eHere, a token is a word. (A token can be a character in some applications.)\u003c/p\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003eTokenizationËÆ≤Á©∂ÂæàÂ§öÔºå‰æãÂ¶ÇÊòØÂê¶Â∫îËØ•ÊääÂ§ßÂÜôÊîπÊàêÂ∞èÂÜôÂë¢ÔºüËøõË°åtypo correctionÁ≠âÁ≠â\u003c/p\u003e\n\u003cp\u003e\u003cimg alt=\"image-20250322150322238\" loading=\"lazy\" src=\"./NLP-2.assets/image-20250322150322238.png\"\u003e\u003c/p\u003e\n\u003cp\u003eStep2: Build Dictionary\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\n\u003cp\u003eUse a dictionary (hash table) to count word frequencies.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003eThe dictionary maps word to index.\u003c/p\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003eÂèØ‰ª•È¶ñÂÖàÁªüËÆ°ËØçÈ¢ëÂéªÊéâ‰ΩéÈ¢ëËØçÔºåÁÑ∂ÂêéËÆ©ÊØè‰∏™ËØçÂØπÂ∫î‰∏Ä‰∏™Ê≠£Êï¥Êï∞ÔºõËøôÊ†∑ÁöÑËØùÔºå‰∏ÄÂè•ËØùÂ∞±ÂèØ‰ª•Áî®‰∏Ä‰∏™Ê≠£Êï¥Êï∞ÂàóË°®Ë°®Á§∫ÔºåËøô‰∏™ÂàóË°®Â∞±Âè´sequenceÔºõÂ¶ÇÊûúÂøÖË¶ÅÂ∞±ËøòÂæóÂÅöone-hot encoding„ÄÇ\u003cimg alt=\"image-20250322150620890\" loading=\"lazy\" src=\"./NLP-2.assets/image-20250322150620890.png\"\u003e\u003c/p\u003e\n\u003cp\u003eÁªìÊûú\u003c/p\u003e\n\u003cp\u003e\u003cimg alt=\"image-20250322150754528\" loading=\"lazy\" src=\"./NLP-2.assets/image-20250322150754528.png\"\u003e\u003c/p\u003e\n\u003cp\u003e‰ΩÜÊòØÈïøÂ∫¶‰∏çÁªü‰∏Ä\u003c/p\u003e\n\u003cp\u003eStep4: ÂØπÈΩêsequence\u003c/p\u003e\n\u003cp\u003e\u003cimg alt=\"image-20250322150854986\" loading=\"lazy\" src=\"./NLP-2.assets/image-20250322150854986.png\"\u003e\u003c/p\u003e\n\u003cp\u003eËß£ÂÜ≥ÊñπÊ°àÊòØËøôÊ†∑ÁöÑÔºöÂèØ‰ª•Âõ∫ÂÆöÈïøÂ∫¶‰∏∫wÔºåÂä†ÂÖ•‰∏Ä‰∏™Â∫èÂàóÈïøÂ∫¶Â§™ÈïøÔºåÂ∞±Á†çÊéâÂâçÈù¢ÁöÑËØçÔºåÂè™‰øùÁïôÊúÄÂêéw‰∏™ËØçÔºõÂ¶ÇÊûú‰∏Ä‰∏™Â∫èÂàóÂ§™Áü≠ÔºåÂ∞±ÂÅözero paddingÔºåÁî®0Â°´ÂÖÖ\u003c/p\u003e\n\u003cp\u003e\u003cimg alt=\"image-20250322151030119\" loading=\"lazy\" src=\"./NLP-2.assets/image-20250322151030119.png\"\u003e\u003c/p\u003e\n\u003cp\u003eËøôÊ†∑‰∏ÄÊù•ÔºåÊâÄÊúâÁöÑÂ∫èÂàóÈïøÂ∫¶Â∞±Áªü‰∏Ä‰∫Ü\u003c/p\u003e\n\u003cp\u003e\u003cimg alt=\"image-20250322151117125\" loading=\"lazy\" src=\"./NLP-2.assets/image-20250322151117125.png\"\u003e\u003c/p\u003e\n\u003cp\u003eÊñáÊú¨Â§ÑÁêÜÂÆåÊàê‰∫ÜÔºåÊé•‰∏ãÊù•ÊòØword embeddingÔºåÊääÂçïËØçË°®Á§∫‰∏∫‰∏Ä‰∏™‰ΩéÁª¥ÂêëÈáèÔºõ\u003c/p\u003e\n\u003cp\u003e\u003cimg alt=\"image-20250322151252837\" loading=\"lazy\" src=\"./NLP-2.assets/image-20250322151252837.png\"\u003e\u003c/p\u003e","title":""},{"content":"üëã About me Hello! I\u0026rsquo;m Xu Zongsi, a passionate technology enthusiast currently pursuing my Master of Science in ECIC at The University of Hong Kong. With a solid background in Software Engineering from the Beijing Institute of Technology, I specialize in artificial intelligence areas like machine learning, deep learning, natural language processing, computer vision, and reinforcement learning.\nInspired by OpenAI‚Äôs five-step plan towards superintelligence, I am excited about AGI and have developed a keen interest in LLM agents, MLLM, and knowledge graphs. I see great potential in these fields and aspire to contribute to innovative solutions.\nüìö Education üá≠üá∞ The University of Hong Kong 09/2024 - Expected 11/2025 School of Computing and Data Science Master of Science in Electronic Commerce \u0026amp; Internet Computing Relevant Courses: Machine learning for business and e-commerce, Knowledge graphs, Financial fraud analytics, Internet infrastructure technologies, Website engineering, Blockchain and cryptocurrency, etc. üá®üá≥ Beijing Institute of Technology 09/2020 - 06/2024 School of Computer Science \u0026amp; Technology Bachelor of Engineering in Software Engineering, last two years GPA: 3.7/4 Relevant Courses: Reinforcement Learning, Deep Learning and Computer Vision, Artificial Intelligence and Robot Ethics, Almost Human: Mind, Brain and Artificial Intelligence, Mathematical Analysis for Engineering, Linear Algebra, Probability and Mathematical Statistics, etc. Skills: Python, Java, common data structures, design patterns, machine learning basics and algorithms, Linux, PyTorch, and some development tools (git, conda, etc.). üèÜ Awards \u0026amp; Honors Beijing Institute of Technology Undergraduate Scholarship (Top 20% of Grade) 06/2023 3rd Prize of China International \u0026#34;Internet \u0026#43;\u0026#34; College Student\u0026#39;s Innovation Competition 08/2022 Bronze Prize of \u0026#34;Challenge Cup\u0026#34; Capital University Entrepreneurship Competition 05/2022 üíº Project Experience üîç Online Transaction Fraud Detection 09/2024 ‚Äì 01/2025 Independent project, supervised by Dr. Vivien Chan Focused on addressing financial fraud in e-commerce to enhance the accuracy of transaction anomaly detection, while independently managing the entire case study that included data preprocessing, feature engineering, model building, evaluation, and results analysis. Effectively resolved class imbalance issues using SMOTE and ROSE techniques. Built various models including Logistic Regression, Random Forest, XGBoost, and LightGBM, ultimately selecting the LightGBM model to achieve a recall rate of 95.45% and an AUC of 99.84%. Wrote efficient and maintainable code, enhancing model training and data processing efficiency through parallel computing and logging. ü§ñ Multi-Model Intelligent Text Keyword Extraction System 08/2023 ‚Äì 09/2023 Group project, supervised by Associate Prof. Xiaolin Zhao Designed and implemented an intelligent text summary system that automatically extracts keywords from article titles and abstracts, enhancing the understanding and summarization of text information. Participated in the planning of the technical route and built a hybrid model combining extractive and generative approaches, utilizing advanced natural language processing techniques including KeyBERT, Sentence Transformer, BERT, and T5 models. Responsible for data preprocessing and tokenization, as well as the end-to-end implementation and training of the T5 model, optimizing the model architecture and hyperparameters, achieving satisfactory results after only 3 epochs of training. Model evaluation results showed that the Rouge-1, Rouge-2, and Rouge-L metrics reached 0.6345, 0.5038, and 0.5282, respectively, in the third epoch, validating the model\u0026rsquo;s effectiveness in the summarization task. üéì Cambridge University Machine Learning Summer Project 07/2023 ‚Äì 08/2023 Group project, supervised by Prof. Pietro Li√≤ Participated in the Cambridge University deep learning summer project, focusing on deep reinforcement learning; explored multi-agent learning algorithms across different environments. Reproduced the Multi-Agent Deep Deterministic Policy Gradient (MADDPG) algorithm in the Simple Adversary environment and studied the effect of agent numbers on convergence speed and stability, finding optimal stability at 21 agents. Designed and implemented comparative experiments inspired by the Rainbow algorithm, assessing target network strategies versus the Double Deep Q-Network (Double DQN). The results demonstrated that Double DQN significantly enhanced convergence speed, optimizing the overall learning process. Co-authored a group project paper on agent numbers and strategies effectiveness in multi-agent systems, achieving a score of 71% in the summer program (the highest in my group) and a \u0026ldquo;First Class\u0026rdquo; classification in the UK grading system. üëÅÔ∏è Deep Learning and Computer Vision Semester Project 09/2022 ‚Äì 12/2022 Independent project, supervised by Associate Prof. Guangyu Gao Designed and implemented a waste classifier using the ResNet model to improve classification accuracy and reduce resource waste. The project also enhanced understanding of transfer learning techniques with ResNet. Collected a dataset of 16 waste categories and preprocessed the images for uniformity and standardization, incorporating data augmentation techniques to enhance the dataset. Conducted experiments using ResNet34 and ResNet50 models through transfer learning, accelerating network convergence by leveraging pretrained weights. During training, techniques such as Batch Normalization and Dropout were applied to mitigate the risk of overfitting. The final model achieved an accuracy of 90% on the training set, while the performance on the test set was 61%, indicating a significant overfitting phenomenon during the training process. üéì Internship ‚öõÔ∏è Beijing Academy of Quantum Information Science 08/2023 ‚Äì 01/2024 Research Intern at Quantum Computation Department Proposed a quantum convolution kernel design based on variational quantum circuits and developed a universal quantum convolution layer, successfully integrating it into classical CNN architectures such as VGG, GoogLeNet, and ResNet. Developed and evaluated various hybrid models, including a simple model named HQCCNN-2, which achieved 84.45% accuracy on the FashionMNIST dataset, surpassing the traditional CNN\u0026rsquo;s 80.72%. This demonstrates the effectiveness of the quantum convolution layer in improving model performance. Tested on a real quantum computer further validated the effectiveness of the hybrid model, demonstrating the viable integration of quantum computing with deep learning, and highlighting the potential for leveraging quantum properties to enhance model performance. üèÖ Competition Experience ü•â China International \u0026#34;Internet \u0026#43;\u0026#34; College Students\u0026#39; Innovation Competition 08/2022 üõ°Ô∏è Zhongke Ushield: Deep Learning-based Face Privacy Protection Authentication System Responsible for constructing a localized facial feature extraction engine based on MobileFaceNet, ensuring feature extraction is completed on end devices (such as mobile phones and cameras), guaranteeing that raw data does not leave the domain and is not stored, thus enhancing user privacy protection while improving recognition efficiency. ü•â \u0026#34;Challenge Cup\u0026#34; Capital University Entrepreneurship Competition 05/2022 üå≥ Smart Orchard Responsible for the development of the fruit detection, ripeness prediction, and pest identification system, using deep convolutional neural network (CNN) technology for intelligent monitoring of crop growth conditions. Applied advanced object detection algorithms such as Faster R-CNN and YOLO to achieve high precision in apple detection and ripeness assessment, with an accuracy rate exceeding 90%, significantly enhancing the intelligence level of orchard management. Built and trained a dedicated dataset containing various pest samples, optimizing pest detection accuracy through data preprocessing (such as image normalization and resizing) and data augmentation techniques (like rotation, flipping, and noise addition), enabling the real-time monitoring system to accurately identify over 80% of pests, providing effective scientific maintenance recommendations to help farmers reduce crop losses. üìã Extracurricular Activities Vice President, Cyber Security Club, Beijing Institute of Technology 09/2021-09/2022 Backbone, Media Center of the Student Union of Beijing Institute of Technology 10/2020-06/2021 üì´ Contact üìß zongsi.xu@outlook.com üëî Zongsi (Tristan) Xu üíª github.com/BaizeXS üìç Hong Kong SAR, China ","permalink":"http://localhost:1313/resume/","summary":"Personal resume of Zongsi (Tristan) Xu","title":"Zongsi (Tristan) Xu"},{"content":"‰∏Ä„ÄÅÊï∞ÂÄºÁâπÂæÅ‰∏éÁ±ªÂà´ÁâπÂæÅ Êï∞ÂÄºÁâπÂæÅ (Numeric Features) ÂÖ∑ÊúâÂèØÂä†ÂáèÁöÑÊÑè‰πâÔºå‰∏îÂ≠òÂú®Â§ßÂ∞èÈ°∫Â∫è„ÄÇ ‰æãÂ≠êÔºöÂπ¥ÈæÑ„ÄÅÊ∏©Â∫¶Á≠â„ÄÇÂèØ‰ª•Áõ¥Êé•‰øùÁïôÂÖ∂Êï¥Êï∞ÊàñÊµÆÁÇπÊï∞ÂΩ¢Âºè‰æõÊ®°Âûã‰ΩøÁî®„ÄÇ Á±ªÂà´ÁâπÂæÅ (Categorical Features) Êï∞ÊçÆÂÄºÁ¶ªÊï£Ôºå‰∏çÂÖ∑Â§á‚ÄúÊï∞ÂÄºÂ§ßÂ∞è‚ÄùÈó¥ÁöÑÂèØÊØîÊÑè‰πâ„ÄÇ ‰æãÂ≠êÔºöÂõΩÁ±çÔºàÁæéÂõΩ/‰∏≠ÂõΩ/Âç∞Â∫¶Á≠âÔºâ„ÄÅÊÄßÂà´ÔºàÁî∑/Â•≥ÔºâÁ≠â„ÄÇ ÈóÆÈ¢òÔºöËã•‰ªÖÁî®Êï¥Êï∞Ë°®Á§∫ÔºàÁæéÂõΩ=1, ‰∏≠ÂõΩ=2ÔºâÔºå‰ºöÂºïÂÖ•ÈîôËØØÁöÑÊï∞ÂÄºËøêÁÆóÂÖ≥Á≥ªÔºåÂ¶Ç ‚ÄúÁæéÂõΩ + ‰∏≠ÂõΩ = Âç∞Â∫¶‚Äù„ÄÇ ‰∫å„ÄÅOne-HotÁºñÁ†ÅÁöÑÂä®Êú∫‰∏éÊµÅÁ®ã ‰∏∫‰ªÄ‰πà‰ΩøÁî®One-Hot\nÈÄöËøáÂ∞ÜÁ±ªÂà´Êò†Â∞Ñ‰∏∫ÂêëÈáèÔºåÈÅøÂÖçÊï¥Êï∞ÁºñÁ†ÅÂºïÂÖ•ÁöÑ‰º™Êï∞ÂÄºÂÖ≥Á≥ª„ÄÇ ÂêåÊó∂‰øùÁïôÂêÑÁßçÂèØËÉΩÁ±ªÂà´ÁöÑ‰ø°ÊÅØÔºå‰∏î‰ªÖÂú®ÂØπÂ∫î‰ΩçÁΩÆ‰∏∫1ÔºåÂÖ∂‰ªñ‰ΩçÁΩÆ‰∏∫0„ÄÇ Âª∫Á´ãÊò†Â∞ÑÔºö‰ªéÁ±ªÂà´Âà∞Á¥¢Âºï\n‰∏∫ÊØè‰∏™Á±ªÂà´ÂàÜÈÖç‰∏Ä‰∏™ÂîØ‰∏ÄÁ¥¢ÂºïÔºåÈÄöÂ∏∏‰ªé1ÂºÄÂßã„ÄÇ È¢ÑÁïôÁ¥¢Âºï0Ë°®Á§∫‚ÄúÊú™Áü•‚ÄùÊàñ‚ÄúÁº∫Â§±‚ÄùÔºåÂØπÂ∫îÂÖ®0ÂêëÈáè„ÄÇ ËΩ¨Êç¢‰∏∫One-HotÂêëÈáè\nËã•Á±ªÂà´ÊÄªÊï∞‰∏∫197ÔºåÂàôÁî®197Áª¥ÂêëÈáèË°®Á§∫„ÄÇ ‰æãÂ≠êÔºöÁæéÂõΩ [1, 0, 0, 0, ‚Ä¶]Ôºå ‰∏≠ÂõΩ [0, 1, 0, 0, ‚Ä¶]„ÄÇ Á§∫‰æãÔºöË°®Á§∫‰∏Ä‰∏™‰∫∫ÁöÑÁâπÂæÅ\nÁâπÂæÅÂåÖÂê´ÔºàÂπ¥ÈæÑ, ÊÄßÂà´, ÂõΩÁ±çÔºåÂÖ∂‰∏≠ÂõΩÁ±ç197ÁßçÔºâ Áª¥Â∫¶ÊÄªÂíåÔºö1Áª¥_age + 1Áª¥_gender + 197Áª¥_nationality = 199Áª¥„ÄÇ ‰æãÂ¶Ç (28, Â•≥, ‰∏≠ÂõΩ) ‚Üí [28, 0, 0, 1, 0, ‚Ä¶, 0]„ÄÇ ‰∏â„ÄÅÊñáÊú¨Êï∞ÊçÆÂ§ÑÁêÜÊµÅÁ®ã ÊñáÊú¨Âú®Ëá™ÁÑ∂ËØ≠Ë®ÄÂ§ÑÁêÜÔºàNLPÔºâ‰∏≠‰Ωú‰∏∫Â∏∏ËßÅÁöÑÂéüÂßãËæìÂÖ•ÔºåÈúÄË¶ÅÊï∞ÂÄºÂåñÊâçËÉΩÈÄÅÂÖ•Ê®°Âûã„ÄÇ‰∏ÄËà¨Ê≠•È™§Â¶Ç‰∏ãÔºö\nÂàÜËØç (Tokenization)\nÂ∞ÜÊñáÊú¨ÊãÜÂàÜ‰∏∫‰∏Ä‰∏™‰∏™ÂçïËØçÔºàTokenÔºâ„ÄÇ ‰æãÂ≠êÔºö\u0026quot;... to be or not to be...\u0026quot; ‚Üí [\u0026quot;...\u0026quot;, \u0026quot;to\u0026quot;, \u0026quot;be\u0026quot;, \u0026quot;or\u0026quot;, \u0026quot;not\u0026quot;, \u0026quot;to\u0026quot;, \u0026quot;be\u0026quot;, \u0026quot;...\u0026quot;]„ÄÇ ÁªüËÆ°ËØçÈ¢ë \u0026amp; ÊûÑÂª∫ËØçÂÖ∏\nËØçÈ¢ëÁªüËÆ° Áî®ÂìàÂ∏åË°®/Â≠óÂÖ∏ËÆ∞ÂΩïÊØè‰∏™ÂçïËØçÂá∫Áé∞Ê¨°Êï∞„ÄÇ ÈÅçÂéÜÊñáÊú¨Êó∂ÔºåËã•ÂçïËØçÂ∞öÊú™ÂÖ•Ë°®ÔºåÂàôÊñ∞Âª∫ËÆ∞ÂΩïÔºõËã•Â∑≤Â≠òÂú®ÔºåÂàôËÆ°Êï∞+1„ÄÇ ÊéíÂ∫è‰∏éÁ¥¢Âºï ÊåâËØçÈ¢ëÈôçÂ∫èÊéíÂ∫èÔºåËØçÈ¢ëÊúÄÈ´òÁöÑÂçïËØçÊéíÂú®ÂâçÈù¢„ÄÇ Á¥¢Âºï‰ªé1ÂºÄÂßãÔºå0ÁïôÁªô‚ÄúÊú™Áü•‚Äù„ÄÇ ËØçÂÖ∏ËßÑÊ®°ÔºàvocabularyÔºâÂèØËßÜÈúÄÊ±ÇÊà™Êñ≠Ôºà‰æãÂ¶ÇÂè™‰øùÁïôTop 10kÔºâ„ÄÇ ‰∏∫‰ªÄ‰πàÁßªÈô§‰ΩéÈ¢ëËØç ‰ΩéÈ¢ëËØçÂèØËÉΩÊòØÊãºÂÜôÈîôËØØ„ÄÅÁΩïËßÅ‰∫∫ÂêçÁ≠âÔºåÂØπÊ®°ÂûãÂ∏ÆÂä©ÊúâÈôê„ÄÇ ÂáèÂ∞ëËØçÂÖ∏ËßÑÊ®°ÂèØÈôç‰ΩéËøêÁÆóÂºÄÈîÄ„ÄÅÂä†Âø´Ê®°ÂûãËÆ≠ÁªÉ‰∏éÊé®ÁêÜÈÄüÂ∫¶„ÄÇ Áã¨ÁÉ≠ÁºñÁ†Å (One-Hot Encoding)\nÂ∞ÜÊØè‰∏™ÂçïËØçÊò†Â∞Ñ‰∏∫ËØçÂÖ∏‰∏≠ÁöÑÁ¥¢ÂºïÂêéÔºàÂ¶Ç [2, 4, 1, 8, ‚Ä¶]ÔºâÔºåÂèØËøõ‰∏ÄÊ≠•ËΩ¨Êç¢ÊàêOne-HotÂêëÈáè„ÄÇ One-HotÁª¥Â∫¶ÂèñÂÜ≥‰∫é‰øùÁïô‰∏ãÊù•ÁöÑËØçÂÖ∏Â§ßÂ∞èÔºà‰æãÂ¶Ç1‰∏áÔºâ„ÄÇ Êú™Êî∂ÂΩïÂçïËØçÂèØËÉΩÁõ¥Êé•ÂøΩÁï•ÔºåÊàñÁªü‰∏ÄÁî®Á¥¢Âºï0‰ª£Êõø„ÄÇ Âõõ„ÄÅÊ†∏ÂøÉÊî∂Ëé∑‰∏éÂ∫îÁî® Á±ªÂà´ÁâπÂæÅÂøÖÈúÄÊï∞ÂÄºÂåñÔºö\n‰ΩøÁî®Êï¥Êï∞1,2,3‚Ä¶‰ªÖË°®Á§∫Á±ªÂà´‚ÄúÊ†áËØÜ‚ÄùÔºåÂπ∂‰∏ç‰ª£Ë°®ÂÆÉ‰ª¨ÂèØËøõË°åÊï∞ÂÄºËøêÁÆó„ÄÇ Âõ†Ê≠§ÈúÄË¶ÅOne-HotÁ≠âÁºñÁ†ÅÊñπÂºèÔºåÈÅøÂÖçÊï∞ÂÄºËØØËß£„ÄÇ ÊñáÊú¨Êï∞ÊçÆÈ¢ÑÂ§ÑÁêÜÔºö\nÂàÜËØç„ÄÅËØçÈ¢ëÁªüËÆ°„ÄÅÊûÑÂª∫ËØçÂÖ∏„ÄÅÁ¥¢ÂºïÂåñ„ÄÅOne-HotÊàñÂÖ∂‰ªñÊñπÂºèÔºàÂ¶ÇËØçÂµåÂÖ•ÔºâÊòØÂ∏∏ËßÅÊµÅÁ®ã„ÄÇ Ê≠£Á°ÆÁöÑÊñáÊú¨È¢ÑÂ§ÑÁêÜÂèØÊòæËëóÂΩ±ÂìçÊ®°ÂûãÊÄßËÉΩÂíåÊïàÁéá„ÄÇ ‰øùÁïôÊú™Áü•Á¥¢ÂºïÔºö\n‰øùËØÅÂØπÁº∫Â§±Êï∞ÊçÆÊàñÂ≠óÂÖ∏Â§ñÊñ∞ËØçËÉΩÊúâÂü∫Êú¨ÁöÑË°®Á§∫ÔºåÊèêÂçáÊ®°ÂûãÂÆπÈîôÊÄß„ÄÇ ÂÆûÈôÖ‰ΩøÁî®Ôºö\nÂØπ‰∫éÂ∞èËßÑÊ®°Á±ªÂà´ÂèØÁõ¥Êé•One-HotÁºñÁ†ÅÔºõÂØπ‰∫éËØçÂÖ∏ÂæàÂ§ßÁöÑÂú∫ÊôØÔºåÈÄöÂ∏∏‰ºöËøõ‰∏ÄÊ≠•ËÄÉËôëËØçÂµåÂÖ•ÔºàWord EmbeddingÔºâÊàñÈ¢ÑËÆ≠ÁªÉËØ≠Ë®ÄÊ®°Âûã„ÄÇ ","permalink":"http://localhost:1313/posts/nlp-1/","summary":"\u003ch2 id=\"‰∏ÄÊï∞ÂÄºÁâπÂæÅ‰∏éÁ±ªÂà´ÁâπÂæÅ\"\u003e‰∏Ä„ÄÅÊï∞ÂÄºÁâπÂæÅ‰∏éÁ±ªÂà´ÁâπÂæÅ\u003c/h2\u003e\n\u003col\u003e\n\u003cli\u003e\u003cstrong\u003eÊï∞ÂÄºÁâπÂæÅ (Numeric Features)\u003c/strong\u003e\n\u003cul\u003e\n\u003cli\u003eÂÖ∑ÊúâÂèØÂä†ÂáèÁöÑÊÑè‰πâÔºå‰∏îÂ≠òÂú®Â§ßÂ∞èÈ°∫Â∫è„ÄÇ\u003c/li\u003e\n\u003cli\u003e‰æãÂ≠êÔºöÂπ¥ÈæÑ„ÄÅÊ∏©Â∫¶Á≠â„ÄÇÂèØ‰ª•Áõ¥Êé•‰øùÁïôÂÖ∂Êï¥Êï∞ÊàñÊµÆÁÇπÊï∞ÂΩ¢Âºè‰æõÊ®°Âûã‰ΩøÁî®„ÄÇ\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003eÁ±ªÂà´ÁâπÂæÅ (Categorical Features)\u003c/strong\u003e\n\u003cul\u003e\n\u003cli\u003eÊï∞ÊçÆÂÄºÁ¶ªÊï£Ôºå‰∏çÂÖ∑Â§á‚ÄúÊï∞ÂÄºÂ§ßÂ∞è‚ÄùÈó¥ÁöÑÂèØÊØîÊÑè‰πâ„ÄÇ\u003c/li\u003e\n\u003cli\u003e‰æãÂ≠êÔºöÂõΩÁ±çÔºàÁæéÂõΩ/‰∏≠ÂõΩ/Âç∞Â∫¶Á≠âÔºâ„ÄÅÊÄßÂà´ÔºàÁî∑/Â•≥ÔºâÁ≠â„ÄÇ\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003eÈóÆÈ¢ò\u003c/strong\u003eÔºöËã•‰ªÖÁî®Êï¥Êï∞Ë°®Á§∫ÔºàÁæéÂõΩ=1, ‰∏≠ÂõΩ=2ÔºâÔºå‰ºöÂºïÂÖ•ÈîôËØØÁöÑÊï∞ÂÄºËøêÁÆóÂÖ≥Á≥ªÔºåÂ¶Ç ‚ÄúÁæéÂõΩ + ‰∏≠ÂõΩ = Âç∞Â∫¶‚Äù„ÄÇ\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003c/ol\u003e\n\u003ch2 id=\"‰∫åone-hotÁºñÁ†ÅÁöÑÂä®Êú∫‰∏éÊµÅÁ®ã\"\u003e‰∫å„ÄÅOne-HotÁºñÁ†ÅÁöÑÂä®Êú∫‰∏éÊµÅÁ®ã\u003c/h2\u003e\n\u003col\u003e\n\u003cli\u003e\n\u003cp\u003e\u003cstrong\u003e‰∏∫‰ªÄ‰πà‰ΩøÁî®One-Hot\u003c/strong\u003e\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eÈÄöËøáÂ∞ÜÁ±ªÂà´Êò†Â∞Ñ‰∏∫ÂêëÈáèÔºåÈÅøÂÖçÊï¥Êï∞ÁºñÁ†ÅÂºïÂÖ•ÁöÑ‰º™Êï∞ÂÄºÂÖ≥Á≥ª„ÄÇ\u003c/li\u003e\n\u003cli\u003eÂêåÊó∂‰øùÁïôÂêÑÁßçÂèØËÉΩÁ±ªÂà´ÁöÑ‰ø°ÊÅØÔºå‰∏î‰ªÖÂú®ÂØπÂ∫î‰ΩçÁΩÆ‰∏∫1ÔºåÂÖ∂‰ªñ‰ΩçÁΩÆ‰∏∫0„ÄÇ\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003e\u003cstrong\u003eÂª∫Á´ãÊò†Â∞ÑÔºö‰ªéÁ±ªÂà´Âà∞Á¥¢Âºï\u003c/strong\u003e\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e‰∏∫ÊØè‰∏™Á±ªÂà´ÂàÜÈÖç‰∏Ä‰∏™ÂîØ‰∏ÄÁ¥¢ÂºïÔºåÈÄöÂ∏∏‰ªé1ÂºÄÂßã„ÄÇ\u003c/li\u003e\n\u003cli\u003eÈ¢ÑÁïôÁ¥¢Âºï0Ë°®Á§∫‚ÄúÊú™Áü•‚ÄùÊàñ‚ÄúÁº∫Â§±‚ÄùÔºåÂØπÂ∫îÂÖ®0ÂêëÈáè„ÄÇ\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003e\u003cstrong\u003eËΩ¨Êç¢‰∏∫One-HotÂêëÈáè\u003c/strong\u003e\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eËã•Á±ªÂà´ÊÄªÊï∞‰∏∫197ÔºåÂàôÁî®197Áª¥ÂêëÈáèË°®Á§∫„ÄÇ\u003c/li\u003e\n\u003cli\u003e‰æãÂ≠êÔºöÁæéÂõΩ \u003ccode\u003e[1, 0, 0, 0, ‚Ä¶]\u003c/code\u003eÔºå ‰∏≠ÂõΩ \u003ccode\u003e[0, 1, 0, 0, ‚Ä¶]\u003c/code\u003e„ÄÇ\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003e\u003cstrong\u003eÁ§∫‰æãÔºöË°®Á§∫‰∏Ä‰∏™‰∫∫ÁöÑÁâπÂæÅ\u003c/strong\u003e\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eÁâπÂæÅÂåÖÂê´ÔºàÂπ¥ÈæÑ, ÊÄßÂà´, ÂõΩÁ±çÔºåÂÖ∂‰∏≠ÂõΩÁ±ç197ÁßçÔºâ\u003c/li\u003e\n\u003cli\u003eÁª¥Â∫¶ÊÄªÂíåÔºö1Áª¥_age + 1Áª¥_gender + 197Áª¥_nationality = 199Áª¥„ÄÇ\u003c/li\u003e\n\u003cli\u003e‰æãÂ¶Ç \u003ccode\u003e(28, Â•≥, ‰∏≠ÂõΩ)\u003c/code\u003e ‚Üí \u003ccode\u003e[28, 0, 0, 1, 0, ‚Ä¶, 0]\u003c/code\u003e„ÄÇ\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003c/ol\u003e\n\u003ch2 id=\"‰∏âÊñáÊú¨Êï∞ÊçÆÂ§ÑÁêÜÊµÅÁ®ã\"\u003e‰∏â„ÄÅÊñáÊú¨Êï∞ÊçÆÂ§ÑÁêÜÊµÅÁ®ã\u003c/h2\u003e\n\u003cp\u003eÊñáÊú¨Âú®Ëá™ÁÑ∂ËØ≠Ë®ÄÂ§ÑÁêÜÔºàNLPÔºâ‰∏≠‰Ωú‰∏∫Â∏∏ËßÅÁöÑÂéüÂßãËæìÂÖ•ÔºåÈúÄË¶ÅÊï∞ÂÄºÂåñÊâçËÉΩÈÄÅÂÖ•Ê®°Âûã„ÄÇ‰∏ÄËà¨Ê≠•È™§Â¶Ç‰∏ãÔºö\u003c/p\u003e\n\u003col\u003e\n\u003cli\u003e\n\u003cp\u003e\u003cstrong\u003eÂàÜËØç (Tokenization)\u003c/strong\u003e\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eÂ∞ÜÊñáÊú¨ÊãÜÂàÜ‰∏∫‰∏Ä‰∏™‰∏™ÂçïËØçÔºàTokenÔºâ„ÄÇ\u003c/li\u003e\n\u003cli\u003e‰æãÂ≠êÔºö\u003ccode\u003e\u0026quot;... to be or not to be...\u0026quot;\u003c/code\u003e ‚Üí \u003ccode\u003e[\u0026quot;...\u0026quot;, \u0026quot;to\u0026quot;, \u0026quot;be\u0026quot;, \u0026quot;or\u0026quot;, \u0026quot;not\u0026quot;, \u0026quot;to\u0026quot;, \u0026quot;be\u0026quot;, \u0026quot;...\u0026quot;]\u003c/code\u003e„ÄÇ\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003e\u003cstrong\u003eÁªüËÆ°ËØçÈ¢ë \u0026amp; ÊûÑÂª∫ËØçÂÖ∏\u003c/strong\u003e\u003c/p\u003e","title":""},{"content":"Text to Sequence ÊñáÊú¨Â§ÑÁêÜ\nStep1: Tokenization\nTokenization breaks a piece of text down into a list of tokens.\nHere, a token is a word. (A token can be a character in some applications.)\nTokenizationËÆ≤Á©∂ÂæàÂ§öÔºå‰æãÂ¶ÇÊòØÂê¶Â∫îËØ•ÊääÂ§ßÂÜôÊîπÊàêÂ∞èÂÜôÂë¢ÔºüËøõË°åtypo correctionÁ≠âÁ≠â\nStep2: Build Dictionary\nUse a dictionary (hash table) to count word frequencies.\nThe dictionary maps word to index.\nÂèØ‰ª•È¶ñÂÖàÁªüËÆ°ËØçÈ¢ëÂéªÊéâ‰ΩéÈ¢ëËØçÔºåÁÑ∂ÂêéËÆ©ÊØè‰∏™ËØçÂØπÂ∫î‰∏Ä‰∏™Ê≠£Êï¥Êï∞ÔºõËøôÊ†∑ÁöÑËØùÔºå‰∏ÄÂè•ËØùÂ∞±ÂèØ‰ª•Áî®‰∏Ä‰∏™Ê≠£Êï¥Êï∞ÂàóË°®Ë°®Á§∫ÔºåËøô‰∏™ÂàóË°®Â∞±Âè´sequenceÔºõÂ¶ÇÊûúÂøÖË¶ÅÂ∞±ËøòÂæóÂÅöone-hot encoding„ÄÇ\nÁªìÊûú\n‰ΩÜÊòØÈïøÂ∫¶‰∏çÁªü‰∏Ä\nStep4: ÂØπÈΩêsequence\nËß£ÂÜ≥ÊñπÊ°àÊòØËøôÊ†∑ÁöÑÔºöÂèØ‰ª•Âõ∫ÂÆöÈïøÂ∫¶‰∏∫wÔºåÂä†ÂÖ•‰∏Ä‰∏™Â∫èÂàóÈïøÂ∫¶Â§™ÈïøÔºåÂ∞±Á†çÊéâÂâçÈù¢ÁöÑËØçÔºåÂè™‰øùÁïôÊúÄÂêéw‰∏™ËØçÔºõÂ¶ÇÊûú‰∏Ä‰∏™Â∫èÂàóÂ§™Áü≠ÔºåÂ∞±ÂÅözero paddingÔºåÁî®0Â°´ÂÖÖ\nËøôÊ†∑‰∏ÄÊù•ÔºåÊâÄÊúâÁöÑÂ∫èÂàóÈïøÂ∫¶Â∞±Áªü‰∏Ä‰∫Ü\nÊñáÊú¨Â§ÑÁêÜÂÆåÊàê‰∫ÜÔºåÊé•‰∏ãÊù•ÊòØword embeddingÔºåÊääÂçïËØçË°®Á§∫‰∏∫‰∏Ä‰∏™‰ΩéÁª¥ÂêëÈáèÔºõ\nÁÑ∂ËÄåËøôÊ†∑ÂÅöÁöÑËØùÔºåÂ¶ÇÊûúÊòØ10000‰∏™ÂçïËØçÔºåÁª¥Â∫¶Â∞±ÊòØ10000Áª¥ÔºåÁª¥Â∫¶Â§™È´ò‰∫ÜÔºõÂõ†Ê≠§Ë¶ÅÂÅöword embeddingÔºõ\nÂÖ∑‰ΩìÂÅöÊ≥ïÂ∞±ÊòØÊääone-hotÂêëÈáèe_iÂíåÂèÇÊï∞Áü©ÈòµpÁõ∏‰πòÔºõÁü©ÈòµPËΩ¨ÁΩÆÁöÑÂ§ßÂ∞èÊòØd x vÔºõdÊòØËØçÂêëÈáèÁöÑÁª¥Â∫¶ÔºõvÊòØÂ≠óÂÖ∏ÈáåËØçÊ±áÁöÑÊï∞ÈáèÔºõÁªìÊûú‰∏∫x_iÔºõx_iÂ∞±ÊòØ‰∏Ä‰∏™ËØçÂêëÈáèÔºõÂ¶ÇÊûúone-hotÂêëÈáèÁöÑÁ¨¨‰∏âË°å‰∏∫1ÔºõÈÇ£‰πàx_iÂ∞±ÊòØPËΩ¨ÁΩÆÁü©ÈòµÁöÑÁ¨¨‰∏âÂàóÔºàÂÖ∂‰ΩôÂàóÈÉΩ‰∏∫0ÔºâÔºõÊâÄ‰ª•PËΩ¨ÁΩÆÊØè‰∏ÄÂàóÈÉΩÊòØ‰∏Ä‰∏™ËØçÂêëÈáèÔºõÊâÄ‰ª•Áü©ÈòµPÊú¨Ë∫´ÁöÑÊØè‰∏ÄË°åÂ∞±ÊòØ‰∏Ä‰∏™ËØçÂêëÈáèÔºõÂÖ∂Ë°åÊï∞‰∏∫vÔºõÂç≥vocabularyÔºåËØçÊ±áÈáèÔºõÊØè‰∏ÄË°åÂØπÂ∫î‰∏Ä‰∏™ÂçïËØçÔºõÁü©ÈòµÁöÑÂàóÊï∞‰∏∫dÔºõdÊòØÁî®Êà∑ÂÜ≥ÂÆöÁöÑÔºõdÁöÑÂ§ßÂ∞è‰ºöÂÜ≥ÂÆöÊú∫Âô®Â≠¶‰π†Ê®°ÂûãÁöÑË°®Áé∞ÔºõÂ∫îËØ•Áî®xxxÊù•ÈÄâÊã©‰∏Ä‰∏™ÊØîËæÉÂ•ΩÁöÑdÔºõ\nÊàë‰ª¨ÁöÑ‰ªªÂä°ÊòØÁúãËØÑËÆ∫ÊòØÊ≠£Èù¢ÁöÑËøòÊòØË¥üÈù¢ÁöÑÔºõÂèÇÊï∞Áü©ÈòµÊòØ‰ªéËÆ≠ÁªÉÊï∞ÊçÆ‰∏≠Â≠¶‰π†Âá∫Êù•ÁöÑÔºåÊâÄ‰ª•Â≠¶Âá∫Êù•ÁöÑËØçÂêëÈáèÊòØÂ∏¶ÊúâÊÑüÊÉÖËâ≤ÂΩ©ÁöÑÔºõÂÅáËÆæËøô‰∫õËØçÂêëÈáèÈÉΩÊòØ‰∫åÁª¥ÁöÑÔºåÂàôÂèØ‰ª•Âú®Âπ≥Èù¢ÂùêÊ†áÁ≥ª‰∏≠Ê†áÂá∫‰∏ãÈù¢ËØçÂêëÈáè\nkerasÊèê‰æõembeddingÂ±ÇÔºõÁî®Êà∑ÂèØ‰ª•ÊåáÂÆövocabularyÂ§ßÂ∞èÂíådÁöÑÂ§ßÂ∞èÔºõ‰ª•ÂèäÊØè‰∏Ä‰∏™sequenceÁöÑÈïøÂ∫¶ÔºõdÊòØÊ†πÊçÆÁÆóÊ≥ïÈÄâÂá∫Êù•ÁöÑ Âà∞Ëøô‰∏ÄÊ≠•ÔºåÊàë‰ª¨Â∑≤ÁªèÂÆåÊàê‰∫ÜÊñáÊú¨Â§ÑÁêÜÂíåword embedding„ÄÇÊé•‰∏ãÊù•Â∞±ÊòØÁî®Logistic Regression for Binary ClassificationÂÅö‰∫åÂàÜÁ±ªÔºõ\n","permalink":"http://localhost:1313/posts/nlp-2/","summary":"\u003ch3 id=\"text-to-sequence\"\u003eText to Sequence\u003c/h3\u003e\n\u003cp\u003eÊñáÊú¨Â§ÑÁêÜ\u003c/p\u003e\n\u003cp\u003eStep1: Tokenization\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\n\u003cp\u003eTokenization breaks a piece of text down into a list of tokens.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003eHere, a token is a word. (A token can be a character in some applications.)\u003c/p\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003eTokenizationËÆ≤Á©∂ÂæàÂ§öÔºå‰æãÂ¶ÇÊòØÂê¶Â∫îËØ•ÊääÂ§ßÂÜôÊîπÊàêÂ∞èÂÜôÂë¢ÔºüËøõË°åtypo correctionÁ≠âÁ≠â\u003c/p\u003e\n\u003cp\u003e\u003cimg alt=\"image-20250322150322238\" loading=\"lazy\" src=\"./NLP-2.assets/image-20250322150322238.png\"\u003e\u003c/p\u003e\n\u003cp\u003eStep2: Build Dictionary\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\n\u003cp\u003eUse a dictionary (hash table) to count word frequencies.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003eThe dictionary maps word to index.\u003c/p\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003eÂèØ‰ª•È¶ñÂÖàÁªüËÆ°ËØçÈ¢ëÂéªÊéâ‰ΩéÈ¢ëËØçÔºåÁÑ∂ÂêéËÆ©ÊØè‰∏™ËØçÂØπÂ∫î‰∏Ä‰∏™Ê≠£Êï¥Êï∞ÔºõËøôÊ†∑ÁöÑËØùÔºå‰∏ÄÂè•ËØùÂ∞±ÂèØ‰ª•Áî®‰∏Ä‰∏™Ê≠£Êï¥Êï∞ÂàóË°®Ë°®Á§∫ÔºåËøô‰∏™ÂàóË°®Â∞±Âè´sequenceÔºõÂ¶ÇÊûúÂøÖË¶ÅÂ∞±ËøòÂæóÂÅöone-hot encoding„ÄÇ\u003cimg alt=\"image-20250322150620890\" loading=\"lazy\" src=\"./NLP-2.assets/image-20250322150620890.png\"\u003e\u003c/p\u003e\n\u003cp\u003eÁªìÊûú\u003c/p\u003e\n\u003cp\u003e\u003cimg alt=\"image-20250322150754528\" loading=\"lazy\" src=\"./NLP-2.assets/image-20250322150754528.png\"\u003e\u003c/p\u003e\n\u003cp\u003e‰ΩÜÊòØÈïøÂ∫¶‰∏çÁªü‰∏Ä\u003c/p\u003e\n\u003cp\u003eStep4: ÂØπÈΩêsequence\u003c/p\u003e\n\u003cp\u003e\u003cimg alt=\"image-20250322150854986\" loading=\"lazy\" src=\"./NLP-2.assets/image-20250322150854986.png\"\u003e\u003c/p\u003e\n\u003cp\u003eËß£ÂÜ≥ÊñπÊ°àÊòØËøôÊ†∑ÁöÑÔºöÂèØ‰ª•Âõ∫ÂÆöÈïøÂ∫¶‰∏∫wÔºåÂä†ÂÖ•‰∏Ä‰∏™Â∫èÂàóÈïøÂ∫¶Â§™ÈïøÔºåÂ∞±Á†çÊéâÂâçÈù¢ÁöÑËØçÔºåÂè™‰øùÁïôÊúÄÂêéw‰∏™ËØçÔºõÂ¶ÇÊûú‰∏Ä‰∏™Â∫èÂàóÂ§™Áü≠ÔºåÂ∞±ÂÅözero paddingÔºåÁî®0Â°´ÂÖÖ\u003c/p\u003e\n\u003cp\u003e\u003cimg alt=\"image-20250322151030119\" loading=\"lazy\" src=\"./NLP-2.assets/image-20250322151030119.png\"\u003e\u003c/p\u003e\n\u003cp\u003eËøôÊ†∑‰∏ÄÊù•ÔºåÊâÄÊúâÁöÑÂ∫èÂàóÈïøÂ∫¶Â∞±Áªü‰∏Ä‰∫Ü\u003c/p\u003e\n\u003cp\u003e\u003cimg alt=\"image-20250322151117125\" loading=\"lazy\" src=\"./NLP-2.assets/image-20250322151117125.png\"\u003e\u003c/p\u003e\n\u003cp\u003eÊñáÊú¨Â§ÑÁêÜÂÆåÊàê‰∫ÜÔºåÊé•‰∏ãÊù•ÊòØword embeddingÔºåÊääÂçïËØçË°®Á§∫‰∏∫‰∏Ä‰∏™‰ΩéÁª¥ÂêëÈáèÔºõ\u003c/p\u003e\n\u003cp\u003e\u003cimg alt=\"image-20250322151252837\" loading=\"lazy\" src=\"./NLP-2.assets/image-20250322151252837.png\"\u003e\u003c/p\u003e","title":""},{"content":"üëã About me Hello! I\u0026rsquo;m Xu Zongsi, a passionate technology enthusiast currently pursuing my Master of Science in ECIC at The University of Hong Kong. With a solid background in Software Engineering from the Beijing Institute of Technology, I specialize in artificial intelligence areas like machine learning, deep learning, natural language processing, computer vision, and reinforcement learning.\nInspired by OpenAI‚Äôs five-step plan towards superintelligence, I am excited about AGI and have developed a keen interest in LLM agents, MLLM, and knowledge graphs. I see great potential in these fields and aspire to contribute to innovative solutions.\nüìö Education üá≠üá∞ The University of Hong Kong 09/2024 - Expected 11/2025 School of Computing and Data Science Master of Science in Electronic Commerce \u0026amp; Internet Computing Relevant Courses: Machine learning for business and e-commerce, Knowledge graphs, Financial fraud analytics, Internet infrastructure technologies, Website engineering, Blockchain and cryptocurrency, etc. üá®üá≥ Beijing Institute of Technology 09/2020 - 06/2024 School of Computer Science \u0026amp; Technology Bachelor of Engineering in Software Engineering, last two years GPA: 3.7/4 Relevant Courses: Reinforcement Learning, Deep Learning and Computer Vision, Artificial Intelligence and Robot Ethics, Almost Human: Mind, Brain and Artificial Intelligence, Mathematical Analysis for Engineering, Linear Algebra, Probability and Mathematical Statistics, etc. Skills: Python, Java, common data structures, design patterns, machine learning basics and algorithms, Linux, PyTorch, and some development tools (git, conda, etc.). üèÜ Awards \u0026amp; Honors Beijing Institute of Technology Undergraduate Scholarship (Top 20% of Grade) 06/2023 3rd Prize of China International \u0026#34;Internet \u0026#43;\u0026#34; College Student\u0026#39;s Innovation Competition 08/2022 Bronze Prize of \u0026#34;Challenge Cup\u0026#34; Capital University Entrepreneurship Competition 05/2022 üíº Project Experience üîç Online Transaction Fraud Detection 09/2024 ‚Äì 01/2025 Independent project, supervised by Dr. Vivien Chan Focused on addressing financial fraud in e-commerce to enhance the accuracy of transaction anomaly detection, while independently managing the entire case study that included data preprocessing, feature engineering, model building, evaluation, and results analysis. Effectively resolved class imbalance issues using SMOTE and ROSE techniques. Built various models including Logistic Regression, Random Forest, XGBoost, and LightGBM, ultimately selecting the LightGBM model to achieve a recall rate of 95.45% and an AUC of 99.84%. Wrote efficient and maintainable code, enhancing model training and data processing efficiency through parallel computing and logging. ü§ñ Multi-Model Intelligent Text Keyword Extraction System 08/2023 ‚Äì 09/2023 Group project, supervised by Associate Prof. Xiaolin Zhao Designed and implemented an intelligent text summary system that automatically extracts keywords from article titles and abstracts, enhancing the understanding and summarization of text information. Participated in the planning of the technical route and built a hybrid model combining extractive and generative approaches, utilizing advanced natural language processing techniques including KeyBERT, Sentence Transformer, BERT, and T5 models. Responsible for data preprocessing and tokenization, as well as the end-to-end implementation and training of the T5 model, optimizing the model architecture and hyperparameters, achieving satisfactory results after only 3 epochs of training. Model evaluation results showed that the Rouge-1, Rouge-2, and Rouge-L metrics reached 0.6345, 0.5038, and 0.5282, respectively, in the third epoch, validating the model\u0026rsquo;s effectiveness in the summarization task. üéì Cambridge University Machine Learning Summer Project 07/2023 ‚Äì 08/2023 Group project, supervised by Prof. Pietro Li√≤ Participated in the Cambridge University deep learning summer project, focusing on deep reinforcement learning; explored multi-agent learning algorithms across different environments. Reproduced the Multi-Agent Deep Deterministic Policy Gradient (MADDPG) algorithm in the Simple Adversary environment and studied the effect of agent numbers on convergence speed and stability, finding optimal stability at 21 agents. Designed and implemented comparative experiments inspired by the Rainbow algorithm, assessing target network strategies versus the Double Deep Q-Network (Double DQN). The results demonstrated that Double DQN significantly enhanced convergence speed, optimizing the overall learning process. Co-authored a group project paper on agent numbers and strategies effectiveness in multi-agent systems, achieving a score of 71% in the summer program (the highest in my group) and a \u0026ldquo;First Class\u0026rdquo; classification in the UK grading system. üëÅÔ∏è Deep Learning and Computer Vision Semester Project 09/2022 ‚Äì 12/2022 Independent project, supervised by Associate Prof. Guangyu Gao Designed and implemented a waste classifier using the ResNet model to improve classification accuracy and reduce resource waste. The project also enhanced understanding of transfer learning techniques with ResNet. Collected a dataset of 16 waste categories and preprocessed the images for uniformity and standardization, incorporating data augmentation techniques to enhance the dataset. Conducted experiments using ResNet34 and ResNet50 models through transfer learning, accelerating network convergence by leveraging pretrained weights. During training, techniques such as Batch Normalization and Dropout were applied to mitigate the risk of overfitting. The final model achieved an accuracy of 90% on the training set, while the performance on the test set was 61%, indicating a significant overfitting phenomenon during the training process. üéì Internship ‚öõÔ∏è Beijing Academy of Quantum Information Science 08/2023 ‚Äì 01/2024 Research Intern at Quantum Computation Department Proposed a quantum convolution kernel design based on variational quantum circuits and developed a universal quantum convolution layer, successfully integrating it into classical CNN architectures such as VGG, GoogLeNet, and ResNet. Developed and evaluated various hybrid models, including a simple model named HQCCNN-2, which achieved 84.45% accuracy on the FashionMNIST dataset, surpassing the traditional CNN\u0026rsquo;s 80.72%. This demonstrates the effectiveness of the quantum convolution layer in improving model performance. Tested on a real quantum computer further validated the effectiveness of the hybrid model, demonstrating the viable integration of quantum computing with deep learning, and highlighting the potential for leveraging quantum properties to enhance model performance. üèÖ Competition Experience ü•â China International \u0026#34;Internet \u0026#43;\u0026#34; College Students\u0026#39; Innovation Competition 08/2022 üõ°Ô∏è Zhongke Ushield: Deep Learning-based Face Privacy Protection Authentication System Responsible for constructing a localized facial feature extraction engine based on MobileFaceNet, ensuring feature extraction is completed on end devices (such as mobile phones and cameras), guaranteeing that raw data does not leave the domain and is not stored, thus enhancing user privacy protection while improving recognition efficiency. ü•â \u0026#34;Challenge Cup\u0026#34; Capital University Entrepreneurship Competition 05/2022 üå≥ Smart Orchard Responsible for the development of the fruit detection, ripeness prediction, and pest identification system, using deep convolutional neural network (CNN) technology for intelligent monitoring of crop growth conditions. Applied advanced object detection algorithms such as Faster R-CNN and YOLO to achieve high precision in apple detection and ripeness assessment, with an accuracy rate exceeding 90%, significantly enhancing the intelligence level of orchard management. Built and trained a dedicated dataset containing various pest samples, optimizing pest detection accuracy through data preprocessing (such as image normalization and resizing) and data augmentation techniques (like rotation, flipping, and noise addition), enabling the real-time monitoring system to accurately identify over 80% of pests, providing effective scientific maintenance recommendations to help farmers reduce crop losses. üìã Extracurricular Activities Vice President, Cyber Security Club, Beijing Institute of Technology 09/2021-09/2022 Backbone, Media Center of the Student Union of Beijing Institute of Technology 10/2020-06/2021 üì´ Contact üìß zongsi.xu@outlook.com üëî Zongsi (Tristan) Xu üíª github.com/BaizeXS üìç Hong Kong SAR, China ","permalink":"http://localhost:1313/resume/","summary":"Personal resume of Zongsi (Tristan) Xu","title":"Zongsi (Tristan) Xu"},{"content":"‰∏Ä„ÄÅÊï∞ÂÄºÁâπÂæÅ‰∏éÁ±ªÂà´ÁâπÂæÅ Êï∞ÂÄºÁâπÂæÅ (Numeric Features) ÂÖ∑ÊúâÂèØÂä†ÂáèÁöÑÊÑè‰πâÔºå‰∏îÂ≠òÂú®Â§ßÂ∞èÈ°∫Â∫è„ÄÇ ‰æãÂ≠êÔºöÂπ¥ÈæÑ„ÄÅÊ∏©Â∫¶Á≠â„ÄÇÂèØ‰ª•Áõ¥Êé•‰øùÁïôÂÖ∂Êï¥Êï∞ÊàñÊµÆÁÇπÊï∞ÂΩ¢Âºè‰æõÊ®°Âûã‰ΩøÁî®„ÄÇ Á±ªÂà´ÁâπÂæÅ (Categorical Features) Êï∞ÊçÆÂÄºÁ¶ªÊï£Ôºå‰∏çÂÖ∑Â§á‚ÄúÊï∞ÂÄºÂ§ßÂ∞è‚ÄùÈó¥ÁöÑÂèØÊØîÊÑè‰πâ„ÄÇ ‰æãÂ≠êÔºöÂõΩÁ±çÔºàÁæéÂõΩ/‰∏≠ÂõΩ/Âç∞Â∫¶Á≠âÔºâ„ÄÅÊÄßÂà´ÔºàÁî∑/Â•≥ÔºâÁ≠â„ÄÇ ÈóÆÈ¢òÔºöËã•‰ªÖÁî®Êï¥Êï∞Ë°®Á§∫ÔºàÁæéÂõΩ=1, ‰∏≠ÂõΩ=2ÔºâÔºå‰ºöÂºïÂÖ•ÈîôËØØÁöÑÊï∞ÂÄºËøêÁÆóÂÖ≥Á≥ªÔºåÂ¶Ç ‚ÄúÁæéÂõΩ + ‰∏≠ÂõΩ = Âç∞Â∫¶‚Äù„ÄÇ ‰∫å„ÄÅOne-HotÁºñÁ†ÅÁöÑÂä®Êú∫‰∏éÊµÅÁ®ã ‰∏∫‰ªÄ‰πà‰ΩøÁî®One-Hot\nÈÄöËøáÂ∞ÜÁ±ªÂà´Êò†Â∞Ñ‰∏∫ÂêëÈáèÔºåÈÅøÂÖçÊï¥Êï∞ÁºñÁ†ÅÂºïÂÖ•ÁöÑ‰º™Êï∞ÂÄºÂÖ≥Á≥ª„ÄÇ ÂêåÊó∂‰øùÁïôÂêÑÁßçÂèØËÉΩÁ±ªÂà´ÁöÑ‰ø°ÊÅØÔºå‰∏î‰ªÖÂú®ÂØπÂ∫î‰ΩçÁΩÆ‰∏∫1ÔºåÂÖ∂‰ªñ‰ΩçÁΩÆ‰∏∫0„ÄÇ Âª∫Á´ãÊò†Â∞ÑÔºö‰ªéÁ±ªÂà´Âà∞Á¥¢Âºï\n‰∏∫ÊØè‰∏™Á±ªÂà´ÂàÜÈÖç‰∏Ä‰∏™ÂîØ‰∏ÄÁ¥¢ÂºïÔºåÈÄöÂ∏∏‰ªé1ÂºÄÂßã„ÄÇ È¢ÑÁïôÁ¥¢Âºï0Ë°®Á§∫‚ÄúÊú™Áü•‚ÄùÊàñ‚ÄúÁº∫Â§±‚ÄùÔºåÂØπÂ∫îÂÖ®0ÂêëÈáè„ÄÇ ËΩ¨Êç¢‰∏∫One-HotÂêëÈáè\nËã•Á±ªÂà´ÊÄªÊï∞‰∏∫197ÔºåÂàôÁî®197Áª¥ÂêëÈáèË°®Á§∫„ÄÇ ‰æãÂ≠êÔºöÁæéÂõΩ [1, 0, 0, 0, ‚Ä¶]Ôºå ‰∏≠ÂõΩ [0, 1, 0, 0, ‚Ä¶]„ÄÇ Á§∫‰æãÔºöË°®Á§∫‰∏Ä‰∏™‰∫∫ÁöÑÁâπÂæÅ\nÁâπÂæÅÂåÖÂê´ÔºàÂπ¥ÈæÑ, ÊÄßÂà´, ÂõΩÁ±çÔºåÂÖ∂‰∏≠ÂõΩÁ±ç197ÁßçÔºâ Áª¥Â∫¶ÊÄªÂíåÔºö1Áª¥_age + 1Áª¥_gender + 197Áª¥_nationality = 199Áª¥„ÄÇ ‰æãÂ¶Ç (28, Â•≥, ‰∏≠ÂõΩ) ‚Üí [28, 0, 0, 1, 0, ‚Ä¶, 0]„ÄÇ ‰∏â„ÄÅÊñáÊú¨Êï∞ÊçÆÂ§ÑÁêÜÊµÅÁ®ã ÊñáÊú¨Âú®Ëá™ÁÑ∂ËØ≠Ë®ÄÂ§ÑÁêÜÔºàNLPÔºâ‰∏≠‰Ωú‰∏∫Â∏∏ËßÅÁöÑÂéüÂßãËæìÂÖ•ÔºåÈúÄË¶ÅÊï∞ÂÄºÂåñÊâçËÉΩÈÄÅÂÖ•Ê®°Âûã„ÄÇ‰∏ÄËà¨Ê≠•È™§Â¶Ç‰∏ãÔºö\nÂàÜËØç (Tokenization)\nÂ∞ÜÊñáÊú¨ÊãÜÂàÜ‰∏∫‰∏Ä‰∏™‰∏™ÂçïËØçÔºàTokenÔºâ„ÄÇ ‰æãÂ≠êÔºö\u0026quot;... to be or not to be...\u0026quot; ‚Üí [\u0026quot;...\u0026quot;, \u0026quot;to\u0026quot;, \u0026quot;be\u0026quot;, \u0026quot;or\u0026quot;, \u0026quot;not\u0026quot;, \u0026quot;to\u0026quot;, \u0026quot;be\u0026quot;, \u0026quot;...\u0026quot;]„ÄÇ ÁªüËÆ°ËØçÈ¢ë \u0026amp; ÊûÑÂª∫ËØçÂÖ∏\nËØçÈ¢ëÁªüËÆ° Áî®ÂìàÂ∏åË°®/Â≠óÂÖ∏ËÆ∞ÂΩïÊØè‰∏™ÂçïËØçÂá∫Áé∞Ê¨°Êï∞„ÄÇ ÈÅçÂéÜÊñáÊú¨Êó∂ÔºåËã•ÂçïËØçÂ∞öÊú™ÂÖ•Ë°®ÔºåÂàôÊñ∞Âª∫ËÆ∞ÂΩïÔºõËã•Â∑≤Â≠òÂú®ÔºåÂàôËÆ°Êï∞+1„ÄÇ ÊéíÂ∫è‰∏éÁ¥¢Âºï ÊåâËØçÈ¢ëÈôçÂ∫èÊéíÂ∫èÔºåËØçÈ¢ëÊúÄÈ´òÁöÑÂçïËØçÊéíÂú®ÂâçÈù¢„ÄÇ Á¥¢Âºï‰ªé1ÂºÄÂßãÔºå0ÁïôÁªô‚ÄúÊú™Áü•‚Äù„ÄÇ ËØçÂÖ∏ËßÑÊ®°ÔºàvocabularyÔºâÂèØËßÜÈúÄÊ±ÇÊà™Êñ≠Ôºà‰æãÂ¶ÇÂè™‰øùÁïôTop 10kÔºâ„ÄÇ ‰∏∫‰ªÄ‰πàÁßªÈô§‰ΩéÈ¢ëËØç ‰ΩéÈ¢ëËØçÂèØËÉΩÊòØÊãºÂÜôÈîôËØØ„ÄÅÁΩïËßÅ‰∫∫ÂêçÁ≠âÔºåÂØπÊ®°ÂûãÂ∏ÆÂä©ÊúâÈôê„ÄÇ ÂáèÂ∞ëËØçÂÖ∏ËßÑÊ®°ÂèØÈôç‰ΩéËøêÁÆóÂºÄÈîÄ„ÄÅÂä†Âø´Ê®°ÂûãËÆ≠ÁªÉ‰∏éÊé®ÁêÜÈÄüÂ∫¶„ÄÇ Áã¨ÁÉ≠ÁºñÁ†Å (One-Hot Encoding)\nÂ∞ÜÊØè‰∏™ÂçïËØçÊò†Â∞Ñ‰∏∫ËØçÂÖ∏‰∏≠ÁöÑÁ¥¢ÂºïÂêéÔºàÂ¶Ç [2, 4, 1, 8, ‚Ä¶]ÔºâÔºåÂèØËøõ‰∏ÄÊ≠•ËΩ¨Êç¢ÊàêOne-HotÂêëÈáè„ÄÇ One-HotÁª¥Â∫¶ÂèñÂÜ≥‰∫é‰øùÁïô‰∏ãÊù•ÁöÑËØçÂÖ∏Â§ßÂ∞èÔºà‰æãÂ¶Ç1‰∏áÔºâ„ÄÇ Êú™Êî∂ÂΩïÂçïËØçÂèØËÉΩÁõ¥Êé•ÂøΩÁï•ÔºåÊàñÁªü‰∏ÄÁî®Á¥¢Âºï0‰ª£Êõø„ÄÇ Âõõ„ÄÅÊ†∏ÂøÉÊî∂Ëé∑‰∏éÂ∫îÁî® Á±ªÂà´ÁâπÂæÅÂøÖÈúÄÊï∞ÂÄºÂåñÔºö\n‰ΩøÁî®Êï¥Êï∞1,2,3‚Ä¶‰ªÖË°®Á§∫Á±ªÂà´‚ÄúÊ†áËØÜ‚ÄùÔºåÂπ∂‰∏ç‰ª£Ë°®ÂÆÉ‰ª¨ÂèØËøõË°åÊï∞ÂÄºËøêÁÆó„ÄÇ Âõ†Ê≠§ÈúÄË¶ÅOne-HotÁ≠âÁºñÁ†ÅÊñπÂºèÔºåÈÅøÂÖçÊï∞ÂÄºËØØËß£„ÄÇ ÊñáÊú¨Êï∞ÊçÆÈ¢ÑÂ§ÑÁêÜÔºö\nÂàÜËØç„ÄÅËØçÈ¢ëÁªüËÆ°„ÄÅÊûÑÂª∫ËØçÂÖ∏„ÄÅÁ¥¢ÂºïÂåñ„ÄÅOne-HotÊàñÂÖ∂‰ªñÊñπÂºèÔºàÂ¶ÇËØçÂµåÂÖ•ÔºâÊòØÂ∏∏ËßÅÊµÅÁ®ã„ÄÇ Ê≠£Á°ÆÁöÑÊñáÊú¨È¢ÑÂ§ÑÁêÜÂèØÊòæËëóÂΩ±ÂìçÊ®°ÂûãÊÄßËÉΩÂíåÊïàÁéá„ÄÇ ‰øùÁïôÊú™Áü•Á¥¢ÂºïÔºö\n‰øùËØÅÂØπÁº∫Â§±Êï∞ÊçÆÊàñÂ≠óÂÖ∏Â§ñÊñ∞ËØçËÉΩÊúâÂü∫Êú¨ÁöÑË°®Á§∫ÔºåÊèêÂçáÊ®°ÂûãÂÆπÈîôÊÄß„ÄÇ ÂÆûÈôÖ‰ΩøÁî®Ôºö\nÂØπ‰∫éÂ∞èËßÑÊ®°Á±ªÂà´ÂèØÁõ¥Êé•One-HotÁºñÁ†ÅÔºõÂØπ‰∫éËØçÂÖ∏ÂæàÂ§ßÁöÑÂú∫ÊôØÔºåÈÄöÂ∏∏‰ºöËøõ‰∏ÄÊ≠•ËÄÉËôëËØçÂµåÂÖ•ÔºàWord EmbeddingÔºâÊàñÈ¢ÑËÆ≠ÁªÉËØ≠Ë®ÄÊ®°Âûã„ÄÇ ","permalink":"http://localhost:1313/posts/nlp-1/","summary":"\u003ch2 id=\"‰∏ÄÊï∞ÂÄºÁâπÂæÅ‰∏éÁ±ªÂà´ÁâπÂæÅ\"\u003e‰∏Ä„ÄÅÊï∞ÂÄºÁâπÂæÅ‰∏éÁ±ªÂà´ÁâπÂæÅ\u003c/h2\u003e\n\u003col\u003e\n\u003cli\u003e\u003cstrong\u003eÊï∞ÂÄºÁâπÂæÅ (Numeric Features)\u003c/strong\u003e\n\u003cul\u003e\n\u003cli\u003eÂÖ∑ÊúâÂèØÂä†ÂáèÁöÑÊÑè‰πâÔºå‰∏îÂ≠òÂú®Â§ßÂ∞èÈ°∫Â∫è„ÄÇ\u003c/li\u003e\n\u003cli\u003e‰æãÂ≠êÔºöÂπ¥ÈæÑ„ÄÅÊ∏©Â∫¶Á≠â„ÄÇÂèØ‰ª•Áõ¥Êé•‰øùÁïôÂÖ∂Êï¥Êï∞ÊàñÊµÆÁÇπÊï∞ÂΩ¢Âºè‰æõÊ®°Âûã‰ΩøÁî®„ÄÇ\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003eÁ±ªÂà´ÁâπÂæÅ (Categorical Features)\u003c/strong\u003e\n\u003cul\u003e\n\u003cli\u003eÊï∞ÊçÆÂÄºÁ¶ªÊï£Ôºå‰∏çÂÖ∑Â§á‚ÄúÊï∞ÂÄºÂ§ßÂ∞è‚ÄùÈó¥ÁöÑÂèØÊØîÊÑè‰πâ„ÄÇ\u003c/li\u003e\n\u003cli\u003e‰æãÂ≠êÔºöÂõΩÁ±çÔºàÁæéÂõΩ/‰∏≠ÂõΩ/Âç∞Â∫¶Á≠âÔºâ„ÄÅÊÄßÂà´ÔºàÁî∑/Â•≥ÔºâÁ≠â„ÄÇ\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003eÈóÆÈ¢ò\u003c/strong\u003eÔºöËã•‰ªÖÁî®Êï¥Êï∞Ë°®Á§∫ÔºàÁæéÂõΩ=1, ‰∏≠ÂõΩ=2ÔºâÔºå‰ºöÂºïÂÖ•ÈîôËØØÁöÑÊï∞ÂÄºËøêÁÆóÂÖ≥Á≥ªÔºåÂ¶Ç ‚ÄúÁæéÂõΩ + ‰∏≠ÂõΩ = Âç∞Â∫¶‚Äù„ÄÇ\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003c/ol\u003e\n\u003ch2 id=\"‰∫åone-hotÁºñÁ†ÅÁöÑÂä®Êú∫‰∏éÊµÅÁ®ã\"\u003e‰∫å„ÄÅOne-HotÁºñÁ†ÅÁöÑÂä®Êú∫‰∏éÊµÅÁ®ã\u003c/h2\u003e\n\u003col\u003e\n\u003cli\u003e\n\u003cp\u003e\u003cstrong\u003e‰∏∫‰ªÄ‰πà‰ΩøÁî®One-Hot\u003c/strong\u003e\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eÈÄöËøáÂ∞ÜÁ±ªÂà´Êò†Â∞Ñ‰∏∫ÂêëÈáèÔºåÈÅøÂÖçÊï¥Êï∞ÁºñÁ†ÅÂºïÂÖ•ÁöÑ‰º™Êï∞ÂÄºÂÖ≥Á≥ª„ÄÇ\u003c/li\u003e\n\u003cli\u003eÂêåÊó∂‰øùÁïôÂêÑÁßçÂèØËÉΩÁ±ªÂà´ÁöÑ‰ø°ÊÅØÔºå‰∏î‰ªÖÂú®ÂØπÂ∫î‰ΩçÁΩÆ‰∏∫1ÔºåÂÖ∂‰ªñ‰ΩçÁΩÆ‰∏∫0„ÄÇ\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003e\u003cstrong\u003eÂª∫Á´ãÊò†Â∞ÑÔºö‰ªéÁ±ªÂà´Âà∞Á¥¢Âºï\u003c/strong\u003e\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e‰∏∫ÊØè‰∏™Á±ªÂà´ÂàÜÈÖç‰∏Ä‰∏™ÂîØ‰∏ÄÁ¥¢ÂºïÔºåÈÄöÂ∏∏‰ªé1ÂºÄÂßã„ÄÇ\u003c/li\u003e\n\u003cli\u003eÈ¢ÑÁïôÁ¥¢Âºï0Ë°®Á§∫‚ÄúÊú™Áü•‚ÄùÊàñ‚ÄúÁº∫Â§±‚ÄùÔºåÂØπÂ∫îÂÖ®0ÂêëÈáè„ÄÇ\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003e\u003cstrong\u003eËΩ¨Êç¢‰∏∫One-HotÂêëÈáè\u003c/strong\u003e\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eËã•Á±ªÂà´ÊÄªÊï∞‰∏∫197ÔºåÂàôÁî®197Áª¥ÂêëÈáèË°®Á§∫„ÄÇ\u003c/li\u003e\n\u003cli\u003e‰æãÂ≠êÔºöÁæéÂõΩ \u003ccode\u003e[1, 0, 0, 0, ‚Ä¶]\u003c/code\u003eÔºå ‰∏≠ÂõΩ \u003ccode\u003e[0, 1, 0, 0, ‚Ä¶]\u003c/code\u003e„ÄÇ\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003e\u003cstrong\u003eÁ§∫‰æãÔºöË°®Á§∫‰∏Ä‰∏™‰∫∫ÁöÑÁâπÂæÅ\u003c/strong\u003e\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eÁâπÂæÅÂåÖÂê´ÔºàÂπ¥ÈæÑ, ÊÄßÂà´, ÂõΩÁ±çÔºåÂÖ∂‰∏≠ÂõΩÁ±ç197ÁßçÔºâ\u003c/li\u003e\n\u003cli\u003eÁª¥Â∫¶ÊÄªÂíåÔºö1Áª¥_age + 1Áª¥_gender + 197Áª¥_nationality = 199Áª¥„ÄÇ\u003c/li\u003e\n\u003cli\u003e‰æãÂ¶Ç \u003ccode\u003e(28, Â•≥, ‰∏≠ÂõΩ)\u003c/code\u003e ‚Üí \u003ccode\u003e[28, 0, 0, 1, 0, ‚Ä¶, 0]\u003c/code\u003e„ÄÇ\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003c/ol\u003e\n\u003ch2 id=\"‰∏âÊñáÊú¨Êï∞ÊçÆÂ§ÑÁêÜÊµÅÁ®ã\"\u003e‰∏â„ÄÅÊñáÊú¨Êï∞ÊçÆÂ§ÑÁêÜÊµÅÁ®ã\u003c/h2\u003e\n\u003cp\u003eÊñáÊú¨Âú®Ëá™ÁÑ∂ËØ≠Ë®ÄÂ§ÑÁêÜÔºàNLPÔºâ‰∏≠‰Ωú‰∏∫Â∏∏ËßÅÁöÑÂéüÂßãËæìÂÖ•ÔºåÈúÄË¶ÅÊï∞ÂÄºÂåñÊâçËÉΩÈÄÅÂÖ•Ê®°Âûã„ÄÇ‰∏ÄËà¨Ê≠•È™§Â¶Ç‰∏ãÔºö\u003c/p\u003e\n\u003col\u003e\n\u003cli\u003e\n\u003cp\u003e\u003cstrong\u003eÂàÜËØç (Tokenization)\u003c/strong\u003e\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eÂ∞ÜÊñáÊú¨ÊãÜÂàÜ‰∏∫‰∏Ä‰∏™‰∏™ÂçïËØçÔºàTokenÔºâ„ÄÇ\u003c/li\u003e\n\u003cli\u003e‰æãÂ≠êÔºö\u003ccode\u003e\u0026quot;... to be or not to be...\u0026quot;\u003c/code\u003e ‚Üí \u003ccode\u003e[\u0026quot;...\u0026quot;, \u0026quot;to\u0026quot;, \u0026quot;be\u0026quot;, \u0026quot;or\u0026quot;, \u0026quot;not\u0026quot;, \u0026quot;to\u0026quot;, \u0026quot;be\u0026quot;, \u0026quot;...\u0026quot;]\u003c/code\u003e„ÄÇ\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003e\u003cstrong\u003eÁªüËÆ°ËØçÈ¢ë \u0026amp; ÊûÑÂª∫ËØçÂÖ∏\u003c/strong\u003e\u003c/p\u003e","title":""},{"content":"Text to Sequence ÊñáÊú¨Â§ÑÁêÜ\nStep1: Tokenization\nTokenization breaks a piece of text down into a list of tokens.\nHere, a token is a word. (A token can be a character in some applications.)\nTokenizationËÆ≤Á©∂ÂæàÂ§öÔºå‰æãÂ¶ÇÊòØÂê¶Â∫îËØ•ÊääÂ§ßÂÜôÊîπÊàêÂ∞èÂÜôÂë¢ÔºüËøõË°åtypo correctionÁ≠âÁ≠â\nStep2: Build Dictionary\nUse a dictionary (hash table) to count word frequencies.\nThe dictionary maps word to index.\nÂèØ‰ª•È¶ñÂÖàÁªüËÆ°ËØçÈ¢ëÂéªÊéâ‰ΩéÈ¢ëËØçÔºåÁÑ∂ÂêéËÆ©ÊØè‰∏™ËØçÂØπÂ∫î‰∏Ä‰∏™Ê≠£Êï¥Êï∞ÔºõËøôÊ†∑ÁöÑËØùÔºå‰∏ÄÂè•ËØùÂ∞±ÂèØ‰ª•Áî®‰∏Ä‰∏™Ê≠£Êï¥Êï∞ÂàóË°®Ë°®Á§∫ÔºåËøô‰∏™ÂàóË°®Â∞±Âè´sequenceÔºõÂ¶ÇÊûúÂøÖË¶ÅÂ∞±ËøòÂæóÂÅöone-hot encoding„ÄÇ\nÁªìÊûú\n‰ΩÜÊòØÈïøÂ∫¶‰∏çÁªü‰∏Ä\nStep4: ÂØπÈΩêsequence\nËß£ÂÜ≥ÊñπÊ°àÊòØËøôÊ†∑ÁöÑÔºöÂèØ‰ª•Âõ∫ÂÆöÈïøÂ∫¶‰∏∫wÔºåÂä†ÂÖ•‰∏Ä‰∏™Â∫èÂàóÈïøÂ∫¶Â§™ÈïøÔºåÂ∞±Á†çÊéâÂâçÈù¢ÁöÑËØçÔºåÂè™‰øùÁïôÊúÄÂêéw‰∏™ËØçÔºõÂ¶ÇÊûú‰∏Ä‰∏™Â∫èÂàóÂ§™Áü≠ÔºåÂ∞±ÂÅözero paddingÔºåÁî®0Â°´ÂÖÖ\nËøôÊ†∑‰∏ÄÊù•ÔºåÊâÄÊúâÁöÑÂ∫èÂàóÈïøÂ∫¶Â∞±Áªü‰∏Ä‰∫Ü\nÊñáÊú¨Â§ÑÁêÜÂÆåÊàê‰∫ÜÔºåÊé•‰∏ãÊù•ÊòØword embeddingÔºåÊääÂçïËØçË°®Á§∫‰∏∫‰∏Ä‰∏™‰ΩéÁª¥ÂêëÈáèÔºõ\nÁÑ∂ËÄåËøôÊ†∑ÂÅöÁöÑËØùÔºåÂ¶ÇÊûúÊòØ10000‰∏™ÂçïËØçÔºåÁª¥Â∫¶Â∞±ÊòØ10000Áª¥ÔºåÁª¥Â∫¶Â§™È´ò‰∫ÜÔºõÂõ†Ê≠§Ë¶ÅÂÅöword embeddingÔºõ\nÂÖ∑‰ΩìÂÅöÊ≥ïÂ∞±ÊòØÊääone-hotÂêëÈáèe_iÂíåÂèÇÊï∞Áü©ÈòµpÁõ∏‰πòÔºõÁü©ÈòµPËΩ¨ÁΩÆÁöÑÂ§ßÂ∞èÊòØd x vÔºõdÊòØËØçÂêëÈáèÁöÑÁª¥Â∫¶ÔºõvÊòØÂ≠óÂÖ∏ÈáåËØçÊ±áÁöÑÊï∞ÈáèÔºõÁªìÊûú‰∏∫x_iÔºõx_iÂ∞±ÊòØ‰∏Ä‰∏™ËØçÂêëÈáèÔºõÂ¶ÇÊûúone-hotÂêëÈáèÁöÑÁ¨¨‰∏âË°å‰∏∫1ÔºõÈÇ£‰πàx_iÂ∞±ÊòØPËΩ¨ÁΩÆÁü©ÈòµÁöÑÁ¨¨‰∏âÂàóÔºàÂÖ∂‰ΩôÂàóÈÉΩ‰∏∫0ÔºâÔºõÊâÄ‰ª•PËΩ¨ÁΩÆÊØè‰∏ÄÂàóÈÉΩÊòØ‰∏Ä‰∏™ËØçÂêëÈáèÔºõÊâÄ‰ª•Áü©ÈòµPÊú¨Ë∫´ÁöÑÊØè‰∏ÄË°åÂ∞±ÊòØ‰∏Ä‰∏™ËØçÂêëÈáèÔºõÂÖ∂Ë°åÊï∞‰∏∫vÔºõÂç≥vocabularyÔºåËØçÊ±áÈáèÔºõÊØè‰∏ÄË°åÂØπÂ∫î‰∏Ä‰∏™ÂçïËØçÔºõÁü©ÈòµÁöÑÂàóÊï∞‰∏∫dÔºõdÊòØÁî®Êà∑ÂÜ≥ÂÆöÁöÑÔºõdÁöÑÂ§ßÂ∞è‰ºöÂÜ≥ÂÆöÊú∫Âô®Â≠¶‰π†Ê®°ÂûãÁöÑË°®Áé∞ÔºõÂ∫îËØ•Áî®xxxÊù•ÈÄâÊã©‰∏Ä‰∏™ÊØîËæÉÂ•ΩÁöÑdÔºõ\nÊàë‰ª¨ÁöÑ‰ªªÂä°ÊòØÁúãËØÑËÆ∫ÊòØÊ≠£Èù¢ÁöÑËøòÊòØË¥üÈù¢ÁöÑÔºõÂèÇÊï∞Áü©ÈòµÊòØ‰ªéËÆ≠ÁªÉÊï∞ÊçÆ‰∏≠Â≠¶‰π†Âá∫Êù•ÁöÑÔºåÊâÄ‰ª•Â≠¶Âá∫Êù•ÁöÑËØçÂêëÈáèÊòØÂ∏¶ÊúâÊÑüÊÉÖËâ≤ÂΩ©ÁöÑÔºõÂÅáËÆæËøô‰∫õËØçÂêëÈáèÈÉΩÊòØ‰∫åÁª¥ÁöÑÔºåÂàôÂèØ‰ª•Âú®Âπ≥Èù¢ÂùêÊ†áÁ≥ª‰∏≠Ê†áÂá∫‰∏ãÈù¢ËØçÂêëÈáè\nkerasÊèê‰æõembeddingÂ±ÇÔºõÁî®Êà∑ÂèØ‰ª•ÊåáÂÆövocabularyÂ§ßÂ∞èÂíådÁöÑÂ§ßÂ∞èÔºõ‰ª•ÂèäÊØè‰∏Ä‰∏™sequenceÁöÑÈïøÂ∫¶ÔºõdÊòØÊ†πÊçÆÁÆóÊ≥ïÈÄâÂá∫Êù•ÁöÑ Âà∞Ëøô‰∏ÄÊ≠•ÔºåÊàë‰ª¨Â∑≤ÁªèÂÆåÊàê‰∫ÜÊñáÊú¨Â§ÑÁêÜÂíåword embedding„ÄÇÊé•‰∏ãÊù•Â∞±ÊòØÁî®Logistic Regression for Binary ClassificationÂÅö‰∫åÂàÜÁ±ªÔºõ\n","permalink":"http://localhost:1313/posts/nlp-2/","summary":"\u003ch3 id=\"text-to-sequence\"\u003eText to Sequence\u003c/h3\u003e\n\u003cp\u003eÊñáÊú¨Â§ÑÁêÜ\u003c/p\u003e\n\u003cp\u003eStep1: Tokenization\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\n\u003cp\u003eTokenization breaks a piece of text down into a list of tokens.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003eHere, a token is a word. (A token can be a character in some applications.)\u003c/p\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003eTokenizationËÆ≤Á©∂ÂæàÂ§öÔºå‰æãÂ¶ÇÊòØÂê¶Â∫îËØ•ÊääÂ§ßÂÜôÊîπÊàêÂ∞èÂÜôÂë¢ÔºüËøõË°åtypo correctionÁ≠âÁ≠â\u003c/p\u003e\n\u003cp\u003e\u003cimg alt=\"image-20250322150322238\" loading=\"lazy\" src=\"./NLP-2.assets/image-20250322150322238.png\"\u003e\u003c/p\u003e\n\u003cp\u003eStep2: Build Dictionary\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\n\u003cp\u003eUse a dictionary (hash table) to count word frequencies.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003eThe dictionary maps word to index.\u003c/p\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003eÂèØ‰ª•È¶ñÂÖàÁªüËÆ°ËØçÈ¢ëÂéªÊéâ‰ΩéÈ¢ëËØçÔºåÁÑ∂ÂêéËÆ©ÊØè‰∏™ËØçÂØπÂ∫î‰∏Ä‰∏™Ê≠£Êï¥Êï∞ÔºõËøôÊ†∑ÁöÑËØùÔºå‰∏ÄÂè•ËØùÂ∞±ÂèØ‰ª•Áî®‰∏Ä‰∏™Ê≠£Êï¥Êï∞ÂàóË°®Ë°®Á§∫ÔºåËøô‰∏™ÂàóË°®Â∞±Âè´sequenceÔºõÂ¶ÇÊûúÂøÖË¶ÅÂ∞±ËøòÂæóÂÅöone-hot encoding„ÄÇ\u003cimg alt=\"image-20250322150620890\" loading=\"lazy\" src=\"./NLP-2.assets/image-20250322150620890.png\"\u003e\u003c/p\u003e\n\u003cp\u003eÁªìÊûú\u003c/p\u003e\n\u003cp\u003e\u003cimg alt=\"image-20250322150754528\" loading=\"lazy\" src=\"./NLP-2.assets/image-20250322150754528.png\"\u003e\u003c/p\u003e\n\u003cp\u003e‰ΩÜÊòØÈïøÂ∫¶‰∏çÁªü‰∏Ä\u003c/p\u003e\n\u003cp\u003eStep4: ÂØπÈΩêsequence\u003c/p\u003e\n\u003cp\u003e\u003cimg alt=\"image-20250322150854986\" loading=\"lazy\" src=\"./NLP-2.assets/image-20250322150854986.png\"\u003e\u003c/p\u003e\n\u003cp\u003eËß£ÂÜ≥ÊñπÊ°àÊòØËøôÊ†∑ÁöÑÔºöÂèØ‰ª•Âõ∫ÂÆöÈïøÂ∫¶‰∏∫wÔºåÂä†ÂÖ•‰∏Ä‰∏™Â∫èÂàóÈïøÂ∫¶Â§™ÈïøÔºåÂ∞±Á†çÊéâÂâçÈù¢ÁöÑËØçÔºåÂè™‰øùÁïôÊúÄÂêéw‰∏™ËØçÔºõÂ¶ÇÊûú‰∏Ä‰∏™Â∫èÂàóÂ§™Áü≠ÔºåÂ∞±ÂÅözero paddingÔºåÁî®0Â°´ÂÖÖ\u003c/p\u003e\n\u003cp\u003e\u003cimg alt=\"image-20250322151030119\" loading=\"lazy\" src=\"./NLP-2.assets/image-20250322151030119.png\"\u003e\u003c/p\u003e\n\u003cp\u003eËøôÊ†∑‰∏ÄÊù•ÔºåÊâÄÊúâÁöÑÂ∫èÂàóÈïøÂ∫¶Â∞±Áªü‰∏Ä‰∫Ü\u003c/p\u003e\n\u003cp\u003e\u003cimg alt=\"image-20250322151117125\" loading=\"lazy\" src=\"./NLP-2.assets/image-20250322151117125.png\"\u003e\u003c/p\u003e\n\u003cp\u003eÊñáÊú¨Â§ÑÁêÜÂÆåÊàê‰∫ÜÔºåÊé•‰∏ãÊù•ÊòØword embeddingÔºåÊääÂçïËØçË°®Á§∫‰∏∫‰∏Ä‰∏™‰ΩéÁª¥ÂêëÈáèÔºõ\u003c/p\u003e\n\u003cp\u003e\u003cimg alt=\"image-20250322151252837\" loading=\"lazy\" src=\"./NLP-2.assets/image-20250322151252837.png\"\u003e\u003c/p\u003e","title":""},{"content":"üëã About me Hello! I\u0026rsquo;m Xu Zongsi, a passionate technology enthusiast currently pursuing my Master of Science in ECIC at The University of Hong Kong. With a solid background in Software Engineering from the Beijing Institute of Technology, I specialize in artificial intelligence areas like machine learning, deep learning, natural language processing, computer vision, and reinforcement learning.\nInspired by OpenAI\u0026rsquo;s five-step plan towards superintelligence, I am excited about AGI and have developed a keen interest in LLM agents, MLLM, and knowledge graphs. I see great potential in these fields and aspire to contribute to innovative solutions.\nüìö Education üá≠üá∞ The University of Hong Kong 09/2024 - Expected 11/2025 School of Computing and Data Science Master of Science in Electronic Commerce \u0026amp; Internet Computing Relevant Courses: Machine learning for business and e-commerce, Knowledge graphs, Financial fraud analytics, Internet infrastructure technologies, Website engineering, Blockchain and cryptocurrency, etc. üá®üá≥ Beijing Institute of Technology 09/2020 - 06/2024 School of Computer Science \u0026amp; Technology Bachelor of Engineering in Software Engineering, last two years GPA: 3.7/4 Relevant Courses: Reinforcement Learning, Deep Learning and Computer Vision, Artificial Intelligence and Robot Ethics, Almost Human: Mind, Brain and Artificial Intelligence, Mathematical Analysis for Engineering, Linear Algebra, Probability and Mathematical Statistics, etc. Skills: Python, Java, common data structures, design patterns, machine learning basics and algorithms, Linux, PyTorch, and some development tools (git, conda, etc.). üèÜ Awards \u0026amp; Honors Beijing Institute of Technology Undergraduate Scholarship (Top 20% of Grade) 06/2023 3rd Prize of China International \u0026#34;Internet \u0026#43;\u0026#34; College Student\u0026#39;s Innovation Competition 08/2022 Bronze Prize of \u0026#34;Challenge Cup\u0026#34; Capital University Entrepreneurship Competition 05/2022 üíº Project Experience üîç Online Transaction Fraud Detection 09/2024 ‚Äì 01/2025 Independent project, supervised by Dr. Vivien Chan Focused on addressing financial fraud in e-commerce to enhance the accuracy of transaction anomaly detection, while independently managing the entire case study that included data preprocessing, feature engineering, model building, evaluation, and results analysis. Effectively resolved class imbalance issues using SMOTE and ROSE techniques. Built various models including Logistic Regression, Random Forest, XGBoost, and LightGBM, ultimately selecting the LightGBM model to achieve a recall rate of 95.45% and an AUC of 99.84%. Wrote efficient and maintainable code, enhancing model training and data processing efficiency through parallel computing and logging. ü§ñ Multi-Model Intelligent Text Keyword Extraction System 08/2023 ‚Äì 09/2023 Group project, supervised by Associate Prof. Xiaolin Zhao Designed and implemented an intelligent text summary system that automatically extracts keywords from article titles and abstracts, enhancing the understanding and summarization of text information. Participated in the planning of the technical route and built a hybrid model combining extractive and generative approaches, utilizing advanced natural language processing techniques including KeyBERT, Sentence Transformer, BERT, and T5 models. Responsible for data preprocessing and tokenization, as well as the end-to-end implementation and training of the T5 model, optimizing the model architecture and hyperparameters, achieving satisfactory results after only 3 epochs of training. Model evaluation results showed that the Rouge-1, Rouge-2, and Rouge-L metrics reached 0.6345, 0.5038, and 0.5282, respectively, in the third epoch, validating the model\u0026rsquo;s effectiveness in the summarization task. üéì Cambridge University Machine Learning Summer Project 07/2023 ‚Äì 08/2023 Group project, supervised by Prof. Pietro Li√≤ Participated in the Cambridge University deep learning summer project, focusing on deep reinforcement learning; explored multi-agent learning algorithms across different environments. Reproduced the Multi-Agent Deep Deterministic Policy Gradient (MADDPG) algorithm in the Simple Adversary environment and studied the effect of agent numbers on convergence speed and stability, finding optimal stability at 21 agents. Designed and implemented comparative experiments inspired by the Rainbow algorithm, assessing target network strategies versus the Double Deep Q-Network (Double DQN). The results demonstrated that Double DQN significantly enhanced convergence speed, optimizing the overall learning process. Co-authored a group project paper on agent numbers and strategies effectiveness in multi-agent systems, achieving a score of 71% in the summer program (the highest in my group) and a \u0026ldquo;First Class\u0026rdquo; classification in the UK grading system. üëÅÔ∏è Deep Learning and Computer Vision Semester Project 09/2022 ‚Äì 12/2022 Independent project, supervised by Associate Prof. Guangyu Gao Designed and implemented a waste classifier using the ResNet model to improve classification accuracy and reduce resource waste. The project also enhanced understanding of transfer learning techniques with ResNet. Collected a dataset of 16 waste categories and preprocessed the images for uniformity and standardization, incorporating data augmentation techniques to enhance the dataset. Conducted experiments using ResNet34 and ResNet50 models through transfer learning, accelerating network convergence by leveraging pretrained weights. During training, techniques such as Batch Normalization and Dropout were applied to mitigate the risk of overfitting. The final model achieved an accuracy of 90% on the training set, while the performance on the test set was 61%, indicating a significant overfitting phenomenon during the training process. üéì Internship ‚öõÔ∏è Beijing Academy of Quantum Information Science 08/2023 ‚Äì 01/2024 Research Intern at Quantum Computation Department Proposed a quantum convolution kernel design based on variational quantum circuits and developed a universal quantum convolution layer, successfully integrating it into classical CNN architectures such as VGG, GoogLeNet, and ResNet. Developed and evaluated various hybrid models, including a simple model named HQCCNN-2, which achieved 84.45% accuracy on the FashionMNIST dataset, surpassing the traditional CNN\u0026rsquo;s 80.72%. This demonstrates the effectiveness of the quantum convolution layer in improving model performance. Tested on a real quantum computer further validated the effectiveness of the hybrid model, demonstrating the viable integration of quantum computing with deep learning, and highlighting the potential for leveraging quantum properties to enhance model performance. üèÖ Competition Experience ü•â China International \u0026#34;Internet \u0026#43;\u0026#34; College Students\u0026#39; Innovation Competition 08/2022 üõ°Ô∏è Zhongke Ushield: Deep Learning-based Face Privacy Protection Authentication System Responsible for constructing a localized facial feature extraction engine based on MobileFaceNet, ensuring feature extraction is completed on end devices (such as mobile phones and cameras), guaranteeing that raw data does not leave the domain and is not stored, thus enhancing user privacy protection while improving recognition efficiency. ü•â \u0026#34;Challenge Cup\u0026#34; Capital University Entrepreneurship Competition 05/2022 üå≥ Smart Orchard Responsible for the development of the fruit detection, ripeness prediction, and pest identification system, using deep convolutional neural network (CNN) technology for intelligent monitoring of crop growth conditions. Applied advanced object detection algorithms such as Faster R-CNN and YOLO to achieve high precision in apple detection and ripeness assessment, with an accuracy rate exceeding 90%, significantly enhancing the intelligence level of orchard management. Built and trained a dedicated dataset containing various pest samples, optimizing pest detection accuracy through data preprocessing (such as image normalization and resizing) and data augmentation techniques (like rotation, flipping, and noise addition), enabling the real-time monitoring system to accurately identify over 80% of pests, providing effective scientific maintenance recommendations to help farmers reduce crop losses. üìã Extracurricular Activities Vice President, Cyber Security Club, Beijing Institute of Technology 09/2021-09/2022 Backbone, Media Center of the Student Union of Beijing Institute of Technology 10/2020-06/2021 üì´ Contact üìß Email: zongsi.xu@outlook.com üëî LinkedIn: Zongsi (Tristan) Xu üíª GitHub: github.com/BaizeXS üìç Location: Hong Kong SAR, China ","permalink":"http://localhost:1313/resume/","summary":"Personal resume of Zongsi (Tristan) Xu","title":"Zongsi (Tristan) Xu"},{"content":"‰∏Ä„ÄÅÊï∞ÂÄºÁâπÂæÅ‰∏éÁ±ªÂà´ÁâπÂæÅ Êï∞ÂÄºÁâπÂæÅ (Numeric Features) ÂÖ∑ÊúâÂèØÂä†ÂáèÁöÑÊÑè‰πâÔºå‰∏îÂ≠òÂú®Â§ßÂ∞èÈ°∫Â∫è„ÄÇ ‰æãÂ≠êÔºöÂπ¥ÈæÑ„ÄÅÊ∏©Â∫¶Á≠â„ÄÇÂèØ‰ª•Áõ¥Êé•‰øùÁïôÂÖ∂Êï¥Êï∞ÊàñÊµÆÁÇπÊï∞ÂΩ¢Âºè‰æõÊ®°Âûã‰ΩøÁî®„ÄÇ Á±ªÂà´ÁâπÂæÅ (Categorical Features) Êï∞ÊçÆÂÄºÁ¶ªÊï£Ôºå‰∏çÂÖ∑Â§á‚ÄúÊï∞ÂÄºÂ§ßÂ∞è‚ÄùÈó¥ÁöÑÂèØÊØîÊÑè‰πâ„ÄÇ ‰æãÂ≠êÔºöÂõΩÁ±çÔºàÁæéÂõΩ/‰∏≠ÂõΩ/Âç∞Â∫¶Á≠âÔºâ„ÄÅÊÄßÂà´ÔºàÁî∑/Â•≥ÔºâÁ≠â„ÄÇ ÈóÆÈ¢òÔºöËã•‰ªÖÁî®Êï¥Êï∞Ë°®Á§∫ÔºàÁæéÂõΩ=1, ‰∏≠ÂõΩ=2ÔºâÔºå‰ºöÂºïÂÖ•ÈîôËØØÁöÑÊï∞ÂÄºËøêÁÆóÂÖ≥Á≥ªÔºåÂ¶Ç ‚ÄúÁæéÂõΩ + ‰∏≠ÂõΩ = Âç∞Â∫¶‚Äù„ÄÇ ‰∫å„ÄÅOne-HotÁºñÁ†ÅÁöÑÂä®Êú∫‰∏éÊµÅÁ®ã ‰∏∫‰ªÄ‰πà‰ΩøÁî®One-Hot\nÈÄöËøáÂ∞ÜÁ±ªÂà´Êò†Â∞Ñ‰∏∫ÂêëÈáèÔºåÈÅøÂÖçÊï¥Êï∞ÁºñÁ†ÅÂºïÂÖ•ÁöÑ‰º™Êï∞ÂÄºÂÖ≥Á≥ª„ÄÇ ÂêåÊó∂‰øùÁïôÂêÑÁßçÂèØËÉΩÁ±ªÂà´ÁöÑ‰ø°ÊÅØÔºå‰∏î‰ªÖÂú®ÂØπÂ∫î‰ΩçÁΩÆ‰∏∫1ÔºåÂÖ∂‰ªñ‰ΩçÁΩÆ‰∏∫0„ÄÇ Âª∫Á´ãÊò†Â∞ÑÔºö‰ªéÁ±ªÂà´Âà∞Á¥¢Âºï\n‰∏∫ÊØè‰∏™Á±ªÂà´ÂàÜÈÖç‰∏Ä‰∏™ÂîØ‰∏ÄÁ¥¢ÂºïÔºåÈÄöÂ∏∏‰ªé1ÂºÄÂßã„ÄÇ È¢ÑÁïôÁ¥¢Âºï0Ë°®Á§∫‚ÄúÊú™Áü•‚ÄùÊàñ‚ÄúÁº∫Â§±‚ÄùÔºåÂØπÂ∫îÂÖ®0ÂêëÈáè„ÄÇ ËΩ¨Êç¢‰∏∫One-HotÂêëÈáè\nËã•Á±ªÂà´ÊÄªÊï∞‰∏∫197ÔºåÂàôÁî®197Áª¥ÂêëÈáèË°®Á§∫„ÄÇ ‰æãÂ≠êÔºöÁæéÂõΩ [1, 0, 0, 0, ‚Ä¶]Ôºå ‰∏≠ÂõΩ [0, 1, 0, 0, ‚Ä¶]„ÄÇ Á§∫‰æãÔºöË°®Á§∫‰∏Ä‰∏™‰∫∫ÁöÑÁâπÂæÅ\nÁâπÂæÅÂåÖÂê´ÔºàÂπ¥ÈæÑ, ÊÄßÂà´, ÂõΩÁ±çÔºåÂÖ∂‰∏≠ÂõΩÁ±ç197ÁßçÔºâ Áª¥Â∫¶ÊÄªÂíåÔºö1Áª¥_age + 1Áª¥_gender + 197Áª¥_nationality = 199Áª¥„ÄÇ ‰æãÂ¶Ç (28, Â•≥, ‰∏≠ÂõΩ) ‚Üí [28, 0, 0, 1, 0, ‚Ä¶, 0]„ÄÇ ‰∏â„ÄÅÊñáÊú¨Êï∞ÊçÆÂ§ÑÁêÜÊµÅÁ®ã ÊñáÊú¨Âú®Ëá™ÁÑ∂ËØ≠Ë®ÄÂ§ÑÁêÜÔºàNLPÔºâ‰∏≠‰Ωú‰∏∫Â∏∏ËßÅÁöÑÂéüÂßãËæìÂÖ•ÔºåÈúÄË¶ÅÊï∞ÂÄºÂåñÊâçËÉΩÈÄÅÂÖ•Ê®°Âûã„ÄÇ‰∏ÄËà¨Ê≠•È™§Â¶Ç‰∏ãÔºö\nÂàÜËØç (Tokenization)\nÂ∞ÜÊñáÊú¨ÊãÜÂàÜ‰∏∫‰∏Ä‰∏™‰∏™ÂçïËØçÔºàTokenÔºâ„ÄÇ ‰æãÂ≠êÔºö\u0026quot;... to be or not to be...\u0026quot; ‚Üí [\u0026quot;...\u0026quot;, \u0026quot;to\u0026quot;, \u0026quot;be\u0026quot;, \u0026quot;or\u0026quot;, \u0026quot;not\u0026quot;, \u0026quot;to\u0026quot;, \u0026quot;be\u0026quot;, \u0026quot;...\u0026quot;]„ÄÇ ÁªüËÆ°ËØçÈ¢ë \u0026amp; ÊûÑÂª∫ËØçÂÖ∏\nËØçÈ¢ëÁªüËÆ° Áî®ÂìàÂ∏åË°®/Â≠óÂÖ∏ËÆ∞ÂΩïÊØè‰∏™ÂçïËØçÂá∫Áé∞Ê¨°Êï∞„ÄÇ ÈÅçÂéÜÊñáÊú¨Êó∂ÔºåËã•ÂçïËØçÂ∞öÊú™ÂÖ•Ë°®ÔºåÂàôÊñ∞Âª∫ËÆ∞ÂΩïÔºõËã•Â∑≤Â≠òÂú®ÔºåÂàôËÆ°Êï∞+1„ÄÇ ÊéíÂ∫è‰∏éÁ¥¢Âºï ÊåâËØçÈ¢ëÈôçÂ∫èÊéíÂ∫èÔºåËØçÈ¢ëÊúÄÈ´òÁöÑÂçïËØçÊéíÂú®ÂâçÈù¢„ÄÇ Á¥¢Âºï‰ªé1ÂºÄÂßãÔºå0ÁïôÁªô‚ÄúÊú™Áü•‚Äù„ÄÇ ËØçÂÖ∏ËßÑÊ®°ÔºàvocabularyÔºâÂèØËßÜÈúÄÊ±ÇÊà™Êñ≠Ôºà‰æãÂ¶ÇÂè™‰øùÁïôTop 10kÔºâ„ÄÇ ‰∏∫‰ªÄ‰πàÁßªÈô§‰ΩéÈ¢ëËØç ‰ΩéÈ¢ëËØçÂèØËÉΩÊòØÊãºÂÜôÈîôËØØ„ÄÅÁΩïËßÅ‰∫∫ÂêçÁ≠âÔºåÂØπÊ®°ÂûãÂ∏ÆÂä©ÊúâÈôê„ÄÇ ÂáèÂ∞ëËØçÂÖ∏ËßÑÊ®°ÂèØÈôç‰ΩéËøêÁÆóÂºÄÈîÄ„ÄÅÂä†Âø´Ê®°ÂûãËÆ≠ÁªÉ‰∏éÊé®ÁêÜÈÄüÂ∫¶„ÄÇ Áã¨ÁÉ≠ÁºñÁ†Å (One-Hot Encoding)\nÂ∞ÜÊØè‰∏™ÂçïËØçÊò†Â∞Ñ‰∏∫ËØçÂÖ∏‰∏≠ÁöÑÁ¥¢ÂºïÂêéÔºàÂ¶Ç [2, 4, 1, 8, ‚Ä¶]ÔºâÔºåÂèØËøõ‰∏ÄÊ≠•ËΩ¨Êç¢ÊàêOne-HotÂêëÈáè„ÄÇ One-HotÁª¥Â∫¶ÂèñÂÜ≥‰∫é‰øùÁïô‰∏ãÊù•ÁöÑËØçÂÖ∏Â§ßÂ∞èÔºà‰æãÂ¶Ç1‰∏áÔºâ„ÄÇ Êú™Êî∂ÂΩïÂçïËØçÂèØËÉΩÁõ¥Êé•ÂøΩÁï•ÔºåÊàñÁªü‰∏ÄÁî®Á¥¢Âºï0‰ª£Êõø„ÄÇ Âõõ„ÄÅÊ†∏ÂøÉÊî∂Ëé∑‰∏éÂ∫îÁî® Á±ªÂà´ÁâπÂæÅÂøÖÈúÄÊï∞ÂÄºÂåñÔºö\n‰ΩøÁî®Êï¥Êï∞1,2,3‚Ä¶‰ªÖË°®Á§∫Á±ªÂà´‚ÄúÊ†áËØÜ‚ÄùÔºåÂπ∂‰∏ç‰ª£Ë°®ÂÆÉ‰ª¨ÂèØËøõË°åÊï∞ÂÄºËøêÁÆó„ÄÇ Âõ†Ê≠§ÈúÄË¶ÅOne-HotÁ≠âÁºñÁ†ÅÊñπÂºèÔºåÈÅøÂÖçÊï∞ÂÄºËØØËß£„ÄÇ ÊñáÊú¨Êï∞ÊçÆÈ¢ÑÂ§ÑÁêÜÔºö\nÂàÜËØç„ÄÅËØçÈ¢ëÁªüËÆ°„ÄÅÊûÑÂª∫ËØçÂÖ∏„ÄÅÁ¥¢ÂºïÂåñ„ÄÅOne-HotÊàñÂÖ∂‰ªñÊñπÂºèÔºàÂ¶ÇËØçÂµåÂÖ•ÔºâÊòØÂ∏∏ËßÅÊµÅÁ®ã„ÄÇ Ê≠£Á°ÆÁöÑÊñáÊú¨È¢ÑÂ§ÑÁêÜÂèØÊòæËëóÂΩ±ÂìçÊ®°ÂûãÊÄßËÉΩÂíåÊïàÁéá„ÄÇ ‰øùÁïôÊú™Áü•Á¥¢ÂºïÔºö\n‰øùËØÅÂØπÁº∫Â§±Êï∞ÊçÆÊàñÂ≠óÂÖ∏Â§ñÊñ∞ËØçËÉΩÊúâÂü∫Êú¨ÁöÑË°®Á§∫ÔºåÊèêÂçáÊ®°ÂûãÂÆπÈîôÊÄß„ÄÇ ÂÆûÈôÖ‰ΩøÁî®Ôºö\nÂØπ‰∫éÂ∞èËßÑÊ®°Á±ªÂà´ÂèØÁõ¥Êé•One-HotÁºñÁ†ÅÔºõÂØπ‰∫éËØçÂÖ∏ÂæàÂ§ßÁöÑÂú∫ÊôØÔºåÈÄöÂ∏∏‰ºöËøõ‰∏ÄÊ≠•ËÄÉËôëËØçÂµåÂÖ•ÔºàWord EmbeddingÔºâÊàñÈ¢ÑËÆ≠ÁªÉËØ≠Ë®ÄÊ®°Âûã„ÄÇ ","permalink":"http://localhost:1313/posts/nlp-1/","summary":"\u003ch2 id=\"‰∏ÄÊï∞ÂÄºÁâπÂæÅ‰∏éÁ±ªÂà´ÁâπÂæÅ\"\u003e‰∏Ä„ÄÅÊï∞ÂÄºÁâπÂæÅ‰∏éÁ±ªÂà´ÁâπÂæÅ\u003c/h2\u003e\n\u003col\u003e\n\u003cli\u003e\u003cstrong\u003eÊï∞ÂÄºÁâπÂæÅ (Numeric Features)\u003c/strong\u003e\n\u003cul\u003e\n\u003cli\u003eÂÖ∑ÊúâÂèØÂä†ÂáèÁöÑÊÑè‰πâÔºå‰∏îÂ≠òÂú®Â§ßÂ∞èÈ°∫Â∫è„ÄÇ\u003c/li\u003e\n\u003cli\u003e‰æãÂ≠êÔºöÂπ¥ÈæÑ„ÄÅÊ∏©Â∫¶Á≠â„ÄÇÂèØ‰ª•Áõ¥Êé•‰øùÁïôÂÖ∂Êï¥Êï∞ÊàñÊµÆÁÇπÊï∞ÂΩ¢Âºè‰æõÊ®°Âûã‰ΩøÁî®„ÄÇ\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003eÁ±ªÂà´ÁâπÂæÅ (Categorical Features)\u003c/strong\u003e\n\u003cul\u003e\n\u003cli\u003eÊï∞ÊçÆÂÄºÁ¶ªÊï£Ôºå‰∏çÂÖ∑Â§á‚ÄúÊï∞ÂÄºÂ§ßÂ∞è‚ÄùÈó¥ÁöÑÂèØÊØîÊÑè‰πâ„ÄÇ\u003c/li\u003e\n\u003cli\u003e‰æãÂ≠êÔºöÂõΩÁ±çÔºàÁæéÂõΩ/‰∏≠ÂõΩ/Âç∞Â∫¶Á≠âÔºâ„ÄÅÊÄßÂà´ÔºàÁî∑/Â•≥ÔºâÁ≠â„ÄÇ\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003eÈóÆÈ¢ò\u003c/strong\u003eÔºöËã•‰ªÖÁî®Êï¥Êï∞Ë°®Á§∫ÔºàÁæéÂõΩ=1, ‰∏≠ÂõΩ=2ÔºâÔºå‰ºöÂºïÂÖ•ÈîôËØØÁöÑÊï∞ÂÄºËøêÁÆóÂÖ≥Á≥ªÔºåÂ¶Ç ‚ÄúÁæéÂõΩ + ‰∏≠ÂõΩ = Âç∞Â∫¶‚Äù„ÄÇ\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003c/ol\u003e\n\u003ch2 id=\"‰∫åone-hotÁºñÁ†ÅÁöÑÂä®Êú∫‰∏éÊµÅÁ®ã\"\u003e‰∫å„ÄÅOne-HotÁºñÁ†ÅÁöÑÂä®Êú∫‰∏éÊµÅÁ®ã\u003c/h2\u003e\n\u003col\u003e\n\u003cli\u003e\n\u003cp\u003e\u003cstrong\u003e‰∏∫‰ªÄ‰πà‰ΩøÁî®One-Hot\u003c/strong\u003e\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eÈÄöËøáÂ∞ÜÁ±ªÂà´Êò†Â∞Ñ‰∏∫ÂêëÈáèÔºåÈÅøÂÖçÊï¥Êï∞ÁºñÁ†ÅÂºïÂÖ•ÁöÑ‰º™Êï∞ÂÄºÂÖ≥Á≥ª„ÄÇ\u003c/li\u003e\n\u003cli\u003eÂêåÊó∂‰øùÁïôÂêÑÁßçÂèØËÉΩÁ±ªÂà´ÁöÑ‰ø°ÊÅØÔºå‰∏î‰ªÖÂú®ÂØπÂ∫î‰ΩçÁΩÆ‰∏∫1ÔºåÂÖ∂‰ªñ‰ΩçÁΩÆ‰∏∫0„ÄÇ\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003e\u003cstrong\u003eÂª∫Á´ãÊò†Â∞ÑÔºö‰ªéÁ±ªÂà´Âà∞Á¥¢Âºï\u003c/strong\u003e\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e‰∏∫ÊØè‰∏™Á±ªÂà´ÂàÜÈÖç‰∏Ä‰∏™ÂîØ‰∏ÄÁ¥¢ÂºïÔºåÈÄöÂ∏∏‰ªé1ÂºÄÂßã„ÄÇ\u003c/li\u003e\n\u003cli\u003eÈ¢ÑÁïôÁ¥¢Âºï0Ë°®Á§∫‚ÄúÊú™Áü•‚ÄùÊàñ‚ÄúÁº∫Â§±‚ÄùÔºåÂØπÂ∫îÂÖ®0ÂêëÈáè„ÄÇ\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003e\u003cstrong\u003eËΩ¨Êç¢‰∏∫One-HotÂêëÈáè\u003c/strong\u003e\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eËã•Á±ªÂà´ÊÄªÊï∞‰∏∫197ÔºåÂàôÁî®197Áª¥ÂêëÈáèË°®Á§∫„ÄÇ\u003c/li\u003e\n\u003cli\u003e‰æãÂ≠êÔºöÁæéÂõΩ \u003ccode\u003e[1, 0, 0, 0, ‚Ä¶]\u003c/code\u003eÔºå ‰∏≠ÂõΩ \u003ccode\u003e[0, 1, 0, 0, ‚Ä¶]\u003c/code\u003e„ÄÇ\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003e\u003cstrong\u003eÁ§∫‰æãÔºöË°®Á§∫‰∏Ä‰∏™‰∫∫ÁöÑÁâπÂæÅ\u003c/strong\u003e\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eÁâπÂæÅÂåÖÂê´ÔºàÂπ¥ÈæÑ, ÊÄßÂà´, ÂõΩÁ±çÔºåÂÖ∂‰∏≠ÂõΩÁ±ç197ÁßçÔºâ\u003c/li\u003e\n\u003cli\u003eÁª¥Â∫¶ÊÄªÂíåÔºö1Áª¥_age + 1Áª¥_gender + 197Áª¥_nationality = 199Áª¥„ÄÇ\u003c/li\u003e\n\u003cli\u003e‰æãÂ¶Ç \u003ccode\u003e(28, Â•≥, ‰∏≠ÂõΩ)\u003c/code\u003e ‚Üí \u003ccode\u003e[28, 0, 0, 1, 0, ‚Ä¶, 0]\u003c/code\u003e„ÄÇ\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003c/ol\u003e\n\u003ch2 id=\"‰∏âÊñáÊú¨Êï∞ÊçÆÂ§ÑÁêÜÊµÅÁ®ã\"\u003e‰∏â„ÄÅÊñáÊú¨Êï∞ÊçÆÂ§ÑÁêÜÊµÅÁ®ã\u003c/h2\u003e\n\u003cp\u003eÊñáÊú¨Âú®Ëá™ÁÑ∂ËØ≠Ë®ÄÂ§ÑÁêÜÔºàNLPÔºâ‰∏≠‰Ωú‰∏∫Â∏∏ËßÅÁöÑÂéüÂßãËæìÂÖ•ÔºåÈúÄË¶ÅÊï∞ÂÄºÂåñÊâçËÉΩÈÄÅÂÖ•Ê®°Âûã„ÄÇ‰∏ÄËà¨Ê≠•È™§Â¶Ç‰∏ãÔºö\u003c/p\u003e\n\u003col\u003e\n\u003cli\u003e\n\u003cp\u003e\u003cstrong\u003eÂàÜËØç (Tokenization)\u003c/strong\u003e\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eÂ∞ÜÊñáÊú¨ÊãÜÂàÜ‰∏∫‰∏Ä‰∏™‰∏™ÂçïËØçÔºàTokenÔºâ„ÄÇ\u003c/li\u003e\n\u003cli\u003e‰æãÂ≠êÔºö\u003ccode\u003e\u0026quot;... to be or not to be...\u0026quot;\u003c/code\u003e ‚Üí \u003ccode\u003e[\u0026quot;...\u0026quot;, \u0026quot;to\u0026quot;, \u0026quot;be\u0026quot;, \u0026quot;or\u0026quot;, \u0026quot;not\u0026quot;, \u0026quot;to\u0026quot;, \u0026quot;be\u0026quot;, \u0026quot;...\u0026quot;]\u003c/code\u003e„ÄÇ\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003e\u003cstrong\u003eÁªüËÆ°ËØçÈ¢ë \u0026amp; ÊûÑÂª∫ËØçÂÖ∏\u003c/strong\u003e\u003c/p\u003e","title":""},{"content":"Text to Sequence ÊñáÊú¨Â§ÑÁêÜ\nStep1: Tokenization\nTokenization breaks a piece of text down into a list of tokens.\nHere, a token is a word. (A token can be a character in some applications.)\nTokenizationËÆ≤Á©∂ÂæàÂ§öÔºå‰æãÂ¶ÇÊòØÂê¶Â∫îËØ•ÊääÂ§ßÂÜôÊîπÊàêÂ∞èÂÜôÂë¢ÔºüËøõË°åtypo correctionÁ≠âÁ≠â\nStep2: Build Dictionary\nUse a dictionary (hash table) to count word frequencies.\nThe dictionary maps word to index.\nÂèØ‰ª•È¶ñÂÖàÁªüËÆ°ËØçÈ¢ëÂéªÊéâ‰ΩéÈ¢ëËØçÔºåÁÑ∂ÂêéËÆ©ÊØè‰∏™ËØçÂØπÂ∫î‰∏Ä‰∏™Ê≠£Êï¥Êï∞ÔºõËøôÊ†∑ÁöÑËØùÔºå‰∏ÄÂè•ËØùÂ∞±ÂèØ‰ª•Áî®‰∏Ä‰∏™Ê≠£Êï¥Êï∞ÂàóË°®Ë°®Á§∫ÔºåËøô‰∏™ÂàóË°®Â∞±Âè´sequenceÔºõÂ¶ÇÊûúÂøÖË¶ÅÂ∞±ËøòÂæóÂÅöone-hot encoding„ÄÇ\nÁªìÊûú\n‰ΩÜÊòØÈïøÂ∫¶‰∏çÁªü‰∏Ä\nStep4: ÂØπÈΩêsequence\nËß£ÂÜ≥ÊñπÊ°àÊòØËøôÊ†∑ÁöÑÔºöÂèØ‰ª•Âõ∫ÂÆöÈïøÂ∫¶‰∏∫wÔºåÂä†ÂÖ•‰∏Ä‰∏™Â∫èÂàóÈïøÂ∫¶Â§™ÈïøÔºåÂ∞±Á†çÊéâÂâçÈù¢ÁöÑËØçÔºåÂè™‰øùÁïôÊúÄÂêéw‰∏™ËØçÔºõÂ¶ÇÊûú‰∏Ä‰∏™Â∫èÂàóÂ§™Áü≠ÔºåÂ∞±ÂÅözero paddingÔºåÁî®0Â°´ÂÖÖ\nËøôÊ†∑‰∏ÄÊù•ÔºåÊâÄÊúâÁöÑÂ∫èÂàóÈïøÂ∫¶Â∞±Áªü‰∏Ä‰∫Ü\nÊñáÊú¨Â§ÑÁêÜÂÆåÊàê‰∫ÜÔºåÊé•‰∏ãÊù•ÊòØword embeddingÔºåÊääÂçïËØçË°®Á§∫‰∏∫‰∏Ä‰∏™‰ΩéÁª¥ÂêëÈáèÔºõ\nÁÑ∂ËÄåËøôÊ†∑ÂÅöÁöÑËØùÔºåÂ¶ÇÊûúÊòØ10000‰∏™ÂçïËØçÔºåÁª¥Â∫¶Â∞±ÊòØ10000Áª¥ÔºåÁª¥Â∫¶Â§™È´ò‰∫ÜÔºõÂõ†Ê≠§Ë¶ÅÂÅöword embeddingÔºõ\nÂÖ∑‰ΩìÂÅöÊ≥ïÂ∞±ÊòØÊääone-hotÂêëÈáèe_iÂíåÂèÇÊï∞Áü©ÈòµpÁõ∏‰πòÔºõÁü©ÈòµPËΩ¨ÁΩÆÁöÑÂ§ßÂ∞èÊòØd x vÔºõdÊòØËØçÂêëÈáèÁöÑÁª¥Â∫¶ÔºõvÊòØÂ≠óÂÖ∏ÈáåËØçÊ±áÁöÑÊï∞ÈáèÔºõÁªìÊûú‰∏∫x_iÔºõx_iÂ∞±ÊòØ‰∏Ä‰∏™ËØçÂêëÈáèÔºõÂ¶ÇÊûúone-hotÂêëÈáèÁöÑÁ¨¨‰∏âË°å‰∏∫1ÔºõÈÇ£‰πàx_iÂ∞±ÊòØPËΩ¨ÁΩÆÁü©ÈòµÁöÑÁ¨¨‰∏âÂàóÔºàÂÖ∂‰ΩôÂàóÈÉΩ‰∏∫0ÔºâÔºõÊâÄ‰ª•PËΩ¨ÁΩÆÊØè‰∏ÄÂàóÈÉΩÊòØ‰∏Ä‰∏™ËØçÂêëÈáèÔºõÊâÄ‰ª•Áü©ÈòµPÊú¨Ë∫´ÁöÑÊØè‰∏ÄË°åÂ∞±ÊòØ‰∏Ä‰∏™ËØçÂêëÈáèÔºõÂÖ∂Ë°åÊï∞‰∏∫vÔºõÂç≥vocabularyÔºåËØçÊ±áÈáèÔºõÊØè‰∏ÄË°åÂØπÂ∫î‰∏Ä‰∏™ÂçïËØçÔºõÁü©ÈòµÁöÑÂàóÊï∞‰∏∫dÔºõdÊòØÁî®Êà∑ÂÜ≥ÂÆöÁöÑÔºõdÁöÑÂ§ßÂ∞è‰ºöÂÜ≥ÂÆöÊú∫Âô®Â≠¶‰π†Ê®°ÂûãÁöÑË°®Áé∞ÔºõÂ∫îËØ•Áî®xxxÊù•ÈÄâÊã©‰∏Ä‰∏™ÊØîËæÉÂ•ΩÁöÑdÔºõ\nÊàë‰ª¨ÁöÑ‰ªªÂä°ÊòØÁúãËØÑËÆ∫ÊòØÊ≠£Èù¢ÁöÑËøòÊòØË¥üÈù¢ÁöÑÔºõÂèÇÊï∞Áü©ÈòµÊòØ‰ªéËÆ≠ÁªÉÊï∞ÊçÆ‰∏≠Â≠¶‰π†Âá∫Êù•ÁöÑÔºåÊâÄ‰ª•Â≠¶Âá∫Êù•ÁöÑËØçÂêëÈáèÊòØÂ∏¶ÊúâÊÑüÊÉÖËâ≤ÂΩ©ÁöÑÔºõÂÅáËÆæËøô‰∫õËØçÂêëÈáèÈÉΩÊòØ‰∫åÁª¥ÁöÑÔºåÂàôÂèØ‰ª•Âú®Âπ≥Èù¢ÂùêÊ†áÁ≥ª‰∏≠Ê†áÂá∫‰∏ãÈù¢ËØçÂêëÈáè\nkerasÊèê‰æõembeddingÂ±ÇÔºõÁî®Êà∑ÂèØ‰ª•ÊåáÂÆövocabularyÂ§ßÂ∞èÂíådÁöÑÂ§ßÂ∞èÔºõ‰ª•ÂèäÊØè‰∏Ä‰∏™sequenceÁöÑÈïøÂ∫¶ÔºõdÊòØÊ†πÊçÆÁÆóÊ≥ïÈÄâÂá∫Êù•ÁöÑ Âà∞Ëøô‰∏ÄÊ≠•ÔºåÊàë‰ª¨Â∑≤ÁªèÂÆåÊàê‰∫ÜÊñáÊú¨Â§ÑÁêÜÂíåword embedding„ÄÇÊé•‰∏ãÊù•Â∞±ÊòØÁî®Logistic Regression for Binary ClassificationÂÅö‰∫åÂàÜÁ±ªÔºõ\n","permalink":"http://localhost:1313/posts/nlp-2/","summary":"\u003ch3 id=\"text-to-sequence\"\u003eText to Sequence\u003c/h3\u003e\n\u003cp\u003eÊñáÊú¨Â§ÑÁêÜ\u003c/p\u003e\n\u003cp\u003eStep1: Tokenization\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\n\u003cp\u003eTokenization breaks a piece of text down into a list of tokens.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003eHere, a token is a word. (A token can be a character in some applications.)\u003c/p\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003eTokenizationËÆ≤Á©∂ÂæàÂ§öÔºå‰æãÂ¶ÇÊòØÂê¶Â∫îËØ•ÊääÂ§ßÂÜôÊîπÊàêÂ∞èÂÜôÂë¢ÔºüËøõË°åtypo correctionÁ≠âÁ≠â\u003c/p\u003e\n\u003cp\u003e\u003cimg alt=\"image-20250322150322238\" loading=\"lazy\" src=\"./NLP-2.assets/image-20250322150322238.png\"\u003e\u003c/p\u003e\n\u003cp\u003eStep2: Build Dictionary\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\n\u003cp\u003eUse a dictionary (hash table) to count word frequencies.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003eThe dictionary maps word to index.\u003c/p\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003eÂèØ‰ª•È¶ñÂÖàÁªüËÆ°ËØçÈ¢ëÂéªÊéâ‰ΩéÈ¢ëËØçÔºåÁÑ∂ÂêéËÆ©ÊØè‰∏™ËØçÂØπÂ∫î‰∏Ä‰∏™Ê≠£Êï¥Êï∞ÔºõËøôÊ†∑ÁöÑËØùÔºå‰∏ÄÂè•ËØùÂ∞±ÂèØ‰ª•Áî®‰∏Ä‰∏™Ê≠£Êï¥Êï∞ÂàóË°®Ë°®Á§∫ÔºåËøô‰∏™ÂàóË°®Â∞±Âè´sequenceÔºõÂ¶ÇÊûúÂøÖË¶ÅÂ∞±ËøòÂæóÂÅöone-hot encoding„ÄÇ\u003cimg alt=\"image-20250322150620890\" loading=\"lazy\" src=\"./NLP-2.assets/image-20250322150620890.png\"\u003e\u003c/p\u003e\n\u003cp\u003eÁªìÊûú\u003c/p\u003e\n\u003cp\u003e\u003cimg alt=\"image-20250322150754528\" loading=\"lazy\" src=\"./NLP-2.assets/image-20250322150754528.png\"\u003e\u003c/p\u003e\n\u003cp\u003e‰ΩÜÊòØÈïøÂ∫¶‰∏çÁªü‰∏Ä\u003c/p\u003e\n\u003cp\u003eStep4: ÂØπÈΩêsequence\u003c/p\u003e\n\u003cp\u003e\u003cimg alt=\"image-20250322150854986\" loading=\"lazy\" src=\"./NLP-2.assets/image-20250322150854986.png\"\u003e\u003c/p\u003e\n\u003cp\u003eËß£ÂÜ≥ÊñπÊ°àÊòØËøôÊ†∑ÁöÑÔºöÂèØ‰ª•Âõ∫ÂÆöÈïøÂ∫¶‰∏∫wÔºåÂä†ÂÖ•‰∏Ä‰∏™Â∫èÂàóÈïøÂ∫¶Â§™ÈïøÔºåÂ∞±Á†çÊéâÂâçÈù¢ÁöÑËØçÔºåÂè™‰øùÁïôÊúÄÂêéw‰∏™ËØçÔºõÂ¶ÇÊûú‰∏Ä‰∏™Â∫èÂàóÂ§™Áü≠ÔºåÂ∞±ÂÅözero paddingÔºåÁî®0Â°´ÂÖÖ\u003c/p\u003e\n\u003cp\u003e\u003cimg alt=\"image-20250322151030119\" loading=\"lazy\" src=\"./NLP-2.assets/image-20250322151030119.png\"\u003e\u003c/p\u003e\n\u003cp\u003eËøôÊ†∑‰∏ÄÊù•ÔºåÊâÄÊúâÁöÑÂ∫èÂàóÈïøÂ∫¶Â∞±Áªü‰∏Ä‰∫Ü\u003c/p\u003e\n\u003cp\u003e\u003cimg alt=\"image-20250322151117125\" loading=\"lazy\" src=\"./NLP-2.assets/image-20250322151117125.png\"\u003e\u003c/p\u003e\n\u003cp\u003eÊñáÊú¨Â§ÑÁêÜÂÆåÊàê‰∫ÜÔºåÊé•‰∏ãÊù•ÊòØword embeddingÔºåÊääÂçïËØçË°®Á§∫‰∏∫‰∏Ä‰∏™‰ΩéÁª¥ÂêëÈáèÔºõ\u003c/p\u003e\n\u003cp\u003e\u003cimg alt=\"image-20250322151252837\" loading=\"lazy\" src=\"./NLP-2.assets/image-20250322151252837.png\"\u003e\u003c/p\u003e","title":""},{"content":"üëã About me Hello! I\u0026rsquo;m Xu Zongsi, a passionate technology enthusiast currently pursuing my Master of Science in ECIC at The University of Hong Kong. With a solid background in Software Engineering from the Beijing Institute of Technology, I specialize in artificial intelligence areas like machine learning, deep learning, natural language processing, computer vision, and reinforcement learning.\nInspired by OpenAI\u0026rsquo;s five-step plan towards superintelligence, I am excited about AGI and have developed a keen interest in LLM agents, MLLM, and knowledge graphs. I see great potential in these fields and aspire to contribute to innovative solutions.\nüìö Education üá≠üá∞ The University of Hong Kong 09/2024 - Expected 11/2025 School of Computing and Data Science Master of Science in Electronic Commerce \u0026amp; Internet Computing Relevant Courses: Machine learning for business and e-commerce, Knowledge graphs, Financial fraud analytics, Internet infrastructure technologies, Website engineering, Blockchain and cryptocurrency, etc. üá®üá≥ Beijing Institute of Technology 09/2020 - 06/2024 School of Computer Science \u0026amp; Technology Bachelor of Engineering in Software Engineering, last two years GPA: 3.7/4 Relevant Courses: Reinforcement Learning, Deep Learning and Computer Vision, Artificial Intelligence and Robot Ethics, Almost Human: Mind, Brain and Artificial Intelligence, Mathematical Analysis for Engineering, Linear Algebra, Probability and Mathematical Statistics, etc. Skills: Python, Java, common data structures, design patterns, machine learning basics and algorithms, Linux, PyTorch, and some development tools (git, conda, etc.). üèÜ Awards \u0026amp; Honors Beijing Institute of Technology Undergraduate Scholarship (Top 20% of Grade) 06/2023 3rd Prize of China International \u0026#34;Internet \u0026#43;\u0026#34; College Student\u0026#39;s Innovation Competition 08/2022 Bronze Prize of \u0026#34;Challenge Cup\u0026#34; Capital University Entrepreneurship Competition 05/2022 üíº Project Experience üîç Online Transaction Fraud Detection 09/2024 ‚Äì 01/2025 Independent project, supervised by Dr. Vivien Chan Focused on addressing financial fraud in e-commerce to enhance the accuracy of transaction anomaly detection, while independently managing the entire case study that included data preprocessing, feature engineering, model building, evaluation, and results analysis. Effectively resolved class imbalance issues using SMOTE and ROSE techniques. Built various models including Logistic Regression, Random Forest, XGBoost, and LightGBM, ultimately selecting the LightGBM model to achieve a recall rate of 95.45% and an AUC of 99.84%. Wrote efficient and maintainable code, enhancing model training and data processing efficiency through parallel computing and logging. ü§ñ Multi-Model Intelligent Text Keyword Extraction System 08/2023 ‚Äì 09/2023 Group project, supervised by Associate Prof. Xiaolin Zhao Designed and implemented an intelligent text summary system that automatically extracts keywords from article titles and abstracts, enhancing the understanding and summarization of text information. Participated in the planning of the technical route and built a hybrid model combining extractive and generative approaches, utilizing advanced natural language processing techniques including KeyBERT, Sentence Transformer, BERT, and T5 models. Responsible for data preprocessing and tokenization, as well as the end-to-end implementation and training of the T5 model, optimizing the model architecture and hyperparameters, achieving satisfactory results after only 3 epochs of training. Model evaluation results showed that the Rouge-1, Rouge-2, and Rouge-L metrics reached 0.6345, 0.5038, and 0.5282, respectively, in the third epoch, validating the model\u0026rsquo;s effectiveness in the summarization task. üéì Cambridge University Machine Learning Summer Project 07/2023 ‚Äì 08/2023 Group project, supervised by Prof. Pietro Li√≤ Participated in the Cambridge University deep learning summer project, focusing on deep reinforcement learning; explored multi-agent learning algorithms across different environments. Reproduced the Multi-Agent Deep Deterministic Policy Gradient (MADDPG) algorithm in the Simple Adversary environment and studied the effect of agent numbers on convergence speed and stability, finding optimal stability at 21 agents. Designed and implemented comparative experiments inspired by the Rainbow algorithm, assessing target network strategies versus the Double Deep Q-Network (Double DQN). The results demonstrated that Double DQN significantly enhanced convergence speed, optimizing the overall learning process. Co-authored a group project paper on agent numbers and strategies effectiveness in multi-agent systems, achieving a score of 71% in the summer program (the highest in my group) and a \u0026ldquo;First Class\u0026rdquo; classification in the UK grading system. üëÅÔ∏è Deep Learning and Computer Vision Semester Project 09/2022 ‚Äì 12/2022 Independent project, supervised by Associate Prof. Guangyu Gao Designed and implemented a waste classifier using the ResNet model to improve classification accuracy and reduce resource waste. The project also enhanced understanding of transfer learning techniques with ResNet. Collected a dataset of 16 waste categories and preprocessed the images for uniformity and standardization, incorporating data augmentation techniques to enhance the dataset. Conducted experiments using ResNet34 and ResNet50 models through transfer learning, accelerating network convergence by leveraging pretrained weights. During training, techniques such as Batch Normalization and Dropout were applied to mitigate the risk of overfitting. The final model achieved an accuracy of 90% on the training set, while the performance on the test set was 61%, indicating a significant overfitting phenomenon during the training process. üéì Internship ‚öõÔ∏è Beijing Academy of Quantum Information Science 08/2023 ‚Äì 01/2024 Research Intern at Quantum Computation Department Proposed a quantum convolution kernel design based on variational quantum circuits and developed a universal quantum convolution layer, successfully integrating it into classical CNN architectures such as VGG, GoogLeNet, and ResNet. Developed and evaluated various hybrid models, including a simple model named HQCCNN-2, which achieved 84.45% accuracy on the FashionMNIST dataset, surpassing the traditional CNN\u0026rsquo;s 80.72%. This demonstrates the effectiveness of the quantum convolution layer in improving model performance. Tested on a real quantum computer further validated the effectiveness of the hybrid model, demonstrating the viable integration of quantum computing with deep learning, and highlighting the potential for leveraging quantum properties to enhance model performance. üèÖ Competition Experience ü•â China International \u0026#34;Internet \u0026#43;\u0026#34; College Students\u0026#39; Innovation Competition 08/2022 üõ°Ô∏è Zhongke Ushield: Deep Learning-based Face Privacy Protection Authentication System Responsible for constructing a localized facial feature extraction engine based on MobileFaceNet, ensuring feature extraction is completed on end devices (such as mobile phones and cameras), guaranteeing that raw data does not leave the domain and is not stored, thus enhancing user privacy protection while improving recognition efficiency. ü•â \u0026#34;Challenge Cup\u0026#34; Capital University Entrepreneurship Competition 05/2022 üå≥ Smart Orchard Responsible for the development of the fruit detection, ripeness prediction, and pest identification system, using deep convolutional neural network (CNN) technology for intelligent monitoring of crop growth conditions. Applied advanced object detection algorithms such as Faster R-CNN and YOLO to achieve high precision in apple detection and ripeness assessment, with an accuracy rate exceeding 90%, significantly enhancing the intelligence level of orchard management. Built and trained a dedicated dataset containing various pest samples, optimizing pest detection accuracy through data preprocessing (such as image normalization and resizing) and data augmentation techniques (like rotation, flipping, and noise addition), enabling the real-time monitoring system to accurately identify over 80% of pests, providing effective scientific maintenance recommendations to help farmers reduce crop losses. üìã Extracurricular Activities Vice President, Cyber Security Club, Beijing Institute of Technology 09/2021-09/2022 Backbone, Media Center of the Student Union of Beijing Institute of Technology 10/2020-06/2021 üì´ Contact üìß Email: zongsi.xu@outlook.com üëî LinkedIn: Zongsi (Tristan) Xu üíª GitHub: github.com/BaizeXS üìç Location: Hong Kong SAR, China ","permalink":"http://localhost:1313/resume/","summary":"Personal resume of Zongsi (Tristan) Xu","title":"Zongsi (Tristan) Xu"},{"content":"‰∏Ä„ÄÅÊï∞ÂÄºÁâπÂæÅ‰∏éÁ±ªÂà´ÁâπÂæÅ Êï∞ÂÄºÁâπÂæÅ (Numeric Features) ÂÖ∑ÊúâÂèØÂä†ÂáèÁöÑÊÑè‰πâÔºå‰∏îÂ≠òÂú®Â§ßÂ∞èÈ°∫Â∫è„ÄÇ ‰æãÂ≠êÔºöÂπ¥ÈæÑ„ÄÅÊ∏©Â∫¶Á≠â„ÄÇÂèØ‰ª•Áõ¥Êé•‰øùÁïôÂÖ∂Êï¥Êï∞ÊàñÊµÆÁÇπÊï∞ÂΩ¢Âºè‰æõÊ®°Âûã‰ΩøÁî®„ÄÇ Á±ªÂà´ÁâπÂæÅ (Categorical Features) Êï∞ÊçÆÂÄºÁ¶ªÊï£Ôºå‰∏çÂÖ∑Â§á‚ÄúÊï∞ÂÄºÂ§ßÂ∞è‚ÄùÈó¥ÁöÑÂèØÊØîÊÑè‰πâ„ÄÇ ‰æãÂ≠êÔºöÂõΩÁ±çÔºàÁæéÂõΩ/‰∏≠ÂõΩ/Âç∞Â∫¶Á≠âÔºâ„ÄÅÊÄßÂà´ÔºàÁî∑/Â•≥ÔºâÁ≠â„ÄÇ ÈóÆÈ¢òÔºöËã•‰ªÖÁî®Êï¥Êï∞Ë°®Á§∫ÔºàÁæéÂõΩ=1, ‰∏≠ÂõΩ=2ÔºâÔºå‰ºöÂºïÂÖ•ÈîôËØØÁöÑÊï∞ÂÄºËøêÁÆóÂÖ≥Á≥ªÔºåÂ¶Ç ‚ÄúÁæéÂõΩ + ‰∏≠ÂõΩ = Âç∞Â∫¶‚Äù„ÄÇ ‰∫å„ÄÅOne-HotÁºñÁ†ÅÁöÑÂä®Êú∫‰∏éÊµÅÁ®ã ‰∏∫‰ªÄ‰πà‰ΩøÁî®One-Hot\nÈÄöËøáÂ∞ÜÁ±ªÂà´Êò†Â∞Ñ‰∏∫ÂêëÈáèÔºåÈÅøÂÖçÊï¥Êï∞ÁºñÁ†ÅÂºïÂÖ•ÁöÑ‰º™Êï∞ÂÄºÂÖ≥Á≥ª„ÄÇ ÂêåÊó∂‰øùÁïôÂêÑÁßçÂèØËÉΩÁ±ªÂà´ÁöÑ‰ø°ÊÅØÔºå‰∏î‰ªÖÂú®ÂØπÂ∫î‰ΩçÁΩÆ‰∏∫1ÔºåÂÖ∂‰ªñ‰ΩçÁΩÆ‰∏∫0„ÄÇ Âª∫Á´ãÊò†Â∞ÑÔºö‰ªéÁ±ªÂà´Âà∞Á¥¢Âºï\n‰∏∫ÊØè‰∏™Á±ªÂà´ÂàÜÈÖç‰∏Ä‰∏™ÂîØ‰∏ÄÁ¥¢ÂºïÔºåÈÄöÂ∏∏‰ªé1ÂºÄÂßã„ÄÇ È¢ÑÁïôÁ¥¢Âºï0Ë°®Á§∫‚ÄúÊú™Áü•‚ÄùÊàñ‚ÄúÁº∫Â§±‚ÄùÔºåÂØπÂ∫îÂÖ®0ÂêëÈáè„ÄÇ ËΩ¨Êç¢‰∏∫One-HotÂêëÈáè\nËã•Á±ªÂà´ÊÄªÊï∞‰∏∫197ÔºåÂàôÁî®197Áª¥ÂêëÈáèË°®Á§∫„ÄÇ ‰æãÂ≠êÔºöÁæéÂõΩ [1, 0, 0, 0, ‚Ä¶]Ôºå ‰∏≠ÂõΩ [0, 1, 0, 0, ‚Ä¶]„ÄÇ Á§∫‰æãÔºöË°®Á§∫‰∏Ä‰∏™‰∫∫ÁöÑÁâπÂæÅ\nÁâπÂæÅÂåÖÂê´ÔºàÂπ¥ÈæÑ, ÊÄßÂà´, ÂõΩÁ±çÔºåÂÖ∂‰∏≠ÂõΩÁ±ç197ÁßçÔºâ Áª¥Â∫¶ÊÄªÂíåÔºö1Áª¥_age + 1Áª¥_gender + 197Áª¥_nationality = 199Áª¥„ÄÇ ‰æãÂ¶Ç (28, Â•≥, ‰∏≠ÂõΩ) ‚Üí [28, 0, 0, 1, 0, ‚Ä¶, 0]„ÄÇ ‰∏â„ÄÅÊñáÊú¨Êï∞ÊçÆÂ§ÑÁêÜÊµÅÁ®ã ÊñáÊú¨Âú®Ëá™ÁÑ∂ËØ≠Ë®ÄÂ§ÑÁêÜÔºàNLPÔºâ‰∏≠‰Ωú‰∏∫Â∏∏ËßÅÁöÑÂéüÂßãËæìÂÖ•ÔºåÈúÄË¶ÅÊï∞ÂÄºÂåñÊâçËÉΩÈÄÅÂÖ•Ê®°Âûã„ÄÇ‰∏ÄËà¨Ê≠•È™§Â¶Ç‰∏ãÔºö\nÂàÜËØç (Tokenization)\nÂ∞ÜÊñáÊú¨ÊãÜÂàÜ‰∏∫‰∏Ä‰∏™‰∏™ÂçïËØçÔºàTokenÔºâ„ÄÇ ‰æãÂ≠êÔºö\u0026quot;... to be or not to be...\u0026quot; ‚Üí [\u0026quot;...\u0026quot;, \u0026quot;to\u0026quot;, \u0026quot;be\u0026quot;, \u0026quot;or\u0026quot;, \u0026quot;not\u0026quot;, \u0026quot;to\u0026quot;, \u0026quot;be\u0026quot;, \u0026quot;...\u0026quot;]„ÄÇ ÁªüËÆ°ËØçÈ¢ë \u0026amp; ÊûÑÂª∫ËØçÂÖ∏\nËØçÈ¢ëÁªüËÆ° Áî®ÂìàÂ∏åË°®/Â≠óÂÖ∏ËÆ∞ÂΩïÊØè‰∏™ÂçïËØçÂá∫Áé∞Ê¨°Êï∞„ÄÇ ÈÅçÂéÜÊñáÊú¨Êó∂ÔºåËã•ÂçïËØçÂ∞öÊú™ÂÖ•Ë°®ÔºåÂàôÊñ∞Âª∫ËÆ∞ÂΩïÔºõËã•Â∑≤Â≠òÂú®ÔºåÂàôËÆ°Êï∞+1„ÄÇ ÊéíÂ∫è‰∏éÁ¥¢Âºï ÊåâËØçÈ¢ëÈôçÂ∫èÊéíÂ∫èÔºåËØçÈ¢ëÊúÄÈ´òÁöÑÂçïËØçÊéíÂú®ÂâçÈù¢„ÄÇ Á¥¢Âºï‰ªé1ÂºÄÂßãÔºå0ÁïôÁªô‚ÄúÊú™Áü•‚Äù„ÄÇ ËØçÂÖ∏ËßÑÊ®°ÔºàvocabularyÔºâÂèØËßÜÈúÄÊ±ÇÊà™Êñ≠Ôºà‰æãÂ¶ÇÂè™‰øùÁïôTop 10kÔºâ„ÄÇ ‰∏∫‰ªÄ‰πàÁßªÈô§‰ΩéÈ¢ëËØç ‰ΩéÈ¢ëËØçÂèØËÉΩÊòØÊãºÂÜôÈîôËØØ„ÄÅÁΩïËßÅ‰∫∫ÂêçÁ≠âÔºåÂØπÊ®°ÂûãÂ∏ÆÂä©ÊúâÈôê„ÄÇ ÂáèÂ∞ëËØçÂÖ∏ËßÑÊ®°ÂèØÈôç‰ΩéËøêÁÆóÂºÄÈîÄ„ÄÅÂä†Âø´Ê®°ÂûãËÆ≠ÁªÉ‰∏éÊé®ÁêÜÈÄüÂ∫¶„ÄÇ Áã¨ÁÉ≠ÁºñÁ†Å (One-Hot Encoding)\nÂ∞ÜÊØè‰∏™ÂçïËØçÊò†Â∞Ñ‰∏∫ËØçÂÖ∏‰∏≠ÁöÑÁ¥¢ÂºïÂêéÔºàÂ¶Ç [2, 4, 1, 8, ‚Ä¶]ÔºâÔºåÂèØËøõ‰∏ÄÊ≠•ËΩ¨Êç¢ÊàêOne-HotÂêëÈáè„ÄÇ One-HotÁª¥Â∫¶ÂèñÂÜ≥‰∫é‰øùÁïô‰∏ãÊù•ÁöÑËØçÂÖ∏Â§ßÂ∞èÔºà‰æãÂ¶Ç1‰∏áÔºâ„ÄÇ Êú™Êî∂ÂΩïÂçïËØçÂèØËÉΩÁõ¥Êé•ÂøΩÁï•ÔºåÊàñÁªü‰∏ÄÁî®Á¥¢Âºï0‰ª£Êõø„ÄÇ Âõõ„ÄÅÊ†∏ÂøÉÊî∂Ëé∑‰∏éÂ∫îÁî® Á±ªÂà´ÁâπÂæÅÂøÖÈúÄÊï∞ÂÄºÂåñÔºö\n‰ΩøÁî®Êï¥Êï∞1,2,3‚Ä¶‰ªÖË°®Á§∫Á±ªÂà´‚ÄúÊ†áËØÜ‚ÄùÔºåÂπ∂‰∏ç‰ª£Ë°®ÂÆÉ‰ª¨ÂèØËøõË°åÊï∞ÂÄºËøêÁÆó„ÄÇ Âõ†Ê≠§ÈúÄË¶ÅOne-HotÁ≠âÁºñÁ†ÅÊñπÂºèÔºåÈÅøÂÖçÊï∞ÂÄºËØØËß£„ÄÇ ÊñáÊú¨Êï∞ÊçÆÈ¢ÑÂ§ÑÁêÜÔºö\nÂàÜËØç„ÄÅËØçÈ¢ëÁªüËÆ°„ÄÅÊûÑÂª∫ËØçÂÖ∏„ÄÅÁ¥¢ÂºïÂåñ„ÄÅOne-HotÊàñÂÖ∂‰ªñÊñπÂºèÔºàÂ¶ÇËØçÂµåÂÖ•ÔºâÊòØÂ∏∏ËßÅÊµÅÁ®ã„ÄÇ Ê≠£Á°ÆÁöÑÊñáÊú¨È¢ÑÂ§ÑÁêÜÂèØÊòæËëóÂΩ±ÂìçÊ®°ÂûãÊÄßËÉΩÂíåÊïàÁéá„ÄÇ ‰øùÁïôÊú™Áü•Á¥¢ÂºïÔºö\n‰øùËØÅÂØπÁº∫Â§±Êï∞ÊçÆÊàñÂ≠óÂÖ∏Â§ñÊñ∞ËØçËÉΩÊúâÂü∫Êú¨ÁöÑË°®Á§∫ÔºåÊèêÂçáÊ®°ÂûãÂÆπÈîôÊÄß„ÄÇ ÂÆûÈôÖ‰ΩøÁî®Ôºö\nÂØπ‰∫éÂ∞èËßÑÊ®°Á±ªÂà´ÂèØÁõ¥Êé•One-HotÁºñÁ†ÅÔºõÂØπ‰∫éËØçÂÖ∏ÂæàÂ§ßÁöÑÂú∫ÊôØÔºåÈÄöÂ∏∏‰ºöËøõ‰∏ÄÊ≠•ËÄÉËôëËØçÂµåÂÖ•ÔºàWord EmbeddingÔºâÊàñÈ¢ÑËÆ≠ÁªÉËØ≠Ë®ÄÊ®°Âûã„ÄÇ ","permalink":"http://localhost:1313/posts/nlp-1/","summary":"\u003ch2 id=\"‰∏ÄÊï∞ÂÄºÁâπÂæÅ‰∏éÁ±ªÂà´ÁâπÂæÅ\"\u003e‰∏Ä„ÄÅÊï∞ÂÄºÁâπÂæÅ‰∏éÁ±ªÂà´ÁâπÂæÅ\u003c/h2\u003e\n\u003col\u003e\n\u003cli\u003e\u003cstrong\u003eÊï∞ÂÄºÁâπÂæÅ (Numeric Features)\u003c/strong\u003e\n\u003cul\u003e\n\u003cli\u003eÂÖ∑ÊúâÂèØÂä†ÂáèÁöÑÊÑè‰πâÔºå‰∏îÂ≠òÂú®Â§ßÂ∞èÈ°∫Â∫è„ÄÇ\u003c/li\u003e\n\u003cli\u003e‰æãÂ≠êÔºöÂπ¥ÈæÑ„ÄÅÊ∏©Â∫¶Á≠â„ÄÇÂèØ‰ª•Áõ¥Êé•‰øùÁïôÂÖ∂Êï¥Êï∞ÊàñÊµÆÁÇπÊï∞ÂΩ¢Âºè‰æõÊ®°Âûã‰ΩøÁî®„ÄÇ\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003eÁ±ªÂà´ÁâπÂæÅ (Categorical Features)\u003c/strong\u003e\n\u003cul\u003e\n\u003cli\u003eÊï∞ÊçÆÂÄºÁ¶ªÊï£Ôºå‰∏çÂÖ∑Â§á‚ÄúÊï∞ÂÄºÂ§ßÂ∞è‚ÄùÈó¥ÁöÑÂèØÊØîÊÑè‰πâ„ÄÇ\u003c/li\u003e\n\u003cli\u003e‰æãÂ≠êÔºöÂõΩÁ±çÔºàÁæéÂõΩ/‰∏≠ÂõΩ/Âç∞Â∫¶Á≠âÔºâ„ÄÅÊÄßÂà´ÔºàÁî∑/Â•≥ÔºâÁ≠â„ÄÇ\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003eÈóÆÈ¢ò\u003c/strong\u003eÔºöËã•‰ªÖÁî®Êï¥Êï∞Ë°®Á§∫ÔºàÁæéÂõΩ=1, ‰∏≠ÂõΩ=2ÔºâÔºå‰ºöÂºïÂÖ•ÈîôËØØÁöÑÊï∞ÂÄºËøêÁÆóÂÖ≥Á≥ªÔºåÂ¶Ç ‚ÄúÁæéÂõΩ + ‰∏≠ÂõΩ = Âç∞Â∫¶‚Äù„ÄÇ\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003c/ol\u003e\n\u003ch2 id=\"‰∫åone-hotÁºñÁ†ÅÁöÑÂä®Êú∫‰∏éÊµÅÁ®ã\"\u003e‰∫å„ÄÅOne-HotÁºñÁ†ÅÁöÑÂä®Êú∫‰∏éÊµÅÁ®ã\u003c/h2\u003e\n\u003col\u003e\n\u003cli\u003e\n\u003cp\u003e\u003cstrong\u003e‰∏∫‰ªÄ‰πà‰ΩøÁî®One-Hot\u003c/strong\u003e\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eÈÄöËøáÂ∞ÜÁ±ªÂà´Êò†Â∞Ñ‰∏∫ÂêëÈáèÔºåÈÅøÂÖçÊï¥Êï∞ÁºñÁ†ÅÂºïÂÖ•ÁöÑ‰º™Êï∞ÂÄºÂÖ≥Á≥ª„ÄÇ\u003c/li\u003e\n\u003cli\u003eÂêåÊó∂‰øùÁïôÂêÑÁßçÂèØËÉΩÁ±ªÂà´ÁöÑ‰ø°ÊÅØÔºå‰∏î‰ªÖÂú®ÂØπÂ∫î‰ΩçÁΩÆ‰∏∫1ÔºåÂÖ∂‰ªñ‰ΩçÁΩÆ‰∏∫0„ÄÇ\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003e\u003cstrong\u003eÂª∫Á´ãÊò†Â∞ÑÔºö‰ªéÁ±ªÂà´Âà∞Á¥¢Âºï\u003c/strong\u003e\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e‰∏∫ÊØè‰∏™Á±ªÂà´ÂàÜÈÖç‰∏Ä‰∏™ÂîØ‰∏ÄÁ¥¢ÂºïÔºåÈÄöÂ∏∏‰ªé1ÂºÄÂßã„ÄÇ\u003c/li\u003e\n\u003cli\u003eÈ¢ÑÁïôÁ¥¢Âºï0Ë°®Á§∫‚ÄúÊú™Áü•‚ÄùÊàñ‚ÄúÁº∫Â§±‚ÄùÔºåÂØπÂ∫îÂÖ®0ÂêëÈáè„ÄÇ\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003e\u003cstrong\u003eËΩ¨Êç¢‰∏∫One-HotÂêëÈáè\u003c/strong\u003e\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eËã•Á±ªÂà´ÊÄªÊï∞‰∏∫197ÔºåÂàôÁî®197Áª¥ÂêëÈáèË°®Á§∫„ÄÇ\u003c/li\u003e\n\u003cli\u003e‰æãÂ≠êÔºöÁæéÂõΩ \u003ccode\u003e[1, 0, 0, 0, ‚Ä¶]\u003c/code\u003eÔºå ‰∏≠ÂõΩ \u003ccode\u003e[0, 1, 0, 0, ‚Ä¶]\u003c/code\u003e„ÄÇ\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003e\u003cstrong\u003eÁ§∫‰æãÔºöË°®Á§∫‰∏Ä‰∏™‰∫∫ÁöÑÁâπÂæÅ\u003c/strong\u003e\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eÁâπÂæÅÂåÖÂê´ÔºàÂπ¥ÈæÑ, ÊÄßÂà´, ÂõΩÁ±çÔºåÂÖ∂‰∏≠ÂõΩÁ±ç197ÁßçÔºâ\u003c/li\u003e\n\u003cli\u003eÁª¥Â∫¶ÊÄªÂíåÔºö1Áª¥_age + 1Áª¥_gender + 197Áª¥_nationality = 199Áª¥„ÄÇ\u003c/li\u003e\n\u003cli\u003e‰æãÂ¶Ç \u003ccode\u003e(28, Â•≥, ‰∏≠ÂõΩ)\u003c/code\u003e ‚Üí \u003ccode\u003e[28, 0, 0, 1, 0, ‚Ä¶, 0]\u003c/code\u003e„ÄÇ\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003c/ol\u003e\n\u003ch2 id=\"‰∏âÊñáÊú¨Êï∞ÊçÆÂ§ÑÁêÜÊµÅÁ®ã\"\u003e‰∏â„ÄÅÊñáÊú¨Êï∞ÊçÆÂ§ÑÁêÜÊµÅÁ®ã\u003c/h2\u003e\n\u003cp\u003eÊñáÊú¨Âú®Ëá™ÁÑ∂ËØ≠Ë®ÄÂ§ÑÁêÜÔºàNLPÔºâ‰∏≠‰Ωú‰∏∫Â∏∏ËßÅÁöÑÂéüÂßãËæìÂÖ•ÔºåÈúÄË¶ÅÊï∞ÂÄºÂåñÊâçËÉΩÈÄÅÂÖ•Ê®°Âûã„ÄÇ‰∏ÄËà¨Ê≠•È™§Â¶Ç‰∏ãÔºö\u003c/p\u003e\n\u003col\u003e\n\u003cli\u003e\n\u003cp\u003e\u003cstrong\u003eÂàÜËØç (Tokenization)\u003c/strong\u003e\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eÂ∞ÜÊñáÊú¨ÊãÜÂàÜ‰∏∫‰∏Ä‰∏™‰∏™ÂçïËØçÔºàTokenÔºâ„ÄÇ\u003c/li\u003e\n\u003cli\u003e‰æãÂ≠êÔºö\u003ccode\u003e\u0026quot;... to be or not to be...\u0026quot;\u003c/code\u003e ‚Üí \u003ccode\u003e[\u0026quot;...\u0026quot;, \u0026quot;to\u0026quot;, \u0026quot;be\u0026quot;, \u0026quot;or\u0026quot;, \u0026quot;not\u0026quot;, \u0026quot;to\u0026quot;, \u0026quot;be\u0026quot;, \u0026quot;...\u0026quot;]\u003c/code\u003e„ÄÇ\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003e\u003cstrong\u003eÁªüËÆ°ËØçÈ¢ë \u0026amp; ÊûÑÂª∫ËØçÂÖ∏\u003c/strong\u003e\u003c/p\u003e","title":""},{"content":"Text to Sequence ÊñáÊú¨Â§ÑÁêÜ\nStep1: Tokenization\nTokenization breaks a piece of text down into a list of tokens.\nHere, a token is a word. (A token can be a character in some applications.)\nTokenizationËÆ≤Á©∂ÂæàÂ§öÔºå‰æãÂ¶ÇÊòØÂê¶Â∫îËØ•ÊääÂ§ßÂÜôÊîπÊàêÂ∞èÂÜôÂë¢ÔºüËøõË°åtypo correctionÁ≠âÁ≠â\nStep2: Build Dictionary\nUse a dictionary (hash table) to count word frequencies.\nThe dictionary maps word to index.\nÂèØ‰ª•È¶ñÂÖàÁªüËÆ°ËØçÈ¢ëÂéªÊéâ‰ΩéÈ¢ëËØçÔºåÁÑ∂ÂêéËÆ©ÊØè‰∏™ËØçÂØπÂ∫î‰∏Ä‰∏™Ê≠£Êï¥Êï∞ÔºõËøôÊ†∑ÁöÑËØùÔºå‰∏ÄÂè•ËØùÂ∞±ÂèØ‰ª•Áî®‰∏Ä‰∏™Ê≠£Êï¥Êï∞ÂàóË°®Ë°®Á§∫ÔºåËøô‰∏™ÂàóË°®Â∞±Âè´sequenceÔºõÂ¶ÇÊûúÂøÖË¶ÅÂ∞±ËøòÂæóÂÅöone-hot encoding„ÄÇ\nÁªìÊûú\n‰ΩÜÊòØÈïøÂ∫¶‰∏çÁªü‰∏Ä\nStep4: ÂØπÈΩêsequence\nËß£ÂÜ≥ÊñπÊ°àÊòØËøôÊ†∑ÁöÑÔºöÂèØ‰ª•Âõ∫ÂÆöÈïøÂ∫¶‰∏∫wÔºåÂä†ÂÖ•‰∏Ä‰∏™Â∫èÂàóÈïøÂ∫¶Â§™ÈïøÔºåÂ∞±Á†çÊéâÂâçÈù¢ÁöÑËØçÔºåÂè™‰øùÁïôÊúÄÂêéw‰∏™ËØçÔºõÂ¶ÇÊûú‰∏Ä‰∏™Â∫èÂàóÂ§™Áü≠ÔºåÂ∞±ÂÅözero paddingÔºåÁî®0Â°´ÂÖÖ\nËøôÊ†∑‰∏ÄÊù•ÔºåÊâÄÊúâÁöÑÂ∫èÂàóÈïøÂ∫¶Â∞±Áªü‰∏Ä‰∫Ü\nÊñáÊú¨Â§ÑÁêÜÂÆåÊàê‰∫ÜÔºåÊé•‰∏ãÊù•ÊòØword embeddingÔºåÊääÂçïËØçË°®Á§∫‰∏∫‰∏Ä‰∏™‰ΩéÁª¥ÂêëÈáèÔºõ\nÁÑ∂ËÄåËøôÊ†∑ÂÅöÁöÑËØùÔºåÂ¶ÇÊûúÊòØ10000‰∏™ÂçïËØçÔºåÁª¥Â∫¶Â∞±ÊòØ10000Áª¥ÔºåÁª¥Â∫¶Â§™È´ò‰∫ÜÔºõÂõ†Ê≠§Ë¶ÅÂÅöword embeddingÔºõ\nÂÖ∑‰ΩìÂÅöÊ≥ïÂ∞±ÊòØÊääone-hotÂêëÈáèe_iÂíåÂèÇÊï∞Áü©ÈòµpÁõ∏‰πòÔºõÁü©ÈòµPËΩ¨ÁΩÆÁöÑÂ§ßÂ∞èÊòØd x vÔºõdÊòØËØçÂêëÈáèÁöÑÁª¥Â∫¶ÔºõvÊòØÂ≠óÂÖ∏ÈáåËØçÊ±áÁöÑÊï∞ÈáèÔºõÁªìÊûú‰∏∫x_iÔºõx_iÂ∞±ÊòØ‰∏Ä‰∏™ËØçÂêëÈáèÔºõÂ¶ÇÊûúone-hotÂêëÈáèÁöÑÁ¨¨‰∏âË°å‰∏∫1ÔºõÈÇ£‰πàx_iÂ∞±ÊòØPËΩ¨ÁΩÆÁü©ÈòµÁöÑÁ¨¨‰∏âÂàóÔºàÂÖ∂‰ΩôÂàóÈÉΩ‰∏∫0ÔºâÔºõÊâÄ‰ª•PËΩ¨ÁΩÆÊØè‰∏ÄÂàóÈÉΩÊòØ‰∏Ä‰∏™ËØçÂêëÈáèÔºõÊâÄ‰ª•Áü©ÈòµPÊú¨Ë∫´ÁöÑÊØè‰∏ÄË°åÂ∞±ÊòØ‰∏Ä‰∏™ËØçÂêëÈáèÔºõÂÖ∂Ë°åÊï∞‰∏∫vÔºõÂç≥vocabularyÔºåËØçÊ±áÈáèÔºõÊØè‰∏ÄË°åÂØπÂ∫î‰∏Ä‰∏™ÂçïËØçÔºõÁü©ÈòµÁöÑÂàóÊï∞‰∏∫dÔºõdÊòØÁî®Êà∑ÂÜ≥ÂÆöÁöÑÔºõdÁöÑÂ§ßÂ∞è‰ºöÂÜ≥ÂÆöÊú∫Âô®Â≠¶‰π†Ê®°ÂûãÁöÑË°®Áé∞ÔºõÂ∫îËØ•Áî®xxxÊù•ÈÄâÊã©‰∏Ä‰∏™ÊØîËæÉÂ•ΩÁöÑdÔºõ\nÊàë‰ª¨ÁöÑ‰ªªÂä°ÊòØÁúãËØÑËÆ∫ÊòØÊ≠£Èù¢ÁöÑËøòÊòØË¥üÈù¢ÁöÑÔºõÂèÇÊï∞Áü©ÈòµÊòØ‰ªéËÆ≠ÁªÉÊï∞ÊçÆ‰∏≠Â≠¶‰π†Âá∫Êù•ÁöÑÔºåÊâÄ‰ª•Â≠¶Âá∫Êù•ÁöÑËØçÂêëÈáèÊòØÂ∏¶ÊúâÊÑüÊÉÖËâ≤ÂΩ©ÁöÑÔºõÂÅáËÆæËøô‰∫õËØçÂêëÈáèÈÉΩÊòØ‰∫åÁª¥ÁöÑÔºåÂàôÂèØ‰ª•Âú®Âπ≥Èù¢ÂùêÊ†áÁ≥ª‰∏≠Ê†áÂá∫‰∏ãÈù¢ËØçÂêëÈáè\nkerasÊèê‰æõembeddingÂ±ÇÔºõÁî®Êà∑ÂèØ‰ª•ÊåáÂÆövocabularyÂ§ßÂ∞èÂíådÁöÑÂ§ßÂ∞èÔºõ‰ª•ÂèäÊØè‰∏Ä‰∏™sequenceÁöÑÈïøÂ∫¶ÔºõdÊòØÊ†πÊçÆÁÆóÊ≥ïÈÄâÂá∫Êù•ÁöÑ Âà∞Ëøô‰∏ÄÊ≠•ÔºåÊàë‰ª¨Â∑≤ÁªèÂÆåÊàê‰∫ÜÊñáÊú¨Â§ÑÁêÜÂíåword embedding„ÄÇÊé•‰∏ãÊù•Â∞±ÊòØÁî®Logistic Regression for Binary ClassificationÂÅö‰∫åÂàÜÁ±ªÔºõ\n","permalink":"http://localhost:1313/posts/nlp-2/","summary":"\u003ch3 id=\"text-to-sequence\"\u003eText to Sequence\u003c/h3\u003e\n\u003cp\u003eÊñáÊú¨Â§ÑÁêÜ\u003c/p\u003e\n\u003cp\u003eStep1: Tokenization\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\n\u003cp\u003eTokenization breaks a piece of text down into a list of tokens.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003eHere, a token is a word. (A token can be a character in some applications.)\u003c/p\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003eTokenizationËÆ≤Á©∂ÂæàÂ§öÔºå‰æãÂ¶ÇÊòØÂê¶Â∫îËØ•ÊääÂ§ßÂÜôÊîπÊàêÂ∞èÂÜôÂë¢ÔºüËøõË°åtypo correctionÁ≠âÁ≠â\u003c/p\u003e\n\u003cp\u003e\u003cimg alt=\"image-20250322150322238\" loading=\"lazy\" src=\"./NLP-2.assets/image-20250322150322238.png\"\u003e\u003c/p\u003e\n\u003cp\u003eStep2: Build Dictionary\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\n\u003cp\u003eUse a dictionary (hash table) to count word frequencies.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003eThe dictionary maps word to index.\u003c/p\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003eÂèØ‰ª•È¶ñÂÖàÁªüËÆ°ËØçÈ¢ëÂéªÊéâ‰ΩéÈ¢ëËØçÔºåÁÑ∂ÂêéËÆ©ÊØè‰∏™ËØçÂØπÂ∫î‰∏Ä‰∏™Ê≠£Êï¥Êï∞ÔºõËøôÊ†∑ÁöÑËØùÔºå‰∏ÄÂè•ËØùÂ∞±ÂèØ‰ª•Áî®‰∏Ä‰∏™Ê≠£Êï¥Êï∞ÂàóË°®Ë°®Á§∫ÔºåËøô‰∏™ÂàóË°®Â∞±Âè´sequenceÔºõÂ¶ÇÊûúÂøÖË¶ÅÂ∞±ËøòÂæóÂÅöone-hot encoding„ÄÇ\u003cimg alt=\"image-20250322150620890\" loading=\"lazy\" src=\"./NLP-2.assets/image-20250322150620890.png\"\u003e\u003c/p\u003e\n\u003cp\u003eÁªìÊûú\u003c/p\u003e\n\u003cp\u003e\u003cimg alt=\"image-20250322150754528\" loading=\"lazy\" src=\"./NLP-2.assets/image-20250322150754528.png\"\u003e\u003c/p\u003e\n\u003cp\u003e‰ΩÜÊòØÈïøÂ∫¶‰∏çÁªü‰∏Ä\u003c/p\u003e\n\u003cp\u003eStep4: ÂØπÈΩêsequence\u003c/p\u003e\n\u003cp\u003e\u003cimg alt=\"image-20250322150854986\" loading=\"lazy\" src=\"./NLP-2.assets/image-20250322150854986.png\"\u003e\u003c/p\u003e\n\u003cp\u003eËß£ÂÜ≥ÊñπÊ°àÊòØËøôÊ†∑ÁöÑÔºöÂèØ‰ª•Âõ∫ÂÆöÈïøÂ∫¶‰∏∫wÔºåÂä†ÂÖ•‰∏Ä‰∏™Â∫èÂàóÈïøÂ∫¶Â§™ÈïøÔºåÂ∞±Á†çÊéâÂâçÈù¢ÁöÑËØçÔºåÂè™‰øùÁïôÊúÄÂêéw‰∏™ËØçÔºõÂ¶ÇÊûú‰∏Ä‰∏™Â∫èÂàóÂ§™Áü≠ÔºåÂ∞±ÂÅözero paddingÔºåÁî®0Â°´ÂÖÖ\u003c/p\u003e\n\u003cp\u003e\u003cimg alt=\"image-20250322151030119\" loading=\"lazy\" src=\"./NLP-2.assets/image-20250322151030119.png\"\u003e\u003c/p\u003e\n\u003cp\u003eËøôÊ†∑‰∏ÄÊù•ÔºåÊâÄÊúâÁöÑÂ∫èÂàóÈïøÂ∫¶Â∞±Áªü‰∏Ä‰∫Ü\u003c/p\u003e\n\u003cp\u003e\u003cimg alt=\"image-20250322151117125\" loading=\"lazy\" src=\"./NLP-2.assets/image-20250322151117125.png\"\u003e\u003c/p\u003e\n\u003cp\u003eÊñáÊú¨Â§ÑÁêÜÂÆåÊàê‰∫ÜÔºåÊé•‰∏ãÊù•ÊòØword embeddingÔºåÊääÂçïËØçË°®Á§∫‰∏∫‰∏Ä‰∏™‰ΩéÁª¥ÂêëÈáèÔºõ\u003c/p\u003e\n\u003cp\u003e\u003cimg alt=\"image-20250322151252837\" loading=\"lazy\" src=\"./NLP-2.assets/image-20250322151252837.png\"\u003e\u003c/p\u003e","title":""},{"content":"üëã About me Hello! I\u0026rsquo;m Xu Zongsi, a passionate technology enthusiast currently pursuing my Master of Science in ECIC at The University of Hong Kong. With a solid background in Software Engineering from the Beijing Institute of Technology, I specialize in artificial intelligence areas like machine learning, deep learning, natural language processing, computer vision, and reinforcement learning.\nInspired by OpenAI\u0026rsquo;s five-step plan towards superintelligence, I am excited about AGI and have developed a keen interest in LLM agents, MLLM, and knowledge graphs. I see great potential in these fields and aspire to contribute to innovative solutions.\nüìö Education üá≠üá∞ The University of Hong Kong 09/2024 - Expected 11/2025 School of Computing and Data Science Master of Science in Electronic Commerce \u0026amp; Internet Computing Relevant Courses: Machine learning for business and e-commerce, Knowledge graphs, Financial fraud analytics, Internet infrastructure technologies, Website engineering, Blockchain and cryptocurrency, etc. üá®üá≥ Beijing Institute of Technology 09/2020 - 06/2024 School of Computer Science \u0026amp; Technology Bachelor of Engineering in Software Engineering, last two years GPA: 3.7/4 Relevant Courses: Reinforcement Learning, Deep Learning and Computer Vision, Artificial Intelligence and Robot Ethics, Almost Human: Mind, Brain and Artificial Intelligence, Mathematical Analysis for Engineering, Linear Algebra, Probability and Mathematical Statistics, etc. Skills: Python, Java, common data structures, design patterns, machine learning basics and algorithms, Linux, PyTorch, and some development tools (git, conda, etc.). üèÜ Awards \u0026amp; Honors Beijing Institute of Technology Undergraduate Scholarship (Top 20% of Grade) 06/2023 3rd Prize of China International \u0026#34;Internet \u0026#43;\u0026#34; College Student\u0026#39;s Innovation Competition 08/2022 Bronze Prize of \u0026#34;Challenge Cup\u0026#34; Capital University Entrepreneurship Competition 05/2022 üíº Project Experience üîç Online Transaction Fraud Detection 09/2024 ‚Äì 01/2025 Independent project, supervised by Dr. Vivien Chan Focused on addressing financial fraud in e-commerce to enhance the accuracy of transaction anomaly detection, while independently managing the entire case study that included data preprocessing, feature engineering, model building, evaluation, and results analysis. Effectively resolved class imbalance issues using SMOTE and ROSE techniques. Built various models including Logistic Regression, Random Forest, XGBoost, and LightGBM, ultimately selecting the LightGBM model to achieve a recall rate of 95.45% and an AUC of 99.84%. Wrote efficient and maintainable code, enhancing model training and data processing efficiency through parallel computing and logging. ü§ñ Multi-Model Intelligent Text Keyword Extraction System 08/2023 ‚Äì 09/2023 Group project, supervised by Associate Prof. Xiaolin Zhao Designed and implemented an intelligent text summary system that automatically extracts keywords from article titles and abstracts, enhancing the understanding and summarization of text information. Participated in the planning of the technical route and built a hybrid model combining extractive and generative approaches, utilizing advanced natural language processing techniques including KeyBERT, Sentence Transformer, BERT, and T5 models. Responsible for data preprocessing and tokenization, as well as the end-to-end implementation and training of the T5 model, optimizing the model architecture and hyperparameters, achieving satisfactory results after only 3 epochs of training. Model evaluation results showed that the Rouge-1, Rouge-2, and Rouge-L metrics reached 0.6345, 0.5038, and 0.5282, respectively, in the third epoch, validating the model\u0026rsquo;s effectiveness in the summarization task. üéì Cambridge University Machine Learning Summer Project 07/2023 ‚Äì 08/2023 Group project, supervised by Prof. Pietro Li√≤ Participated in the Cambridge University deep learning summer project, focusing on deep reinforcement learning; explored multi-agent learning algorithms across different environments. Reproduced the Multi-Agent Deep Deterministic Policy Gradient (MADDPG) algorithm in the Simple Adversary environment and studied the effect of agent numbers on convergence speed and stability, finding optimal stability at 21 agents. Designed and implemented comparative experiments inspired by the Rainbow algorithm, assessing target network strategies versus the Double Deep Q-Network (Double DQN). The results demonstrated that Double DQN significantly enhanced convergence speed, optimizing the overall learning process. Co-authored a group project paper on agent numbers and strategies effectiveness in multi-agent systems, achieving a score of 71% in the summer program (the highest in my group) and a \u0026ldquo;First Class\u0026rdquo; classification in the UK grading system. üëÅÔ∏è Deep Learning and Computer Vision Semester Project 09/2022 ‚Äì 12/2022 Independent project, supervised by Associate Prof. Guangyu Gao Designed and implemented a waste classifier using the ResNet model to improve classification accuracy and reduce resource waste. The project also enhanced understanding of transfer learning techniques with ResNet. Collected a dataset of 16 waste categories and preprocessed the images for uniformity and standardization, incorporating data augmentation techniques to enhance the dataset. Conducted experiments using ResNet34 and ResNet50 models through transfer learning, accelerating network convergence by leveraging pretrained weights. During training, techniques such as Batch Normalization and Dropout were applied to mitigate the risk of overfitting. The final model achieved an accuracy of 90% on the training set, while the performance on the test set was 61%, indicating a significant overfitting phenomenon during the training process. üéì Internship ‚öõÔ∏è Beijing Academy of Quantum Information Science 08/2023 ‚Äì 01/2024 Research Intern at Quantum Computation Department Proposed a quantum convolution kernel design based on variational quantum circuits and developed a universal quantum convolution layer, successfully integrating it into classical CNN architectures such as VGG, GoogLeNet, and ResNet. Developed and evaluated various hybrid models, including a simple model named HQCCNN-2, which achieved 84.45% accuracy on the FashionMNIST dataset, surpassing the traditional CNN\u0026rsquo;s 80.72%. This demonstrates the effectiveness of the quantum convolution layer in improving model performance. Tested on a real quantum computer further validated the effectiveness of the hybrid model, demonstrating the viable integration of quantum computing with deep learning, and highlighting the potential for leveraging quantum properties to enhance model performance. üèÖ Competition Experience ü•â China International \u0026#34;Internet \u0026#43;\u0026#34; College Students\u0026#39; Innovation Competition 08/2022 üõ°Ô∏è Zhongke Ushield: Deep Learning-based Face Privacy Protection Authentication System Responsible for constructing a localized facial feature extraction engine based on MobileFaceNet, ensuring feature extraction is completed on end devices (such as mobile phones and cameras), guaranteeing that raw data does not leave the domain and is not stored, thus enhancing user privacy protection while improving recognition efficiency. ü•â \u0026#34;Challenge Cup\u0026#34; Capital University Entrepreneurship Competition 05/2022 üå≥ Smart Orchard Responsible for the development of the fruit detection, ripeness prediction, and pest identification system, using deep convolutional neural network (CNN) technology for intelligent monitoring of crop growth conditions. Applied advanced object detection algorithms such as Faster R-CNN and YOLO to achieve high precision in apple detection and ripeness assessment, with an accuracy rate exceeding 90%, significantly enhancing the intelligence level of orchard management. Built and trained a dedicated dataset containing various pest samples, optimizing pest detection accuracy through data preprocessing (such as image normalization and resizing) and data augmentation techniques (like rotation, flipping, and noise addition), enabling the real-time monitoring system to accurately identify over 80% of pests, providing effective scientific maintenance recommendations to help farmers reduce crop losses. üìã Extracurricular Activities Vice President, Cyber Security Club, Beijing Institute of Technology 09/2021-09/2022 Backbone, Media Center of the Student Union of Beijing Institute of Technology 10/2020-06/2021 üì´ Contact üìß Email: zongsi.xu@outlook.com üëî LinkedIn: Zongsi (Tristan) Xu üíª GitHub: github.com/BaizeXS üìç Location: Hong Kong SAR, China ","permalink":"http://localhost:1313/resume/","summary":"Personal resume of Zongsi (Tristan) Xu","title":"Zongsi (Tristan) Xu"},{"content":"‰∏Ä„ÄÅÊï∞ÂÄºÁâπÂæÅ‰∏éÁ±ªÂà´ÁâπÂæÅ Êï∞ÂÄºÁâπÂæÅ (Numeric Features) ÂÖ∑ÊúâÂèØÂä†ÂáèÁöÑÊÑè‰πâÔºå‰∏îÂ≠òÂú®Â§ßÂ∞èÈ°∫Â∫è„ÄÇ ‰æãÂ≠êÔºöÂπ¥ÈæÑ„ÄÅÊ∏©Â∫¶Á≠â„ÄÇÂèØ‰ª•Áõ¥Êé•‰øùÁïôÂÖ∂Êï¥Êï∞ÊàñÊµÆÁÇπÊï∞ÂΩ¢Âºè‰æõÊ®°Âûã‰ΩøÁî®„ÄÇ Á±ªÂà´ÁâπÂæÅ (Categorical Features) Êï∞ÊçÆÂÄºÁ¶ªÊï£Ôºå‰∏çÂÖ∑Â§á‚ÄúÊï∞ÂÄºÂ§ßÂ∞è‚ÄùÈó¥ÁöÑÂèØÊØîÊÑè‰πâ„ÄÇ ‰æãÂ≠êÔºöÂõΩÁ±çÔºàÁæéÂõΩ/‰∏≠ÂõΩ/Âç∞Â∫¶Á≠âÔºâ„ÄÅÊÄßÂà´ÔºàÁî∑/Â•≥ÔºâÁ≠â„ÄÇ ÈóÆÈ¢òÔºöËã•‰ªÖÁî®Êï¥Êï∞Ë°®Á§∫ÔºàÁæéÂõΩ=1, ‰∏≠ÂõΩ=2ÔºâÔºå‰ºöÂºïÂÖ•ÈîôËØØÁöÑÊï∞ÂÄºËøêÁÆóÂÖ≥Á≥ªÔºåÂ¶Ç ‚ÄúÁæéÂõΩ + ‰∏≠ÂõΩ = Âç∞Â∫¶‚Äù„ÄÇ ‰∫å„ÄÅOne-HotÁºñÁ†ÅÁöÑÂä®Êú∫‰∏éÊµÅÁ®ã ‰∏∫‰ªÄ‰πà‰ΩøÁî®One-Hot\nÈÄöËøáÂ∞ÜÁ±ªÂà´Êò†Â∞Ñ‰∏∫ÂêëÈáèÔºåÈÅøÂÖçÊï¥Êï∞ÁºñÁ†ÅÂºïÂÖ•ÁöÑ‰º™Êï∞ÂÄºÂÖ≥Á≥ª„ÄÇ ÂêåÊó∂‰øùÁïôÂêÑÁßçÂèØËÉΩÁ±ªÂà´ÁöÑ‰ø°ÊÅØÔºå‰∏î‰ªÖÂú®ÂØπÂ∫î‰ΩçÁΩÆ‰∏∫1ÔºåÂÖ∂‰ªñ‰ΩçÁΩÆ‰∏∫0„ÄÇ Âª∫Á´ãÊò†Â∞ÑÔºö‰ªéÁ±ªÂà´Âà∞Á¥¢Âºï\n‰∏∫ÊØè‰∏™Á±ªÂà´ÂàÜÈÖç‰∏Ä‰∏™ÂîØ‰∏ÄÁ¥¢ÂºïÔºåÈÄöÂ∏∏‰ªé1ÂºÄÂßã„ÄÇ È¢ÑÁïôÁ¥¢Âºï0Ë°®Á§∫‚ÄúÊú™Áü•‚ÄùÊàñ‚ÄúÁº∫Â§±‚ÄùÔºåÂØπÂ∫îÂÖ®0ÂêëÈáè„ÄÇ ËΩ¨Êç¢‰∏∫One-HotÂêëÈáè\nËã•Á±ªÂà´ÊÄªÊï∞‰∏∫197ÔºåÂàôÁî®197Áª¥ÂêëÈáèË°®Á§∫„ÄÇ ‰æãÂ≠êÔºöÁæéÂõΩ [1, 0, 0, 0, ‚Ä¶]Ôºå ‰∏≠ÂõΩ [0, 1, 0, 0, ‚Ä¶]„ÄÇ Á§∫‰æãÔºöË°®Á§∫‰∏Ä‰∏™‰∫∫ÁöÑÁâπÂæÅ\nÁâπÂæÅÂåÖÂê´ÔºàÂπ¥ÈæÑ, ÊÄßÂà´, ÂõΩÁ±çÔºåÂÖ∂‰∏≠ÂõΩÁ±ç197ÁßçÔºâ Áª¥Â∫¶ÊÄªÂíåÔºö1Áª¥_age + 1Áª¥_gender + 197Áª¥_nationality = 199Áª¥„ÄÇ ‰æãÂ¶Ç (28, Â•≥, ‰∏≠ÂõΩ) ‚Üí [28, 0, 0, 1, 0, ‚Ä¶, 0]„ÄÇ ‰∏â„ÄÅÊñáÊú¨Êï∞ÊçÆÂ§ÑÁêÜÊµÅÁ®ã ÊñáÊú¨Âú®Ëá™ÁÑ∂ËØ≠Ë®ÄÂ§ÑÁêÜÔºàNLPÔºâ‰∏≠‰Ωú‰∏∫Â∏∏ËßÅÁöÑÂéüÂßãËæìÂÖ•ÔºåÈúÄË¶ÅÊï∞ÂÄºÂåñÊâçËÉΩÈÄÅÂÖ•Ê®°Âûã„ÄÇ‰∏ÄËà¨Ê≠•È™§Â¶Ç‰∏ãÔºö\nÂàÜËØç (Tokenization)\nÂ∞ÜÊñáÊú¨ÊãÜÂàÜ‰∏∫‰∏Ä‰∏™‰∏™ÂçïËØçÔºàTokenÔºâ„ÄÇ ‰æãÂ≠êÔºö\u0026quot;... to be or not to be...\u0026quot; ‚Üí [\u0026quot;...\u0026quot;, \u0026quot;to\u0026quot;, \u0026quot;be\u0026quot;, \u0026quot;or\u0026quot;, \u0026quot;not\u0026quot;, \u0026quot;to\u0026quot;, \u0026quot;be\u0026quot;, \u0026quot;...\u0026quot;]„ÄÇ ÁªüËÆ°ËØçÈ¢ë \u0026amp; ÊûÑÂª∫ËØçÂÖ∏\nËØçÈ¢ëÁªüËÆ° Áî®ÂìàÂ∏åË°®/Â≠óÂÖ∏ËÆ∞ÂΩïÊØè‰∏™ÂçïËØçÂá∫Áé∞Ê¨°Êï∞„ÄÇ ÈÅçÂéÜÊñáÊú¨Êó∂ÔºåËã•ÂçïËØçÂ∞öÊú™ÂÖ•Ë°®ÔºåÂàôÊñ∞Âª∫ËÆ∞ÂΩïÔºõËã•Â∑≤Â≠òÂú®ÔºåÂàôËÆ°Êï∞+1„ÄÇ ÊéíÂ∫è‰∏éÁ¥¢Âºï ÊåâËØçÈ¢ëÈôçÂ∫èÊéíÂ∫èÔºåËØçÈ¢ëÊúÄÈ´òÁöÑÂçïËØçÊéíÂú®ÂâçÈù¢„ÄÇ Á¥¢Âºï‰ªé1ÂºÄÂßãÔºå0ÁïôÁªô‚ÄúÊú™Áü•‚Äù„ÄÇ ËØçÂÖ∏ËßÑÊ®°ÔºàvocabularyÔºâÂèØËßÜÈúÄÊ±ÇÊà™Êñ≠Ôºà‰æãÂ¶ÇÂè™‰øùÁïôTop 10kÔºâ„ÄÇ ‰∏∫‰ªÄ‰πàÁßªÈô§‰ΩéÈ¢ëËØç ‰ΩéÈ¢ëËØçÂèØËÉΩÊòØÊãºÂÜôÈîôËØØ„ÄÅÁΩïËßÅ‰∫∫ÂêçÁ≠âÔºåÂØπÊ®°ÂûãÂ∏ÆÂä©ÊúâÈôê„ÄÇ ÂáèÂ∞ëËØçÂÖ∏ËßÑÊ®°ÂèØÈôç‰ΩéËøêÁÆóÂºÄÈîÄ„ÄÅÂä†Âø´Ê®°ÂûãËÆ≠ÁªÉ‰∏éÊé®ÁêÜÈÄüÂ∫¶„ÄÇ Áã¨ÁÉ≠ÁºñÁ†Å (One-Hot Encoding)\nÂ∞ÜÊØè‰∏™ÂçïËØçÊò†Â∞Ñ‰∏∫ËØçÂÖ∏‰∏≠ÁöÑÁ¥¢ÂºïÂêéÔºàÂ¶Ç [2, 4, 1, 8, ‚Ä¶]ÔºâÔºåÂèØËøõ‰∏ÄÊ≠•ËΩ¨Êç¢ÊàêOne-HotÂêëÈáè„ÄÇ One-HotÁª¥Â∫¶ÂèñÂÜ≥‰∫é‰øùÁïô‰∏ãÊù•ÁöÑËØçÂÖ∏Â§ßÂ∞èÔºà‰æãÂ¶Ç1‰∏áÔºâ„ÄÇ Êú™Êî∂ÂΩïÂçïËØçÂèØËÉΩÁõ¥Êé•ÂøΩÁï•ÔºåÊàñÁªü‰∏ÄÁî®Á¥¢Âºï0‰ª£Êõø„ÄÇ Âõõ„ÄÅÊ†∏ÂøÉÊî∂Ëé∑‰∏éÂ∫îÁî® Á±ªÂà´ÁâπÂæÅÂøÖÈúÄÊï∞ÂÄºÂåñÔºö\n‰ΩøÁî®Êï¥Êï∞1,2,3‚Ä¶‰ªÖË°®Á§∫Á±ªÂà´‚ÄúÊ†áËØÜ‚ÄùÔºåÂπ∂‰∏ç‰ª£Ë°®ÂÆÉ‰ª¨ÂèØËøõË°åÊï∞ÂÄºËøêÁÆó„ÄÇ Âõ†Ê≠§ÈúÄË¶ÅOne-HotÁ≠âÁºñÁ†ÅÊñπÂºèÔºåÈÅøÂÖçÊï∞ÂÄºËØØËß£„ÄÇ ÊñáÊú¨Êï∞ÊçÆÈ¢ÑÂ§ÑÁêÜÔºö\nÂàÜËØç„ÄÅËØçÈ¢ëÁªüËÆ°„ÄÅÊûÑÂª∫ËØçÂÖ∏„ÄÅÁ¥¢ÂºïÂåñ„ÄÅOne-HotÊàñÂÖ∂‰ªñÊñπÂºèÔºàÂ¶ÇËØçÂµåÂÖ•ÔºâÊòØÂ∏∏ËßÅÊµÅÁ®ã„ÄÇ Ê≠£Á°ÆÁöÑÊñáÊú¨È¢ÑÂ§ÑÁêÜÂèØÊòæËëóÂΩ±ÂìçÊ®°ÂûãÊÄßËÉΩÂíåÊïàÁéá„ÄÇ ‰øùÁïôÊú™Áü•Á¥¢ÂºïÔºö\n‰øùËØÅÂØπÁº∫Â§±Êï∞ÊçÆÊàñÂ≠óÂÖ∏Â§ñÊñ∞ËØçËÉΩÊúâÂü∫Êú¨ÁöÑË°®Á§∫ÔºåÊèêÂçáÊ®°ÂûãÂÆπÈîôÊÄß„ÄÇ ÂÆûÈôÖ‰ΩøÁî®Ôºö\nÂØπ‰∫éÂ∞èËßÑÊ®°Á±ªÂà´ÂèØÁõ¥Êé•One-HotÁºñÁ†ÅÔºõÂØπ‰∫éËØçÂÖ∏ÂæàÂ§ßÁöÑÂú∫ÊôØÔºåÈÄöÂ∏∏‰ºöËøõ‰∏ÄÊ≠•ËÄÉËôëËØçÂµåÂÖ•ÔºàWord EmbeddingÔºâÊàñÈ¢ÑËÆ≠ÁªÉËØ≠Ë®ÄÊ®°Âûã„ÄÇ ","permalink":"http://localhost:1313/posts/nlp-1/","summary":"\u003ch2 id=\"‰∏ÄÊï∞ÂÄºÁâπÂæÅ‰∏éÁ±ªÂà´ÁâπÂæÅ\"\u003e‰∏Ä„ÄÅÊï∞ÂÄºÁâπÂæÅ‰∏éÁ±ªÂà´ÁâπÂæÅ\u003c/h2\u003e\n\u003col\u003e\n\u003cli\u003e\u003cstrong\u003eÊï∞ÂÄºÁâπÂæÅ (Numeric Features)\u003c/strong\u003e\n\u003cul\u003e\n\u003cli\u003eÂÖ∑ÊúâÂèØÂä†ÂáèÁöÑÊÑè‰πâÔºå‰∏îÂ≠òÂú®Â§ßÂ∞èÈ°∫Â∫è„ÄÇ\u003c/li\u003e\n\u003cli\u003e‰æãÂ≠êÔºöÂπ¥ÈæÑ„ÄÅÊ∏©Â∫¶Á≠â„ÄÇÂèØ‰ª•Áõ¥Êé•‰øùÁïôÂÖ∂Êï¥Êï∞ÊàñÊµÆÁÇπÊï∞ÂΩ¢Âºè‰æõÊ®°Âûã‰ΩøÁî®„ÄÇ\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003eÁ±ªÂà´ÁâπÂæÅ (Categorical Features)\u003c/strong\u003e\n\u003cul\u003e\n\u003cli\u003eÊï∞ÊçÆÂÄºÁ¶ªÊï£Ôºå‰∏çÂÖ∑Â§á‚ÄúÊï∞ÂÄºÂ§ßÂ∞è‚ÄùÈó¥ÁöÑÂèØÊØîÊÑè‰πâ„ÄÇ\u003c/li\u003e\n\u003cli\u003e‰æãÂ≠êÔºöÂõΩÁ±çÔºàÁæéÂõΩ/‰∏≠ÂõΩ/Âç∞Â∫¶Á≠âÔºâ„ÄÅÊÄßÂà´ÔºàÁî∑/Â•≥ÔºâÁ≠â„ÄÇ\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003eÈóÆÈ¢ò\u003c/strong\u003eÔºöËã•‰ªÖÁî®Êï¥Êï∞Ë°®Á§∫ÔºàÁæéÂõΩ=1, ‰∏≠ÂõΩ=2ÔºâÔºå‰ºöÂºïÂÖ•ÈîôËØØÁöÑÊï∞ÂÄºËøêÁÆóÂÖ≥Á≥ªÔºåÂ¶Ç ‚ÄúÁæéÂõΩ + ‰∏≠ÂõΩ = Âç∞Â∫¶‚Äù„ÄÇ\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003c/ol\u003e\n\u003ch2 id=\"‰∫åone-hotÁºñÁ†ÅÁöÑÂä®Êú∫‰∏éÊµÅÁ®ã\"\u003e‰∫å„ÄÅOne-HotÁºñÁ†ÅÁöÑÂä®Êú∫‰∏éÊµÅÁ®ã\u003c/h2\u003e\n\u003col\u003e\n\u003cli\u003e\n\u003cp\u003e\u003cstrong\u003e‰∏∫‰ªÄ‰πà‰ΩøÁî®One-Hot\u003c/strong\u003e\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eÈÄöËøáÂ∞ÜÁ±ªÂà´Êò†Â∞Ñ‰∏∫ÂêëÈáèÔºåÈÅøÂÖçÊï¥Êï∞ÁºñÁ†ÅÂºïÂÖ•ÁöÑ‰º™Êï∞ÂÄºÂÖ≥Á≥ª„ÄÇ\u003c/li\u003e\n\u003cli\u003eÂêåÊó∂‰øùÁïôÂêÑÁßçÂèØËÉΩÁ±ªÂà´ÁöÑ‰ø°ÊÅØÔºå‰∏î‰ªÖÂú®ÂØπÂ∫î‰ΩçÁΩÆ‰∏∫1ÔºåÂÖ∂‰ªñ‰ΩçÁΩÆ‰∏∫0„ÄÇ\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003e\u003cstrong\u003eÂª∫Á´ãÊò†Â∞ÑÔºö‰ªéÁ±ªÂà´Âà∞Á¥¢Âºï\u003c/strong\u003e\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e‰∏∫ÊØè‰∏™Á±ªÂà´ÂàÜÈÖç‰∏Ä‰∏™ÂîØ‰∏ÄÁ¥¢ÂºïÔºåÈÄöÂ∏∏‰ªé1ÂºÄÂßã„ÄÇ\u003c/li\u003e\n\u003cli\u003eÈ¢ÑÁïôÁ¥¢Âºï0Ë°®Á§∫‚ÄúÊú™Áü•‚ÄùÊàñ‚ÄúÁº∫Â§±‚ÄùÔºåÂØπÂ∫îÂÖ®0ÂêëÈáè„ÄÇ\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003e\u003cstrong\u003eËΩ¨Êç¢‰∏∫One-HotÂêëÈáè\u003c/strong\u003e\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eËã•Á±ªÂà´ÊÄªÊï∞‰∏∫197ÔºåÂàôÁî®197Áª¥ÂêëÈáèË°®Á§∫„ÄÇ\u003c/li\u003e\n\u003cli\u003e‰æãÂ≠êÔºöÁæéÂõΩ \u003ccode\u003e[1, 0, 0, 0, ‚Ä¶]\u003c/code\u003eÔºå ‰∏≠ÂõΩ \u003ccode\u003e[0, 1, 0, 0, ‚Ä¶]\u003c/code\u003e„ÄÇ\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003e\u003cstrong\u003eÁ§∫‰æãÔºöË°®Á§∫‰∏Ä‰∏™‰∫∫ÁöÑÁâπÂæÅ\u003c/strong\u003e\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eÁâπÂæÅÂåÖÂê´ÔºàÂπ¥ÈæÑ, ÊÄßÂà´, ÂõΩÁ±çÔºåÂÖ∂‰∏≠ÂõΩÁ±ç197ÁßçÔºâ\u003c/li\u003e\n\u003cli\u003eÁª¥Â∫¶ÊÄªÂíåÔºö1Áª¥_age + 1Áª¥_gender + 197Áª¥_nationality = 199Áª¥„ÄÇ\u003c/li\u003e\n\u003cli\u003e‰æãÂ¶Ç \u003ccode\u003e(28, Â•≥, ‰∏≠ÂõΩ)\u003c/code\u003e ‚Üí \u003ccode\u003e[28, 0, 0, 1, 0, ‚Ä¶, 0]\u003c/code\u003e„ÄÇ\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003c/ol\u003e\n\u003ch2 id=\"‰∏âÊñáÊú¨Êï∞ÊçÆÂ§ÑÁêÜÊµÅÁ®ã\"\u003e‰∏â„ÄÅÊñáÊú¨Êï∞ÊçÆÂ§ÑÁêÜÊµÅÁ®ã\u003c/h2\u003e\n\u003cp\u003eÊñáÊú¨Âú®Ëá™ÁÑ∂ËØ≠Ë®ÄÂ§ÑÁêÜÔºàNLPÔºâ‰∏≠‰Ωú‰∏∫Â∏∏ËßÅÁöÑÂéüÂßãËæìÂÖ•ÔºåÈúÄË¶ÅÊï∞ÂÄºÂåñÊâçËÉΩÈÄÅÂÖ•Ê®°Âûã„ÄÇ‰∏ÄËà¨Ê≠•È™§Â¶Ç‰∏ãÔºö\u003c/p\u003e\n\u003col\u003e\n\u003cli\u003e\n\u003cp\u003e\u003cstrong\u003eÂàÜËØç (Tokenization)\u003c/strong\u003e\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eÂ∞ÜÊñáÊú¨ÊãÜÂàÜ‰∏∫‰∏Ä‰∏™‰∏™ÂçïËØçÔºàTokenÔºâ„ÄÇ\u003c/li\u003e\n\u003cli\u003e‰æãÂ≠êÔºö\u003ccode\u003e\u0026quot;... to be or not to be...\u0026quot;\u003c/code\u003e ‚Üí \u003ccode\u003e[\u0026quot;...\u0026quot;, \u0026quot;to\u0026quot;, \u0026quot;be\u0026quot;, \u0026quot;or\u0026quot;, \u0026quot;not\u0026quot;, \u0026quot;to\u0026quot;, \u0026quot;be\u0026quot;, \u0026quot;...\u0026quot;]\u003c/code\u003e„ÄÇ\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003e\u003cstrong\u003eÁªüËÆ°ËØçÈ¢ë \u0026amp; ÊûÑÂª∫ËØçÂÖ∏\u003c/strong\u003e\u003c/p\u003e","title":""},{"content":"Text to Sequence ÊñáÊú¨Â§ÑÁêÜ\nStep1: Tokenization\nTokenization breaks a piece of text down into a list of tokens.\nHere, a token is a word. (A token can be a character in some applications.)\nTokenizationËÆ≤Á©∂ÂæàÂ§öÔºå‰æãÂ¶ÇÊòØÂê¶Â∫îËØ•ÊääÂ§ßÂÜôÊîπÊàêÂ∞èÂÜôÂë¢ÔºüËøõË°åtypo correctionÁ≠âÁ≠â\nStep2: Build Dictionary\nUse a dictionary (hash table) to count word frequencies.\nThe dictionary maps word to index.\nÂèØ‰ª•È¶ñÂÖàÁªüËÆ°ËØçÈ¢ëÂéªÊéâ‰ΩéÈ¢ëËØçÔºåÁÑ∂ÂêéËÆ©ÊØè‰∏™ËØçÂØπÂ∫î‰∏Ä‰∏™Ê≠£Êï¥Êï∞ÔºõËøôÊ†∑ÁöÑËØùÔºå‰∏ÄÂè•ËØùÂ∞±ÂèØ‰ª•Áî®‰∏Ä‰∏™Ê≠£Êï¥Êï∞ÂàóË°®Ë°®Á§∫ÔºåËøô‰∏™ÂàóË°®Â∞±Âè´sequenceÔºõÂ¶ÇÊûúÂøÖË¶ÅÂ∞±ËøòÂæóÂÅöone-hot encoding„ÄÇ\nÁªìÊûú\n‰ΩÜÊòØÈïøÂ∫¶‰∏çÁªü‰∏Ä\nStep4: ÂØπÈΩêsequence\nËß£ÂÜ≥ÊñπÊ°àÊòØËøôÊ†∑ÁöÑÔºöÂèØ‰ª•Âõ∫ÂÆöÈïøÂ∫¶‰∏∫wÔºåÂä†ÂÖ•‰∏Ä‰∏™Â∫èÂàóÈïøÂ∫¶Â§™ÈïøÔºåÂ∞±Á†çÊéâÂâçÈù¢ÁöÑËØçÔºåÂè™‰øùÁïôÊúÄÂêéw‰∏™ËØçÔºõÂ¶ÇÊûú‰∏Ä‰∏™Â∫èÂàóÂ§™Áü≠ÔºåÂ∞±ÂÅözero paddingÔºåÁî®0Â°´ÂÖÖ\nËøôÊ†∑‰∏ÄÊù•ÔºåÊâÄÊúâÁöÑÂ∫èÂàóÈïøÂ∫¶Â∞±Áªü‰∏Ä‰∫Ü\nÊñáÊú¨Â§ÑÁêÜÂÆåÊàê‰∫ÜÔºåÊé•‰∏ãÊù•ÊòØword embeddingÔºåÊääÂçïËØçË°®Á§∫‰∏∫‰∏Ä‰∏™‰ΩéÁª¥ÂêëÈáèÔºõ\nÁÑ∂ËÄåËøôÊ†∑ÂÅöÁöÑËØùÔºåÂ¶ÇÊûúÊòØ10000‰∏™ÂçïËØçÔºåÁª¥Â∫¶Â∞±ÊòØ10000Áª¥ÔºåÁª¥Â∫¶Â§™È´ò‰∫ÜÔºõÂõ†Ê≠§Ë¶ÅÂÅöword embeddingÔºõ\nÂÖ∑‰ΩìÂÅöÊ≥ïÂ∞±ÊòØÊääone-hotÂêëÈáèe_iÂíåÂèÇÊï∞Áü©ÈòµpÁõ∏‰πòÔºõÁü©ÈòµPËΩ¨ÁΩÆÁöÑÂ§ßÂ∞èÊòØd x vÔºõdÊòØËØçÂêëÈáèÁöÑÁª¥Â∫¶ÔºõvÊòØÂ≠óÂÖ∏ÈáåËØçÊ±áÁöÑÊï∞ÈáèÔºõÁªìÊûú‰∏∫x_iÔºõx_iÂ∞±ÊòØ‰∏Ä‰∏™ËØçÂêëÈáèÔºõÂ¶ÇÊûúone-hotÂêëÈáèÁöÑÁ¨¨‰∏âË°å‰∏∫1ÔºõÈÇ£‰πàx_iÂ∞±ÊòØPËΩ¨ÁΩÆÁü©ÈòµÁöÑÁ¨¨‰∏âÂàóÔºàÂÖ∂‰ΩôÂàóÈÉΩ‰∏∫0ÔºâÔºõÊâÄ‰ª•PËΩ¨ÁΩÆÊØè‰∏ÄÂàóÈÉΩÊòØ‰∏Ä‰∏™ËØçÂêëÈáèÔºõÊâÄ‰ª•Áü©ÈòµPÊú¨Ë∫´ÁöÑÊØè‰∏ÄË°åÂ∞±ÊòØ‰∏Ä‰∏™ËØçÂêëÈáèÔºõÂÖ∂Ë°åÊï∞‰∏∫vÔºõÂç≥vocabularyÔºåËØçÊ±áÈáèÔºõÊØè‰∏ÄË°åÂØπÂ∫î‰∏Ä‰∏™ÂçïËØçÔºõÁü©ÈòµÁöÑÂàóÊï∞‰∏∫dÔºõdÊòØÁî®Êà∑ÂÜ≥ÂÆöÁöÑÔºõdÁöÑÂ§ßÂ∞è‰ºöÂÜ≥ÂÆöÊú∫Âô®Â≠¶‰π†Ê®°ÂûãÁöÑË°®Áé∞ÔºõÂ∫îËØ•Áî®xxxÊù•ÈÄâÊã©‰∏Ä‰∏™ÊØîËæÉÂ•ΩÁöÑdÔºõ\nÊàë‰ª¨ÁöÑ‰ªªÂä°ÊòØÁúãËØÑËÆ∫ÊòØÊ≠£Èù¢ÁöÑËøòÊòØË¥üÈù¢ÁöÑÔºõÂèÇÊï∞Áü©ÈòµÊòØ‰ªéËÆ≠ÁªÉÊï∞ÊçÆ‰∏≠Â≠¶‰π†Âá∫Êù•ÁöÑÔºåÊâÄ‰ª•Â≠¶Âá∫Êù•ÁöÑËØçÂêëÈáèÊòØÂ∏¶ÊúâÊÑüÊÉÖËâ≤ÂΩ©ÁöÑÔºõÂÅáËÆæËøô‰∫õËØçÂêëÈáèÈÉΩÊòØ‰∫åÁª¥ÁöÑÔºåÂàôÂèØ‰ª•Âú®Âπ≥Èù¢ÂùêÊ†áÁ≥ª‰∏≠Ê†áÂá∫‰∏ãÈù¢ËØçÂêëÈáè\nkerasÊèê‰æõembeddingÂ±ÇÔºõÁî®Êà∑ÂèØ‰ª•ÊåáÂÆövocabularyÂ§ßÂ∞èÂíådÁöÑÂ§ßÂ∞èÔºõ‰ª•ÂèäÊØè‰∏Ä‰∏™sequenceÁöÑÈïøÂ∫¶ÔºõdÊòØÊ†πÊçÆÁÆóÊ≥ïÈÄâÂá∫Êù•ÁöÑ Âà∞Ëøô‰∏ÄÊ≠•ÔºåÊàë‰ª¨Â∑≤ÁªèÂÆåÊàê‰∫ÜÊñáÊú¨Â§ÑÁêÜÂíåword embedding„ÄÇÊé•‰∏ãÊù•Â∞±ÊòØÁî®Logistic Regression for Binary ClassificationÂÅö‰∫åÂàÜÁ±ªÔºõ\n","permalink":"http://localhost:1313/posts/nlp-2/","summary":"\u003ch3 id=\"text-to-sequence\"\u003eText to Sequence\u003c/h3\u003e\n\u003cp\u003eÊñáÊú¨Â§ÑÁêÜ\u003c/p\u003e\n\u003cp\u003eStep1: Tokenization\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\n\u003cp\u003eTokenization breaks a piece of text down into a list of tokens.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003eHere, a token is a word. (A token can be a character in some applications.)\u003c/p\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003eTokenizationËÆ≤Á©∂ÂæàÂ§öÔºå‰æãÂ¶ÇÊòØÂê¶Â∫îËØ•ÊääÂ§ßÂÜôÊîπÊàêÂ∞èÂÜôÂë¢ÔºüËøõË°åtypo correctionÁ≠âÁ≠â\u003c/p\u003e\n\u003cp\u003e\u003cimg alt=\"image-20250322150322238\" loading=\"lazy\" src=\"./NLP-2.assets/image-20250322150322238.png\"\u003e\u003c/p\u003e\n\u003cp\u003eStep2: Build Dictionary\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\n\u003cp\u003eUse a dictionary (hash table) to count word frequencies.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003eThe dictionary maps word to index.\u003c/p\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003eÂèØ‰ª•È¶ñÂÖàÁªüËÆ°ËØçÈ¢ëÂéªÊéâ‰ΩéÈ¢ëËØçÔºåÁÑ∂ÂêéËÆ©ÊØè‰∏™ËØçÂØπÂ∫î‰∏Ä‰∏™Ê≠£Êï¥Êï∞ÔºõËøôÊ†∑ÁöÑËØùÔºå‰∏ÄÂè•ËØùÂ∞±ÂèØ‰ª•Áî®‰∏Ä‰∏™Ê≠£Êï¥Êï∞ÂàóË°®Ë°®Á§∫ÔºåËøô‰∏™ÂàóË°®Â∞±Âè´sequenceÔºõÂ¶ÇÊûúÂøÖË¶ÅÂ∞±ËøòÂæóÂÅöone-hot encoding„ÄÇ\u003cimg alt=\"image-20250322150620890\" loading=\"lazy\" src=\"./NLP-2.assets/image-20250322150620890.png\"\u003e\u003c/p\u003e\n\u003cp\u003eÁªìÊûú\u003c/p\u003e\n\u003cp\u003e\u003cimg alt=\"image-20250322150754528\" loading=\"lazy\" src=\"./NLP-2.assets/image-20250322150754528.png\"\u003e\u003c/p\u003e\n\u003cp\u003e‰ΩÜÊòØÈïøÂ∫¶‰∏çÁªü‰∏Ä\u003c/p\u003e\n\u003cp\u003eStep4: ÂØπÈΩêsequence\u003c/p\u003e\n\u003cp\u003e\u003cimg alt=\"image-20250322150854986\" loading=\"lazy\" src=\"./NLP-2.assets/image-20250322150854986.png\"\u003e\u003c/p\u003e\n\u003cp\u003eËß£ÂÜ≥ÊñπÊ°àÊòØËøôÊ†∑ÁöÑÔºöÂèØ‰ª•Âõ∫ÂÆöÈïøÂ∫¶‰∏∫wÔºåÂä†ÂÖ•‰∏Ä‰∏™Â∫èÂàóÈïøÂ∫¶Â§™ÈïøÔºåÂ∞±Á†çÊéâÂâçÈù¢ÁöÑËØçÔºåÂè™‰øùÁïôÊúÄÂêéw‰∏™ËØçÔºõÂ¶ÇÊûú‰∏Ä‰∏™Â∫èÂàóÂ§™Áü≠ÔºåÂ∞±ÂÅözero paddingÔºåÁî®0Â°´ÂÖÖ\u003c/p\u003e\n\u003cp\u003e\u003cimg alt=\"image-20250322151030119\" loading=\"lazy\" src=\"./NLP-2.assets/image-20250322151030119.png\"\u003e\u003c/p\u003e\n\u003cp\u003eËøôÊ†∑‰∏ÄÊù•ÔºåÊâÄÊúâÁöÑÂ∫èÂàóÈïøÂ∫¶Â∞±Áªü‰∏Ä‰∫Ü\u003c/p\u003e\n\u003cp\u003e\u003cimg alt=\"image-20250322151117125\" loading=\"lazy\" src=\"./NLP-2.assets/image-20250322151117125.png\"\u003e\u003c/p\u003e\n\u003cp\u003eÊñáÊú¨Â§ÑÁêÜÂÆåÊàê‰∫ÜÔºåÊé•‰∏ãÊù•ÊòØword embeddingÔºåÊääÂçïËØçË°®Á§∫‰∏∫‰∏Ä‰∏™‰ΩéÁª¥ÂêëÈáèÔºõ\u003c/p\u003e\n\u003cp\u003e\u003cimg alt=\"image-20250322151252837\" loading=\"lazy\" src=\"./NLP-2.assets/image-20250322151252837.png\"\u003e\u003c/p\u003e","title":""},{"content":"üëã About me Hello! I\u0026rsquo;m Xu Zongsi, a passionate technology enthusiast currently pursuing my Master of Science in ECIC at The University of Hong Kong. With a solid background in Software Engineering from the Beijing Institute of Technology, I specialize in artificial intelligence areas like machine learning, deep learning, natural language processing, computer vision, and reinforcement learning.\nInspired by OpenAI\u0026rsquo;s five-step plan towards superintelligence, I am excited about AGI and have developed a keen interest in LLM agents, MLLM, and knowledge graphs. I see great potential in these fields and aspire to contribute to innovative solutions.\nüìö Education üá≠üá∞ The University of Hong Kong 09/2024 - Expected 11/2025 School of Computing and Data Science Master of Science in Electronic Commerce \u0026amp; Internet Computing Relevant Courses: Machine learning for business and e-commerce, Knowledge graphs, Financial fraud analytics, Internet infrastructure technologies, Website engineering, Blockchain and cryptocurrency, etc. üá®üá≥ Beijing Institute of Technology 09/2020 - 06/2024 School of Computer Science \u0026amp; Technology Bachelor of Engineering in Software Engineering, last two years GPA: 3.7/4 Relevant Courses: Reinforcement Learning, Deep Learning and Computer Vision, Artificial Intelligence and Robot Ethics, Almost Human: Mind, Brain and Artificial Intelligence, Mathematical Analysis for Engineering, Linear Algebra, Probability and Mathematical Statistics, etc. Skills: Python, Java, common data structures, design patterns, machine learning basics and algorithms, Linux, PyTorch, and some development tools (git, conda, etc.). üèÜ Awards \u0026amp; Honors Beijing Institute of Technology Undergraduate Scholarship (Top 20% of Grade) 06/2023 3rd Prize of China International \u0026#34;Internet \u0026#43;\u0026#34; College Student\u0026#39;s Innovation Competition 08/2022 Bronze Prize of \u0026#34;Challenge Cup\u0026#34; Capital University Entrepreneurship Competition 05/2022 üíº Project Experience üîç Online Transaction Fraud Detection 09/2024 ‚Äì 01/2025 Independent project, supervised by Dr. Vivien Chan Focused on addressing financial fraud in e-commerce to enhance the accuracy of transaction anomaly detection, while independently managing the entire case study that included data preprocessing, feature engineering, model building, evaluation, and results analysis. Effectively resolved class imbalance issues using SMOTE and ROSE techniques. Built various models including Logistic Regression, Random Forest, XGBoost, and LightGBM, ultimately selecting the LightGBM model to achieve a recall rate of 95.45% and an AUC of 99.84%. Wrote efficient and maintainable code, enhancing model training and data processing efficiency through parallel computing and logging. ü§ñ Multi-Model Intelligent Text Keyword Extraction System 08/2023 ‚Äì 09/2023 Group project, supervised by Associate Prof. Xiaolin Zhao Designed and implemented an intelligent text summary system that automatically extracts keywords from article titles and abstracts, enhancing the understanding and summarization of text information. Participated in the planning of the technical route and built a hybrid model combining extractive and generative approaches, utilizing advanced natural language processing techniques including KeyBERT, Sentence Transformer, BERT, and T5 models. Responsible for data preprocessing and tokenization, as well as the end-to-end implementation and training of the T5 model, optimizing the model architecture and hyperparameters, achieving satisfactory results after only 3 epochs of training. Model evaluation results showed that the Rouge-1, Rouge-2, and Rouge-L metrics reached 0.6345, 0.5038, and 0.5282, respectively, in the third epoch, validating the model\u0026rsquo;s effectiveness in the summarization task. üéì Cambridge University Machine Learning Summer Project 07/2023 ‚Äì 08/2023 Group project, supervised by Prof. Pietro Li√≤ Participated in the Cambridge University deep learning summer project, focusing on deep reinforcement learning; explored multi-agent learning algorithms across different environments. Reproduced the Multi-Agent Deep Deterministic Policy Gradient (MADDPG) algorithm in the Simple Adversary environment and studied the effect of agent numbers on convergence speed and stability, finding optimal stability at 21 agents. Designed and implemented comparative experiments inspired by the Rainbow algorithm, assessing target network strategies versus the Double Deep Q-Network (Double DQN). The results demonstrated that Double DQN significantly enhanced convergence speed, optimizing the overall learning process. Co-authored a group project paper on agent numbers and strategies effectiveness in multi-agent systems, achieving a score of 71% in the summer program (the highest in my group) and a \u0026ldquo;First Class\u0026rdquo; classification in the UK grading system. üëÅÔ∏è Deep Learning and Computer Vision Semester Project 09/2022 ‚Äì 12/2022 Independent project, supervised by Associate Prof. Guangyu Gao Designed and implemented a waste classifier using the ResNet model to improve classification accuracy and reduce resource waste. The project also enhanced understanding of transfer learning techniques with ResNet. Collected a dataset of 16 waste categories and preprocessed the images for uniformity and standardization, incorporating data augmentation techniques to enhance the dataset. Conducted experiments using ResNet34 and ResNet50 models through transfer learning, accelerating network convergence by leveraging pretrained weights. During training, techniques such as Batch Normalization and Dropout were applied to mitigate the risk of overfitting. The final model achieved an accuracy of 90% on the training set, while the performance on the test set was 61%, indicating a significant overfitting phenomenon during the training process. üéì Internship ‚öõÔ∏è Beijing Academy of Quantum Information Science 08/2023 ‚Äì 01/2024 Research Intern at Quantum Computation Department Proposed a quantum convolution kernel design based on variational quantum circuits and developed a universal quantum convolution layer, successfully integrating it into classical CNN architectures such as VGG, GoogLeNet, and ResNet. Developed and evaluated various hybrid models, including a simple model named HQCCNN-2, which achieved 84.45% accuracy on the FashionMNIST dataset, surpassing the traditional CNN\u0026rsquo;s 80.72%. This demonstrates the effectiveness of the quantum convolution layer in improving model performance. Tested on a real quantum computer further validated the effectiveness of the hybrid model, demonstrating the viable integration of quantum computing with deep learning, and highlighting the potential for leveraging quantum properties to enhance model performance. üèÖ Competition Experience ü•â China International \u0026#34;Internet \u0026#43;\u0026#34; College Students\u0026#39; Innovation Competition 08/2022 üõ°Ô∏è Zhongke Ushield: Deep Learning-based Face Privacy Protection Authentication System Responsible for constructing a localized facial feature extraction engine based on MobileFaceNet, ensuring feature extraction is completed on end devices (such as mobile phones and cameras), guaranteeing that raw data does not leave the domain and is not stored, thus enhancing user privacy protection while improving recognition efficiency. ü•â \u0026#34;Challenge Cup\u0026#34; Capital University Entrepreneurship Competition 05/2022 üå≥ Smart Orchard Responsible for the development of the fruit detection, ripeness prediction, and pest identification system, using deep convolutional neural network (CNN) technology for intelligent monitoring of crop growth conditions. Applied advanced object detection algorithms such as Faster R-CNN and YOLO to achieve high precision in apple detection and ripeness assessment, with an accuracy rate exceeding 90%, significantly enhancing the intelligence level of orchard management. Built and trained a dedicated dataset containing various pest samples, optimizing pest detection accuracy through data preprocessing (such as image normalization and resizing) and data augmentation techniques (like rotation, flipping, and noise addition), enabling the real-time monitoring system to accurately identify over 80% of pests, providing effective scientific maintenance recommendations to help farmers reduce crop losses. üìã Extracurricular Activities Vice President, Cyber Security Club, Beijing Institute of Technology 09/2021-09/2022 Backbone, Media Center of the Student Union of Beijing Institute of Technology 10/2020-06/2021 üì´ Contact üìß Email: zongsi.xu@outlook.com üëî LinkedIn: Zongsi (Tristan) Xu üíª GitHub: github.com/BaizeXS üìç Location: Hong Kong SAR, China ","permalink":"http://localhost:1313/resume/","summary":"Personal resume of Zongsi (Tristan) Xu","title":"Zongsi (Tristan) Xu"},{"content":"‰∏Ä„ÄÅÊï∞ÂÄºÁâπÂæÅ‰∏éÁ±ªÂà´ÁâπÂæÅ Êï∞ÂÄºÁâπÂæÅ (Numeric Features) ÂÖ∑ÊúâÂèØÂä†ÂáèÁöÑÊÑè‰πâÔºå‰∏îÂ≠òÂú®Â§ßÂ∞èÈ°∫Â∫è„ÄÇ ‰æãÂ≠êÔºöÂπ¥ÈæÑ„ÄÅÊ∏©Â∫¶Á≠â„ÄÇÂèØ‰ª•Áõ¥Êé•‰øùÁïôÂÖ∂Êï¥Êï∞ÊàñÊµÆÁÇπÊï∞ÂΩ¢Âºè‰æõÊ®°Âûã‰ΩøÁî®„ÄÇ Á±ªÂà´ÁâπÂæÅ (Categorical Features) Êï∞ÊçÆÂÄºÁ¶ªÊï£Ôºå‰∏çÂÖ∑Â§á‚ÄúÊï∞ÂÄºÂ§ßÂ∞è‚ÄùÈó¥ÁöÑÂèØÊØîÊÑè‰πâ„ÄÇ ‰æãÂ≠êÔºöÂõΩÁ±çÔºàÁæéÂõΩ/‰∏≠ÂõΩ/Âç∞Â∫¶Á≠âÔºâ„ÄÅÊÄßÂà´ÔºàÁî∑/Â•≥ÔºâÁ≠â„ÄÇ ÈóÆÈ¢òÔºöËã•‰ªÖÁî®Êï¥Êï∞Ë°®Á§∫ÔºàÁæéÂõΩ=1, ‰∏≠ÂõΩ=2ÔºâÔºå‰ºöÂºïÂÖ•ÈîôËØØÁöÑÊï∞ÂÄºËøêÁÆóÂÖ≥Á≥ªÔºåÂ¶Ç ‚ÄúÁæéÂõΩ + ‰∏≠ÂõΩ = Âç∞Â∫¶‚Äù„ÄÇ ‰∫å„ÄÅOne-HotÁºñÁ†ÅÁöÑÂä®Êú∫‰∏éÊµÅÁ®ã ‰∏∫‰ªÄ‰πà‰ΩøÁî®One-Hot\nÈÄöËøáÂ∞ÜÁ±ªÂà´Êò†Â∞Ñ‰∏∫ÂêëÈáèÔºåÈÅøÂÖçÊï¥Êï∞ÁºñÁ†ÅÂºïÂÖ•ÁöÑ‰º™Êï∞ÂÄºÂÖ≥Á≥ª„ÄÇ ÂêåÊó∂‰øùÁïôÂêÑÁßçÂèØËÉΩÁ±ªÂà´ÁöÑ‰ø°ÊÅØÔºå‰∏î‰ªÖÂú®ÂØπÂ∫î‰ΩçÁΩÆ‰∏∫1ÔºåÂÖ∂‰ªñ‰ΩçÁΩÆ‰∏∫0„ÄÇ Âª∫Á´ãÊò†Â∞ÑÔºö‰ªéÁ±ªÂà´Âà∞Á¥¢Âºï\n‰∏∫ÊØè‰∏™Á±ªÂà´ÂàÜÈÖç‰∏Ä‰∏™ÂîØ‰∏ÄÁ¥¢ÂºïÔºåÈÄöÂ∏∏‰ªé1ÂºÄÂßã„ÄÇ È¢ÑÁïôÁ¥¢Âºï0Ë°®Á§∫‚ÄúÊú™Áü•‚ÄùÊàñ‚ÄúÁº∫Â§±‚ÄùÔºåÂØπÂ∫îÂÖ®0ÂêëÈáè„ÄÇ ËΩ¨Êç¢‰∏∫One-HotÂêëÈáè\nËã•Á±ªÂà´ÊÄªÊï∞‰∏∫197ÔºåÂàôÁî®197Áª¥ÂêëÈáèË°®Á§∫„ÄÇ ‰æãÂ≠êÔºöÁæéÂõΩ [1, 0, 0, 0, ‚Ä¶]Ôºå ‰∏≠ÂõΩ [0, 1, 0, 0, ‚Ä¶]„ÄÇ Á§∫‰æãÔºöË°®Á§∫‰∏Ä‰∏™‰∫∫ÁöÑÁâπÂæÅ\nÁâπÂæÅÂåÖÂê´ÔºàÂπ¥ÈæÑ, ÊÄßÂà´, ÂõΩÁ±çÔºåÂÖ∂‰∏≠ÂõΩÁ±ç197ÁßçÔºâ Áª¥Â∫¶ÊÄªÂíåÔºö1Áª¥_age + 1Áª¥_gender + 197Áª¥_nationality = 199Áª¥„ÄÇ ‰æãÂ¶Ç (28, Â•≥, ‰∏≠ÂõΩ) ‚Üí [28, 0, 0, 1, 0, ‚Ä¶, 0]„ÄÇ ‰∏â„ÄÅÊñáÊú¨Êï∞ÊçÆÂ§ÑÁêÜÊµÅÁ®ã ÊñáÊú¨Âú®Ëá™ÁÑ∂ËØ≠Ë®ÄÂ§ÑÁêÜÔºàNLPÔºâ‰∏≠‰Ωú‰∏∫Â∏∏ËßÅÁöÑÂéüÂßãËæìÂÖ•ÔºåÈúÄË¶ÅÊï∞ÂÄºÂåñÊâçËÉΩÈÄÅÂÖ•Ê®°Âûã„ÄÇ‰∏ÄËà¨Ê≠•È™§Â¶Ç‰∏ãÔºö\nÂàÜËØç (Tokenization)\nÂ∞ÜÊñáÊú¨ÊãÜÂàÜ‰∏∫‰∏Ä‰∏™‰∏™ÂçïËØçÔºàTokenÔºâ„ÄÇ ‰æãÂ≠êÔºö\u0026quot;... to be or not to be...\u0026quot; ‚Üí [\u0026quot;...\u0026quot;, \u0026quot;to\u0026quot;, \u0026quot;be\u0026quot;, \u0026quot;or\u0026quot;, \u0026quot;not\u0026quot;, \u0026quot;to\u0026quot;, \u0026quot;be\u0026quot;, \u0026quot;...\u0026quot;]„ÄÇ ÁªüËÆ°ËØçÈ¢ë \u0026amp; ÊûÑÂª∫ËØçÂÖ∏\nËØçÈ¢ëÁªüËÆ° Áî®ÂìàÂ∏åË°®/Â≠óÂÖ∏ËÆ∞ÂΩïÊØè‰∏™ÂçïËØçÂá∫Áé∞Ê¨°Êï∞„ÄÇ ÈÅçÂéÜÊñáÊú¨Êó∂ÔºåËã•ÂçïËØçÂ∞öÊú™ÂÖ•Ë°®ÔºåÂàôÊñ∞Âª∫ËÆ∞ÂΩïÔºõËã•Â∑≤Â≠òÂú®ÔºåÂàôËÆ°Êï∞+1„ÄÇ ÊéíÂ∫è‰∏éÁ¥¢Âºï ÊåâËØçÈ¢ëÈôçÂ∫èÊéíÂ∫èÔºåËØçÈ¢ëÊúÄÈ´òÁöÑÂçïËØçÊéíÂú®ÂâçÈù¢„ÄÇ Á¥¢Âºï‰ªé1ÂºÄÂßãÔºå0ÁïôÁªô‚ÄúÊú™Áü•‚Äù„ÄÇ ËØçÂÖ∏ËßÑÊ®°ÔºàvocabularyÔºâÂèØËßÜÈúÄÊ±ÇÊà™Êñ≠Ôºà‰æãÂ¶ÇÂè™‰øùÁïôTop 10kÔºâ„ÄÇ ‰∏∫‰ªÄ‰πàÁßªÈô§‰ΩéÈ¢ëËØç ‰ΩéÈ¢ëËØçÂèØËÉΩÊòØÊãºÂÜôÈîôËØØ„ÄÅÁΩïËßÅ‰∫∫ÂêçÁ≠âÔºåÂØπÊ®°ÂûãÂ∏ÆÂä©ÊúâÈôê„ÄÇ ÂáèÂ∞ëËØçÂÖ∏ËßÑÊ®°ÂèØÈôç‰ΩéËøêÁÆóÂºÄÈîÄ„ÄÅÂä†Âø´Ê®°ÂûãËÆ≠ÁªÉ‰∏éÊé®ÁêÜÈÄüÂ∫¶„ÄÇ Áã¨ÁÉ≠ÁºñÁ†Å (One-Hot Encoding)\nÂ∞ÜÊØè‰∏™ÂçïËØçÊò†Â∞Ñ‰∏∫ËØçÂÖ∏‰∏≠ÁöÑÁ¥¢ÂºïÂêéÔºàÂ¶Ç [2, 4, 1, 8, ‚Ä¶]ÔºâÔºåÂèØËøõ‰∏ÄÊ≠•ËΩ¨Êç¢ÊàêOne-HotÂêëÈáè„ÄÇ One-HotÁª¥Â∫¶ÂèñÂÜ≥‰∫é‰øùÁïô‰∏ãÊù•ÁöÑËØçÂÖ∏Â§ßÂ∞èÔºà‰æãÂ¶Ç1‰∏áÔºâ„ÄÇ Êú™Êî∂ÂΩïÂçïËØçÂèØËÉΩÁõ¥Êé•ÂøΩÁï•ÔºåÊàñÁªü‰∏ÄÁî®Á¥¢Âºï0‰ª£Êõø„ÄÇ Âõõ„ÄÅÊ†∏ÂøÉÊî∂Ëé∑‰∏éÂ∫îÁî® Á±ªÂà´ÁâπÂæÅÂøÖÈúÄÊï∞ÂÄºÂåñÔºö\n‰ΩøÁî®Êï¥Êï∞1,2,3‚Ä¶‰ªÖË°®Á§∫Á±ªÂà´‚ÄúÊ†áËØÜ‚ÄùÔºåÂπ∂‰∏ç‰ª£Ë°®ÂÆÉ‰ª¨ÂèØËøõË°åÊï∞ÂÄºËøêÁÆó„ÄÇ Âõ†Ê≠§ÈúÄË¶ÅOne-HotÁ≠âÁºñÁ†ÅÊñπÂºèÔºåÈÅøÂÖçÊï∞ÂÄºËØØËß£„ÄÇ ÊñáÊú¨Êï∞ÊçÆÈ¢ÑÂ§ÑÁêÜÔºö\nÂàÜËØç„ÄÅËØçÈ¢ëÁªüËÆ°„ÄÅÊûÑÂª∫ËØçÂÖ∏„ÄÅÁ¥¢ÂºïÂåñ„ÄÅOne-HotÊàñÂÖ∂‰ªñÊñπÂºèÔºàÂ¶ÇËØçÂµåÂÖ•ÔºâÊòØÂ∏∏ËßÅÊµÅÁ®ã„ÄÇ Ê≠£Á°ÆÁöÑÊñáÊú¨È¢ÑÂ§ÑÁêÜÂèØÊòæËëóÂΩ±ÂìçÊ®°ÂûãÊÄßËÉΩÂíåÊïàÁéá„ÄÇ ‰øùÁïôÊú™Áü•Á¥¢ÂºïÔºö\n‰øùËØÅÂØπÁº∫Â§±Êï∞ÊçÆÊàñÂ≠óÂÖ∏Â§ñÊñ∞ËØçËÉΩÊúâÂü∫Êú¨ÁöÑË°®Á§∫ÔºåÊèêÂçáÊ®°ÂûãÂÆπÈîôÊÄß„ÄÇ ÂÆûÈôÖ‰ΩøÁî®Ôºö\nÂØπ‰∫éÂ∞èËßÑÊ®°Á±ªÂà´ÂèØÁõ¥Êé•One-HotÁºñÁ†ÅÔºõÂØπ‰∫éËØçÂÖ∏ÂæàÂ§ßÁöÑÂú∫ÊôØÔºåÈÄöÂ∏∏‰ºöËøõ‰∏ÄÊ≠•ËÄÉËôëËØçÂµåÂÖ•ÔºàWord EmbeddingÔºâÊàñÈ¢ÑËÆ≠ÁªÉËØ≠Ë®ÄÊ®°Âûã„ÄÇ ","permalink":"http://localhost:1313/posts/nlp-1/","summary":"\u003ch2 id=\"‰∏ÄÊï∞ÂÄºÁâπÂæÅ‰∏éÁ±ªÂà´ÁâπÂæÅ\"\u003e‰∏Ä„ÄÅÊï∞ÂÄºÁâπÂæÅ‰∏éÁ±ªÂà´ÁâπÂæÅ\u003c/h2\u003e\n\u003col\u003e\n\u003cli\u003e\u003cstrong\u003eÊï∞ÂÄºÁâπÂæÅ (Numeric Features)\u003c/strong\u003e\n\u003cul\u003e\n\u003cli\u003eÂÖ∑ÊúâÂèØÂä†ÂáèÁöÑÊÑè‰πâÔºå‰∏îÂ≠òÂú®Â§ßÂ∞èÈ°∫Â∫è„ÄÇ\u003c/li\u003e\n\u003cli\u003e‰æãÂ≠êÔºöÂπ¥ÈæÑ„ÄÅÊ∏©Â∫¶Á≠â„ÄÇÂèØ‰ª•Áõ¥Êé•‰øùÁïôÂÖ∂Êï¥Êï∞ÊàñÊµÆÁÇπÊï∞ÂΩ¢Âºè‰æõÊ®°Âûã‰ΩøÁî®„ÄÇ\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003eÁ±ªÂà´ÁâπÂæÅ (Categorical Features)\u003c/strong\u003e\n\u003cul\u003e\n\u003cli\u003eÊï∞ÊçÆÂÄºÁ¶ªÊï£Ôºå‰∏çÂÖ∑Â§á‚ÄúÊï∞ÂÄºÂ§ßÂ∞è‚ÄùÈó¥ÁöÑÂèØÊØîÊÑè‰πâ„ÄÇ\u003c/li\u003e\n\u003cli\u003e‰æãÂ≠êÔºöÂõΩÁ±çÔºàÁæéÂõΩ/‰∏≠ÂõΩ/Âç∞Â∫¶Á≠âÔºâ„ÄÅÊÄßÂà´ÔºàÁî∑/Â•≥ÔºâÁ≠â„ÄÇ\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003eÈóÆÈ¢ò\u003c/strong\u003eÔºöËã•‰ªÖÁî®Êï¥Êï∞Ë°®Á§∫ÔºàÁæéÂõΩ=1, ‰∏≠ÂõΩ=2ÔºâÔºå‰ºöÂºïÂÖ•ÈîôËØØÁöÑÊï∞ÂÄºËøêÁÆóÂÖ≥Á≥ªÔºåÂ¶Ç ‚ÄúÁæéÂõΩ + ‰∏≠ÂõΩ = Âç∞Â∫¶‚Äù„ÄÇ\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003c/ol\u003e\n\u003ch2 id=\"‰∫åone-hotÁºñÁ†ÅÁöÑÂä®Êú∫‰∏éÊµÅÁ®ã\"\u003e‰∫å„ÄÅOne-HotÁºñÁ†ÅÁöÑÂä®Êú∫‰∏éÊµÅÁ®ã\u003c/h2\u003e\n\u003col\u003e\n\u003cli\u003e\n\u003cp\u003e\u003cstrong\u003e‰∏∫‰ªÄ‰πà‰ΩøÁî®One-Hot\u003c/strong\u003e\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eÈÄöËøáÂ∞ÜÁ±ªÂà´Êò†Â∞Ñ‰∏∫ÂêëÈáèÔºåÈÅøÂÖçÊï¥Êï∞ÁºñÁ†ÅÂºïÂÖ•ÁöÑ‰º™Êï∞ÂÄºÂÖ≥Á≥ª„ÄÇ\u003c/li\u003e\n\u003cli\u003eÂêåÊó∂‰øùÁïôÂêÑÁßçÂèØËÉΩÁ±ªÂà´ÁöÑ‰ø°ÊÅØÔºå‰∏î‰ªÖÂú®ÂØπÂ∫î‰ΩçÁΩÆ‰∏∫1ÔºåÂÖ∂‰ªñ‰ΩçÁΩÆ‰∏∫0„ÄÇ\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003e\u003cstrong\u003eÂª∫Á´ãÊò†Â∞ÑÔºö‰ªéÁ±ªÂà´Âà∞Á¥¢Âºï\u003c/strong\u003e\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e‰∏∫ÊØè‰∏™Á±ªÂà´ÂàÜÈÖç‰∏Ä‰∏™ÂîØ‰∏ÄÁ¥¢ÂºïÔºåÈÄöÂ∏∏‰ªé1ÂºÄÂßã„ÄÇ\u003c/li\u003e\n\u003cli\u003eÈ¢ÑÁïôÁ¥¢Âºï0Ë°®Á§∫‚ÄúÊú™Áü•‚ÄùÊàñ‚ÄúÁº∫Â§±‚ÄùÔºåÂØπÂ∫îÂÖ®0ÂêëÈáè„ÄÇ\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003e\u003cstrong\u003eËΩ¨Êç¢‰∏∫One-HotÂêëÈáè\u003c/strong\u003e\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eËã•Á±ªÂà´ÊÄªÊï∞‰∏∫197ÔºåÂàôÁî®197Áª¥ÂêëÈáèË°®Á§∫„ÄÇ\u003c/li\u003e\n\u003cli\u003e‰æãÂ≠êÔºöÁæéÂõΩ \u003ccode\u003e[1, 0, 0, 0, ‚Ä¶]\u003c/code\u003eÔºå ‰∏≠ÂõΩ \u003ccode\u003e[0, 1, 0, 0, ‚Ä¶]\u003c/code\u003e„ÄÇ\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003e\u003cstrong\u003eÁ§∫‰æãÔºöË°®Á§∫‰∏Ä‰∏™‰∫∫ÁöÑÁâπÂæÅ\u003c/strong\u003e\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eÁâπÂæÅÂåÖÂê´ÔºàÂπ¥ÈæÑ, ÊÄßÂà´, ÂõΩÁ±çÔºåÂÖ∂‰∏≠ÂõΩÁ±ç197ÁßçÔºâ\u003c/li\u003e\n\u003cli\u003eÁª¥Â∫¶ÊÄªÂíåÔºö1Áª¥_age + 1Áª¥_gender + 197Áª¥_nationality = 199Áª¥„ÄÇ\u003c/li\u003e\n\u003cli\u003e‰æãÂ¶Ç \u003ccode\u003e(28, Â•≥, ‰∏≠ÂõΩ)\u003c/code\u003e ‚Üí \u003ccode\u003e[28, 0, 0, 1, 0, ‚Ä¶, 0]\u003c/code\u003e„ÄÇ\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003c/ol\u003e\n\u003ch2 id=\"‰∏âÊñáÊú¨Êï∞ÊçÆÂ§ÑÁêÜÊµÅÁ®ã\"\u003e‰∏â„ÄÅÊñáÊú¨Êï∞ÊçÆÂ§ÑÁêÜÊµÅÁ®ã\u003c/h2\u003e\n\u003cp\u003eÊñáÊú¨Âú®Ëá™ÁÑ∂ËØ≠Ë®ÄÂ§ÑÁêÜÔºàNLPÔºâ‰∏≠‰Ωú‰∏∫Â∏∏ËßÅÁöÑÂéüÂßãËæìÂÖ•ÔºåÈúÄË¶ÅÊï∞ÂÄºÂåñÊâçËÉΩÈÄÅÂÖ•Ê®°Âûã„ÄÇ‰∏ÄËà¨Ê≠•È™§Â¶Ç‰∏ãÔºö\u003c/p\u003e\n\u003col\u003e\n\u003cli\u003e\n\u003cp\u003e\u003cstrong\u003eÂàÜËØç (Tokenization)\u003c/strong\u003e\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eÂ∞ÜÊñáÊú¨ÊãÜÂàÜ‰∏∫‰∏Ä‰∏™‰∏™ÂçïËØçÔºàTokenÔºâ„ÄÇ\u003c/li\u003e\n\u003cli\u003e‰æãÂ≠êÔºö\u003ccode\u003e\u0026quot;... to be or not to be...\u0026quot;\u003c/code\u003e ‚Üí \u003ccode\u003e[\u0026quot;...\u0026quot;, \u0026quot;to\u0026quot;, \u0026quot;be\u0026quot;, \u0026quot;or\u0026quot;, \u0026quot;not\u0026quot;, \u0026quot;to\u0026quot;, \u0026quot;be\u0026quot;, \u0026quot;...\u0026quot;]\u003c/code\u003e„ÄÇ\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003e\u003cstrong\u003eÁªüËÆ°ËØçÈ¢ë \u0026amp; ÊûÑÂª∫ËØçÂÖ∏\u003c/strong\u003e\u003c/p\u003e","title":""},{"content":"Text to Sequence ÊñáÊú¨Â§ÑÁêÜ\nStep1: Tokenization\nTokenization breaks a piece of text down into a list of tokens.\nHere, a token is a word. (A token can be a character in some applications.)\nTokenizationËÆ≤Á©∂ÂæàÂ§öÔºå‰æãÂ¶ÇÊòØÂê¶Â∫îËØ•ÊääÂ§ßÂÜôÊîπÊàêÂ∞èÂÜôÂë¢ÔºüËøõË°åtypo correctionÁ≠âÁ≠â\nStep2: Build Dictionary\nUse a dictionary (hash table) to count word frequencies.\nThe dictionary maps word to index.\nÂèØ‰ª•È¶ñÂÖàÁªüËÆ°ËØçÈ¢ëÂéªÊéâ‰ΩéÈ¢ëËØçÔºåÁÑ∂ÂêéËÆ©ÊØè‰∏™ËØçÂØπÂ∫î‰∏Ä‰∏™Ê≠£Êï¥Êï∞ÔºõËøôÊ†∑ÁöÑËØùÔºå‰∏ÄÂè•ËØùÂ∞±ÂèØ‰ª•Áî®‰∏Ä‰∏™Ê≠£Êï¥Êï∞ÂàóË°®Ë°®Á§∫ÔºåËøô‰∏™ÂàóË°®Â∞±Âè´sequenceÔºõÂ¶ÇÊûúÂøÖË¶ÅÂ∞±ËøòÂæóÂÅöone-hot encoding„ÄÇ\nÁªìÊûú\n‰ΩÜÊòØÈïøÂ∫¶‰∏çÁªü‰∏Ä\nStep4: ÂØπÈΩêsequence\nËß£ÂÜ≥ÊñπÊ°àÊòØËøôÊ†∑ÁöÑÔºöÂèØ‰ª•Âõ∫ÂÆöÈïøÂ∫¶‰∏∫wÔºåÂä†ÂÖ•‰∏Ä‰∏™Â∫èÂàóÈïøÂ∫¶Â§™ÈïøÔºåÂ∞±Á†çÊéâÂâçÈù¢ÁöÑËØçÔºåÂè™‰øùÁïôÊúÄÂêéw‰∏™ËØçÔºõÂ¶ÇÊûú‰∏Ä‰∏™Â∫èÂàóÂ§™Áü≠ÔºåÂ∞±ÂÅözero paddingÔºåÁî®0Â°´ÂÖÖ\nËøôÊ†∑‰∏ÄÊù•ÔºåÊâÄÊúâÁöÑÂ∫èÂàóÈïøÂ∫¶Â∞±Áªü‰∏Ä‰∫Ü\nÊñáÊú¨Â§ÑÁêÜÂÆåÊàê‰∫ÜÔºåÊé•‰∏ãÊù•ÊòØword embeddingÔºåÊääÂçïËØçË°®Á§∫‰∏∫‰∏Ä‰∏™‰ΩéÁª¥ÂêëÈáèÔºõ\nÁÑ∂ËÄåËøôÊ†∑ÂÅöÁöÑËØùÔºåÂ¶ÇÊûúÊòØ10000‰∏™ÂçïËØçÔºåÁª¥Â∫¶Â∞±ÊòØ10000Áª¥ÔºåÁª¥Â∫¶Â§™È´ò‰∫ÜÔºõÂõ†Ê≠§Ë¶ÅÂÅöword embeddingÔºõ\nÂÖ∑‰ΩìÂÅöÊ≥ïÂ∞±ÊòØÊääone-hotÂêëÈáèe_iÂíåÂèÇÊï∞Áü©ÈòµpÁõ∏‰πòÔºõÁü©ÈòµPËΩ¨ÁΩÆÁöÑÂ§ßÂ∞èÊòØd x vÔºõdÊòØËØçÂêëÈáèÁöÑÁª¥Â∫¶ÔºõvÊòØÂ≠óÂÖ∏ÈáåËØçÊ±áÁöÑÊï∞ÈáèÔºõÁªìÊûú‰∏∫x_iÔºõx_iÂ∞±ÊòØ‰∏Ä‰∏™ËØçÂêëÈáèÔºõÂ¶ÇÊûúone-hotÂêëÈáèÁöÑÁ¨¨‰∏âË°å‰∏∫1ÔºõÈÇ£‰πàx_iÂ∞±ÊòØPËΩ¨ÁΩÆÁü©ÈòµÁöÑÁ¨¨‰∏âÂàóÔºàÂÖ∂‰ΩôÂàóÈÉΩ‰∏∫0ÔºâÔºõÊâÄ‰ª•PËΩ¨ÁΩÆÊØè‰∏ÄÂàóÈÉΩÊòØ‰∏Ä‰∏™ËØçÂêëÈáèÔºõÊâÄ‰ª•Áü©ÈòµPÊú¨Ë∫´ÁöÑÊØè‰∏ÄË°åÂ∞±ÊòØ‰∏Ä‰∏™ËØçÂêëÈáèÔºõÂÖ∂Ë°åÊï∞‰∏∫vÔºõÂç≥vocabularyÔºåËØçÊ±áÈáèÔºõÊØè‰∏ÄË°åÂØπÂ∫î‰∏Ä‰∏™ÂçïËØçÔºõÁü©ÈòµÁöÑÂàóÊï∞‰∏∫dÔºõdÊòØÁî®Êà∑ÂÜ≥ÂÆöÁöÑÔºõdÁöÑÂ§ßÂ∞è‰ºöÂÜ≥ÂÆöÊú∫Âô®Â≠¶‰π†Ê®°ÂûãÁöÑË°®Áé∞ÔºõÂ∫îËØ•Áî®xxxÊù•ÈÄâÊã©‰∏Ä‰∏™ÊØîËæÉÂ•ΩÁöÑdÔºõ\nÊàë‰ª¨ÁöÑ‰ªªÂä°ÊòØÁúãËØÑËÆ∫ÊòØÊ≠£Èù¢ÁöÑËøòÊòØË¥üÈù¢ÁöÑÔºõÂèÇÊï∞Áü©ÈòµÊòØ‰ªéËÆ≠ÁªÉÊï∞ÊçÆ‰∏≠Â≠¶‰π†Âá∫Êù•ÁöÑÔºåÊâÄ‰ª•Â≠¶Âá∫Êù•ÁöÑËØçÂêëÈáèÊòØÂ∏¶ÊúâÊÑüÊÉÖËâ≤ÂΩ©ÁöÑÔºõÂÅáËÆæËøô‰∫õËØçÂêëÈáèÈÉΩÊòØ‰∫åÁª¥ÁöÑÔºåÂàôÂèØ‰ª•Âú®Âπ≥Èù¢ÂùêÊ†áÁ≥ª‰∏≠Ê†áÂá∫‰∏ãÈù¢ËØçÂêëÈáè\nkerasÊèê‰æõembeddingÂ±ÇÔºõÁî®Êà∑ÂèØ‰ª•ÊåáÂÆövocabularyÂ§ßÂ∞èÂíådÁöÑÂ§ßÂ∞èÔºõ‰ª•ÂèäÊØè‰∏Ä‰∏™sequenceÁöÑÈïøÂ∫¶ÔºõdÊòØÊ†πÊçÆÁÆóÊ≥ïÈÄâÂá∫Êù•ÁöÑ Âà∞Ëøô‰∏ÄÊ≠•ÔºåÊàë‰ª¨Â∑≤ÁªèÂÆåÊàê‰∫ÜÊñáÊú¨Â§ÑÁêÜÂíåword embedding„ÄÇÊé•‰∏ãÊù•Â∞±ÊòØÁî®Logistic Regression for Binary ClassificationÂÅö‰∫åÂàÜÁ±ªÔºõ\n","permalink":"http://localhost:1313/posts/nlp-2/","summary":"\u003ch3 id=\"text-to-sequence\"\u003eText to Sequence\u003c/h3\u003e\n\u003cp\u003eÊñáÊú¨Â§ÑÁêÜ\u003c/p\u003e\n\u003cp\u003eStep1: Tokenization\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\n\u003cp\u003eTokenization breaks a piece of text down into a list of tokens.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003eHere, a token is a word. (A token can be a character in some applications.)\u003c/p\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003eTokenizationËÆ≤Á©∂ÂæàÂ§öÔºå‰æãÂ¶ÇÊòØÂê¶Â∫îËØ•ÊääÂ§ßÂÜôÊîπÊàêÂ∞èÂÜôÂë¢ÔºüËøõË°åtypo correctionÁ≠âÁ≠â\u003c/p\u003e\n\u003cp\u003e\u003cimg alt=\"image-20250322150322238\" loading=\"lazy\" src=\"./NLP-2.assets/image-20250322150322238.png\"\u003e\u003c/p\u003e\n\u003cp\u003eStep2: Build Dictionary\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\n\u003cp\u003eUse a dictionary (hash table) to count word frequencies.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003eThe dictionary maps word to index.\u003c/p\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003eÂèØ‰ª•È¶ñÂÖàÁªüËÆ°ËØçÈ¢ëÂéªÊéâ‰ΩéÈ¢ëËØçÔºåÁÑ∂ÂêéËÆ©ÊØè‰∏™ËØçÂØπÂ∫î‰∏Ä‰∏™Ê≠£Êï¥Êï∞ÔºõËøôÊ†∑ÁöÑËØùÔºå‰∏ÄÂè•ËØùÂ∞±ÂèØ‰ª•Áî®‰∏Ä‰∏™Ê≠£Êï¥Êï∞ÂàóË°®Ë°®Á§∫ÔºåËøô‰∏™ÂàóË°®Â∞±Âè´sequenceÔºõÂ¶ÇÊûúÂøÖË¶ÅÂ∞±ËøòÂæóÂÅöone-hot encoding„ÄÇ\u003cimg alt=\"image-20250322150620890\" loading=\"lazy\" src=\"./NLP-2.assets/image-20250322150620890.png\"\u003e\u003c/p\u003e\n\u003cp\u003eÁªìÊûú\u003c/p\u003e\n\u003cp\u003e\u003cimg alt=\"image-20250322150754528\" loading=\"lazy\" src=\"./NLP-2.assets/image-20250322150754528.png\"\u003e\u003c/p\u003e\n\u003cp\u003e‰ΩÜÊòØÈïøÂ∫¶‰∏çÁªü‰∏Ä\u003c/p\u003e\n\u003cp\u003eStep4: ÂØπÈΩêsequence\u003c/p\u003e\n\u003cp\u003e\u003cimg alt=\"image-20250322150854986\" loading=\"lazy\" src=\"./NLP-2.assets/image-20250322150854986.png\"\u003e\u003c/p\u003e\n\u003cp\u003eËß£ÂÜ≥ÊñπÊ°àÊòØËøôÊ†∑ÁöÑÔºöÂèØ‰ª•Âõ∫ÂÆöÈïøÂ∫¶‰∏∫wÔºåÂä†ÂÖ•‰∏Ä‰∏™Â∫èÂàóÈïøÂ∫¶Â§™ÈïøÔºåÂ∞±Á†çÊéâÂâçÈù¢ÁöÑËØçÔºåÂè™‰øùÁïôÊúÄÂêéw‰∏™ËØçÔºõÂ¶ÇÊûú‰∏Ä‰∏™Â∫èÂàóÂ§™Áü≠ÔºåÂ∞±ÂÅözero paddingÔºåÁî®0Â°´ÂÖÖ\u003c/p\u003e\n\u003cp\u003e\u003cimg alt=\"image-20250322151030119\" loading=\"lazy\" src=\"./NLP-2.assets/image-20250322151030119.png\"\u003e\u003c/p\u003e\n\u003cp\u003eËøôÊ†∑‰∏ÄÊù•ÔºåÊâÄÊúâÁöÑÂ∫èÂàóÈïøÂ∫¶Â∞±Áªü‰∏Ä‰∫Ü\u003c/p\u003e\n\u003cp\u003e\u003cimg alt=\"image-20250322151117125\" loading=\"lazy\" src=\"./NLP-2.assets/image-20250322151117125.png\"\u003e\u003c/p\u003e\n\u003cp\u003eÊñáÊú¨Â§ÑÁêÜÂÆåÊàê‰∫ÜÔºåÊé•‰∏ãÊù•ÊòØword embeddingÔºåÊääÂçïËØçË°®Á§∫‰∏∫‰∏Ä‰∏™‰ΩéÁª¥ÂêëÈáèÔºõ\u003c/p\u003e\n\u003cp\u003e\u003cimg alt=\"image-20250322151252837\" loading=\"lazy\" src=\"./NLP-2.assets/image-20250322151252837.png\"\u003e\u003c/p\u003e","title":""},{"content":"üëã About me Hello! I\u0026rsquo;m Xu Zongsi, a passionate technology enthusiast currently pursuing my Master of Science in ECIC at The University of Hong Kong. With a solid background in Software Engineering from the Beijing Institute of Technology, I specialize in artificial intelligence areas like machine learning, deep learning, natural language processing, computer vision, and reinforcement learning.\nInspired by OpenAI\u0026rsquo;s five-step plan towards superintelligence, I am excited about AGI and have developed a keen interest in LLM agents, MLLM, and knowledge graphs. I see great potential in these fields and aspire to contribute to innovative solutions.\nüìö Education üá≠üá∞ The University of Hong Kong 09/2024 - Expected 11/2025 School of Computing and Data Science Master of Science in Electronic Commerce \u0026amp; Internet Computing Relevant Courses: Machine learning for business and e-commerce, Knowledge graphs, Financial fraud analytics, Internet infrastructure technologies, Website engineering, Blockchain and cryptocurrency, etc. üá®üá≥ Beijing Institute of Technology 09/2020 - 06/2024 School of Computer Science \u0026amp; Technology Bachelor of Engineering in Software Engineering, last two years GPA: 3.7/4 Relevant Courses: Reinforcement Learning, Deep Learning and Computer Vision, Artificial Intelligence and Robot Ethics, Almost Human: Mind, Brain and Artificial Intelligence, Mathematical Analysis for Engineering, Linear Algebra, Probability and Mathematical Statistics, etc. Skills: Python, Java, common data structures, design patterns, machine learning basics and algorithms, Linux, PyTorch, and some development tools (git, conda, etc.). üèÜ Awards \u0026amp; Honors Beijing Institute of Technology Undergraduate Scholarship (Top 20% of Grade) 06/2023 3rd Prize of China International \u0026#34;Internet \u0026#43;\u0026#34; College Student\u0026#39;s Innovation Competition 08/2022 Bronze Prize of \u0026#34;Challenge Cup\u0026#34; Capital University Entrepreneurship Competition 05/2022 üíº Project Experience üîç Online Transaction Fraud Detection 09/2024 ‚Äì 01/2025 Independent project, supervised by Dr. Vivien Chan Focused on addressing financial fraud in e-commerce to enhance the accuracy of transaction anomaly detection, while independently managing the entire case study that included data preprocessing, feature engineering, model building, evaluation, and results analysis. Effectively resolved class imbalance issues using SMOTE and ROSE techniques. Built various models including Logistic Regression, Random Forest, XGBoost, and LightGBM, ultimately selecting the LightGBM model to achieve a recall rate of 95.45% and an AUC of 99.84%. Wrote efficient and maintainable code, enhancing model training and data processing efficiency through parallel computing and logging. ü§ñ Multi-Model Intelligent Text Keyword Extraction System 08/2023 ‚Äì 09/2023 Group project, supervised by Associate Prof. Xiaolin Zhao Designed and implemented an intelligent text summary system that automatically extracts keywords from article titles and abstracts, enhancing the understanding and summarization of text information. Participated in the planning of the technical route and built a hybrid model combining extractive and generative approaches, utilizing advanced natural language processing techniques including KeyBERT, Sentence Transformer, BERT, and T5 models. Responsible for data preprocessing and tokenization, as well as the end-to-end implementation and training of the T5 model, optimizing the model architecture and hyperparameters, achieving satisfactory results after only 3 epochs of training. Model evaluation results showed that the Rouge-1, Rouge-2, and Rouge-L metrics reached 0.6345, 0.5038, and 0.5282, respectively, in the third epoch, validating the model\u0026rsquo;s effectiveness in the summarization task. üéì Cambridge University Machine Learning Summer Project 07/2023 ‚Äì 08/2023 Group project, supervised by Prof. Pietro Li√≤ Participated in the Cambridge University deep learning summer project, focusing on deep reinforcement learning; explored multi-agent learning algorithms across different environments. Reproduced the Multi-Agent Deep Deterministic Policy Gradient (MADDPG) algorithm in the Simple Adversary environment and studied the effect of agent numbers on convergence speed and stability, finding optimal stability at 21 agents. Designed and implemented comparative experiments inspired by the Rainbow algorithm, assessing target network strategies versus the Double Deep Q-Network (Double DQN). The results demonstrated that Double DQN significantly enhanced convergence speed, optimizing the overall learning process. Co-authored a group project paper on agent numbers and strategies effectiveness in multi-agent systems, achieving a score of 71% in the summer program (the highest in my group) and a \u0026ldquo;First Class\u0026rdquo; classification in the UK grading system. üëÅÔ∏è Deep Learning and Computer Vision Semester Project 09/2022 ‚Äì 12/2022 Independent project, supervised by Associate Prof. Guangyu Gao Designed and implemented a waste classifier using the ResNet model to improve classification accuracy and reduce resource waste. The project also enhanced understanding of transfer learning techniques with ResNet. Collected a dataset of 16 waste categories and preprocessed the images for uniformity and standardization, incorporating data augmentation techniques to enhance the dataset. Conducted experiments using ResNet34 and ResNet50 models through transfer learning, accelerating network convergence by leveraging pretrained weights. During training, techniques such as Batch Normalization and Dropout were applied to mitigate the risk of overfitting. The final model achieved an accuracy of 90% on the training set, while the performance on the test set was 61%, indicating a significant overfitting phenomenon during the training process. üéì Internship ‚öõÔ∏è Beijing Academy of Quantum Information Science 08/2023 ‚Äì 01/2024 Research Intern at Quantum Computation Department Proposed a quantum convolution kernel design based on variational quantum circuits and developed a universal quantum convolution layer, successfully integrating it into classical CNN architectures such as VGG, GoogLeNet, and ResNet. Developed and evaluated various hybrid models, including a simple model named HQCCNN-2, which achieved 84.45% accuracy on the FashionMNIST dataset, surpassing the traditional CNN\u0026rsquo;s 80.72%. This demonstrates the effectiveness of the quantum convolution layer in improving model performance. Tested on a real quantum computer further validated the effectiveness of the hybrid model, demonstrating the viable integration of quantum computing with deep learning, and highlighting the potential for leveraging quantum properties to enhance model performance. üèÖ Competition Experience ü•â China International \u0026#34;Internet \u0026#43;\u0026#34; College Students\u0026#39; Innovation Competition 08/2022 üõ°Ô∏è Zhongke Ushield: Deep Learning-based Face Privacy Protection Authentication System Responsible for constructing a localized facial feature extraction engine based on MobileFaceNet, ensuring feature extraction is completed on end devices (such as mobile phones and cameras), guaranteeing that raw data does not leave the domain and is not stored, thus enhancing user privacy protection while improving recognition efficiency. ü•â \u0026#34;Challenge Cup\u0026#34; Capital University Entrepreneurship Competition 05/2022 üå≥ Smart Orchard Responsible for the development of the fruit detection, ripeness prediction, and pest identification system, using deep convolutional neural network (CNN) technology for intelligent monitoring of crop growth conditions. Applied advanced object detection algorithms such as Faster R-CNN and YOLO to achieve high precision in apple detection and ripeness assessment, with an accuracy rate exceeding 90%, significantly enhancing the intelligence level of orchard management. Built and trained a dedicated dataset containing various pest samples, optimizing pest detection accuracy through data preprocessing (such as image normalization and resizing) and data augmentation techniques (like rotation, flipping, and noise addition), enabling the real-time monitoring system to accurately identify over 80% of pests, providing effective scientific maintenance recommendations to help farmers reduce crop losses. üìã Extracurricular Activities Vice President, Cyber Security Club, Beijing Institute of Technology 09/2021-09/2022 Backbone, Media Center of the Student Union of Beijing Institute of Technology 10/2020-06/2021 üì´ Contact üìß Email: zongsi.xu@outlook.com üëî LinkedIn: Zongsi (Tristan) Xu üíª GitHub: github.com/BaizeXS üìç Location: Hong Kong SAR, China ","permalink":"http://localhost:1313/resume/","summary":"Personal resume of Zongsi (Tristan) Xu","title":"Zongsi (Tristan) Xu"},{"content":"‰∏Ä„ÄÅÊï∞ÂÄºÁâπÂæÅ‰∏éÁ±ªÂà´ÁâπÂæÅ Êï∞ÂÄºÁâπÂæÅ (Numeric Features) ÂÖ∑ÊúâÂèØÂä†ÂáèÁöÑÊÑè‰πâÔºå‰∏îÂ≠òÂú®Â§ßÂ∞èÈ°∫Â∫è„ÄÇ ‰æãÂ≠êÔºöÂπ¥ÈæÑ„ÄÅÊ∏©Â∫¶Á≠â„ÄÇÂèØ‰ª•Áõ¥Êé•‰øùÁïôÂÖ∂Êï¥Êï∞ÊàñÊµÆÁÇπÊï∞ÂΩ¢Âºè‰æõÊ®°Âûã‰ΩøÁî®„ÄÇ Á±ªÂà´ÁâπÂæÅ (Categorical Features) Êï∞ÊçÆÂÄºÁ¶ªÊï£Ôºå‰∏çÂÖ∑Â§á‚ÄúÊï∞ÂÄºÂ§ßÂ∞è‚ÄùÈó¥ÁöÑÂèØÊØîÊÑè‰πâ„ÄÇ ‰æãÂ≠êÔºöÂõΩÁ±çÔºàÁæéÂõΩ/‰∏≠ÂõΩ/Âç∞Â∫¶Á≠âÔºâ„ÄÅÊÄßÂà´ÔºàÁî∑/Â•≥ÔºâÁ≠â„ÄÇ ÈóÆÈ¢òÔºöËã•‰ªÖÁî®Êï¥Êï∞Ë°®Á§∫ÔºàÁæéÂõΩ=1, ‰∏≠ÂõΩ=2ÔºâÔºå‰ºöÂºïÂÖ•ÈîôËØØÁöÑÊï∞ÂÄºËøêÁÆóÂÖ≥Á≥ªÔºåÂ¶Ç ‚ÄúÁæéÂõΩ + ‰∏≠ÂõΩ = Âç∞Â∫¶‚Äù„ÄÇ ‰∫å„ÄÅOne-HotÁºñÁ†ÅÁöÑÂä®Êú∫‰∏éÊµÅÁ®ã ‰∏∫‰ªÄ‰πà‰ΩøÁî®One-Hot\nÈÄöËøáÂ∞ÜÁ±ªÂà´Êò†Â∞Ñ‰∏∫ÂêëÈáèÔºåÈÅøÂÖçÊï¥Êï∞ÁºñÁ†ÅÂºïÂÖ•ÁöÑ‰º™Êï∞ÂÄºÂÖ≥Á≥ª„ÄÇ ÂêåÊó∂‰øùÁïôÂêÑÁßçÂèØËÉΩÁ±ªÂà´ÁöÑ‰ø°ÊÅØÔºå‰∏î‰ªÖÂú®ÂØπÂ∫î‰ΩçÁΩÆ‰∏∫1ÔºåÂÖ∂‰ªñ‰ΩçÁΩÆ‰∏∫0„ÄÇ Âª∫Á´ãÊò†Â∞ÑÔºö‰ªéÁ±ªÂà´Âà∞Á¥¢Âºï\n‰∏∫ÊØè‰∏™Á±ªÂà´ÂàÜÈÖç‰∏Ä‰∏™ÂîØ‰∏ÄÁ¥¢ÂºïÔºåÈÄöÂ∏∏‰ªé1ÂºÄÂßã„ÄÇ È¢ÑÁïôÁ¥¢Âºï0Ë°®Á§∫‚ÄúÊú™Áü•‚ÄùÊàñ‚ÄúÁº∫Â§±‚ÄùÔºåÂØπÂ∫îÂÖ®0ÂêëÈáè„ÄÇ ËΩ¨Êç¢‰∏∫One-HotÂêëÈáè\nËã•Á±ªÂà´ÊÄªÊï∞‰∏∫197ÔºåÂàôÁî®197Áª¥ÂêëÈáèË°®Á§∫„ÄÇ ‰æãÂ≠êÔºöÁæéÂõΩ [1, 0, 0, 0, ‚Ä¶]Ôºå ‰∏≠ÂõΩ [0, 1, 0, 0, ‚Ä¶]„ÄÇ Á§∫‰æãÔºöË°®Á§∫‰∏Ä‰∏™‰∫∫ÁöÑÁâπÂæÅ\nÁâπÂæÅÂåÖÂê´ÔºàÂπ¥ÈæÑ, ÊÄßÂà´, ÂõΩÁ±çÔºåÂÖ∂‰∏≠ÂõΩÁ±ç197ÁßçÔºâ Áª¥Â∫¶ÊÄªÂíåÔºö1Áª¥_age + 1Áª¥_gender + 197Áª¥_nationality = 199Áª¥„ÄÇ ‰æãÂ¶Ç (28, Â•≥, ‰∏≠ÂõΩ) ‚Üí [28, 0, 0, 1, 0, ‚Ä¶, 0]„ÄÇ ‰∏â„ÄÅÊñáÊú¨Êï∞ÊçÆÂ§ÑÁêÜÊµÅÁ®ã ÊñáÊú¨Âú®Ëá™ÁÑ∂ËØ≠Ë®ÄÂ§ÑÁêÜÔºàNLPÔºâ‰∏≠‰Ωú‰∏∫Â∏∏ËßÅÁöÑÂéüÂßãËæìÂÖ•ÔºåÈúÄË¶ÅÊï∞ÂÄºÂåñÊâçËÉΩÈÄÅÂÖ•Ê®°Âûã„ÄÇ‰∏ÄËà¨Ê≠•È™§Â¶Ç‰∏ãÔºö\nÂàÜËØç (Tokenization)\nÂ∞ÜÊñáÊú¨ÊãÜÂàÜ‰∏∫‰∏Ä‰∏™‰∏™ÂçïËØçÔºàTokenÔºâ„ÄÇ ‰æãÂ≠êÔºö\u0026quot;... to be or not to be...\u0026quot; ‚Üí [\u0026quot;...\u0026quot;, \u0026quot;to\u0026quot;, \u0026quot;be\u0026quot;, \u0026quot;or\u0026quot;, \u0026quot;not\u0026quot;, \u0026quot;to\u0026quot;, \u0026quot;be\u0026quot;, \u0026quot;...\u0026quot;]„ÄÇ ÁªüËÆ°ËØçÈ¢ë \u0026amp; ÊûÑÂª∫ËØçÂÖ∏\nËØçÈ¢ëÁªüËÆ° Áî®ÂìàÂ∏åË°®/Â≠óÂÖ∏ËÆ∞ÂΩïÊØè‰∏™ÂçïËØçÂá∫Áé∞Ê¨°Êï∞„ÄÇ ÈÅçÂéÜÊñáÊú¨Êó∂ÔºåËã•ÂçïËØçÂ∞öÊú™ÂÖ•Ë°®ÔºåÂàôÊñ∞Âª∫ËÆ∞ÂΩïÔºõËã•Â∑≤Â≠òÂú®ÔºåÂàôËÆ°Êï∞+1„ÄÇ ÊéíÂ∫è‰∏éÁ¥¢Âºï ÊåâËØçÈ¢ëÈôçÂ∫èÊéíÂ∫èÔºåËØçÈ¢ëÊúÄÈ´òÁöÑÂçïËØçÊéíÂú®ÂâçÈù¢„ÄÇ Á¥¢Âºï‰ªé1ÂºÄÂßãÔºå0ÁïôÁªô‚ÄúÊú™Áü•‚Äù„ÄÇ ËØçÂÖ∏ËßÑÊ®°ÔºàvocabularyÔºâÂèØËßÜÈúÄÊ±ÇÊà™Êñ≠Ôºà‰æãÂ¶ÇÂè™‰øùÁïôTop 10kÔºâ„ÄÇ ‰∏∫‰ªÄ‰πàÁßªÈô§‰ΩéÈ¢ëËØç ‰ΩéÈ¢ëËØçÂèØËÉΩÊòØÊãºÂÜôÈîôËØØ„ÄÅÁΩïËßÅ‰∫∫ÂêçÁ≠âÔºåÂØπÊ®°ÂûãÂ∏ÆÂä©ÊúâÈôê„ÄÇ ÂáèÂ∞ëËØçÂÖ∏ËßÑÊ®°ÂèØÈôç‰ΩéËøêÁÆóÂºÄÈîÄ„ÄÅÂä†Âø´Ê®°ÂûãËÆ≠ÁªÉ‰∏éÊé®ÁêÜÈÄüÂ∫¶„ÄÇ Áã¨ÁÉ≠ÁºñÁ†Å (One-Hot Encoding)\nÂ∞ÜÊØè‰∏™ÂçïËØçÊò†Â∞Ñ‰∏∫ËØçÂÖ∏‰∏≠ÁöÑÁ¥¢ÂºïÂêéÔºàÂ¶Ç [2, 4, 1, 8, ‚Ä¶]ÔºâÔºåÂèØËøõ‰∏ÄÊ≠•ËΩ¨Êç¢ÊàêOne-HotÂêëÈáè„ÄÇ One-HotÁª¥Â∫¶ÂèñÂÜ≥‰∫é‰øùÁïô‰∏ãÊù•ÁöÑËØçÂÖ∏Â§ßÂ∞èÔºà‰æãÂ¶Ç1‰∏áÔºâ„ÄÇ Êú™Êî∂ÂΩïÂçïËØçÂèØËÉΩÁõ¥Êé•ÂøΩÁï•ÔºåÊàñÁªü‰∏ÄÁî®Á¥¢Âºï0‰ª£Êõø„ÄÇ Âõõ„ÄÅÊ†∏ÂøÉÊî∂Ëé∑‰∏éÂ∫îÁî® Á±ªÂà´ÁâπÂæÅÂøÖÈúÄÊï∞ÂÄºÂåñÔºö\n‰ΩøÁî®Êï¥Êï∞1,2,3‚Ä¶‰ªÖË°®Á§∫Á±ªÂà´‚ÄúÊ†áËØÜ‚ÄùÔºåÂπ∂‰∏ç‰ª£Ë°®ÂÆÉ‰ª¨ÂèØËøõË°åÊï∞ÂÄºËøêÁÆó„ÄÇ Âõ†Ê≠§ÈúÄË¶ÅOne-HotÁ≠âÁºñÁ†ÅÊñπÂºèÔºåÈÅøÂÖçÊï∞ÂÄºËØØËß£„ÄÇ ÊñáÊú¨Êï∞ÊçÆÈ¢ÑÂ§ÑÁêÜÔºö\nÂàÜËØç„ÄÅËØçÈ¢ëÁªüËÆ°„ÄÅÊûÑÂª∫ËØçÂÖ∏„ÄÅÁ¥¢ÂºïÂåñ„ÄÅOne-HotÊàñÂÖ∂‰ªñÊñπÂºèÔºàÂ¶ÇËØçÂµåÂÖ•ÔºâÊòØÂ∏∏ËßÅÊµÅÁ®ã„ÄÇ Ê≠£Á°ÆÁöÑÊñáÊú¨È¢ÑÂ§ÑÁêÜÂèØÊòæËëóÂΩ±ÂìçÊ®°ÂûãÊÄßËÉΩÂíåÊïàÁéá„ÄÇ ‰øùÁïôÊú™Áü•Á¥¢ÂºïÔºö\n‰øùËØÅÂØπÁº∫Â§±Êï∞ÊçÆÊàñÂ≠óÂÖ∏Â§ñÊñ∞ËØçËÉΩÊúâÂü∫Êú¨ÁöÑË°®Á§∫ÔºåÊèêÂçáÊ®°ÂûãÂÆπÈîôÊÄß„ÄÇ ÂÆûÈôÖ‰ΩøÁî®Ôºö\nÂØπ‰∫éÂ∞èËßÑÊ®°Á±ªÂà´ÂèØÁõ¥Êé•One-HotÁºñÁ†ÅÔºõÂØπ‰∫éËØçÂÖ∏ÂæàÂ§ßÁöÑÂú∫ÊôØÔºåÈÄöÂ∏∏‰ºöËøõ‰∏ÄÊ≠•ËÄÉËôëËØçÂµåÂÖ•ÔºàWord EmbeddingÔºâÊàñÈ¢ÑËÆ≠ÁªÉËØ≠Ë®ÄÊ®°Âûã„ÄÇ ","permalink":"http://localhost:1313/posts/nlp-1/","summary":"\u003ch2 id=\"‰∏ÄÊï∞ÂÄºÁâπÂæÅ‰∏éÁ±ªÂà´ÁâπÂæÅ\"\u003e‰∏Ä„ÄÅÊï∞ÂÄºÁâπÂæÅ‰∏éÁ±ªÂà´ÁâπÂæÅ\u003c/h2\u003e\n\u003col\u003e\n\u003cli\u003e\u003cstrong\u003eÊï∞ÂÄºÁâπÂæÅ (Numeric Features)\u003c/strong\u003e\n\u003cul\u003e\n\u003cli\u003eÂÖ∑ÊúâÂèØÂä†ÂáèÁöÑÊÑè‰πâÔºå‰∏îÂ≠òÂú®Â§ßÂ∞èÈ°∫Â∫è„ÄÇ\u003c/li\u003e\n\u003cli\u003e‰æãÂ≠êÔºöÂπ¥ÈæÑ„ÄÅÊ∏©Â∫¶Á≠â„ÄÇÂèØ‰ª•Áõ¥Êé•‰øùÁïôÂÖ∂Êï¥Êï∞ÊàñÊµÆÁÇπÊï∞ÂΩ¢Âºè‰æõÊ®°Âûã‰ΩøÁî®„ÄÇ\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003eÁ±ªÂà´ÁâπÂæÅ (Categorical Features)\u003c/strong\u003e\n\u003cul\u003e\n\u003cli\u003eÊï∞ÊçÆÂÄºÁ¶ªÊï£Ôºå‰∏çÂÖ∑Â§á‚ÄúÊï∞ÂÄºÂ§ßÂ∞è‚ÄùÈó¥ÁöÑÂèØÊØîÊÑè‰πâ„ÄÇ\u003c/li\u003e\n\u003cli\u003e‰æãÂ≠êÔºöÂõΩÁ±çÔºàÁæéÂõΩ/‰∏≠ÂõΩ/Âç∞Â∫¶Á≠âÔºâ„ÄÅÊÄßÂà´ÔºàÁî∑/Â•≥ÔºâÁ≠â„ÄÇ\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003eÈóÆÈ¢ò\u003c/strong\u003eÔºöËã•‰ªÖÁî®Êï¥Êï∞Ë°®Á§∫ÔºàÁæéÂõΩ=1, ‰∏≠ÂõΩ=2ÔºâÔºå‰ºöÂºïÂÖ•ÈîôËØØÁöÑÊï∞ÂÄºËøêÁÆóÂÖ≥Á≥ªÔºåÂ¶Ç ‚ÄúÁæéÂõΩ + ‰∏≠ÂõΩ = Âç∞Â∫¶‚Äù„ÄÇ\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003c/ol\u003e\n\u003ch2 id=\"‰∫åone-hotÁºñÁ†ÅÁöÑÂä®Êú∫‰∏éÊµÅÁ®ã\"\u003e‰∫å„ÄÅOne-HotÁºñÁ†ÅÁöÑÂä®Êú∫‰∏éÊµÅÁ®ã\u003c/h2\u003e\n\u003col\u003e\n\u003cli\u003e\n\u003cp\u003e\u003cstrong\u003e‰∏∫‰ªÄ‰πà‰ΩøÁî®One-Hot\u003c/strong\u003e\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eÈÄöËøáÂ∞ÜÁ±ªÂà´Êò†Â∞Ñ‰∏∫ÂêëÈáèÔºåÈÅøÂÖçÊï¥Êï∞ÁºñÁ†ÅÂºïÂÖ•ÁöÑ‰º™Êï∞ÂÄºÂÖ≥Á≥ª„ÄÇ\u003c/li\u003e\n\u003cli\u003eÂêåÊó∂‰øùÁïôÂêÑÁßçÂèØËÉΩÁ±ªÂà´ÁöÑ‰ø°ÊÅØÔºå‰∏î‰ªÖÂú®ÂØπÂ∫î‰ΩçÁΩÆ‰∏∫1ÔºåÂÖ∂‰ªñ‰ΩçÁΩÆ‰∏∫0„ÄÇ\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003e\u003cstrong\u003eÂª∫Á´ãÊò†Â∞ÑÔºö‰ªéÁ±ªÂà´Âà∞Á¥¢Âºï\u003c/strong\u003e\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e‰∏∫ÊØè‰∏™Á±ªÂà´ÂàÜÈÖç‰∏Ä‰∏™ÂîØ‰∏ÄÁ¥¢ÂºïÔºåÈÄöÂ∏∏‰ªé1ÂºÄÂßã„ÄÇ\u003c/li\u003e\n\u003cli\u003eÈ¢ÑÁïôÁ¥¢Âºï0Ë°®Á§∫‚ÄúÊú™Áü•‚ÄùÊàñ‚ÄúÁº∫Â§±‚ÄùÔºåÂØπÂ∫îÂÖ®0ÂêëÈáè„ÄÇ\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003e\u003cstrong\u003eËΩ¨Êç¢‰∏∫One-HotÂêëÈáè\u003c/strong\u003e\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eËã•Á±ªÂà´ÊÄªÊï∞‰∏∫197ÔºåÂàôÁî®197Áª¥ÂêëÈáèË°®Á§∫„ÄÇ\u003c/li\u003e\n\u003cli\u003e‰æãÂ≠êÔºöÁæéÂõΩ \u003ccode\u003e[1, 0, 0, 0, ‚Ä¶]\u003c/code\u003eÔºå ‰∏≠ÂõΩ \u003ccode\u003e[0, 1, 0, 0, ‚Ä¶]\u003c/code\u003e„ÄÇ\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003e\u003cstrong\u003eÁ§∫‰æãÔºöË°®Á§∫‰∏Ä‰∏™‰∫∫ÁöÑÁâπÂæÅ\u003c/strong\u003e\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eÁâπÂæÅÂåÖÂê´ÔºàÂπ¥ÈæÑ, ÊÄßÂà´, ÂõΩÁ±çÔºåÂÖ∂‰∏≠ÂõΩÁ±ç197ÁßçÔºâ\u003c/li\u003e\n\u003cli\u003eÁª¥Â∫¶ÊÄªÂíåÔºö1Áª¥_age + 1Áª¥_gender + 197Áª¥_nationality = 199Áª¥„ÄÇ\u003c/li\u003e\n\u003cli\u003e‰æãÂ¶Ç \u003ccode\u003e(28, Â•≥, ‰∏≠ÂõΩ)\u003c/code\u003e ‚Üí \u003ccode\u003e[28, 0, 0, 1, 0, ‚Ä¶, 0]\u003c/code\u003e„ÄÇ\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003c/ol\u003e\n\u003ch2 id=\"‰∏âÊñáÊú¨Êï∞ÊçÆÂ§ÑÁêÜÊµÅÁ®ã\"\u003e‰∏â„ÄÅÊñáÊú¨Êï∞ÊçÆÂ§ÑÁêÜÊµÅÁ®ã\u003c/h2\u003e\n\u003cp\u003eÊñáÊú¨Âú®Ëá™ÁÑ∂ËØ≠Ë®ÄÂ§ÑÁêÜÔºàNLPÔºâ‰∏≠‰Ωú‰∏∫Â∏∏ËßÅÁöÑÂéüÂßãËæìÂÖ•ÔºåÈúÄË¶ÅÊï∞ÂÄºÂåñÊâçËÉΩÈÄÅÂÖ•Ê®°Âûã„ÄÇ‰∏ÄËà¨Ê≠•È™§Â¶Ç‰∏ãÔºö\u003c/p\u003e\n\u003col\u003e\n\u003cli\u003e\n\u003cp\u003e\u003cstrong\u003eÂàÜËØç (Tokenization)\u003c/strong\u003e\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eÂ∞ÜÊñáÊú¨ÊãÜÂàÜ‰∏∫‰∏Ä‰∏™‰∏™ÂçïËØçÔºàTokenÔºâ„ÄÇ\u003c/li\u003e\n\u003cli\u003e‰æãÂ≠êÔºö\u003ccode\u003e\u0026quot;... to be or not to be...\u0026quot;\u003c/code\u003e ‚Üí \u003ccode\u003e[\u0026quot;...\u0026quot;, \u0026quot;to\u0026quot;, \u0026quot;be\u0026quot;, \u0026quot;or\u0026quot;, \u0026quot;not\u0026quot;, \u0026quot;to\u0026quot;, \u0026quot;be\u0026quot;, \u0026quot;...\u0026quot;]\u003c/code\u003e„ÄÇ\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003e\u003cstrong\u003eÁªüËÆ°ËØçÈ¢ë \u0026amp; ÊûÑÂª∫ËØçÂÖ∏\u003c/strong\u003e\u003c/p\u003e","title":""},{"content":"Text to Sequence ÊñáÊú¨Â§ÑÁêÜ\nStep1: Tokenization\nTokenization breaks a piece of text down into a list of tokens.\nHere, a token is a word. (A token can be a character in some applications.)\nTokenizationËÆ≤Á©∂ÂæàÂ§öÔºå‰æãÂ¶ÇÊòØÂê¶Â∫îËØ•ÊääÂ§ßÂÜôÊîπÊàêÂ∞èÂÜôÂë¢ÔºüËøõË°åtypo correctionÁ≠âÁ≠â\nStep2: Build Dictionary\nUse a dictionary (hash table) to count word frequencies.\nThe dictionary maps word to index.\nÂèØ‰ª•È¶ñÂÖàÁªüËÆ°ËØçÈ¢ëÂéªÊéâ‰ΩéÈ¢ëËØçÔºåÁÑ∂ÂêéËÆ©ÊØè‰∏™ËØçÂØπÂ∫î‰∏Ä‰∏™Ê≠£Êï¥Êï∞ÔºõËøôÊ†∑ÁöÑËØùÔºå‰∏ÄÂè•ËØùÂ∞±ÂèØ‰ª•Áî®‰∏Ä‰∏™Ê≠£Êï¥Êï∞ÂàóË°®Ë°®Á§∫ÔºåËøô‰∏™ÂàóË°®Â∞±Âè´sequenceÔºõÂ¶ÇÊûúÂøÖË¶ÅÂ∞±ËøòÂæóÂÅöone-hot encoding„ÄÇ\nÁªìÊûú\n‰ΩÜÊòØÈïøÂ∫¶‰∏çÁªü‰∏Ä\nStep4: ÂØπÈΩêsequence\nËß£ÂÜ≥ÊñπÊ°àÊòØËøôÊ†∑ÁöÑÔºöÂèØ‰ª•Âõ∫ÂÆöÈïøÂ∫¶‰∏∫wÔºåÂä†ÂÖ•‰∏Ä‰∏™Â∫èÂàóÈïøÂ∫¶Â§™ÈïøÔºåÂ∞±Á†çÊéâÂâçÈù¢ÁöÑËØçÔºåÂè™‰øùÁïôÊúÄÂêéw‰∏™ËØçÔºõÂ¶ÇÊûú‰∏Ä‰∏™Â∫èÂàóÂ§™Áü≠ÔºåÂ∞±ÂÅözero paddingÔºåÁî®0Â°´ÂÖÖ\nËøôÊ†∑‰∏ÄÊù•ÔºåÊâÄÊúâÁöÑÂ∫èÂàóÈïøÂ∫¶Â∞±Áªü‰∏Ä‰∫Ü\nÊñáÊú¨Â§ÑÁêÜÂÆåÊàê‰∫ÜÔºåÊé•‰∏ãÊù•ÊòØword embeddingÔºåÊääÂçïËØçË°®Á§∫‰∏∫‰∏Ä‰∏™‰ΩéÁª¥ÂêëÈáèÔºõ\nÁÑ∂ËÄåËøôÊ†∑ÂÅöÁöÑËØùÔºåÂ¶ÇÊûúÊòØ10000‰∏™ÂçïËØçÔºåÁª¥Â∫¶Â∞±ÊòØ10000Áª¥ÔºåÁª¥Â∫¶Â§™È´ò‰∫ÜÔºõÂõ†Ê≠§Ë¶ÅÂÅöword embeddingÔºõ\nÂÖ∑‰ΩìÂÅöÊ≥ïÂ∞±ÊòØÊääone-hotÂêëÈáèe_iÂíåÂèÇÊï∞Áü©ÈòµpÁõ∏‰πòÔºõÁü©ÈòµPËΩ¨ÁΩÆÁöÑÂ§ßÂ∞èÊòØd x vÔºõdÊòØËØçÂêëÈáèÁöÑÁª¥Â∫¶ÔºõvÊòØÂ≠óÂÖ∏ÈáåËØçÊ±áÁöÑÊï∞ÈáèÔºõÁªìÊûú‰∏∫x_iÔºõx_iÂ∞±ÊòØ‰∏Ä‰∏™ËØçÂêëÈáèÔºõÂ¶ÇÊûúone-hotÂêëÈáèÁöÑÁ¨¨‰∏âË°å‰∏∫1ÔºõÈÇ£‰πàx_iÂ∞±ÊòØPËΩ¨ÁΩÆÁü©ÈòµÁöÑÁ¨¨‰∏âÂàóÔºàÂÖ∂‰ΩôÂàóÈÉΩ‰∏∫0ÔºâÔºõÊâÄ‰ª•PËΩ¨ÁΩÆÊØè‰∏ÄÂàóÈÉΩÊòØ‰∏Ä‰∏™ËØçÂêëÈáèÔºõÊâÄ‰ª•Áü©ÈòµPÊú¨Ë∫´ÁöÑÊØè‰∏ÄË°åÂ∞±ÊòØ‰∏Ä‰∏™ËØçÂêëÈáèÔºõÂÖ∂Ë°åÊï∞‰∏∫vÔºõÂç≥vocabularyÔºåËØçÊ±áÈáèÔºõÊØè‰∏ÄË°åÂØπÂ∫î‰∏Ä‰∏™ÂçïËØçÔºõÁü©ÈòµÁöÑÂàóÊï∞‰∏∫dÔºõdÊòØÁî®Êà∑ÂÜ≥ÂÆöÁöÑÔºõdÁöÑÂ§ßÂ∞è‰ºöÂÜ≥ÂÆöÊú∫Âô®Â≠¶‰π†Ê®°ÂûãÁöÑË°®Áé∞ÔºõÂ∫îËØ•Áî®xxxÊù•ÈÄâÊã©‰∏Ä‰∏™ÊØîËæÉÂ•ΩÁöÑdÔºõ\nÊàë‰ª¨ÁöÑ‰ªªÂä°ÊòØÁúãËØÑËÆ∫ÊòØÊ≠£Èù¢ÁöÑËøòÊòØË¥üÈù¢ÁöÑÔºõÂèÇÊï∞Áü©ÈòµÊòØ‰ªéËÆ≠ÁªÉÊï∞ÊçÆ‰∏≠Â≠¶‰π†Âá∫Êù•ÁöÑÔºåÊâÄ‰ª•Â≠¶Âá∫Êù•ÁöÑËØçÂêëÈáèÊòØÂ∏¶ÊúâÊÑüÊÉÖËâ≤ÂΩ©ÁöÑÔºõÂÅáËÆæËøô‰∫õËØçÂêëÈáèÈÉΩÊòØ‰∫åÁª¥ÁöÑÔºåÂàôÂèØ‰ª•Âú®Âπ≥Èù¢ÂùêÊ†áÁ≥ª‰∏≠Ê†áÂá∫‰∏ãÈù¢ËØçÂêëÈáè\nkerasÊèê‰æõembeddingÂ±ÇÔºõÁî®Êà∑ÂèØ‰ª•ÊåáÂÆövocabularyÂ§ßÂ∞èÂíådÁöÑÂ§ßÂ∞èÔºõ‰ª•ÂèäÊØè‰∏Ä‰∏™sequenceÁöÑÈïøÂ∫¶ÔºõdÊòØÊ†πÊçÆÁÆóÊ≥ïÈÄâÂá∫Êù•ÁöÑ Âà∞Ëøô‰∏ÄÊ≠•ÔºåÊàë‰ª¨Â∑≤ÁªèÂÆåÊàê‰∫ÜÊñáÊú¨Â§ÑÁêÜÂíåword embedding„ÄÇÊé•‰∏ãÊù•Â∞±ÊòØÁî®Logistic Regression for Binary ClassificationÂÅö‰∫åÂàÜÁ±ªÔºõ\n","permalink":"http://localhost:1313/posts/nlp-2/","summary":"\u003ch3 id=\"text-to-sequence\"\u003eText to Sequence\u003c/h3\u003e\n\u003cp\u003eÊñáÊú¨Â§ÑÁêÜ\u003c/p\u003e\n\u003cp\u003eStep1: Tokenization\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\n\u003cp\u003eTokenization breaks a piece of text down into a list of tokens.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003eHere, a token is a word. (A token can be a character in some applications.)\u003c/p\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003eTokenizationËÆ≤Á©∂ÂæàÂ§öÔºå‰æãÂ¶ÇÊòØÂê¶Â∫îËØ•ÊääÂ§ßÂÜôÊîπÊàêÂ∞èÂÜôÂë¢ÔºüËøõË°åtypo correctionÁ≠âÁ≠â\u003c/p\u003e\n\u003cp\u003e\u003cimg alt=\"image-20250322150322238\" loading=\"lazy\" src=\"./NLP-2.assets/image-20250322150322238.png\"\u003e\u003c/p\u003e\n\u003cp\u003eStep2: Build Dictionary\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\n\u003cp\u003eUse a dictionary (hash table) to count word frequencies.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003eThe dictionary maps word to index.\u003c/p\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003eÂèØ‰ª•È¶ñÂÖàÁªüËÆ°ËØçÈ¢ëÂéªÊéâ‰ΩéÈ¢ëËØçÔºåÁÑ∂ÂêéËÆ©ÊØè‰∏™ËØçÂØπÂ∫î‰∏Ä‰∏™Ê≠£Êï¥Êï∞ÔºõËøôÊ†∑ÁöÑËØùÔºå‰∏ÄÂè•ËØùÂ∞±ÂèØ‰ª•Áî®‰∏Ä‰∏™Ê≠£Êï¥Êï∞ÂàóË°®Ë°®Á§∫ÔºåËøô‰∏™ÂàóË°®Â∞±Âè´sequenceÔºõÂ¶ÇÊûúÂøÖË¶ÅÂ∞±ËøòÂæóÂÅöone-hot encoding„ÄÇ\u003cimg alt=\"image-20250322150620890\" loading=\"lazy\" src=\"./NLP-2.assets/image-20250322150620890.png\"\u003e\u003c/p\u003e\n\u003cp\u003eÁªìÊûú\u003c/p\u003e\n\u003cp\u003e\u003cimg alt=\"image-20250322150754528\" loading=\"lazy\" src=\"./NLP-2.assets/image-20250322150754528.png\"\u003e\u003c/p\u003e\n\u003cp\u003e‰ΩÜÊòØÈïøÂ∫¶‰∏çÁªü‰∏Ä\u003c/p\u003e\n\u003cp\u003eStep4: ÂØπÈΩêsequence\u003c/p\u003e\n\u003cp\u003e\u003cimg alt=\"image-20250322150854986\" loading=\"lazy\" src=\"./NLP-2.assets/image-20250322150854986.png\"\u003e\u003c/p\u003e\n\u003cp\u003eËß£ÂÜ≥ÊñπÊ°àÊòØËøôÊ†∑ÁöÑÔºöÂèØ‰ª•Âõ∫ÂÆöÈïøÂ∫¶‰∏∫wÔºåÂä†ÂÖ•‰∏Ä‰∏™Â∫èÂàóÈïøÂ∫¶Â§™ÈïøÔºåÂ∞±Á†çÊéâÂâçÈù¢ÁöÑËØçÔºåÂè™‰øùÁïôÊúÄÂêéw‰∏™ËØçÔºõÂ¶ÇÊûú‰∏Ä‰∏™Â∫èÂàóÂ§™Áü≠ÔºåÂ∞±ÂÅözero paddingÔºåÁî®0Â°´ÂÖÖ\u003c/p\u003e\n\u003cp\u003e\u003cimg alt=\"image-20250322151030119\" loading=\"lazy\" src=\"./NLP-2.assets/image-20250322151030119.png\"\u003e\u003c/p\u003e\n\u003cp\u003eËøôÊ†∑‰∏ÄÊù•ÔºåÊâÄÊúâÁöÑÂ∫èÂàóÈïøÂ∫¶Â∞±Áªü‰∏Ä‰∫Ü\u003c/p\u003e\n\u003cp\u003e\u003cimg alt=\"image-20250322151117125\" loading=\"lazy\" src=\"./NLP-2.assets/image-20250322151117125.png\"\u003e\u003c/p\u003e\n\u003cp\u003eÊñáÊú¨Â§ÑÁêÜÂÆåÊàê‰∫ÜÔºåÊé•‰∏ãÊù•ÊòØword embeddingÔºåÊääÂçïËØçË°®Á§∫‰∏∫‰∏Ä‰∏™‰ΩéÁª¥ÂêëÈáèÔºõ\u003c/p\u003e\n\u003cp\u003e\u003cimg alt=\"image-20250322151252837\" loading=\"lazy\" src=\"./NLP-2.assets/image-20250322151252837.png\"\u003e\u003c/p\u003e","title":""},{"content":"üëã About me Hello! I\u0026rsquo;m Xu Zongsi, a passionate technology enthusiast currently pursuing my Master of Science in ECIC at The University of Hong Kong. With a solid background in Software Engineering from the Beijing Institute of Technology, I specialize in artificial intelligence areas like machine learning, deep learning, natural language processing, computer vision, and reinforcement learning.\nInspired by OpenAI\u0026rsquo;s five-step plan towards superintelligence, I am excited about AGI and have developed a keen interest in LLM agents, MLLM, and knowledge graphs. I see great potential in these fields and aspire to contribute to innovative solutions.\nüìö Education üá≠üá∞ The University of Hong Kong 09/2024 - Expected 11/2025 School of Computing and Data Science Master of Science in Electronic Commerce \u0026amp; Internet Computing Relevant Courses: Machine learning for business and e-commerce, Knowledge graphs, Financial fraud analytics, Internet infrastructure technologies, Website engineering, Blockchain and cryptocurrency, etc. üá®üá≥ Beijing Institute of Technology 09/2020 - 06/2024 School of Computer Science \u0026amp; Technology Bachelor of Engineering in Software Engineering, last two years GPA: 3.7/4 Relevant Courses: Reinforcement Learning, Deep Learning and Computer Vision, Artificial Intelligence and Robot Ethics, Almost Human: Mind, Brain and Artificial Intelligence, Mathematical Analysis for Engineering, Linear Algebra, Probability and Mathematical Statistics, etc. Skills: Python, Java, common data structures, design patterns, machine learning basics and algorithms, Linux, PyTorch, and some development tools (git, conda, etc.). üèÜ Awards \u0026amp; Honors Beijing Institute of Technology Undergraduate Scholarship (Top 20% of Grade) 06/2023 3rd Prize of China International \u0026#34;Internet \u0026#43;\u0026#34; College Student\u0026#39;s Innovation Competition 08/2022 Bronze Prize of \u0026#34;Challenge Cup\u0026#34; Capital University Entrepreneurship Competition 05/2022 üíº Project Experience üîç Online Transaction Fraud Detection 09/2024 ‚Äì 01/2025 Independent project, supervised by Dr. Vivien Chan Focused on addressing financial fraud in e-commerce to enhance the accuracy of transaction anomaly detection, while independently managing the entire case study that included data preprocessing, feature engineering, model building, evaluation, and results analysis. Effectively resolved class imbalance issues using SMOTE and ROSE techniques. Built various models including Logistic Regression, Random Forest, XGBoost, and LightGBM, ultimately selecting the LightGBM model to achieve a recall rate of 95.45% and an AUC of 99.84%. Wrote efficient and maintainable code, enhancing model training and data processing efficiency through parallel computing and logging. ü§ñ Multi-Model Intelligent Text Keyword Extraction System 08/2023 ‚Äì 09/2023 Group project, supervised by Associate Prof. Xiaolin Zhao Designed and implemented an intelligent text summary system that automatically extracts keywords from article titles and abstracts, enhancing the understanding and summarization of text information. Participated in the planning of the technical route and built a hybrid model combining extractive and generative approaches, utilizing advanced natural language processing techniques including KeyBERT, Sentence Transformer, BERT, and T5 models. Responsible for data preprocessing and tokenization, as well as the end-to-end implementation and training of the T5 model, optimizing the model architecture and hyperparameters, achieving satisfactory results after only 3 epochs of training. Model evaluation results showed that the Rouge-1, Rouge-2, and Rouge-L metrics reached 0.6345, 0.5038, and 0.5282, respectively, in the third epoch, validating the model\u0026rsquo;s effectiveness in the summarization task. üéì Cambridge University Machine Learning Summer Project 07/2023 ‚Äì 08/2023 Group project, supervised by Prof. Pietro Li√≤ Participated in the Cambridge University deep learning summer project, focusing on deep reinforcement learning; explored multi-agent learning algorithms across different environments. Reproduced the Multi-Agent Deep Deterministic Policy Gradient (MADDPG) algorithm in the Simple Adversary environment and studied the effect of agent numbers on convergence speed and stability, finding optimal stability at 21 agents. Designed and implemented comparative experiments inspired by the Rainbow algorithm, assessing target network strategies versus the Double Deep Q-Network (Double DQN). The results demonstrated that Double DQN significantly enhanced convergence speed, optimizing the overall learning process. Co-authored a group project paper on agent numbers and strategies effectiveness in multi-agent systems, achieving a score of 71% in the summer program (the highest in my group) and a \u0026ldquo;First Class\u0026rdquo; classification in the UK grading system. üëÅÔ∏è Deep Learning and Computer Vision Semester Project 09/2022 ‚Äì 12/2022 Independent project, supervised by Associate Prof. Guangyu Gao Designed and implemented a waste classifier using the ResNet model to improve classification accuracy and reduce resource waste. The project also enhanced understanding of transfer learning techniques with ResNet. Collected a dataset of 16 waste categories and preprocessed the images for uniformity and standardization, incorporating data augmentation techniques to enhance the dataset. Conducted experiments using ResNet34 and ResNet50 models through transfer learning, accelerating network convergence by leveraging pretrained weights. During training, techniques such as Batch Normalization and Dropout were applied to mitigate the risk of overfitting. The final model achieved an accuracy of 90% on the training set, while the performance on the test set was 61%, indicating a significant overfitting phenomenon during the training process. üéì Internship ‚öõÔ∏è Beijing Academy of Quantum Information Science 08/2023 ‚Äì 01/2024 Research Intern at Quantum Computation Department Proposed a quantum convolution kernel design based on variational quantum circuits and developed a universal quantum convolution layer, successfully integrating it into classical CNN architectures such as VGG, GoogLeNet, and ResNet. Developed and evaluated various hybrid models, including a simple model named HQCCNN-2, which achieved 84.45% accuracy on the FashionMNIST dataset, surpassing the traditional CNN\u0026rsquo;s 80.72%. This demonstrates the effectiveness of the quantum convolution layer in improving model performance. Tested on a real quantum computer further validated the effectiveness of the hybrid model, demonstrating the viable integration of quantum computing with deep learning, and highlighting the potential for leveraging quantum properties to enhance model performance. üèÖ Competition Experience ü•â China International \u0026#34;Internet \u0026#43;\u0026#34; College Students\u0026#39; Innovation Competition 08/2022 üõ°Ô∏è Zhongke Ushield: Deep Learning-based Face Privacy Protection Authentication System Responsible for constructing a localized facial feature extraction engine based on MobileFaceNet, ensuring feature extraction is completed on end devices (such as mobile phones and cameras), guaranteeing that raw data does not leave the domain and is not stored, thus enhancing user privacy protection while improving recognition efficiency. ü•â \u0026#34;Challenge Cup\u0026#34; Capital University Entrepreneurship Competition 05/2022 üå≥ Smart Orchard Responsible for the development of the fruit detection, ripeness prediction, and pest identification system, using deep convolutional neural network (CNN) technology for intelligent monitoring of crop growth conditions. Applied advanced object detection algorithms such as Faster R-CNN and YOLO to achieve high precision in apple detection and ripeness assessment, with an accuracy rate exceeding 90%, significantly enhancing the intelligence level of orchard management. Built and trained a dedicated dataset containing various pest samples, optimizing pest detection accuracy through data preprocessing (such as image normalization and resizing) and data augmentation techniques (like rotation, flipping, and noise addition), enabling the real-time monitoring system to accurately identify over 80% of pests, providing effective scientific maintenance recommendations to help farmers reduce crop losses. üìã Extracurricular Activities Vice President, Cyber Security Club, Beijing Institute of Technology 09/2021-09/2022 Backbone, Media Center of the Student Union of Beijing Institute of Technology 10/2020-06/2021 üì´ Contact üìß Email: zongsi.xu@outlook.com üëî LinkedIn: Zongsi (Tristan) Xu üíª GitHub: github.com/BaizeXS üìç Location: Hong Kong SAR, China ","permalink":"http://localhost:1313/resume/","summary":"Personal resume of Zongsi (Tristan) Xu","title":"Zongsi (Tristan) Xu"},{"content":"‰∏Ä„ÄÅÊï∞ÂÄºÁâπÂæÅ‰∏éÁ±ªÂà´ÁâπÂæÅ Êï∞ÂÄºÁâπÂæÅ (Numeric Features) ÂÖ∑ÊúâÂèØÂä†ÂáèÁöÑÊÑè‰πâÔºå‰∏îÂ≠òÂú®Â§ßÂ∞èÈ°∫Â∫è„ÄÇ ‰æãÂ≠êÔºöÂπ¥ÈæÑ„ÄÅÊ∏©Â∫¶Á≠â„ÄÇÂèØ‰ª•Áõ¥Êé•‰øùÁïôÂÖ∂Êï¥Êï∞ÊàñÊµÆÁÇπÊï∞ÂΩ¢Âºè‰æõÊ®°Âûã‰ΩøÁî®„ÄÇ Á±ªÂà´ÁâπÂæÅ (Categorical Features) Êï∞ÊçÆÂÄºÁ¶ªÊï£Ôºå‰∏çÂÖ∑Â§á‚ÄúÊï∞ÂÄºÂ§ßÂ∞è‚ÄùÈó¥ÁöÑÂèØÊØîÊÑè‰πâ„ÄÇ ‰æãÂ≠êÔºöÂõΩÁ±çÔºàÁæéÂõΩ/‰∏≠ÂõΩ/Âç∞Â∫¶Á≠âÔºâ„ÄÅÊÄßÂà´ÔºàÁî∑/Â•≥ÔºâÁ≠â„ÄÇ ÈóÆÈ¢òÔºöËã•‰ªÖÁî®Êï¥Êï∞Ë°®Á§∫ÔºàÁæéÂõΩ=1, ‰∏≠ÂõΩ=2ÔºâÔºå‰ºöÂºïÂÖ•ÈîôËØØÁöÑÊï∞ÂÄºËøêÁÆóÂÖ≥Á≥ªÔºåÂ¶Ç ‚ÄúÁæéÂõΩ + ‰∏≠ÂõΩ = Âç∞Â∫¶‚Äù„ÄÇ ‰∫å„ÄÅOne-HotÁºñÁ†ÅÁöÑÂä®Êú∫‰∏éÊµÅÁ®ã ‰∏∫‰ªÄ‰πà‰ΩøÁî®One-Hot\nÈÄöËøáÂ∞ÜÁ±ªÂà´Êò†Â∞Ñ‰∏∫ÂêëÈáèÔºåÈÅøÂÖçÊï¥Êï∞ÁºñÁ†ÅÂºïÂÖ•ÁöÑ‰º™Êï∞ÂÄºÂÖ≥Á≥ª„ÄÇ ÂêåÊó∂‰øùÁïôÂêÑÁßçÂèØËÉΩÁ±ªÂà´ÁöÑ‰ø°ÊÅØÔºå‰∏î‰ªÖÂú®ÂØπÂ∫î‰ΩçÁΩÆ‰∏∫1ÔºåÂÖ∂‰ªñ‰ΩçÁΩÆ‰∏∫0„ÄÇ Âª∫Á´ãÊò†Â∞ÑÔºö‰ªéÁ±ªÂà´Âà∞Á¥¢Âºï\n‰∏∫ÊØè‰∏™Á±ªÂà´ÂàÜÈÖç‰∏Ä‰∏™ÂîØ‰∏ÄÁ¥¢ÂºïÔºåÈÄöÂ∏∏‰ªé1ÂºÄÂßã„ÄÇ È¢ÑÁïôÁ¥¢Âºï0Ë°®Á§∫‚ÄúÊú™Áü•‚ÄùÊàñ‚ÄúÁº∫Â§±‚ÄùÔºåÂØπÂ∫îÂÖ®0ÂêëÈáè„ÄÇ ËΩ¨Êç¢‰∏∫One-HotÂêëÈáè\nËã•Á±ªÂà´ÊÄªÊï∞‰∏∫197ÔºåÂàôÁî®197Áª¥ÂêëÈáèË°®Á§∫„ÄÇ ‰æãÂ≠êÔºöÁæéÂõΩ [1, 0, 0, 0, ‚Ä¶]Ôºå ‰∏≠ÂõΩ [0, 1, 0, 0, ‚Ä¶]„ÄÇ Á§∫‰æãÔºöË°®Á§∫‰∏Ä‰∏™‰∫∫ÁöÑÁâπÂæÅ\nÁâπÂæÅÂåÖÂê´ÔºàÂπ¥ÈæÑ, ÊÄßÂà´, ÂõΩÁ±çÔºåÂÖ∂‰∏≠ÂõΩÁ±ç197ÁßçÔºâ Áª¥Â∫¶ÊÄªÂíåÔºö1Áª¥_age + 1Áª¥_gender + 197Áª¥_nationality = 199Áª¥„ÄÇ ‰æãÂ¶Ç (28, Â•≥, ‰∏≠ÂõΩ) ‚Üí [28, 0, 0, 1, 0, ‚Ä¶, 0]„ÄÇ ‰∏â„ÄÅÊñáÊú¨Êï∞ÊçÆÂ§ÑÁêÜÊµÅÁ®ã ÊñáÊú¨Âú®Ëá™ÁÑ∂ËØ≠Ë®ÄÂ§ÑÁêÜÔºàNLPÔºâ‰∏≠‰Ωú‰∏∫Â∏∏ËßÅÁöÑÂéüÂßãËæìÂÖ•ÔºåÈúÄË¶ÅÊï∞ÂÄºÂåñÊâçËÉΩÈÄÅÂÖ•Ê®°Âûã„ÄÇ‰∏ÄËà¨Ê≠•È™§Â¶Ç‰∏ãÔºö\nÂàÜËØç (Tokenization)\nÂ∞ÜÊñáÊú¨ÊãÜÂàÜ‰∏∫‰∏Ä‰∏™‰∏™ÂçïËØçÔºàTokenÔºâ„ÄÇ ‰æãÂ≠êÔºö\u0026quot;... to be or not to be...\u0026quot; ‚Üí [\u0026quot;...\u0026quot;, \u0026quot;to\u0026quot;, \u0026quot;be\u0026quot;, \u0026quot;or\u0026quot;, \u0026quot;not\u0026quot;, \u0026quot;to\u0026quot;, \u0026quot;be\u0026quot;, \u0026quot;...\u0026quot;]„ÄÇ ÁªüËÆ°ËØçÈ¢ë \u0026amp; ÊûÑÂª∫ËØçÂÖ∏\nËØçÈ¢ëÁªüËÆ° Áî®ÂìàÂ∏åË°®/Â≠óÂÖ∏ËÆ∞ÂΩïÊØè‰∏™ÂçïËØçÂá∫Áé∞Ê¨°Êï∞„ÄÇ ÈÅçÂéÜÊñáÊú¨Êó∂ÔºåËã•ÂçïËØçÂ∞öÊú™ÂÖ•Ë°®ÔºåÂàôÊñ∞Âª∫ËÆ∞ÂΩïÔºõËã•Â∑≤Â≠òÂú®ÔºåÂàôËÆ°Êï∞+1„ÄÇ ÊéíÂ∫è‰∏éÁ¥¢Âºï ÊåâËØçÈ¢ëÈôçÂ∫èÊéíÂ∫èÔºåËØçÈ¢ëÊúÄÈ´òÁöÑÂçïËØçÊéíÂú®ÂâçÈù¢„ÄÇ Á¥¢Âºï‰ªé1ÂºÄÂßãÔºå0ÁïôÁªô‚ÄúÊú™Áü•‚Äù„ÄÇ ËØçÂÖ∏ËßÑÊ®°ÔºàvocabularyÔºâÂèØËßÜÈúÄÊ±ÇÊà™Êñ≠Ôºà‰æãÂ¶ÇÂè™‰øùÁïôTop 10kÔºâ„ÄÇ ‰∏∫‰ªÄ‰πàÁßªÈô§‰ΩéÈ¢ëËØç ‰ΩéÈ¢ëËØçÂèØËÉΩÊòØÊãºÂÜôÈîôËØØ„ÄÅÁΩïËßÅ‰∫∫ÂêçÁ≠âÔºåÂØπÊ®°ÂûãÂ∏ÆÂä©ÊúâÈôê„ÄÇ ÂáèÂ∞ëËØçÂÖ∏ËßÑÊ®°ÂèØÈôç‰ΩéËøêÁÆóÂºÄÈîÄ„ÄÅÂä†Âø´Ê®°ÂûãËÆ≠ÁªÉ‰∏éÊé®ÁêÜÈÄüÂ∫¶„ÄÇ Áã¨ÁÉ≠ÁºñÁ†Å (One-Hot Encoding)\nÂ∞ÜÊØè‰∏™ÂçïËØçÊò†Â∞Ñ‰∏∫ËØçÂÖ∏‰∏≠ÁöÑÁ¥¢ÂºïÂêéÔºàÂ¶Ç [2, 4, 1, 8, ‚Ä¶]ÔºâÔºåÂèØËøõ‰∏ÄÊ≠•ËΩ¨Êç¢ÊàêOne-HotÂêëÈáè„ÄÇ One-HotÁª¥Â∫¶ÂèñÂÜ≥‰∫é‰øùÁïô‰∏ãÊù•ÁöÑËØçÂÖ∏Â§ßÂ∞èÔºà‰æãÂ¶Ç1‰∏áÔºâ„ÄÇ Êú™Êî∂ÂΩïÂçïËØçÂèØËÉΩÁõ¥Êé•ÂøΩÁï•ÔºåÊàñÁªü‰∏ÄÁî®Á¥¢Âºï0‰ª£Êõø„ÄÇ Âõõ„ÄÅÊ†∏ÂøÉÊî∂Ëé∑‰∏éÂ∫îÁî® Á±ªÂà´ÁâπÂæÅÂøÖÈúÄÊï∞ÂÄºÂåñÔºö\n‰ΩøÁî®Êï¥Êï∞1,2,3‚Ä¶‰ªÖË°®Á§∫Á±ªÂà´‚ÄúÊ†áËØÜ‚ÄùÔºåÂπ∂‰∏ç‰ª£Ë°®ÂÆÉ‰ª¨ÂèØËøõË°åÊï∞ÂÄºËøêÁÆó„ÄÇ Âõ†Ê≠§ÈúÄË¶ÅOne-HotÁ≠âÁºñÁ†ÅÊñπÂºèÔºåÈÅøÂÖçÊï∞ÂÄºËØØËß£„ÄÇ ÊñáÊú¨Êï∞ÊçÆÈ¢ÑÂ§ÑÁêÜÔºö\nÂàÜËØç„ÄÅËØçÈ¢ëÁªüËÆ°„ÄÅÊûÑÂª∫ËØçÂÖ∏„ÄÅÁ¥¢ÂºïÂåñ„ÄÅOne-HotÊàñÂÖ∂‰ªñÊñπÂºèÔºàÂ¶ÇËØçÂµåÂÖ•ÔºâÊòØÂ∏∏ËßÅÊµÅÁ®ã„ÄÇ Ê≠£Á°ÆÁöÑÊñáÊú¨È¢ÑÂ§ÑÁêÜÂèØÊòæËëóÂΩ±ÂìçÊ®°ÂûãÊÄßËÉΩÂíåÊïàÁéá„ÄÇ ‰øùÁïôÊú™Áü•Á¥¢ÂºïÔºö\n‰øùËØÅÂØπÁº∫Â§±Êï∞ÊçÆÊàñÂ≠óÂÖ∏Â§ñÊñ∞ËØçËÉΩÊúâÂü∫Êú¨ÁöÑË°®Á§∫ÔºåÊèêÂçáÊ®°ÂûãÂÆπÈîôÊÄß„ÄÇ ÂÆûÈôÖ‰ΩøÁî®Ôºö\nÂØπ‰∫éÂ∞èËßÑÊ®°Á±ªÂà´ÂèØÁõ¥Êé•One-HotÁºñÁ†ÅÔºõÂØπ‰∫éËØçÂÖ∏ÂæàÂ§ßÁöÑÂú∫ÊôØÔºåÈÄöÂ∏∏‰ºöËøõ‰∏ÄÊ≠•ËÄÉËôëËØçÂµåÂÖ•ÔºàWord EmbeddingÔºâÊàñÈ¢ÑËÆ≠ÁªÉËØ≠Ë®ÄÊ®°Âûã„ÄÇ ","permalink":"http://localhost:1313/posts/nlp-1/","summary":"\u003ch2 id=\"‰∏ÄÊï∞ÂÄºÁâπÂæÅ‰∏éÁ±ªÂà´ÁâπÂæÅ\"\u003e‰∏Ä„ÄÅÊï∞ÂÄºÁâπÂæÅ‰∏éÁ±ªÂà´ÁâπÂæÅ\u003c/h2\u003e\n\u003col\u003e\n\u003cli\u003e\u003cstrong\u003eÊï∞ÂÄºÁâπÂæÅ (Numeric Features)\u003c/strong\u003e\n\u003cul\u003e\n\u003cli\u003eÂÖ∑ÊúâÂèØÂä†ÂáèÁöÑÊÑè‰πâÔºå‰∏îÂ≠òÂú®Â§ßÂ∞èÈ°∫Â∫è„ÄÇ\u003c/li\u003e\n\u003cli\u003e‰æãÂ≠êÔºöÂπ¥ÈæÑ„ÄÅÊ∏©Â∫¶Á≠â„ÄÇÂèØ‰ª•Áõ¥Êé•‰øùÁïôÂÖ∂Êï¥Êï∞ÊàñÊµÆÁÇπÊï∞ÂΩ¢Âºè‰æõÊ®°Âûã‰ΩøÁî®„ÄÇ\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003eÁ±ªÂà´ÁâπÂæÅ (Categorical Features)\u003c/strong\u003e\n\u003cul\u003e\n\u003cli\u003eÊï∞ÊçÆÂÄºÁ¶ªÊï£Ôºå‰∏çÂÖ∑Â§á‚ÄúÊï∞ÂÄºÂ§ßÂ∞è‚ÄùÈó¥ÁöÑÂèØÊØîÊÑè‰πâ„ÄÇ\u003c/li\u003e\n\u003cli\u003e‰æãÂ≠êÔºöÂõΩÁ±çÔºàÁæéÂõΩ/‰∏≠ÂõΩ/Âç∞Â∫¶Á≠âÔºâ„ÄÅÊÄßÂà´ÔºàÁî∑/Â•≥ÔºâÁ≠â„ÄÇ\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003eÈóÆÈ¢ò\u003c/strong\u003eÔºöËã•‰ªÖÁî®Êï¥Êï∞Ë°®Á§∫ÔºàÁæéÂõΩ=1, ‰∏≠ÂõΩ=2ÔºâÔºå‰ºöÂºïÂÖ•ÈîôËØØÁöÑÊï∞ÂÄºËøêÁÆóÂÖ≥Á≥ªÔºåÂ¶Ç ‚ÄúÁæéÂõΩ + ‰∏≠ÂõΩ = Âç∞Â∫¶‚Äù„ÄÇ\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003c/ol\u003e\n\u003ch2 id=\"‰∫åone-hotÁºñÁ†ÅÁöÑÂä®Êú∫‰∏éÊµÅÁ®ã\"\u003e‰∫å„ÄÅOne-HotÁºñÁ†ÅÁöÑÂä®Êú∫‰∏éÊµÅÁ®ã\u003c/h2\u003e\n\u003col\u003e\n\u003cli\u003e\n\u003cp\u003e\u003cstrong\u003e‰∏∫‰ªÄ‰πà‰ΩøÁî®One-Hot\u003c/strong\u003e\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eÈÄöËøáÂ∞ÜÁ±ªÂà´Êò†Â∞Ñ‰∏∫ÂêëÈáèÔºåÈÅøÂÖçÊï¥Êï∞ÁºñÁ†ÅÂºïÂÖ•ÁöÑ‰º™Êï∞ÂÄºÂÖ≥Á≥ª„ÄÇ\u003c/li\u003e\n\u003cli\u003eÂêåÊó∂‰øùÁïôÂêÑÁßçÂèØËÉΩÁ±ªÂà´ÁöÑ‰ø°ÊÅØÔºå‰∏î‰ªÖÂú®ÂØπÂ∫î‰ΩçÁΩÆ‰∏∫1ÔºåÂÖ∂‰ªñ‰ΩçÁΩÆ‰∏∫0„ÄÇ\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003e\u003cstrong\u003eÂª∫Á´ãÊò†Â∞ÑÔºö‰ªéÁ±ªÂà´Âà∞Á¥¢Âºï\u003c/strong\u003e\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e‰∏∫ÊØè‰∏™Á±ªÂà´ÂàÜÈÖç‰∏Ä‰∏™ÂîØ‰∏ÄÁ¥¢ÂºïÔºåÈÄöÂ∏∏‰ªé1ÂºÄÂßã„ÄÇ\u003c/li\u003e\n\u003cli\u003eÈ¢ÑÁïôÁ¥¢Âºï0Ë°®Á§∫‚ÄúÊú™Áü•‚ÄùÊàñ‚ÄúÁº∫Â§±‚ÄùÔºåÂØπÂ∫îÂÖ®0ÂêëÈáè„ÄÇ\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003e\u003cstrong\u003eËΩ¨Êç¢‰∏∫One-HotÂêëÈáè\u003c/strong\u003e\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eËã•Á±ªÂà´ÊÄªÊï∞‰∏∫197ÔºåÂàôÁî®197Áª¥ÂêëÈáèË°®Á§∫„ÄÇ\u003c/li\u003e\n\u003cli\u003e‰æãÂ≠êÔºöÁæéÂõΩ \u003ccode\u003e[1, 0, 0, 0, ‚Ä¶]\u003c/code\u003eÔºå ‰∏≠ÂõΩ \u003ccode\u003e[0, 1, 0, 0, ‚Ä¶]\u003c/code\u003e„ÄÇ\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003e\u003cstrong\u003eÁ§∫‰æãÔºöË°®Á§∫‰∏Ä‰∏™‰∫∫ÁöÑÁâπÂæÅ\u003c/strong\u003e\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eÁâπÂæÅÂåÖÂê´ÔºàÂπ¥ÈæÑ, ÊÄßÂà´, ÂõΩÁ±çÔºåÂÖ∂‰∏≠ÂõΩÁ±ç197ÁßçÔºâ\u003c/li\u003e\n\u003cli\u003eÁª¥Â∫¶ÊÄªÂíåÔºö1Áª¥_age + 1Áª¥_gender + 197Áª¥_nationality = 199Áª¥„ÄÇ\u003c/li\u003e\n\u003cli\u003e‰æãÂ¶Ç \u003ccode\u003e(28, Â•≥, ‰∏≠ÂõΩ)\u003c/code\u003e ‚Üí \u003ccode\u003e[28, 0, 0, 1, 0, ‚Ä¶, 0]\u003c/code\u003e„ÄÇ\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003c/ol\u003e\n\u003ch2 id=\"‰∏âÊñáÊú¨Êï∞ÊçÆÂ§ÑÁêÜÊµÅÁ®ã\"\u003e‰∏â„ÄÅÊñáÊú¨Êï∞ÊçÆÂ§ÑÁêÜÊµÅÁ®ã\u003c/h2\u003e\n\u003cp\u003eÊñáÊú¨Âú®Ëá™ÁÑ∂ËØ≠Ë®ÄÂ§ÑÁêÜÔºàNLPÔºâ‰∏≠‰Ωú‰∏∫Â∏∏ËßÅÁöÑÂéüÂßãËæìÂÖ•ÔºåÈúÄË¶ÅÊï∞ÂÄºÂåñÊâçËÉΩÈÄÅÂÖ•Ê®°Âûã„ÄÇ‰∏ÄËà¨Ê≠•È™§Â¶Ç‰∏ãÔºö\u003c/p\u003e\n\u003col\u003e\n\u003cli\u003e\n\u003cp\u003e\u003cstrong\u003eÂàÜËØç (Tokenization)\u003c/strong\u003e\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eÂ∞ÜÊñáÊú¨ÊãÜÂàÜ‰∏∫‰∏Ä‰∏™‰∏™ÂçïËØçÔºàTokenÔºâ„ÄÇ\u003c/li\u003e\n\u003cli\u003e‰æãÂ≠êÔºö\u003ccode\u003e\u0026quot;... to be or not to be...\u0026quot;\u003c/code\u003e ‚Üí \u003ccode\u003e[\u0026quot;...\u0026quot;, \u0026quot;to\u0026quot;, \u0026quot;be\u0026quot;, \u0026quot;or\u0026quot;, \u0026quot;not\u0026quot;, \u0026quot;to\u0026quot;, \u0026quot;be\u0026quot;, \u0026quot;...\u0026quot;]\u003c/code\u003e„ÄÇ\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003e\u003cstrong\u003eÁªüËÆ°ËØçÈ¢ë \u0026amp; ÊûÑÂª∫ËØçÂÖ∏\u003c/strong\u003e\u003c/p\u003e","title":""},{"content":"Text to Sequence ÊñáÊú¨Â§ÑÁêÜ\nStep1: Tokenization\nTokenization breaks a piece of text down into a list of tokens.\nHere, a token is a word. (A token can be a character in some applications.)\nTokenizationËÆ≤Á©∂ÂæàÂ§öÔºå‰æãÂ¶ÇÊòØÂê¶Â∫îËØ•ÊääÂ§ßÂÜôÊîπÊàêÂ∞èÂÜôÂë¢ÔºüËøõË°åtypo correctionÁ≠âÁ≠â\nStep2: Build Dictionary\nUse a dictionary (hash table) to count word frequencies.\nThe dictionary maps word to index.\nÂèØ‰ª•È¶ñÂÖàÁªüËÆ°ËØçÈ¢ëÂéªÊéâ‰ΩéÈ¢ëËØçÔºåÁÑ∂ÂêéËÆ©ÊØè‰∏™ËØçÂØπÂ∫î‰∏Ä‰∏™Ê≠£Êï¥Êï∞ÔºõËøôÊ†∑ÁöÑËØùÔºå‰∏ÄÂè•ËØùÂ∞±ÂèØ‰ª•Áî®‰∏Ä‰∏™Ê≠£Êï¥Êï∞ÂàóË°®Ë°®Á§∫ÔºåËøô‰∏™ÂàóË°®Â∞±Âè´sequenceÔºõÂ¶ÇÊûúÂøÖË¶ÅÂ∞±ËøòÂæóÂÅöone-hot encoding„ÄÇ\nÁªìÊûú\n‰ΩÜÊòØÈïøÂ∫¶‰∏çÁªü‰∏Ä\nStep4: ÂØπÈΩêsequence\nËß£ÂÜ≥ÊñπÊ°àÊòØËøôÊ†∑ÁöÑÔºöÂèØ‰ª•Âõ∫ÂÆöÈïøÂ∫¶‰∏∫wÔºåÂä†ÂÖ•‰∏Ä‰∏™Â∫èÂàóÈïøÂ∫¶Â§™ÈïøÔºåÂ∞±Á†çÊéâÂâçÈù¢ÁöÑËØçÔºåÂè™‰øùÁïôÊúÄÂêéw‰∏™ËØçÔºõÂ¶ÇÊûú‰∏Ä‰∏™Â∫èÂàóÂ§™Áü≠ÔºåÂ∞±ÂÅözero paddingÔºåÁî®0Â°´ÂÖÖ\nËøôÊ†∑‰∏ÄÊù•ÔºåÊâÄÊúâÁöÑÂ∫èÂàóÈïøÂ∫¶Â∞±Áªü‰∏Ä‰∫Ü\nÊñáÊú¨Â§ÑÁêÜÂÆåÊàê‰∫ÜÔºåÊé•‰∏ãÊù•ÊòØword embeddingÔºåÊääÂçïËØçË°®Á§∫‰∏∫‰∏Ä‰∏™‰ΩéÁª¥ÂêëÈáèÔºõ\nÁÑ∂ËÄåËøôÊ†∑ÂÅöÁöÑËØùÔºåÂ¶ÇÊûúÊòØ10000‰∏™ÂçïËØçÔºåÁª¥Â∫¶Â∞±ÊòØ10000Áª¥ÔºåÁª¥Â∫¶Â§™È´ò‰∫ÜÔºõÂõ†Ê≠§Ë¶ÅÂÅöword embeddingÔºõ\nÂÖ∑‰ΩìÂÅöÊ≥ïÂ∞±ÊòØÊääone-hotÂêëÈáèe_iÂíåÂèÇÊï∞Áü©ÈòµpÁõ∏‰πòÔºõÁü©ÈòµPËΩ¨ÁΩÆÁöÑÂ§ßÂ∞èÊòØd x vÔºõdÊòØËØçÂêëÈáèÁöÑÁª¥Â∫¶ÔºõvÊòØÂ≠óÂÖ∏ÈáåËØçÊ±áÁöÑÊï∞ÈáèÔºõÁªìÊûú‰∏∫x_iÔºõx_iÂ∞±ÊòØ‰∏Ä‰∏™ËØçÂêëÈáèÔºõÂ¶ÇÊûúone-hotÂêëÈáèÁöÑÁ¨¨‰∏âË°å‰∏∫1ÔºõÈÇ£‰πàx_iÂ∞±ÊòØPËΩ¨ÁΩÆÁü©ÈòµÁöÑÁ¨¨‰∏âÂàóÔºàÂÖ∂‰ΩôÂàóÈÉΩ‰∏∫0ÔºâÔºõÊâÄ‰ª•PËΩ¨ÁΩÆÊØè‰∏ÄÂàóÈÉΩÊòØ‰∏Ä‰∏™ËØçÂêëÈáèÔºõÊâÄ‰ª•Áü©ÈòµPÊú¨Ë∫´ÁöÑÊØè‰∏ÄË°åÂ∞±ÊòØ‰∏Ä‰∏™ËØçÂêëÈáèÔºõÂÖ∂Ë°åÊï∞‰∏∫vÔºõÂç≥vocabularyÔºåËØçÊ±áÈáèÔºõÊØè‰∏ÄË°åÂØπÂ∫î‰∏Ä‰∏™ÂçïËØçÔºõÁü©ÈòµÁöÑÂàóÊï∞‰∏∫dÔºõdÊòØÁî®Êà∑ÂÜ≥ÂÆöÁöÑÔºõdÁöÑÂ§ßÂ∞è‰ºöÂÜ≥ÂÆöÊú∫Âô®Â≠¶‰π†Ê®°ÂûãÁöÑË°®Áé∞ÔºõÂ∫îËØ•Áî®xxxÊù•ÈÄâÊã©‰∏Ä‰∏™ÊØîËæÉÂ•ΩÁöÑdÔºõ\nÊàë‰ª¨ÁöÑ‰ªªÂä°ÊòØÁúãËØÑËÆ∫ÊòØÊ≠£Èù¢ÁöÑËøòÊòØË¥üÈù¢ÁöÑÔºõÂèÇÊï∞Áü©ÈòµÊòØ‰ªéËÆ≠ÁªÉÊï∞ÊçÆ‰∏≠Â≠¶‰π†Âá∫Êù•ÁöÑÔºåÊâÄ‰ª•Â≠¶Âá∫Êù•ÁöÑËØçÂêëÈáèÊòØÂ∏¶ÊúâÊÑüÊÉÖËâ≤ÂΩ©ÁöÑÔºõÂÅáËÆæËøô‰∫õËØçÂêëÈáèÈÉΩÊòØ‰∫åÁª¥ÁöÑÔºåÂàôÂèØ‰ª•Âú®Âπ≥Èù¢ÂùêÊ†áÁ≥ª‰∏≠Ê†áÂá∫‰∏ãÈù¢ËØçÂêëÈáè\nkerasÊèê‰æõembeddingÂ±ÇÔºõÁî®Êà∑ÂèØ‰ª•ÊåáÂÆövocabularyÂ§ßÂ∞èÂíådÁöÑÂ§ßÂ∞èÔºõ‰ª•ÂèäÊØè‰∏Ä‰∏™sequenceÁöÑÈïøÂ∫¶ÔºõdÊòØÊ†πÊçÆÁÆóÊ≥ïÈÄâÂá∫Êù•ÁöÑ Âà∞Ëøô‰∏ÄÊ≠•ÔºåÊàë‰ª¨Â∑≤ÁªèÂÆåÊàê‰∫ÜÊñáÊú¨Â§ÑÁêÜÂíåword embedding„ÄÇÊé•‰∏ãÊù•Â∞±ÊòØÁî®Logistic Regression for Binary ClassificationÂÅö‰∫åÂàÜÁ±ªÔºõ\n","permalink":"http://localhost:1313/posts/nlp-2/","summary":"\u003ch3 id=\"text-to-sequence\"\u003eText to Sequence\u003c/h3\u003e\n\u003cp\u003eÊñáÊú¨Â§ÑÁêÜ\u003c/p\u003e\n\u003cp\u003eStep1: Tokenization\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\n\u003cp\u003eTokenization breaks a piece of text down into a list of tokens.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003eHere, a token is a word. (A token can be a character in some applications.)\u003c/p\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003eTokenizationËÆ≤Á©∂ÂæàÂ§öÔºå‰æãÂ¶ÇÊòØÂê¶Â∫îËØ•ÊääÂ§ßÂÜôÊîπÊàêÂ∞èÂÜôÂë¢ÔºüËøõË°åtypo correctionÁ≠âÁ≠â\u003c/p\u003e\n\u003cp\u003e\u003cimg alt=\"image-20250322150322238\" loading=\"lazy\" src=\"./NLP-2.assets/image-20250322150322238.png\"\u003e\u003c/p\u003e\n\u003cp\u003eStep2: Build Dictionary\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\n\u003cp\u003eUse a dictionary (hash table) to count word frequencies.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003eThe dictionary maps word to index.\u003c/p\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003eÂèØ‰ª•È¶ñÂÖàÁªüËÆ°ËØçÈ¢ëÂéªÊéâ‰ΩéÈ¢ëËØçÔºåÁÑ∂ÂêéËÆ©ÊØè‰∏™ËØçÂØπÂ∫î‰∏Ä‰∏™Ê≠£Êï¥Êï∞ÔºõËøôÊ†∑ÁöÑËØùÔºå‰∏ÄÂè•ËØùÂ∞±ÂèØ‰ª•Áî®‰∏Ä‰∏™Ê≠£Êï¥Êï∞ÂàóË°®Ë°®Á§∫ÔºåËøô‰∏™ÂàóË°®Â∞±Âè´sequenceÔºõÂ¶ÇÊûúÂøÖË¶ÅÂ∞±ËøòÂæóÂÅöone-hot encoding„ÄÇ\u003cimg alt=\"image-20250322150620890\" loading=\"lazy\" src=\"./NLP-2.assets/image-20250322150620890.png\"\u003e\u003c/p\u003e\n\u003cp\u003eÁªìÊûú\u003c/p\u003e\n\u003cp\u003e\u003cimg alt=\"image-20250322150754528\" loading=\"lazy\" src=\"./NLP-2.assets/image-20250322150754528.png\"\u003e\u003c/p\u003e\n\u003cp\u003e‰ΩÜÊòØÈïøÂ∫¶‰∏çÁªü‰∏Ä\u003c/p\u003e\n\u003cp\u003eStep4: ÂØπÈΩêsequence\u003c/p\u003e\n\u003cp\u003e\u003cimg alt=\"image-20250322150854986\" loading=\"lazy\" src=\"./NLP-2.assets/image-20250322150854986.png\"\u003e\u003c/p\u003e\n\u003cp\u003eËß£ÂÜ≥ÊñπÊ°àÊòØËøôÊ†∑ÁöÑÔºöÂèØ‰ª•Âõ∫ÂÆöÈïøÂ∫¶‰∏∫wÔºåÂä†ÂÖ•‰∏Ä‰∏™Â∫èÂàóÈïøÂ∫¶Â§™ÈïøÔºåÂ∞±Á†çÊéâÂâçÈù¢ÁöÑËØçÔºåÂè™‰øùÁïôÊúÄÂêéw‰∏™ËØçÔºõÂ¶ÇÊûú‰∏Ä‰∏™Â∫èÂàóÂ§™Áü≠ÔºåÂ∞±ÂÅözero paddingÔºåÁî®0Â°´ÂÖÖ\u003c/p\u003e\n\u003cp\u003e\u003cimg alt=\"image-20250322151030119\" loading=\"lazy\" src=\"./NLP-2.assets/image-20250322151030119.png\"\u003e\u003c/p\u003e\n\u003cp\u003eËøôÊ†∑‰∏ÄÊù•ÔºåÊâÄÊúâÁöÑÂ∫èÂàóÈïøÂ∫¶Â∞±Áªü‰∏Ä‰∫Ü\u003c/p\u003e\n\u003cp\u003e\u003cimg alt=\"image-20250322151117125\" loading=\"lazy\" src=\"./NLP-2.assets/image-20250322151117125.png\"\u003e\u003c/p\u003e\n\u003cp\u003eÊñáÊú¨Â§ÑÁêÜÂÆåÊàê‰∫ÜÔºåÊé•‰∏ãÊù•ÊòØword embeddingÔºåÊääÂçïËØçË°®Á§∫‰∏∫‰∏Ä‰∏™‰ΩéÁª¥ÂêëÈáèÔºõ\u003c/p\u003e\n\u003cp\u003e\u003cimg alt=\"image-20250322151252837\" loading=\"lazy\" src=\"./NLP-2.assets/image-20250322151252837.png\"\u003e\u003c/p\u003e","title":""},{"content":"üëã About me Hello! I\u0026rsquo;m Xu Zongsi, a passionate technology enthusiast currently pursuing my Master of Science in ECIC at The University of Hong Kong. With a solid background in Software Engineering from the Beijing Institute of Technology, I specialize in artificial intelligence areas like machine learning, deep learning, natural language processing, computer vision, and reinforcement learning.\nInspired by OpenAI\u0026rsquo;s five-step plan towards superintelligence, I am excited about AGI and have developed a keen interest in LLM agents, MLLM, and knowledge graphs. I see great potential in these fields and aspire to contribute to innovative solutions.\nüìö Education üá≠üá∞ The University of Hong Kong 09/2024 - Expected 11/2025 School of Computing and Data Science Master of Science in Electronic Commerce \u0026amp; Internet Computing Relevant Courses: Machine learning for business and e-commerce, Knowledge graphs, Financial fraud analytics, Internet infrastructure technologies, Website engineering, Blockchain and cryptocurrency, etc. üá®üá≥ Beijing Institute of Technology 09/2020 - 06/2024 School of Computer Science \u0026amp; Technology Bachelor of Engineering in Software Engineering, last two years GPA: 3.7/4 Relevant Courses: Reinforcement Learning, Deep Learning and Computer Vision, Artificial Intelligence and Robot Ethics, Almost Human: Mind, Brain and Artificial Intelligence, Mathematical Analysis for Engineering, Linear Algebra, Probability and Mathematical Statistics, etc. Skills: Python, Java, common data structures, design patterns, machine learning basics and algorithms, Linux, PyTorch, and some development tools (git, conda, etc.). üèÜ Awards \u0026amp; Honors Beijing Institute of Technology Undergraduate Scholarship (Top 20% of Grade) 06/2023 3rd Prize of China International \u0026#34;Internet \u0026#43;\u0026#34; College Student\u0026#39;s Innovation Competition 08/2022 Bronze Prize of \u0026#34;Challenge Cup\u0026#34; Capital University Entrepreneurship Competition 05/2022 üíº Project Experience üîç Online Transaction Fraud Detection 09/2024 ‚Äì 01/2025 Independent project, supervised by Dr. Vivien Chan Focused on addressing financial fraud in e-commerce to enhance the accuracy of transaction anomaly detection, while independently managing the entire case study that included data preprocessing, feature engineering, model building, evaluation, and results analysis. Effectively resolved class imbalance issues using SMOTE and ROSE techniques. Built various models including Logistic Regression, Random Forest, XGBoost, and LightGBM, ultimately selecting the LightGBM model to achieve a recall rate of 95.45% and an AUC of 99.84%. Wrote efficient and maintainable code, enhancing model training and data processing efficiency through parallel computing and logging. ü§ñ Multi-Model Intelligent Text Keyword Extraction System 08/2023 ‚Äì 09/2023 Group project, supervised by Associate Prof. Xiaolin Zhao Designed and implemented an intelligent text summary system that automatically extracts keywords from article titles and abstracts, enhancing the understanding and summarization of text information. Participated in the planning of the technical route and built a hybrid model combining extractive and generative approaches, utilizing advanced natural language processing techniques including KeyBERT, Sentence Transformer, BERT, and T5 models. Responsible for data preprocessing and tokenization, as well as the end-to-end implementation and training of the T5 model, optimizing the model architecture and hyperparameters, achieving satisfactory results after only 3 epochs of training. Model evaluation results showed that the Rouge-1, Rouge-2, and Rouge-L metrics reached 0.6345, 0.5038, and 0.5282, respectively, in the third epoch, validating the model\u0026rsquo;s effectiveness in the summarization task. üéì Cambridge University Machine Learning Summer Project 07/2023 ‚Äì 08/2023 Group project, supervised by Prof. Pietro Li√≤ Participated in the Cambridge University deep learning summer project, focusing on deep reinforcement learning; explored multi-agent learning algorithms across different environments. Reproduced the Multi-Agent Deep Deterministic Policy Gradient (MADDPG) algorithm in the Simple Adversary environment and studied the effect of agent numbers on convergence speed and stability, finding optimal stability at 21 agents. Designed and implemented comparative experiments inspired by the Rainbow algorithm, assessing target network strategies versus the Double Deep Q-Network (Double DQN). The results demonstrated that Double DQN significantly enhanced convergence speed, optimizing the overall learning process. Co-authored a group project paper on agent numbers and strategies effectiveness in multi-agent systems, achieving a score of 71% in the summer program (the highest in my group) and a \u0026ldquo;First Class\u0026rdquo; classification in the UK grading system. üëÅÔ∏è Deep Learning and Computer Vision Semester Project 09/2022 ‚Äì 12/2022 Independent project, supervised by Associate Prof. Guangyu Gao Designed and implemented a waste classifier using the ResNet model to improve classification accuracy and reduce resource waste. The project also enhanced understanding of transfer learning techniques with ResNet. Collected a dataset of 16 waste categories and preprocessed the images for uniformity and standardization, incorporating data augmentation techniques to enhance the dataset. Conducted experiments using ResNet34 and ResNet50 models through transfer learning, accelerating network convergence by leveraging pretrained weights. During training, techniques such as Batch Normalization and Dropout were applied to mitigate the risk of overfitting. The final model achieved an accuracy of 90% on the training set, while the performance on the test set was 61%, indicating a significant overfitting phenomenon during the training process. üéì Internship ‚öõÔ∏è Beijing Academy of Quantum Information Science 08/2023 ‚Äì 01/2024 Research Intern at Quantum Computation Department Proposed a quantum convolution kernel design based on variational quantum circuits and developed a universal quantum convolution layer, successfully integrating it into classical CNN architectures such as VGG, GoogLeNet, and ResNet. Developed and evaluated various hybrid models, including a simple model named HQCCNN-2, which achieved 84.45% accuracy on the FashionMNIST dataset, surpassing the traditional CNN\u0026rsquo;s 80.72%. This demonstrates the effectiveness of the quantum convolution layer in improving model performance. Tested on a real quantum computer further validated the effectiveness of the hybrid model, demonstrating the viable integration of quantum computing with deep learning, and highlighting the potential for leveraging quantum properties to enhance model performance. üèÖ Competition Experience ü•â China International \u0026#34;Internet \u0026#43;\u0026#34; College Students\u0026#39; Innovation Competition 08/2022 üõ°Ô∏è Zhongke Ushield: Deep Learning-based Face Privacy Protection Authentication System Responsible for constructing a localized facial feature extraction engine based on MobileFaceNet, ensuring feature extraction is completed on end devices (such as mobile phones and cameras), guaranteeing that raw data does not leave the domain and is not stored, thus enhancing user privacy protection while improving recognition efficiency. ü•â \u0026#34;Challenge Cup\u0026#34; Capital University Entrepreneurship Competition 05/2022 üå≥ Smart Orchard Responsible for the development of the fruit detection, ripeness prediction, and pest identification system, using deep convolutional neural network (CNN) technology for intelligent monitoring of crop growth conditions. Applied advanced object detection algorithms such as Faster R-CNN and YOLO to achieve high precision in apple detection and ripeness assessment, with an accuracy rate exceeding 90%, significantly enhancing the intelligence level of orchard management. Built and trained a dedicated dataset containing various pest samples, optimizing pest detection accuracy through data preprocessing (such as image normalization and resizing) and data augmentation techniques (like rotation, flipping, and noise addition), enabling the real-time monitoring system to accurately identify over 80% of pests, providing effective scientific maintenance recommendations to help farmers reduce crop losses. üìã Extracurricular Activities Vice President, Cyber Security Club, Beijing Institute of Technology 09/2021-09/2022 Backbone, Media Center of the Student Union of Beijing Institute of Technology 10/2020-06/2021 üì´ Contact üìß Email: zongsi.xu@outlook.com üëî LinkedIn: Zongsi (Tristan) Xu üíª GitHub: github.com/BaizeXS üìç Location: Hong Kong SAR, China ","permalink":"http://localhost:1313/resume/","summary":"Personal resume of Zongsi (Tristan) Xu","title":"Zongsi (Tristan) Xu"},{"content":"‰∏Ä„ÄÅÊï∞ÂÄºÁâπÂæÅ‰∏éÁ±ªÂà´ÁâπÂæÅ Êï∞ÂÄºÁâπÂæÅ (Numeric Features) ÂÖ∑ÊúâÂèØÂä†ÂáèÁöÑÊÑè‰πâÔºå‰∏îÂ≠òÂú®Â§ßÂ∞èÈ°∫Â∫è„ÄÇ ‰æãÂ≠êÔºöÂπ¥ÈæÑ„ÄÅÊ∏©Â∫¶Á≠â„ÄÇÂèØ‰ª•Áõ¥Êé•‰øùÁïôÂÖ∂Êï¥Êï∞ÊàñÊµÆÁÇπÊï∞ÂΩ¢Âºè‰æõÊ®°Âûã‰ΩøÁî®„ÄÇ Á±ªÂà´ÁâπÂæÅ (Categorical Features) Êï∞ÊçÆÂÄºÁ¶ªÊï£Ôºå‰∏çÂÖ∑Â§á‚ÄúÊï∞ÂÄºÂ§ßÂ∞è‚ÄùÈó¥ÁöÑÂèØÊØîÊÑè‰πâ„ÄÇ ‰æãÂ≠êÔºöÂõΩÁ±çÔºàÁæéÂõΩ/‰∏≠ÂõΩ/Âç∞Â∫¶Á≠âÔºâ„ÄÅÊÄßÂà´ÔºàÁî∑/Â•≥ÔºâÁ≠â„ÄÇ ÈóÆÈ¢òÔºöËã•‰ªÖÁî®Êï¥Êï∞Ë°®Á§∫ÔºàÁæéÂõΩ=1, ‰∏≠ÂõΩ=2ÔºâÔºå‰ºöÂºïÂÖ•ÈîôËØØÁöÑÊï∞ÂÄºËøêÁÆóÂÖ≥Á≥ªÔºåÂ¶Ç ‚ÄúÁæéÂõΩ + ‰∏≠ÂõΩ = Âç∞Â∫¶‚Äù„ÄÇ ‰∫å„ÄÅOne-HotÁºñÁ†ÅÁöÑÂä®Êú∫‰∏éÊµÅÁ®ã ‰∏∫‰ªÄ‰πà‰ΩøÁî®One-Hot\nÈÄöËøáÂ∞ÜÁ±ªÂà´Êò†Â∞Ñ‰∏∫ÂêëÈáèÔºåÈÅøÂÖçÊï¥Êï∞ÁºñÁ†ÅÂºïÂÖ•ÁöÑ‰º™Êï∞ÂÄºÂÖ≥Á≥ª„ÄÇ ÂêåÊó∂‰øùÁïôÂêÑÁßçÂèØËÉΩÁ±ªÂà´ÁöÑ‰ø°ÊÅØÔºå‰∏î‰ªÖÂú®ÂØπÂ∫î‰ΩçÁΩÆ‰∏∫1ÔºåÂÖ∂‰ªñ‰ΩçÁΩÆ‰∏∫0„ÄÇ Âª∫Á´ãÊò†Â∞ÑÔºö‰ªéÁ±ªÂà´Âà∞Á¥¢Âºï\n‰∏∫ÊØè‰∏™Á±ªÂà´ÂàÜÈÖç‰∏Ä‰∏™ÂîØ‰∏ÄÁ¥¢ÂºïÔºåÈÄöÂ∏∏‰ªé1ÂºÄÂßã„ÄÇ È¢ÑÁïôÁ¥¢Âºï0Ë°®Á§∫‚ÄúÊú™Áü•‚ÄùÊàñ‚ÄúÁº∫Â§±‚ÄùÔºåÂØπÂ∫îÂÖ®0ÂêëÈáè„ÄÇ ËΩ¨Êç¢‰∏∫One-HotÂêëÈáè\nËã•Á±ªÂà´ÊÄªÊï∞‰∏∫197ÔºåÂàôÁî®197Áª¥ÂêëÈáèË°®Á§∫„ÄÇ ‰æãÂ≠êÔºöÁæéÂõΩ [1, 0, 0, 0, ‚Ä¶]Ôºå ‰∏≠ÂõΩ [0, 1, 0, 0, ‚Ä¶]„ÄÇ Á§∫‰æãÔºöË°®Á§∫‰∏Ä‰∏™‰∫∫ÁöÑÁâπÂæÅ\nÁâπÂæÅÂåÖÂê´ÔºàÂπ¥ÈæÑ, ÊÄßÂà´, ÂõΩÁ±çÔºåÂÖ∂‰∏≠ÂõΩÁ±ç197ÁßçÔºâ Áª¥Â∫¶ÊÄªÂíåÔºö1Áª¥_age + 1Áª¥_gender + 197Áª¥_nationality = 199Áª¥„ÄÇ ‰æãÂ¶Ç (28, Â•≥, ‰∏≠ÂõΩ) ‚Üí [28, 0, 0, 1, 0, ‚Ä¶, 0]„ÄÇ ‰∏â„ÄÅÊñáÊú¨Êï∞ÊçÆÂ§ÑÁêÜÊµÅÁ®ã ÊñáÊú¨Âú®Ëá™ÁÑ∂ËØ≠Ë®ÄÂ§ÑÁêÜÔºàNLPÔºâ‰∏≠‰Ωú‰∏∫Â∏∏ËßÅÁöÑÂéüÂßãËæìÂÖ•ÔºåÈúÄË¶ÅÊï∞ÂÄºÂåñÊâçËÉΩÈÄÅÂÖ•Ê®°Âûã„ÄÇ‰∏ÄËà¨Ê≠•È™§Â¶Ç‰∏ãÔºö\nÂàÜËØç (Tokenization)\nÂ∞ÜÊñáÊú¨ÊãÜÂàÜ‰∏∫‰∏Ä‰∏™‰∏™ÂçïËØçÔºàTokenÔºâ„ÄÇ ‰æãÂ≠êÔºö\u0026quot;... to be or not to be...\u0026quot; ‚Üí [\u0026quot;...\u0026quot;, \u0026quot;to\u0026quot;, \u0026quot;be\u0026quot;, \u0026quot;or\u0026quot;, \u0026quot;not\u0026quot;, \u0026quot;to\u0026quot;, \u0026quot;be\u0026quot;, \u0026quot;...\u0026quot;]„ÄÇ ÁªüËÆ°ËØçÈ¢ë \u0026amp; ÊûÑÂª∫ËØçÂÖ∏\nËØçÈ¢ëÁªüËÆ° Áî®ÂìàÂ∏åË°®/Â≠óÂÖ∏ËÆ∞ÂΩïÊØè‰∏™ÂçïËØçÂá∫Áé∞Ê¨°Êï∞„ÄÇ ÈÅçÂéÜÊñáÊú¨Êó∂ÔºåËã•ÂçïËØçÂ∞öÊú™ÂÖ•Ë°®ÔºåÂàôÊñ∞Âª∫ËÆ∞ÂΩïÔºõËã•Â∑≤Â≠òÂú®ÔºåÂàôËÆ°Êï∞+1„ÄÇ ÊéíÂ∫è‰∏éÁ¥¢Âºï ÊåâËØçÈ¢ëÈôçÂ∫èÊéíÂ∫èÔºåËØçÈ¢ëÊúÄÈ´òÁöÑÂçïËØçÊéíÂú®ÂâçÈù¢„ÄÇ Á¥¢Âºï‰ªé1ÂºÄÂßãÔºå0ÁïôÁªô‚ÄúÊú™Áü•‚Äù„ÄÇ ËØçÂÖ∏ËßÑÊ®°ÔºàvocabularyÔºâÂèØËßÜÈúÄÊ±ÇÊà™Êñ≠Ôºà‰æãÂ¶ÇÂè™‰øùÁïôTop 10kÔºâ„ÄÇ ‰∏∫‰ªÄ‰πàÁßªÈô§‰ΩéÈ¢ëËØç ‰ΩéÈ¢ëËØçÂèØËÉΩÊòØÊãºÂÜôÈîôËØØ„ÄÅÁΩïËßÅ‰∫∫ÂêçÁ≠âÔºåÂØπÊ®°ÂûãÂ∏ÆÂä©ÊúâÈôê„ÄÇ ÂáèÂ∞ëËØçÂÖ∏ËßÑÊ®°ÂèØÈôç‰ΩéËøêÁÆóÂºÄÈîÄ„ÄÅÂä†Âø´Ê®°ÂûãËÆ≠ÁªÉ‰∏éÊé®ÁêÜÈÄüÂ∫¶„ÄÇ Áã¨ÁÉ≠ÁºñÁ†Å (One-Hot Encoding)\nÂ∞ÜÊØè‰∏™ÂçïËØçÊò†Â∞Ñ‰∏∫ËØçÂÖ∏‰∏≠ÁöÑÁ¥¢ÂºïÂêéÔºàÂ¶Ç [2, 4, 1, 8, ‚Ä¶]ÔºâÔºåÂèØËøõ‰∏ÄÊ≠•ËΩ¨Êç¢ÊàêOne-HotÂêëÈáè„ÄÇ One-HotÁª¥Â∫¶ÂèñÂÜ≥‰∫é‰øùÁïô‰∏ãÊù•ÁöÑËØçÂÖ∏Â§ßÂ∞èÔºà‰æãÂ¶Ç1‰∏áÔºâ„ÄÇ Êú™Êî∂ÂΩïÂçïËØçÂèØËÉΩÁõ¥Êé•ÂøΩÁï•ÔºåÊàñÁªü‰∏ÄÁî®Á¥¢Âºï0‰ª£Êõø„ÄÇ Âõõ„ÄÅÊ†∏ÂøÉÊî∂Ëé∑‰∏éÂ∫îÁî® Á±ªÂà´ÁâπÂæÅÂøÖÈúÄÊï∞ÂÄºÂåñÔºö\n‰ΩøÁî®Êï¥Êï∞1,2,3‚Ä¶‰ªÖË°®Á§∫Á±ªÂà´‚ÄúÊ†áËØÜ‚ÄùÔºåÂπ∂‰∏ç‰ª£Ë°®ÂÆÉ‰ª¨ÂèØËøõË°åÊï∞ÂÄºËøêÁÆó„ÄÇ Âõ†Ê≠§ÈúÄË¶ÅOne-HotÁ≠âÁºñÁ†ÅÊñπÂºèÔºåÈÅøÂÖçÊï∞ÂÄºËØØËß£„ÄÇ ÊñáÊú¨Êï∞ÊçÆÈ¢ÑÂ§ÑÁêÜÔºö\nÂàÜËØç„ÄÅËØçÈ¢ëÁªüËÆ°„ÄÅÊûÑÂª∫ËØçÂÖ∏„ÄÅÁ¥¢ÂºïÂåñ„ÄÅOne-HotÊàñÂÖ∂‰ªñÊñπÂºèÔºàÂ¶ÇËØçÂµåÂÖ•ÔºâÊòØÂ∏∏ËßÅÊµÅÁ®ã„ÄÇ Ê≠£Á°ÆÁöÑÊñáÊú¨È¢ÑÂ§ÑÁêÜÂèØÊòæËëóÂΩ±ÂìçÊ®°ÂûãÊÄßËÉΩÂíåÊïàÁéá„ÄÇ ‰øùÁïôÊú™Áü•Á¥¢ÂºïÔºö\n‰øùËØÅÂØπÁº∫Â§±Êï∞ÊçÆÊàñÂ≠óÂÖ∏Â§ñÊñ∞ËØçËÉΩÊúâÂü∫Êú¨ÁöÑË°®Á§∫ÔºåÊèêÂçáÊ®°ÂûãÂÆπÈîôÊÄß„ÄÇ ÂÆûÈôÖ‰ΩøÁî®Ôºö\nÂØπ‰∫éÂ∞èËßÑÊ®°Á±ªÂà´ÂèØÁõ¥Êé•One-HotÁºñÁ†ÅÔºõÂØπ‰∫éËØçÂÖ∏ÂæàÂ§ßÁöÑÂú∫ÊôØÔºåÈÄöÂ∏∏‰ºöËøõ‰∏ÄÊ≠•ËÄÉËôëËØçÂµåÂÖ•ÔºàWord EmbeddingÔºâÊàñÈ¢ÑËÆ≠ÁªÉËØ≠Ë®ÄÊ®°Âûã„ÄÇ ","permalink":"http://localhost:1313/posts/nlp-1/","summary":"\u003ch2 id=\"‰∏ÄÊï∞ÂÄºÁâπÂæÅ‰∏éÁ±ªÂà´ÁâπÂæÅ\"\u003e‰∏Ä„ÄÅÊï∞ÂÄºÁâπÂæÅ‰∏éÁ±ªÂà´ÁâπÂæÅ\u003c/h2\u003e\n\u003col\u003e\n\u003cli\u003e\u003cstrong\u003eÊï∞ÂÄºÁâπÂæÅ (Numeric Features)\u003c/strong\u003e\n\u003cul\u003e\n\u003cli\u003eÂÖ∑ÊúâÂèØÂä†ÂáèÁöÑÊÑè‰πâÔºå‰∏îÂ≠òÂú®Â§ßÂ∞èÈ°∫Â∫è„ÄÇ\u003c/li\u003e\n\u003cli\u003e‰æãÂ≠êÔºöÂπ¥ÈæÑ„ÄÅÊ∏©Â∫¶Á≠â„ÄÇÂèØ‰ª•Áõ¥Êé•‰øùÁïôÂÖ∂Êï¥Êï∞ÊàñÊµÆÁÇπÊï∞ÂΩ¢Âºè‰æõÊ®°Âûã‰ΩøÁî®„ÄÇ\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003eÁ±ªÂà´ÁâπÂæÅ (Categorical Features)\u003c/strong\u003e\n\u003cul\u003e\n\u003cli\u003eÊï∞ÊçÆÂÄºÁ¶ªÊï£Ôºå‰∏çÂÖ∑Â§á‚ÄúÊï∞ÂÄºÂ§ßÂ∞è‚ÄùÈó¥ÁöÑÂèØÊØîÊÑè‰πâ„ÄÇ\u003c/li\u003e\n\u003cli\u003e‰æãÂ≠êÔºöÂõΩÁ±çÔºàÁæéÂõΩ/‰∏≠ÂõΩ/Âç∞Â∫¶Á≠âÔºâ„ÄÅÊÄßÂà´ÔºàÁî∑/Â•≥ÔºâÁ≠â„ÄÇ\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003eÈóÆÈ¢ò\u003c/strong\u003eÔºöËã•‰ªÖÁî®Êï¥Êï∞Ë°®Á§∫ÔºàÁæéÂõΩ=1, ‰∏≠ÂõΩ=2ÔºâÔºå‰ºöÂºïÂÖ•ÈîôËØØÁöÑÊï∞ÂÄºËøêÁÆóÂÖ≥Á≥ªÔºåÂ¶Ç ‚ÄúÁæéÂõΩ + ‰∏≠ÂõΩ = Âç∞Â∫¶‚Äù„ÄÇ\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003c/ol\u003e\n\u003ch2 id=\"‰∫åone-hotÁºñÁ†ÅÁöÑÂä®Êú∫‰∏éÊµÅÁ®ã\"\u003e‰∫å„ÄÅOne-HotÁºñÁ†ÅÁöÑÂä®Êú∫‰∏éÊµÅÁ®ã\u003c/h2\u003e\n\u003col\u003e\n\u003cli\u003e\n\u003cp\u003e\u003cstrong\u003e‰∏∫‰ªÄ‰πà‰ΩøÁî®One-Hot\u003c/strong\u003e\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eÈÄöËøáÂ∞ÜÁ±ªÂà´Êò†Â∞Ñ‰∏∫ÂêëÈáèÔºåÈÅøÂÖçÊï¥Êï∞ÁºñÁ†ÅÂºïÂÖ•ÁöÑ‰º™Êï∞ÂÄºÂÖ≥Á≥ª„ÄÇ\u003c/li\u003e\n\u003cli\u003eÂêåÊó∂‰øùÁïôÂêÑÁßçÂèØËÉΩÁ±ªÂà´ÁöÑ‰ø°ÊÅØÔºå‰∏î‰ªÖÂú®ÂØπÂ∫î‰ΩçÁΩÆ‰∏∫1ÔºåÂÖ∂‰ªñ‰ΩçÁΩÆ‰∏∫0„ÄÇ\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003e\u003cstrong\u003eÂª∫Á´ãÊò†Â∞ÑÔºö‰ªéÁ±ªÂà´Âà∞Á¥¢Âºï\u003c/strong\u003e\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e‰∏∫ÊØè‰∏™Á±ªÂà´ÂàÜÈÖç‰∏Ä‰∏™ÂîØ‰∏ÄÁ¥¢ÂºïÔºåÈÄöÂ∏∏‰ªé1ÂºÄÂßã„ÄÇ\u003c/li\u003e\n\u003cli\u003eÈ¢ÑÁïôÁ¥¢Âºï0Ë°®Á§∫‚ÄúÊú™Áü•‚ÄùÊàñ‚ÄúÁº∫Â§±‚ÄùÔºåÂØπÂ∫îÂÖ®0ÂêëÈáè„ÄÇ\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003e\u003cstrong\u003eËΩ¨Êç¢‰∏∫One-HotÂêëÈáè\u003c/strong\u003e\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eËã•Á±ªÂà´ÊÄªÊï∞‰∏∫197ÔºåÂàôÁî®197Áª¥ÂêëÈáèË°®Á§∫„ÄÇ\u003c/li\u003e\n\u003cli\u003e‰æãÂ≠êÔºöÁæéÂõΩ \u003ccode\u003e[1, 0, 0, 0, ‚Ä¶]\u003c/code\u003eÔºå ‰∏≠ÂõΩ \u003ccode\u003e[0, 1, 0, 0, ‚Ä¶]\u003c/code\u003e„ÄÇ\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003e\u003cstrong\u003eÁ§∫‰æãÔºöË°®Á§∫‰∏Ä‰∏™‰∫∫ÁöÑÁâπÂæÅ\u003c/strong\u003e\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eÁâπÂæÅÂåÖÂê´ÔºàÂπ¥ÈæÑ, ÊÄßÂà´, ÂõΩÁ±çÔºåÂÖ∂‰∏≠ÂõΩÁ±ç197ÁßçÔºâ\u003c/li\u003e\n\u003cli\u003eÁª¥Â∫¶ÊÄªÂíåÔºö1Áª¥_age + 1Áª¥_gender + 197Áª¥_nationality = 199Áª¥„ÄÇ\u003c/li\u003e\n\u003cli\u003e‰æãÂ¶Ç \u003ccode\u003e(28, Â•≥, ‰∏≠ÂõΩ)\u003c/code\u003e ‚Üí \u003ccode\u003e[28, 0, 0, 1, 0, ‚Ä¶, 0]\u003c/code\u003e„ÄÇ\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003c/ol\u003e\n\u003ch2 id=\"‰∏âÊñáÊú¨Êï∞ÊçÆÂ§ÑÁêÜÊµÅÁ®ã\"\u003e‰∏â„ÄÅÊñáÊú¨Êï∞ÊçÆÂ§ÑÁêÜÊµÅÁ®ã\u003c/h2\u003e\n\u003cp\u003eÊñáÊú¨Âú®Ëá™ÁÑ∂ËØ≠Ë®ÄÂ§ÑÁêÜÔºàNLPÔºâ‰∏≠‰Ωú‰∏∫Â∏∏ËßÅÁöÑÂéüÂßãËæìÂÖ•ÔºåÈúÄË¶ÅÊï∞ÂÄºÂåñÊâçËÉΩÈÄÅÂÖ•Ê®°Âûã„ÄÇ‰∏ÄËà¨Ê≠•È™§Â¶Ç‰∏ãÔºö\u003c/p\u003e\n\u003col\u003e\n\u003cli\u003e\n\u003cp\u003e\u003cstrong\u003eÂàÜËØç (Tokenization)\u003c/strong\u003e\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eÂ∞ÜÊñáÊú¨ÊãÜÂàÜ‰∏∫‰∏Ä‰∏™‰∏™ÂçïËØçÔºàTokenÔºâ„ÄÇ\u003c/li\u003e\n\u003cli\u003e‰æãÂ≠êÔºö\u003ccode\u003e\u0026quot;... to be or not to be...\u0026quot;\u003c/code\u003e ‚Üí \u003ccode\u003e[\u0026quot;...\u0026quot;, \u0026quot;to\u0026quot;, \u0026quot;be\u0026quot;, \u0026quot;or\u0026quot;, \u0026quot;not\u0026quot;, \u0026quot;to\u0026quot;, \u0026quot;be\u0026quot;, \u0026quot;...\u0026quot;]\u003c/code\u003e„ÄÇ\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003e\u003cstrong\u003eÁªüËÆ°ËØçÈ¢ë \u0026amp; ÊûÑÂª∫ËØçÂÖ∏\u003c/strong\u003e\u003c/p\u003e","title":""},{"content":"Text to Sequence ÊñáÊú¨Â§ÑÁêÜ\nStep1: Tokenization\nTokenization breaks a piece of text down into a list of tokens.\nHere, a token is a word. (A token can be a character in some applications.)\nTokenizationËÆ≤Á©∂ÂæàÂ§öÔºå‰æãÂ¶ÇÊòØÂê¶Â∫îËØ•ÊääÂ§ßÂÜôÊîπÊàêÂ∞èÂÜôÂë¢ÔºüËøõË°åtypo correctionÁ≠âÁ≠â\nStep2: Build Dictionary\nUse a dictionary (hash table) to count word frequencies.\nThe dictionary maps word to index.\nÂèØ‰ª•È¶ñÂÖàÁªüËÆ°ËØçÈ¢ëÂéªÊéâ‰ΩéÈ¢ëËØçÔºåÁÑ∂ÂêéËÆ©ÊØè‰∏™ËØçÂØπÂ∫î‰∏Ä‰∏™Ê≠£Êï¥Êï∞ÔºõËøôÊ†∑ÁöÑËØùÔºå‰∏ÄÂè•ËØùÂ∞±ÂèØ‰ª•Áî®‰∏Ä‰∏™Ê≠£Êï¥Êï∞ÂàóË°®Ë°®Á§∫ÔºåËøô‰∏™ÂàóË°®Â∞±Âè´sequenceÔºõÂ¶ÇÊûúÂøÖË¶ÅÂ∞±ËøòÂæóÂÅöone-hot encoding„ÄÇ\nÁªìÊûú\n‰ΩÜÊòØÈïøÂ∫¶‰∏çÁªü‰∏Ä\nStep4: ÂØπÈΩêsequence\nËß£ÂÜ≥ÊñπÊ°àÊòØËøôÊ†∑ÁöÑÔºöÂèØ‰ª•Âõ∫ÂÆöÈïøÂ∫¶‰∏∫wÔºåÂä†ÂÖ•‰∏Ä‰∏™Â∫èÂàóÈïøÂ∫¶Â§™ÈïøÔºåÂ∞±Á†çÊéâÂâçÈù¢ÁöÑËØçÔºåÂè™‰øùÁïôÊúÄÂêéw‰∏™ËØçÔºõÂ¶ÇÊûú‰∏Ä‰∏™Â∫èÂàóÂ§™Áü≠ÔºåÂ∞±ÂÅözero paddingÔºåÁî®0Â°´ÂÖÖ\nËøôÊ†∑‰∏ÄÊù•ÔºåÊâÄÊúâÁöÑÂ∫èÂàóÈïøÂ∫¶Â∞±Áªü‰∏Ä‰∫Ü\nÊñáÊú¨Â§ÑÁêÜÂÆåÊàê‰∫ÜÔºåÊé•‰∏ãÊù•ÊòØword embeddingÔºåÊääÂçïËØçË°®Á§∫‰∏∫‰∏Ä‰∏™‰ΩéÁª¥ÂêëÈáèÔºõ\nÁÑ∂ËÄåËøôÊ†∑ÂÅöÁöÑËØùÔºåÂ¶ÇÊûúÊòØ10000‰∏™ÂçïËØçÔºåÁª¥Â∫¶Â∞±ÊòØ10000Áª¥ÔºåÁª¥Â∫¶Â§™È´ò‰∫ÜÔºõÂõ†Ê≠§Ë¶ÅÂÅöword embeddingÔºõ\nÂÖ∑‰ΩìÂÅöÊ≥ïÂ∞±ÊòØÊääone-hotÂêëÈáèe_iÂíåÂèÇÊï∞Áü©ÈòµpÁõ∏‰πòÔºõÁü©ÈòµPËΩ¨ÁΩÆÁöÑÂ§ßÂ∞èÊòØd x vÔºõdÊòØËØçÂêëÈáèÁöÑÁª¥Â∫¶ÔºõvÊòØÂ≠óÂÖ∏ÈáåËØçÊ±áÁöÑÊï∞ÈáèÔºõÁªìÊûú‰∏∫x_iÔºõx_iÂ∞±ÊòØ‰∏Ä‰∏™ËØçÂêëÈáèÔºõÂ¶ÇÊûúone-hotÂêëÈáèÁöÑÁ¨¨‰∏âË°å‰∏∫1ÔºõÈÇ£‰πàx_iÂ∞±ÊòØPËΩ¨ÁΩÆÁü©ÈòµÁöÑÁ¨¨‰∏âÂàóÔºàÂÖ∂‰ΩôÂàóÈÉΩ‰∏∫0ÔºâÔºõÊâÄ‰ª•PËΩ¨ÁΩÆÊØè‰∏ÄÂàóÈÉΩÊòØ‰∏Ä‰∏™ËØçÂêëÈáèÔºõÊâÄ‰ª•Áü©ÈòµPÊú¨Ë∫´ÁöÑÊØè‰∏ÄË°åÂ∞±ÊòØ‰∏Ä‰∏™ËØçÂêëÈáèÔºõÂÖ∂Ë°åÊï∞‰∏∫vÔºõÂç≥vocabularyÔºåËØçÊ±áÈáèÔºõÊØè‰∏ÄË°åÂØπÂ∫î‰∏Ä‰∏™ÂçïËØçÔºõÁü©ÈòµÁöÑÂàóÊï∞‰∏∫dÔºõdÊòØÁî®Êà∑ÂÜ≥ÂÆöÁöÑÔºõdÁöÑÂ§ßÂ∞è‰ºöÂÜ≥ÂÆöÊú∫Âô®Â≠¶‰π†Ê®°ÂûãÁöÑË°®Áé∞ÔºõÂ∫îËØ•Áî®xxxÊù•ÈÄâÊã©‰∏Ä‰∏™ÊØîËæÉÂ•ΩÁöÑdÔºõ\nÊàë‰ª¨ÁöÑ‰ªªÂä°ÊòØÁúãËØÑËÆ∫ÊòØÊ≠£Èù¢ÁöÑËøòÊòØË¥üÈù¢ÁöÑÔºõÂèÇÊï∞Áü©ÈòµÊòØ‰ªéËÆ≠ÁªÉÊï∞ÊçÆ‰∏≠Â≠¶‰π†Âá∫Êù•ÁöÑÔºåÊâÄ‰ª•Â≠¶Âá∫Êù•ÁöÑËØçÂêëÈáèÊòØÂ∏¶ÊúâÊÑüÊÉÖËâ≤ÂΩ©ÁöÑÔºõÂÅáËÆæËøô‰∫õËØçÂêëÈáèÈÉΩÊòØ‰∫åÁª¥ÁöÑÔºåÂàôÂèØ‰ª•Âú®Âπ≥Èù¢ÂùêÊ†áÁ≥ª‰∏≠Ê†áÂá∫‰∏ãÈù¢ËØçÂêëÈáè\nkerasÊèê‰æõembeddingÂ±ÇÔºõÁî®Êà∑ÂèØ‰ª•ÊåáÂÆövocabularyÂ§ßÂ∞èÂíådÁöÑÂ§ßÂ∞èÔºõ‰ª•ÂèäÊØè‰∏Ä‰∏™sequenceÁöÑÈïøÂ∫¶ÔºõdÊòØÊ†πÊçÆÁÆóÊ≥ïÈÄâÂá∫Êù•ÁöÑ Âà∞Ëøô‰∏ÄÊ≠•ÔºåÊàë‰ª¨Â∑≤ÁªèÂÆåÊàê‰∫ÜÊñáÊú¨Â§ÑÁêÜÂíåword embedding„ÄÇÊé•‰∏ãÊù•Â∞±ÊòØÁî®Logistic Regression for Binary ClassificationÂÅö‰∫åÂàÜÁ±ªÔºõ\n","permalink":"http://localhost:1313/posts/nlp-2/","summary":"\u003ch3 id=\"text-to-sequence\"\u003eText to Sequence\u003c/h3\u003e\n\u003cp\u003eÊñáÊú¨Â§ÑÁêÜ\u003c/p\u003e\n\u003cp\u003eStep1: Tokenization\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\n\u003cp\u003eTokenization breaks a piece of text down into a list of tokens.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003eHere, a token is a word. (A token can be a character in some applications.)\u003c/p\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003eTokenizationËÆ≤Á©∂ÂæàÂ§öÔºå‰æãÂ¶ÇÊòØÂê¶Â∫îËØ•ÊääÂ§ßÂÜôÊîπÊàêÂ∞èÂÜôÂë¢ÔºüËøõË°åtypo correctionÁ≠âÁ≠â\u003c/p\u003e\n\u003cp\u003e\u003cimg alt=\"image-20250322150322238\" loading=\"lazy\" src=\"./NLP-2.assets/image-20250322150322238.png\"\u003e\u003c/p\u003e\n\u003cp\u003eStep2: Build Dictionary\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\n\u003cp\u003eUse a dictionary (hash table) to count word frequencies.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003eThe dictionary maps word to index.\u003c/p\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003eÂèØ‰ª•È¶ñÂÖàÁªüËÆ°ËØçÈ¢ëÂéªÊéâ‰ΩéÈ¢ëËØçÔºåÁÑ∂ÂêéËÆ©ÊØè‰∏™ËØçÂØπÂ∫î‰∏Ä‰∏™Ê≠£Êï¥Êï∞ÔºõËøôÊ†∑ÁöÑËØùÔºå‰∏ÄÂè•ËØùÂ∞±ÂèØ‰ª•Áî®‰∏Ä‰∏™Ê≠£Êï¥Êï∞ÂàóË°®Ë°®Á§∫ÔºåËøô‰∏™ÂàóË°®Â∞±Âè´sequenceÔºõÂ¶ÇÊûúÂøÖË¶ÅÂ∞±ËøòÂæóÂÅöone-hot encoding„ÄÇ\u003cimg alt=\"image-20250322150620890\" loading=\"lazy\" src=\"./NLP-2.assets/image-20250322150620890.png\"\u003e\u003c/p\u003e\n\u003cp\u003eÁªìÊûú\u003c/p\u003e\n\u003cp\u003e\u003cimg alt=\"image-20250322150754528\" loading=\"lazy\" src=\"./NLP-2.assets/image-20250322150754528.png\"\u003e\u003c/p\u003e\n\u003cp\u003e‰ΩÜÊòØÈïøÂ∫¶‰∏çÁªü‰∏Ä\u003c/p\u003e\n\u003cp\u003eStep4: ÂØπÈΩêsequence\u003c/p\u003e\n\u003cp\u003e\u003cimg alt=\"image-20250322150854986\" loading=\"lazy\" src=\"./NLP-2.assets/image-20250322150854986.png\"\u003e\u003c/p\u003e\n\u003cp\u003eËß£ÂÜ≥ÊñπÊ°àÊòØËøôÊ†∑ÁöÑÔºöÂèØ‰ª•Âõ∫ÂÆöÈïøÂ∫¶‰∏∫wÔºåÂä†ÂÖ•‰∏Ä‰∏™Â∫èÂàóÈïøÂ∫¶Â§™ÈïøÔºåÂ∞±Á†çÊéâÂâçÈù¢ÁöÑËØçÔºåÂè™‰øùÁïôÊúÄÂêéw‰∏™ËØçÔºõÂ¶ÇÊûú‰∏Ä‰∏™Â∫èÂàóÂ§™Áü≠ÔºåÂ∞±ÂÅözero paddingÔºåÁî®0Â°´ÂÖÖ\u003c/p\u003e\n\u003cp\u003e\u003cimg alt=\"image-20250322151030119\" loading=\"lazy\" src=\"./NLP-2.assets/image-20250322151030119.png\"\u003e\u003c/p\u003e\n\u003cp\u003eËøôÊ†∑‰∏ÄÊù•ÔºåÊâÄÊúâÁöÑÂ∫èÂàóÈïøÂ∫¶Â∞±Áªü‰∏Ä‰∫Ü\u003c/p\u003e\n\u003cp\u003e\u003cimg alt=\"image-20250322151117125\" loading=\"lazy\" src=\"./NLP-2.assets/image-20250322151117125.png\"\u003e\u003c/p\u003e\n\u003cp\u003eÊñáÊú¨Â§ÑÁêÜÂÆåÊàê‰∫ÜÔºåÊé•‰∏ãÊù•ÊòØword embeddingÔºåÊääÂçïËØçË°®Á§∫‰∏∫‰∏Ä‰∏™‰ΩéÁª¥ÂêëÈáèÔºõ\u003c/p\u003e\n\u003cp\u003e\u003cimg alt=\"image-20250322151252837\" loading=\"lazy\" src=\"./NLP-2.assets/image-20250322151252837.png\"\u003e\u003c/p\u003e","title":""},{"content":"üëã About me Hello! I\u0026rsquo;m Xu Zongsi, a passionate technology enthusiast currently pursuing my Master of Science in ECIC at The University of Hong Kong. With a solid background in Software Engineering from the Beijing Institute of Technology, I specialize in artificial intelligence areas like machine learning, deep learning, natural language processing, computer vision, and reinforcement learning.\nInspired by OpenAI\u0026rsquo;s five-step plan towards superintelligence, I am excited about AGI and have developed a keen interest in LLM agents, MLLM, and knowledge graphs. I see great potential in these fields and aspire to contribute to innovative solutions.\nüìö Education üá≠üá∞ The University of Hong Kong 09/2024 - Expected 11/2025 School of Computing and Data Science Master of Science in Electronic Commerce \u0026amp; Internet Computing Relevant Courses: Machine learning for business and e-commerce, Knowledge graphs, Financial fraud analytics, Internet infrastructure technologies, Website engineering, Blockchain and cryptocurrency, etc. üá®üá≥ Beijing Institute of Technology 09/2020 - 06/2024 School of Computer Science \u0026amp; Technology Bachelor of Engineering in Software Engineering, last two years GPA: 3.7/4 Relevant Courses: Reinforcement Learning, Deep Learning and Computer Vision, Artificial Intelligence and Robot Ethics, Almost Human: Mind, Brain and Artificial Intelligence, Mathematical Analysis for Engineering, Linear Algebra, Probability and Mathematical Statistics, etc. Skills: Python, Java, common data structures, design patterns, machine learning basics and algorithms, Linux, PyTorch, and some development tools (git, conda, etc.). üèÜ Awards \u0026amp; Honors Beijing Institute of Technology Undergraduate Scholarship (Top 20% of Grade) 06/2023 3rd Prize of China International \u0026#34;Internet \u0026#43;\u0026#34; College Student\u0026#39;s Innovation Competition 08/2022 Bronze Prize of \u0026#34;Challenge Cup\u0026#34; Capital University Entrepreneurship Competition 05/2022 üíº Project Experience üîç Online Transaction Fraud Detection 09/2024 ‚Äì 01/2025 Independent project, supervised by Dr. Vivien Chan Focused on addressing financial fraud in e-commerce to enhance the accuracy of transaction anomaly detection, while independently managing the entire case study that included data preprocessing, feature engineering, model building, evaluation, and results analysis. Effectively resolved class imbalance issues using SMOTE and ROSE techniques. Built various models including Logistic Regression, Random Forest, XGBoost, and LightGBM, ultimately selecting the LightGBM model to achieve a recall rate of 95.45% and an AUC of 99.84%. Wrote efficient and maintainable code, enhancing model training and data processing efficiency through parallel computing and logging. ü§ñ Multi-Model Intelligent Text Keyword Extraction System 08/2023 ‚Äì 09/2023 Group project, supervised by Associate Prof. Xiaolin Zhao Designed and implemented an intelligent text summary system that automatically extracts keywords from article titles and abstracts, enhancing the understanding and summarization of text information. Participated in the planning of the technical route and built a hybrid model combining extractive and generative approaches, utilizing advanced natural language processing techniques including KeyBERT, Sentence Transformer, BERT, and T5 models. Responsible for data preprocessing and tokenization, as well as the end-to-end implementation and training of the T5 model, optimizing the model architecture and hyperparameters, achieving satisfactory results after only 3 epochs of training. Model evaluation results showed that the Rouge-1, Rouge-2, and Rouge-L metrics reached 0.6345, 0.5038, and 0.5282, respectively, in the third epoch, validating the model\u0026rsquo;s effectiveness in the summarization task. üéì Cambridge University Machine Learning Summer Project 07/2023 ‚Äì 08/2023 Group project, supervised by Prof. Pietro Li√≤ Participated in the Cambridge University deep learning summer project, focusing on deep reinforcement learning; explored multi-agent learning algorithms across different environments. Reproduced the Multi-Agent Deep Deterministic Policy Gradient (MADDPG) algorithm in the Simple Adversary environment and studied the effect of agent numbers on convergence speed and stability, finding optimal stability at 21 agents. Designed and implemented comparative experiments inspired by the Rainbow algorithm, assessing target network strategies versus the Double Deep Q-Network (Double DQN). The results demonstrated that Double DQN significantly enhanced convergence speed, optimizing the overall learning process. Co-authored a group project paper on agent numbers and strategies effectiveness in multi-agent systems, achieving a score of 71% in the summer program (the highest in my group) and a \u0026ldquo;First Class\u0026rdquo; classification in the UK grading system. üëÅÔ∏è Deep Learning and Computer Vision Semester Project 09/2022 ‚Äì 12/2022 Independent project, supervised by Associate Prof. Guangyu Gao Designed and implemented a waste classifier using the ResNet model to improve classification accuracy and reduce resource waste. The project also enhanced understanding of transfer learning techniques with ResNet. Collected a dataset of 16 waste categories and preprocessed the images for uniformity and standardization, incorporating data augmentation techniques to enhance the dataset. Conducted experiments using ResNet34 and ResNet50 models through transfer learning, accelerating network convergence by leveraging pretrained weights. During training, techniques such as Batch Normalization and Dropout were applied to mitigate the risk of overfitting. The final model achieved an accuracy of 90% on the training set, while the performance on the test set was 61%, indicating a significant overfitting phenomenon during the training process. üéì Internship ‚öõÔ∏è Beijing Academy of Quantum Information Science 08/2023 ‚Äì 01/2024 Research Intern at Quantum Computation Department Proposed a quantum convolution kernel design based on variational quantum circuits and developed a universal quantum convolution layer, successfully integrating it into classical CNN architectures such as VGG, GoogLeNet, and ResNet. Developed and evaluated various hybrid models, including a simple model named HQCCNN-2, which achieved 84.45% accuracy on the FashionMNIST dataset, surpassing the traditional CNN\u0026rsquo;s 80.72%. This demonstrates the effectiveness of the quantum convolution layer in improving model performance. Tested on a real quantum computer further validated the effectiveness of the hybrid model, demonstrating the viable integration of quantum computing with deep learning, and highlighting the potential for leveraging quantum properties to enhance model performance. üèÖ Competition Experience ü•â China International \u0026#34;Internet \u0026#43;\u0026#34; College Students\u0026#39; Innovation Competition 08/2022 üõ°Ô∏è Zhongke Ushield: Deep Learning-based Face Privacy Protection Authentication System Responsible for constructing a localized facial feature extraction engine based on MobileFaceNet, ensuring feature extraction is completed on end devices (such as mobile phones and cameras), guaranteeing that raw data does not leave the domain and is not stored, thus enhancing user privacy protection while improving recognition efficiency. ü•â \u0026#34;Challenge Cup\u0026#34; Capital University Entrepreneurship Competition 05/2022 üå≥ Smart Orchard Responsible for the development of the fruit detection, ripeness prediction, and pest identification system, using deep convolutional neural network (CNN) technology for intelligent monitoring of crop growth conditions. Applied advanced object detection algorithms such as Faster R-CNN and YOLO to achieve high precision in apple detection and ripeness assessment, with an accuracy rate exceeding 90%, significantly enhancing the intelligence level of orchard management. Built and trained a dedicated dataset containing various pest samples, optimizing pest detection accuracy through data preprocessing (such as image normalization and resizing) and data augmentation techniques (like rotation, flipping, and noise addition), enabling the real-time monitoring system to accurately identify over 80% of pests, providing effective scientific maintenance recommendations to help farmers reduce crop losses. üìã Extracurricular Activities Vice President, Cyber Security Club, Beijing Institute of Technology 09/2021-09/2022 Backbone, Media Center of the Student Union of Beijing Institute of Technology 10/2020-06/2021 üì´ Contact üìß Email: zongsi.xu@outlook.com üëî LinkedIn: Zongsi (Tristan) Xu üíª GitHub: github.com/BaizeXS üìç Location: Hong Kong SAR, China ","permalink":"http://localhost:1313/resume/","summary":"Personal resume of Zongsi (Tristan) Xu","title":"Zongsi (Tristan) Xu"},{"content":"‰∏Ä„ÄÅÊï∞ÂÄºÁâπÂæÅ‰∏éÁ±ªÂà´ÁâπÂæÅ Êï∞ÂÄºÁâπÂæÅ (Numeric Features) ÂÖ∑ÊúâÂèØÂä†ÂáèÁöÑÊÑè‰πâÔºå‰∏îÂ≠òÂú®Â§ßÂ∞èÈ°∫Â∫è„ÄÇ ‰æãÂ≠êÔºöÂπ¥ÈæÑ„ÄÅÊ∏©Â∫¶Á≠â„ÄÇÂèØ‰ª•Áõ¥Êé•‰øùÁïôÂÖ∂Êï¥Êï∞ÊàñÊµÆÁÇπÊï∞ÂΩ¢Âºè‰æõÊ®°Âûã‰ΩøÁî®„ÄÇ Á±ªÂà´ÁâπÂæÅ (Categorical Features) Êï∞ÊçÆÂÄºÁ¶ªÊï£Ôºå‰∏çÂÖ∑Â§á‚ÄúÊï∞ÂÄºÂ§ßÂ∞è‚ÄùÈó¥ÁöÑÂèØÊØîÊÑè‰πâ„ÄÇ ‰æãÂ≠êÔºöÂõΩÁ±çÔºàÁæéÂõΩ/‰∏≠ÂõΩ/Âç∞Â∫¶Á≠âÔºâ„ÄÅÊÄßÂà´ÔºàÁî∑/Â•≥ÔºâÁ≠â„ÄÇ ÈóÆÈ¢òÔºöËã•‰ªÖÁî®Êï¥Êï∞Ë°®Á§∫ÔºàÁæéÂõΩ=1, ‰∏≠ÂõΩ=2ÔºâÔºå‰ºöÂºïÂÖ•ÈîôËØØÁöÑÊï∞ÂÄºËøêÁÆóÂÖ≥Á≥ªÔºåÂ¶Ç ‚ÄúÁæéÂõΩ + ‰∏≠ÂõΩ = Âç∞Â∫¶‚Äù„ÄÇ ‰∫å„ÄÅOne-HotÁºñÁ†ÅÁöÑÂä®Êú∫‰∏éÊµÅÁ®ã ‰∏∫‰ªÄ‰πà‰ΩøÁî®One-Hot\nÈÄöËøáÂ∞ÜÁ±ªÂà´Êò†Â∞Ñ‰∏∫ÂêëÈáèÔºåÈÅøÂÖçÊï¥Êï∞ÁºñÁ†ÅÂºïÂÖ•ÁöÑ‰º™Êï∞ÂÄºÂÖ≥Á≥ª„ÄÇ ÂêåÊó∂‰øùÁïôÂêÑÁßçÂèØËÉΩÁ±ªÂà´ÁöÑ‰ø°ÊÅØÔºå‰∏î‰ªÖÂú®ÂØπÂ∫î‰ΩçÁΩÆ‰∏∫1ÔºåÂÖ∂‰ªñ‰ΩçÁΩÆ‰∏∫0„ÄÇ Âª∫Á´ãÊò†Â∞ÑÔºö‰ªéÁ±ªÂà´Âà∞Á¥¢Âºï\n‰∏∫ÊØè‰∏™Á±ªÂà´ÂàÜÈÖç‰∏Ä‰∏™ÂîØ‰∏ÄÁ¥¢ÂºïÔºåÈÄöÂ∏∏‰ªé1ÂºÄÂßã„ÄÇ È¢ÑÁïôÁ¥¢Âºï0Ë°®Á§∫‚ÄúÊú™Áü•‚ÄùÊàñ‚ÄúÁº∫Â§±‚ÄùÔºåÂØπÂ∫îÂÖ®0ÂêëÈáè„ÄÇ ËΩ¨Êç¢‰∏∫One-HotÂêëÈáè\nËã•Á±ªÂà´ÊÄªÊï∞‰∏∫197ÔºåÂàôÁî®197Áª¥ÂêëÈáèË°®Á§∫„ÄÇ ‰æãÂ≠êÔºöÁæéÂõΩ [1, 0, 0, 0, ‚Ä¶]Ôºå ‰∏≠ÂõΩ [0, 1, 0, 0, ‚Ä¶]„ÄÇ Á§∫‰æãÔºöË°®Á§∫‰∏Ä‰∏™‰∫∫ÁöÑÁâπÂæÅ\nÁâπÂæÅÂåÖÂê´ÔºàÂπ¥ÈæÑ, ÊÄßÂà´, ÂõΩÁ±çÔºåÂÖ∂‰∏≠ÂõΩÁ±ç197ÁßçÔºâ Áª¥Â∫¶ÊÄªÂíåÔºö1Áª¥_age + 1Áª¥_gender + 197Áª¥_nationality = 199Áª¥„ÄÇ ‰æãÂ¶Ç (28, Â•≥, ‰∏≠ÂõΩ) ‚Üí [28, 0, 0, 1, 0, ‚Ä¶, 0]„ÄÇ ‰∏â„ÄÅÊñáÊú¨Êï∞ÊçÆÂ§ÑÁêÜÊµÅÁ®ã ÊñáÊú¨Âú®Ëá™ÁÑ∂ËØ≠Ë®ÄÂ§ÑÁêÜÔºàNLPÔºâ‰∏≠‰Ωú‰∏∫Â∏∏ËßÅÁöÑÂéüÂßãËæìÂÖ•ÔºåÈúÄË¶ÅÊï∞ÂÄºÂåñÊâçËÉΩÈÄÅÂÖ•Ê®°Âûã„ÄÇ‰∏ÄËà¨Ê≠•È™§Â¶Ç‰∏ãÔºö\nÂàÜËØç (Tokenization)\nÂ∞ÜÊñáÊú¨ÊãÜÂàÜ‰∏∫‰∏Ä‰∏™‰∏™ÂçïËØçÔºàTokenÔºâ„ÄÇ ‰æãÂ≠êÔºö\u0026quot;... to be or not to be...\u0026quot; ‚Üí [\u0026quot;...\u0026quot;, \u0026quot;to\u0026quot;, \u0026quot;be\u0026quot;, \u0026quot;or\u0026quot;, \u0026quot;not\u0026quot;, \u0026quot;to\u0026quot;, \u0026quot;be\u0026quot;, \u0026quot;...\u0026quot;]„ÄÇ ÁªüËÆ°ËØçÈ¢ë \u0026amp; ÊûÑÂª∫ËØçÂÖ∏\nËØçÈ¢ëÁªüËÆ° Áî®ÂìàÂ∏åË°®/Â≠óÂÖ∏ËÆ∞ÂΩïÊØè‰∏™ÂçïËØçÂá∫Áé∞Ê¨°Êï∞„ÄÇ ÈÅçÂéÜÊñáÊú¨Êó∂ÔºåËã•ÂçïËØçÂ∞öÊú™ÂÖ•Ë°®ÔºåÂàôÊñ∞Âª∫ËÆ∞ÂΩïÔºõËã•Â∑≤Â≠òÂú®ÔºåÂàôËÆ°Êï∞+1„ÄÇ ÊéíÂ∫è‰∏éÁ¥¢Âºï ÊåâËØçÈ¢ëÈôçÂ∫èÊéíÂ∫èÔºåËØçÈ¢ëÊúÄÈ´òÁöÑÂçïËØçÊéíÂú®ÂâçÈù¢„ÄÇ Á¥¢Âºï‰ªé1ÂºÄÂßãÔºå0ÁïôÁªô‚ÄúÊú™Áü•‚Äù„ÄÇ ËØçÂÖ∏ËßÑÊ®°ÔºàvocabularyÔºâÂèØËßÜÈúÄÊ±ÇÊà™Êñ≠Ôºà‰æãÂ¶ÇÂè™‰øùÁïôTop 10kÔºâ„ÄÇ ‰∏∫‰ªÄ‰πàÁßªÈô§‰ΩéÈ¢ëËØç ‰ΩéÈ¢ëËØçÂèØËÉΩÊòØÊãºÂÜôÈîôËØØ„ÄÅÁΩïËßÅ‰∫∫ÂêçÁ≠âÔºåÂØπÊ®°ÂûãÂ∏ÆÂä©ÊúâÈôê„ÄÇ ÂáèÂ∞ëËØçÂÖ∏ËßÑÊ®°ÂèØÈôç‰ΩéËøêÁÆóÂºÄÈîÄ„ÄÅÂä†Âø´Ê®°ÂûãËÆ≠ÁªÉ‰∏éÊé®ÁêÜÈÄüÂ∫¶„ÄÇ Áã¨ÁÉ≠ÁºñÁ†Å (One-Hot Encoding)\nÂ∞ÜÊØè‰∏™ÂçïËØçÊò†Â∞Ñ‰∏∫ËØçÂÖ∏‰∏≠ÁöÑÁ¥¢ÂºïÂêéÔºàÂ¶Ç [2, 4, 1, 8, ‚Ä¶]ÔºâÔºåÂèØËøõ‰∏ÄÊ≠•ËΩ¨Êç¢ÊàêOne-HotÂêëÈáè„ÄÇ One-HotÁª¥Â∫¶ÂèñÂÜ≥‰∫é‰øùÁïô‰∏ãÊù•ÁöÑËØçÂÖ∏Â§ßÂ∞èÔºà‰æãÂ¶Ç1‰∏áÔºâ„ÄÇ Êú™Êî∂ÂΩïÂçïËØçÂèØËÉΩÁõ¥Êé•ÂøΩÁï•ÔºåÊàñÁªü‰∏ÄÁî®Á¥¢Âºï0‰ª£Êõø„ÄÇ Âõõ„ÄÅÊ†∏ÂøÉÊî∂Ëé∑‰∏éÂ∫îÁî® Á±ªÂà´ÁâπÂæÅÂøÖÈúÄÊï∞ÂÄºÂåñÔºö\n‰ΩøÁî®Êï¥Êï∞1,2,3‚Ä¶‰ªÖË°®Á§∫Á±ªÂà´‚ÄúÊ†áËØÜ‚ÄùÔºåÂπ∂‰∏ç‰ª£Ë°®ÂÆÉ‰ª¨ÂèØËøõË°åÊï∞ÂÄºËøêÁÆó„ÄÇ Âõ†Ê≠§ÈúÄË¶ÅOne-HotÁ≠âÁºñÁ†ÅÊñπÂºèÔºåÈÅøÂÖçÊï∞ÂÄºËØØËß£„ÄÇ ÊñáÊú¨Êï∞ÊçÆÈ¢ÑÂ§ÑÁêÜÔºö\nÂàÜËØç„ÄÅËØçÈ¢ëÁªüËÆ°„ÄÅÊûÑÂª∫ËØçÂÖ∏„ÄÅÁ¥¢ÂºïÂåñ„ÄÅOne-HotÊàñÂÖ∂‰ªñÊñπÂºèÔºàÂ¶ÇËØçÂµåÂÖ•ÔºâÊòØÂ∏∏ËßÅÊµÅÁ®ã„ÄÇ Ê≠£Á°ÆÁöÑÊñáÊú¨È¢ÑÂ§ÑÁêÜÂèØÊòæËëóÂΩ±ÂìçÊ®°ÂûãÊÄßËÉΩÂíåÊïàÁéá„ÄÇ ‰øùÁïôÊú™Áü•Á¥¢ÂºïÔºö\n‰øùËØÅÂØπÁº∫Â§±Êï∞ÊçÆÊàñÂ≠óÂÖ∏Â§ñÊñ∞ËØçËÉΩÊúâÂü∫Êú¨ÁöÑË°®Á§∫ÔºåÊèêÂçáÊ®°ÂûãÂÆπÈîôÊÄß„ÄÇ ÂÆûÈôÖ‰ΩøÁî®Ôºö\nÂØπ‰∫éÂ∞èËßÑÊ®°Á±ªÂà´ÂèØÁõ¥Êé•One-HotÁºñÁ†ÅÔºõÂØπ‰∫éËØçÂÖ∏ÂæàÂ§ßÁöÑÂú∫ÊôØÔºåÈÄöÂ∏∏‰ºöËøõ‰∏ÄÊ≠•ËÄÉËôëËØçÂµåÂÖ•ÔºàWord EmbeddingÔºâÊàñÈ¢ÑËÆ≠ÁªÉËØ≠Ë®ÄÊ®°Âûã„ÄÇ ","permalink":"http://localhost:1313/posts/nlp-1/","summary":"\u003ch2 id=\"‰∏ÄÊï∞ÂÄºÁâπÂæÅ‰∏éÁ±ªÂà´ÁâπÂæÅ\"\u003e‰∏Ä„ÄÅÊï∞ÂÄºÁâπÂæÅ‰∏éÁ±ªÂà´ÁâπÂæÅ\u003c/h2\u003e\n\u003col\u003e\n\u003cli\u003e\u003cstrong\u003eÊï∞ÂÄºÁâπÂæÅ (Numeric Features)\u003c/strong\u003e\n\u003cul\u003e\n\u003cli\u003eÂÖ∑ÊúâÂèØÂä†ÂáèÁöÑÊÑè‰πâÔºå‰∏îÂ≠òÂú®Â§ßÂ∞èÈ°∫Â∫è„ÄÇ\u003c/li\u003e\n\u003cli\u003e‰æãÂ≠êÔºöÂπ¥ÈæÑ„ÄÅÊ∏©Â∫¶Á≠â„ÄÇÂèØ‰ª•Áõ¥Êé•‰øùÁïôÂÖ∂Êï¥Êï∞ÊàñÊµÆÁÇπÊï∞ÂΩ¢Âºè‰æõÊ®°Âûã‰ΩøÁî®„ÄÇ\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003eÁ±ªÂà´ÁâπÂæÅ (Categorical Features)\u003c/strong\u003e\n\u003cul\u003e\n\u003cli\u003eÊï∞ÊçÆÂÄºÁ¶ªÊï£Ôºå‰∏çÂÖ∑Â§á‚ÄúÊï∞ÂÄºÂ§ßÂ∞è‚ÄùÈó¥ÁöÑÂèØÊØîÊÑè‰πâ„ÄÇ\u003c/li\u003e\n\u003cli\u003e‰æãÂ≠êÔºöÂõΩÁ±çÔºàÁæéÂõΩ/‰∏≠ÂõΩ/Âç∞Â∫¶Á≠âÔºâ„ÄÅÊÄßÂà´ÔºàÁî∑/Â•≥ÔºâÁ≠â„ÄÇ\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003eÈóÆÈ¢ò\u003c/strong\u003eÔºöËã•‰ªÖÁî®Êï¥Êï∞Ë°®Á§∫ÔºàÁæéÂõΩ=1, ‰∏≠ÂõΩ=2ÔºâÔºå‰ºöÂºïÂÖ•ÈîôËØØÁöÑÊï∞ÂÄºËøêÁÆóÂÖ≥Á≥ªÔºåÂ¶Ç ‚ÄúÁæéÂõΩ + ‰∏≠ÂõΩ = Âç∞Â∫¶‚Äù„ÄÇ\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003c/ol\u003e\n\u003ch2 id=\"‰∫åone-hotÁºñÁ†ÅÁöÑÂä®Êú∫‰∏éÊµÅÁ®ã\"\u003e‰∫å„ÄÅOne-HotÁºñÁ†ÅÁöÑÂä®Êú∫‰∏éÊµÅÁ®ã\u003c/h2\u003e\n\u003col\u003e\n\u003cli\u003e\n\u003cp\u003e\u003cstrong\u003e‰∏∫‰ªÄ‰πà‰ΩøÁî®One-Hot\u003c/strong\u003e\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eÈÄöËøáÂ∞ÜÁ±ªÂà´Êò†Â∞Ñ‰∏∫ÂêëÈáèÔºåÈÅøÂÖçÊï¥Êï∞ÁºñÁ†ÅÂºïÂÖ•ÁöÑ‰º™Êï∞ÂÄºÂÖ≥Á≥ª„ÄÇ\u003c/li\u003e\n\u003cli\u003eÂêåÊó∂‰øùÁïôÂêÑÁßçÂèØËÉΩÁ±ªÂà´ÁöÑ‰ø°ÊÅØÔºå‰∏î‰ªÖÂú®ÂØπÂ∫î‰ΩçÁΩÆ‰∏∫1ÔºåÂÖ∂‰ªñ‰ΩçÁΩÆ‰∏∫0„ÄÇ\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003e\u003cstrong\u003eÂª∫Á´ãÊò†Â∞ÑÔºö‰ªéÁ±ªÂà´Âà∞Á¥¢Âºï\u003c/strong\u003e\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e‰∏∫ÊØè‰∏™Á±ªÂà´ÂàÜÈÖç‰∏Ä‰∏™ÂîØ‰∏ÄÁ¥¢ÂºïÔºåÈÄöÂ∏∏‰ªé1ÂºÄÂßã„ÄÇ\u003c/li\u003e\n\u003cli\u003eÈ¢ÑÁïôÁ¥¢Âºï0Ë°®Á§∫‚ÄúÊú™Áü•‚ÄùÊàñ‚ÄúÁº∫Â§±‚ÄùÔºåÂØπÂ∫îÂÖ®0ÂêëÈáè„ÄÇ\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003e\u003cstrong\u003eËΩ¨Êç¢‰∏∫One-HotÂêëÈáè\u003c/strong\u003e\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eËã•Á±ªÂà´ÊÄªÊï∞‰∏∫197ÔºåÂàôÁî®197Áª¥ÂêëÈáèË°®Á§∫„ÄÇ\u003c/li\u003e\n\u003cli\u003e‰æãÂ≠êÔºöÁæéÂõΩ \u003ccode\u003e[1, 0, 0, 0, ‚Ä¶]\u003c/code\u003eÔºå ‰∏≠ÂõΩ \u003ccode\u003e[0, 1, 0, 0, ‚Ä¶]\u003c/code\u003e„ÄÇ\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003e\u003cstrong\u003eÁ§∫‰æãÔºöË°®Á§∫‰∏Ä‰∏™‰∫∫ÁöÑÁâπÂæÅ\u003c/strong\u003e\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eÁâπÂæÅÂåÖÂê´ÔºàÂπ¥ÈæÑ, ÊÄßÂà´, ÂõΩÁ±çÔºåÂÖ∂‰∏≠ÂõΩÁ±ç197ÁßçÔºâ\u003c/li\u003e\n\u003cli\u003eÁª¥Â∫¶ÊÄªÂíåÔºö1Áª¥_age + 1Áª¥_gender + 197Áª¥_nationality = 199Áª¥„ÄÇ\u003c/li\u003e\n\u003cli\u003e‰æãÂ¶Ç \u003ccode\u003e(28, Â•≥, ‰∏≠ÂõΩ)\u003c/code\u003e ‚Üí \u003ccode\u003e[28, 0, 0, 1, 0, ‚Ä¶, 0]\u003c/code\u003e„ÄÇ\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003c/ol\u003e\n\u003ch2 id=\"‰∏âÊñáÊú¨Êï∞ÊçÆÂ§ÑÁêÜÊµÅÁ®ã\"\u003e‰∏â„ÄÅÊñáÊú¨Êï∞ÊçÆÂ§ÑÁêÜÊµÅÁ®ã\u003c/h2\u003e\n\u003cp\u003eÊñáÊú¨Âú®Ëá™ÁÑ∂ËØ≠Ë®ÄÂ§ÑÁêÜÔºàNLPÔºâ‰∏≠‰Ωú‰∏∫Â∏∏ËßÅÁöÑÂéüÂßãËæìÂÖ•ÔºåÈúÄË¶ÅÊï∞ÂÄºÂåñÊâçËÉΩÈÄÅÂÖ•Ê®°Âûã„ÄÇ‰∏ÄËà¨Ê≠•È™§Â¶Ç‰∏ãÔºö\u003c/p\u003e\n\u003col\u003e\n\u003cli\u003e\n\u003cp\u003e\u003cstrong\u003eÂàÜËØç (Tokenization)\u003c/strong\u003e\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eÂ∞ÜÊñáÊú¨ÊãÜÂàÜ‰∏∫‰∏Ä‰∏™‰∏™ÂçïËØçÔºàTokenÔºâ„ÄÇ\u003c/li\u003e\n\u003cli\u003e‰æãÂ≠êÔºö\u003ccode\u003e\u0026quot;... to be or not to be...\u0026quot;\u003c/code\u003e ‚Üí \u003ccode\u003e[\u0026quot;...\u0026quot;, \u0026quot;to\u0026quot;, \u0026quot;be\u0026quot;, \u0026quot;or\u0026quot;, \u0026quot;not\u0026quot;, \u0026quot;to\u0026quot;, \u0026quot;be\u0026quot;, \u0026quot;...\u0026quot;]\u003c/code\u003e„ÄÇ\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003e\u003cstrong\u003eÁªüËÆ°ËØçÈ¢ë \u0026amp; ÊûÑÂª∫ËØçÂÖ∏\u003c/strong\u003e\u003c/p\u003e","title":""},{"content":"Text to Sequence ÊñáÊú¨Â§ÑÁêÜ\nStep1: Tokenization\nTokenization breaks a piece of text down into a list of tokens.\nHere, a token is a word. (A token can be a character in some applications.)\nTokenizationËÆ≤Á©∂ÂæàÂ§öÔºå‰æãÂ¶ÇÊòØÂê¶Â∫îËØ•ÊääÂ§ßÂÜôÊîπÊàêÂ∞èÂÜôÂë¢ÔºüËøõË°åtypo correctionÁ≠âÁ≠â\nStep2: Build Dictionary\nUse a dictionary (hash table) to count word frequencies.\nThe dictionary maps word to index.\nÂèØ‰ª•È¶ñÂÖàÁªüËÆ°ËØçÈ¢ëÂéªÊéâ‰ΩéÈ¢ëËØçÔºåÁÑ∂ÂêéËÆ©ÊØè‰∏™ËØçÂØπÂ∫î‰∏Ä‰∏™Ê≠£Êï¥Êï∞ÔºõËøôÊ†∑ÁöÑËØùÔºå‰∏ÄÂè•ËØùÂ∞±ÂèØ‰ª•Áî®‰∏Ä‰∏™Ê≠£Êï¥Êï∞ÂàóË°®Ë°®Á§∫ÔºåËøô‰∏™ÂàóË°®Â∞±Âè´sequenceÔºõÂ¶ÇÊûúÂøÖË¶ÅÂ∞±ËøòÂæóÂÅöone-hot encoding„ÄÇ\nÁªìÊûú\n‰ΩÜÊòØÈïøÂ∫¶‰∏çÁªü‰∏Ä\nStep4: ÂØπÈΩêsequence\nËß£ÂÜ≥ÊñπÊ°àÊòØËøôÊ†∑ÁöÑÔºöÂèØ‰ª•Âõ∫ÂÆöÈïøÂ∫¶‰∏∫wÔºåÂä†ÂÖ•‰∏Ä‰∏™Â∫èÂàóÈïøÂ∫¶Â§™ÈïøÔºåÂ∞±Á†çÊéâÂâçÈù¢ÁöÑËØçÔºåÂè™‰øùÁïôÊúÄÂêéw‰∏™ËØçÔºõÂ¶ÇÊûú‰∏Ä‰∏™Â∫èÂàóÂ§™Áü≠ÔºåÂ∞±ÂÅözero paddingÔºåÁî®0Â°´ÂÖÖ\nËøôÊ†∑‰∏ÄÊù•ÔºåÊâÄÊúâÁöÑÂ∫èÂàóÈïøÂ∫¶Â∞±Áªü‰∏Ä‰∫Ü\nÊñáÊú¨Â§ÑÁêÜÂÆåÊàê‰∫ÜÔºåÊé•‰∏ãÊù•ÊòØword embeddingÔºåÊääÂçïËØçË°®Á§∫‰∏∫‰∏Ä‰∏™‰ΩéÁª¥ÂêëÈáèÔºõ\nÁÑ∂ËÄåËøôÊ†∑ÂÅöÁöÑËØùÔºåÂ¶ÇÊûúÊòØ10000‰∏™ÂçïËØçÔºåÁª¥Â∫¶Â∞±ÊòØ10000Áª¥ÔºåÁª¥Â∫¶Â§™È´ò‰∫ÜÔºõÂõ†Ê≠§Ë¶ÅÂÅöword embeddingÔºõ\nÂÖ∑‰ΩìÂÅöÊ≥ïÂ∞±ÊòØÊääone-hotÂêëÈáèe_iÂíåÂèÇÊï∞Áü©ÈòµpÁõ∏‰πòÔºõÁü©ÈòµPËΩ¨ÁΩÆÁöÑÂ§ßÂ∞èÊòØd x vÔºõdÊòØËØçÂêëÈáèÁöÑÁª¥Â∫¶ÔºõvÊòØÂ≠óÂÖ∏ÈáåËØçÊ±áÁöÑÊï∞ÈáèÔºõÁªìÊûú‰∏∫x_iÔºõx_iÂ∞±ÊòØ‰∏Ä‰∏™ËØçÂêëÈáèÔºõÂ¶ÇÊûúone-hotÂêëÈáèÁöÑÁ¨¨‰∏âË°å‰∏∫1ÔºõÈÇ£‰πàx_iÂ∞±ÊòØPËΩ¨ÁΩÆÁü©ÈòµÁöÑÁ¨¨‰∏âÂàóÔºàÂÖ∂‰ΩôÂàóÈÉΩ‰∏∫0ÔºâÔºõÊâÄ‰ª•PËΩ¨ÁΩÆÊØè‰∏ÄÂàóÈÉΩÊòØ‰∏Ä‰∏™ËØçÂêëÈáèÔºõÊâÄ‰ª•Áü©ÈòµPÊú¨Ë∫´ÁöÑÊØè‰∏ÄË°åÂ∞±ÊòØ‰∏Ä‰∏™ËØçÂêëÈáèÔºõÂÖ∂Ë°åÊï∞‰∏∫vÔºõÂç≥vocabularyÔºåËØçÊ±áÈáèÔºõÊØè‰∏ÄË°åÂØπÂ∫î‰∏Ä‰∏™ÂçïËØçÔºõÁü©ÈòµÁöÑÂàóÊï∞‰∏∫dÔºõdÊòØÁî®Êà∑ÂÜ≥ÂÆöÁöÑÔºõdÁöÑÂ§ßÂ∞è‰ºöÂÜ≥ÂÆöÊú∫Âô®Â≠¶‰π†Ê®°ÂûãÁöÑË°®Áé∞ÔºõÂ∫îËØ•Áî®xxxÊù•ÈÄâÊã©‰∏Ä‰∏™ÊØîËæÉÂ•ΩÁöÑdÔºõ\nÊàë‰ª¨ÁöÑ‰ªªÂä°ÊòØÁúãËØÑËÆ∫ÊòØÊ≠£Èù¢ÁöÑËøòÊòØË¥üÈù¢ÁöÑÔºõÂèÇÊï∞Áü©ÈòµÊòØ‰ªéËÆ≠ÁªÉÊï∞ÊçÆ‰∏≠Â≠¶‰π†Âá∫Êù•ÁöÑÔºåÊâÄ‰ª•Â≠¶Âá∫Êù•ÁöÑËØçÂêëÈáèÊòØÂ∏¶ÊúâÊÑüÊÉÖËâ≤ÂΩ©ÁöÑÔºõÂÅáËÆæËøô‰∫õËØçÂêëÈáèÈÉΩÊòØ‰∫åÁª¥ÁöÑÔºåÂàôÂèØ‰ª•Âú®Âπ≥Èù¢ÂùêÊ†áÁ≥ª‰∏≠Ê†áÂá∫‰∏ãÈù¢ËØçÂêëÈáè\nkerasÊèê‰æõembeddingÂ±ÇÔºõÁî®Êà∑ÂèØ‰ª•ÊåáÂÆövocabularyÂ§ßÂ∞èÂíådÁöÑÂ§ßÂ∞èÔºõ‰ª•ÂèäÊØè‰∏Ä‰∏™sequenceÁöÑÈïøÂ∫¶ÔºõdÊòØÊ†πÊçÆÁÆóÊ≥ïÈÄâÂá∫Êù•ÁöÑ Âà∞Ëøô‰∏ÄÊ≠•ÔºåÊàë‰ª¨Â∑≤ÁªèÂÆåÊàê‰∫ÜÊñáÊú¨Â§ÑÁêÜÂíåword embedding„ÄÇÊé•‰∏ãÊù•Â∞±ÊòØÁî®Logistic Regression for Binary ClassificationÂÅö‰∫åÂàÜÁ±ªÔºõ\n","permalink":"http://localhost:1313/posts/nlp-2/","summary":"\u003ch3 id=\"text-to-sequence\"\u003eText to Sequence\u003c/h3\u003e\n\u003cp\u003eÊñáÊú¨Â§ÑÁêÜ\u003c/p\u003e\n\u003cp\u003eStep1: Tokenization\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\n\u003cp\u003eTokenization breaks a piece of text down into a list of tokens.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003eHere, a token is a word. (A token can be a character in some applications.)\u003c/p\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003eTokenizationËÆ≤Á©∂ÂæàÂ§öÔºå‰æãÂ¶ÇÊòØÂê¶Â∫îËØ•ÊääÂ§ßÂÜôÊîπÊàêÂ∞èÂÜôÂë¢ÔºüËøõË°åtypo correctionÁ≠âÁ≠â\u003c/p\u003e\n\u003cp\u003e\u003cimg alt=\"image-20250322150322238\" loading=\"lazy\" src=\"./NLP-2.assets/image-20250322150322238.png\"\u003e\u003c/p\u003e\n\u003cp\u003eStep2: Build Dictionary\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\n\u003cp\u003eUse a dictionary (hash table) to count word frequencies.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003eThe dictionary maps word to index.\u003c/p\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003eÂèØ‰ª•È¶ñÂÖàÁªüËÆ°ËØçÈ¢ëÂéªÊéâ‰ΩéÈ¢ëËØçÔºåÁÑ∂ÂêéËÆ©ÊØè‰∏™ËØçÂØπÂ∫î‰∏Ä‰∏™Ê≠£Êï¥Êï∞ÔºõËøôÊ†∑ÁöÑËØùÔºå‰∏ÄÂè•ËØùÂ∞±ÂèØ‰ª•Áî®‰∏Ä‰∏™Ê≠£Êï¥Êï∞ÂàóË°®Ë°®Á§∫ÔºåËøô‰∏™ÂàóË°®Â∞±Âè´sequenceÔºõÂ¶ÇÊûúÂøÖË¶ÅÂ∞±ËøòÂæóÂÅöone-hot encoding„ÄÇ\u003cimg alt=\"image-20250322150620890\" loading=\"lazy\" src=\"./NLP-2.assets/image-20250322150620890.png\"\u003e\u003c/p\u003e\n\u003cp\u003eÁªìÊûú\u003c/p\u003e\n\u003cp\u003e\u003cimg alt=\"image-20250322150754528\" loading=\"lazy\" src=\"./NLP-2.assets/image-20250322150754528.png\"\u003e\u003c/p\u003e\n\u003cp\u003e‰ΩÜÊòØÈïøÂ∫¶‰∏çÁªü‰∏Ä\u003c/p\u003e\n\u003cp\u003eStep4: ÂØπÈΩêsequence\u003c/p\u003e\n\u003cp\u003e\u003cimg alt=\"image-20250322150854986\" loading=\"lazy\" src=\"./NLP-2.assets/image-20250322150854986.png\"\u003e\u003c/p\u003e\n\u003cp\u003eËß£ÂÜ≥ÊñπÊ°àÊòØËøôÊ†∑ÁöÑÔºöÂèØ‰ª•Âõ∫ÂÆöÈïøÂ∫¶‰∏∫wÔºåÂä†ÂÖ•‰∏Ä‰∏™Â∫èÂàóÈïøÂ∫¶Â§™ÈïøÔºåÂ∞±Á†çÊéâÂâçÈù¢ÁöÑËØçÔºåÂè™‰øùÁïôÊúÄÂêéw‰∏™ËØçÔºõÂ¶ÇÊûú‰∏Ä‰∏™Â∫èÂàóÂ§™Áü≠ÔºåÂ∞±ÂÅözero paddingÔºåÁî®0Â°´ÂÖÖ\u003c/p\u003e\n\u003cp\u003e\u003cimg alt=\"image-20250322151030119\" loading=\"lazy\" src=\"./NLP-2.assets/image-20250322151030119.png\"\u003e\u003c/p\u003e\n\u003cp\u003eËøôÊ†∑‰∏ÄÊù•ÔºåÊâÄÊúâÁöÑÂ∫èÂàóÈïøÂ∫¶Â∞±Áªü‰∏Ä‰∫Ü\u003c/p\u003e\n\u003cp\u003e\u003cimg alt=\"image-20250322151117125\" loading=\"lazy\" src=\"./NLP-2.assets/image-20250322151117125.png\"\u003e\u003c/p\u003e\n\u003cp\u003eÊñáÊú¨Â§ÑÁêÜÂÆåÊàê‰∫ÜÔºåÊé•‰∏ãÊù•ÊòØword embeddingÔºåÊääÂçïËØçË°®Á§∫‰∏∫‰∏Ä‰∏™‰ΩéÁª¥ÂêëÈáèÔºõ\u003c/p\u003e\n\u003cp\u003e\u003cimg alt=\"image-20250322151252837\" loading=\"lazy\" src=\"./NLP-2.assets/image-20250322151252837.png\"\u003e\u003c/p\u003e","title":""},{"content":"üëã About me Hello! I\u0026rsquo;m Xu Zongsi, a passionate technology enthusiast currently pursuing my Master of Science in ECIC at The University of Hong Kong. With a solid background in Software Engineering from the Beijing Institute of Technology, I specialize in artificial intelligence areas like machine learning, deep learning, natural language processing, computer vision, and reinforcement learning.\nInspired by OpenAI\u0026rsquo;s five-step plan towards superintelligence, I am excited about AGI and have developed a keen interest in LLM agents, MLLM, and knowledge graphs. I see great potential in these fields and aspire to contribute to innovative solutions.\nüìö Education üá≠üá∞ The University of Hong Kong 09/2024 - Expected 11/2025 School of Computing and Data Science Master of Science in Electronic Commerce \u0026amp; Internet Computing Relevant Courses: Machine learning for business and e-commerce, Knowledge graphs, Financial fraud analytics, Internet infrastructure technologies, Website engineering, Blockchain and cryptocurrency, etc. üá®üá≥ Beijing Institute of Technology 09/2020 - 06/2024 School of Computer Science \u0026amp; Technology Bachelor of Engineering in Software Engineering, last two years GPA: 3.7/4 Relevant Courses: Reinforcement Learning, Deep Learning and Computer Vision, Artificial Intelligence and Robot Ethics, Almost Human: Mind, Brain and Artificial Intelligence, Mathematical Analysis for Engineering, Linear Algebra, Probability and Mathematical Statistics, etc. Skills: Python, Java, common data structures, design patterns, machine learning basics and algorithms, Linux, PyTorch, and some development tools (git, conda, etc.). üèÜ Awards \u0026amp; Honors Beijing Institute of Technology Undergraduate Scholarship (Top 20% of Grade) 06/2023 3rd Prize of China International \u0026#34;Internet \u0026#43;\u0026#34; College Student\u0026#39;s Innovation Competition 08/2022 Bronze Prize of \u0026#34;Challenge Cup\u0026#34; Capital University Entrepreneurship Competition 05/2022 üíº Project Experience üîç Online Transaction Fraud Detection 09/2024 ‚Äì 01/2025 Independent project, supervised by Dr. Vivien Chan Focused on addressing financial fraud in e-commerce to enhance the accuracy of transaction anomaly detection, while independently managing the entire case study that included data preprocessing, feature engineering, model building, evaluation, and results analysis. Effectively resolved class imbalance issues using SMOTE and ROSE techniques. Built various models including Logistic Regression, Random Forest, XGBoost, and LightGBM, ultimately selecting the LightGBM model to achieve a recall rate of 95.45% and an AUC of 99.84%. Wrote efficient and maintainable code, enhancing model training and data processing efficiency through parallel computing and logging. ü§ñ Multi-Model Intelligent Text Keyword Extraction System 08/2023 ‚Äì 09/2023 Group project, supervised by Associate Prof. Xiaolin Zhao Designed and implemented an intelligent text summary system that automatically extracts keywords from article titles and abstracts, enhancing the understanding and summarization of text information. Participated in the planning of the technical route and built a hybrid model combining extractive and generative approaches, utilizing advanced natural language processing techniques including KeyBERT, Sentence Transformer, BERT, and T5 models. Responsible for data preprocessing and tokenization, as well as the end-to-end implementation and training of the T5 model, optimizing the model architecture and hyperparameters, achieving satisfactory results after only 3 epochs of training. Model evaluation results showed that the Rouge-1, Rouge-2, and Rouge-L metrics reached 0.6345, 0.5038, and 0.5282, respectively, in the third epoch, validating the model\u0026rsquo;s effectiveness in the summarization task. üéì Cambridge University Machine Learning Summer Project 07/2023 ‚Äì 08/2023 Group project, supervised by Prof. Pietro Li√≤ Participated in the Cambridge University deep learning summer project, focusing on deep reinforcement learning; explored multi-agent learning algorithms across different environments. Reproduced the Multi-Agent Deep Deterministic Policy Gradient (MADDPG) algorithm in the Simple Adversary environment and studied the effect of agent numbers on convergence speed and stability, finding optimal stability at 21 agents. Designed and implemented comparative experiments inspired by the Rainbow algorithm, assessing target network strategies versus the Double Deep Q-Network (Double DQN). The results demonstrated that Double DQN significantly enhanced convergence speed, optimizing the overall learning process. Co-authored a group project paper on agent numbers and strategies effectiveness in multi-agent systems, achieving a score of 71% in the summer program (the highest in my group) and a \u0026ldquo;First Class\u0026rdquo; classification in the UK grading system. üëÅÔ∏è Deep Learning and Computer Vision Semester Project 09/2022 ‚Äì 12/2022 Independent project, supervised by Associate Prof. Guangyu Gao Designed and implemented a waste classifier using the ResNet model to improve classification accuracy and reduce resource waste. The project also enhanced understanding of transfer learning techniques with ResNet. Collected a dataset of 16 waste categories and preprocessed the images for uniformity and standardization, incorporating data augmentation techniques to enhance the dataset. Conducted experiments using ResNet34 and ResNet50 models through transfer learning, accelerating network convergence by leveraging pretrained weights. During training, techniques such as Batch Normalization and Dropout were applied to mitigate the risk of overfitting. The final model achieved an accuracy of 90% on the training set, while the performance on the test set was 61%, indicating a significant overfitting phenomenon during the training process. üéì Internship ‚öõÔ∏è Beijing Academy of Quantum Information Science 08/2023 ‚Äì 01/2024 Research Intern at Quantum Computation Department Proposed a quantum convolution kernel design based on variational quantum circuits and developed a universal quantum convolution layer, successfully integrating it into classical CNN architectures such as VGG, GoogLeNet, and ResNet. Developed and evaluated various hybrid models, including a simple model named HQCCNN-2, which achieved 84.45% accuracy on the FashionMNIST dataset, surpassing the traditional CNN\u0026rsquo;s 80.72%. This demonstrates the effectiveness of the quantum convolution layer in improving model performance. Tested on a real quantum computer further validated the effectiveness of the hybrid model, demonstrating the viable integration of quantum computing with deep learning, and highlighting the potential for leveraging quantum properties to enhance model performance. üèÖ Competition Experience ü•â China International \u0026#34;Internet \u0026#43;\u0026#34; College Students\u0026#39; Innovation Competition 08/2022 üõ°Ô∏è Zhongke Ushield: Deep Learning-based Face Privacy Protection Authentication System Responsible for constructing a localized facial feature extraction engine based on MobileFaceNet, ensuring feature extraction is completed on end devices (such as mobile phones and cameras), guaranteeing that raw data does not leave the domain and is not stored, thus enhancing user privacy protection while improving recognition efficiency. ü•â \u0026#34;Challenge Cup\u0026#34; Capital University Entrepreneurship Competition 05/2022 üå≥ Smart Orchard Responsible for the development of the fruit detection, ripeness prediction, and pest identification system, using deep convolutional neural network (CNN) technology for intelligent monitoring of crop growth conditions. Applied advanced object detection algorithms such as Faster R-CNN and YOLO to achieve high precision in apple detection and ripeness assessment, with an accuracy rate exceeding 90%, significantly enhancing the intelligence level of orchard management. Built and trained a dedicated dataset containing various pest samples, optimizing pest detection accuracy through data preprocessing (such as image normalization and resizing) and data augmentation techniques (like rotation, flipping, and noise addition), enabling the real-time monitoring system to accurately identify over 80% of pests, providing effective scientific maintenance recommendations to help farmers reduce crop losses. üìã Extracurricular Activities Vice President, Cyber Security Club, Beijing Institute of Technology 09/2021-09/2022 Backbone, Media Center of the Student Union of Beijing Institute of Technology 10/2020-06/2021 üì´ Contact üìß Email: zongsi.xu@outlook.com üëî LinkedIn: Zongsi (Tristan) Xu üíª GitHub: github.com/BaizeXS üìç Location: Hong Kong SAR, China ","permalink":"http://localhost:1313/resume/","summary":"Personal resume of Zongsi (Tristan) Xu","title":"Zongsi (Tristan) Xu"},{"content":"‰∏Ä„ÄÅÊï∞ÂÄºÁâπÂæÅ‰∏éÁ±ªÂà´ÁâπÂæÅ Êï∞ÂÄºÁâπÂæÅ (Numeric Features) ÂÖ∑ÊúâÂèØÂä†ÂáèÁöÑÊÑè‰πâÔºå‰∏îÂ≠òÂú®Â§ßÂ∞èÈ°∫Â∫è„ÄÇ ‰æãÂ≠êÔºöÂπ¥ÈæÑ„ÄÅÊ∏©Â∫¶Á≠â„ÄÇÂèØ‰ª•Áõ¥Êé•‰øùÁïôÂÖ∂Êï¥Êï∞ÊàñÊµÆÁÇπÊï∞ÂΩ¢Âºè‰æõÊ®°Âûã‰ΩøÁî®„ÄÇ Á±ªÂà´ÁâπÂæÅ (Categorical Features) Êï∞ÊçÆÂÄºÁ¶ªÊï£Ôºå‰∏çÂÖ∑Â§á‚ÄúÊï∞ÂÄºÂ§ßÂ∞è‚ÄùÈó¥ÁöÑÂèØÊØîÊÑè‰πâ„ÄÇ ‰æãÂ≠êÔºöÂõΩÁ±çÔºàÁæéÂõΩ/‰∏≠ÂõΩ/Âç∞Â∫¶Á≠âÔºâ„ÄÅÊÄßÂà´ÔºàÁî∑/Â•≥ÔºâÁ≠â„ÄÇ ÈóÆÈ¢òÔºöËã•‰ªÖÁî®Êï¥Êï∞Ë°®Á§∫ÔºàÁæéÂõΩ=1, ‰∏≠ÂõΩ=2ÔºâÔºå‰ºöÂºïÂÖ•ÈîôËØØÁöÑÊï∞ÂÄºËøêÁÆóÂÖ≥Á≥ªÔºåÂ¶Ç ‚ÄúÁæéÂõΩ + ‰∏≠ÂõΩ = Âç∞Â∫¶‚Äù„ÄÇ ‰∫å„ÄÅOne-HotÁºñÁ†ÅÁöÑÂä®Êú∫‰∏éÊµÅÁ®ã ‰∏∫‰ªÄ‰πà‰ΩøÁî®One-Hot\nÈÄöËøáÂ∞ÜÁ±ªÂà´Êò†Â∞Ñ‰∏∫ÂêëÈáèÔºåÈÅøÂÖçÊï¥Êï∞ÁºñÁ†ÅÂºïÂÖ•ÁöÑ‰º™Êï∞ÂÄºÂÖ≥Á≥ª„ÄÇ ÂêåÊó∂‰øùÁïôÂêÑÁßçÂèØËÉΩÁ±ªÂà´ÁöÑ‰ø°ÊÅØÔºå‰∏î‰ªÖÂú®ÂØπÂ∫î‰ΩçÁΩÆ‰∏∫1ÔºåÂÖ∂‰ªñ‰ΩçÁΩÆ‰∏∫0„ÄÇ Âª∫Á´ãÊò†Â∞ÑÔºö‰ªéÁ±ªÂà´Âà∞Á¥¢Âºï\n‰∏∫ÊØè‰∏™Á±ªÂà´ÂàÜÈÖç‰∏Ä‰∏™ÂîØ‰∏ÄÁ¥¢ÂºïÔºåÈÄöÂ∏∏‰ªé1ÂºÄÂßã„ÄÇ È¢ÑÁïôÁ¥¢Âºï0Ë°®Á§∫‚ÄúÊú™Áü•‚ÄùÊàñ‚ÄúÁº∫Â§±‚ÄùÔºåÂØπÂ∫îÂÖ®0ÂêëÈáè„ÄÇ ËΩ¨Êç¢‰∏∫One-HotÂêëÈáè\nËã•Á±ªÂà´ÊÄªÊï∞‰∏∫197ÔºåÂàôÁî®197Áª¥ÂêëÈáèË°®Á§∫„ÄÇ ‰æãÂ≠êÔºöÁæéÂõΩ [1, 0, 0, 0, ‚Ä¶]Ôºå ‰∏≠ÂõΩ [0, 1, 0, 0, ‚Ä¶]„ÄÇ Á§∫‰æãÔºöË°®Á§∫‰∏Ä‰∏™‰∫∫ÁöÑÁâπÂæÅ\nÁâπÂæÅÂåÖÂê´ÔºàÂπ¥ÈæÑ, ÊÄßÂà´, ÂõΩÁ±çÔºåÂÖ∂‰∏≠ÂõΩÁ±ç197ÁßçÔºâ Áª¥Â∫¶ÊÄªÂíåÔºö1Áª¥_age + 1Áª¥_gender + 197Áª¥_nationality = 199Áª¥„ÄÇ ‰æãÂ¶Ç (28, Â•≥, ‰∏≠ÂõΩ) ‚Üí [28, 0, 0, 1, 0, ‚Ä¶, 0]„ÄÇ ‰∏â„ÄÅÊñáÊú¨Êï∞ÊçÆÂ§ÑÁêÜÊµÅÁ®ã ÊñáÊú¨Âú®Ëá™ÁÑ∂ËØ≠Ë®ÄÂ§ÑÁêÜÔºàNLPÔºâ‰∏≠‰Ωú‰∏∫Â∏∏ËßÅÁöÑÂéüÂßãËæìÂÖ•ÔºåÈúÄË¶ÅÊï∞ÂÄºÂåñÊâçËÉΩÈÄÅÂÖ•Ê®°Âûã„ÄÇ‰∏ÄËà¨Ê≠•È™§Â¶Ç‰∏ãÔºö\nÂàÜËØç (Tokenization)\nÂ∞ÜÊñáÊú¨ÊãÜÂàÜ‰∏∫‰∏Ä‰∏™‰∏™ÂçïËØçÔºàTokenÔºâ„ÄÇ ‰æãÂ≠êÔºö\u0026quot;... to be or not to be...\u0026quot; ‚Üí [\u0026quot;...\u0026quot;, \u0026quot;to\u0026quot;, \u0026quot;be\u0026quot;, \u0026quot;or\u0026quot;, \u0026quot;not\u0026quot;, \u0026quot;to\u0026quot;, \u0026quot;be\u0026quot;, \u0026quot;...\u0026quot;]„ÄÇ ÁªüËÆ°ËØçÈ¢ë \u0026amp; ÊûÑÂª∫ËØçÂÖ∏\nËØçÈ¢ëÁªüËÆ° Áî®ÂìàÂ∏åË°®/Â≠óÂÖ∏ËÆ∞ÂΩïÊØè‰∏™ÂçïËØçÂá∫Áé∞Ê¨°Êï∞„ÄÇ ÈÅçÂéÜÊñáÊú¨Êó∂ÔºåËã•ÂçïËØçÂ∞öÊú™ÂÖ•Ë°®ÔºåÂàôÊñ∞Âª∫ËÆ∞ÂΩïÔºõËã•Â∑≤Â≠òÂú®ÔºåÂàôËÆ°Êï∞+1„ÄÇ ÊéíÂ∫è‰∏éÁ¥¢Âºï ÊåâËØçÈ¢ëÈôçÂ∫èÊéíÂ∫èÔºåËØçÈ¢ëÊúÄÈ´òÁöÑÂçïËØçÊéíÂú®ÂâçÈù¢„ÄÇ Á¥¢Âºï‰ªé1ÂºÄÂßãÔºå0ÁïôÁªô‚ÄúÊú™Áü•‚Äù„ÄÇ ËØçÂÖ∏ËßÑÊ®°ÔºàvocabularyÔºâÂèØËßÜÈúÄÊ±ÇÊà™Êñ≠Ôºà‰æãÂ¶ÇÂè™‰øùÁïôTop 10kÔºâ„ÄÇ ‰∏∫‰ªÄ‰πàÁßªÈô§‰ΩéÈ¢ëËØç ‰ΩéÈ¢ëËØçÂèØËÉΩÊòØÊãºÂÜôÈîôËØØ„ÄÅÁΩïËßÅ‰∫∫ÂêçÁ≠âÔºåÂØπÊ®°ÂûãÂ∏ÆÂä©ÊúâÈôê„ÄÇ ÂáèÂ∞ëËØçÂÖ∏ËßÑÊ®°ÂèØÈôç‰ΩéËøêÁÆóÂºÄÈîÄ„ÄÅÂä†Âø´Ê®°ÂûãËÆ≠ÁªÉ‰∏éÊé®ÁêÜÈÄüÂ∫¶„ÄÇ Áã¨ÁÉ≠ÁºñÁ†Å (One-Hot Encoding)\nÂ∞ÜÊØè‰∏™ÂçïËØçÊò†Â∞Ñ‰∏∫ËØçÂÖ∏‰∏≠ÁöÑÁ¥¢ÂºïÂêéÔºàÂ¶Ç [2, 4, 1, 8, ‚Ä¶]ÔºâÔºåÂèØËøõ‰∏ÄÊ≠•ËΩ¨Êç¢ÊàêOne-HotÂêëÈáè„ÄÇ One-HotÁª¥Â∫¶ÂèñÂÜ≥‰∫é‰øùÁïô‰∏ãÊù•ÁöÑËØçÂÖ∏Â§ßÂ∞èÔºà‰æãÂ¶Ç1‰∏áÔºâ„ÄÇ Êú™Êî∂ÂΩïÂçïËØçÂèØËÉΩÁõ¥Êé•ÂøΩÁï•ÔºåÊàñÁªü‰∏ÄÁî®Á¥¢Âºï0‰ª£Êõø„ÄÇ Âõõ„ÄÅÊ†∏ÂøÉÊî∂Ëé∑‰∏éÂ∫îÁî® Á±ªÂà´ÁâπÂæÅÂøÖÈúÄÊï∞ÂÄºÂåñÔºö\n‰ΩøÁî®Êï¥Êï∞1,2,3‚Ä¶‰ªÖË°®Á§∫Á±ªÂà´‚ÄúÊ†áËØÜ‚ÄùÔºåÂπ∂‰∏ç‰ª£Ë°®ÂÆÉ‰ª¨ÂèØËøõË°åÊï∞ÂÄºËøêÁÆó„ÄÇ Âõ†Ê≠§ÈúÄË¶ÅOne-HotÁ≠âÁºñÁ†ÅÊñπÂºèÔºåÈÅøÂÖçÊï∞ÂÄºËØØËß£„ÄÇ ÊñáÊú¨Êï∞ÊçÆÈ¢ÑÂ§ÑÁêÜÔºö\nÂàÜËØç„ÄÅËØçÈ¢ëÁªüËÆ°„ÄÅÊûÑÂª∫ËØçÂÖ∏„ÄÅÁ¥¢ÂºïÂåñ„ÄÅOne-HotÊàñÂÖ∂‰ªñÊñπÂºèÔºàÂ¶ÇËØçÂµåÂÖ•ÔºâÊòØÂ∏∏ËßÅÊµÅÁ®ã„ÄÇ Ê≠£Á°ÆÁöÑÊñáÊú¨È¢ÑÂ§ÑÁêÜÂèØÊòæËëóÂΩ±ÂìçÊ®°ÂûãÊÄßËÉΩÂíåÊïàÁéá„ÄÇ ‰øùÁïôÊú™Áü•Á¥¢ÂºïÔºö\n‰øùËØÅÂØπÁº∫Â§±Êï∞ÊçÆÊàñÂ≠óÂÖ∏Â§ñÊñ∞ËØçËÉΩÊúâÂü∫Êú¨ÁöÑË°®Á§∫ÔºåÊèêÂçáÊ®°ÂûãÂÆπÈîôÊÄß„ÄÇ ÂÆûÈôÖ‰ΩøÁî®Ôºö\nÂØπ‰∫éÂ∞èËßÑÊ®°Á±ªÂà´ÂèØÁõ¥Êé•One-HotÁºñÁ†ÅÔºõÂØπ‰∫éËØçÂÖ∏ÂæàÂ§ßÁöÑÂú∫ÊôØÔºåÈÄöÂ∏∏‰ºöËøõ‰∏ÄÊ≠•ËÄÉËôëËØçÂµåÂÖ•ÔºàWord EmbeddingÔºâÊàñÈ¢ÑËÆ≠ÁªÉËØ≠Ë®ÄÊ®°Âûã„ÄÇ ","permalink":"http://localhost:1313/posts/nlp-1/","summary":"\u003ch2 id=\"‰∏ÄÊï∞ÂÄºÁâπÂæÅ‰∏éÁ±ªÂà´ÁâπÂæÅ\"\u003e‰∏Ä„ÄÅÊï∞ÂÄºÁâπÂæÅ‰∏éÁ±ªÂà´ÁâπÂæÅ\u003c/h2\u003e\n\u003col\u003e\n\u003cli\u003e\u003cstrong\u003eÊï∞ÂÄºÁâπÂæÅ (Numeric Features)\u003c/strong\u003e\n\u003cul\u003e\n\u003cli\u003eÂÖ∑ÊúâÂèØÂä†ÂáèÁöÑÊÑè‰πâÔºå‰∏îÂ≠òÂú®Â§ßÂ∞èÈ°∫Â∫è„ÄÇ\u003c/li\u003e\n\u003cli\u003e‰æãÂ≠êÔºöÂπ¥ÈæÑ„ÄÅÊ∏©Â∫¶Á≠â„ÄÇÂèØ‰ª•Áõ¥Êé•‰øùÁïôÂÖ∂Êï¥Êï∞ÊàñÊµÆÁÇπÊï∞ÂΩ¢Âºè‰æõÊ®°Âûã‰ΩøÁî®„ÄÇ\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003eÁ±ªÂà´ÁâπÂæÅ (Categorical Features)\u003c/strong\u003e\n\u003cul\u003e\n\u003cli\u003eÊï∞ÊçÆÂÄºÁ¶ªÊï£Ôºå‰∏çÂÖ∑Â§á‚ÄúÊï∞ÂÄºÂ§ßÂ∞è‚ÄùÈó¥ÁöÑÂèØÊØîÊÑè‰πâ„ÄÇ\u003c/li\u003e\n\u003cli\u003e‰æãÂ≠êÔºöÂõΩÁ±çÔºàÁæéÂõΩ/‰∏≠ÂõΩ/Âç∞Â∫¶Á≠âÔºâ„ÄÅÊÄßÂà´ÔºàÁî∑/Â•≥ÔºâÁ≠â„ÄÇ\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003eÈóÆÈ¢ò\u003c/strong\u003eÔºöËã•‰ªÖÁî®Êï¥Êï∞Ë°®Á§∫ÔºàÁæéÂõΩ=1, ‰∏≠ÂõΩ=2ÔºâÔºå‰ºöÂºïÂÖ•ÈîôËØØÁöÑÊï∞ÂÄºËøêÁÆóÂÖ≥Á≥ªÔºåÂ¶Ç ‚ÄúÁæéÂõΩ + ‰∏≠ÂõΩ = Âç∞Â∫¶‚Äù„ÄÇ\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003c/ol\u003e\n\u003ch2 id=\"‰∫åone-hotÁºñÁ†ÅÁöÑÂä®Êú∫‰∏éÊµÅÁ®ã\"\u003e‰∫å„ÄÅOne-HotÁºñÁ†ÅÁöÑÂä®Êú∫‰∏éÊµÅÁ®ã\u003c/h2\u003e\n\u003col\u003e\n\u003cli\u003e\n\u003cp\u003e\u003cstrong\u003e‰∏∫‰ªÄ‰πà‰ΩøÁî®One-Hot\u003c/strong\u003e\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eÈÄöËøáÂ∞ÜÁ±ªÂà´Êò†Â∞Ñ‰∏∫ÂêëÈáèÔºåÈÅøÂÖçÊï¥Êï∞ÁºñÁ†ÅÂºïÂÖ•ÁöÑ‰º™Êï∞ÂÄºÂÖ≥Á≥ª„ÄÇ\u003c/li\u003e\n\u003cli\u003eÂêåÊó∂‰øùÁïôÂêÑÁßçÂèØËÉΩÁ±ªÂà´ÁöÑ‰ø°ÊÅØÔºå‰∏î‰ªÖÂú®ÂØπÂ∫î‰ΩçÁΩÆ‰∏∫1ÔºåÂÖ∂‰ªñ‰ΩçÁΩÆ‰∏∫0„ÄÇ\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003e\u003cstrong\u003eÂª∫Á´ãÊò†Â∞ÑÔºö‰ªéÁ±ªÂà´Âà∞Á¥¢Âºï\u003c/strong\u003e\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e‰∏∫ÊØè‰∏™Á±ªÂà´ÂàÜÈÖç‰∏Ä‰∏™ÂîØ‰∏ÄÁ¥¢ÂºïÔºåÈÄöÂ∏∏‰ªé1ÂºÄÂßã„ÄÇ\u003c/li\u003e\n\u003cli\u003eÈ¢ÑÁïôÁ¥¢Âºï0Ë°®Á§∫‚ÄúÊú™Áü•‚ÄùÊàñ‚ÄúÁº∫Â§±‚ÄùÔºåÂØπÂ∫îÂÖ®0ÂêëÈáè„ÄÇ\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003e\u003cstrong\u003eËΩ¨Êç¢‰∏∫One-HotÂêëÈáè\u003c/strong\u003e\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eËã•Á±ªÂà´ÊÄªÊï∞‰∏∫197ÔºåÂàôÁî®197Áª¥ÂêëÈáèË°®Á§∫„ÄÇ\u003c/li\u003e\n\u003cli\u003e‰æãÂ≠êÔºöÁæéÂõΩ \u003ccode\u003e[1, 0, 0, 0, ‚Ä¶]\u003c/code\u003eÔºå ‰∏≠ÂõΩ \u003ccode\u003e[0, 1, 0, 0, ‚Ä¶]\u003c/code\u003e„ÄÇ\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003e\u003cstrong\u003eÁ§∫‰æãÔºöË°®Á§∫‰∏Ä‰∏™‰∫∫ÁöÑÁâπÂæÅ\u003c/strong\u003e\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eÁâπÂæÅÂåÖÂê´ÔºàÂπ¥ÈæÑ, ÊÄßÂà´, ÂõΩÁ±çÔºåÂÖ∂‰∏≠ÂõΩÁ±ç197ÁßçÔºâ\u003c/li\u003e\n\u003cli\u003eÁª¥Â∫¶ÊÄªÂíåÔºö1Áª¥_age + 1Áª¥_gender + 197Áª¥_nationality = 199Áª¥„ÄÇ\u003c/li\u003e\n\u003cli\u003e‰æãÂ¶Ç \u003ccode\u003e(28, Â•≥, ‰∏≠ÂõΩ)\u003c/code\u003e ‚Üí \u003ccode\u003e[28, 0, 0, 1, 0, ‚Ä¶, 0]\u003c/code\u003e„ÄÇ\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003c/ol\u003e\n\u003ch2 id=\"‰∏âÊñáÊú¨Êï∞ÊçÆÂ§ÑÁêÜÊµÅÁ®ã\"\u003e‰∏â„ÄÅÊñáÊú¨Êï∞ÊçÆÂ§ÑÁêÜÊµÅÁ®ã\u003c/h2\u003e\n\u003cp\u003eÊñáÊú¨Âú®Ëá™ÁÑ∂ËØ≠Ë®ÄÂ§ÑÁêÜÔºàNLPÔºâ‰∏≠‰Ωú‰∏∫Â∏∏ËßÅÁöÑÂéüÂßãËæìÂÖ•ÔºåÈúÄË¶ÅÊï∞ÂÄºÂåñÊâçËÉΩÈÄÅÂÖ•Ê®°Âûã„ÄÇ‰∏ÄËà¨Ê≠•È™§Â¶Ç‰∏ãÔºö\u003c/p\u003e\n\u003col\u003e\n\u003cli\u003e\n\u003cp\u003e\u003cstrong\u003eÂàÜËØç (Tokenization)\u003c/strong\u003e\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eÂ∞ÜÊñáÊú¨ÊãÜÂàÜ‰∏∫‰∏Ä‰∏™‰∏™ÂçïËØçÔºàTokenÔºâ„ÄÇ\u003c/li\u003e\n\u003cli\u003e‰æãÂ≠êÔºö\u003ccode\u003e\u0026quot;... to be or not to be...\u0026quot;\u003c/code\u003e ‚Üí \u003ccode\u003e[\u0026quot;...\u0026quot;, \u0026quot;to\u0026quot;, \u0026quot;be\u0026quot;, \u0026quot;or\u0026quot;, \u0026quot;not\u0026quot;, \u0026quot;to\u0026quot;, \u0026quot;be\u0026quot;, \u0026quot;...\u0026quot;]\u003c/code\u003e„ÄÇ\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003e\u003cstrong\u003eÁªüËÆ°ËØçÈ¢ë \u0026amp; ÊûÑÂª∫ËØçÂÖ∏\u003c/strong\u003e\u003c/p\u003e","title":""},{"content":"Text to Sequence ÊñáÊú¨Â§ÑÁêÜ\nStep1: Tokenization\nTokenization breaks a piece of text down into a list of tokens.\nHere, a token is a word. (A token can be a character in some applications.)\nTokenizationËÆ≤Á©∂ÂæàÂ§öÔºå‰æãÂ¶ÇÊòØÂê¶Â∫îËØ•ÊääÂ§ßÂÜôÊîπÊàêÂ∞èÂÜôÂë¢ÔºüËøõË°åtypo correctionÁ≠âÁ≠â\nStep2: Build Dictionary\nUse a dictionary (hash table) to count word frequencies.\nThe dictionary maps word to index.\nÂèØ‰ª•È¶ñÂÖàÁªüËÆ°ËØçÈ¢ëÂéªÊéâ‰ΩéÈ¢ëËØçÔºåÁÑ∂ÂêéËÆ©ÊØè‰∏™ËØçÂØπÂ∫î‰∏Ä‰∏™Ê≠£Êï¥Êï∞ÔºõËøôÊ†∑ÁöÑËØùÔºå‰∏ÄÂè•ËØùÂ∞±ÂèØ‰ª•Áî®‰∏Ä‰∏™Ê≠£Êï¥Êï∞ÂàóË°®Ë°®Á§∫ÔºåËøô‰∏™ÂàóË°®Â∞±Âè´sequenceÔºõÂ¶ÇÊûúÂøÖË¶ÅÂ∞±ËøòÂæóÂÅöone-hot encoding„ÄÇ\nÁªìÊûú\n‰ΩÜÊòØÈïøÂ∫¶‰∏çÁªü‰∏Ä\nStep4: ÂØπÈΩêsequence\nËß£ÂÜ≥ÊñπÊ°àÊòØËøôÊ†∑ÁöÑÔºöÂèØ‰ª•Âõ∫ÂÆöÈïøÂ∫¶‰∏∫wÔºåÂä†ÂÖ•‰∏Ä‰∏™Â∫èÂàóÈïøÂ∫¶Â§™ÈïøÔºåÂ∞±Á†çÊéâÂâçÈù¢ÁöÑËØçÔºåÂè™‰øùÁïôÊúÄÂêéw‰∏™ËØçÔºõÂ¶ÇÊûú‰∏Ä‰∏™Â∫èÂàóÂ§™Áü≠ÔºåÂ∞±ÂÅözero paddingÔºåÁî®0Â°´ÂÖÖ\nËøôÊ†∑‰∏ÄÊù•ÔºåÊâÄÊúâÁöÑÂ∫èÂàóÈïøÂ∫¶Â∞±Áªü‰∏Ä‰∫Ü\nÊñáÊú¨Â§ÑÁêÜÂÆåÊàê‰∫ÜÔºåÊé•‰∏ãÊù•ÊòØword embeddingÔºåÊääÂçïËØçË°®Á§∫‰∏∫‰∏Ä‰∏™‰ΩéÁª¥ÂêëÈáèÔºõ\nÁÑ∂ËÄåËøôÊ†∑ÂÅöÁöÑËØùÔºåÂ¶ÇÊûúÊòØ10000‰∏™ÂçïËØçÔºåÁª¥Â∫¶Â∞±ÊòØ10000Áª¥ÔºåÁª¥Â∫¶Â§™È´ò‰∫ÜÔºõÂõ†Ê≠§Ë¶ÅÂÅöword embeddingÔºõ\nÂÖ∑‰ΩìÂÅöÊ≥ïÂ∞±ÊòØÊääone-hotÂêëÈáèe_iÂíåÂèÇÊï∞Áü©ÈòµpÁõ∏‰πòÔºõÁü©ÈòµPËΩ¨ÁΩÆÁöÑÂ§ßÂ∞èÊòØd x vÔºõdÊòØËØçÂêëÈáèÁöÑÁª¥Â∫¶ÔºõvÊòØÂ≠óÂÖ∏ÈáåËØçÊ±áÁöÑÊï∞ÈáèÔºõÁªìÊûú‰∏∫x_iÔºõx_iÂ∞±ÊòØ‰∏Ä‰∏™ËØçÂêëÈáèÔºõÂ¶ÇÊûúone-hotÂêëÈáèÁöÑÁ¨¨‰∏âË°å‰∏∫1ÔºõÈÇ£‰πàx_iÂ∞±ÊòØPËΩ¨ÁΩÆÁü©ÈòµÁöÑÁ¨¨‰∏âÂàóÔºàÂÖ∂‰ΩôÂàóÈÉΩ‰∏∫0ÔºâÔºõÊâÄ‰ª•PËΩ¨ÁΩÆÊØè‰∏ÄÂàóÈÉΩÊòØ‰∏Ä‰∏™ËØçÂêëÈáèÔºõÊâÄ‰ª•Áü©ÈòµPÊú¨Ë∫´ÁöÑÊØè‰∏ÄË°åÂ∞±ÊòØ‰∏Ä‰∏™ËØçÂêëÈáèÔºõÂÖ∂Ë°åÊï∞‰∏∫vÔºõÂç≥vocabularyÔºåËØçÊ±áÈáèÔºõÊØè‰∏ÄË°åÂØπÂ∫î‰∏Ä‰∏™ÂçïËØçÔºõÁü©ÈòµÁöÑÂàóÊï∞‰∏∫dÔºõdÊòØÁî®Êà∑ÂÜ≥ÂÆöÁöÑÔºõdÁöÑÂ§ßÂ∞è‰ºöÂÜ≥ÂÆöÊú∫Âô®Â≠¶‰π†Ê®°ÂûãÁöÑË°®Áé∞ÔºõÂ∫îËØ•Áî®xxxÊù•ÈÄâÊã©‰∏Ä‰∏™ÊØîËæÉÂ•ΩÁöÑdÔºõ\nÊàë‰ª¨ÁöÑ‰ªªÂä°ÊòØÁúãËØÑËÆ∫ÊòØÊ≠£Èù¢ÁöÑËøòÊòØË¥üÈù¢ÁöÑÔºõÂèÇÊï∞Áü©ÈòµÊòØ‰ªéËÆ≠ÁªÉÊï∞ÊçÆ‰∏≠Â≠¶‰π†Âá∫Êù•ÁöÑÔºåÊâÄ‰ª•Â≠¶Âá∫Êù•ÁöÑËØçÂêëÈáèÊòØÂ∏¶ÊúâÊÑüÊÉÖËâ≤ÂΩ©ÁöÑÔºõÂÅáËÆæËøô‰∫õËØçÂêëÈáèÈÉΩÊòØ‰∫åÁª¥ÁöÑÔºåÂàôÂèØ‰ª•Âú®Âπ≥Èù¢ÂùêÊ†áÁ≥ª‰∏≠Ê†áÂá∫‰∏ãÈù¢ËØçÂêëÈáè\nkerasÊèê‰æõembeddingÂ±ÇÔºõÁî®Êà∑ÂèØ‰ª•ÊåáÂÆövocabularyÂ§ßÂ∞èÂíådÁöÑÂ§ßÂ∞èÔºõ‰ª•ÂèäÊØè‰∏Ä‰∏™sequenceÁöÑÈïøÂ∫¶ÔºõdÊòØÊ†πÊçÆÁÆóÊ≥ïÈÄâÂá∫Êù•ÁöÑ Âà∞Ëøô‰∏ÄÊ≠•ÔºåÊàë‰ª¨Â∑≤ÁªèÂÆåÊàê‰∫ÜÊñáÊú¨Â§ÑÁêÜÂíåword embedding„ÄÇÊé•‰∏ãÊù•Â∞±ÊòØÁî®Logistic Regression for Binary ClassificationÂÅö‰∫åÂàÜÁ±ªÔºõ\n","permalink":"http://localhost:1313/posts/nlp-2/","summary":"\u003ch3 id=\"text-to-sequence\"\u003eText to Sequence\u003c/h3\u003e\n\u003cp\u003eÊñáÊú¨Â§ÑÁêÜ\u003c/p\u003e\n\u003cp\u003eStep1: Tokenization\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\n\u003cp\u003eTokenization breaks a piece of text down into a list of tokens.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003eHere, a token is a word. (A token can be a character in some applications.)\u003c/p\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003eTokenizationËÆ≤Á©∂ÂæàÂ§öÔºå‰æãÂ¶ÇÊòØÂê¶Â∫îËØ•ÊääÂ§ßÂÜôÊîπÊàêÂ∞èÂÜôÂë¢ÔºüËøõË°åtypo correctionÁ≠âÁ≠â\u003c/p\u003e\n\u003cp\u003e\u003cimg alt=\"image-20250322150322238\" loading=\"lazy\" src=\"./NLP-2.assets/image-20250322150322238.png\"\u003e\u003c/p\u003e\n\u003cp\u003eStep2: Build Dictionary\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\n\u003cp\u003eUse a dictionary (hash table) to count word frequencies.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003eThe dictionary maps word to index.\u003c/p\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003eÂèØ‰ª•È¶ñÂÖàÁªüËÆ°ËØçÈ¢ëÂéªÊéâ‰ΩéÈ¢ëËØçÔºåÁÑ∂ÂêéËÆ©ÊØè‰∏™ËØçÂØπÂ∫î‰∏Ä‰∏™Ê≠£Êï¥Êï∞ÔºõËøôÊ†∑ÁöÑËØùÔºå‰∏ÄÂè•ËØùÂ∞±ÂèØ‰ª•Áî®‰∏Ä‰∏™Ê≠£Êï¥Êï∞ÂàóË°®Ë°®Á§∫ÔºåËøô‰∏™ÂàóË°®Â∞±Âè´sequenceÔºõÂ¶ÇÊûúÂøÖË¶ÅÂ∞±ËøòÂæóÂÅöone-hot encoding„ÄÇ\u003cimg alt=\"image-20250322150620890\" loading=\"lazy\" src=\"./NLP-2.assets/image-20250322150620890.png\"\u003e\u003c/p\u003e\n\u003cp\u003eÁªìÊûú\u003c/p\u003e\n\u003cp\u003e\u003cimg alt=\"image-20250322150754528\" loading=\"lazy\" src=\"./NLP-2.assets/image-20250322150754528.png\"\u003e\u003c/p\u003e\n\u003cp\u003e‰ΩÜÊòØÈïøÂ∫¶‰∏çÁªü‰∏Ä\u003c/p\u003e\n\u003cp\u003eStep4: ÂØπÈΩêsequence\u003c/p\u003e\n\u003cp\u003e\u003cimg alt=\"image-20250322150854986\" loading=\"lazy\" src=\"./NLP-2.assets/image-20250322150854986.png\"\u003e\u003c/p\u003e\n\u003cp\u003eËß£ÂÜ≥ÊñπÊ°àÊòØËøôÊ†∑ÁöÑÔºöÂèØ‰ª•Âõ∫ÂÆöÈïøÂ∫¶‰∏∫wÔºåÂä†ÂÖ•‰∏Ä‰∏™Â∫èÂàóÈïøÂ∫¶Â§™ÈïøÔºåÂ∞±Á†çÊéâÂâçÈù¢ÁöÑËØçÔºåÂè™‰øùÁïôÊúÄÂêéw‰∏™ËØçÔºõÂ¶ÇÊûú‰∏Ä‰∏™Â∫èÂàóÂ§™Áü≠ÔºåÂ∞±ÂÅözero paddingÔºåÁî®0Â°´ÂÖÖ\u003c/p\u003e\n\u003cp\u003e\u003cimg alt=\"image-20250322151030119\" loading=\"lazy\" src=\"./NLP-2.assets/image-20250322151030119.png\"\u003e\u003c/p\u003e\n\u003cp\u003eËøôÊ†∑‰∏ÄÊù•ÔºåÊâÄÊúâÁöÑÂ∫èÂàóÈïøÂ∫¶Â∞±Áªü‰∏Ä‰∫Ü\u003c/p\u003e\n\u003cp\u003e\u003cimg alt=\"image-20250322151117125\" loading=\"lazy\" src=\"./NLP-2.assets/image-20250322151117125.png\"\u003e\u003c/p\u003e\n\u003cp\u003eÊñáÊú¨Â§ÑÁêÜÂÆåÊàê‰∫ÜÔºåÊé•‰∏ãÊù•ÊòØword embeddingÔºåÊääÂçïËØçË°®Á§∫‰∏∫‰∏Ä‰∏™‰ΩéÁª¥ÂêëÈáèÔºõ\u003c/p\u003e\n\u003cp\u003e\u003cimg alt=\"image-20250322151252837\" loading=\"lazy\" src=\"./NLP-2.assets/image-20250322151252837.png\"\u003e\u003c/p\u003e","title":""},{"content":"üëã About me Hello! I\u0026rsquo;m Xu Zongsi, a passionate technology enthusiast currently pursuing my Master of Science in ECIC at The University of Hong Kong. With a solid background in Software Engineering from the Beijing Institute of Technology, I specialize in artificial intelligence areas like machine learning, deep learning, natural language processing, computer vision, and reinforcement learning.\nInspired by OpenAI\u0026rsquo;s five-step plan towards superintelligence, I am excited about AGI and have developed a keen interest in LLM agents, MLLM, and knowledge graphs. I see great potential in these fields and aspire to contribute to innovative solutions.\nüìö Education üá≠üá∞ The University of Hong Kong 09/2024 - Expected 11/2025 School of Computing and Data Science Master of Science in Electronic Commerce \u0026amp; Internet Computing Relevant Courses: Machine learning for business and e-commerce, Knowledge graphs, Financial fraud analytics, Internet infrastructure technologies, Website engineering, Blockchain and cryptocurrency, etc. üá®üá≥ Beijing Institute of Technology 09/2020 - 06/2024 School of Computer Science \u0026amp; Technology Bachelor of Engineering in Software Engineering, last two years GPA: 3.7/4 Relevant Courses: Reinforcement Learning, Deep Learning and Computer Vision, Artificial Intelligence and Robot Ethics, Almost Human: Mind, Brain and Artificial Intelligence, Mathematical Analysis for Engineering, Linear Algebra, Probability and Mathematical Statistics, etc. Skills: Python, Java, common data structures, design patterns, machine learning basics and algorithms, Linux, PyTorch, and some development tools (git, conda, etc.). üèÜ Awards \u0026amp; Honors Beijing Institute of Technology Undergraduate Scholarship (Top 20% of Grade) 06/2023 3rd Prize of China International \u0026#34;Internet \u0026#43;\u0026#34; College Student\u0026#39;s Innovation Competition 08/2022 Bronze Prize of \u0026#34;Challenge Cup\u0026#34; Capital University Entrepreneurship Competition 05/2022 üíº Project Experience üîç Online Transaction Fraud Detection 09/2024 ‚Äì 01/2025 Independent project, supervised by Dr. Vivien Chan Focused on addressing financial fraud in e-commerce to enhance the accuracy of transaction anomaly detection, while independently managing the entire case study that included data preprocessing, feature engineering, model building, evaluation, and results analysis. Effectively resolved class imbalance issues using SMOTE and ROSE techniques. Built various models including Logistic Regression, Random Forest, XGBoost, and LightGBM, ultimately selecting the LightGBM model to achieve a recall rate of 95.45% and an AUC of 99.84%. Wrote efficient and maintainable code, enhancing model training and data processing efficiency through parallel computing and logging. ü§ñ Multi-Model Intelligent Text Keyword Extraction System 08/2023 ‚Äì 09/2023 Group project, supervised by Associate Prof. Xiaolin Zhao Designed and implemented an intelligent text summary system that automatically extracts keywords from article titles and abstracts, enhancing the understanding and summarization of text information. Participated in the planning of the technical route and built a hybrid model combining extractive and generative approaches, utilizing advanced natural language processing techniques including KeyBERT, Sentence Transformer, BERT, and T5 models. Responsible for data preprocessing and tokenization, as well as the end-to-end implementation and training of the T5 model, optimizing the model architecture and hyperparameters, achieving satisfactory results after only 3 epochs of training. Model evaluation results showed that the Rouge-1, Rouge-2, and Rouge-L metrics reached 0.6345, 0.5038, and 0.5282, respectively, in the third epoch, validating the model\u0026rsquo;s effectiveness in the summarization task. üéì Cambridge University Machine Learning Summer Project 07/2023 ‚Äì 08/2023 Group project, supervised by Prof. Pietro Li√≤ Participated in the Cambridge University deep learning summer project, focusing on deep reinforcement learning; explored multi-agent learning algorithms across different environments. Reproduced the Multi-Agent Deep Deterministic Policy Gradient (MADDPG) algorithm in the Simple Adversary environment and studied the effect of agent numbers on convergence speed and stability, finding optimal stability at 21 agents. Designed and implemented comparative experiments inspired by the Rainbow algorithm, assessing target network strategies versus the Double Deep Q-Network (Double DQN). The results demonstrated that Double DQN significantly enhanced convergence speed, optimizing the overall learning process. Co-authored a group project paper on agent numbers and strategies effectiveness in multi-agent systems, achieving a score of 71% in the summer program (the highest in my group) and a \u0026ldquo;First Class\u0026rdquo; classification in the UK grading system. üëÅÔ∏è Deep Learning and Computer Vision Semester Project 09/2022 ‚Äì 12/2022 Independent project, supervised by Associate Prof. Guangyu Gao Designed and implemented a waste classifier using the ResNet model to improve classification accuracy and reduce resource waste. The project also enhanced understanding of transfer learning techniques with ResNet. Collected a dataset of 16 waste categories and preprocessed the images for uniformity and standardization, incorporating data augmentation techniques to enhance the dataset. Conducted experiments using ResNet34 and ResNet50 models through transfer learning, accelerating network convergence by leveraging pretrained weights. During training, techniques such as Batch Normalization and Dropout were applied to mitigate the risk of overfitting. The final model achieved an accuracy of 90% on the training set, while the performance on the test set was 61%, indicating a significant overfitting phenomenon during the training process. üéì Internship ‚öõÔ∏è Beijing Academy of Quantum Information Science 08/2023 ‚Äì 01/2024 Research Intern at Quantum Computation Department Proposed a quantum convolution kernel design based on variational quantum circuits and developed a universal quantum convolution layer, successfully integrating it into classical CNN architectures such as VGG, GoogLeNet, and ResNet. Developed and evaluated various hybrid models, including a simple model named HQCCNN-2, which achieved 84.45% accuracy on the FashionMNIST dataset, surpassing the traditional CNN\u0026rsquo;s 80.72%. This demonstrates the effectiveness of the quantum convolution layer in improving model performance. Tested on a real quantum computer further validated the effectiveness of the hybrid model, demonstrating the viable integration of quantum computing with deep learning, and highlighting the potential for leveraging quantum properties to enhance model performance. üèÖ Competition Experience ü•â China International \u0026#34;Internet \u0026#43;\u0026#34; College Students\u0026#39; Innovation Competition 08/2022 üõ°Ô∏è Zhongke Ushield: Deep Learning-based Face Privacy Protection Authentication System Responsible for constructing a localized facial feature extraction engine based on MobileFaceNet, ensuring feature extraction is completed on end devices (such as mobile phones and cameras), guaranteeing that raw data does not leave the domain and is not stored, thus enhancing user privacy protection while improving recognition efficiency. ü•â \u0026#34;Challenge Cup\u0026#34; Capital University Entrepreneurship Competition 05/2022 üå≥ Smart Orchard Responsible for the development of the fruit detection, ripeness prediction, and pest identification system, using deep convolutional neural network (CNN) technology for intelligent monitoring of crop growth conditions. Applied advanced object detection algorithms such as Faster R-CNN and YOLO to achieve high precision in apple detection and ripeness assessment, with an accuracy rate exceeding 90%, significantly enhancing the intelligence level of orchard management. Built and trained a dedicated dataset containing various pest samples, optimizing pest detection accuracy through data preprocessing (such as image normalization and resizing) and data augmentation techniques (like rotation, flipping, and noise addition), enabling the real-time monitoring system to accurately identify over 80% of pests, providing effective scientific maintenance recommendations to help farmers reduce crop losses. üìã Extracurricular Activities Vice President, Cyber Security Club, Beijing Institute of Technology 09/2021-09/2022 Backbone, Media Center of the Student Union of Beijing Institute of Technology 10/2020-06/2021 üì´ Contact üìß Email: zongsi.xu@outlook.com üëî LinkedIn: Zongsi (Tristan) Xu üíª GitHub: github.com/BaizeXS üìç Location: Hong Kong SAR, China ","permalink":"http://localhost:1313/resume/","summary":"Personal resume of Zongsi (Tristan) Xu","title":"Zongsi (Tristan) Xu"},{"content":"‰∏Ä„ÄÅÊï∞ÂÄºÁâπÂæÅ‰∏éÁ±ªÂà´ÁâπÂæÅ Êï∞ÂÄºÁâπÂæÅ (Numeric Features) ÂÖ∑ÊúâÂèØÂä†ÂáèÁöÑÊÑè‰πâÔºå‰∏îÂ≠òÂú®Â§ßÂ∞èÈ°∫Â∫è„ÄÇ ‰æãÂ≠êÔºöÂπ¥ÈæÑ„ÄÅÊ∏©Â∫¶Á≠â„ÄÇÂèØ‰ª•Áõ¥Êé•‰øùÁïôÂÖ∂Êï¥Êï∞ÊàñÊµÆÁÇπÊï∞ÂΩ¢Âºè‰æõÊ®°Âûã‰ΩøÁî®„ÄÇ Á±ªÂà´ÁâπÂæÅ (Categorical Features) Êï∞ÊçÆÂÄºÁ¶ªÊï£Ôºå‰∏çÂÖ∑Â§á‚ÄúÊï∞ÂÄºÂ§ßÂ∞è‚ÄùÈó¥ÁöÑÂèØÊØîÊÑè‰πâ„ÄÇ ‰æãÂ≠êÔºöÂõΩÁ±çÔºàÁæéÂõΩ/‰∏≠ÂõΩ/Âç∞Â∫¶Á≠âÔºâ„ÄÅÊÄßÂà´ÔºàÁî∑/Â•≥ÔºâÁ≠â„ÄÇ ÈóÆÈ¢òÔºöËã•‰ªÖÁî®Êï¥Êï∞Ë°®Á§∫ÔºàÁæéÂõΩ=1, ‰∏≠ÂõΩ=2ÔºâÔºå‰ºöÂºïÂÖ•ÈîôËØØÁöÑÊï∞ÂÄºËøêÁÆóÂÖ≥Á≥ªÔºåÂ¶Ç ‚ÄúÁæéÂõΩ + ‰∏≠ÂõΩ = Âç∞Â∫¶‚Äù„ÄÇ ‰∫å„ÄÅOne-HotÁºñÁ†ÅÁöÑÂä®Êú∫‰∏éÊµÅÁ®ã ‰∏∫‰ªÄ‰πà‰ΩøÁî®One-Hot\nÈÄöËøáÂ∞ÜÁ±ªÂà´Êò†Â∞Ñ‰∏∫ÂêëÈáèÔºåÈÅøÂÖçÊï¥Êï∞ÁºñÁ†ÅÂºïÂÖ•ÁöÑ‰º™Êï∞ÂÄºÂÖ≥Á≥ª„ÄÇ ÂêåÊó∂‰øùÁïôÂêÑÁßçÂèØËÉΩÁ±ªÂà´ÁöÑ‰ø°ÊÅØÔºå‰∏î‰ªÖÂú®ÂØπÂ∫î‰ΩçÁΩÆ‰∏∫1ÔºåÂÖ∂‰ªñ‰ΩçÁΩÆ‰∏∫0„ÄÇ Âª∫Á´ãÊò†Â∞ÑÔºö‰ªéÁ±ªÂà´Âà∞Á¥¢Âºï\n‰∏∫ÊØè‰∏™Á±ªÂà´ÂàÜÈÖç‰∏Ä‰∏™ÂîØ‰∏ÄÁ¥¢ÂºïÔºåÈÄöÂ∏∏‰ªé1ÂºÄÂßã„ÄÇ È¢ÑÁïôÁ¥¢Âºï0Ë°®Á§∫‚ÄúÊú™Áü•‚ÄùÊàñ‚ÄúÁº∫Â§±‚ÄùÔºåÂØπÂ∫îÂÖ®0ÂêëÈáè„ÄÇ ËΩ¨Êç¢‰∏∫One-HotÂêëÈáè\nËã•Á±ªÂà´ÊÄªÊï∞‰∏∫197ÔºåÂàôÁî®197Áª¥ÂêëÈáèË°®Á§∫„ÄÇ ‰æãÂ≠êÔºöÁæéÂõΩ [1, 0, 0, 0, ‚Ä¶]Ôºå ‰∏≠ÂõΩ [0, 1, 0, 0, ‚Ä¶]„ÄÇ Á§∫‰æãÔºöË°®Á§∫‰∏Ä‰∏™‰∫∫ÁöÑÁâπÂæÅ\nÁâπÂæÅÂåÖÂê´ÔºàÂπ¥ÈæÑ, ÊÄßÂà´, ÂõΩÁ±çÔºåÂÖ∂‰∏≠ÂõΩÁ±ç197ÁßçÔºâ Áª¥Â∫¶ÊÄªÂíåÔºö1Áª¥_age + 1Áª¥_gender + 197Áª¥_nationality = 199Áª¥„ÄÇ ‰æãÂ¶Ç (28, Â•≥, ‰∏≠ÂõΩ) ‚Üí [28, 0, 0, 1, 0, ‚Ä¶, 0]„ÄÇ ‰∏â„ÄÅÊñáÊú¨Êï∞ÊçÆÂ§ÑÁêÜÊµÅÁ®ã ÊñáÊú¨Âú®Ëá™ÁÑ∂ËØ≠Ë®ÄÂ§ÑÁêÜÔºàNLPÔºâ‰∏≠‰Ωú‰∏∫Â∏∏ËßÅÁöÑÂéüÂßãËæìÂÖ•ÔºåÈúÄË¶ÅÊï∞ÂÄºÂåñÊâçËÉΩÈÄÅÂÖ•Ê®°Âûã„ÄÇ‰∏ÄËà¨Ê≠•È™§Â¶Ç‰∏ãÔºö\nÂàÜËØç (Tokenization)\nÂ∞ÜÊñáÊú¨ÊãÜÂàÜ‰∏∫‰∏Ä‰∏™‰∏™ÂçïËØçÔºàTokenÔºâ„ÄÇ ‰æãÂ≠êÔºö\u0026quot;... to be or not to be...\u0026quot; ‚Üí [\u0026quot;...\u0026quot;, \u0026quot;to\u0026quot;, \u0026quot;be\u0026quot;, \u0026quot;or\u0026quot;, \u0026quot;not\u0026quot;, \u0026quot;to\u0026quot;, \u0026quot;be\u0026quot;, \u0026quot;...\u0026quot;]„ÄÇ ÁªüËÆ°ËØçÈ¢ë \u0026amp; ÊûÑÂª∫ËØçÂÖ∏\nËØçÈ¢ëÁªüËÆ° Áî®ÂìàÂ∏åË°®/Â≠óÂÖ∏ËÆ∞ÂΩïÊØè‰∏™ÂçïËØçÂá∫Áé∞Ê¨°Êï∞„ÄÇ ÈÅçÂéÜÊñáÊú¨Êó∂ÔºåËã•ÂçïËØçÂ∞öÊú™ÂÖ•Ë°®ÔºåÂàôÊñ∞Âª∫ËÆ∞ÂΩïÔºõËã•Â∑≤Â≠òÂú®ÔºåÂàôËÆ°Êï∞+1„ÄÇ ÊéíÂ∫è‰∏éÁ¥¢Âºï ÊåâËØçÈ¢ëÈôçÂ∫èÊéíÂ∫èÔºåËØçÈ¢ëÊúÄÈ´òÁöÑÂçïËØçÊéíÂú®ÂâçÈù¢„ÄÇ Á¥¢Âºï‰ªé1ÂºÄÂßãÔºå0ÁïôÁªô‚ÄúÊú™Áü•‚Äù„ÄÇ ËØçÂÖ∏ËßÑÊ®°ÔºàvocabularyÔºâÂèØËßÜÈúÄÊ±ÇÊà™Êñ≠Ôºà‰æãÂ¶ÇÂè™‰øùÁïôTop 10kÔºâ„ÄÇ ‰∏∫‰ªÄ‰πàÁßªÈô§‰ΩéÈ¢ëËØç ‰ΩéÈ¢ëËØçÂèØËÉΩÊòØÊãºÂÜôÈîôËØØ„ÄÅÁΩïËßÅ‰∫∫ÂêçÁ≠âÔºåÂØπÊ®°ÂûãÂ∏ÆÂä©ÊúâÈôê„ÄÇ ÂáèÂ∞ëËØçÂÖ∏ËßÑÊ®°ÂèØÈôç‰ΩéËøêÁÆóÂºÄÈîÄ„ÄÅÂä†Âø´Ê®°ÂûãËÆ≠ÁªÉ‰∏éÊé®ÁêÜÈÄüÂ∫¶„ÄÇ Áã¨ÁÉ≠ÁºñÁ†Å (One-Hot Encoding)\nÂ∞ÜÊØè‰∏™ÂçïËØçÊò†Â∞Ñ‰∏∫ËØçÂÖ∏‰∏≠ÁöÑÁ¥¢ÂºïÂêéÔºàÂ¶Ç [2, 4, 1, 8, ‚Ä¶]ÔºâÔºåÂèØËøõ‰∏ÄÊ≠•ËΩ¨Êç¢ÊàêOne-HotÂêëÈáè„ÄÇ One-HotÁª¥Â∫¶ÂèñÂÜ≥‰∫é‰øùÁïô‰∏ãÊù•ÁöÑËØçÂÖ∏Â§ßÂ∞èÔºà‰æãÂ¶Ç1‰∏áÔºâ„ÄÇ Êú™Êî∂ÂΩïÂçïËØçÂèØËÉΩÁõ¥Êé•ÂøΩÁï•ÔºåÊàñÁªü‰∏ÄÁî®Á¥¢Âºï0‰ª£Êõø„ÄÇ Âõõ„ÄÅÊ†∏ÂøÉÊî∂Ëé∑‰∏éÂ∫îÁî® Á±ªÂà´ÁâπÂæÅÂøÖÈúÄÊï∞ÂÄºÂåñÔºö\n‰ΩøÁî®Êï¥Êï∞1,2,3‚Ä¶‰ªÖË°®Á§∫Á±ªÂà´‚ÄúÊ†áËØÜ‚ÄùÔºåÂπ∂‰∏ç‰ª£Ë°®ÂÆÉ‰ª¨ÂèØËøõË°åÊï∞ÂÄºËøêÁÆó„ÄÇ Âõ†Ê≠§ÈúÄË¶ÅOne-HotÁ≠âÁºñÁ†ÅÊñπÂºèÔºåÈÅøÂÖçÊï∞ÂÄºËØØËß£„ÄÇ ÊñáÊú¨Êï∞ÊçÆÈ¢ÑÂ§ÑÁêÜÔºö\nÂàÜËØç„ÄÅËØçÈ¢ëÁªüËÆ°„ÄÅÊûÑÂª∫ËØçÂÖ∏„ÄÅÁ¥¢ÂºïÂåñ„ÄÅOne-HotÊàñÂÖ∂‰ªñÊñπÂºèÔºàÂ¶ÇËØçÂµåÂÖ•ÔºâÊòØÂ∏∏ËßÅÊµÅÁ®ã„ÄÇ Ê≠£Á°ÆÁöÑÊñáÊú¨È¢ÑÂ§ÑÁêÜÂèØÊòæËëóÂΩ±ÂìçÊ®°ÂûãÊÄßËÉΩÂíåÊïàÁéá„ÄÇ ‰øùÁïôÊú™Áü•Á¥¢ÂºïÔºö\n‰øùËØÅÂØπÁº∫Â§±Êï∞ÊçÆÊàñÂ≠óÂÖ∏Â§ñÊñ∞ËØçËÉΩÊúâÂü∫Êú¨ÁöÑË°®Á§∫ÔºåÊèêÂçáÊ®°ÂûãÂÆπÈîôÊÄß„ÄÇ ÂÆûÈôÖ‰ΩøÁî®Ôºö\nÂØπ‰∫éÂ∞èËßÑÊ®°Á±ªÂà´ÂèØÁõ¥Êé•One-HotÁºñÁ†ÅÔºõÂØπ‰∫éËØçÂÖ∏ÂæàÂ§ßÁöÑÂú∫ÊôØÔºåÈÄöÂ∏∏‰ºöËøõ‰∏ÄÊ≠•ËÄÉËôëËØçÂµåÂÖ•ÔºàWord EmbeddingÔºâÊàñÈ¢ÑËÆ≠ÁªÉËØ≠Ë®ÄÊ®°Âûã„ÄÇ ","permalink":"http://localhost:1313/posts/nlp-1/","summary":"\u003ch2 id=\"‰∏ÄÊï∞ÂÄºÁâπÂæÅ‰∏éÁ±ªÂà´ÁâπÂæÅ\"\u003e‰∏Ä„ÄÅÊï∞ÂÄºÁâπÂæÅ‰∏éÁ±ªÂà´ÁâπÂæÅ\u003c/h2\u003e\n\u003col\u003e\n\u003cli\u003e\u003cstrong\u003eÊï∞ÂÄºÁâπÂæÅ (Numeric Features)\u003c/strong\u003e\n\u003cul\u003e\n\u003cli\u003eÂÖ∑ÊúâÂèØÂä†ÂáèÁöÑÊÑè‰πâÔºå‰∏îÂ≠òÂú®Â§ßÂ∞èÈ°∫Â∫è„ÄÇ\u003c/li\u003e\n\u003cli\u003e‰æãÂ≠êÔºöÂπ¥ÈæÑ„ÄÅÊ∏©Â∫¶Á≠â„ÄÇÂèØ‰ª•Áõ¥Êé•‰øùÁïôÂÖ∂Êï¥Êï∞ÊàñÊµÆÁÇπÊï∞ÂΩ¢Âºè‰æõÊ®°Âûã‰ΩøÁî®„ÄÇ\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003eÁ±ªÂà´ÁâπÂæÅ (Categorical Features)\u003c/strong\u003e\n\u003cul\u003e\n\u003cli\u003eÊï∞ÊçÆÂÄºÁ¶ªÊï£Ôºå‰∏çÂÖ∑Â§á‚ÄúÊï∞ÂÄºÂ§ßÂ∞è‚ÄùÈó¥ÁöÑÂèØÊØîÊÑè‰πâ„ÄÇ\u003c/li\u003e\n\u003cli\u003e‰æãÂ≠êÔºöÂõΩÁ±çÔºàÁæéÂõΩ/‰∏≠ÂõΩ/Âç∞Â∫¶Á≠âÔºâ„ÄÅÊÄßÂà´ÔºàÁî∑/Â•≥ÔºâÁ≠â„ÄÇ\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003eÈóÆÈ¢ò\u003c/strong\u003eÔºöËã•‰ªÖÁî®Êï¥Êï∞Ë°®Á§∫ÔºàÁæéÂõΩ=1, ‰∏≠ÂõΩ=2ÔºâÔºå‰ºöÂºïÂÖ•ÈîôËØØÁöÑÊï∞ÂÄºËøêÁÆóÂÖ≥Á≥ªÔºåÂ¶Ç ‚ÄúÁæéÂõΩ + ‰∏≠ÂõΩ = Âç∞Â∫¶‚Äù„ÄÇ\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003c/ol\u003e\n\u003ch2 id=\"‰∫åone-hotÁºñÁ†ÅÁöÑÂä®Êú∫‰∏éÊµÅÁ®ã\"\u003e‰∫å„ÄÅOne-HotÁºñÁ†ÅÁöÑÂä®Êú∫‰∏éÊµÅÁ®ã\u003c/h2\u003e\n\u003col\u003e\n\u003cli\u003e\n\u003cp\u003e\u003cstrong\u003e‰∏∫‰ªÄ‰πà‰ΩøÁî®One-Hot\u003c/strong\u003e\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eÈÄöËøáÂ∞ÜÁ±ªÂà´Êò†Â∞Ñ‰∏∫ÂêëÈáèÔºåÈÅøÂÖçÊï¥Êï∞ÁºñÁ†ÅÂºïÂÖ•ÁöÑ‰º™Êï∞ÂÄºÂÖ≥Á≥ª„ÄÇ\u003c/li\u003e\n\u003cli\u003eÂêåÊó∂‰øùÁïôÂêÑÁßçÂèØËÉΩÁ±ªÂà´ÁöÑ‰ø°ÊÅØÔºå‰∏î‰ªÖÂú®ÂØπÂ∫î‰ΩçÁΩÆ‰∏∫1ÔºåÂÖ∂‰ªñ‰ΩçÁΩÆ‰∏∫0„ÄÇ\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003e\u003cstrong\u003eÂª∫Á´ãÊò†Â∞ÑÔºö‰ªéÁ±ªÂà´Âà∞Á¥¢Âºï\u003c/strong\u003e\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e‰∏∫ÊØè‰∏™Á±ªÂà´ÂàÜÈÖç‰∏Ä‰∏™ÂîØ‰∏ÄÁ¥¢ÂºïÔºåÈÄöÂ∏∏‰ªé1ÂºÄÂßã„ÄÇ\u003c/li\u003e\n\u003cli\u003eÈ¢ÑÁïôÁ¥¢Âºï0Ë°®Á§∫‚ÄúÊú™Áü•‚ÄùÊàñ‚ÄúÁº∫Â§±‚ÄùÔºåÂØπÂ∫îÂÖ®0ÂêëÈáè„ÄÇ\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003e\u003cstrong\u003eËΩ¨Êç¢‰∏∫One-HotÂêëÈáè\u003c/strong\u003e\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eËã•Á±ªÂà´ÊÄªÊï∞‰∏∫197ÔºåÂàôÁî®197Áª¥ÂêëÈáèË°®Á§∫„ÄÇ\u003c/li\u003e\n\u003cli\u003e‰æãÂ≠êÔºöÁæéÂõΩ \u003ccode\u003e[1, 0, 0, 0, ‚Ä¶]\u003c/code\u003eÔºå ‰∏≠ÂõΩ \u003ccode\u003e[0, 1, 0, 0, ‚Ä¶]\u003c/code\u003e„ÄÇ\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003e\u003cstrong\u003eÁ§∫‰æãÔºöË°®Á§∫‰∏Ä‰∏™‰∫∫ÁöÑÁâπÂæÅ\u003c/strong\u003e\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eÁâπÂæÅÂåÖÂê´ÔºàÂπ¥ÈæÑ, ÊÄßÂà´, ÂõΩÁ±çÔºåÂÖ∂‰∏≠ÂõΩÁ±ç197ÁßçÔºâ\u003c/li\u003e\n\u003cli\u003eÁª¥Â∫¶ÊÄªÂíåÔºö1Áª¥_age + 1Áª¥_gender + 197Áª¥_nationality = 199Áª¥„ÄÇ\u003c/li\u003e\n\u003cli\u003e‰æãÂ¶Ç \u003ccode\u003e(28, Â•≥, ‰∏≠ÂõΩ)\u003c/code\u003e ‚Üí \u003ccode\u003e[28, 0, 0, 1, 0, ‚Ä¶, 0]\u003c/code\u003e„ÄÇ\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003c/ol\u003e\n\u003ch2 id=\"‰∏âÊñáÊú¨Êï∞ÊçÆÂ§ÑÁêÜÊµÅÁ®ã\"\u003e‰∏â„ÄÅÊñáÊú¨Êï∞ÊçÆÂ§ÑÁêÜÊµÅÁ®ã\u003c/h2\u003e\n\u003cp\u003eÊñáÊú¨Âú®Ëá™ÁÑ∂ËØ≠Ë®ÄÂ§ÑÁêÜÔºàNLPÔºâ‰∏≠‰Ωú‰∏∫Â∏∏ËßÅÁöÑÂéüÂßãËæìÂÖ•ÔºåÈúÄË¶ÅÊï∞ÂÄºÂåñÊâçËÉΩÈÄÅÂÖ•Ê®°Âûã„ÄÇ‰∏ÄËà¨Ê≠•È™§Â¶Ç‰∏ãÔºö\u003c/p\u003e\n\u003col\u003e\n\u003cli\u003e\n\u003cp\u003e\u003cstrong\u003eÂàÜËØç (Tokenization)\u003c/strong\u003e\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eÂ∞ÜÊñáÊú¨ÊãÜÂàÜ‰∏∫‰∏Ä‰∏™‰∏™ÂçïËØçÔºàTokenÔºâ„ÄÇ\u003c/li\u003e\n\u003cli\u003e‰æãÂ≠êÔºö\u003ccode\u003e\u0026quot;... to be or not to be...\u0026quot;\u003c/code\u003e ‚Üí \u003ccode\u003e[\u0026quot;...\u0026quot;, \u0026quot;to\u0026quot;, \u0026quot;be\u0026quot;, \u0026quot;or\u0026quot;, \u0026quot;not\u0026quot;, \u0026quot;to\u0026quot;, \u0026quot;be\u0026quot;, \u0026quot;...\u0026quot;]\u003c/code\u003e„ÄÇ\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003e\u003cstrong\u003eÁªüËÆ°ËØçÈ¢ë \u0026amp; ÊûÑÂª∫ËØçÂÖ∏\u003c/strong\u003e\u003c/p\u003e","title":""},{"content":"Text to Sequence ÊñáÊú¨Â§ÑÁêÜ\nStep1: Tokenization\nTokenization breaks a piece of text down into a list of tokens.\nHere, a token is a word. (A token can be a character in some applications.)\nTokenizationËÆ≤Á©∂ÂæàÂ§öÔºå‰æãÂ¶ÇÊòØÂê¶Â∫îËØ•ÊääÂ§ßÂÜôÊîπÊàêÂ∞èÂÜôÂë¢ÔºüËøõË°åtypo correctionÁ≠âÁ≠â\nStep2: Build Dictionary\nUse a dictionary (hash table) to count word frequencies.\nThe dictionary maps word to index.\nÂèØ‰ª•È¶ñÂÖàÁªüËÆ°ËØçÈ¢ëÂéªÊéâ‰ΩéÈ¢ëËØçÔºåÁÑ∂ÂêéËÆ©ÊØè‰∏™ËØçÂØπÂ∫î‰∏Ä‰∏™Ê≠£Êï¥Êï∞ÔºõËøôÊ†∑ÁöÑËØùÔºå‰∏ÄÂè•ËØùÂ∞±ÂèØ‰ª•Áî®‰∏Ä‰∏™Ê≠£Êï¥Êï∞ÂàóË°®Ë°®Á§∫ÔºåËøô‰∏™ÂàóË°®Â∞±Âè´sequenceÔºõÂ¶ÇÊûúÂøÖË¶ÅÂ∞±ËøòÂæóÂÅöone-hot encoding„ÄÇ\nÁªìÊûú\n‰ΩÜÊòØÈïøÂ∫¶‰∏çÁªü‰∏Ä\nStep4: ÂØπÈΩêsequence\nËß£ÂÜ≥ÊñπÊ°àÊòØËøôÊ†∑ÁöÑÔºöÂèØ‰ª•Âõ∫ÂÆöÈïøÂ∫¶‰∏∫wÔºåÂä†ÂÖ•‰∏Ä‰∏™Â∫èÂàóÈïøÂ∫¶Â§™ÈïøÔºåÂ∞±Á†çÊéâÂâçÈù¢ÁöÑËØçÔºåÂè™‰øùÁïôÊúÄÂêéw‰∏™ËØçÔºõÂ¶ÇÊûú‰∏Ä‰∏™Â∫èÂàóÂ§™Áü≠ÔºåÂ∞±ÂÅözero paddingÔºåÁî®0Â°´ÂÖÖ\nËøôÊ†∑‰∏ÄÊù•ÔºåÊâÄÊúâÁöÑÂ∫èÂàóÈïøÂ∫¶Â∞±Áªü‰∏Ä‰∫Ü\nÊñáÊú¨Â§ÑÁêÜÂÆåÊàê‰∫ÜÔºåÊé•‰∏ãÊù•ÊòØword embeddingÔºåÊääÂçïËØçË°®Á§∫‰∏∫‰∏Ä‰∏™‰ΩéÁª¥ÂêëÈáèÔºõ\nÁÑ∂ËÄåËøôÊ†∑ÂÅöÁöÑËØùÔºåÂ¶ÇÊûúÊòØ10000‰∏™ÂçïËØçÔºåÁª¥Â∫¶Â∞±ÊòØ10000Áª¥ÔºåÁª¥Â∫¶Â§™È´ò‰∫ÜÔºõÂõ†Ê≠§Ë¶ÅÂÅöword embeddingÔºõ\nÂÖ∑‰ΩìÂÅöÊ≥ïÂ∞±ÊòØÊääone-hotÂêëÈáèe_iÂíåÂèÇÊï∞Áü©ÈòµpÁõ∏‰πòÔºõÁü©ÈòµPËΩ¨ÁΩÆÁöÑÂ§ßÂ∞èÊòØd x vÔºõdÊòØËØçÂêëÈáèÁöÑÁª¥Â∫¶ÔºõvÊòØÂ≠óÂÖ∏ÈáåËØçÊ±áÁöÑÊï∞ÈáèÔºõÁªìÊûú‰∏∫x_iÔºõx_iÂ∞±ÊòØ‰∏Ä‰∏™ËØçÂêëÈáèÔºõÂ¶ÇÊûúone-hotÂêëÈáèÁöÑÁ¨¨‰∏âË°å‰∏∫1ÔºõÈÇ£‰πàx_iÂ∞±ÊòØPËΩ¨ÁΩÆÁü©ÈòµÁöÑÁ¨¨‰∏âÂàóÔºàÂÖ∂‰ΩôÂàóÈÉΩ‰∏∫0ÔºâÔºõÊâÄ‰ª•PËΩ¨ÁΩÆÊØè‰∏ÄÂàóÈÉΩÊòØ‰∏Ä‰∏™ËØçÂêëÈáèÔºõÊâÄ‰ª•Áü©ÈòµPÊú¨Ë∫´ÁöÑÊØè‰∏ÄË°åÂ∞±ÊòØ‰∏Ä‰∏™ËØçÂêëÈáèÔºõÂÖ∂Ë°åÊï∞‰∏∫vÔºõÂç≥vocabularyÔºåËØçÊ±áÈáèÔºõÊØè‰∏ÄË°åÂØπÂ∫î‰∏Ä‰∏™ÂçïËØçÔºõÁü©ÈòµÁöÑÂàóÊï∞‰∏∫dÔºõdÊòØÁî®Êà∑ÂÜ≥ÂÆöÁöÑÔºõdÁöÑÂ§ßÂ∞è‰ºöÂÜ≥ÂÆöÊú∫Âô®Â≠¶‰π†Ê®°ÂûãÁöÑË°®Áé∞ÔºõÂ∫îËØ•Áî®xxxÊù•ÈÄâÊã©‰∏Ä‰∏™ÊØîËæÉÂ•ΩÁöÑdÔºõ\nÊàë‰ª¨ÁöÑ‰ªªÂä°ÊòØÁúãËØÑËÆ∫ÊòØÊ≠£Èù¢ÁöÑËøòÊòØË¥üÈù¢ÁöÑÔºõÂèÇÊï∞Áü©ÈòµÊòØ‰ªéËÆ≠ÁªÉÊï∞ÊçÆ‰∏≠Â≠¶‰π†Âá∫Êù•ÁöÑÔºåÊâÄ‰ª•Â≠¶Âá∫Êù•ÁöÑËØçÂêëÈáèÊòØÂ∏¶ÊúâÊÑüÊÉÖËâ≤ÂΩ©ÁöÑÔºõÂÅáËÆæËøô‰∫õËØçÂêëÈáèÈÉΩÊòØ‰∫åÁª¥ÁöÑÔºåÂàôÂèØ‰ª•Âú®Âπ≥Èù¢ÂùêÊ†áÁ≥ª‰∏≠Ê†áÂá∫‰∏ãÈù¢ËØçÂêëÈáè\nkerasÊèê‰æõembeddingÂ±ÇÔºõÁî®Êà∑ÂèØ‰ª•ÊåáÂÆövocabularyÂ§ßÂ∞èÂíådÁöÑÂ§ßÂ∞èÔºõ‰ª•ÂèäÊØè‰∏Ä‰∏™sequenceÁöÑÈïøÂ∫¶ÔºõdÊòØÊ†πÊçÆÁÆóÊ≥ïÈÄâÂá∫Êù•ÁöÑ Âà∞Ëøô‰∏ÄÊ≠•ÔºåÊàë‰ª¨Â∑≤ÁªèÂÆåÊàê‰∫ÜÊñáÊú¨Â§ÑÁêÜÂíåword embedding„ÄÇÊé•‰∏ãÊù•Â∞±ÊòØÁî®Logistic Regression for Binary ClassificationÂÅö‰∫åÂàÜÁ±ªÔºõ\n","permalink":"http://localhost:1313/posts/nlp-2/","summary":"\u003ch3 id=\"text-to-sequence\"\u003eText to Sequence\u003c/h3\u003e\n\u003cp\u003eÊñáÊú¨Â§ÑÁêÜ\u003c/p\u003e\n\u003cp\u003eStep1: Tokenization\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\n\u003cp\u003eTokenization breaks a piece of text down into a list of tokens.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003eHere, a token is a word. (A token can be a character in some applications.)\u003c/p\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003eTokenizationËÆ≤Á©∂ÂæàÂ§öÔºå‰æãÂ¶ÇÊòØÂê¶Â∫îËØ•ÊääÂ§ßÂÜôÊîπÊàêÂ∞èÂÜôÂë¢ÔºüËøõË°åtypo correctionÁ≠âÁ≠â\u003c/p\u003e\n\u003cp\u003e\u003cimg alt=\"image-20250322150322238\" loading=\"lazy\" src=\"./NLP-2.assets/image-20250322150322238.png\"\u003e\u003c/p\u003e\n\u003cp\u003eStep2: Build Dictionary\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\n\u003cp\u003eUse a dictionary (hash table) to count word frequencies.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003eThe dictionary maps word to index.\u003c/p\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003eÂèØ‰ª•È¶ñÂÖàÁªüËÆ°ËØçÈ¢ëÂéªÊéâ‰ΩéÈ¢ëËØçÔºåÁÑ∂ÂêéËÆ©ÊØè‰∏™ËØçÂØπÂ∫î‰∏Ä‰∏™Ê≠£Êï¥Êï∞ÔºõËøôÊ†∑ÁöÑËØùÔºå‰∏ÄÂè•ËØùÂ∞±ÂèØ‰ª•Áî®‰∏Ä‰∏™Ê≠£Êï¥Êï∞ÂàóË°®Ë°®Á§∫ÔºåËøô‰∏™ÂàóË°®Â∞±Âè´sequenceÔºõÂ¶ÇÊûúÂøÖË¶ÅÂ∞±ËøòÂæóÂÅöone-hot encoding„ÄÇ\u003cimg alt=\"image-20250322150620890\" loading=\"lazy\" src=\"./NLP-2.assets/image-20250322150620890.png\"\u003e\u003c/p\u003e\n\u003cp\u003eÁªìÊûú\u003c/p\u003e\n\u003cp\u003e\u003cimg alt=\"image-20250322150754528\" loading=\"lazy\" src=\"./NLP-2.assets/image-20250322150754528.png\"\u003e\u003c/p\u003e\n\u003cp\u003e‰ΩÜÊòØÈïøÂ∫¶‰∏çÁªü‰∏Ä\u003c/p\u003e\n\u003cp\u003eStep4: ÂØπÈΩêsequence\u003c/p\u003e\n\u003cp\u003e\u003cimg alt=\"image-20250322150854986\" loading=\"lazy\" src=\"./NLP-2.assets/image-20250322150854986.png\"\u003e\u003c/p\u003e\n\u003cp\u003eËß£ÂÜ≥ÊñπÊ°àÊòØËøôÊ†∑ÁöÑÔºöÂèØ‰ª•Âõ∫ÂÆöÈïøÂ∫¶‰∏∫wÔºåÂä†ÂÖ•‰∏Ä‰∏™Â∫èÂàóÈïøÂ∫¶Â§™ÈïøÔºåÂ∞±Á†çÊéâÂâçÈù¢ÁöÑËØçÔºåÂè™‰øùÁïôÊúÄÂêéw‰∏™ËØçÔºõÂ¶ÇÊûú‰∏Ä‰∏™Â∫èÂàóÂ§™Áü≠ÔºåÂ∞±ÂÅözero paddingÔºåÁî®0Â°´ÂÖÖ\u003c/p\u003e\n\u003cp\u003e\u003cimg alt=\"image-20250322151030119\" loading=\"lazy\" src=\"./NLP-2.assets/image-20250322151030119.png\"\u003e\u003c/p\u003e\n\u003cp\u003eËøôÊ†∑‰∏ÄÊù•ÔºåÊâÄÊúâÁöÑÂ∫èÂàóÈïøÂ∫¶Â∞±Áªü‰∏Ä‰∫Ü\u003c/p\u003e\n\u003cp\u003e\u003cimg alt=\"image-20250322151117125\" loading=\"lazy\" src=\"./NLP-2.assets/image-20250322151117125.png\"\u003e\u003c/p\u003e\n\u003cp\u003eÊñáÊú¨Â§ÑÁêÜÂÆåÊàê‰∫ÜÔºåÊé•‰∏ãÊù•ÊòØword embeddingÔºåÊääÂçïËØçË°®Á§∫‰∏∫‰∏Ä‰∏™‰ΩéÁª¥ÂêëÈáèÔºõ\u003c/p\u003e\n\u003cp\u003e\u003cimg alt=\"image-20250322151252837\" loading=\"lazy\" src=\"./NLP-2.assets/image-20250322151252837.png\"\u003e\u003c/p\u003e","title":""},{"content":"üëã About me Hello! I\u0026rsquo;m Xu Zongsi, a passionate technology enthusiast currently pursuing my Master of Science in ECIC at The University of Hong Kong. With a solid background in Software Engineering from the Beijing Institute of Technology, I specialize in artificial intelligence areas like machine learning, deep learning, natural language processing, computer vision, and reinforcement learning.\nInspired by OpenAI\u0026rsquo;s five-step plan towards superintelligence, I am excited about AGI and have developed a keen interest in LLM agents, MLLM, and knowledge graphs. I see great potential in these fields and aspire to contribute to innovative solutions.\nüìö Education üá≠üá∞ The University of Hong Kong 09/2024 - Expected 11/2025 School of Computing and Data Science Master of Science in Electronic Commerce \u0026amp; Internet Computing Relevant Courses: Machine learning for business and e-commerce, Knowledge graphs, Financial fraud analytics, Internet infrastructure technologies, Website engineering, Blockchain and cryptocurrency, etc. üá®üá≥ Beijing Institute of Technology 09/2020 - 06/2024 School of Computer Science \u0026amp; Technology Bachelor of Engineering in Software Engineering, last two years GPA: 3.7/4 Relevant Courses: Reinforcement Learning, Deep Learning and Computer Vision, Artificial Intelligence and Robot Ethics, Almost Human: Mind, Brain and Artificial Intelligence, Mathematical Analysis for Engineering, Linear Algebra, Probability and Mathematical Statistics, etc. Skills: Python, Java, common data structures, design patterns, machine learning basics and algorithms, Linux, PyTorch, and some development tools (git, conda, etc.). üèÜ Awards \u0026amp; Honors Beijing Institute of Technology Undergraduate Scholarship (Top 20% of Grade) 06/2023 3rd Prize of China International \u0026#34;Internet \u0026#43;\u0026#34; College Student\u0026#39;s Innovation Competition 08/2022 Bronze Prize of \u0026#34;Challenge Cup\u0026#34; Capital University Entrepreneurship Competition 05/2022 üíº Project Experience üîç Online Transaction Fraud Detection 09/2024 ‚Äì 01/2025 Independent project, supervised by Dr. Vivien Chan Focused on addressing financial fraud in e-commerce to enhance the accuracy of transaction anomaly detection, while independently managing the entire case study that included data preprocessing, feature engineering, model building, evaluation, and results analysis. Effectively resolved class imbalance issues using SMOTE and ROSE techniques. Built various models including Logistic Regression, Random Forest, XGBoost, and LightGBM, ultimately selecting the LightGBM model to achieve a recall rate of 95.45% and an AUC of 99.84%. Wrote efficient and maintainable code, enhancing model training and data processing efficiency through parallel computing and logging. ü§ñ Multi-Model Intelligent Text Keyword Extraction System 08/2023 ‚Äì 09/2023 Group project, supervised by Associate Prof. Xiaolin Zhao Designed and implemented an intelligent text summary system that automatically extracts keywords from article titles and abstracts, enhancing the understanding and summarization of text information. Participated in the planning of the technical route and built a hybrid model combining extractive and generative approaches, utilizing advanced natural language processing techniques including KeyBERT, Sentence Transformer, BERT, and T5 models. Responsible for data preprocessing and tokenization, as well as the end-to-end implementation and training of the T5 model, optimizing the model architecture and hyperparameters, achieving satisfactory results after only 3 epochs of training. Model evaluation results showed that the Rouge-1, Rouge-2, and Rouge-L metrics reached 0.6345, 0.5038, and 0.5282, respectively, in the third epoch, validating the model\u0026rsquo;s effectiveness in the summarization task. üéì Cambridge University Machine Learning Summer Project 07/2023 ‚Äì 08/2023 Group project, supervised by Prof. Pietro Li√≤ Participated in the Cambridge University deep learning summer project, focusing on deep reinforcement learning; explored multi-agent learning algorithms across different environments. Reproduced the Multi-Agent Deep Deterministic Policy Gradient (MADDPG) algorithm in the Simple Adversary environment and studied the effect of agent numbers on convergence speed and stability, finding optimal stability at 21 agents. Designed and implemented comparative experiments inspired by the Rainbow algorithm, assessing target network strategies versus the Double Deep Q-Network (Double DQN). The results demonstrated that Double DQN significantly enhanced convergence speed, optimizing the overall learning process. Co-authored a group project paper on agent numbers and strategies effectiveness in multi-agent systems, achieving a score of 71% in the summer program (the highest in my group) and a \u0026ldquo;First Class\u0026rdquo; classification in the UK grading system. üëÅÔ∏è Deep Learning and Computer Vision Semester Project 09/2022 ‚Äì 12/2022 Independent project, supervised by Associate Prof. Guangyu Gao Designed and implemented a waste classifier using the ResNet model to improve classification accuracy and reduce resource waste. The project also enhanced understanding of transfer learning techniques with ResNet. Collected a dataset of 16 waste categories and preprocessed the images for uniformity and standardization, incorporating data augmentation techniques to enhance the dataset. Conducted experiments using ResNet34 and ResNet50 models through transfer learning, accelerating network convergence by leveraging pretrained weights. During training, techniques such as Batch Normalization and Dropout were applied to mitigate the risk of overfitting. The final model achieved an accuracy of 90% on the training set, while the performance on the test set was 61%, indicating a significant overfitting phenomenon during the training process. üéì Internship ‚öõÔ∏è Beijing Academy of Quantum Information Science 08/2023 ‚Äì 01/2024 Research Intern at Quantum Computation Department Proposed a quantum convolution kernel design based on variational quantum circuits and developed a universal quantum convolution layer, successfully integrating it into classical CNN architectures such as VGG, GoogLeNet, and ResNet. Developed and evaluated various hybrid models, including a simple model named HQCCNN-2, which achieved 84.45% accuracy on the FashionMNIST dataset, surpassing the traditional CNN\u0026rsquo;s 80.72%. This demonstrates the effectiveness of the quantum convolution layer in improving model performance. Tested on a real quantum computer further validated the effectiveness of the hybrid model, demonstrating the viable integration of quantum computing with deep learning, and highlighting the potential for leveraging quantum properties to enhance model performance. üèÖ Competition Experience ü•â China International \u0026#34;Internet \u0026#43;\u0026#34; College Students\u0026#39; Innovation Competition 08/2022 üõ°Ô∏è Zhongke Ushield: Deep Learning-based Face Privacy Protection Authentication System Responsible for constructing a localized facial feature extraction engine based on MobileFaceNet, ensuring feature extraction is completed on end devices (such as mobile phones and cameras), guaranteeing that raw data does not leave the domain and is not stored, thus enhancing user privacy protection while improving recognition efficiency. ü•â \u0026#34;Challenge Cup\u0026#34; Capital University Entrepreneurship Competition 05/2022 üå≥ Smart Orchard Responsible for the development of the fruit detection, ripeness prediction, and pest identification system, using deep convolutional neural network (CNN) technology for intelligent monitoring of crop growth conditions. Applied advanced object detection algorithms such as Faster R-CNN and YOLO to achieve high precision in apple detection and ripeness assessment, with an accuracy rate exceeding 90%, significantly enhancing the intelligence level of orchard management. Built and trained a dedicated dataset containing various pest samples, optimizing pest detection accuracy through data preprocessing (such as image normalization and resizing) and data augmentation techniques (like rotation, flipping, and noise addition), enabling the real-time monitoring system to accurately identify over 80% of pests, providing effective scientific maintenance recommendations to help farmers reduce crop losses. üìã Extracurricular Activities Vice President, Cyber Security Club, Beijing Institute of Technology 09/2021-09/2022 Backbone, Media Center of the Student Union of Beijing Institute of Technology 10/2020-06/2021 üì´ Contact üìß Email: zongsi.xu@outlook.com üëî LinkedIn: Zongsi (Tristan) Xu üíª GitHub: github.com/BaizeXS üìç Location: Hong Kong SAR, China ","permalink":"http://localhost:1313/resume/","summary":"Personal resume of Zongsi (Tristan) Xu","title":"Zongsi (Tristan) Xu"},{"content":"‰∏Ä„ÄÅÊï∞ÂÄºÁâπÂæÅ‰∏éÁ±ªÂà´ÁâπÂæÅ Êï∞ÂÄºÁâπÂæÅ (Numeric Features) ÂÖ∑ÊúâÂèØÂä†ÂáèÁöÑÊÑè‰πâÔºå‰∏îÂ≠òÂú®Â§ßÂ∞èÈ°∫Â∫è„ÄÇ ‰æãÂ≠êÔºöÂπ¥ÈæÑ„ÄÅÊ∏©Â∫¶Á≠â„ÄÇÂèØ‰ª•Áõ¥Êé•‰øùÁïôÂÖ∂Êï¥Êï∞ÊàñÊµÆÁÇπÊï∞ÂΩ¢Âºè‰æõÊ®°Âûã‰ΩøÁî®„ÄÇ Á±ªÂà´ÁâπÂæÅ (Categorical Features) Êï∞ÊçÆÂÄºÁ¶ªÊï£Ôºå‰∏çÂÖ∑Â§á‚ÄúÊï∞ÂÄºÂ§ßÂ∞è‚ÄùÈó¥ÁöÑÂèØÊØîÊÑè‰πâ„ÄÇ ‰æãÂ≠êÔºöÂõΩÁ±çÔºàÁæéÂõΩ/‰∏≠ÂõΩ/Âç∞Â∫¶Á≠âÔºâ„ÄÅÊÄßÂà´ÔºàÁî∑/Â•≥ÔºâÁ≠â„ÄÇ ÈóÆÈ¢òÔºöËã•‰ªÖÁî®Êï¥Êï∞Ë°®Á§∫ÔºàÁæéÂõΩ=1, ‰∏≠ÂõΩ=2ÔºâÔºå‰ºöÂºïÂÖ•ÈîôËØØÁöÑÊï∞ÂÄºËøêÁÆóÂÖ≥Á≥ªÔºåÂ¶Ç ‚ÄúÁæéÂõΩ + ‰∏≠ÂõΩ = Âç∞Â∫¶‚Äù„ÄÇ ‰∫å„ÄÅOne-HotÁºñÁ†ÅÁöÑÂä®Êú∫‰∏éÊµÅÁ®ã ‰∏∫‰ªÄ‰πà‰ΩøÁî®One-Hot\nÈÄöËøáÂ∞ÜÁ±ªÂà´Êò†Â∞Ñ‰∏∫ÂêëÈáèÔºåÈÅøÂÖçÊï¥Êï∞ÁºñÁ†ÅÂºïÂÖ•ÁöÑ‰º™Êï∞ÂÄºÂÖ≥Á≥ª„ÄÇ ÂêåÊó∂‰øùÁïôÂêÑÁßçÂèØËÉΩÁ±ªÂà´ÁöÑ‰ø°ÊÅØÔºå‰∏î‰ªÖÂú®ÂØπÂ∫î‰ΩçÁΩÆ‰∏∫1ÔºåÂÖ∂‰ªñ‰ΩçÁΩÆ‰∏∫0„ÄÇ Âª∫Á´ãÊò†Â∞ÑÔºö‰ªéÁ±ªÂà´Âà∞Á¥¢Âºï\n‰∏∫ÊØè‰∏™Á±ªÂà´ÂàÜÈÖç‰∏Ä‰∏™ÂîØ‰∏ÄÁ¥¢ÂºïÔºåÈÄöÂ∏∏‰ªé1ÂºÄÂßã„ÄÇ È¢ÑÁïôÁ¥¢Âºï0Ë°®Á§∫‚ÄúÊú™Áü•‚ÄùÊàñ‚ÄúÁº∫Â§±‚ÄùÔºåÂØπÂ∫îÂÖ®0ÂêëÈáè„ÄÇ ËΩ¨Êç¢‰∏∫One-HotÂêëÈáè\nËã•Á±ªÂà´ÊÄªÊï∞‰∏∫197ÔºåÂàôÁî®197Áª¥ÂêëÈáèË°®Á§∫„ÄÇ ‰æãÂ≠êÔºöÁæéÂõΩ [1, 0, 0, 0, ‚Ä¶]Ôºå ‰∏≠ÂõΩ [0, 1, 0, 0, ‚Ä¶]„ÄÇ Á§∫‰æãÔºöË°®Á§∫‰∏Ä‰∏™‰∫∫ÁöÑÁâπÂæÅ\nÁâπÂæÅÂåÖÂê´ÔºàÂπ¥ÈæÑ, ÊÄßÂà´, ÂõΩÁ±çÔºåÂÖ∂‰∏≠ÂõΩÁ±ç197ÁßçÔºâ Áª¥Â∫¶ÊÄªÂíåÔºö1Áª¥_age + 1Áª¥_gender + 197Áª¥_nationality = 199Áª¥„ÄÇ ‰æãÂ¶Ç (28, Â•≥, ‰∏≠ÂõΩ) ‚Üí [28, 0, 0, 1, 0, ‚Ä¶, 0]„ÄÇ ‰∏â„ÄÅÊñáÊú¨Êï∞ÊçÆÂ§ÑÁêÜÊµÅÁ®ã ÊñáÊú¨Âú®Ëá™ÁÑ∂ËØ≠Ë®ÄÂ§ÑÁêÜÔºàNLPÔºâ‰∏≠‰Ωú‰∏∫Â∏∏ËßÅÁöÑÂéüÂßãËæìÂÖ•ÔºåÈúÄË¶ÅÊï∞ÂÄºÂåñÊâçËÉΩÈÄÅÂÖ•Ê®°Âûã„ÄÇ‰∏ÄËà¨Ê≠•È™§Â¶Ç‰∏ãÔºö\nÂàÜËØç (Tokenization)\nÂ∞ÜÊñáÊú¨ÊãÜÂàÜ‰∏∫‰∏Ä‰∏™‰∏™ÂçïËØçÔºàTokenÔºâ„ÄÇ ‰æãÂ≠êÔºö\u0026quot;... to be or not to be...\u0026quot; ‚Üí [\u0026quot;...\u0026quot;, \u0026quot;to\u0026quot;, \u0026quot;be\u0026quot;, \u0026quot;or\u0026quot;, \u0026quot;not\u0026quot;, \u0026quot;to\u0026quot;, \u0026quot;be\u0026quot;, \u0026quot;...\u0026quot;]„ÄÇ ÁªüËÆ°ËØçÈ¢ë \u0026amp; ÊûÑÂª∫ËØçÂÖ∏\nËØçÈ¢ëÁªüËÆ° Áî®ÂìàÂ∏åË°®/Â≠óÂÖ∏ËÆ∞ÂΩïÊØè‰∏™ÂçïËØçÂá∫Áé∞Ê¨°Êï∞„ÄÇ ÈÅçÂéÜÊñáÊú¨Êó∂ÔºåËã•ÂçïËØçÂ∞öÊú™ÂÖ•Ë°®ÔºåÂàôÊñ∞Âª∫ËÆ∞ÂΩïÔºõËã•Â∑≤Â≠òÂú®ÔºåÂàôËÆ°Êï∞+1„ÄÇ ÊéíÂ∫è‰∏éÁ¥¢Âºï ÊåâËØçÈ¢ëÈôçÂ∫èÊéíÂ∫èÔºåËØçÈ¢ëÊúÄÈ´òÁöÑÂçïËØçÊéíÂú®ÂâçÈù¢„ÄÇ Á¥¢Âºï‰ªé1ÂºÄÂßãÔºå0ÁïôÁªô‚ÄúÊú™Áü•‚Äù„ÄÇ ËØçÂÖ∏ËßÑÊ®°ÔºàvocabularyÔºâÂèØËßÜÈúÄÊ±ÇÊà™Êñ≠Ôºà‰æãÂ¶ÇÂè™‰øùÁïôTop 10kÔºâ„ÄÇ ‰∏∫‰ªÄ‰πàÁßªÈô§‰ΩéÈ¢ëËØç ‰ΩéÈ¢ëËØçÂèØËÉΩÊòØÊãºÂÜôÈîôËØØ„ÄÅÁΩïËßÅ‰∫∫ÂêçÁ≠âÔºåÂØπÊ®°ÂûãÂ∏ÆÂä©ÊúâÈôê„ÄÇ ÂáèÂ∞ëËØçÂÖ∏ËßÑÊ®°ÂèØÈôç‰ΩéËøêÁÆóÂºÄÈîÄ„ÄÅÂä†Âø´Ê®°ÂûãËÆ≠ÁªÉ‰∏éÊé®ÁêÜÈÄüÂ∫¶„ÄÇ Áã¨ÁÉ≠ÁºñÁ†Å (One-Hot Encoding)\nÂ∞ÜÊØè‰∏™ÂçïËØçÊò†Â∞Ñ‰∏∫ËØçÂÖ∏‰∏≠ÁöÑÁ¥¢ÂºïÂêéÔºàÂ¶Ç [2, 4, 1, 8, ‚Ä¶]ÔºâÔºåÂèØËøõ‰∏ÄÊ≠•ËΩ¨Êç¢ÊàêOne-HotÂêëÈáè„ÄÇ One-HotÁª¥Â∫¶ÂèñÂÜ≥‰∫é‰øùÁïô‰∏ãÊù•ÁöÑËØçÂÖ∏Â§ßÂ∞èÔºà‰æãÂ¶Ç1‰∏áÔºâ„ÄÇ Êú™Êî∂ÂΩïÂçïËØçÂèØËÉΩÁõ¥Êé•ÂøΩÁï•ÔºåÊàñÁªü‰∏ÄÁî®Á¥¢Âºï0‰ª£Êõø„ÄÇ Âõõ„ÄÅÊ†∏ÂøÉÊî∂Ëé∑‰∏éÂ∫îÁî® Á±ªÂà´ÁâπÂæÅÂøÖÈúÄÊï∞ÂÄºÂåñÔºö\n‰ΩøÁî®Êï¥Êï∞1,2,3‚Ä¶‰ªÖË°®Á§∫Á±ªÂà´‚ÄúÊ†áËØÜ‚ÄùÔºåÂπ∂‰∏ç‰ª£Ë°®ÂÆÉ‰ª¨ÂèØËøõË°åÊï∞ÂÄºËøêÁÆó„ÄÇ Âõ†Ê≠§ÈúÄË¶ÅOne-HotÁ≠âÁºñÁ†ÅÊñπÂºèÔºåÈÅøÂÖçÊï∞ÂÄºËØØËß£„ÄÇ ÊñáÊú¨Êï∞ÊçÆÈ¢ÑÂ§ÑÁêÜÔºö\nÂàÜËØç„ÄÅËØçÈ¢ëÁªüËÆ°„ÄÅÊûÑÂª∫ËØçÂÖ∏„ÄÅÁ¥¢ÂºïÂåñ„ÄÅOne-HotÊàñÂÖ∂‰ªñÊñπÂºèÔºàÂ¶ÇËØçÂµåÂÖ•ÔºâÊòØÂ∏∏ËßÅÊµÅÁ®ã„ÄÇ Ê≠£Á°ÆÁöÑÊñáÊú¨È¢ÑÂ§ÑÁêÜÂèØÊòæËëóÂΩ±ÂìçÊ®°ÂûãÊÄßËÉΩÂíåÊïàÁéá„ÄÇ ‰øùÁïôÊú™Áü•Á¥¢ÂºïÔºö\n‰øùËØÅÂØπÁº∫Â§±Êï∞ÊçÆÊàñÂ≠óÂÖ∏Â§ñÊñ∞ËØçËÉΩÊúâÂü∫Êú¨ÁöÑË°®Á§∫ÔºåÊèêÂçáÊ®°ÂûãÂÆπÈîôÊÄß„ÄÇ ÂÆûÈôÖ‰ΩøÁî®Ôºö\nÂØπ‰∫éÂ∞èËßÑÊ®°Á±ªÂà´ÂèØÁõ¥Êé•One-HotÁºñÁ†ÅÔºõÂØπ‰∫éËØçÂÖ∏ÂæàÂ§ßÁöÑÂú∫ÊôØÔºåÈÄöÂ∏∏‰ºöËøõ‰∏ÄÊ≠•ËÄÉËôëËØçÂµåÂÖ•ÔºàWord EmbeddingÔºâÊàñÈ¢ÑËÆ≠ÁªÉËØ≠Ë®ÄÊ®°Âûã„ÄÇ ","permalink":"http://localhost:1313/posts/nlp-1/","summary":"\u003ch2 id=\"‰∏ÄÊï∞ÂÄºÁâπÂæÅ‰∏éÁ±ªÂà´ÁâπÂæÅ\"\u003e‰∏Ä„ÄÅÊï∞ÂÄºÁâπÂæÅ‰∏éÁ±ªÂà´ÁâπÂæÅ\u003c/h2\u003e\n\u003col\u003e\n\u003cli\u003e\u003cstrong\u003eÊï∞ÂÄºÁâπÂæÅ (Numeric Features)\u003c/strong\u003e\n\u003cul\u003e\n\u003cli\u003eÂÖ∑ÊúâÂèØÂä†ÂáèÁöÑÊÑè‰πâÔºå‰∏îÂ≠òÂú®Â§ßÂ∞èÈ°∫Â∫è„ÄÇ\u003c/li\u003e\n\u003cli\u003e‰æãÂ≠êÔºöÂπ¥ÈæÑ„ÄÅÊ∏©Â∫¶Á≠â„ÄÇÂèØ‰ª•Áõ¥Êé•‰øùÁïôÂÖ∂Êï¥Êï∞ÊàñÊµÆÁÇπÊï∞ÂΩ¢Âºè‰æõÊ®°Âûã‰ΩøÁî®„ÄÇ\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003eÁ±ªÂà´ÁâπÂæÅ (Categorical Features)\u003c/strong\u003e\n\u003cul\u003e\n\u003cli\u003eÊï∞ÊçÆÂÄºÁ¶ªÊï£Ôºå‰∏çÂÖ∑Â§á‚ÄúÊï∞ÂÄºÂ§ßÂ∞è‚ÄùÈó¥ÁöÑÂèØÊØîÊÑè‰πâ„ÄÇ\u003c/li\u003e\n\u003cli\u003e‰æãÂ≠êÔºöÂõΩÁ±çÔºàÁæéÂõΩ/‰∏≠ÂõΩ/Âç∞Â∫¶Á≠âÔºâ„ÄÅÊÄßÂà´ÔºàÁî∑/Â•≥ÔºâÁ≠â„ÄÇ\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003eÈóÆÈ¢ò\u003c/strong\u003eÔºöËã•‰ªÖÁî®Êï¥Êï∞Ë°®Á§∫ÔºàÁæéÂõΩ=1, ‰∏≠ÂõΩ=2ÔºâÔºå‰ºöÂºïÂÖ•ÈîôËØØÁöÑÊï∞ÂÄºËøêÁÆóÂÖ≥Á≥ªÔºåÂ¶Ç ‚ÄúÁæéÂõΩ + ‰∏≠ÂõΩ = Âç∞Â∫¶‚Äù„ÄÇ\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003c/ol\u003e\n\u003ch2 id=\"‰∫åone-hotÁºñÁ†ÅÁöÑÂä®Êú∫‰∏éÊµÅÁ®ã\"\u003e‰∫å„ÄÅOne-HotÁºñÁ†ÅÁöÑÂä®Êú∫‰∏éÊµÅÁ®ã\u003c/h2\u003e\n\u003col\u003e\n\u003cli\u003e\n\u003cp\u003e\u003cstrong\u003e‰∏∫‰ªÄ‰πà‰ΩøÁî®One-Hot\u003c/strong\u003e\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eÈÄöËøáÂ∞ÜÁ±ªÂà´Êò†Â∞Ñ‰∏∫ÂêëÈáèÔºåÈÅøÂÖçÊï¥Êï∞ÁºñÁ†ÅÂºïÂÖ•ÁöÑ‰º™Êï∞ÂÄºÂÖ≥Á≥ª„ÄÇ\u003c/li\u003e\n\u003cli\u003eÂêåÊó∂‰øùÁïôÂêÑÁßçÂèØËÉΩÁ±ªÂà´ÁöÑ‰ø°ÊÅØÔºå‰∏î‰ªÖÂú®ÂØπÂ∫î‰ΩçÁΩÆ‰∏∫1ÔºåÂÖ∂‰ªñ‰ΩçÁΩÆ‰∏∫0„ÄÇ\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003e\u003cstrong\u003eÂª∫Á´ãÊò†Â∞ÑÔºö‰ªéÁ±ªÂà´Âà∞Á¥¢Âºï\u003c/strong\u003e\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e‰∏∫ÊØè‰∏™Á±ªÂà´ÂàÜÈÖç‰∏Ä‰∏™ÂîØ‰∏ÄÁ¥¢ÂºïÔºåÈÄöÂ∏∏‰ªé1ÂºÄÂßã„ÄÇ\u003c/li\u003e\n\u003cli\u003eÈ¢ÑÁïôÁ¥¢Âºï0Ë°®Á§∫‚ÄúÊú™Áü•‚ÄùÊàñ‚ÄúÁº∫Â§±‚ÄùÔºåÂØπÂ∫îÂÖ®0ÂêëÈáè„ÄÇ\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003e\u003cstrong\u003eËΩ¨Êç¢‰∏∫One-HotÂêëÈáè\u003c/strong\u003e\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eËã•Á±ªÂà´ÊÄªÊï∞‰∏∫197ÔºåÂàôÁî®197Áª¥ÂêëÈáèË°®Á§∫„ÄÇ\u003c/li\u003e\n\u003cli\u003e‰æãÂ≠êÔºöÁæéÂõΩ \u003ccode\u003e[1, 0, 0, 0, ‚Ä¶]\u003c/code\u003eÔºå ‰∏≠ÂõΩ \u003ccode\u003e[0, 1, 0, 0, ‚Ä¶]\u003c/code\u003e„ÄÇ\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003e\u003cstrong\u003eÁ§∫‰æãÔºöË°®Á§∫‰∏Ä‰∏™‰∫∫ÁöÑÁâπÂæÅ\u003c/strong\u003e\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eÁâπÂæÅÂåÖÂê´ÔºàÂπ¥ÈæÑ, ÊÄßÂà´, ÂõΩÁ±çÔºåÂÖ∂‰∏≠ÂõΩÁ±ç197ÁßçÔºâ\u003c/li\u003e\n\u003cli\u003eÁª¥Â∫¶ÊÄªÂíåÔºö1Áª¥_age + 1Áª¥_gender + 197Áª¥_nationality = 199Áª¥„ÄÇ\u003c/li\u003e\n\u003cli\u003e‰æãÂ¶Ç \u003ccode\u003e(28, Â•≥, ‰∏≠ÂõΩ)\u003c/code\u003e ‚Üí \u003ccode\u003e[28, 0, 0, 1, 0, ‚Ä¶, 0]\u003c/code\u003e„ÄÇ\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003c/ol\u003e\n\u003ch2 id=\"‰∏âÊñáÊú¨Êï∞ÊçÆÂ§ÑÁêÜÊµÅÁ®ã\"\u003e‰∏â„ÄÅÊñáÊú¨Êï∞ÊçÆÂ§ÑÁêÜÊµÅÁ®ã\u003c/h2\u003e\n\u003cp\u003eÊñáÊú¨Âú®Ëá™ÁÑ∂ËØ≠Ë®ÄÂ§ÑÁêÜÔºàNLPÔºâ‰∏≠‰Ωú‰∏∫Â∏∏ËßÅÁöÑÂéüÂßãËæìÂÖ•ÔºåÈúÄË¶ÅÊï∞ÂÄºÂåñÊâçËÉΩÈÄÅÂÖ•Ê®°Âûã„ÄÇ‰∏ÄËà¨Ê≠•È™§Â¶Ç‰∏ãÔºö\u003c/p\u003e\n\u003col\u003e\n\u003cli\u003e\n\u003cp\u003e\u003cstrong\u003eÂàÜËØç (Tokenization)\u003c/strong\u003e\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eÂ∞ÜÊñáÊú¨ÊãÜÂàÜ‰∏∫‰∏Ä‰∏™‰∏™ÂçïËØçÔºàTokenÔºâ„ÄÇ\u003c/li\u003e\n\u003cli\u003e‰æãÂ≠êÔºö\u003ccode\u003e\u0026quot;... to be or not to be...\u0026quot;\u003c/code\u003e ‚Üí \u003ccode\u003e[\u0026quot;...\u0026quot;, \u0026quot;to\u0026quot;, \u0026quot;be\u0026quot;, \u0026quot;or\u0026quot;, \u0026quot;not\u0026quot;, \u0026quot;to\u0026quot;, \u0026quot;be\u0026quot;, \u0026quot;...\u0026quot;]\u003c/code\u003e„ÄÇ\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003e\u003cstrong\u003eÁªüËÆ°ËØçÈ¢ë \u0026amp; ÊûÑÂª∫ËØçÂÖ∏\u003c/strong\u003e\u003c/p\u003e","title":""},{"content":"Text to Sequence ÊñáÊú¨Â§ÑÁêÜ\nStep1: Tokenization\nTokenization breaks a piece of text down into a list of tokens.\nHere, a token is a word. (A token can be a character in some applications.)\nTokenizationËÆ≤Á©∂ÂæàÂ§öÔºå‰æãÂ¶ÇÊòØÂê¶Â∫îËØ•ÊääÂ§ßÂÜôÊîπÊàêÂ∞èÂÜôÂë¢ÔºüËøõË°åtypo correctionÁ≠âÁ≠â\nStep2: Build Dictionary\nUse a dictionary (hash table) to count word frequencies.\nThe dictionary maps word to index.\nÂèØ‰ª•È¶ñÂÖàÁªüËÆ°ËØçÈ¢ëÂéªÊéâ‰ΩéÈ¢ëËØçÔºåÁÑ∂ÂêéËÆ©ÊØè‰∏™ËØçÂØπÂ∫î‰∏Ä‰∏™Ê≠£Êï¥Êï∞ÔºõËøôÊ†∑ÁöÑËØùÔºå‰∏ÄÂè•ËØùÂ∞±ÂèØ‰ª•Áî®‰∏Ä‰∏™Ê≠£Êï¥Êï∞ÂàóË°®Ë°®Á§∫ÔºåËøô‰∏™ÂàóË°®Â∞±Âè´sequenceÔºõÂ¶ÇÊûúÂøÖË¶ÅÂ∞±ËøòÂæóÂÅöone-hot encoding„ÄÇ\nÁªìÊûú\n‰ΩÜÊòØÈïøÂ∫¶‰∏çÁªü‰∏Ä\nStep4: ÂØπÈΩêsequence\nËß£ÂÜ≥ÊñπÊ°àÊòØËøôÊ†∑ÁöÑÔºöÂèØ‰ª•Âõ∫ÂÆöÈïøÂ∫¶‰∏∫wÔºåÂä†ÂÖ•‰∏Ä‰∏™Â∫èÂàóÈïøÂ∫¶Â§™ÈïøÔºåÂ∞±Á†çÊéâÂâçÈù¢ÁöÑËØçÔºåÂè™‰øùÁïôÊúÄÂêéw‰∏™ËØçÔºõÂ¶ÇÊûú‰∏Ä‰∏™Â∫èÂàóÂ§™Áü≠ÔºåÂ∞±ÂÅözero paddingÔºåÁî®0Â°´ÂÖÖ\nËøôÊ†∑‰∏ÄÊù•ÔºåÊâÄÊúâÁöÑÂ∫èÂàóÈïøÂ∫¶Â∞±Áªü‰∏Ä‰∫Ü\nÊñáÊú¨Â§ÑÁêÜÂÆåÊàê‰∫ÜÔºåÊé•‰∏ãÊù•ÊòØword embeddingÔºåÊääÂçïËØçË°®Á§∫‰∏∫‰∏Ä‰∏™‰ΩéÁª¥ÂêëÈáèÔºõ\nÁÑ∂ËÄåËøôÊ†∑ÂÅöÁöÑËØùÔºåÂ¶ÇÊûúÊòØ10000‰∏™ÂçïËØçÔºåÁª¥Â∫¶Â∞±ÊòØ10000Áª¥ÔºåÁª¥Â∫¶Â§™È´ò‰∫ÜÔºõÂõ†Ê≠§Ë¶ÅÂÅöword embeddingÔºõ\nÂÖ∑‰ΩìÂÅöÊ≥ïÂ∞±ÊòØÊääone-hotÂêëÈáèe_iÂíåÂèÇÊï∞Áü©ÈòµpÁõ∏‰πòÔºõÁü©ÈòµPËΩ¨ÁΩÆÁöÑÂ§ßÂ∞èÊòØd x vÔºõdÊòØËØçÂêëÈáèÁöÑÁª¥Â∫¶ÔºõvÊòØÂ≠óÂÖ∏ÈáåËØçÊ±áÁöÑÊï∞ÈáèÔºõÁªìÊûú‰∏∫x_iÔºõx_iÂ∞±ÊòØ‰∏Ä‰∏™ËØçÂêëÈáèÔºõÂ¶ÇÊûúone-hotÂêëÈáèÁöÑÁ¨¨‰∏âË°å‰∏∫1ÔºõÈÇ£‰πàx_iÂ∞±ÊòØPËΩ¨ÁΩÆÁü©ÈòµÁöÑÁ¨¨‰∏âÂàóÔºàÂÖ∂‰ΩôÂàóÈÉΩ‰∏∫0ÔºâÔºõÊâÄ‰ª•PËΩ¨ÁΩÆÊØè‰∏ÄÂàóÈÉΩÊòØ‰∏Ä‰∏™ËØçÂêëÈáèÔºõÊâÄ‰ª•Áü©ÈòµPÊú¨Ë∫´ÁöÑÊØè‰∏ÄË°åÂ∞±ÊòØ‰∏Ä‰∏™ËØçÂêëÈáèÔºõÂÖ∂Ë°åÊï∞‰∏∫vÔºõÂç≥vocabularyÔºåËØçÊ±áÈáèÔºõÊØè‰∏ÄË°åÂØπÂ∫î‰∏Ä‰∏™ÂçïËØçÔºõÁü©ÈòµÁöÑÂàóÊï∞‰∏∫dÔºõdÊòØÁî®Êà∑ÂÜ≥ÂÆöÁöÑÔºõdÁöÑÂ§ßÂ∞è‰ºöÂÜ≥ÂÆöÊú∫Âô®Â≠¶‰π†Ê®°ÂûãÁöÑË°®Áé∞ÔºõÂ∫îËØ•Áî®xxxÊù•ÈÄâÊã©‰∏Ä‰∏™ÊØîËæÉÂ•ΩÁöÑdÔºõ\nÊàë‰ª¨ÁöÑ‰ªªÂä°ÊòØÁúãËØÑËÆ∫ÊòØÊ≠£Èù¢ÁöÑËøòÊòØË¥üÈù¢ÁöÑÔºõÂèÇÊï∞Áü©ÈòµÊòØ‰ªéËÆ≠ÁªÉÊï∞ÊçÆ‰∏≠Â≠¶‰π†Âá∫Êù•ÁöÑÔºåÊâÄ‰ª•Â≠¶Âá∫Êù•ÁöÑËØçÂêëÈáèÊòØÂ∏¶ÊúâÊÑüÊÉÖËâ≤ÂΩ©ÁöÑÔºõÂÅáËÆæËøô‰∫õËØçÂêëÈáèÈÉΩÊòØ‰∫åÁª¥ÁöÑÔºåÂàôÂèØ‰ª•Âú®Âπ≥Èù¢ÂùêÊ†áÁ≥ª‰∏≠Ê†áÂá∫‰∏ãÈù¢ËØçÂêëÈáè\nkerasÊèê‰æõembeddingÂ±ÇÔºõÁî®Êà∑ÂèØ‰ª•ÊåáÂÆövocabularyÂ§ßÂ∞èÂíådÁöÑÂ§ßÂ∞èÔºõ‰ª•ÂèäÊØè‰∏Ä‰∏™sequenceÁöÑÈïøÂ∫¶ÔºõdÊòØÊ†πÊçÆÁÆóÊ≥ïÈÄâÂá∫Êù•ÁöÑ Âà∞Ëøô‰∏ÄÊ≠•ÔºåÊàë‰ª¨Â∑≤ÁªèÂÆåÊàê‰∫ÜÊñáÊú¨Â§ÑÁêÜÂíåword embedding„ÄÇÊé•‰∏ãÊù•Â∞±ÊòØÁî®Logistic Regression for Binary ClassificationÂÅö‰∫åÂàÜÁ±ªÔºõ\n","permalink":"http://localhost:1313/posts/nlp-2/","summary":"\u003ch3 id=\"text-to-sequence\"\u003eText to Sequence\u003c/h3\u003e\n\u003cp\u003eÊñáÊú¨Â§ÑÁêÜ\u003c/p\u003e\n\u003cp\u003eStep1: Tokenization\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\n\u003cp\u003eTokenization breaks a piece of text down into a list of tokens.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003eHere, a token is a word. (A token can be a character in some applications.)\u003c/p\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003eTokenizationËÆ≤Á©∂ÂæàÂ§öÔºå‰æãÂ¶ÇÊòØÂê¶Â∫îËØ•ÊääÂ§ßÂÜôÊîπÊàêÂ∞èÂÜôÂë¢ÔºüËøõË°åtypo correctionÁ≠âÁ≠â\u003c/p\u003e\n\u003cp\u003e\u003cimg alt=\"image-20250322150322238\" loading=\"lazy\" src=\"./NLP-2.assets/image-20250322150322238.png\"\u003e\u003c/p\u003e\n\u003cp\u003eStep2: Build Dictionary\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\n\u003cp\u003eUse a dictionary (hash table) to count word frequencies.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003eThe dictionary maps word to index.\u003c/p\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003eÂèØ‰ª•È¶ñÂÖàÁªüËÆ°ËØçÈ¢ëÂéªÊéâ‰ΩéÈ¢ëËØçÔºåÁÑ∂ÂêéËÆ©ÊØè‰∏™ËØçÂØπÂ∫î‰∏Ä‰∏™Ê≠£Êï¥Êï∞ÔºõËøôÊ†∑ÁöÑËØùÔºå‰∏ÄÂè•ËØùÂ∞±ÂèØ‰ª•Áî®‰∏Ä‰∏™Ê≠£Êï¥Êï∞ÂàóË°®Ë°®Á§∫ÔºåËøô‰∏™ÂàóË°®Â∞±Âè´sequenceÔºõÂ¶ÇÊûúÂøÖË¶ÅÂ∞±ËøòÂæóÂÅöone-hot encoding„ÄÇ\u003cimg alt=\"image-20250322150620890\" loading=\"lazy\" src=\"./NLP-2.assets/image-20250322150620890.png\"\u003e\u003c/p\u003e\n\u003cp\u003eÁªìÊûú\u003c/p\u003e\n\u003cp\u003e\u003cimg alt=\"image-20250322150754528\" loading=\"lazy\" src=\"./NLP-2.assets/image-20250322150754528.png\"\u003e\u003c/p\u003e\n\u003cp\u003e‰ΩÜÊòØÈïøÂ∫¶‰∏çÁªü‰∏Ä\u003c/p\u003e\n\u003cp\u003eStep4: ÂØπÈΩêsequence\u003c/p\u003e\n\u003cp\u003e\u003cimg alt=\"image-20250322150854986\" loading=\"lazy\" src=\"./NLP-2.assets/image-20250322150854986.png\"\u003e\u003c/p\u003e\n\u003cp\u003eËß£ÂÜ≥ÊñπÊ°àÊòØËøôÊ†∑ÁöÑÔºöÂèØ‰ª•Âõ∫ÂÆöÈïøÂ∫¶‰∏∫wÔºåÂä†ÂÖ•‰∏Ä‰∏™Â∫èÂàóÈïøÂ∫¶Â§™ÈïøÔºåÂ∞±Á†çÊéâÂâçÈù¢ÁöÑËØçÔºåÂè™‰øùÁïôÊúÄÂêéw‰∏™ËØçÔºõÂ¶ÇÊûú‰∏Ä‰∏™Â∫èÂàóÂ§™Áü≠ÔºåÂ∞±ÂÅözero paddingÔºåÁî®0Â°´ÂÖÖ\u003c/p\u003e\n\u003cp\u003e\u003cimg alt=\"image-20250322151030119\" loading=\"lazy\" src=\"./NLP-2.assets/image-20250322151030119.png\"\u003e\u003c/p\u003e\n\u003cp\u003eËøôÊ†∑‰∏ÄÊù•ÔºåÊâÄÊúâÁöÑÂ∫èÂàóÈïøÂ∫¶Â∞±Áªü‰∏Ä‰∫Ü\u003c/p\u003e\n\u003cp\u003e\u003cimg alt=\"image-20250322151117125\" loading=\"lazy\" src=\"./NLP-2.assets/image-20250322151117125.png\"\u003e\u003c/p\u003e\n\u003cp\u003eÊñáÊú¨Â§ÑÁêÜÂÆåÊàê‰∫ÜÔºåÊé•‰∏ãÊù•ÊòØword embeddingÔºåÊääÂçïËØçË°®Á§∫‰∏∫‰∏Ä‰∏™‰ΩéÁª¥ÂêëÈáèÔºõ\u003c/p\u003e\n\u003cp\u003e\u003cimg alt=\"image-20250322151252837\" loading=\"lazy\" src=\"./NLP-2.assets/image-20250322151252837.png\"\u003e\u003c/p\u003e","title":""},{"content":"üëã About me Hello! I\u0026rsquo;m Xu Zongsi, a passionate technology enthusiast currently pursuing my Master of Science in ECIC at The University of Hong Kong. With a solid background in Software Engineering from the Beijing Institute of Technology, I specialize in artificial intelligence areas like machine learning, deep learning, natural language processing, computer vision, and reinforcement learning.\nInspired by OpenAI\u0026rsquo;s five-step plan towards superintelligence, I am excited about AGI and have developed a keen interest in LLM agents, MLLM, and knowledge graphs. I see great potential in these fields and aspire to contribute to innovative solutions.\nüìö Education üá≠üá∞ The University of Hong Kong 09/2024 - Expected 11/2025 School of Computing and Data Science Master of Science in Electronic Commerce \u0026amp; Internet Computing Relevant Courses: Machine learning for business and e-commerce, Knowledge graphs, Financial fraud analytics, Internet infrastructure technologies, Website engineering, Blockchain and cryptocurrency, etc. üá®üá≥ Beijing Institute of Technology 09/2020 - 06/2024 School of Computer Science \u0026amp; Technology Bachelor of Engineering in Software Engineering, last two years GPA: 3.7/4 Relevant Courses: Reinforcement Learning, Deep Learning and Computer Vision, Artificial Intelligence and Robot Ethics, Almost Human: Mind, Brain and Artificial Intelligence, Mathematical Analysis for Engineering, Linear Algebra, Probability and Mathematical Statistics, etc. Skills: Python, Java, common data structures, design patterns, machine learning basics and algorithms, Linux, PyTorch, and some development tools (git, conda, etc.). üèÜ Awards \u0026amp; Honors Beijing Institute of Technology Undergraduate Scholarship (Top 20% of Grade) 06/2023 3rd Prize of China International \u0026#34;Internet \u0026#43;\u0026#34; College Student\u0026#39;s Innovation Competition 08/2022 Bronze Prize of \u0026#34;Challenge Cup\u0026#34; Capital University Entrepreneurship Competition 05/2022 üíº Project Experience üîç Online Transaction Fraud Detection 09/2024 ‚Äì 01/2025 Independent project, supervised by Dr. Vivien Chan Focused on addressing financial fraud in e-commerce to enhance the accuracy of transaction anomaly detection, while independently managing the entire case study that included data preprocessing, feature engineering, model building, evaluation, and results analysis. Effectively resolved class imbalance issues using SMOTE and ROSE techniques. Built various models including Logistic Regression, Random Forest, XGBoost, and LightGBM, ultimately selecting the LightGBM model to achieve a recall rate of 95.45% and an AUC of 99.84%. Wrote efficient and maintainable code, enhancing model training and data processing efficiency through parallel computing and logging. ü§ñ Multi-Model Intelligent Text Keyword Extraction System 08/2023 ‚Äì 09/2023 Group project, supervised by Associate Prof. Xiaolin Zhao Designed and implemented an intelligent text summary system that automatically extracts keywords from article titles and abstracts, enhancing the understanding and summarization of text information. Participated in the planning of the technical route and built a hybrid model combining extractive and generative approaches, utilizing advanced natural language processing techniques including KeyBERT, Sentence Transformer, BERT, and T5 models. Responsible for data preprocessing and tokenization, as well as the end-to-end implementation and training of the T5 model, optimizing the model architecture and hyperparameters, achieving satisfactory results after only 3 epochs of training. Model evaluation results showed that the Rouge-1, Rouge-2, and Rouge-L metrics reached 0.6345, 0.5038, and 0.5282, respectively, in the third epoch, validating the model\u0026rsquo;s effectiveness in the summarization task. üéì Cambridge University Machine Learning Summer Project 07/2023 ‚Äì 08/2023 Group project, supervised by Prof. Pietro Li√≤ Participated in the Cambridge University deep learning summer project, focusing on deep reinforcement learning; explored multi-agent learning algorithms across different environments. Reproduced the Multi-Agent Deep Deterministic Policy Gradient (MADDPG) algorithm in the Simple Adversary environment and studied the effect of agent numbers on convergence speed and stability, finding optimal stability at 21 agents. Designed and implemented comparative experiments inspired by the Rainbow algorithm, assessing target network strategies versus the Double Deep Q-Network (Double DQN). The results demonstrated that Double DQN significantly enhanced convergence speed, optimizing the overall learning process. Co-authored a group project paper on agent numbers and strategies effectiveness in multi-agent systems, achieving a score of 71% in the summer program (the highest in my group) and a \u0026ldquo;First Class\u0026rdquo; classification in the UK grading system. üëÅÔ∏è Deep Learning and Computer Vision Semester Project 09/2022 ‚Äì 12/2022 Independent project, supervised by Associate Prof. Guangyu Gao Designed and implemented a waste classifier using the ResNet model to improve classification accuracy and reduce resource waste. The project also enhanced understanding of transfer learning techniques with ResNet. Collected a dataset of 16 waste categories and preprocessed the images for uniformity and standardization, incorporating data augmentation techniques to enhance the dataset. Conducted experiments using ResNet34 and ResNet50 models through transfer learning, accelerating network convergence by leveraging pretrained weights. During training, techniques such as Batch Normalization and Dropout were applied to mitigate the risk of overfitting. The final model achieved an accuracy of 90% on the training set, while the performance on the test set was 61%, indicating a significant overfitting phenomenon during the training process. üéì Internship ‚öõÔ∏è Beijing Academy of Quantum Information Science 08/2023 ‚Äì 01/2024 Research Intern at Quantum Computation Department Proposed a quantum convolution kernel design based on variational quantum circuits and developed a universal quantum convolution layer, successfully integrating it into classical CNN architectures such as VGG, GoogLeNet, and ResNet. Developed and evaluated various hybrid models, including a simple model named HQCCNN-2, which achieved 84.45% accuracy on the FashionMNIST dataset, surpassing the traditional CNN\u0026rsquo;s 80.72%. This demonstrates the effectiveness of the quantum convolution layer in improving model performance. Tested on a real quantum computer further validated the effectiveness of the hybrid model, demonstrating the viable integration of quantum computing with deep learning, and highlighting the potential for leveraging quantum properties to enhance model performance. üèÖ Competition Experience ü•â China International \u0026#34;Internet \u0026#43;\u0026#34; College Students\u0026#39; Innovation Competition 08/2022 üõ°Ô∏è Zhongke Ushield: Deep Learning-based Face Privacy Protection Authentication System Responsible for constructing a localized facial feature extraction engine based on MobileFaceNet, ensuring feature extraction is completed on end devices (such as mobile phones and cameras), guaranteeing that raw data does not leave the domain and is not stored, thus enhancing user privacy protection while improving recognition efficiency. ü•â \u0026#34;Challenge Cup\u0026#34; Capital University Entrepreneurship Competition 05/2022 üå≥ Smart Orchard Responsible for the development of the fruit detection, ripeness prediction, and pest identification system, using deep convolutional neural network (CNN) technology for intelligent monitoring of crop growth conditions. Applied advanced object detection algorithms such as Faster R-CNN and YOLO to achieve high precision in apple detection and ripeness assessment, with an accuracy rate exceeding 90%, significantly enhancing the intelligence level of orchard management. Built and trained a dedicated dataset containing various pest samples, optimizing pest detection accuracy through data preprocessing (such as image normalization and resizing) and data augmentation techniques (like rotation, flipping, and noise addition), enabling the real-time monitoring system to accurately identify over 80% of pests, providing effective scientific maintenance recommendations to help farmers reduce crop losses. üìã Extracurricular Activities Vice President, Cyber Security Club, Beijing Institute of Technology 09/2021-09/2022 Backbone, Media Center of the Student Union of Beijing Institute of Technology 10/2020-06/2021 üì´ Contact üìß Email: zongsi.xu@outlook.com üëî LinkedIn: Zongsi (Tristan) Xu üíª GitHub: github.com/BaizeXS üìç Location: Hong Kong SAR, China ","permalink":"http://localhost:1313/resume/","summary":"Personal resume of Zongsi (Tristan) Xu","title":"Zongsi (Tristan) Xu"},{"content":"‰∏Ä„ÄÅÊï∞ÂÄºÁâπÂæÅ‰∏éÁ±ªÂà´ÁâπÂæÅ Êï∞ÂÄºÁâπÂæÅ (Numeric Features) ÂÖ∑ÊúâÂèØÂä†ÂáèÁöÑÊÑè‰πâÔºå‰∏îÂ≠òÂú®Â§ßÂ∞èÈ°∫Â∫è„ÄÇ ‰æãÂ≠êÔºöÂπ¥ÈæÑ„ÄÅÊ∏©Â∫¶Á≠â„ÄÇÂèØ‰ª•Áõ¥Êé•‰øùÁïôÂÖ∂Êï¥Êï∞ÊàñÊµÆÁÇπÊï∞ÂΩ¢Âºè‰æõÊ®°Âûã‰ΩøÁî®„ÄÇ Á±ªÂà´ÁâπÂæÅ (Categorical Features) Êï∞ÊçÆÂÄºÁ¶ªÊï£Ôºå‰∏çÂÖ∑Â§á‚ÄúÊï∞ÂÄºÂ§ßÂ∞è‚ÄùÈó¥ÁöÑÂèØÊØîÊÑè‰πâ„ÄÇ ‰æãÂ≠êÔºöÂõΩÁ±çÔºàÁæéÂõΩ/‰∏≠ÂõΩ/Âç∞Â∫¶Á≠âÔºâ„ÄÅÊÄßÂà´ÔºàÁî∑/Â•≥ÔºâÁ≠â„ÄÇ ÈóÆÈ¢òÔºöËã•‰ªÖÁî®Êï¥Êï∞Ë°®Á§∫ÔºàÁæéÂõΩ=1, ‰∏≠ÂõΩ=2ÔºâÔºå‰ºöÂºïÂÖ•ÈîôËØØÁöÑÊï∞ÂÄºËøêÁÆóÂÖ≥Á≥ªÔºåÂ¶Ç ‚ÄúÁæéÂõΩ + ‰∏≠ÂõΩ = Âç∞Â∫¶‚Äù„ÄÇ ‰∫å„ÄÅOne-HotÁºñÁ†ÅÁöÑÂä®Êú∫‰∏éÊµÅÁ®ã ‰∏∫‰ªÄ‰πà‰ΩøÁî®One-Hot\nÈÄöËøáÂ∞ÜÁ±ªÂà´Êò†Â∞Ñ‰∏∫ÂêëÈáèÔºåÈÅøÂÖçÊï¥Êï∞ÁºñÁ†ÅÂºïÂÖ•ÁöÑ‰º™Êï∞ÂÄºÂÖ≥Á≥ª„ÄÇ ÂêåÊó∂‰øùÁïôÂêÑÁßçÂèØËÉΩÁ±ªÂà´ÁöÑ‰ø°ÊÅØÔºå‰∏î‰ªÖÂú®ÂØπÂ∫î‰ΩçÁΩÆ‰∏∫1ÔºåÂÖ∂‰ªñ‰ΩçÁΩÆ‰∏∫0„ÄÇ Âª∫Á´ãÊò†Â∞ÑÔºö‰ªéÁ±ªÂà´Âà∞Á¥¢Âºï\n‰∏∫ÊØè‰∏™Á±ªÂà´ÂàÜÈÖç‰∏Ä‰∏™ÂîØ‰∏ÄÁ¥¢ÂºïÔºåÈÄöÂ∏∏‰ªé1ÂºÄÂßã„ÄÇ È¢ÑÁïôÁ¥¢Âºï0Ë°®Á§∫‚ÄúÊú™Áü•‚ÄùÊàñ‚ÄúÁº∫Â§±‚ÄùÔºåÂØπÂ∫îÂÖ®0ÂêëÈáè„ÄÇ ËΩ¨Êç¢‰∏∫One-HotÂêëÈáè\nËã•Á±ªÂà´ÊÄªÊï∞‰∏∫197ÔºåÂàôÁî®197Áª¥ÂêëÈáèË°®Á§∫„ÄÇ ‰æãÂ≠êÔºöÁæéÂõΩ [1, 0, 0, 0, ‚Ä¶]Ôºå ‰∏≠ÂõΩ [0, 1, 0, 0, ‚Ä¶]„ÄÇ Á§∫‰æãÔºöË°®Á§∫‰∏Ä‰∏™‰∫∫ÁöÑÁâπÂæÅ\nÁâπÂæÅÂåÖÂê´ÔºàÂπ¥ÈæÑ, ÊÄßÂà´, ÂõΩÁ±çÔºåÂÖ∂‰∏≠ÂõΩÁ±ç197ÁßçÔºâ Áª¥Â∫¶ÊÄªÂíåÔºö1Áª¥_age + 1Áª¥_gender + 197Áª¥_nationality = 199Áª¥„ÄÇ ‰æãÂ¶Ç (28, Â•≥, ‰∏≠ÂõΩ) ‚Üí [28, 0, 0, 1, 0, ‚Ä¶, 0]„ÄÇ ‰∏â„ÄÅÊñáÊú¨Êï∞ÊçÆÂ§ÑÁêÜÊµÅÁ®ã ÊñáÊú¨Âú®Ëá™ÁÑ∂ËØ≠Ë®ÄÂ§ÑÁêÜÔºàNLPÔºâ‰∏≠‰Ωú‰∏∫Â∏∏ËßÅÁöÑÂéüÂßãËæìÂÖ•ÔºåÈúÄË¶ÅÊï∞ÂÄºÂåñÊâçËÉΩÈÄÅÂÖ•Ê®°Âûã„ÄÇ‰∏ÄËà¨Ê≠•È™§Â¶Ç‰∏ãÔºö\nÂàÜËØç (Tokenization)\nÂ∞ÜÊñáÊú¨ÊãÜÂàÜ‰∏∫‰∏Ä‰∏™‰∏™ÂçïËØçÔºàTokenÔºâ„ÄÇ ‰æãÂ≠êÔºö\u0026quot;... to be or not to be...\u0026quot; ‚Üí [\u0026quot;...\u0026quot;, \u0026quot;to\u0026quot;, \u0026quot;be\u0026quot;, \u0026quot;or\u0026quot;, \u0026quot;not\u0026quot;, \u0026quot;to\u0026quot;, \u0026quot;be\u0026quot;, \u0026quot;...\u0026quot;]„ÄÇ ÁªüËÆ°ËØçÈ¢ë \u0026amp; ÊûÑÂª∫ËØçÂÖ∏\nËØçÈ¢ëÁªüËÆ° Áî®ÂìàÂ∏åË°®/Â≠óÂÖ∏ËÆ∞ÂΩïÊØè‰∏™ÂçïËØçÂá∫Áé∞Ê¨°Êï∞„ÄÇ ÈÅçÂéÜÊñáÊú¨Êó∂ÔºåËã•ÂçïËØçÂ∞öÊú™ÂÖ•Ë°®ÔºåÂàôÊñ∞Âª∫ËÆ∞ÂΩïÔºõËã•Â∑≤Â≠òÂú®ÔºåÂàôËÆ°Êï∞+1„ÄÇ ÊéíÂ∫è‰∏éÁ¥¢Âºï ÊåâËØçÈ¢ëÈôçÂ∫èÊéíÂ∫èÔºåËØçÈ¢ëÊúÄÈ´òÁöÑÂçïËØçÊéíÂú®ÂâçÈù¢„ÄÇ Á¥¢Âºï‰ªé1ÂºÄÂßãÔºå0ÁïôÁªô‚ÄúÊú™Áü•‚Äù„ÄÇ ËØçÂÖ∏ËßÑÊ®°ÔºàvocabularyÔºâÂèØËßÜÈúÄÊ±ÇÊà™Êñ≠Ôºà‰æãÂ¶ÇÂè™‰øùÁïôTop 10kÔºâ„ÄÇ ‰∏∫‰ªÄ‰πàÁßªÈô§‰ΩéÈ¢ëËØç ‰ΩéÈ¢ëËØçÂèØËÉΩÊòØÊãºÂÜôÈîôËØØ„ÄÅÁΩïËßÅ‰∫∫ÂêçÁ≠âÔºåÂØπÊ®°ÂûãÂ∏ÆÂä©ÊúâÈôê„ÄÇ ÂáèÂ∞ëËØçÂÖ∏ËßÑÊ®°ÂèØÈôç‰ΩéËøêÁÆóÂºÄÈîÄ„ÄÅÂä†Âø´Ê®°ÂûãËÆ≠ÁªÉ‰∏éÊé®ÁêÜÈÄüÂ∫¶„ÄÇ Áã¨ÁÉ≠ÁºñÁ†Å (One-Hot Encoding)\nÂ∞ÜÊØè‰∏™ÂçïËØçÊò†Â∞Ñ‰∏∫ËØçÂÖ∏‰∏≠ÁöÑÁ¥¢ÂºïÂêéÔºàÂ¶Ç [2, 4, 1, 8, ‚Ä¶]ÔºâÔºåÂèØËøõ‰∏ÄÊ≠•ËΩ¨Êç¢ÊàêOne-HotÂêëÈáè„ÄÇ One-HotÁª¥Â∫¶ÂèñÂÜ≥‰∫é‰øùÁïô‰∏ãÊù•ÁöÑËØçÂÖ∏Â§ßÂ∞èÔºà‰æãÂ¶Ç1‰∏áÔºâ„ÄÇ Êú™Êî∂ÂΩïÂçïËØçÂèØËÉΩÁõ¥Êé•ÂøΩÁï•ÔºåÊàñÁªü‰∏ÄÁî®Á¥¢Âºï0‰ª£Êõø„ÄÇ Âõõ„ÄÅÊ†∏ÂøÉÊî∂Ëé∑‰∏éÂ∫îÁî® Á±ªÂà´ÁâπÂæÅÂøÖÈúÄÊï∞ÂÄºÂåñÔºö\n‰ΩøÁî®Êï¥Êï∞1,2,3‚Ä¶‰ªÖË°®Á§∫Á±ªÂà´‚ÄúÊ†áËØÜ‚ÄùÔºåÂπ∂‰∏ç‰ª£Ë°®ÂÆÉ‰ª¨ÂèØËøõË°åÊï∞ÂÄºËøêÁÆó„ÄÇ Âõ†Ê≠§ÈúÄË¶ÅOne-HotÁ≠âÁºñÁ†ÅÊñπÂºèÔºåÈÅøÂÖçÊï∞ÂÄºËØØËß£„ÄÇ ÊñáÊú¨Êï∞ÊçÆÈ¢ÑÂ§ÑÁêÜÔºö\nÂàÜËØç„ÄÅËØçÈ¢ëÁªüËÆ°„ÄÅÊûÑÂª∫ËØçÂÖ∏„ÄÅÁ¥¢ÂºïÂåñ„ÄÅOne-HotÊàñÂÖ∂‰ªñÊñπÂºèÔºàÂ¶ÇËØçÂµåÂÖ•ÔºâÊòØÂ∏∏ËßÅÊµÅÁ®ã„ÄÇ Ê≠£Á°ÆÁöÑÊñáÊú¨È¢ÑÂ§ÑÁêÜÂèØÊòæËëóÂΩ±ÂìçÊ®°ÂûãÊÄßËÉΩÂíåÊïàÁéá„ÄÇ ‰øùÁïôÊú™Áü•Á¥¢ÂºïÔºö\n‰øùËØÅÂØπÁº∫Â§±Êï∞ÊçÆÊàñÂ≠óÂÖ∏Â§ñÊñ∞ËØçËÉΩÊúâÂü∫Êú¨ÁöÑË°®Á§∫ÔºåÊèêÂçáÊ®°ÂûãÂÆπÈîôÊÄß„ÄÇ ÂÆûÈôÖ‰ΩøÁî®Ôºö\nÂØπ‰∫éÂ∞èËßÑÊ®°Á±ªÂà´ÂèØÁõ¥Êé•One-HotÁºñÁ†ÅÔºõÂØπ‰∫éËØçÂÖ∏ÂæàÂ§ßÁöÑÂú∫ÊôØÔºåÈÄöÂ∏∏‰ºöËøõ‰∏ÄÊ≠•ËÄÉËôëËØçÂµåÂÖ•ÔºàWord EmbeddingÔºâÊàñÈ¢ÑËÆ≠ÁªÉËØ≠Ë®ÄÊ®°Âûã„ÄÇ ","permalink":"http://localhost:1313/posts/nlp-1/","summary":"\u003ch2 id=\"‰∏ÄÊï∞ÂÄºÁâπÂæÅ‰∏éÁ±ªÂà´ÁâπÂæÅ\"\u003e‰∏Ä„ÄÅÊï∞ÂÄºÁâπÂæÅ‰∏éÁ±ªÂà´ÁâπÂæÅ\u003c/h2\u003e\n\u003col\u003e\n\u003cli\u003e\u003cstrong\u003eÊï∞ÂÄºÁâπÂæÅ (Numeric Features)\u003c/strong\u003e\n\u003cul\u003e\n\u003cli\u003eÂÖ∑ÊúâÂèØÂä†ÂáèÁöÑÊÑè‰πâÔºå‰∏îÂ≠òÂú®Â§ßÂ∞èÈ°∫Â∫è„ÄÇ\u003c/li\u003e\n\u003cli\u003e‰æãÂ≠êÔºöÂπ¥ÈæÑ„ÄÅÊ∏©Â∫¶Á≠â„ÄÇÂèØ‰ª•Áõ¥Êé•‰øùÁïôÂÖ∂Êï¥Êï∞ÊàñÊµÆÁÇπÊï∞ÂΩ¢Âºè‰æõÊ®°Âûã‰ΩøÁî®„ÄÇ\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003eÁ±ªÂà´ÁâπÂæÅ (Categorical Features)\u003c/strong\u003e\n\u003cul\u003e\n\u003cli\u003eÊï∞ÊçÆÂÄºÁ¶ªÊï£Ôºå‰∏çÂÖ∑Â§á‚ÄúÊï∞ÂÄºÂ§ßÂ∞è‚ÄùÈó¥ÁöÑÂèØÊØîÊÑè‰πâ„ÄÇ\u003c/li\u003e\n\u003cli\u003e‰æãÂ≠êÔºöÂõΩÁ±çÔºàÁæéÂõΩ/‰∏≠ÂõΩ/Âç∞Â∫¶Á≠âÔºâ„ÄÅÊÄßÂà´ÔºàÁî∑/Â•≥ÔºâÁ≠â„ÄÇ\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003eÈóÆÈ¢ò\u003c/strong\u003eÔºöËã•‰ªÖÁî®Êï¥Êï∞Ë°®Á§∫ÔºàÁæéÂõΩ=1, ‰∏≠ÂõΩ=2ÔºâÔºå‰ºöÂºïÂÖ•ÈîôËØØÁöÑÊï∞ÂÄºËøêÁÆóÂÖ≥Á≥ªÔºåÂ¶Ç ‚ÄúÁæéÂõΩ + ‰∏≠ÂõΩ = Âç∞Â∫¶‚Äù„ÄÇ\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003c/ol\u003e\n\u003ch2 id=\"‰∫åone-hotÁºñÁ†ÅÁöÑÂä®Êú∫‰∏éÊµÅÁ®ã\"\u003e‰∫å„ÄÅOne-HotÁºñÁ†ÅÁöÑÂä®Êú∫‰∏éÊµÅÁ®ã\u003c/h2\u003e\n\u003col\u003e\n\u003cli\u003e\n\u003cp\u003e\u003cstrong\u003e‰∏∫‰ªÄ‰πà‰ΩøÁî®One-Hot\u003c/strong\u003e\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eÈÄöËøáÂ∞ÜÁ±ªÂà´Êò†Â∞Ñ‰∏∫ÂêëÈáèÔºåÈÅøÂÖçÊï¥Êï∞ÁºñÁ†ÅÂºïÂÖ•ÁöÑ‰º™Êï∞ÂÄºÂÖ≥Á≥ª„ÄÇ\u003c/li\u003e\n\u003cli\u003eÂêåÊó∂‰øùÁïôÂêÑÁßçÂèØËÉΩÁ±ªÂà´ÁöÑ‰ø°ÊÅØÔºå‰∏î‰ªÖÂú®ÂØπÂ∫î‰ΩçÁΩÆ‰∏∫1ÔºåÂÖ∂‰ªñ‰ΩçÁΩÆ‰∏∫0„ÄÇ\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003e\u003cstrong\u003eÂª∫Á´ãÊò†Â∞ÑÔºö‰ªéÁ±ªÂà´Âà∞Á¥¢Âºï\u003c/strong\u003e\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e‰∏∫ÊØè‰∏™Á±ªÂà´ÂàÜÈÖç‰∏Ä‰∏™ÂîØ‰∏ÄÁ¥¢ÂºïÔºåÈÄöÂ∏∏‰ªé1ÂºÄÂßã„ÄÇ\u003c/li\u003e\n\u003cli\u003eÈ¢ÑÁïôÁ¥¢Âºï0Ë°®Á§∫‚ÄúÊú™Áü•‚ÄùÊàñ‚ÄúÁº∫Â§±‚ÄùÔºåÂØπÂ∫îÂÖ®0ÂêëÈáè„ÄÇ\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003e\u003cstrong\u003eËΩ¨Êç¢‰∏∫One-HotÂêëÈáè\u003c/strong\u003e\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eËã•Á±ªÂà´ÊÄªÊï∞‰∏∫197ÔºåÂàôÁî®197Áª¥ÂêëÈáèË°®Á§∫„ÄÇ\u003c/li\u003e\n\u003cli\u003e‰æãÂ≠êÔºöÁæéÂõΩ \u003ccode\u003e[1, 0, 0, 0, ‚Ä¶]\u003c/code\u003eÔºå ‰∏≠ÂõΩ \u003ccode\u003e[0, 1, 0, 0, ‚Ä¶]\u003c/code\u003e„ÄÇ\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003e\u003cstrong\u003eÁ§∫‰æãÔºöË°®Á§∫‰∏Ä‰∏™‰∫∫ÁöÑÁâπÂæÅ\u003c/strong\u003e\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eÁâπÂæÅÂåÖÂê´ÔºàÂπ¥ÈæÑ, ÊÄßÂà´, ÂõΩÁ±çÔºåÂÖ∂‰∏≠ÂõΩÁ±ç197ÁßçÔºâ\u003c/li\u003e\n\u003cli\u003eÁª¥Â∫¶ÊÄªÂíåÔºö1Áª¥_age + 1Áª¥_gender + 197Áª¥_nationality = 199Áª¥„ÄÇ\u003c/li\u003e\n\u003cli\u003e‰æãÂ¶Ç \u003ccode\u003e(28, Â•≥, ‰∏≠ÂõΩ)\u003c/code\u003e ‚Üí \u003ccode\u003e[28, 0, 0, 1, 0, ‚Ä¶, 0]\u003c/code\u003e„ÄÇ\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003c/ol\u003e\n\u003ch2 id=\"‰∏âÊñáÊú¨Êï∞ÊçÆÂ§ÑÁêÜÊµÅÁ®ã\"\u003e‰∏â„ÄÅÊñáÊú¨Êï∞ÊçÆÂ§ÑÁêÜÊµÅÁ®ã\u003c/h2\u003e\n\u003cp\u003eÊñáÊú¨Âú®Ëá™ÁÑ∂ËØ≠Ë®ÄÂ§ÑÁêÜÔºàNLPÔºâ‰∏≠‰Ωú‰∏∫Â∏∏ËßÅÁöÑÂéüÂßãËæìÂÖ•ÔºåÈúÄË¶ÅÊï∞ÂÄºÂåñÊâçËÉΩÈÄÅÂÖ•Ê®°Âûã„ÄÇ‰∏ÄËà¨Ê≠•È™§Â¶Ç‰∏ãÔºö\u003c/p\u003e\n\u003col\u003e\n\u003cli\u003e\n\u003cp\u003e\u003cstrong\u003eÂàÜËØç (Tokenization)\u003c/strong\u003e\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eÂ∞ÜÊñáÊú¨ÊãÜÂàÜ‰∏∫‰∏Ä‰∏™‰∏™ÂçïËØçÔºàTokenÔºâ„ÄÇ\u003c/li\u003e\n\u003cli\u003e‰æãÂ≠êÔºö\u003ccode\u003e\u0026quot;... to be or not to be...\u0026quot;\u003c/code\u003e ‚Üí \u003ccode\u003e[\u0026quot;...\u0026quot;, \u0026quot;to\u0026quot;, \u0026quot;be\u0026quot;, \u0026quot;or\u0026quot;, \u0026quot;not\u0026quot;, \u0026quot;to\u0026quot;, \u0026quot;be\u0026quot;, \u0026quot;...\u0026quot;]\u003c/code\u003e„ÄÇ\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003e\u003cstrong\u003eÁªüËÆ°ËØçÈ¢ë \u0026amp; ÊûÑÂª∫ËØçÂÖ∏\u003c/strong\u003e\u003c/p\u003e","title":""},{"content":"Text to Sequence ÊñáÊú¨Â§ÑÁêÜ\nStep1: Tokenization\nTokenization breaks a piece of text down into a list of tokens.\nHere, a token is a word. (A token can be a character in some applications.)\nTokenizationËÆ≤Á©∂ÂæàÂ§öÔºå‰æãÂ¶ÇÊòØÂê¶Â∫îËØ•ÊääÂ§ßÂÜôÊîπÊàêÂ∞èÂÜôÂë¢ÔºüËøõË°åtypo correctionÁ≠âÁ≠â\nStep2: Build Dictionary\nUse a dictionary (hash table) to count word frequencies.\nThe dictionary maps word to index.\nÂèØ‰ª•È¶ñÂÖàÁªüËÆ°ËØçÈ¢ëÂéªÊéâ‰ΩéÈ¢ëËØçÔºåÁÑ∂ÂêéËÆ©ÊØè‰∏™ËØçÂØπÂ∫î‰∏Ä‰∏™Ê≠£Êï¥Êï∞ÔºõËøôÊ†∑ÁöÑËØùÔºå‰∏ÄÂè•ËØùÂ∞±ÂèØ‰ª•Áî®‰∏Ä‰∏™Ê≠£Êï¥Êï∞ÂàóË°®Ë°®Á§∫ÔºåËøô‰∏™ÂàóË°®Â∞±Âè´sequenceÔºõÂ¶ÇÊûúÂøÖË¶ÅÂ∞±ËøòÂæóÂÅöone-hot encoding„ÄÇ\nÁªìÊûú\n‰ΩÜÊòØÈïøÂ∫¶‰∏çÁªü‰∏Ä\nStep4: ÂØπÈΩêsequence\nËß£ÂÜ≥ÊñπÊ°àÊòØËøôÊ†∑ÁöÑÔºöÂèØ‰ª•Âõ∫ÂÆöÈïøÂ∫¶‰∏∫wÔºåÂä†ÂÖ•‰∏Ä‰∏™Â∫èÂàóÈïøÂ∫¶Â§™ÈïøÔºåÂ∞±Á†çÊéâÂâçÈù¢ÁöÑËØçÔºåÂè™‰øùÁïôÊúÄÂêéw‰∏™ËØçÔºõÂ¶ÇÊûú‰∏Ä‰∏™Â∫èÂàóÂ§™Áü≠ÔºåÂ∞±ÂÅözero paddingÔºåÁî®0Â°´ÂÖÖ\nËøôÊ†∑‰∏ÄÊù•ÔºåÊâÄÊúâÁöÑÂ∫èÂàóÈïøÂ∫¶Â∞±Áªü‰∏Ä‰∫Ü\nÊñáÊú¨Â§ÑÁêÜÂÆåÊàê‰∫ÜÔºåÊé•‰∏ãÊù•ÊòØword embeddingÔºåÊääÂçïËØçË°®Á§∫‰∏∫‰∏Ä‰∏™‰ΩéÁª¥ÂêëÈáèÔºõ\nÁÑ∂ËÄåËøôÊ†∑ÂÅöÁöÑËØùÔºåÂ¶ÇÊûúÊòØ10000‰∏™ÂçïËØçÔºåÁª¥Â∫¶Â∞±ÊòØ10000Áª¥ÔºåÁª¥Â∫¶Â§™È´ò‰∫ÜÔºõÂõ†Ê≠§Ë¶ÅÂÅöword embeddingÔºõ\nÂÖ∑‰ΩìÂÅöÊ≥ïÂ∞±ÊòØÊääone-hotÂêëÈáèe_iÂíåÂèÇÊï∞Áü©ÈòµpÁõ∏‰πòÔºõÁü©ÈòµPËΩ¨ÁΩÆÁöÑÂ§ßÂ∞èÊòØd x vÔºõdÊòØËØçÂêëÈáèÁöÑÁª¥Â∫¶ÔºõvÊòØÂ≠óÂÖ∏ÈáåËØçÊ±áÁöÑÊï∞ÈáèÔºõÁªìÊûú‰∏∫x_iÔºõx_iÂ∞±ÊòØ‰∏Ä‰∏™ËØçÂêëÈáèÔºõÂ¶ÇÊûúone-hotÂêëÈáèÁöÑÁ¨¨‰∏âË°å‰∏∫1ÔºõÈÇ£‰πàx_iÂ∞±ÊòØPËΩ¨ÁΩÆÁü©ÈòµÁöÑÁ¨¨‰∏âÂàóÔºàÂÖ∂‰ΩôÂàóÈÉΩ‰∏∫0ÔºâÔºõÊâÄ‰ª•PËΩ¨ÁΩÆÊØè‰∏ÄÂàóÈÉΩÊòØ‰∏Ä‰∏™ËØçÂêëÈáèÔºõÊâÄ‰ª•Áü©ÈòµPÊú¨Ë∫´ÁöÑÊØè‰∏ÄË°åÂ∞±ÊòØ‰∏Ä‰∏™ËØçÂêëÈáèÔºõÂÖ∂Ë°åÊï∞‰∏∫vÔºõÂç≥vocabularyÔºåËØçÊ±áÈáèÔºõÊØè‰∏ÄË°åÂØπÂ∫î‰∏Ä‰∏™ÂçïËØçÔºõÁü©ÈòµÁöÑÂàóÊï∞‰∏∫dÔºõdÊòØÁî®Êà∑ÂÜ≥ÂÆöÁöÑÔºõdÁöÑÂ§ßÂ∞è‰ºöÂÜ≥ÂÆöÊú∫Âô®Â≠¶‰π†Ê®°ÂûãÁöÑË°®Áé∞ÔºõÂ∫îËØ•Áî®xxxÊù•ÈÄâÊã©‰∏Ä‰∏™ÊØîËæÉÂ•ΩÁöÑdÔºõ\nÊàë‰ª¨ÁöÑ‰ªªÂä°ÊòØÁúãËØÑËÆ∫ÊòØÊ≠£Èù¢ÁöÑËøòÊòØË¥üÈù¢ÁöÑÔºõÂèÇÊï∞Áü©ÈòµÊòØ‰ªéËÆ≠ÁªÉÊï∞ÊçÆ‰∏≠Â≠¶‰π†Âá∫Êù•ÁöÑÔºåÊâÄ‰ª•Â≠¶Âá∫Êù•ÁöÑËØçÂêëÈáèÊòØÂ∏¶ÊúâÊÑüÊÉÖËâ≤ÂΩ©ÁöÑÔºõÂÅáËÆæËøô‰∫õËØçÂêëÈáèÈÉΩÊòØ‰∫åÁª¥ÁöÑÔºåÂàôÂèØ‰ª•Âú®Âπ≥Èù¢ÂùêÊ†áÁ≥ª‰∏≠Ê†áÂá∫‰∏ãÈù¢ËØçÂêëÈáè\nkerasÊèê‰æõembeddingÂ±ÇÔºõÁî®Êà∑ÂèØ‰ª•ÊåáÂÆövocabularyÂ§ßÂ∞èÂíådÁöÑÂ§ßÂ∞èÔºõ‰ª•ÂèäÊØè‰∏Ä‰∏™sequenceÁöÑÈïøÂ∫¶ÔºõdÊòØÊ†πÊçÆÁÆóÊ≥ïÈÄâÂá∫Êù•ÁöÑ Âà∞Ëøô‰∏ÄÊ≠•ÔºåÊàë‰ª¨Â∑≤ÁªèÂÆåÊàê‰∫ÜÊñáÊú¨Â§ÑÁêÜÂíåword embedding„ÄÇÊé•‰∏ãÊù•Â∞±ÊòØÁî®Logistic Regression for Binary ClassificationÂÅö‰∫åÂàÜÁ±ªÔºõ\n","permalink":"http://localhost:1313/posts/nlp-2/","summary":"\u003ch3 id=\"text-to-sequence\"\u003eText to Sequence\u003c/h3\u003e\n\u003cp\u003eÊñáÊú¨Â§ÑÁêÜ\u003c/p\u003e\n\u003cp\u003eStep1: Tokenization\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\n\u003cp\u003eTokenization breaks a piece of text down into a list of tokens.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003eHere, a token is a word. (A token can be a character in some applications.)\u003c/p\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003eTokenizationËÆ≤Á©∂ÂæàÂ§öÔºå‰æãÂ¶ÇÊòØÂê¶Â∫îËØ•ÊääÂ§ßÂÜôÊîπÊàêÂ∞èÂÜôÂë¢ÔºüËøõË°åtypo correctionÁ≠âÁ≠â\u003c/p\u003e\n\u003cp\u003e\u003cimg alt=\"image-20250322150322238\" loading=\"lazy\" src=\"./NLP-2.assets/image-20250322150322238.png\"\u003e\u003c/p\u003e\n\u003cp\u003eStep2: Build Dictionary\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\n\u003cp\u003eUse a dictionary (hash table) to count word frequencies.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003eThe dictionary maps word to index.\u003c/p\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003eÂèØ‰ª•È¶ñÂÖàÁªüËÆ°ËØçÈ¢ëÂéªÊéâ‰ΩéÈ¢ëËØçÔºåÁÑ∂ÂêéËÆ©ÊØè‰∏™ËØçÂØπÂ∫î‰∏Ä‰∏™Ê≠£Êï¥Êï∞ÔºõËøôÊ†∑ÁöÑËØùÔºå‰∏ÄÂè•ËØùÂ∞±ÂèØ‰ª•Áî®‰∏Ä‰∏™Ê≠£Êï¥Êï∞ÂàóË°®Ë°®Á§∫ÔºåËøô‰∏™ÂàóË°®Â∞±Âè´sequenceÔºõÂ¶ÇÊûúÂøÖË¶ÅÂ∞±ËøòÂæóÂÅöone-hot encoding„ÄÇ\u003cimg alt=\"image-20250322150620890\" loading=\"lazy\" src=\"./NLP-2.assets/image-20250322150620890.png\"\u003e\u003c/p\u003e\n\u003cp\u003eÁªìÊûú\u003c/p\u003e\n\u003cp\u003e\u003cimg alt=\"image-20250322150754528\" loading=\"lazy\" src=\"./NLP-2.assets/image-20250322150754528.png\"\u003e\u003c/p\u003e\n\u003cp\u003e‰ΩÜÊòØÈïøÂ∫¶‰∏çÁªü‰∏Ä\u003c/p\u003e\n\u003cp\u003eStep4: ÂØπÈΩêsequence\u003c/p\u003e\n\u003cp\u003e\u003cimg alt=\"image-20250322150854986\" loading=\"lazy\" src=\"./NLP-2.assets/image-20250322150854986.png\"\u003e\u003c/p\u003e\n\u003cp\u003eËß£ÂÜ≥ÊñπÊ°àÊòØËøôÊ†∑ÁöÑÔºöÂèØ‰ª•Âõ∫ÂÆöÈïøÂ∫¶‰∏∫wÔºåÂä†ÂÖ•‰∏Ä‰∏™Â∫èÂàóÈïøÂ∫¶Â§™ÈïøÔºåÂ∞±Á†çÊéâÂâçÈù¢ÁöÑËØçÔºåÂè™‰øùÁïôÊúÄÂêéw‰∏™ËØçÔºõÂ¶ÇÊûú‰∏Ä‰∏™Â∫èÂàóÂ§™Áü≠ÔºåÂ∞±ÂÅözero paddingÔºåÁî®0Â°´ÂÖÖ\u003c/p\u003e\n\u003cp\u003e\u003cimg alt=\"image-20250322151030119\" loading=\"lazy\" src=\"./NLP-2.assets/image-20250322151030119.png\"\u003e\u003c/p\u003e\n\u003cp\u003eËøôÊ†∑‰∏ÄÊù•ÔºåÊâÄÊúâÁöÑÂ∫èÂàóÈïøÂ∫¶Â∞±Áªü‰∏Ä‰∫Ü\u003c/p\u003e\n\u003cp\u003e\u003cimg alt=\"image-20250322151117125\" loading=\"lazy\" src=\"./NLP-2.assets/image-20250322151117125.png\"\u003e\u003c/p\u003e\n\u003cp\u003eÊñáÊú¨Â§ÑÁêÜÂÆåÊàê‰∫ÜÔºåÊé•‰∏ãÊù•ÊòØword embeddingÔºåÊääÂçïËØçË°®Á§∫‰∏∫‰∏Ä‰∏™‰ΩéÁª¥ÂêëÈáèÔºõ\u003c/p\u003e\n\u003cp\u003e\u003cimg alt=\"image-20250322151252837\" loading=\"lazy\" src=\"./NLP-2.assets/image-20250322151252837.png\"\u003e\u003c/p\u003e","title":""},{"content":"üëã About me Hello! I\u0026rsquo;m Xu Zongsi, a passionate technology enthusiast currently pursuing my Master of Science in ECIC at The University of Hong Kong. With a solid background in Software Engineering from the Beijing Institute of Technology, I specialize in artificial intelligence areas like machine learning, deep learning, natural language processing, computer vision, and reinforcement learning.\nInspired by OpenAI\u0026rsquo;s five-step plan towards superintelligence, I am excited about AGI and have developed a keen interest in LLM agents, MLLM, and knowledge graphs. I see great potential in these fields and aspire to contribute to innovative solutions.\nüìö Education üá≠üá∞ The University of Hong Kong 09/2024 - Expected 11/2025 School of Computing and Data Science Master of Science in Electronic Commerce \u0026amp; Internet Computing Relevant Courses: Machine learning for business and e-commerce, Knowledge graphs, Financial fraud analytics, Internet infrastructure technologies, Website engineering, Blockchain and cryptocurrency, etc. üá®üá≥ Beijing Institute of Technology 09/2020 - 06/2024 School of Computer Science \u0026amp; Technology Bachelor of Engineering in Software Engineering, last two years GPA: 3.7/4 Relevant Courses: Reinforcement Learning, Deep Learning and Computer Vision, Artificial Intelligence and Robot Ethics, Almost Human: Mind, Brain and Artificial Intelligence, Mathematical Analysis for Engineering, Linear Algebra, Probability and Mathematical Statistics, etc. Skills: Python, Java, common data structures, design patterns, machine learning basics and algorithms, Linux, PyTorch, and some development tools (git, conda, etc.). üèÜ Awards \u0026amp; Honors Beijing Institute of Technology Undergraduate Scholarship (Top 20% of Grade) 06/2023 3rd Prize of China International \u0026#34;Internet \u0026#43;\u0026#34; College Student\u0026#39;s Innovation Competition 08/2022 Bronze Prize of \u0026#34;Challenge Cup\u0026#34; Capital University Entrepreneurship Competition 05/2022 üíº Project Experience üîç Online Transaction Fraud Detection 09/2024 ‚Äì 01/2025 Independent project, supervised by Dr. Vivien Chan Focused on addressing financial fraud in e-commerce to enhance the accuracy of transaction anomaly detection, while independently managing the entire case study that included data preprocessing, feature engineering, model building, evaluation, and results analysis. Effectively resolved class imbalance issues using SMOTE and ROSE techniques. Built various models including Logistic Regression, Random Forest, XGBoost, and LightGBM, ultimately selecting the LightGBM model to achieve a recall rate of 95.45% and an AUC of 99.84%. Wrote efficient and maintainable code, enhancing model training and data processing efficiency through parallel computing and logging. ü§ñ Multi-Model Intelligent Text Keyword Extraction System 08/2023 ‚Äì 09/2023 Group project, supervised by Associate Prof. Xiaolin Zhao Designed and implemented an intelligent text summary system that automatically extracts keywords from article titles and abstracts, enhancing the understanding and summarization of text information. Participated in the planning of the technical route and built a hybrid model combining extractive and generative approaches, utilizing advanced natural language processing techniques including KeyBERT, Sentence Transformer, BERT, and T5 models. Responsible for data preprocessing and tokenization, as well as the end-to-end implementation and training of the T5 model, optimizing the model architecture and hyperparameters, achieving satisfactory results after only 3 epochs of training. Model evaluation results showed that the Rouge-1, Rouge-2, and Rouge-L metrics reached 0.6345, 0.5038, and 0.5282, respectively, in the third epoch, validating the model\u0026rsquo;s effectiveness in the summarization task. üéì Cambridge University Machine Learning Summer Project 07/2023 ‚Äì 08/2023 Group project, supervised by Prof. Pietro Li√≤ Participated in the Cambridge University deep learning summer project, focusing on deep reinforcement learning; explored multi-agent learning algorithms across different environments. Reproduced the Multi-Agent Deep Deterministic Policy Gradient (MADDPG) algorithm in the Simple Adversary environment and studied the effect of agent numbers on convergence speed and stability, finding optimal stability at 21 agents. Designed and implemented comparative experiments inspired by the Rainbow algorithm, assessing target network strategies versus the Double Deep Q-Network (Double DQN). The results demonstrated that Double DQN significantly enhanced convergence speed, optimizing the overall learning process. Co-authored a group project paper on agent numbers and strategies effectiveness in multi-agent systems, achieving a score of 71% in the summer program (the highest in my group) and a \u0026ldquo;First Class\u0026rdquo; classification in the UK grading system. üëÅÔ∏è Deep Learning and Computer Vision Semester Project 09/2022 ‚Äì 12/2022 Independent project, supervised by Associate Prof. Guangyu Gao Designed and implemented a waste classifier using the ResNet model to improve classification accuracy and reduce resource waste. The project also enhanced understanding of transfer learning techniques with ResNet. Collected a dataset of 16 waste categories and preprocessed the images for uniformity and standardization, incorporating data augmentation techniques to enhance the dataset. Conducted experiments using ResNet34 and ResNet50 models through transfer learning, accelerating network convergence by leveraging pretrained weights. During training, techniques such as Batch Normalization and Dropout were applied to mitigate the risk of overfitting. The final model achieved an accuracy of 90% on the training set, while the performance on the test set was 61%, indicating a significant overfitting phenomenon during the training process. üéì Internship ‚öõÔ∏è Beijing Academy of Quantum Information Science 08/2023 ‚Äì 01/2024 Research Intern at Quantum Computation Department Proposed a quantum convolution kernel design based on variational quantum circuits and developed a universal quantum convolution layer, successfully integrating it into classical CNN architectures such as VGG, GoogLeNet, and ResNet. Developed and evaluated various hybrid models, including a simple model named HQCCNN-2, which achieved 84.45% accuracy on the FashionMNIST dataset, surpassing the traditional CNN\u0026rsquo;s 80.72%. This demonstrates the effectiveness of the quantum convolution layer in improving model performance. Tested on a real quantum computer further validated the effectiveness of the hybrid model, demonstrating the viable integration of quantum computing with deep learning, and highlighting the potential for leveraging quantum properties to enhance model performance. üèÖ Competition Experience ü•â China International \u0026#34;Internet \u0026#43;\u0026#34; College Students\u0026#39; Innovation Competition 08/2022 üõ°Ô∏è Zhongke Ushield: Deep Learning-based Face Privacy Protection Authentication System Responsible for constructing a localized facial feature extraction engine based on MobileFaceNet, ensuring feature extraction is completed on end devices (such as mobile phones and cameras), guaranteeing that raw data does not leave the domain and is not stored, thus enhancing user privacy protection while improving recognition efficiency. ü•â \u0026#34;Challenge Cup\u0026#34; Capital University Entrepreneurship Competition 05/2022 üå≥ Smart Orchard Responsible for the development of the fruit detection, ripeness prediction, and pest identification system, using deep convolutional neural network (CNN) technology for intelligent monitoring of crop growth conditions. Applied advanced object detection algorithms such as Faster R-CNN and YOLO to achieve high precision in apple detection and ripeness assessment, with an accuracy rate exceeding 90%, significantly enhancing the intelligence level of orchard management. Built and trained a dedicated dataset containing various pest samples, optimizing pest detection accuracy through data preprocessing (such as image normalization and resizing) and data augmentation techniques (like rotation, flipping, and noise addition), enabling the real-time monitoring system to accurately identify over 80% of pests, providing effective scientific maintenance recommendations to help farmers reduce crop losses. üìã Extracurricular Activities Vice President, Cyber Security Club, Beijing Institute of Technology 09/2021-09/2022 Backbone, Media Center of the Student Union of Beijing Institute of Technology 10/2020-06/2021 üì´ Contact üìß Email: zongsi.xu@outlook.com üëî LinkedIn: Zongsi (Tristan) Xu üíª GitHub: github.com/BaizeXS üìç Location: Hong Kong SAR, China ","permalink":"http://localhost:1313/resume/","summary":"Personal resume of Zongsi (Tristan) Xu","title":"Zongsi (Tristan) Xu"},{"content":"‰∏Ä„ÄÅÊï∞ÂÄºÁâπÂæÅ‰∏éÁ±ªÂà´ÁâπÂæÅ Êï∞ÂÄºÁâπÂæÅ (Numeric Features) ÂÖ∑ÊúâÂèØÂä†ÂáèÁöÑÊÑè‰πâÔºå‰∏îÂ≠òÂú®Â§ßÂ∞èÈ°∫Â∫è„ÄÇ ‰æãÂ≠êÔºöÂπ¥ÈæÑ„ÄÅÊ∏©Â∫¶Á≠â„ÄÇÂèØ‰ª•Áõ¥Êé•‰øùÁïôÂÖ∂Êï¥Êï∞ÊàñÊµÆÁÇπÊï∞ÂΩ¢Âºè‰æõÊ®°Âûã‰ΩøÁî®„ÄÇ Á±ªÂà´ÁâπÂæÅ (Categorical Features) Êï∞ÊçÆÂÄºÁ¶ªÊï£Ôºå‰∏çÂÖ∑Â§á‚ÄúÊï∞ÂÄºÂ§ßÂ∞è‚ÄùÈó¥ÁöÑÂèØÊØîÊÑè‰πâ„ÄÇ ‰æãÂ≠êÔºöÂõΩÁ±çÔºàÁæéÂõΩ/‰∏≠ÂõΩ/Âç∞Â∫¶Á≠âÔºâ„ÄÅÊÄßÂà´ÔºàÁî∑/Â•≥ÔºâÁ≠â„ÄÇ ÈóÆÈ¢òÔºöËã•‰ªÖÁî®Êï¥Êï∞Ë°®Á§∫ÔºàÁæéÂõΩ=1, ‰∏≠ÂõΩ=2ÔºâÔºå‰ºöÂºïÂÖ•ÈîôËØØÁöÑÊï∞ÂÄºËøêÁÆóÂÖ≥Á≥ªÔºåÂ¶Ç ‚ÄúÁæéÂõΩ + ‰∏≠ÂõΩ = Âç∞Â∫¶‚Äù„ÄÇ ‰∫å„ÄÅOne-HotÁºñÁ†ÅÁöÑÂä®Êú∫‰∏éÊµÅÁ®ã ‰∏∫‰ªÄ‰πà‰ΩøÁî®One-Hot\nÈÄöËøáÂ∞ÜÁ±ªÂà´Êò†Â∞Ñ‰∏∫ÂêëÈáèÔºåÈÅøÂÖçÊï¥Êï∞ÁºñÁ†ÅÂºïÂÖ•ÁöÑ‰º™Êï∞ÂÄºÂÖ≥Á≥ª„ÄÇ ÂêåÊó∂‰øùÁïôÂêÑÁßçÂèØËÉΩÁ±ªÂà´ÁöÑ‰ø°ÊÅØÔºå‰∏î‰ªÖÂú®ÂØπÂ∫î‰ΩçÁΩÆ‰∏∫1ÔºåÂÖ∂‰ªñ‰ΩçÁΩÆ‰∏∫0„ÄÇ Âª∫Á´ãÊò†Â∞ÑÔºö‰ªéÁ±ªÂà´Âà∞Á¥¢Âºï\n‰∏∫ÊØè‰∏™Á±ªÂà´ÂàÜÈÖç‰∏Ä‰∏™ÂîØ‰∏ÄÁ¥¢ÂºïÔºåÈÄöÂ∏∏‰ªé1ÂºÄÂßã„ÄÇ È¢ÑÁïôÁ¥¢Âºï0Ë°®Á§∫‚ÄúÊú™Áü•‚ÄùÊàñ‚ÄúÁº∫Â§±‚ÄùÔºåÂØπÂ∫îÂÖ®0ÂêëÈáè„ÄÇ ËΩ¨Êç¢‰∏∫One-HotÂêëÈáè\nËã•Á±ªÂà´ÊÄªÊï∞‰∏∫197ÔºåÂàôÁî®197Áª¥ÂêëÈáèË°®Á§∫„ÄÇ ‰æãÂ≠êÔºöÁæéÂõΩ [1, 0, 0, 0, ‚Ä¶]Ôºå ‰∏≠ÂõΩ [0, 1, 0, 0, ‚Ä¶]„ÄÇ Á§∫‰æãÔºöË°®Á§∫‰∏Ä‰∏™‰∫∫ÁöÑÁâπÂæÅ\nÁâπÂæÅÂåÖÂê´ÔºàÂπ¥ÈæÑ, ÊÄßÂà´, ÂõΩÁ±çÔºåÂÖ∂‰∏≠ÂõΩÁ±ç197ÁßçÔºâ Áª¥Â∫¶ÊÄªÂíåÔºö1Áª¥_age + 1Áª¥_gender + 197Áª¥_nationality = 199Áª¥„ÄÇ ‰æãÂ¶Ç (28, Â•≥, ‰∏≠ÂõΩ) ‚Üí [28, 0, 0, 1, 0, ‚Ä¶, 0]„ÄÇ ‰∏â„ÄÅÊñáÊú¨Êï∞ÊçÆÂ§ÑÁêÜÊµÅÁ®ã ÊñáÊú¨Âú®Ëá™ÁÑ∂ËØ≠Ë®ÄÂ§ÑÁêÜÔºàNLPÔºâ‰∏≠‰Ωú‰∏∫Â∏∏ËßÅÁöÑÂéüÂßãËæìÂÖ•ÔºåÈúÄË¶ÅÊï∞ÂÄºÂåñÊâçËÉΩÈÄÅÂÖ•Ê®°Âûã„ÄÇ‰∏ÄËà¨Ê≠•È™§Â¶Ç‰∏ãÔºö\nÂàÜËØç (Tokenization)\nÂ∞ÜÊñáÊú¨ÊãÜÂàÜ‰∏∫‰∏Ä‰∏™‰∏™ÂçïËØçÔºàTokenÔºâ„ÄÇ ‰æãÂ≠êÔºö\u0026quot;... to be or not to be...\u0026quot; ‚Üí [\u0026quot;...\u0026quot;, \u0026quot;to\u0026quot;, \u0026quot;be\u0026quot;, \u0026quot;or\u0026quot;, \u0026quot;not\u0026quot;, \u0026quot;to\u0026quot;, \u0026quot;be\u0026quot;, \u0026quot;...\u0026quot;]„ÄÇ ÁªüËÆ°ËØçÈ¢ë \u0026amp; ÊûÑÂª∫ËØçÂÖ∏\nËØçÈ¢ëÁªüËÆ° Áî®ÂìàÂ∏åË°®/Â≠óÂÖ∏ËÆ∞ÂΩïÊØè‰∏™ÂçïËØçÂá∫Áé∞Ê¨°Êï∞„ÄÇ ÈÅçÂéÜÊñáÊú¨Êó∂ÔºåËã•ÂçïËØçÂ∞öÊú™ÂÖ•Ë°®ÔºåÂàôÊñ∞Âª∫ËÆ∞ÂΩïÔºõËã•Â∑≤Â≠òÂú®ÔºåÂàôËÆ°Êï∞+1„ÄÇ ÊéíÂ∫è‰∏éÁ¥¢Âºï ÊåâËØçÈ¢ëÈôçÂ∫èÊéíÂ∫èÔºåËØçÈ¢ëÊúÄÈ´òÁöÑÂçïËØçÊéíÂú®ÂâçÈù¢„ÄÇ Á¥¢Âºï‰ªé1ÂºÄÂßãÔºå0ÁïôÁªô‚ÄúÊú™Áü•‚Äù„ÄÇ ËØçÂÖ∏ËßÑÊ®°ÔºàvocabularyÔºâÂèØËßÜÈúÄÊ±ÇÊà™Êñ≠Ôºà‰æãÂ¶ÇÂè™‰øùÁïôTop 10kÔºâ„ÄÇ ‰∏∫‰ªÄ‰πàÁßªÈô§‰ΩéÈ¢ëËØç ‰ΩéÈ¢ëËØçÂèØËÉΩÊòØÊãºÂÜôÈîôËØØ„ÄÅÁΩïËßÅ‰∫∫ÂêçÁ≠âÔºåÂØπÊ®°ÂûãÂ∏ÆÂä©ÊúâÈôê„ÄÇ ÂáèÂ∞ëËØçÂÖ∏ËßÑÊ®°ÂèØÈôç‰ΩéËøêÁÆóÂºÄÈîÄ„ÄÅÂä†Âø´Ê®°ÂûãËÆ≠ÁªÉ‰∏éÊé®ÁêÜÈÄüÂ∫¶„ÄÇ Áã¨ÁÉ≠ÁºñÁ†Å (One-Hot Encoding)\nÂ∞ÜÊØè‰∏™ÂçïËØçÊò†Â∞Ñ‰∏∫ËØçÂÖ∏‰∏≠ÁöÑÁ¥¢ÂºïÂêéÔºàÂ¶Ç [2, 4, 1, 8, ‚Ä¶]ÔºâÔºåÂèØËøõ‰∏ÄÊ≠•ËΩ¨Êç¢ÊàêOne-HotÂêëÈáè„ÄÇ One-HotÁª¥Â∫¶ÂèñÂÜ≥‰∫é‰øùÁïô‰∏ãÊù•ÁöÑËØçÂÖ∏Â§ßÂ∞èÔºà‰æãÂ¶Ç1‰∏áÔºâ„ÄÇ Êú™Êî∂ÂΩïÂçïËØçÂèØËÉΩÁõ¥Êé•ÂøΩÁï•ÔºåÊàñÁªü‰∏ÄÁî®Á¥¢Âºï0‰ª£Êõø„ÄÇ Âõõ„ÄÅÊ†∏ÂøÉÊî∂Ëé∑‰∏éÂ∫îÁî® Á±ªÂà´ÁâπÂæÅÂøÖÈúÄÊï∞ÂÄºÂåñÔºö\n‰ΩøÁî®Êï¥Êï∞1,2,3‚Ä¶‰ªÖË°®Á§∫Á±ªÂà´‚ÄúÊ†áËØÜ‚ÄùÔºåÂπ∂‰∏ç‰ª£Ë°®ÂÆÉ‰ª¨ÂèØËøõË°åÊï∞ÂÄºËøêÁÆó„ÄÇ Âõ†Ê≠§ÈúÄË¶ÅOne-HotÁ≠âÁºñÁ†ÅÊñπÂºèÔºåÈÅøÂÖçÊï∞ÂÄºËØØËß£„ÄÇ ÊñáÊú¨Êï∞ÊçÆÈ¢ÑÂ§ÑÁêÜÔºö\nÂàÜËØç„ÄÅËØçÈ¢ëÁªüËÆ°„ÄÅÊûÑÂª∫ËØçÂÖ∏„ÄÅÁ¥¢ÂºïÂåñ„ÄÅOne-HotÊàñÂÖ∂‰ªñÊñπÂºèÔºàÂ¶ÇËØçÂµåÂÖ•ÔºâÊòØÂ∏∏ËßÅÊµÅÁ®ã„ÄÇ Ê≠£Á°ÆÁöÑÊñáÊú¨È¢ÑÂ§ÑÁêÜÂèØÊòæËëóÂΩ±ÂìçÊ®°ÂûãÊÄßËÉΩÂíåÊïàÁéá„ÄÇ ‰øùÁïôÊú™Áü•Á¥¢ÂºïÔºö\n‰øùËØÅÂØπÁº∫Â§±Êï∞ÊçÆÊàñÂ≠óÂÖ∏Â§ñÊñ∞ËØçËÉΩÊúâÂü∫Êú¨ÁöÑË°®Á§∫ÔºåÊèêÂçáÊ®°ÂûãÂÆπÈîôÊÄß„ÄÇ ÂÆûÈôÖ‰ΩøÁî®Ôºö\nÂØπ‰∫éÂ∞èËßÑÊ®°Á±ªÂà´ÂèØÁõ¥Êé•One-HotÁºñÁ†ÅÔºõÂØπ‰∫éËØçÂÖ∏ÂæàÂ§ßÁöÑÂú∫ÊôØÔºåÈÄöÂ∏∏‰ºöËøõ‰∏ÄÊ≠•ËÄÉËôëËØçÂµåÂÖ•ÔºàWord EmbeddingÔºâÊàñÈ¢ÑËÆ≠ÁªÉËØ≠Ë®ÄÊ®°Âûã„ÄÇ ","permalink":"http://localhost:1313/posts/nlp-1/","summary":"\u003ch2 id=\"‰∏ÄÊï∞ÂÄºÁâπÂæÅ‰∏éÁ±ªÂà´ÁâπÂæÅ\"\u003e‰∏Ä„ÄÅÊï∞ÂÄºÁâπÂæÅ‰∏éÁ±ªÂà´ÁâπÂæÅ\u003c/h2\u003e\n\u003col\u003e\n\u003cli\u003e\u003cstrong\u003eÊï∞ÂÄºÁâπÂæÅ (Numeric Features)\u003c/strong\u003e\n\u003cul\u003e\n\u003cli\u003eÂÖ∑ÊúâÂèØÂä†ÂáèÁöÑÊÑè‰πâÔºå‰∏îÂ≠òÂú®Â§ßÂ∞èÈ°∫Â∫è„ÄÇ\u003c/li\u003e\n\u003cli\u003e‰æãÂ≠êÔºöÂπ¥ÈæÑ„ÄÅÊ∏©Â∫¶Á≠â„ÄÇÂèØ‰ª•Áõ¥Êé•‰øùÁïôÂÖ∂Êï¥Êï∞ÊàñÊµÆÁÇπÊï∞ÂΩ¢Âºè‰æõÊ®°Âûã‰ΩøÁî®„ÄÇ\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003eÁ±ªÂà´ÁâπÂæÅ (Categorical Features)\u003c/strong\u003e\n\u003cul\u003e\n\u003cli\u003eÊï∞ÊçÆÂÄºÁ¶ªÊï£Ôºå‰∏çÂÖ∑Â§á‚ÄúÊï∞ÂÄºÂ§ßÂ∞è‚ÄùÈó¥ÁöÑÂèØÊØîÊÑè‰πâ„ÄÇ\u003c/li\u003e\n\u003cli\u003e‰æãÂ≠êÔºöÂõΩÁ±çÔºàÁæéÂõΩ/‰∏≠ÂõΩ/Âç∞Â∫¶Á≠âÔºâ„ÄÅÊÄßÂà´ÔºàÁî∑/Â•≥ÔºâÁ≠â„ÄÇ\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003eÈóÆÈ¢ò\u003c/strong\u003eÔºöËã•‰ªÖÁî®Êï¥Êï∞Ë°®Á§∫ÔºàÁæéÂõΩ=1, ‰∏≠ÂõΩ=2ÔºâÔºå‰ºöÂºïÂÖ•ÈîôËØØÁöÑÊï∞ÂÄºËøêÁÆóÂÖ≥Á≥ªÔºåÂ¶Ç ‚ÄúÁæéÂõΩ + ‰∏≠ÂõΩ = Âç∞Â∫¶‚Äù„ÄÇ\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003c/ol\u003e\n\u003ch2 id=\"‰∫åone-hotÁºñÁ†ÅÁöÑÂä®Êú∫‰∏éÊµÅÁ®ã\"\u003e‰∫å„ÄÅOne-HotÁºñÁ†ÅÁöÑÂä®Êú∫‰∏éÊµÅÁ®ã\u003c/h2\u003e\n\u003col\u003e\n\u003cli\u003e\n\u003cp\u003e\u003cstrong\u003e‰∏∫‰ªÄ‰πà‰ΩøÁî®One-Hot\u003c/strong\u003e\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eÈÄöËøáÂ∞ÜÁ±ªÂà´Êò†Â∞Ñ‰∏∫ÂêëÈáèÔºåÈÅøÂÖçÊï¥Êï∞ÁºñÁ†ÅÂºïÂÖ•ÁöÑ‰º™Êï∞ÂÄºÂÖ≥Á≥ª„ÄÇ\u003c/li\u003e\n\u003cli\u003eÂêåÊó∂‰øùÁïôÂêÑÁßçÂèØËÉΩÁ±ªÂà´ÁöÑ‰ø°ÊÅØÔºå‰∏î‰ªÖÂú®ÂØπÂ∫î‰ΩçÁΩÆ‰∏∫1ÔºåÂÖ∂‰ªñ‰ΩçÁΩÆ‰∏∫0„ÄÇ\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003e\u003cstrong\u003eÂª∫Á´ãÊò†Â∞ÑÔºö‰ªéÁ±ªÂà´Âà∞Á¥¢Âºï\u003c/strong\u003e\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e‰∏∫ÊØè‰∏™Á±ªÂà´ÂàÜÈÖç‰∏Ä‰∏™ÂîØ‰∏ÄÁ¥¢ÂºïÔºåÈÄöÂ∏∏‰ªé1ÂºÄÂßã„ÄÇ\u003c/li\u003e\n\u003cli\u003eÈ¢ÑÁïôÁ¥¢Âºï0Ë°®Á§∫‚ÄúÊú™Áü•‚ÄùÊàñ‚ÄúÁº∫Â§±‚ÄùÔºåÂØπÂ∫îÂÖ®0ÂêëÈáè„ÄÇ\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003e\u003cstrong\u003eËΩ¨Êç¢‰∏∫One-HotÂêëÈáè\u003c/strong\u003e\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eËã•Á±ªÂà´ÊÄªÊï∞‰∏∫197ÔºåÂàôÁî®197Áª¥ÂêëÈáèË°®Á§∫„ÄÇ\u003c/li\u003e\n\u003cli\u003e‰æãÂ≠êÔºöÁæéÂõΩ \u003ccode\u003e[1, 0, 0, 0, ‚Ä¶]\u003c/code\u003eÔºå ‰∏≠ÂõΩ \u003ccode\u003e[0, 1, 0, 0, ‚Ä¶]\u003c/code\u003e„ÄÇ\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003e\u003cstrong\u003eÁ§∫‰æãÔºöË°®Á§∫‰∏Ä‰∏™‰∫∫ÁöÑÁâπÂæÅ\u003c/strong\u003e\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eÁâπÂæÅÂåÖÂê´ÔºàÂπ¥ÈæÑ, ÊÄßÂà´, ÂõΩÁ±çÔºåÂÖ∂‰∏≠ÂõΩÁ±ç197ÁßçÔºâ\u003c/li\u003e\n\u003cli\u003eÁª¥Â∫¶ÊÄªÂíåÔºö1Áª¥_age + 1Áª¥_gender + 197Áª¥_nationality = 199Áª¥„ÄÇ\u003c/li\u003e\n\u003cli\u003e‰æãÂ¶Ç \u003ccode\u003e(28, Â•≥, ‰∏≠ÂõΩ)\u003c/code\u003e ‚Üí \u003ccode\u003e[28, 0, 0, 1, 0, ‚Ä¶, 0]\u003c/code\u003e„ÄÇ\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003c/ol\u003e\n\u003ch2 id=\"‰∏âÊñáÊú¨Êï∞ÊçÆÂ§ÑÁêÜÊµÅÁ®ã\"\u003e‰∏â„ÄÅÊñáÊú¨Êï∞ÊçÆÂ§ÑÁêÜÊµÅÁ®ã\u003c/h2\u003e\n\u003cp\u003eÊñáÊú¨Âú®Ëá™ÁÑ∂ËØ≠Ë®ÄÂ§ÑÁêÜÔºàNLPÔºâ‰∏≠‰Ωú‰∏∫Â∏∏ËßÅÁöÑÂéüÂßãËæìÂÖ•ÔºåÈúÄË¶ÅÊï∞ÂÄºÂåñÊâçËÉΩÈÄÅÂÖ•Ê®°Âûã„ÄÇ‰∏ÄËà¨Ê≠•È™§Â¶Ç‰∏ãÔºö\u003c/p\u003e\n\u003col\u003e\n\u003cli\u003e\n\u003cp\u003e\u003cstrong\u003eÂàÜËØç (Tokenization)\u003c/strong\u003e\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eÂ∞ÜÊñáÊú¨ÊãÜÂàÜ‰∏∫‰∏Ä‰∏™‰∏™ÂçïËØçÔºàTokenÔºâ„ÄÇ\u003c/li\u003e\n\u003cli\u003e‰æãÂ≠êÔºö\u003ccode\u003e\u0026quot;... to be or not to be...\u0026quot;\u003c/code\u003e ‚Üí \u003ccode\u003e[\u0026quot;...\u0026quot;, \u0026quot;to\u0026quot;, \u0026quot;be\u0026quot;, \u0026quot;or\u0026quot;, \u0026quot;not\u0026quot;, \u0026quot;to\u0026quot;, \u0026quot;be\u0026quot;, \u0026quot;...\u0026quot;]\u003c/code\u003e„ÄÇ\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003e\u003cstrong\u003eÁªüËÆ°ËØçÈ¢ë \u0026amp; ÊûÑÂª∫ËØçÂÖ∏\u003c/strong\u003e\u003c/p\u003e","title":""},{"content":"Text to Sequence ÊñáÊú¨Â§ÑÁêÜ\nStep1: Tokenization\nTokenization breaks a piece of text down into a list of tokens.\nHere, a token is a word. (A token can be a character in some applications.)\nTokenizationËÆ≤Á©∂ÂæàÂ§öÔºå‰æãÂ¶ÇÊòØÂê¶Â∫îËØ•ÊääÂ§ßÂÜôÊîπÊàêÂ∞èÂÜôÂë¢ÔºüËøõË°åtypo correctionÁ≠âÁ≠â\nStep2: Build Dictionary\nUse a dictionary (hash table) to count word frequencies.\nThe dictionary maps word to index.\nÂèØ‰ª•È¶ñÂÖàÁªüËÆ°ËØçÈ¢ëÂéªÊéâ‰ΩéÈ¢ëËØçÔºåÁÑ∂ÂêéËÆ©ÊØè‰∏™ËØçÂØπÂ∫î‰∏Ä‰∏™Ê≠£Êï¥Êï∞ÔºõËøôÊ†∑ÁöÑËØùÔºå‰∏ÄÂè•ËØùÂ∞±ÂèØ‰ª•Áî®‰∏Ä‰∏™Ê≠£Êï¥Êï∞ÂàóË°®Ë°®Á§∫ÔºåËøô‰∏™ÂàóË°®Â∞±Âè´sequenceÔºõÂ¶ÇÊûúÂøÖË¶ÅÂ∞±ËøòÂæóÂÅöone-hot encoding„ÄÇ\nÁªìÊûú\n‰ΩÜÊòØÈïøÂ∫¶‰∏çÁªü‰∏Ä\nStep4: ÂØπÈΩêsequence\nËß£ÂÜ≥ÊñπÊ°àÊòØËøôÊ†∑ÁöÑÔºöÂèØ‰ª•Âõ∫ÂÆöÈïøÂ∫¶‰∏∫wÔºåÂä†ÂÖ•‰∏Ä‰∏™Â∫èÂàóÈïøÂ∫¶Â§™ÈïøÔºåÂ∞±Á†çÊéâÂâçÈù¢ÁöÑËØçÔºåÂè™‰øùÁïôÊúÄÂêéw‰∏™ËØçÔºõÂ¶ÇÊûú‰∏Ä‰∏™Â∫èÂàóÂ§™Áü≠ÔºåÂ∞±ÂÅözero paddingÔºåÁî®0Â°´ÂÖÖ\nËøôÊ†∑‰∏ÄÊù•ÔºåÊâÄÊúâÁöÑÂ∫èÂàóÈïøÂ∫¶Â∞±Áªü‰∏Ä‰∫Ü\nÊñáÊú¨Â§ÑÁêÜÂÆåÊàê‰∫ÜÔºåÊé•‰∏ãÊù•ÊòØword embeddingÔºåÊääÂçïËØçË°®Á§∫‰∏∫‰∏Ä‰∏™‰ΩéÁª¥ÂêëÈáèÔºõ\nÁÑ∂ËÄåËøôÊ†∑ÂÅöÁöÑËØùÔºåÂ¶ÇÊûúÊòØ10000‰∏™ÂçïËØçÔºåÁª¥Â∫¶Â∞±ÊòØ10000Áª¥ÔºåÁª¥Â∫¶Â§™È´ò‰∫ÜÔºõÂõ†Ê≠§Ë¶ÅÂÅöword embeddingÔºõ\nÂÖ∑‰ΩìÂÅöÊ≥ïÂ∞±ÊòØÊääone-hotÂêëÈáèe_iÂíåÂèÇÊï∞Áü©ÈòµpÁõ∏‰πòÔºõÁü©ÈòµPËΩ¨ÁΩÆÁöÑÂ§ßÂ∞èÊòØd x vÔºõdÊòØËØçÂêëÈáèÁöÑÁª¥Â∫¶ÔºõvÊòØÂ≠óÂÖ∏ÈáåËØçÊ±áÁöÑÊï∞ÈáèÔºõÁªìÊûú‰∏∫x_iÔºõx_iÂ∞±ÊòØ‰∏Ä‰∏™ËØçÂêëÈáèÔºõÂ¶ÇÊûúone-hotÂêëÈáèÁöÑÁ¨¨‰∏âË°å‰∏∫1ÔºõÈÇ£‰πàx_iÂ∞±ÊòØPËΩ¨ÁΩÆÁü©ÈòµÁöÑÁ¨¨‰∏âÂàóÔºàÂÖ∂‰ΩôÂàóÈÉΩ‰∏∫0ÔºâÔºõÊâÄ‰ª•PËΩ¨ÁΩÆÊØè‰∏ÄÂàóÈÉΩÊòØ‰∏Ä‰∏™ËØçÂêëÈáèÔºõÊâÄ‰ª•Áü©ÈòµPÊú¨Ë∫´ÁöÑÊØè‰∏ÄË°åÂ∞±ÊòØ‰∏Ä‰∏™ËØçÂêëÈáèÔºõÂÖ∂Ë°åÊï∞‰∏∫vÔºõÂç≥vocabularyÔºåËØçÊ±áÈáèÔºõÊØè‰∏ÄË°åÂØπÂ∫î‰∏Ä‰∏™ÂçïËØçÔºõÁü©ÈòµÁöÑÂàóÊï∞‰∏∫dÔºõdÊòØÁî®Êà∑ÂÜ≥ÂÆöÁöÑÔºõdÁöÑÂ§ßÂ∞è‰ºöÂÜ≥ÂÆöÊú∫Âô®Â≠¶‰π†Ê®°ÂûãÁöÑË°®Áé∞ÔºõÂ∫îËØ•Áî®xxxÊù•ÈÄâÊã©‰∏Ä‰∏™ÊØîËæÉÂ•ΩÁöÑdÔºõ\nÊàë‰ª¨ÁöÑ‰ªªÂä°ÊòØÁúãËØÑËÆ∫ÊòØÊ≠£Èù¢ÁöÑËøòÊòØË¥üÈù¢ÁöÑÔºõÂèÇÊï∞Áü©ÈòµÊòØ‰ªéËÆ≠ÁªÉÊï∞ÊçÆ‰∏≠Â≠¶‰π†Âá∫Êù•ÁöÑÔºåÊâÄ‰ª•Â≠¶Âá∫Êù•ÁöÑËØçÂêëÈáèÊòØÂ∏¶ÊúâÊÑüÊÉÖËâ≤ÂΩ©ÁöÑÔºõÂÅáËÆæËøô‰∫õËØçÂêëÈáèÈÉΩÊòØ‰∫åÁª¥ÁöÑÔºåÂàôÂèØ‰ª•Âú®Âπ≥Èù¢ÂùêÊ†áÁ≥ª‰∏≠Ê†áÂá∫‰∏ãÈù¢ËØçÂêëÈáè\nkerasÊèê‰æõembeddingÂ±ÇÔºõÁî®Êà∑ÂèØ‰ª•ÊåáÂÆövocabularyÂ§ßÂ∞èÂíådÁöÑÂ§ßÂ∞èÔºõ‰ª•ÂèäÊØè‰∏Ä‰∏™sequenceÁöÑÈïøÂ∫¶ÔºõdÊòØÊ†πÊçÆÁÆóÊ≥ïÈÄâÂá∫Êù•ÁöÑ Âà∞Ëøô‰∏ÄÊ≠•ÔºåÊàë‰ª¨Â∑≤ÁªèÂÆåÊàê‰∫ÜÊñáÊú¨Â§ÑÁêÜÂíåword embedding„ÄÇÊé•‰∏ãÊù•Â∞±ÊòØÁî®Logistic Regression for Binary ClassificationÂÅö‰∫åÂàÜÁ±ªÔºõ\n","permalink":"http://localhost:1313/posts/nlp-2/","summary":"\u003ch3 id=\"text-to-sequence\"\u003eText to Sequence\u003c/h3\u003e\n\u003cp\u003eÊñáÊú¨Â§ÑÁêÜ\u003c/p\u003e\n\u003cp\u003eStep1: Tokenization\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\n\u003cp\u003eTokenization breaks a piece of text down into a list of tokens.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003eHere, a token is a word. (A token can be a character in some applications.)\u003c/p\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003eTokenizationËÆ≤Á©∂ÂæàÂ§öÔºå‰æãÂ¶ÇÊòØÂê¶Â∫îËØ•ÊääÂ§ßÂÜôÊîπÊàêÂ∞èÂÜôÂë¢ÔºüËøõË°åtypo correctionÁ≠âÁ≠â\u003c/p\u003e\n\u003cp\u003e\u003cimg alt=\"image-20250322150322238\" loading=\"lazy\" src=\"./NLP-2.assets/image-20250322150322238.png\"\u003e\u003c/p\u003e\n\u003cp\u003eStep2: Build Dictionary\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\n\u003cp\u003eUse a dictionary (hash table) to count word frequencies.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003eThe dictionary maps word to index.\u003c/p\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003eÂèØ‰ª•È¶ñÂÖàÁªüËÆ°ËØçÈ¢ëÂéªÊéâ‰ΩéÈ¢ëËØçÔºåÁÑ∂ÂêéËÆ©ÊØè‰∏™ËØçÂØπÂ∫î‰∏Ä‰∏™Ê≠£Êï¥Êï∞ÔºõËøôÊ†∑ÁöÑËØùÔºå‰∏ÄÂè•ËØùÂ∞±ÂèØ‰ª•Áî®‰∏Ä‰∏™Ê≠£Êï¥Êï∞ÂàóË°®Ë°®Á§∫ÔºåËøô‰∏™ÂàóË°®Â∞±Âè´sequenceÔºõÂ¶ÇÊûúÂøÖË¶ÅÂ∞±ËøòÂæóÂÅöone-hot encoding„ÄÇ\u003cimg alt=\"image-20250322150620890\" loading=\"lazy\" src=\"./NLP-2.assets/image-20250322150620890.png\"\u003e\u003c/p\u003e\n\u003cp\u003eÁªìÊûú\u003c/p\u003e\n\u003cp\u003e\u003cimg alt=\"image-20250322150754528\" loading=\"lazy\" src=\"./NLP-2.assets/image-20250322150754528.png\"\u003e\u003c/p\u003e\n\u003cp\u003e‰ΩÜÊòØÈïøÂ∫¶‰∏çÁªü‰∏Ä\u003c/p\u003e\n\u003cp\u003eStep4: ÂØπÈΩêsequence\u003c/p\u003e\n\u003cp\u003e\u003cimg alt=\"image-20250322150854986\" loading=\"lazy\" src=\"./NLP-2.assets/image-20250322150854986.png\"\u003e\u003c/p\u003e\n\u003cp\u003eËß£ÂÜ≥ÊñπÊ°àÊòØËøôÊ†∑ÁöÑÔºöÂèØ‰ª•Âõ∫ÂÆöÈïøÂ∫¶‰∏∫wÔºåÂä†ÂÖ•‰∏Ä‰∏™Â∫èÂàóÈïøÂ∫¶Â§™ÈïøÔºåÂ∞±Á†çÊéâÂâçÈù¢ÁöÑËØçÔºåÂè™‰øùÁïôÊúÄÂêéw‰∏™ËØçÔºõÂ¶ÇÊûú‰∏Ä‰∏™Â∫èÂàóÂ§™Áü≠ÔºåÂ∞±ÂÅözero paddingÔºåÁî®0Â°´ÂÖÖ\u003c/p\u003e\n\u003cp\u003e\u003cimg alt=\"image-20250322151030119\" loading=\"lazy\" src=\"./NLP-2.assets/image-20250322151030119.png\"\u003e\u003c/p\u003e\n\u003cp\u003eËøôÊ†∑‰∏ÄÊù•ÔºåÊâÄÊúâÁöÑÂ∫èÂàóÈïøÂ∫¶Â∞±Áªü‰∏Ä‰∫Ü\u003c/p\u003e\n\u003cp\u003e\u003cimg alt=\"image-20250322151117125\" loading=\"lazy\" src=\"./NLP-2.assets/image-20250322151117125.png\"\u003e\u003c/p\u003e\n\u003cp\u003eÊñáÊú¨Â§ÑÁêÜÂÆåÊàê‰∫ÜÔºåÊé•‰∏ãÊù•ÊòØword embeddingÔºåÊääÂçïËØçË°®Á§∫‰∏∫‰∏Ä‰∏™‰ΩéÁª¥ÂêëÈáèÔºõ\u003c/p\u003e\n\u003cp\u003e\u003cimg alt=\"image-20250322151252837\" loading=\"lazy\" src=\"./NLP-2.assets/image-20250322151252837.png\"\u003e\u003c/p\u003e","title":""},{"content":"üëã About me Hello! I\u0026rsquo;m Xu Zongsi, a passionate technology enthusiast currently pursuing my Master of Science in ECIC at The University of Hong Kong. With a solid background in Software Engineering from the Beijing Institute of Technology, I specialize in artificial intelligence areas like machine learning, deep learning, natural language processing, computer vision, and reinforcement learning.\nInspired by OpenAI\u0026rsquo;s five-step plan towards superintelligence, I am excited about AGI and have developed a keen interest in LLM agents, MLLM, and knowledge graphs. I see great potential in these fields and aspire to contribute to innovative solutions.\nüìö Education üá≠üá∞ The University of Hong Kong 09/2024 - Expected 11/2025 School of Computing and Data Science Master of Science in Electronic Commerce \u0026amp; Internet Computing Relevant Courses: Machine learning for business and e-commerce, Knowledge graphs, Financial fraud analytics, Internet infrastructure technologies, Website engineering, Blockchain and cryptocurrency, etc. üá®üá≥ Beijing Institute of Technology 09/2020 - 06/2024 School of Computer Science \u0026amp; Technology Bachelor of Engineering in Software Engineering, last two years GPA: 3.7/4 Relevant Courses: Reinforcement Learning, Deep Learning and Computer Vision, Artificial Intelligence and Robot Ethics, Almost Human: Mind, Brain and Artificial Intelligence, Mathematical Analysis for Engineering, Linear Algebra, Probability and Mathematical Statistics, etc. Skills: Python, Java, common data structures, design patterns, machine learning basics and algorithms, Linux, PyTorch, and some development tools (git, conda, etc.). üèÜ Awards \u0026amp; Honors Beijing Institute of Technology Undergraduate Scholarship (Top 20% of Grade) 06/2023 3rd Prize of China International \u0026#34;Internet \u0026#43;\u0026#34; College Student\u0026#39;s Innovation Competition 08/2022 Bronze Prize of \u0026#34;Challenge Cup\u0026#34; Capital University Entrepreneurship Competition 05/2022 üíº Project Experience üîç Online Transaction Fraud Detection 09/2024 ‚Äì 01/2025 Independent project, supervised by Dr. Vivien Chan Focused on addressing financial fraud in e-commerce to enhance the accuracy of transaction anomaly detection, while independently managing the entire case study that included data preprocessing, feature engineering, model building, evaluation, and results analysis. Effectively resolved class imbalance issues using SMOTE and ROSE techniques. Built various models including Logistic Regression, Random Forest, XGBoost, and LightGBM, ultimately selecting the LightGBM model to achieve a recall rate of 95.45% and an AUC of 99.84%. Wrote efficient and maintainable code, enhancing model training and data processing efficiency through parallel computing and logging. ü§ñ Multi-Model Intelligent Text Keyword Extraction System 08/2023 ‚Äì 09/2023 Group project, supervised by Associate Prof. Xiaolin Zhao Designed and implemented an intelligent text summary system that automatically extracts keywords from article titles and abstracts, enhancing the understanding and summarization of text information. Participated in the planning of the technical route and built a hybrid model combining extractive and generative approaches, utilizing advanced natural language processing techniques including KeyBERT, Sentence Transformer, BERT, and T5 models. Responsible for data preprocessing and tokenization, as well as the end-to-end implementation and training of the T5 model, optimizing the model architecture and hyperparameters, achieving satisfactory results after only 3 epochs of training. Model evaluation results showed that the Rouge-1, Rouge-2, and Rouge-L metrics reached 0.6345, 0.5038, and 0.5282, respectively, in the third epoch, validating the model\u0026rsquo;s effectiveness in the summarization task. üéì Cambridge University Machine Learning Summer Project 07/2023 ‚Äì 08/2023 Group project, supervised by Prof. Pietro Li√≤ Participated in the Cambridge University deep learning summer project, focusing on deep reinforcement learning; explored multi-agent learning algorithms across different environments. Reproduced the Multi-Agent Deep Deterministic Policy Gradient (MADDPG) algorithm in the Simple Adversary environment and studied the effect of agent numbers on convergence speed and stability, finding optimal stability at 21 agents. Designed and implemented comparative experiments inspired by the Rainbow algorithm, assessing target network strategies versus the Double Deep Q-Network (Double DQN). The results demonstrated that Double DQN significantly enhanced convergence speed, optimizing the overall learning process. Co-authored a group project paper on agent numbers and strategies effectiveness in multi-agent systems, achieving a score of 71% in the summer program (the highest in my group) and a \u0026ldquo;First Class\u0026rdquo; classification in the UK grading system. üëÅÔ∏è Deep Learning and Computer Vision Semester Project 09/2022 ‚Äì 12/2022 Independent project, supervised by Associate Prof. Guangyu Gao Designed and implemented a waste classifier using the ResNet model to improve classification accuracy and reduce resource waste. The project also enhanced understanding of transfer learning techniques with ResNet. Collected a dataset of 16 waste categories and preprocessed the images for uniformity and standardization, incorporating data augmentation techniques to enhance the dataset. Conducted experiments using ResNet34 and ResNet50 models through transfer learning, accelerating network convergence by leveraging pretrained weights. During training, techniques such as Batch Normalization and Dropout were applied to mitigate the risk of overfitting. The final model achieved an accuracy of 90% on the training set, while the performance on the test set was 61%, indicating a significant overfitting phenomenon during the training process. üéì Internship ‚öõÔ∏è Beijing Academy of Quantum Information Science 08/2023 ‚Äì 01/2024 Research Intern at Quantum Computation Department Proposed a quantum convolution kernel design based on variational quantum circuits and developed a universal quantum convolution layer, successfully integrating it into classical CNN architectures such as VGG, GoogLeNet, and ResNet. Developed and evaluated various hybrid models, including a simple model named HQCCNN-2, which achieved 84.45% accuracy on the FashionMNIST dataset, surpassing the traditional CNN\u0026rsquo;s 80.72%. This demonstrates the effectiveness of the quantum convolution layer in improving model performance. Tested on a real quantum computer further validated the effectiveness of the hybrid model, demonstrating the viable integration of quantum computing with deep learning, and highlighting the potential for leveraging quantum properties to enhance model performance. üèÖ Competition Experience ü•â China International \u0026#34;Internet \u0026#43;\u0026#34; College Students\u0026#39; Innovation Competition 08/2022 üõ°Ô∏è Zhongke Ushield: Deep Learning-based Face Privacy Protection Authentication System Responsible for constructing a localized facial feature extraction engine based on MobileFaceNet, ensuring feature extraction is completed on end devices (such as mobile phones and cameras), guaranteeing that raw data does not leave the domain and is not stored, thus enhancing user privacy protection while improving recognition efficiency. ü•â \u0026#34;Challenge Cup\u0026#34; Capital University Entrepreneurship Competition 05/2022 üå≥ Smart Orchard Responsible for the development of the fruit detection, ripeness prediction, and pest identification system, using deep convolutional neural network (CNN) technology for intelligent monitoring of crop growth conditions. Applied advanced object detection algorithms such as Faster R-CNN and YOLO to achieve high precision in apple detection and ripeness assessment, with an accuracy rate exceeding 90%, significantly enhancing the intelligence level of orchard management. Built and trained a dedicated dataset containing various pest samples, optimizing pest detection accuracy through data preprocessing (such as image normalization and resizing) and data augmentation techniques (like rotation, flipping, and noise addition), enabling the real-time monitoring system to accurately identify over 80% of pests, providing effective scientific maintenance recommendations to help farmers reduce crop losses. üìã Extracurricular Activities Vice President, Cyber Security Club, Beijing Institute of Technology 09/2021-09/2022 Backbone, Media Center of the Student Union of Beijing Institute of Technology 10/2020-06/2021 üì´ Contact üìß Email: zongsi.xu@outlook.com üëî LinkedIn: Zongsi (Tristan) Xu üíª GitHub: BaizeXS üìç Location: Hong Kong SAR, China ","permalink":"http://localhost:1313/resume/","summary":"Personal resume of Zongsi (Tristan) Xu","title":"Zongsi (Tristan) Xu"},{"content":"‰∏Ä„ÄÅÊï∞ÂÄºÁâπÂæÅ‰∏éÁ±ªÂà´ÁâπÂæÅ Êï∞ÂÄºÁâπÂæÅ (Numeric Features) ÂÖ∑ÊúâÂèØÂä†ÂáèÁöÑÊÑè‰πâÔºå‰∏îÂ≠òÂú®Â§ßÂ∞èÈ°∫Â∫è„ÄÇ ‰æãÂ≠êÔºöÂπ¥ÈæÑ„ÄÅÊ∏©Â∫¶Á≠â„ÄÇÂèØ‰ª•Áõ¥Êé•‰øùÁïôÂÖ∂Êï¥Êï∞ÊàñÊµÆÁÇπÊï∞ÂΩ¢Âºè‰æõÊ®°Âûã‰ΩøÁî®„ÄÇ Á±ªÂà´ÁâπÂæÅ (Categorical Features) Êï∞ÊçÆÂÄºÁ¶ªÊï£Ôºå‰∏çÂÖ∑Â§á‚ÄúÊï∞ÂÄºÂ§ßÂ∞è‚ÄùÈó¥ÁöÑÂèØÊØîÊÑè‰πâ„ÄÇ ‰æãÂ≠êÔºöÂõΩÁ±çÔºàÁæéÂõΩ/‰∏≠ÂõΩ/Âç∞Â∫¶Á≠âÔºâ„ÄÅÊÄßÂà´ÔºàÁî∑/Â•≥ÔºâÁ≠â„ÄÇ ÈóÆÈ¢òÔºöËã•‰ªÖÁî®Êï¥Êï∞Ë°®Á§∫ÔºàÁæéÂõΩ=1, ‰∏≠ÂõΩ=2ÔºâÔºå‰ºöÂºïÂÖ•ÈîôËØØÁöÑÊï∞ÂÄºËøêÁÆóÂÖ≥Á≥ªÔºåÂ¶Ç ‚ÄúÁæéÂõΩ + ‰∏≠ÂõΩ = Âç∞Â∫¶‚Äù„ÄÇ ‰∫å„ÄÅOne-HotÁºñÁ†ÅÁöÑÂä®Êú∫‰∏éÊµÅÁ®ã ‰∏∫‰ªÄ‰πà‰ΩøÁî®One-Hot\nÈÄöËøáÂ∞ÜÁ±ªÂà´Êò†Â∞Ñ‰∏∫ÂêëÈáèÔºåÈÅøÂÖçÊï¥Êï∞ÁºñÁ†ÅÂºïÂÖ•ÁöÑ‰º™Êï∞ÂÄºÂÖ≥Á≥ª„ÄÇ ÂêåÊó∂‰øùÁïôÂêÑÁßçÂèØËÉΩÁ±ªÂà´ÁöÑ‰ø°ÊÅØÔºå‰∏î‰ªÖÂú®ÂØπÂ∫î‰ΩçÁΩÆ‰∏∫1ÔºåÂÖ∂‰ªñ‰ΩçÁΩÆ‰∏∫0„ÄÇ Âª∫Á´ãÊò†Â∞ÑÔºö‰ªéÁ±ªÂà´Âà∞Á¥¢Âºï\n‰∏∫ÊØè‰∏™Á±ªÂà´ÂàÜÈÖç‰∏Ä‰∏™ÂîØ‰∏ÄÁ¥¢ÂºïÔºåÈÄöÂ∏∏‰ªé1ÂºÄÂßã„ÄÇ È¢ÑÁïôÁ¥¢Âºï0Ë°®Á§∫‚ÄúÊú™Áü•‚ÄùÊàñ‚ÄúÁº∫Â§±‚ÄùÔºåÂØπÂ∫îÂÖ®0ÂêëÈáè„ÄÇ ËΩ¨Êç¢‰∏∫One-HotÂêëÈáè\nËã•Á±ªÂà´ÊÄªÊï∞‰∏∫197ÔºåÂàôÁî®197Áª¥ÂêëÈáèË°®Á§∫„ÄÇ ‰æãÂ≠êÔºöÁæéÂõΩ [1, 0, 0, 0, ‚Ä¶]Ôºå ‰∏≠ÂõΩ [0, 1, 0, 0, ‚Ä¶]„ÄÇ Á§∫‰æãÔºöË°®Á§∫‰∏Ä‰∏™‰∫∫ÁöÑÁâπÂæÅ\nÁâπÂæÅÂåÖÂê´ÔºàÂπ¥ÈæÑ, ÊÄßÂà´, ÂõΩÁ±çÔºåÂÖ∂‰∏≠ÂõΩÁ±ç197ÁßçÔºâ Áª¥Â∫¶ÊÄªÂíåÔºö1Áª¥_age + 1Áª¥_gender + 197Áª¥_nationality = 199Áª¥„ÄÇ ‰æãÂ¶Ç (28, Â•≥, ‰∏≠ÂõΩ) ‚Üí [28, 0, 0, 1, 0, ‚Ä¶, 0]„ÄÇ ‰∏â„ÄÅÊñáÊú¨Êï∞ÊçÆÂ§ÑÁêÜÊµÅÁ®ã ÊñáÊú¨Âú®Ëá™ÁÑ∂ËØ≠Ë®ÄÂ§ÑÁêÜÔºàNLPÔºâ‰∏≠‰Ωú‰∏∫Â∏∏ËßÅÁöÑÂéüÂßãËæìÂÖ•ÔºåÈúÄË¶ÅÊï∞ÂÄºÂåñÊâçËÉΩÈÄÅÂÖ•Ê®°Âûã„ÄÇ‰∏ÄËà¨Ê≠•È™§Â¶Ç‰∏ãÔºö\nÂàÜËØç (Tokenization)\nÂ∞ÜÊñáÊú¨ÊãÜÂàÜ‰∏∫‰∏Ä‰∏™‰∏™ÂçïËØçÔºàTokenÔºâ„ÄÇ ‰æãÂ≠êÔºö\u0026quot;... to be or not to be...\u0026quot; ‚Üí [\u0026quot;...\u0026quot;, \u0026quot;to\u0026quot;, \u0026quot;be\u0026quot;, \u0026quot;or\u0026quot;, \u0026quot;not\u0026quot;, \u0026quot;to\u0026quot;, \u0026quot;be\u0026quot;, \u0026quot;...\u0026quot;]„ÄÇ ÁªüËÆ°ËØçÈ¢ë \u0026amp; ÊûÑÂª∫ËØçÂÖ∏\nËØçÈ¢ëÁªüËÆ° Áî®ÂìàÂ∏åË°®/Â≠óÂÖ∏ËÆ∞ÂΩïÊØè‰∏™ÂçïËØçÂá∫Áé∞Ê¨°Êï∞„ÄÇ ÈÅçÂéÜÊñáÊú¨Êó∂ÔºåËã•ÂçïËØçÂ∞öÊú™ÂÖ•Ë°®ÔºåÂàôÊñ∞Âª∫ËÆ∞ÂΩïÔºõËã•Â∑≤Â≠òÂú®ÔºåÂàôËÆ°Êï∞+1„ÄÇ ÊéíÂ∫è‰∏éÁ¥¢Âºï ÊåâËØçÈ¢ëÈôçÂ∫èÊéíÂ∫èÔºåËØçÈ¢ëÊúÄÈ´òÁöÑÂçïËØçÊéíÂú®ÂâçÈù¢„ÄÇ Á¥¢Âºï‰ªé1ÂºÄÂßãÔºå0ÁïôÁªô‚ÄúÊú™Áü•‚Äù„ÄÇ ËØçÂÖ∏ËßÑÊ®°ÔºàvocabularyÔºâÂèØËßÜÈúÄÊ±ÇÊà™Êñ≠Ôºà‰æãÂ¶ÇÂè™‰øùÁïôTop 10kÔºâ„ÄÇ ‰∏∫‰ªÄ‰πàÁßªÈô§‰ΩéÈ¢ëËØç ‰ΩéÈ¢ëËØçÂèØËÉΩÊòØÊãºÂÜôÈîôËØØ„ÄÅÁΩïËßÅ‰∫∫ÂêçÁ≠âÔºåÂØπÊ®°ÂûãÂ∏ÆÂä©ÊúâÈôê„ÄÇ ÂáèÂ∞ëËØçÂÖ∏ËßÑÊ®°ÂèØÈôç‰ΩéËøêÁÆóÂºÄÈîÄ„ÄÅÂä†Âø´Ê®°ÂûãËÆ≠ÁªÉ‰∏éÊé®ÁêÜÈÄüÂ∫¶„ÄÇ Áã¨ÁÉ≠ÁºñÁ†Å (One-Hot Encoding)\nÂ∞ÜÊØè‰∏™ÂçïËØçÊò†Â∞Ñ‰∏∫ËØçÂÖ∏‰∏≠ÁöÑÁ¥¢ÂºïÂêéÔºàÂ¶Ç [2, 4, 1, 8, ‚Ä¶]ÔºâÔºåÂèØËøõ‰∏ÄÊ≠•ËΩ¨Êç¢ÊàêOne-HotÂêëÈáè„ÄÇ One-HotÁª¥Â∫¶ÂèñÂÜ≥‰∫é‰øùÁïô‰∏ãÊù•ÁöÑËØçÂÖ∏Â§ßÂ∞èÔºà‰æãÂ¶Ç1‰∏áÔºâ„ÄÇ Êú™Êî∂ÂΩïÂçïËØçÂèØËÉΩÁõ¥Êé•ÂøΩÁï•ÔºåÊàñÁªü‰∏ÄÁî®Á¥¢Âºï0‰ª£Êõø„ÄÇ Âõõ„ÄÅÊ†∏ÂøÉÊî∂Ëé∑‰∏éÂ∫îÁî® Á±ªÂà´ÁâπÂæÅÂøÖÈúÄÊï∞ÂÄºÂåñÔºö\n‰ΩøÁî®Êï¥Êï∞1,2,3‚Ä¶‰ªÖË°®Á§∫Á±ªÂà´‚ÄúÊ†áËØÜ‚ÄùÔºåÂπ∂‰∏ç‰ª£Ë°®ÂÆÉ‰ª¨ÂèØËøõË°åÊï∞ÂÄºËøêÁÆó„ÄÇ Âõ†Ê≠§ÈúÄË¶ÅOne-HotÁ≠âÁºñÁ†ÅÊñπÂºèÔºåÈÅøÂÖçÊï∞ÂÄºËØØËß£„ÄÇ ÊñáÊú¨Êï∞ÊçÆÈ¢ÑÂ§ÑÁêÜÔºö\nÂàÜËØç„ÄÅËØçÈ¢ëÁªüËÆ°„ÄÅÊûÑÂª∫ËØçÂÖ∏„ÄÅÁ¥¢ÂºïÂåñ„ÄÅOne-HotÊàñÂÖ∂‰ªñÊñπÂºèÔºàÂ¶ÇËØçÂµåÂÖ•ÔºâÊòØÂ∏∏ËßÅÊµÅÁ®ã„ÄÇ Ê≠£Á°ÆÁöÑÊñáÊú¨È¢ÑÂ§ÑÁêÜÂèØÊòæËëóÂΩ±ÂìçÊ®°ÂûãÊÄßËÉΩÂíåÊïàÁéá„ÄÇ ‰øùÁïôÊú™Áü•Á¥¢ÂºïÔºö\n‰øùËØÅÂØπÁº∫Â§±Êï∞ÊçÆÊàñÂ≠óÂÖ∏Â§ñÊñ∞ËØçËÉΩÊúâÂü∫Êú¨ÁöÑË°®Á§∫ÔºåÊèêÂçáÊ®°ÂûãÂÆπÈîôÊÄß„ÄÇ ÂÆûÈôÖ‰ΩøÁî®Ôºö\nÂØπ‰∫éÂ∞èËßÑÊ®°Á±ªÂà´ÂèØÁõ¥Êé•One-HotÁºñÁ†ÅÔºõÂØπ‰∫éËØçÂÖ∏ÂæàÂ§ßÁöÑÂú∫ÊôØÔºåÈÄöÂ∏∏‰ºöËøõ‰∏ÄÊ≠•ËÄÉËôëËØçÂµåÂÖ•ÔºàWord EmbeddingÔºâÊàñÈ¢ÑËÆ≠ÁªÉËØ≠Ë®ÄÊ®°Âûã„ÄÇ ","permalink":"http://localhost:1313/posts/nlp-1/","summary":"\u003ch2 id=\"‰∏ÄÊï∞ÂÄºÁâπÂæÅ‰∏éÁ±ªÂà´ÁâπÂæÅ\"\u003e‰∏Ä„ÄÅÊï∞ÂÄºÁâπÂæÅ‰∏éÁ±ªÂà´ÁâπÂæÅ\u003c/h2\u003e\n\u003col\u003e\n\u003cli\u003e\u003cstrong\u003eÊï∞ÂÄºÁâπÂæÅ (Numeric Features)\u003c/strong\u003e\n\u003cul\u003e\n\u003cli\u003eÂÖ∑ÊúâÂèØÂä†ÂáèÁöÑÊÑè‰πâÔºå‰∏îÂ≠òÂú®Â§ßÂ∞èÈ°∫Â∫è„ÄÇ\u003c/li\u003e\n\u003cli\u003e‰æãÂ≠êÔºöÂπ¥ÈæÑ„ÄÅÊ∏©Â∫¶Á≠â„ÄÇÂèØ‰ª•Áõ¥Êé•‰øùÁïôÂÖ∂Êï¥Êï∞ÊàñÊµÆÁÇπÊï∞ÂΩ¢Âºè‰æõÊ®°Âûã‰ΩøÁî®„ÄÇ\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003eÁ±ªÂà´ÁâπÂæÅ (Categorical Features)\u003c/strong\u003e\n\u003cul\u003e\n\u003cli\u003eÊï∞ÊçÆÂÄºÁ¶ªÊï£Ôºå‰∏çÂÖ∑Â§á‚ÄúÊï∞ÂÄºÂ§ßÂ∞è‚ÄùÈó¥ÁöÑÂèØÊØîÊÑè‰πâ„ÄÇ\u003c/li\u003e\n\u003cli\u003e‰æãÂ≠êÔºöÂõΩÁ±çÔºàÁæéÂõΩ/‰∏≠ÂõΩ/Âç∞Â∫¶Á≠âÔºâ„ÄÅÊÄßÂà´ÔºàÁî∑/Â•≥ÔºâÁ≠â„ÄÇ\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003eÈóÆÈ¢ò\u003c/strong\u003eÔºöËã•‰ªÖÁî®Êï¥Êï∞Ë°®Á§∫ÔºàÁæéÂõΩ=1, ‰∏≠ÂõΩ=2ÔºâÔºå‰ºöÂºïÂÖ•ÈîôËØØÁöÑÊï∞ÂÄºËøêÁÆóÂÖ≥Á≥ªÔºåÂ¶Ç ‚ÄúÁæéÂõΩ + ‰∏≠ÂõΩ = Âç∞Â∫¶‚Äù„ÄÇ\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003c/ol\u003e\n\u003ch2 id=\"‰∫åone-hotÁºñÁ†ÅÁöÑÂä®Êú∫‰∏éÊµÅÁ®ã\"\u003e‰∫å„ÄÅOne-HotÁºñÁ†ÅÁöÑÂä®Êú∫‰∏éÊµÅÁ®ã\u003c/h2\u003e\n\u003col\u003e\n\u003cli\u003e\n\u003cp\u003e\u003cstrong\u003e‰∏∫‰ªÄ‰πà‰ΩøÁî®One-Hot\u003c/strong\u003e\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eÈÄöËøáÂ∞ÜÁ±ªÂà´Êò†Â∞Ñ‰∏∫ÂêëÈáèÔºåÈÅøÂÖçÊï¥Êï∞ÁºñÁ†ÅÂºïÂÖ•ÁöÑ‰º™Êï∞ÂÄºÂÖ≥Á≥ª„ÄÇ\u003c/li\u003e\n\u003cli\u003eÂêåÊó∂‰øùÁïôÂêÑÁßçÂèØËÉΩÁ±ªÂà´ÁöÑ‰ø°ÊÅØÔºå‰∏î‰ªÖÂú®ÂØπÂ∫î‰ΩçÁΩÆ‰∏∫1ÔºåÂÖ∂‰ªñ‰ΩçÁΩÆ‰∏∫0„ÄÇ\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003e\u003cstrong\u003eÂª∫Á´ãÊò†Â∞ÑÔºö‰ªéÁ±ªÂà´Âà∞Á¥¢Âºï\u003c/strong\u003e\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e‰∏∫ÊØè‰∏™Á±ªÂà´ÂàÜÈÖç‰∏Ä‰∏™ÂîØ‰∏ÄÁ¥¢ÂºïÔºåÈÄöÂ∏∏‰ªé1ÂºÄÂßã„ÄÇ\u003c/li\u003e\n\u003cli\u003eÈ¢ÑÁïôÁ¥¢Âºï0Ë°®Á§∫‚ÄúÊú™Áü•‚ÄùÊàñ‚ÄúÁº∫Â§±‚ÄùÔºåÂØπÂ∫îÂÖ®0ÂêëÈáè„ÄÇ\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003e\u003cstrong\u003eËΩ¨Êç¢‰∏∫One-HotÂêëÈáè\u003c/strong\u003e\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eËã•Á±ªÂà´ÊÄªÊï∞‰∏∫197ÔºåÂàôÁî®197Áª¥ÂêëÈáèË°®Á§∫„ÄÇ\u003c/li\u003e\n\u003cli\u003e‰æãÂ≠êÔºöÁæéÂõΩ \u003ccode\u003e[1, 0, 0, 0, ‚Ä¶]\u003c/code\u003eÔºå ‰∏≠ÂõΩ \u003ccode\u003e[0, 1, 0, 0, ‚Ä¶]\u003c/code\u003e„ÄÇ\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003e\u003cstrong\u003eÁ§∫‰æãÔºöË°®Á§∫‰∏Ä‰∏™‰∫∫ÁöÑÁâπÂæÅ\u003c/strong\u003e\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eÁâπÂæÅÂåÖÂê´ÔºàÂπ¥ÈæÑ, ÊÄßÂà´, ÂõΩÁ±çÔºåÂÖ∂‰∏≠ÂõΩÁ±ç197ÁßçÔºâ\u003c/li\u003e\n\u003cli\u003eÁª¥Â∫¶ÊÄªÂíåÔºö1Áª¥_age + 1Áª¥_gender + 197Áª¥_nationality = 199Áª¥„ÄÇ\u003c/li\u003e\n\u003cli\u003e‰æãÂ¶Ç \u003ccode\u003e(28, Â•≥, ‰∏≠ÂõΩ)\u003c/code\u003e ‚Üí \u003ccode\u003e[28, 0, 0, 1, 0, ‚Ä¶, 0]\u003c/code\u003e„ÄÇ\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003c/ol\u003e\n\u003ch2 id=\"‰∏âÊñáÊú¨Êï∞ÊçÆÂ§ÑÁêÜÊµÅÁ®ã\"\u003e‰∏â„ÄÅÊñáÊú¨Êï∞ÊçÆÂ§ÑÁêÜÊµÅÁ®ã\u003c/h2\u003e\n\u003cp\u003eÊñáÊú¨Âú®Ëá™ÁÑ∂ËØ≠Ë®ÄÂ§ÑÁêÜÔºàNLPÔºâ‰∏≠‰Ωú‰∏∫Â∏∏ËßÅÁöÑÂéüÂßãËæìÂÖ•ÔºåÈúÄË¶ÅÊï∞ÂÄºÂåñÊâçËÉΩÈÄÅÂÖ•Ê®°Âûã„ÄÇ‰∏ÄËà¨Ê≠•È™§Â¶Ç‰∏ãÔºö\u003c/p\u003e\n\u003col\u003e\n\u003cli\u003e\n\u003cp\u003e\u003cstrong\u003eÂàÜËØç (Tokenization)\u003c/strong\u003e\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eÂ∞ÜÊñáÊú¨ÊãÜÂàÜ‰∏∫‰∏Ä‰∏™‰∏™ÂçïËØçÔºàTokenÔºâ„ÄÇ\u003c/li\u003e\n\u003cli\u003e‰æãÂ≠êÔºö\u003ccode\u003e\u0026quot;... to be or not to be...\u0026quot;\u003c/code\u003e ‚Üí \u003ccode\u003e[\u0026quot;...\u0026quot;, \u0026quot;to\u0026quot;, \u0026quot;be\u0026quot;, \u0026quot;or\u0026quot;, \u0026quot;not\u0026quot;, \u0026quot;to\u0026quot;, \u0026quot;be\u0026quot;, \u0026quot;...\u0026quot;]\u003c/code\u003e„ÄÇ\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003e\u003cstrong\u003eÁªüËÆ°ËØçÈ¢ë \u0026amp; ÊûÑÂª∫ËØçÂÖ∏\u003c/strong\u003e\u003c/p\u003e","title":""},{"content":"Text to Sequence ÊñáÊú¨Â§ÑÁêÜ\nStep1: Tokenization\nTokenization breaks a piece of text down into a list of tokens.\nHere, a token is a word. (A token can be a character in some applications.)\nTokenizationËÆ≤Á©∂ÂæàÂ§öÔºå‰æãÂ¶ÇÊòØÂê¶Â∫îËØ•ÊääÂ§ßÂÜôÊîπÊàêÂ∞èÂÜôÂë¢ÔºüËøõË°åtypo correctionÁ≠âÁ≠â\nStep2: Build Dictionary\nUse a dictionary (hash table) to count word frequencies.\nThe dictionary maps word to index.\nÂèØ‰ª•È¶ñÂÖàÁªüËÆ°ËØçÈ¢ëÂéªÊéâ‰ΩéÈ¢ëËØçÔºåÁÑ∂ÂêéËÆ©ÊØè‰∏™ËØçÂØπÂ∫î‰∏Ä‰∏™Ê≠£Êï¥Êï∞ÔºõËøôÊ†∑ÁöÑËØùÔºå‰∏ÄÂè•ËØùÂ∞±ÂèØ‰ª•Áî®‰∏Ä‰∏™Ê≠£Êï¥Êï∞ÂàóË°®Ë°®Á§∫ÔºåËøô‰∏™ÂàóË°®Â∞±Âè´sequenceÔºõÂ¶ÇÊûúÂøÖË¶ÅÂ∞±ËøòÂæóÂÅöone-hot encoding„ÄÇ\nÁªìÊûú\n‰ΩÜÊòØÈïøÂ∫¶‰∏çÁªü‰∏Ä\nStep4: ÂØπÈΩêsequence\nËß£ÂÜ≥ÊñπÊ°àÊòØËøôÊ†∑ÁöÑÔºöÂèØ‰ª•Âõ∫ÂÆöÈïøÂ∫¶‰∏∫wÔºåÂä†ÂÖ•‰∏Ä‰∏™Â∫èÂàóÈïøÂ∫¶Â§™ÈïøÔºåÂ∞±Á†çÊéâÂâçÈù¢ÁöÑËØçÔºåÂè™‰øùÁïôÊúÄÂêéw‰∏™ËØçÔºõÂ¶ÇÊûú‰∏Ä‰∏™Â∫èÂàóÂ§™Áü≠ÔºåÂ∞±ÂÅözero paddingÔºåÁî®0Â°´ÂÖÖ\nËøôÊ†∑‰∏ÄÊù•ÔºåÊâÄÊúâÁöÑÂ∫èÂàóÈïøÂ∫¶Â∞±Áªü‰∏Ä‰∫Ü\nÊñáÊú¨Â§ÑÁêÜÂÆåÊàê‰∫ÜÔºåÊé•‰∏ãÊù•ÊòØword embeddingÔºåÊääÂçïËØçË°®Á§∫‰∏∫‰∏Ä‰∏™‰ΩéÁª¥ÂêëÈáèÔºõ\nÁÑ∂ËÄåËøôÊ†∑ÂÅöÁöÑËØùÔºåÂ¶ÇÊûúÊòØ10000‰∏™ÂçïËØçÔºåÁª¥Â∫¶Â∞±ÊòØ10000Áª¥ÔºåÁª¥Â∫¶Â§™È´ò‰∫ÜÔºõÂõ†Ê≠§Ë¶ÅÂÅöword embeddingÔºõ\nÂÖ∑‰ΩìÂÅöÊ≥ïÂ∞±ÊòØÊääone-hotÂêëÈáèe_iÂíåÂèÇÊï∞Áü©ÈòµpÁõ∏‰πòÔºõÁü©ÈòµPËΩ¨ÁΩÆÁöÑÂ§ßÂ∞èÊòØd x vÔºõdÊòØËØçÂêëÈáèÁöÑÁª¥Â∫¶ÔºõvÊòØÂ≠óÂÖ∏ÈáåËØçÊ±áÁöÑÊï∞ÈáèÔºõÁªìÊûú‰∏∫x_iÔºõx_iÂ∞±ÊòØ‰∏Ä‰∏™ËØçÂêëÈáèÔºõÂ¶ÇÊûúone-hotÂêëÈáèÁöÑÁ¨¨‰∏âË°å‰∏∫1ÔºõÈÇ£‰πàx_iÂ∞±ÊòØPËΩ¨ÁΩÆÁü©ÈòµÁöÑÁ¨¨‰∏âÂàóÔºàÂÖ∂‰ΩôÂàóÈÉΩ‰∏∫0ÔºâÔºõÊâÄ‰ª•PËΩ¨ÁΩÆÊØè‰∏ÄÂàóÈÉΩÊòØ‰∏Ä‰∏™ËØçÂêëÈáèÔºõÊâÄ‰ª•Áü©ÈòµPÊú¨Ë∫´ÁöÑÊØè‰∏ÄË°åÂ∞±ÊòØ‰∏Ä‰∏™ËØçÂêëÈáèÔºõÂÖ∂Ë°åÊï∞‰∏∫vÔºõÂç≥vocabularyÔºåËØçÊ±áÈáèÔºõÊØè‰∏ÄË°åÂØπÂ∫î‰∏Ä‰∏™ÂçïËØçÔºõÁü©ÈòµÁöÑÂàóÊï∞‰∏∫dÔºõdÊòØÁî®Êà∑ÂÜ≥ÂÆöÁöÑÔºõdÁöÑÂ§ßÂ∞è‰ºöÂÜ≥ÂÆöÊú∫Âô®Â≠¶‰π†Ê®°ÂûãÁöÑË°®Áé∞ÔºõÂ∫îËØ•Áî®xxxÊù•ÈÄâÊã©‰∏Ä‰∏™ÊØîËæÉÂ•ΩÁöÑdÔºõ\nÊàë‰ª¨ÁöÑ‰ªªÂä°ÊòØÁúãËØÑËÆ∫ÊòØÊ≠£Èù¢ÁöÑËøòÊòØË¥üÈù¢ÁöÑÔºõÂèÇÊï∞Áü©ÈòµÊòØ‰ªéËÆ≠ÁªÉÊï∞ÊçÆ‰∏≠Â≠¶‰π†Âá∫Êù•ÁöÑÔºåÊâÄ‰ª•Â≠¶Âá∫Êù•ÁöÑËØçÂêëÈáèÊòØÂ∏¶ÊúâÊÑüÊÉÖËâ≤ÂΩ©ÁöÑÔºõÂÅáËÆæËøô‰∫õËØçÂêëÈáèÈÉΩÊòØ‰∫åÁª¥ÁöÑÔºåÂàôÂèØ‰ª•Âú®Âπ≥Èù¢ÂùêÊ†áÁ≥ª‰∏≠Ê†áÂá∫‰∏ãÈù¢ËØçÂêëÈáè\nkerasÊèê‰æõembeddingÂ±ÇÔºõÁî®Êà∑ÂèØ‰ª•ÊåáÂÆövocabularyÂ§ßÂ∞èÂíådÁöÑÂ§ßÂ∞èÔºõ‰ª•ÂèäÊØè‰∏Ä‰∏™sequenceÁöÑÈïøÂ∫¶ÔºõdÊòØÊ†πÊçÆÁÆóÊ≥ïÈÄâÂá∫Êù•ÁöÑ Âà∞Ëøô‰∏ÄÊ≠•ÔºåÊàë‰ª¨Â∑≤ÁªèÂÆåÊàê‰∫ÜÊñáÊú¨Â§ÑÁêÜÂíåword embedding„ÄÇÊé•‰∏ãÊù•Â∞±ÊòØÁî®Logistic Regression for Binary ClassificationÂÅö‰∫åÂàÜÁ±ªÔºõ\n","permalink":"http://localhost:1313/posts/nlp-2/","summary":"\u003ch3 id=\"text-to-sequence\"\u003eText to Sequence\u003c/h3\u003e\n\u003cp\u003eÊñáÊú¨Â§ÑÁêÜ\u003c/p\u003e\n\u003cp\u003eStep1: Tokenization\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\n\u003cp\u003eTokenization breaks a piece of text down into a list of tokens.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003eHere, a token is a word. (A token can be a character in some applications.)\u003c/p\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003eTokenizationËÆ≤Á©∂ÂæàÂ§öÔºå‰æãÂ¶ÇÊòØÂê¶Â∫îËØ•ÊääÂ§ßÂÜôÊîπÊàêÂ∞èÂÜôÂë¢ÔºüËøõË°åtypo correctionÁ≠âÁ≠â\u003c/p\u003e\n\u003cp\u003e\u003cimg alt=\"image-20250322150322238\" loading=\"lazy\" src=\"./NLP-2.assets/image-20250322150322238.png\"\u003e\u003c/p\u003e\n\u003cp\u003eStep2: Build Dictionary\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\n\u003cp\u003eUse a dictionary (hash table) to count word frequencies.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003eThe dictionary maps word to index.\u003c/p\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003eÂèØ‰ª•È¶ñÂÖàÁªüËÆ°ËØçÈ¢ëÂéªÊéâ‰ΩéÈ¢ëËØçÔºåÁÑ∂ÂêéËÆ©ÊØè‰∏™ËØçÂØπÂ∫î‰∏Ä‰∏™Ê≠£Êï¥Êï∞ÔºõËøôÊ†∑ÁöÑËØùÔºå‰∏ÄÂè•ËØùÂ∞±ÂèØ‰ª•Áî®‰∏Ä‰∏™Ê≠£Êï¥Êï∞ÂàóË°®Ë°®Á§∫ÔºåËøô‰∏™ÂàóË°®Â∞±Âè´sequenceÔºõÂ¶ÇÊûúÂøÖË¶ÅÂ∞±ËøòÂæóÂÅöone-hot encoding„ÄÇ\u003cimg alt=\"image-20250322150620890\" loading=\"lazy\" src=\"./NLP-2.assets/image-20250322150620890.png\"\u003e\u003c/p\u003e\n\u003cp\u003eÁªìÊûú\u003c/p\u003e\n\u003cp\u003e\u003cimg alt=\"image-20250322150754528\" loading=\"lazy\" src=\"./NLP-2.assets/image-20250322150754528.png\"\u003e\u003c/p\u003e\n\u003cp\u003e‰ΩÜÊòØÈïøÂ∫¶‰∏çÁªü‰∏Ä\u003c/p\u003e\n\u003cp\u003eStep4: ÂØπÈΩêsequence\u003c/p\u003e\n\u003cp\u003e\u003cimg alt=\"image-20250322150854986\" loading=\"lazy\" src=\"./NLP-2.assets/image-20250322150854986.png\"\u003e\u003c/p\u003e\n\u003cp\u003eËß£ÂÜ≥ÊñπÊ°àÊòØËøôÊ†∑ÁöÑÔºöÂèØ‰ª•Âõ∫ÂÆöÈïøÂ∫¶‰∏∫wÔºåÂä†ÂÖ•‰∏Ä‰∏™Â∫èÂàóÈïøÂ∫¶Â§™ÈïøÔºåÂ∞±Á†çÊéâÂâçÈù¢ÁöÑËØçÔºåÂè™‰øùÁïôÊúÄÂêéw‰∏™ËØçÔºõÂ¶ÇÊûú‰∏Ä‰∏™Â∫èÂàóÂ§™Áü≠ÔºåÂ∞±ÂÅözero paddingÔºåÁî®0Â°´ÂÖÖ\u003c/p\u003e\n\u003cp\u003e\u003cimg alt=\"image-20250322151030119\" loading=\"lazy\" src=\"./NLP-2.assets/image-20250322151030119.png\"\u003e\u003c/p\u003e\n\u003cp\u003eËøôÊ†∑‰∏ÄÊù•ÔºåÊâÄÊúâÁöÑÂ∫èÂàóÈïøÂ∫¶Â∞±Áªü‰∏Ä‰∫Ü\u003c/p\u003e\n\u003cp\u003e\u003cimg alt=\"image-20250322151117125\" loading=\"lazy\" src=\"./NLP-2.assets/image-20250322151117125.png\"\u003e\u003c/p\u003e\n\u003cp\u003eÊñáÊú¨Â§ÑÁêÜÂÆåÊàê‰∫ÜÔºåÊé•‰∏ãÊù•ÊòØword embeddingÔºåÊääÂçïËØçË°®Á§∫‰∏∫‰∏Ä‰∏™‰ΩéÁª¥ÂêëÈáèÔºõ\u003c/p\u003e\n\u003cp\u003e\u003cimg alt=\"image-20250322151252837\" loading=\"lazy\" src=\"./NLP-2.assets/image-20250322151252837.png\"\u003e\u003c/p\u003e","title":""},{"content":"üëã About me Hello! I\u0026rsquo;m Xu Zongsi, a passionate technology enthusiast currently pursuing my Master of Science in ECIC at The University of Hong Kong. With a solid background in Software Engineering from the Beijing Institute of Technology, I specialize in artificial intelligence areas like machine learning, deep learning, natural language processing, computer vision, and reinforcement learning.\nInspired by OpenAI\u0026rsquo;s five-step plan towards superintelligence, I am excited about AGI and have developed a keen interest in LLM agents, MLLM, and knowledge graphs. I see great potential in these fields and aspire to contribute to innovative solutions.\nüìö Education üá≠üá∞ The University of Hong Kong 09/2024 - Expected 11/2025 School of Computing and Data Science Master of Science in Electronic Commerce \u0026amp; Internet Computing Relevant Courses: Machine learning for business and e-commerce, Knowledge graphs, Financial fraud analytics, Internet infrastructure technologies, Website engineering, Blockchain and cryptocurrency, etc. üá®üá≥ Beijing Institute of Technology 09/2020 - 06/2024 School of Computer Science \u0026amp; Technology Bachelor of Engineering in Software Engineering, last two years GPA: 3.7/4 Relevant Courses: Reinforcement Learning, Deep Learning and Computer Vision, Artificial Intelligence and Robot Ethics, Almost Human: Mind, Brain and Artificial Intelligence, Mathematical Analysis for Engineering, Linear Algebra, Probability and Mathematical Statistics, etc. Skills: Python, Java, common data structures, design patterns, machine learning basics and algorithms, Linux, PyTorch, and some development tools (git, conda, etc.). üèÜ Awards \u0026amp; Honors Beijing Institute of Technology Undergraduate Scholarship (Top 20% of Grade) 06/2023 3rd Prize of China International \u0026#34;Internet \u0026#43;\u0026#34; College Student\u0026#39;s Innovation Competition 08/2022 Bronze Prize of \u0026#34;Challenge Cup\u0026#34; Capital University Entrepreneurship Competition 05/2022 üíº Project Experience üîç Online Transaction Fraud Detection 09/2024 ‚Äì 01/2025 Independent project, supervised by Dr. Vivien Chan Focused on addressing financial fraud in e-commerce to enhance the accuracy of transaction anomaly detection, while independently managing the entire case study that included data preprocessing, feature engineering, model building, evaluation, and results analysis. Effectively resolved class imbalance issues using SMOTE and ROSE techniques. Built various models including Logistic Regression, Random Forest, XGBoost, and LightGBM, ultimately selecting the LightGBM model to achieve a recall rate of 95.45% and an AUC of 99.84%. Wrote efficient and maintainable code, enhancing model training and data processing efficiency through parallel computing and logging. ü§ñ Multi-Model Intelligent Text Keyword Extraction System 08/2023 ‚Äì 09/2023 Group project, supervised by Associate Prof. Xiaolin Zhao Designed and implemented an intelligent text summary system that automatically extracts keywords from article titles and abstracts, enhancing the understanding and summarization of text information. Participated in the planning of the technical route and built a hybrid model combining extractive and generative approaches, utilizing advanced natural language processing techniques including KeyBERT, Sentence Transformer, BERT, and T5 models. Responsible for data preprocessing and tokenization, as well as the end-to-end implementation and training of the T5 model, optimizing the model architecture and hyperparameters, achieving satisfactory results after only 3 epochs of training. Model evaluation results showed that the Rouge-1, Rouge-2, and Rouge-L metrics reached 0.6345, 0.5038, and 0.5282, respectively, in the third epoch, validating the model\u0026rsquo;s effectiveness in the summarization task. üéì Cambridge University Machine Learning Summer Project 07/2023 ‚Äì 08/2023 Group project, supervised by Prof. Pietro Li√≤ Participated in the Cambridge University deep learning summer project, focusing on deep reinforcement learning; explored multi-agent learning algorithms across different environments. Reproduced the Multi-Agent Deep Deterministic Policy Gradient (MADDPG) algorithm in the Simple Adversary environment and studied the effect of agent numbers on convergence speed and stability, finding optimal stability at 21 agents. Designed and implemented comparative experiments inspired by the Rainbow algorithm, assessing target network strategies versus the Double Deep Q-Network (Double DQN). The results demonstrated that Double DQN significantly enhanced convergence speed, optimizing the overall learning process. Co-authored a group project paper on agent numbers and strategies effectiveness in multi-agent systems, achieving a score of 71% in the summer program (the highest in my group) and a \u0026ldquo;First Class\u0026rdquo; classification in the UK grading system. üëÅÔ∏è Deep Learning and Computer Vision Semester Project 09/2022 ‚Äì 12/2022 Independent project, supervised by Associate Prof. Guangyu Gao Designed and implemented a waste classifier using the ResNet model to improve classification accuracy and reduce resource waste. The project also enhanced understanding of transfer learning techniques with ResNet. Collected a dataset of 16 waste categories and preprocessed the images for uniformity and standardization, incorporating data augmentation techniques to enhance the dataset. Conducted experiments using ResNet34 and ResNet50 models through transfer learning, accelerating network convergence by leveraging pretrained weights. During training, techniques such as Batch Normalization and Dropout were applied to mitigate the risk of overfitting. The final model achieved an accuracy of 90% on the training set, while the performance on the test set was 61%, indicating a significant overfitting phenomenon during the training process. üéì Internship ‚öõÔ∏è Beijing Academy of Quantum Information Science 08/2023 ‚Äì 01/2024 Research Intern at Quantum Computation Department Proposed a quantum convolution kernel design based on variational quantum circuits and developed a universal quantum convolution layer, successfully integrating it into classical CNN architectures such as VGG, GoogLeNet, and ResNet. Developed and evaluated various hybrid models, including a simple model named HQCCNN-2, which achieved 84.45% accuracy on the FashionMNIST dataset, surpassing the traditional CNN\u0026rsquo;s 80.72%. This demonstrates the effectiveness of the quantum convolution layer in improving model performance. Tested on a real quantum computer further validated the effectiveness of the hybrid model, demonstrating the viable integration of quantum computing with deep learning, and highlighting the potential for leveraging quantum properties to enhance model performance. üèÖ Competition Experience ü•â China International \u0026#34;Internet \u0026#43;\u0026#34; College Students\u0026#39; Innovation Competition 08/2022 üõ°Ô∏è Zhongke Ushield: Deep Learning-based Face Privacy Protection Authentication System Responsible for constructing a localized facial feature extraction engine based on MobileFaceNet, ensuring feature extraction is completed on end devices (such as mobile phones and cameras), guaranteeing that raw data does not leave the domain and is not stored, thus enhancing user privacy protection while improving recognition efficiency. ü•â \u0026#34;Challenge Cup\u0026#34; Capital University Entrepreneurship Competition 05/2022 üå≥ Smart Orchard Responsible for the development of the fruit detection, ripeness prediction, and pest identification system, using deep convolutional neural network (CNN) technology for intelligent monitoring of crop growth conditions. Applied advanced object detection algorithms such as Faster R-CNN and YOLO to achieve high precision in apple detection and ripeness assessment, with an accuracy rate exceeding 90%, significantly enhancing the intelligence level of orchard management. Built and trained a dedicated dataset containing various pest samples, optimizing pest detection accuracy through data preprocessing (such as image normalization and resizing) and data augmentation techniques (like rotation, flipping, and noise addition), enabling the real-time monitoring system to accurately identify over 80% of pests, providing effective scientific maintenance recommendations to help farmers reduce crop losses. üìã Extracurricular Activities Vice President, Cyber Security Club, Beijing Institute of Technology 09/2021-09/2022 Backbone, Media Center of the Student Union of Beijing Institute of Technology 10/2020-06/2021 üì´ Contact üìß Email: zongsi.xu@outlook.com üëî LinkedIn: Zongsi (Tristan) Xu üíª GitHub: BaizeXS üìç Location: Hong Kong SAR, China ","permalink":"http://localhost:1313/resume/","summary":"Personal resume of Zongsi (Tristan) Xu","title":"Zongsi (Tristan) Xu"},{"content":"‰∏Ä„ÄÅÊï∞ÂÄºÁâπÂæÅ‰∏éÁ±ªÂà´ÁâπÂæÅ Êï∞ÂÄºÁâπÂæÅ (Numeric Features) ÂÖ∑ÊúâÂèØÂä†ÂáèÁöÑÊÑè‰πâÔºå‰∏îÂ≠òÂú®Â§ßÂ∞èÈ°∫Â∫è„ÄÇ ‰æãÂ≠êÔºöÂπ¥ÈæÑ„ÄÅÊ∏©Â∫¶Á≠â„ÄÇÂèØ‰ª•Áõ¥Êé•‰øùÁïôÂÖ∂Êï¥Êï∞ÊàñÊµÆÁÇπÊï∞ÂΩ¢Âºè‰æõÊ®°Âûã‰ΩøÁî®„ÄÇ Á±ªÂà´ÁâπÂæÅ (Categorical Features) Êï∞ÊçÆÂÄºÁ¶ªÊï£Ôºå‰∏çÂÖ∑Â§á‚ÄúÊï∞ÂÄºÂ§ßÂ∞è‚ÄùÈó¥ÁöÑÂèØÊØîÊÑè‰πâ„ÄÇ ‰æãÂ≠êÔºöÂõΩÁ±çÔºàÁæéÂõΩ/‰∏≠ÂõΩ/Âç∞Â∫¶Á≠âÔºâ„ÄÅÊÄßÂà´ÔºàÁî∑/Â•≥ÔºâÁ≠â„ÄÇ ÈóÆÈ¢òÔºöËã•‰ªÖÁî®Êï¥Êï∞Ë°®Á§∫ÔºàÁæéÂõΩ=1, ‰∏≠ÂõΩ=2ÔºâÔºå‰ºöÂºïÂÖ•ÈîôËØØÁöÑÊï∞ÂÄºËøêÁÆóÂÖ≥Á≥ªÔºåÂ¶Ç ‚ÄúÁæéÂõΩ + ‰∏≠ÂõΩ = Âç∞Â∫¶‚Äù„ÄÇ ‰∫å„ÄÅOne-HotÁºñÁ†ÅÁöÑÂä®Êú∫‰∏éÊµÅÁ®ã ‰∏∫‰ªÄ‰πà‰ΩøÁî®One-Hot\nÈÄöËøáÂ∞ÜÁ±ªÂà´Êò†Â∞Ñ‰∏∫ÂêëÈáèÔºåÈÅøÂÖçÊï¥Êï∞ÁºñÁ†ÅÂºïÂÖ•ÁöÑ‰º™Êï∞ÂÄºÂÖ≥Á≥ª„ÄÇ ÂêåÊó∂‰øùÁïôÂêÑÁßçÂèØËÉΩÁ±ªÂà´ÁöÑ‰ø°ÊÅØÔºå‰∏î‰ªÖÂú®ÂØπÂ∫î‰ΩçÁΩÆ‰∏∫1ÔºåÂÖ∂‰ªñ‰ΩçÁΩÆ‰∏∫0„ÄÇ Âª∫Á´ãÊò†Â∞ÑÔºö‰ªéÁ±ªÂà´Âà∞Á¥¢Âºï\n‰∏∫ÊØè‰∏™Á±ªÂà´ÂàÜÈÖç‰∏Ä‰∏™ÂîØ‰∏ÄÁ¥¢ÂºïÔºåÈÄöÂ∏∏‰ªé1ÂºÄÂßã„ÄÇ È¢ÑÁïôÁ¥¢Âºï0Ë°®Á§∫‚ÄúÊú™Áü•‚ÄùÊàñ‚ÄúÁº∫Â§±‚ÄùÔºåÂØπÂ∫îÂÖ®0ÂêëÈáè„ÄÇ ËΩ¨Êç¢‰∏∫One-HotÂêëÈáè\nËã•Á±ªÂà´ÊÄªÊï∞‰∏∫197ÔºåÂàôÁî®197Áª¥ÂêëÈáèË°®Á§∫„ÄÇ ‰æãÂ≠êÔºöÁæéÂõΩ [1, 0, 0, 0, ‚Ä¶]Ôºå ‰∏≠ÂõΩ [0, 1, 0, 0, ‚Ä¶]„ÄÇ Á§∫‰æãÔºöË°®Á§∫‰∏Ä‰∏™‰∫∫ÁöÑÁâπÂæÅ\nÁâπÂæÅÂåÖÂê´ÔºàÂπ¥ÈæÑ, ÊÄßÂà´, ÂõΩÁ±çÔºåÂÖ∂‰∏≠ÂõΩÁ±ç197ÁßçÔºâ Áª¥Â∫¶ÊÄªÂíåÔºö1Áª¥_age + 1Áª¥_gender + 197Áª¥_nationality = 199Áª¥„ÄÇ ‰æãÂ¶Ç (28, Â•≥, ‰∏≠ÂõΩ) ‚Üí [28, 0, 0, 1, 0, ‚Ä¶, 0]„ÄÇ ‰∏â„ÄÅÊñáÊú¨Êï∞ÊçÆÂ§ÑÁêÜÊµÅÁ®ã ÊñáÊú¨Âú®Ëá™ÁÑ∂ËØ≠Ë®ÄÂ§ÑÁêÜÔºàNLPÔºâ‰∏≠‰Ωú‰∏∫Â∏∏ËßÅÁöÑÂéüÂßãËæìÂÖ•ÔºåÈúÄË¶ÅÊï∞ÂÄºÂåñÊâçËÉΩÈÄÅÂÖ•Ê®°Âûã„ÄÇ‰∏ÄËà¨Ê≠•È™§Â¶Ç‰∏ãÔºö\nÂàÜËØç (Tokenization)\nÂ∞ÜÊñáÊú¨ÊãÜÂàÜ‰∏∫‰∏Ä‰∏™‰∏™ÂçïËØçÔºàTokenÔºâ„ÄÇ ‰æãÂ≠êÔºö\u0026quot;... to be or not to be...\u0026quot; ‚Üí [\u0026quot;...\u0026quot;, \u0026quot;to\u0026quot;, \u0026quot;be\u0026quot;, \u0026quot;or\u0026quot;, \u0026quot;not\u0026quot;, \u0026quot;to\u0026quot;, \u0026quot;be\u0026quot;, \u0026quot;...\u0026quot;]„ÄÇ ÁªüËÆ°ËØçÈ¢ë \u0026amp; ÊûÑÂª∫ËØçÂÖ∏\nËØçÈ¢ëÁªüËÆ° Áî®ÂìàÂ∏åË°®/Â≠óÂÖ∏ËÆ∞ÂΩïÊØè‰∏™ÂçïËØçÂá∫Áé∞Ê¨°Êï∞„ÄÇ ÈÅçÂéÜÊñáÊú¨Êó∂ÔºåËã•ÂçïËØçÂ∞öÊú™ÂÖ•Ë°®ÔºåÂàôÊñ∞Âª∫ËÆ∞ÂΩïÔºõËã•Â∑≤Â≠òÂú®ÔºåÂàôËÆ°Êï∞+1„ÄÇ ÊéíÂ∫è‰∏éÁ¥¢Âºï ÊåâËØçÈ¢ëÈôçÂ∫èÊéíÂ∫èÔºåËØçÈ¢ëÊúÄÈ´òÁöÑÂçïËØçÊéíÂú®ÂâçÈù¢„ÄÇ Á¥¢Âºï‰ªé1ÂºÄÂßãÔºå0ÁïôÁªô‚ÄúÊú™Áü•‚Äù„ÄÇ ËØçÂÖ∏ËßÑÊ®°ÔºàvocabularyÔºâÂèØËßÜÈúÄÊ±ÇÊà™Êñ≠Ôºà‰æãÂ¶ÇÂè™‰øùÁïôTop 10kÔºâ„ÄÇ ‰∏∫‰ªÄ‰πàÁßªÈô§‰ΩéÈ¢ëËØç ‰ΩéÈ¢ëËØçÂèØËÉΩÊòØÊãºÂÜôÈîôËØØ„ÄÅÁΩïËßÅ‰∫∫ÂêçÁ≠âÔºåÂØπÊ®°ÂûãÂ∏ÆÂä©ÊúâÈôê„ÄÇ ÂáèÂ∞ëËØçÂÖ∏ËßÑÊ®°ÂèØÈôç‰ΩéËøêÁÆóÂºÄÈîÄ„ÄÅÂä†Âø´Ê®°ÂûãËÆ≠ÁªÉ‰∏éÊé®ÁêÜÈÄüÂ∫¶„ÄÇ Áã¨ÁÉ≠ÁºñÁ†Å (One-Hot Encoding)\nÂ∞ÜÊØè‰∏™ÂçïËØçÊò†Â∞Ñ‰∏∫ËØçÂÖ∏‰∏≠ÁöÑÁ¥¢ÂºïÂêéÔºàÂ¶Ç [2, 4, 1, 8, ‚Ä¶]ÔºâÔºåÂèØËøõ‰∏ÄÊ≠•ËΩ¨Êç¢ÊàêOne-HotÂêëÈáè„ÄÇ One-HotÁª¥Â∫¶ÂèñÂÜ≥‰∫é‰øùÁïô‰∏ãÊù•ÁöÑËØçÂÖ∏Â§ßÂ∞èÔºà‰æãÂ¶Ç1‰∏áÔºâ„ÄÇ Êú™Êî∂ÂΩïÂçïËØçÂèØËÉΩÁõ¥Êé•ÂøΩÁï•ÔºåÊàñÁªü‰∏ÄÁî®Á¥¢Âºï0‰ª£Êõø„ÄÇ Âõõ„ÄÅÊ†∏ÂøÉÊî∂Ëé∑‰∏éÂ∫îÁî® Á±ªÂà´ÁâπÂæÅÂøÖÈúÄÊï∞ÂÄºÂåñÔºö\n‰ΩøÁî®Êï¥Êï∞1,2,3‚Ä¶‰ªÖË°®Á§∫Á±ªÂà´‚ÄúÊ†áËØÜ‚ÄùÔºåÂπ∂‰∏ç‰ª£Ë°®ÂÆÉ‰ª¨ÂèØËøõË°åÊï∞ÂÄºËøêÁÆó„ÄÇ Âõ†Ê≠§ÈúÄË¶ÅOne-HotÁ≠âÁºñÁ†ÅÊñπÂºèÔºåÈÅøÂÖçÊï∞ÂÄºËØØËß£„ÄÇ ÊñáÊú¨Êï∞ÊçÆÈ¢ÑÂ§ÑÁêÜÔºö\nÂàÜËØç„ÄÅËØçÈ¢ëÁªüËÆ°„ÄÅÊûÑÂª∫ËØçÂÖ∏„ÄÅÁ¥¢ÂºïÂåñ„ÄÅOne-HotÊàñÂÖ∂‰ªñÊñπÂºèÔºàÂ¶ÇËØçÂµåÂÖ•ÔºâÊòØÂ∏∏ËßÅÊµÅÁ®ã„ÄÇ Ê≠£Á°ÆÁöÑÊñáÊú¨È¢ÑÂ§ÑÁêÜÂèØÊòæËëóÂΩ±ÂìçÊ®°ÂûãÊÄßËÉΩÂíåÊïàÁéá„ÄÇ ‰øùÁïôÊú™Áü•Á¥¢ÂºïÔºö\n‰øùËØÅÂØπÁº∫Â§±Êï∞ÊçÆÊàñÂ≠óÂÖ∏Â§ñÊñ∞ËØçËÉΩÊúâÂü∫Êú¨ÁöÑË°®Á§∫ÔºåÊèêÂçáÊ®°ÂûãÂÆπÈîôÊÄß„ÄÇ ÂÆûÈôÖ‰ΩøÁî®Ôºö\nÂØπ‰∫éÂ∞èËßÑÊ®°Á±ªÂà´ÂèØÁõ¥Êé•One-HotÁºñÁ†ÅÔºõÂØπ‰∫éËØçÂÖ∏ÂæàÂ§ßÁöÑÂú∫ÊôØÔºåÈÄöÂ∏∏‰ºöËøõ‰∏ÄÊ≠•ËÄÉËôëËØçÂµåÂÖ•ÔºàWord EmbeddingÔºâÊàñÈ¢ÑËÆ≠ÁªÉËØ≠Ë®ÄÊ®°Âûã„ÄÇ ","permalink":"http://localhost:1313/posts/nlp-1/","summary":"\u003ch2 id=\"‰∏ÄÊï∞ÂÄºÁâπÂæÅ‰∏éÁ±ªÂà´ÁâπÂæÅ\"\u003e‰∏Ä„ÄÅÊï∞ÂÄºÁâπÂæÅ‰∏éÁ±ªÂà´ÁâπÂæÅ\u003c/h2\u003e\n\u003col\u003e\n\u003cli\u003e\u003cstrong\u003eÊï∞ÂÄºÁâπÂæÅ (Numeric Features)\u003c/strong\u003e\n\u003cul\u003e\n\u003cli\u003eÂÖ∑ÊúâÂèØÂä†ÂáèÁöÑÊÑè‰πâÔºå‰∏îÂ≠òÂú®Â§ßÂ∞èÈ°∫Â∫è„ÄÇ\u003c/li\u003e\n\u003cli\u003e‰æãÂ≠êÔºöÂπ¥ÈæÑ„ÄÅÊ∏©Â∫¶Á≠â„ÄÇÂèØ‰ª•Áõ¥Êé•‰øùÁïôÂÖ∂Êï¥Êï∞ÊàñÊµÆÁÇπÊï∞ÂΩ¢Âºè‰æõÊ®°Âûã‰ΩøÁî®„ÄÇ\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003eÁ±ªÂà´ÁâπÂæÅ (Categorical Features)\u003c/strong\u003e\n\u003cul\u003e\n\u003cli\u003eÊï∞ÊçÆÂÄºÁ¶ªÊï£Ôºå‰∏çÂÖ∑Â§á‚ÄúÊï∞ÂÄºÂ§ßÂ∞è‚ÄùÈó¥ÁöÑÂèØÊØîÊÑè‰πâ„ÄÇ\u003c/li\u003e\n\u003cli\u003e‰æãÂ≠êÔºöÂõΩÁ±çÔºàÁæéÂõΩ/‰∏≠ÂõΩ/Âç∞Â∫¶Á≠âÔºâ„ÄÅÊÄßÂà´ÔºàÁî∑/Â•≥ÔºâÁ≠â„ÄÇ\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003eÈóÆÈ¢ò\u003c/strong\u003eÔºöËã•‰ªÖÁî®Êï¥Êï∞Ë°®Á§∫ÔºàÁæéÂõΩ=1, ‰∏≠ÂõΩ=2ÔºâÔºå‰ºöÂºïÂÖ•ÈîôËØØÁöÑÊï∞ÂÄºËøêÁÆóÂÖ≥Á≥ªÔºåÂ¶Ç ‚ÄúÁæéÂõΩ + ‰∏≠ÂõΩ = Âç∞Â∫¶‚Äù„ÄÇ\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003c/ol\u003e\n\u003ch2 id=\"‰∫åone-hotÁºñÁ†ÅÁöÑÂä®Êú∫‰∏éÊµÅÁ®ã\"\u003e‰∫å„ÄÅOne-HotÁºñÁ†ÅÁöÑÂä®Êú∫‰∏éÊµÅÁ®ã\u003c/h2\u003e\n\u003col\u003e\n\u003cli\u003e\n\u003cp\u003e\u003cstrong\u003e‰∏∫‰ªÄ‰πà‰ΩøÁî®One-Hot\u003c/strong\u003e\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eÈÄöËøáÂ∞ÜÁ±ªÂà´Êò†Â∞Ñ‰∏∫ÂêëÈáèÔºåÈÅøÂÖçÊï¥Êï∞ÁºñÁ†ÅÂºïÂÖ•ÁöÑ‰º™Êï∞ÂÄºÂÖ≥Á≥ª„ÄÇ\u003c/li\u003e\n\u003cli\u003eÂêåÊó∂‰øùÁïôÂêÑÁßçÂèØËÉΩÁ±ªÂà´ÁöÑ‰ø°ÊÅØÔºå‰∏î‰ªÖÂú®ÂØπÂ∫î‰ΩçÁΩÆ‰∏∫1ÔºåÂÖ∂‰ªñ‰ΩçÁΩÆ‰∏∫0„ÄÇ\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003e\u003cstrong\u003eÂª∫Á´ãÊò†Â∞ÑÔºö‰ªéÁ±ªÂà´Âà∞Á¥¢Âºï\u003c/strong\u003e\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e‰∏∫ÊØè‰∏™Á±ªÂà´ÂàÜÈÖç‰∏Ä‰∏™ÂîØ‰∏ÄÁ¥¢ÂºïÔºåÈÄöÂ∏∏‰ªé1ÂºÄÂßã„ÄÇ\u003c/li\u003e\n\u003cli\u003eÈ¢ÑÁïôÁ¥¢Âºï0Ë°®Á§∫‚ÄúÊú™Áü•‚ÄùÊàñ‚ÄúÁº∫Â§±‚ÄùÔºåÂØπÂ∫îÂÖ®0ÂêëÈáè„ÄÇ\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003e\u003cstrong\u003eËΩ¨Êç¢‰∏∫One-HotÂêëÈáè\u003c/strong\u003e\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eËã•Á±ªÂà´ÊÄªÊï∞‰∏∫197ÔºåÂàôÁî®197Áª¥ÂêëÈáèË°®Á§∫„ÄÇ\u003c/li\u003e\n\u003cli\u003e‰æãÂ≠êÔºöÁæéÂõΩ \u003ccode\u003e[1, 0, 0, 0, ‚Ä¶]\u003c/code\u003eÔºå ‰∏≠ÂõΩ \u003ccode\u003e[0, 1, 0, 0, ‚Ä¶]\u003c/code\u003e„ÄÇ\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003e\u003cstrong\u003eÁ§∫‰æãÔºöË°®Á§∫‰∏Ä‰∏™‰∫∫ÁöÑÁâπÂæÅ\u003c/strong\u003e\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eÁâπÂæÅÂåÖÂê´ÔºàÂπ¥ÈæÑ, ÊÄßÂà´, ÂõΩÁ±çÔºåÂÖ∂‰∏≠ÂõΩÁ±ç197ÁßçÔºâ\u003c/li\u003e\n\u003cli\u003eÁª¥Â∫¶ÊÄªÂíåÔºö1Áª¥_age + 1Áª¥_gender + 197Áª¥_nationality = 199Áª¥„ÄÇ\u003c/li\u003e\n\u003cli\u003e‰æãÂ¶Ç \u003ccode\u003e(28, Â•≥, ‰∏≠ÂõΩ)\u003c/code\u003e ‚Üí \u003ccode\u003e[28, 0, 0, 1, 0, ‚Ä¶, 0]\u003c/code\u003e„ÄÇ\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003c/ol\u003e\n\u003ch2 id=\"‰∏âÊñáÊú¨Êï∞ÊçÆÂ§ÑÁêÜÊµÅÁ®ã\"\u003e‰∏â„ÄÅÊñáÊú¨Êï∞ÊçÆÂ§ÑÁêÜÊµÅÁ®ã\u003c/h2\u003e\n\u003cp\u003eÊñáÊú¨Âú®Ëá™ÁÑ∂ËØ≠Ë®ÄÂ§ÑÁêÜÔºàNLPÔºâ‰∏≠‰Ωú‰∏∫Â∏∏ËßÅÁöÑÂéüÂßãËæìÂÖ•ÔºåÈúÄË¶ÅÊï∞ÂÄºÂåñÊâçËÉΩÈÄÅÂÖ•Ê®°Âûã„ÄÇ‰∏ÄËà¨Ê≠•È™§Â¶Ç‰∏ãÔºö\u003c/p\u003e\n\u003col\u003e\n\u003cli\u003e\n\u003cp\u003e\u003cstrong\u003eÂàÜËØç (Tokenization)\u003c/strong\u003e\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eÂ∞ÜÊñáÊú¨ÊãÜÂàÜ‰∏∫‰∏Ä‰∏™‰∏™ÂçïËØçÔºàTokenÔºâ„ÄÇ\u003c/li\u003e\n\u003cli\u003e‰æãÂ≠êÔºö\u003ccode\u003e\u0026quot;... to be or not to be...\u0026quot;\u003c/code\u003e ‚Üí \u003ccode\u003e[\u0026quot;...\u0026quot;, \u0026quot;to\u0026quot;, \u0026quot;be\u0026quot;, \u0026quot;or\u0026quot;, \u0026quot;not\u0026quot;, \u0026quot;to\u0026quot;, \u0026quot;be\u0026quot;, \u0026quot;...\u0026quot;]\u003c/code\u003e„ÄÇ\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003e\u003cstrong\u003eÁªüËÆ°ËØçÈ¢ë \u0026amp; ÊûÑÂª∫ËØçÂÖ∏\u003c/strong\u003e\u003c/p\u003e","title":""},{"content":"Text to Sequence ÊñáÊú¨Â§ÑÁêÜ\nStep1: Tokenization\nTokenization breaks a piece of text down into a list of tokens.\nHere, a token is a word. (A token can be a character in some applications.)\nTokenizationËÆ≤Á©∂ÂæàÂ§öÔºå‰æãÂ¶ÇÊòØÂê¶Â∫îËØ•ÊääÂ§ßÂÜôÊîπÊàêÂ∞èÂÜôÂë¢ÔºüËøõË°åtypo correctionÁ≠âÁ≠â\nStep2: Build Dictionary\nUse a dictionary (hash table) to count word frequencies.\nThe dictionary maps word to index.\nÂèØ‰ª•È¶ñÂÖàÁªüËÆ°ËØçÈ¢ëÂéªÊéâ‰ΩéÈ¢ëËØçÔºåÁÑ∂ÂêéËÆ©ÊØè‰∏™ËØçÂØπÂ∫î‰∏Ä‰∏™Ê≠£Êï¥Êï∞ÔºõËøôÊ†∑ÁöÑËØùÔºå‰∏ÄÂè•ËØùÂ∞±ÂèØ‰ª•Áî®‰∏Ä‰∏™Ê≠£Êï¥Êï∞ÂàóË°®Ë°®Á§∫ÔºåËøô‰∏™ÂàóË°®Â∞±Âè´sequenceÔºõÂ¶ÇÊûúÂøÖË¶ÅÂ∞±ËøòÂæóÂÅöone-hot encoding„ÄÇ\nÁªìÊûú\n‰ΩÜÊòØÈïøÂ∫¶‰∏çÁªü‰∏Ä\nStep4: ÂØπÈΩêsequence\nËß£ÂÜ≥ÊñπÊ°àÊòØËøôÊ†∑ÁöÑÔºöÂèØ‰ª•Âõ∫ÂÆöÈïøÂ∫¶‰∏∫wÔºåÂä†ÂÖ•‰∏Ä‰∏™Â∫èÂàóÈïøÂ∫¶Â§™ÈïøÔºåÂ∞±Á†çÊéâÂâçÈù¢ÁöÑËØçÔºåÂè™‰øùÁïôÊúÄÂêéw‰∏™ËØçÔºõÂ¶ÇÊûú‰∏Ä‰∏™Â∫èÂàóÂ§™Áü≠ÔºåÂ∞±ÂÅözero paddingÔºåÁî®0Â°´ÂÖÖ\nËøôÊ†∑‰∏ÄÊù•ÔºåÊâÄÊúâÁöÑÂ∫èÂàóÈïøÂ∫¶Â∞±Áªü‰∏Ä‰∫Ü\nÊñáÊú¨Â§ÑÁêÜÂÆåÊàê‰∫ÜÔºåÊé•‰∏ãÊù•ÊòØword embeddingÔºåÊääÂçïËØçË°®Á§∫‰∏∫‰∏Ä‰∏™‰ΩéÁª¥ÂêëÈáèÔºõ\nÁÑ∂ËÄåËøôÊ†∑ÂÅöÁöÑËØùÔºåÂ¶ÇÊûúÊòØ10000‰∏™ÂçïËØçÔºåÁª¥Â∫¶Â∞±ÊòØ10000Áª¥ÔºåÁª¥Â∫¶Â§™È´ò‰∫ÜÔºõÂõ†Ê≠§Ë¶ÅÂÅöword embeddingÔºõ\nÂÖ∑‰ΩìÂÅöÊ≥ïÂ∞±ÊòØÊääone-hotÂêëÈáèe_iÂíåÂèÇÊï∞Áü©ÈòµpÁõ∏‰πòÔºõÁü©ÈòµPËΩ¨ÁΩÆÁöÑÂ§ßÂ∞èÊòØd x vÔºõdÊòØËØçÂêëÈáèÁöÑÁª¥Â∫¶ÔºõvÊòØÂ≠óÂÖ∏ÈáåËØçÊ±áÁöÑÊï∞ÈáèÔºõÁªìÊûú‰∏∫x_iÔºõx_iÂ∞±ÊòØ‰∏Ä‰∏™ËØçÂêëÈáèÔºõÂ¶ÇÊûúone-hotÂêëÈáèÁöÑÁ¨¨‰∏âË°å‰∏∫1ÔºõÈÇ£‰πàx_iÂ∞±ÊòØPËΩ¨ÁΩÆÁü©ÈòµÁöÑÁ¨¨‰∏âÂàóÔºàÂÖ∂‰ΩôÂàóÈÉΩ‰∏∫0ÔºâÔºõÊâÄ‰ª•PËΩ¨ÁΩÆÊØè‰∏ÄÂàóÈÉΩÊòØ‰∏Ä‰∏™ËØçÂêëÈáèÔºõÊâÄ‰ª•Áü©ÈòµPÊú¨Ë∫´ÁöÑÊØè‰∏ÄË°åÂ∞±ÊòØ‰∏Ä‰∏™ËØçÂêëÈáèÔºõÂÖ∂Ë°åÊï∞‰∏∫vÔºõÂç≥vocabularyÔºåËØçÊ±áÈáèÔºõÊØè‰∏ÄË°åÂØπÂ∫î‰∏Ä‰∏™ÂçïËØçÔºõÁü©ÈòµÁöÑÂàóÊï∞‰∏∫dÔºõdÊòØÁî®Êà∑ÂÜ≥ÂÆöÁöÑÔºõdÁöÑÂ§ßÂ∞è‰ºöÂÜ≥ÂÆöÊú∫Âô®Â≠¶‰π†Ê®°ÂûãÁöÑË°®Áé∞ÔºõÂ∫îËØ•Áî®xxxÊù•ÈÄâÊã©‰∏Ä‰∏™ÊØîËæÉÂ•ΩÁöÑdÔºõ\nÊàë‰ª¨ÁöÑ‰ªªÂä°ÊòØÁúãËØÑËÆ∫ÊòØÊ≠£Èù¢ÁöÑËøòÊòØË¥üÈù¢ÁöÑÔºõÂèÇÊï∞Áü©ÈòµÊòØ‰ªéËÆ≠ÁªÉÊï∞ÊçÆ‰∏≠Â≠¶‰π†Âá∫Êù•ÁöÑÔºåÊâÄ‰ª•Â≠¶Âá∫Êù•ÁöÑËØçÂêëÈáèÊòØÂ∏¶ÊúâÊÑüÊÉÖËâ≤ÂΩ©ÁöÑÔºõÂÅáËÆæËøô‰∫õËØçÂêëÈáèÈÉΩÊòØ‰∫åÁª¥ÁöÑÔºåÂàôÂèØ‰ª•Âú®Âπ≥Èù¢ÂùêÊ†áÁ≥ª‰∏≠Ê†áÂá∫‰∏ãÈù¢ËØçÂêëÈáè\nkerasÊèê‰æõembeddingÂ±ÇÔºõÁî®Êà∑ÂèØ‰ª•ÊåáÂÆövocabularyÂ§ßÂ∞èÂíådÁöÑÂ§ßÂ∞èÔºõ‰ª•ÂèäÊØè‰∏Ä‰∏™sequenceÁöÑÈïøÂ∫¶ÔºõdÊòØÊ†πÊçÆÁÆóÊ≥ïÈÄâÂá∫Êù•ÁöÑ Âà∞Ëøô‰∏ÄÊ≠•ÔºåÊàë‰ª¨Â∑≤ÁªèÂÆåÊàê‰∫ÜÊñáÊú¨Â§ÑÁêÜÂíåword embedding„ÄÇÊé•‰∏ãÊù•Â∞±ÊòØÁî®Logistic Regression for Binary ClassificationÂÅö‰∫åÂàÜÁ±ªÔºõ\n","permalink":"http://localhost:1313/posts/nlp-2/","summary":"\u003ch3 id=\"text-to-sequence\"\u003eText to Sequence\u003c/h3\u003e\n\u003cp\u003eÊñáÊú¨Â§ÑÁêÜ\u003c/p\u003e\n\u003cp\u003eStep1: Tokenization\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\n\u003cp\u003eTokenization breaks a piece of text down into a list of tokens.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003eHere, a token is a word. (A token can be a character in some applications.)\u003c/p\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003eTokenizationËÆ≤Á©∂ÂæàÂ§öÔºå‰æãÂ¶ÇÊòØÂê¶Â∫îËØ•ÊääÂ§ßÂÜôÊîπÊàêÂ∞èÂÜôÂë¢ÔºüËøõË°åtypo correctionÁ≠âÁ≠â\u003c/p\u003e\n\u003cp\u003e\u003cimg alt=\"image-20250322150322238\" loading=\"lazy\" src=\"./NLP-2.assets/image-20250322150322238.png\"\u003e\u003c/p\u003e\n\u003cp\u003eStep2: Build Dictionary\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\n\u003cp\u003eUse a dictionary (hash table) to count word frequencies.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003eThe dictionary maps word to index.\u003c/p\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003eÂèØ‰ª•È¶ñÂÖàÁªüËÆ°ËØçÈ¢ëÂéªÊéâ‰ΩéÈ¢ëËØçÔºåÁÑ∂ÂêéËÆ©ÊØè‰∏™ËØçÂØπÂ∫î‰∏Ä‰∏™Ê≠£Êï¥Êï∞ÔºõËøôÊ†∑ÁöÑËØùÔºå‰∏ÄÂè•ËØùÂ∞±ÂèØ‰ª•Áî®‰∏Ä‰∏™Ê≠£Êï¥Êï∞ÂàóË°®Ë°®Á§∫ÔºåËøô‰∏™ÂàóË°®Â∞±Âè´sequenceÔºõÂ¶ÇÊûúÂøÖË¶ÅÂ∞±ËøòÂæóÂÅöone-hot encoding„ÄÇ\u003cimg alt=\"image-20250322150620890\" loading=\"lazy\" src=\"./NLP-2.assets/image-20250322150620890.png\"\u003e\u003c/p\u003e\n\u003cp\u003eÁªìÊûú\u003c/p\u003e\n\u003cp\u003e\u003cimg alt=\"image-20250322150754528\" loading=\"lazy\" src=\"./NLP-2.assets/image-20250322150754528.png\"\u003e\u003c/p\u003e\n\u003cp\u003e‰ΩÜÊòØÈïøÂ∫¶‰∏çÁªü‰∏Ä\u003c/p\u003e\n\u003cp\u003eStep4: ÂØπÈΩêsequence\u003c/p\u003e\n\u003cp\u003e\u003cimg alt=\"image-20250322150854986\" loading=\"lazy\" src=\"./NLP-2.assets/image-20250322150854986.png\"\u003e\u003c/p\u003e\n\u003cp\u003eËß£ÂÜ≥ÊñπÊ°àÊòØËøôÊ†∑ÁöÑÔºöÂèØ‰ª•Âõ∫ÂÆöÈïøÂ∫¶‰∏∫wÔºåÂä†ÂÖ•‰∏Ä‰∏™Â∫èÂàóÈïøÂ∫¶Â§™ÈïøÔºåÂ∞±Á†çÊéâÂâçÈù¢ÁöÑËØçÔºåÂè™‰øùÁïôÊúÄÂêéw‰∏™ËØçÔºõÂ¶ÇÊûú‰∏Ä‰∏™Â∫èÂàóÂ§™Áü≠ÔºåÂ∞±ÂÅözero paddingÔºåÁî®0Â°´ÂÖÖ\u003c/p\u003e\n\u003cp\u003e\u003cimg alt=\"image-20250322151030119\" loading=\"lazy\" src=\"./NLP-2.assets/image-20250322151030119.png\"\u003e\u003c/p\u003e\n\u003cp\u003eËøôÊ†∑‰∏ÄÊù•ÔºåÊâÄÊúâÁöÑÂ∫èÂàóÈïøÂ∫¶Â∞±Áªü‰∏Ä‰∫Ü\u003c/p\u003e\n\u003cp\u003e\u003cimg alt=\"image-20250322151117125\" loading=\"lazy\" src=\"./NLP-2.assets/image-20250322151117125.png\"\u003e\u003c/p\u003e\n\u003cp\u003eÊñáÊú¨Â§ÑÁêÜÂÆåÊàê‰∫ÜÔºåÊé•‰∏ãÊù•ÊòØword embeddingÔºåÊääÂçïËØçË°®Á§∫‰∏∫‰∏Ä‰∏™‰ΩéÁª¥ÂêëÈáèÔºõ\u003c/p\u003e\n\u003cp\u003e\u003cimg alt=\"image-20250322151252837\" loading=\"lazy\" src=\"./NLP-2.assets/image-20250322151252837.png\"\u003e\u003c/p\u003e","title":""},{"content":"üëã About me Hello! I\u0026rsquo;m Xu Zongsi, a passionate technology enthusiast currently pursuing my Master of Science in ECIC at The University of Hong Kong. With a solid background in Software Engineering from the Beijing Institute of Technology, I specialize in artificial intelligence areas like machine learning, deep learning, natural language processing, computer vision, and reinforcement learning.\nInspired by OpenAI\u0026rsquo;s five-step plan towards superintelligence, I am excited about AGI and have developed a keen interest in LLM agents, MLLM, and knowledge graphs. I see great potential in these fields and aspire to contribute to innovative solutions.\nüìö Education üá≠üá∞ The University of Hong Kong 09/2024 - Expected 11/2025 School of Computing and Data Science Master of Science in Electronic Commerce \u0026amp; Internet Computing Relevant Courses: Machine learning for business and e-commerce, Knowledge graphs, Financial fraud analytics, Internet infrastructure technologies, Website engineering, Blockchain and cryptocurrency, etc. üá®üá≥ Beijing Institute of Technology 09/2020 - 06/2024 School of Computer Science \u0026amp; Technology Bachelor of Engineering in Software Engineering, last two years GPA: 3.7/4 Relevant Courses: Reinforcement Learning, Deep Learning and Computer Vision, Artificial Intelligence and Robot Ethics, Almost Human: Mind, Brain and Artificial Intelligence, Mathematical Analysis for Engineering, Linear Algebra, Probability and Mathematical Statistics, etc. Skills: Python, Java, common data structures, design patterns, machine learning basics and algorithms, Linux, PyTorch, and some development tools (git, conda, etc.). üèÜ Awards \u0026amp; Honors Beijing Institute of Technology Undergraduate Scholarship (Top 20% of Grade) 06/2023 3rd Prize of China International \u0026#34;Internet \u0026#43;\u0026#34; College Student\u0026#39;s Innovation Competition 08/2022 Bronze Prize of \u0026#34;Challenge Cup\u0026#34; Capital University Entrepreneurship Competition 05/2022 üíº Project Experience üîç Online Transaction Fraud Detection 09/2024 ‚Äì 01/2025 Independent project, supervised by Dr. Vivien Chan Focused on addressing financial fraud in e-commerce to enhance the accuracy of transaction anomaly detection, while independently managing the entire case study that included data preprocessing, feature engineering, model building, evaluation, and results analysis. Effectively resolved class imbalance issues using SMOTE and ROSE techniques. Built various models including Logistic Regression, Random Forest, XGBoost, and LightGBM, ultimately selecting the LightGBM model to achieve a recall rate of 95.45% and an AUC of 99.84%. Wrote efficient and maintainable code, enhancing model training and data processing efficiency through parallel computing and logging. ü§ñ Multi-Model Intelligent Text Keyword Extraction System 08/2023 ‚Äì 09/2023 Group project, supervised by Associate Prof. Xiaolin Zhao Designed and implemented an intelligent text summary system that automatically extracts keywords from article titles and abstracts, enhancing the understanding and summarization of text information. Participated in the planning of the technical route and built a hybrid model combining extractive and generative approaches, utilizing advanced natural language processing techniques including KeyBERT, Sentence Transformer, BERT, and T5 models. Responsible for data preprocessing and tokenization, as well as the end-to-end implementation and training of the T5 model, optimizing the model architecture and hyperparameters, achieving satisfactory results after only 3 epochs of training. Model evaluation results showed that the Rouge-1, Rouge-2, and Rouge-L metrics reached 0.6345, 0.5038, and 0.5282, respectively, in the third epoch, validating the model\u0026rsquo;s effectiveness in the summarization task. üéì Cambridge University Machine Learning Summer Project 07/2023 ‚Äì 08/2023 Group project, supervised by Prof. Pietro Li√≤ Participated in the Cambridge University deep learning summer project, focusing on deep reinforcement learning; explored multi-agent learning algorithms across different environments. Reproduced the Multi-Agent Deep Deterministic Policy Gradient (MADDPG) algorithm in the Simple Adversary environment and studied the effect of agent numbers on convergence speed and stability, finding optimal stability at 21 agents. Designed and implemented comparative experiments inspired by the Rainbow algorithm, assessing target network strategies versus the Double Deep Q-Network (Double DQN). The results demonstrated that Double DQN significantly enhanced convergence speed, optimizing the overall learning process. Co-authored a group project paper on agent numbers and strategies effectiveness in multi-agent systems, achieving a score of 71% in the summer program (the highest in my group) and a \u0026ldquo;First Class\u0026rdquo; classification in the UK grading system. üëÅÔ∏è Deep Learning and Computer Vision Semester Project 09/2022 ‚Äì 12/2022 Independent project, supervised by Associate Prof. Guangyu Gao Designed and implemented a waste classifier using the ResNet model to improve classification accuracy and reduce resource waste. The project also enhanced understanding of transfer learning techniques with ResNet. Collected a dataset of 16 waste categories and preprocessed the images for uniformity and standardization, incorporating data augmentation techniques to enhance the dataset. Conducted experiments using ResNet34 and ResNet50 models through transfer learning, accelerating network convergence by leveraging pretrained weights. During training, techniques such as Batch Normalization and Dropout were applied to mitigate the risk of overfitting. The final model achieved an accuracy of 90% on the training set, while the performance on the test set was 61%, indicating a significant overfitting phenomenon during the training process. üéì Internship ‚öõÔ∏è Beijing Academy of Quantum Information Science 08/2023 ‚Äì 01/2024 Research Intern at Quantum Computation Department Proposed a quantum convolution kernel design based on variational quantum circuits and developed a universal quantum convolution layer, successfully integrating it into classical CNN architectures such as VGG, GoogLeNet, and ResNet. Developed and evaluated various hybrid models, including a simple model named HQCCNN-2, which achieved 84.45% accuracy on the FashionMNIST dataset, surpassing the traditional CNN\u0026rsquo;s 80.72%. This demonstrates the effectiveness of the quantum convolution layer in improving model performance. Tested on a real quantum computer further validated the effectiveness of the hybrid model, demonstrating the viable integration of quantum computing with deep learning, and highlighting the potential for leveraging quantum properties to enhance model performance. üèÖ Competition Experience ü•â China International \u0026#34;Internet \u0026#43;\u0026#34; College Students\u0026#39; Innovation Competition 08/2022 üõ°Ô∏è Zhongke Ushield: Deep Learning-based Face Privacy Protection Authentication System Responsible for constructing a localized facial feature extraction engine based on MobileFaceNet, ensuring feature extraction is completed on end devices (such as mobile phones and cameras), guaranteeing that raw data does not leave the domain and is not stored, thus enhancing user privacy protection while improving recognition efficiency. ü•â \u0026#34;Challenge Cup\u0026#34; Capital University Entrepreneurship Competition 05/2022 üå≥ Smart Orchard Responsible for the development of the fruit detection, ripeness prediction, and pest identification system, using deep convolutional neural network (CNN) technology for intelligent monitoring of crop growth conditions. Applied advanced object detection algorithms such as Faster R-CNN and YOLO to achieve high precision in apple detection and ripeness assessment, with an accuracy rate exceeding 90%, significantly enhancing the intelligence level of orchard management. Built and trained a dedicated dataset containing various pest samples, optimizing pest detection accuracy through data preprocessing (such as image normalization and resizing) and data augmentation techniques (like rotation, flipping, and noise addition), enabling the real-time monitoring system to accurately identify over 80% of pests, providing effective scientific maintenance recommendations to help farmers reduce crop losses. üìã Extracurricular Activities Vice President, Cyber Security Club, Beijing Institute of Technology 09/2021-09/2022 Backbone, Media Center of the Student Union of Beijing Institute of Technology 10/2020-06/2021 üì´ Contact üìß Email: zongsi.xu@outlook.com üëî LinkedIn: Zongsi (Tristan) Xu üíª GitHub: BaizeXS üìç Location: Hong Kong SAR, China ","permalink":"http://localhost:1313/resume/","summary":"Personal resume of Zongsi (Tristan) Xu","title":"Zongsi (Tristan) Xu"},{"content":"‰∏Ä„ÄÅÊï∞ÂÄºÁâπÂæÅ‰∏éÁ±ªÂà´ÁâπÂæÅ Êï∞ÂÄºÁâπÂæÅ (Numeric Features) ÂÖ∑ÊúâÂèØÂä†ÂáèÁöÑÊÑè‰πâÔºå‰∏îÂ≠òÂú®Â§ßÂ∞èÈ°∫Â∫è„ÄÇ ‰æãÂ≠êÔºöÂπ¥ÈæÑ„ÄÅÊ∏©Â∫¶Á≠â„ÄÇÂèØ‰ª•Áõ¥Êé•‰øùÁïôÂÖ∂Êï¥Êï∞ÊàñÊµÆÁÇπÊï∞ÂΩ¢Âºè‰æõÊ®°Âûã‰ΩøÁî®„ÄÇ Á±ªÂà´ÁâπÂæÅ (Categorical Features) Êï∞ÊçÆÂÄºÁ¶ªÊï£Ôºå‰∏çÂÖ∑Â§á‚ÄúÊï∞ÂÄºÂ§ßÂ∞è‚ÄùÈó¥ÁöÑÂèØÊØîÊÑè‰πâ„ÄÇ ‰æãÂ≠êÔºöÂõΩÁ±çÔºàÁæéÂõΩ/‰∏≠ÂõΩ/Âç∞Â∫¶Á≠âÔºâ„ÄÅÊÄßÂà´ÔºàÁî∑/Â•≥ÔºâÁ≠â„ÄÇ ÈóÆÈ¢òÔºöËã•‰ªÖÁî®Êï¥Êï∞Ë°®Á§∫ÔºàÁæéÂõΩ=1, ‰∏≠ÂõΩ=2ÔºâÔºå‰ºöÂºïÂÖ•ÈîôËØØÁöÑÊï∞ÂÄºËøêÁÆóÂÖ≥Á≥ªÔºåÂ¶Ç ‚ÄúÁæéÂõΩ + ‰∏≠ÂõΩ = Âç∞Â∫¶‚Äù„ÄÇ ‰∫å„ÄÅOne-HotÁºñÁ†ÅÁöÑÂä®Êú∫‰∏éÊµÅÁ®ã ‰∏∫‰ªÄ‰πà‰ΩøÁî®One-Hot\nÈÄöËøáÂ∞ÜÁ±ªÂà´Êò†Â∞Ñ‰∏∫ÂêëÈáèÔºåÈÅøÂÖçÊï¥Êï∞ÁºñÁ†ÅÂºïÂÖ•ÁöÑ‰º™Êï∞ÂÄºÂÖ≥Á≥ª„ÄÇ ÂêåÊó∂‰øùÁïôÂêÑÁßçÂèØËÉΩÁ±ªÂà´ÁöÑ‰ø°ÊÅØÔºå‰∏î‰ªÖÂú®ÂØπÂ∫î‰ΩçÁΩÆ‰∏∫1ÔºåÂÖ∂‰ªñ‰ΩçÁΩÆ‰∏∫0„ÄÇ Âª∫Á´ãÊò†Â∞ÑÔºö‰ªéÁ±ªÂà´Âà∞Á¥¢Âºï\n‰∏∫ÊØè‰∏™Á±ªÂà´ÂàÜÈÖç‰∏Ä‰∏™ÂîØ‰∏ÄÁ¥¢ÂºïÔºåÈÄöÂ∏∏‰ªé1ÂºÄÂßã„ÄÇ È¢ÑÁïôÁ¥¢Âºï0Ë°®Á§∫‚ÄúÊú™Áü•‚ÄùÊàñ‚ÄúÁº∫Â§±‚ÄùÔºåÂØπÂ∫îÂÖ®0ÂêëÈáè„ÄÇ ËΩ¨Êç¢‰∏∫One-HotÂêëÈáè\nËã•Á±ªÂà´ÊÄªÊï∞‰∏∫197ÔºåÂàôÁî®197Áª¥ÂêëÈáèË°®Á§∫„ÄÇ ‰æãÂ≠êÔºöÁæéÂõΩ [1, 0, 0, 0, ‚Ä¶]Ôºå ‰∏≠ÂõΩ [0, 1, 0, 0, ‚Ä¶]„ÄÇ Á§∫‰æãÔºöË°®Á§∫‰∏Ä‰∏™‰∫∫ÁöÑÁâπÂæÅ\nÁâπÂæÅÂåÖÂê´ÔºàÂπ¥ÈæÑ, ÊÄßÂà´, ÂõΩÁ±çÔºåÂÖ∂‰∏≠ÂõΩÁ±ç197ÁßçÔºâ Áª¥Â∫¶ÊÄªÂíåÔºö1Áª¥_age + 1Áª¥_gender + 197Áª¥_nationality = 199Áª¥„ÄÇ ‰æãÂ¶Ç (28, Â•≥, ‰∏≠ÂõΩ) ‚Üí [28, 0, 0, 1, 0, ‚Ä¶, 0]„ÄÇ ‰∏â„ÄÅÊñáÊú¨Êï∞ÊçÆÂ§ÑÁêÜÊµÅÁ®ã ÊñáÊú¨Âú®Ëá™ÁÑ∂ËØ≠Ë®ÄÂ§ÑÁêÜÔºàNLPÔºâ‰∏≠‰Ωú‰∏∫Â∏∏ËßÅÁöÑÂéüÂßãËæìÂÖ•ÔºåÈúÄË¶ÅÊï∞ÂÄºÂåñÊâçËÉΩÈÄÅÂÖ•Ê®°Âûã„ÄÇ‰∏ÄËà¨Ê≠•È™§Â¶Ç‰∏ãÔºö\nÂàÜËØç (Tokenization)\nÂ∞ÜÊñáÊú¨ÊãÜÂàÜ‰∏∫‰∏Ä‰∏™‰∏™ÂçïËØçÔºàTokenÔºâ„ÄÇ ‰æãÂ≠êÔºö\u0026quot;... to be or not to be...\u0026quot; ‚Üí [\u0026quot;...\u0026quot;, \u0026quot;to\u0026quot;, \u0026quot;be\u0026quot;, \u0026quot;or\u0026quot;, \u0026quot;not\u0026quot;, \u0026quot;to\u0026quot;, \u0026quot;be\u0026quot;, \u0026quot;...\u0026quot;]„ÄÇ ÁªüËÆ°ËØçÈ¢ë \u0026amp; ÊûÑÂª∫ËØçÂÖ∏\nËØçÈ¢ëÁªüËÆ° Áî®ÂìàÂ∏åË°®/Â≠óÂÖ∏ËÆ∞ÂΩïÊØè‰∏™ÂçïËØçÂá∫Áé∞Ê¨°Êï∞„ÄÇ ÈÅçÂéÜÊñáÊú¨Êó∂ÔºåËã•ÂçïËØçÂ∞öÊú™ÂÖ•Ë°®ÔºåÂàôÊñ∞Âª∫ËÆ∞ÂΩïÔºõËã•Â∑≤Â≠òÂú®ÔºåÂàôËÆ°Êï∞+1„ÄÇ ÊéíÂ∫è‰∏éÁ¥¢Âºï ÊåâËØçÈ¢ëÈôçÂ∫èÊéíÂ∫èÔºåËØçÈ¢ëÊúÄÈ´òÁöÑÂçïËØçÊéíÂú®ÂâçÈù¢„ÄÇ Á¥¢Âºï‰ªé1ÂºÄÂßãÔºå0ÁïôÁªô‚ÄúÊú™Áü•‚Äù„ÄÇ ËØçÂÖ∏ËßÑÊ®°ÔºàvocabularyÔºâÂèØËßÜÈúÄÊ±ÇÊà™Êñ≠Ôºà‰æãÂ¶ÇÂè™‰øùÁïôTop 10kÔºâ„ÄÇ ‰∏∫‰ªÄ‰πàÁßªÈô§‰ΩéÈ¢ëËØç ‰ΩéÈ¢ëËØçÂèØËÉΩÊòØÊãºÂÜôÈîôËØØ„ÄÅÁΩïËßÅ‰∫∫ÂêçÁ≠âÔºåÂØπÊ®°ÂûãÂ∏ÆÂä©ÊúâÈôê„ÄÇ ÂáèÂ∞ëËØçÂÖ∏ËßÑÊ®°ÂèØÈôç‰ΩéËøêÁÆóÂºÄÈîÄ„ÄÅÂä†Âø´Ê®°ÂûãËÆ≠ÁªÉ‰∏éÊé®ÁêÜÈÄüÂ∫¶„ÄÇ Áã¨ÁÉ≠ÁºñÁ†Å (One-Hot Encoding)\nÂ∞ÜÊØè‰∏™ÂçïËØçÊò†Â∞Ñ‰∏∫ËØçÂÖ∏‰∏≠ÁöÑÁ¥¢ÂºïÂêéÔºàÂ¶Ç [2, 4, 1, 8, ‚Ä¶]ÔºâÔºåÂèØËøõ‰∏ÄÊ≠•ËΩ¨Êç¢ÊàêOne-HotÂêëÈáè„ÄÇ One-HotÁª¥Â∫¶ÂèñÂÜ≥‰∫é‰øùÁïô‰∏ãÊù•ÁöÑËØçÂÖ∏Â§ßÂ∞èÔºà‰æãÂ¶Ç1‰∏áÔºâ„ÄÇ Êú™Êî∂ÂΩïÂçïËØçÂèØËÉΩÁõ¥Êé•ÂøΩÁï•ÔºåÊàñÁªü‰∏ÄÁî®Á¥¢Âºï0‰ª£Êõø„ÄÇ Âõõ„ÄÅÊ†∏ÂøÉÊî∂Ëé∑‰∏éÂ∫îÁî® Á±ªÂà´ÁâπÂæÅÂøÖÈúÄÊï∞ÂÄºÂåñÔºö\n‰ΩøÁî®Êï¥Êï∞1,2,3‚Ä¶‰ªÖË°®Á§∫Á±ªÂà´‚ÄúÊ†áËØÜ‚ÄùÔºåÂπ∂‰∏ç‰ª£Ë°®ÂÆÉ‰ª¨ÂèØËøõË°åÊï∞ÂÄºËøêÁÆó„ÄÇ Âõ†Ê≠§ÈúÄË¶ÅOne-HotÁ≠âÁºñÁ†ÅÊñπÂºèÔºåÈÅøÂÖçÊï∞ÂÄºËØØËß£„ÄÇ ÊñáÊú¨Êï∞ÊçÆÈ¢ÑÂ§ÑÁêÜÔºö\nÂàÜËØç„ÄÅËØçÈ¢ëÁªüËÆ°„ÄÅÊûÑÂª∫ËØçÂÖ∏„ÄÅÁ¥¢ÂºïÂåñ„ÄÅOne-HotÊàñÂÖ∂‰ªñÊñπÂºèÔºàÂ¶ÇËØçÂµåÂÖ•ÔºâÊòØÂ∏∏ËßÅÊµÅÁ®ã„ÄÇ Ê≠£Á°ÆÁöÑÊñáÊú¨È¢ÑÂ§ÑÁêÜÂèØÊòæËëóÂΩ±ÂìçÊ®°ÂûãÊÄßËÉΩÂíåÊïàÁéá„ÄÇ ‰øùÁïôÊú™Áü•Á¥¢ÂºïÔºö\n‰øùËØÅÂØπÁº∫Â§±Êï∞ÊçÆÊàñÂ≠óÂÖ∏Â§ñÊñ∞ËØçËÉΩÊúâÂü∫Êú¨ÁöÑË°®Á§∫ÔºåÊèêÂçáÊ®°ÂûãÂÆπÈîôÊÄß„ÄÇ ÂÆûÈôÖ‰ΩøÁî®Ôºö\nÂØπ‰∫éÂ∞èËßÑÊ®°Á±ªÂà´ÂèØÁõ¥Êé•One-HotÁºñÁ†ÅÔºõÂØπ‰∫éËØçÂÖ∏ÂæàÂ§ßÁöÑÂú∫ÊôØÔºåÈÄöÂ∏∏‰ºöËøõ‰∏ÄÊ≠•ËÄÉËôëËØçÂµåÂÖ•ÔºàWord EmbeddingÔºâÊàñÈ¢ÑËÆ≠ÁªÉËØ≠Ë®ÄÊ®°Âûã„ÄÇ ","permalink":"http://localhost:1313/posts/nlp-1/","summary":"\u003ch2 id=\"‰∏ÄÊï∞ÂÄºÁâπÂæÅ‰∏éÁ±ªÂà´ÁâπÂæÅ\"\u003e‰∏Ä„ÄÅÊï∞ÂÄºÁâπÂæÅ‰∏éÁ±ªÂà´ÁâπÂæÅ\u003c/h2\u003e\n\u003col\u003e\n\u003cli\u003e\u003cstrong\u003eÊï∞ÂÄºÁâπÂæÅ (Numeric Features)\u003c/strong\u003e\n\u003cul\u003e\n\u003cli\u003eÂÖ∑ÊúâÂèØÂä†ÂáèÁöÑÊÑè‰πâÔºå‰∏îÂ≠òÂú®Â§ßÂ∞èÈ°∫Â∫è„ÄÇ\u003c/li\u003e\n\u003cli\u003e‰æãÂ≠êÔºöÂπ¥ÈæÑ„ÄÅÊ∏©Â∫¶Á≠â„ÄÇÂèØ‰ª•Áõ¥Êé•‰øùÁïôÂÖ∂Êï¥Êï∞ÊàñÊµÆÁÇπÊï∞ÂΩ¢Âºè‰æõÊ®°Âûã‰ΩøÁî®„ÄÇ\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003eÁ±ªÂà´ÁâπÂæÅ (Categorical Features)\u003c/strong\u003e\n\u003cul\u003e\n\u003cli\u003eÊï∞ÊçÆÂÄºÁ¶ªÊï£Ôºå‰∏çÂÖ∑Â§á‚ÄúÊï∞ÂÄºÂ§ßÂ∞è‚ÄùÈó¥ÁöÑÂèØÊØîÊÑè‰πâ„ÄÇ\u003c/li\u003e\n\u003cli\u003e‰æãÂ≠êÔºöÂõΩÁ±çÔºàÁæéÂõΩ/‰∏≠ÂõΩ/Âç∞Â∫¶Á≠âÔºâ„ÄÅÊÄßÂà´ÔºàÁî∑/Â•≥ÔºâÁ≠â„ÄÇ\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003eÈóÆÈ¢ò\u003c/strong\u003eÔºöËã•‰ªÖÁî®Êï¥Êï∞Ë°®Á§∫ÔºàÁæéÂõΩ=1, ‰∏≠ÂõΩ=2ÔºâÔºå‰ºöÂºïÂÖ•ÈîôËØØÁöÑÊï∞ÂÄºËøêÁÆóÂÖ≥Á≥ªÔºåÂ¶Ç ‚ÄúÁæéÂõΩ + ‰∏≠ÂõΩ = Âç∞Â∫¶‚Äù„ÄÇ\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003c/ol\u003e\n\u003ch2 id=\"‰∫åone-hotÁºñÁ†ÅÁöÑÂä®Êú∫‰∏éÊµÅÁ®ã\"\u003e‰∫å„ÄÅOne-HotÁºñÁ†ÅÁöÑÂä®Êú∫‰∏éÊµÅÁ®ã\u003c/h2\u003e\n\u003col\u003e\n\u003cli\u003e\n\u003cp\u003e\u003cstrong\u003e‰∏∫‰ªÄ‰πà‰ΩøÁî®One-Hot\u003c/strong\u003e\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eÈÄöËøáÂ∞ÜÁ±ªÂà´Êò†Â∞Ñ‰∏∫ÂêëÈáèÔºåÈÅøÂÖçÊï¥Êï∞ÁºñÁ†ÅÂºïÂÖ•ÁöÑ‰º™Êï∞ÂÄºÂÖ≥Á≥ª„ÄÇ\u003c/li\u003e\n\u003cli\u003eÂêåÊó∂‰øùÁïôÂêÑÁßçÂèØËÉΩÁ±ªÂà´ÁöÑ‰ø°ÊÅØÔºå‰∏î‰ªÖÂú®ÂØπÂ∫î‰ΩçÁΩÆ‰∏∫1ÔºåÂÖ∂‰ªñ‰ΩçÁΩÆ‰∏∫0„ÄÇ\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003e\u003cstrong\u003eÂª∫Á´ãÊò†Â∞ÑÔºö‰ªéÁ±ªÂà´Âà∞Á¥¢Âºï\u003c/strong\u003e\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e‰∏∫ÊØè‰∏™Á±ªÂà´ÂàÜÈÖç‰∏Ä‰∏™ÂîØ‰∏ÄÁ¥¢ÂºïÔºåÈÄöÂ∏∏‰ªé1ÂºÄÂßã„ÄÇ\u003c/li\u003e\n\u003cli\u003eÈ¢ÑÁïôÁ¥¢Âºï0Ë°®Á§∫‚ÄúÊú™Áü•‚ÄùÊàñ‚ÄúÁº∫Â§±‚ÄùÔºåÂØπÂ∫îÂÖ®0ÂêëÈáè„ÄÇ\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003e\u003cstrong\u003eËΩ¨Êç¢‰∏∫One-HotÂêëÈáè\u003c/strong\u003e\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eËã•Á±ªÂà´ÊÄªÊï∞‰∏∫197ÔºåÂàôÁî®197Áª¥ÂêëÈáèË°®Á§∫„ÄÇ\u003c/li\u003e\n\u003cli\u003e‰æãÂ≠êÔºöÁæéÂõΩ \u003ccode\u003e[1, 0, 0, 0, ‚Ä¶]\u003c/code\u003eÔºå ‰∏≠ÂõΩ \u003ccode\u003e[0, 1, 0, 0, ‚Ä¶]\u003c/code\u003e„ÄÇ\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003e\u003cstrong\u003eÁ§∫‰æãÔºöË°®Á§∫‰∏Ä‰∏™‰∫∫ÁöÑÁâπÂæÅ\u003c/strong\u003e\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eÁâπÂæÅÂåÖÂê´ÔºàÂπ¥ÈæÑ, ÊÄßÂà´, ÂõΩÁ±çÔºåÂÖ∂‰∏≠ÂõΩÁ±ç197ÁßçÔºâ\u003c/li\u003e\n\u003cli\u003eÁª¥Â∫¶ÊÄªÂíåÔºö1Áª¥_age + 1Áª¥_gender + 197Áª¥_nationality = 199Áª¥„ÄÇ\u003c/li\u003e\n\u003cli\u003e‰æãÂ¶Ç \u003ccode\u003e(28, Â•≥, ‰∏≠ÂõΩ)\u003c/code\u003e ‚Üí \u003ccode\u003e[28, 0, 0, 1, 0, ‚Ä¶, 0]\u003c/code\u003e„ÄÇ\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003c/ol\u003e\n\u003ch2 id=\"‰∏âÊñáÊú¨Êï∞ÊçÆÂ§ÑÁêÜÊµÅÁ®ã\"\u003e‰∏â„ÄÅÊñáÊú¨Êï∞ÊçÆÂ§ÑÁêÜÊµÅÁ®ã\u003c/h2\u003e\n\u003cp\u003eÊñáÊú¨Âú®Ëá™ÁÑ∂ËØ≠Ë®ÄÂ§ÑÁêÜÔºàNLPÔºâ‰∏≠‰Ωú‰∏∫Â∏∏ËßÅÁöÑÂéüÂßãËæìÂÖ•ÔºåÈúÄË¶ÅÊï∞ÂÄºÂåñÊâçËÉΩÈÄÅÂÖ•Ê®°Âûã„ÄÇ‰∏ÄËà¨Ê≠•È™§Â¶Ç‰∏ãÔºö\u003c/p\u003e\n\u003col\u003e\n\u003cli\u003e\n\u003cp\u003e\u003cstrong\u003eÂàÜËØç (Tokenization)\u003c/strong\u003e\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eÂ∞ÜÊñáÊú¨ÊãÜÂàÜ‰∏∫‰∏Ä‰∏™‰∏™ÂçïËØçÔºàTokenÔºâ„ÄÇ\u003c/li\u003e\n\u003cli\u003e‰æãÂ≠êÔºö\u003ccode\u003e\u0026quot;... to be or not to be...\u0026quot;\u003c/code\u003e ‚Üí \u003ccode\u003e[\u0026quot;...\u0026quot;, \u0026quot;to\u0026quot;, \u0026quot;be\u0026quot;, \u0026quot;or\u0026quot;, \u0026quot;not\u0026quot;, \u0026quot;to\u0026quot;, \u0026quot;be\u0026quot;, \u0026quot;...\u0026quot;]\u003c/code\u003e„ÄÇ\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003e\u003cstrong\u003eÁªüËÆ°ËØçÈ¢ë \u0026amp; ÊûÑÂª∫ËØçÂÖ∏\u003c/strong\u003e\u003c/p\u003e","title":""},{"content":"Text to Sequence ÊñáÊú¨Â§ÑÁêÜ\nStep1: Tokenization\nTokenization breaks a piece of text down into a list of tokens.\nHere, a token is a word. (A token can be a character in some applications.)\nTokenizationËÆ≤Á©∂ÂæàÂ§öÔºå‰æãÂ¶ÇÊòØÂê¶Â∫îËØ•ÊääÂ§ßÂÜôÊîπÊàêÂ∞èÂÜôÂë¢ÔºüËøõË°åtypo correctionÁ≠âÁ≠â\nStep2: Build Dictionary\nUse a dictionary (hash table) to count word frequencies.\nThe dictionary maps word to index.\nÂèØ‰ª•È¶ñÂÖàÁªüËÆ°ËØçÈ¢ëÂéªÊéâ‰ΩéÈ¢ëËØçÔºåÁÑ∂ÂêéËÆ©ÊØè‰∏™ËØçÂØπÂ∫î‰∏Ä‰∏™Ê≠£Êï¥Êï∞ÔºõËøôÊ†∑ÁöÑËØùÔºå‰∏ÄÂè•ËØùÂ∞±ÂèØ‰ª•Áî®‰∏Ä‰∏™Ê≠£Êï¥Êï∞ÂàóË°®Ë°®Á§∫ÔºåËøô‰∏™ÂàóË°®Â∞±Âè´sequenceÔºõÂ¶ÇÊûúÂøÖË¶ÅÂ∞±ËøòÂæóÂÅöone-hot encoding„ÄÇ\nÁªìÊûú\n‰ΩÜÊòØÈïøÂ∫¶‰∏çÁªü‰∏Ä\nStep4: ÂØπÈΩêsequence\nËß£ÂÜ≥ÊñπÊ°àÊòØËøôÊ†∑ÁöÑÔºöÂèØ‰ª•Âõ∫ÂÆöÈïøÂ∫¶‰∏∫wÔºåÂä†ÂÖ•‰∏Ä‰∏™Â∫èÂàóÈïøÂ∫¶Â§™ÈïøÔºåÂ∞±Á†çÊéâÂâçÈù¢ÁöÑËØçÔºåÂè™‰øùÁïôÊúÄÂêéw‰∏™ËØçÔºõÂ¶ÇÊûú‰∏Ä‰∏™Â∫èÂàóÂ§™Áü≠ÔºåÂ∞±ÂÅözero paddingÔºåÁî®0Â°´ÂÖÖ\nËøôÊ†∑‰∏ÄÊù•ÔºåÊâÄÊúâÁöÑÂ∫èÂàóÈïøÂ∫¶Â∞±Áªü‰∏Ä‰∫Ü\nÊñáÊú¨Â§ÑÁêÜÂÆåÊàê‰∫ÜÔºåÊé•‰∏ãÊù•ÊòØword embeddingÔºåÊääÂçïËØçË°®Á§∫‰∏∫‰∏Ä‰∏™‰ΩéÁª¥ÂêëÈáèÔºõ\nÁÑ∂ËÄåËøôÊ†∑ÂÅöÁöÑËØùÔºåÂ¶ÇÊûúÊòØ10000‰∏™ÂçïËØçÔºåÁª¥Â∫¶Â∞±ÊòØ10000Áª¥ÔºåÁª¥Â∫¶Â§™È´ò‰∫ÜÔºõÂõ†Ê≠§Ë¶ÅÂÅöword embeddingÔºõ\nÂÖ∑‰ΩìÂÅöÊ≥ïÂ∞±ÊòØÊääone-hotÂêëÈáèe_iÂíåÂèÇÊï∞Áü©ÈòµpÁõ∏‰πòÔºõÁü©ÈòµPËΩ¨ÁΩÆÁöÑÂ§ßÂ∞èÊòØd x vÔºõdÊòØËØçÂêëÈáèÁöÑÁª¥Â∫¶ÔºõvÊòØÂ≠óÂÖ∏ÈáåËØçÊ±áÁöÑÊï∞ÈáèÔºõÁªìÊûú‰∏∫x_iÔºõx_iÂ∞±ÊòØ‰∏Ä‰∏™ËØçÂêëÈáèÔºõÂ¶ÇÊûúone-hotÂêëÈáèÁöÑÁ¨¨‰∏âË°å‰∏∫1ÔºõÈÇ£‰πàx_iÂ∞±ÊòØPËΩ¨ÁΩÆÁü©ÈòµÁöÑÁ¨¨‰∏âÂàóÔºàÂÖ∂‰ΩôÂàóÈÉΩ‰∏∫0ÔºâÔºõÊâÄ‰ª•PËΩ¨ÁΩÆÊØè‰∏ÄÂàóÈÉΩÊòØ‰∏Ä‰∏™ËØçÂêëÈáèÔºõÊâÄ‰ª•Áü©ÈòµPÊú¨Ë∫´ÁöÑÊØè‰∏ÄË°åÂ∞±ÊòØ‰∏Ä‰∏™ËØçÂêëÈáèÔºõÂÖ∂Ë°åÊï∞‰∏∫vÔºõÂç≥vocabularyÔºåËØçÊ±áÈáèÔºõÊØè‰∏ÄË°åÂØπÂ∫î‰∏Ä‰∏™ÂçïËØçÔºõÁü©ÈòµÁöÑÂàóÊï∞‰∏∫dÔºõdÊòØÁî®Êà∑ÂÜ≥ÂÆöÁöÑÔºõdÁöÑÂ§ßÂ∞è‰ºöÂÜ≥ÂÆöÊú∫Âô®Â≠¶‰π†Ê®°ÂûãÁöÑË°®Áé∞ÔºõÂ∫îËØ•Áî®xxxÊù•ÈÄâÊã©‰∏Ä‰∏™ÊØîËæÉÂ•ΩÁöÑdÔºõ\nÊàë‰ª¨ÁöÑ‰ªªÂä°ÊòØÁúãËØÑËÆ∫ÊòØÊ≠£Èù¢ÁöÑËøòÊòØË¥üÈù¢ÁöÑÔºõÂèÇÊï∞Áü©ÈòµÊòØ‰ªéËÆ≠ÁªÉÊï∞ÊçÆ‰∏≠Â≠¶‰π†Âá∫Êù•ÁöÑÔºåÊâÄ‰ª•Â≠¶Âá∫Êù•ÁöÑËØçÂêëÈáèÊòØÂ∏¶ÊúâÊÑüÊÉÖËâ≤ÂΩ©ÁöÑÔºõÂÅáËÆæËøô‰∫õËØçÂêëÈáèÈÉΩÊòØ‰∫åÁª¥ÁöÑÔºåÂàôÂèØ‰ª•Âú®Âπ≥Èù¢ÂùêÊ†áÁ≥ª‰∏≠Ê†áÂá∫‰∏ãÈù¢ËØçÂêëÈáè\nkerasÊèê‰æõembeddingÂ±ÇÔºõÁî®Êà∑ÂèØ‰ª•ÊåáÂÆövocabularyÂ§ßÂ∞èÂíådÁöÑÂ§ßÂ∞èÔºõ‰ª•ÂèäÊØè‰∏Ä‰∏™sequenceÁöÑÈïøÂ∫¶ÔºõdÊòØÊ†πÊçÆÁÆóÊ≥ïÈÄâÂá∫Êù•ÁöÑ Âà∞Ëøô‰∏ÄÊ≠•ÔºåÊàë‰ª¨Â∑≤ÁªèÂÆåÊàê‰∫ÜÊñáÊú¨Â§ÑÁêÜÂíåword embedding„ÄÇÊé•‰∏ãÊù•Â∞±ÊòØÁî®Logistic Regression for Binary ClassificationÂÅö‰∫åÂàÜÁ±ªÔºõ\n","permalink":"http://localhost:1313/posts/nlp-2/","summary":"\u003ch3 id=\"text-to-sequence\"\u003eText to Sequence\u003c/h3\u003e\n\u003cp\u003eÊñáÊú¨Â§ÑÁêÜ\u003c/p\u003e\n\u003cp\u003eStep1: Tokenization\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\n\u003cp\u003eTokenization breaks a piece of text down into a list of tokens.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003eHere, a token is a word. (A token can be a character in some applications.)\u003c/p\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003eTokenizationËÆ≤Á©∂ÂæàÂ§öÔºå‰æãÂ¶ÇÊòØÂê¶Â∫îËØ•ÊääÂ§ßÂÜôÊîπÊàêÂ∞èÂÜôÂë¢ÔºüËøõË°åtypo correctionÁ≠âÁ≠â\u003c/p\u003e\n\u003cp\u003e\u003cimg alt=\"image-20250322150322238\" loading=\"lazy\" src=\"./NLP-2.assets/image-20250322150322238.png\"\u003e\u003c/p\u003e\n\u003cp\u003eStep2: Build Dictionary\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\n\u003cp\u003eUse a dictionary (hash table) to count word frequencies.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003eThe dictionary maps word to index.\u003c/p\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003eÂèØ‰ª•È¶ñÂÖàÁªüËÆ°ËØçÈ¢ëÂéªÊéâ‰ΩéÈ¢ëËØçÔºåÁÑ∂ÂêéËÆ©ÊØè‰∏™ËØçÂØπÂ∫î‰∏Ä‰∏™Ê≠£Êï¥Êï∞ÔºõËøôÊ†∑ÁöÑËØùÔºå‰∏ÄÂè•ËØùÂ∞±ÂèØ‰ª•Áî®‰∏Ä‰∏™Ê≠£Êï¥Êï∞ÂàóË°®Ë°®Á§∫ÔºåËøô‰∏™ÂàóË°®Â∞±Âè´sequenceÔºõÂ¶ÇÊûúÂøÖË¶ÅÂ∞±ËøòÂæóÂÅöone-hot encoding„ÄÇ\u003cimg alt=\"image-20250322150620890\" loading=\"lazy\" src=\"./NLP-2.assets/image-20250322150620890.png\"\u003e\u003c/p\u003e\n\u003cp\u003eÁªìÊûú\u003c/p\u003e\n\u003cp\u003e\u003cimg alt=\"image-20250322150754528\" loading=\"lazy\" src=\"./NLP-2.assets/image-20250322150754528.png\"\u003e\u003c/p\u003e\n\u003cp\u003e‰ΩÜÊòØÈïøÂ∫¶‰∏çÁªü‰∏Ä\u003c/p\u003e\n\u003cp\u003eStep4: ÂØπÈΩêsequence\u003c/p\u003e\n\u003cp\u003e\u003cimg alt=\"image-20250322150854986\" loading=\"lazy\" src=\"./NLP-2.assets/image-20250322150854986.png\"\u003e\u003c/p\u003e\n\u003cp\u003eËß£ÂÜ≥ÊñπÊ°àÊòØËøôÊ†∑ÁöÑÔºöÂèØ‰ª•Âõ∫ÂÆöÈïøÂ∫¶‰∏∫wÔºåÂä†ÂÖ•‰∏Ä‰∏™Â∫èÂàóÈïøÂ∫¶Â§™ÈïøÔºåÂ∞±Á†çÊéâÂâçÈù¢ÁöÑËØçÔºåÂè™‰øùÁïôÊúÄÂêéw‰∏™ËØçÔºõÂ¶ÇÊûú‰∏Ä‰∏™Â∫èÂàóÂ§™Áü≠ÔºåÂ∞±ÂÅözero paddingÔºåÁî®0Â°´ÂÖÖ\u003c/p\u003e\n\u003cp\u003e\u003cimg alt=\"image-20250322151030119\" loading=\"lazy\" src=\"./NLP-2.assets/image-20250322151030119.png\"\u003e\u003c/p\u003e\n\u003cp\u003eËøôÊ†∑‰∏ÄÊù•ÔºåÊâÄÊúâÁöÑÂ∫èÂàóÈïøÂ∫¶Â∞±Áªü‰∏Ä‰∫Ü\u003c/p\u003e\n\u003cp\u003e\u003cimg alt=\"image-20250322151117125\" loading=\"lazy\" src=\"./NLP-2.assets/image-20250322151117125.png\"\u003e\u003c/p\u003e\n\u003cp\u003eÊñáÊú¨Â§ÑÁêÜÂÆåÊàê‰∫ÜÔºåÊé•‰∏ãÊù•ÊòØword embeddingÔºåÊääÂçïËØçË°®Á§∫‰∏∫‰∏Ä‰∏™‰ΩéÁª¥ÂêëÈáèÔºõ\u003c/p\u003e\n\u003cp\u003e\u003cimg alt=\"image-20250322151252837\" loading=\"lazy\" src=\"./NLP-2.assets/image-20250322151252837.png\"\u003e\u003c/p\u003e","title":""},{"content":"üëã About me Hello! I\u0026rsquo;m Xu Zongsi, a passionate technology enthusiast currently pursuing my Master of Science in ECIC at The University of Hong Kong. With a solid background in Software Engineering from the Beijing Institute of Technology, I specialize in artificial intelligence areas like machine learning, deep learning, natural language processing, computer vision, and reinforcement learning.\nInspired by OpenAI\u0026rsquo;s five-step plan towards superintelligence, I am excited about AGI and have developed a keen interest in LLM agents, MLLM, and knowledge graphs. I see great potential in these fields and aspire to contribute to innovative solutions.\nüìö Education üá≠üá∞ The University of Hong Kong 09/2024 - Expected 11/2025 School of Computing and Data Science Master of Science in Electronic Commerce \u0026amp; Internet Computing Relevant Courses: Machine learning for business and e-commerce, Knowledge graphs, Financial fraud analytics, Internet infrastructure technologies, Website engineering, Blockchain and cryptocurrency, etc. üá®üá≥ Beijing Institute of Technology 09/2020 - 06/2024 School of Computer Science \u0026amp; Technology Bachelor of Engineering in Software Engineering, last two years GPA: 3.7/4 Relevant Courses: Reinforcement Learning, Deep Learning and Computer Vision, Artificial Intelligence and Robot Ethics, Almost Human: Mind, Brain and Artificial Intelligence, Mathematical Analysis for Engineering, Linear Algebra, Probability and Mathematical Statistics, etc. Skills: Python, Java, common data structures, design patterns, machine learning basics and algorithms, Linux, PyTorch, and some development tools (git, conda, etc.). üèÜ Awards \u0026amp; Honors Beijing Institute of Technology Undergraduate Scholarship (Top 20% of Grade) 06/2023 3rd Prize of China International \u0026#34;Internet \u0026#43;\u0026#34; College Student\u0026#39;s Innovation Competition 08/2022 Bronze Prize of \u0026#34;Challenge Cup\u0026#34; Capital University Entrepreneurship Competition 05/2022 üíº Project Experience üîç Online Transaction Fraud Detection 09/2024 ‚Äì 01/2025 Independent project, supervised by Dr. Vivien Chan Focused on addressing financial fraud in e-commerce to enhance the accuracy of transaction anomaly detection, while independently managing the entire case study that included data preprocessing, feature engineering, model building, evaluation, and results analysis. Effectively resolved class imbalance issues using SMOTE and ROSE techniques. Built various models including Logistic Regression, Random Forest, XGBoost, and LightGBM, ultimately selecting the LightGBM model to achieve a recall rate of 95.45% and an AUC of 99.84%. Wrote efficient and maintainable code, enhancing model training and data processing efficiency through parallel computing and logging. ü§ñ Multi-Model Intelligent Text Keyword Extraction System 08/2023 ‚Äì 09/2023 Group project, supervised by Associate Prof. Xiaolin Zhao Designed and implemented an intelligent text summary system that automatically extracts keywords from article titles and abstracts, enhancing the understanding and summarization of text information. Participated in the planning of the technical route and built a hybrid model combining extractive and generative approaches, utilizing advanced natural language processing techniques including KeyBERT, Sentence Transformer, BERT, and T5 models. Responsible for data preprocessing and tokenization, as well as the end-to-end implementation and training of the T5 model, optimizing the model architecture and hyperparameters, achieving satisfactory results after only 3 epochs of training. Model evaluation results showed that the Rouge-1, Rouge-2, and Rouge-L metrics reached 0.6345, 0.5038, and 0.5282, respectively, in the third epoch, validating the model\u0026rsquo;s effectiveness in the summarization task. üéì Cambridge University Machine Learning Summer Project 07/2023 ‚Äì 08/2023 Group project, supervised by Prof. Pietro Li√≤ Participated in the Cambridge University deep learning summer project, focusing on deep reinforcement learning; explored multi-agent learning algorithms across different environments. Reproduced the Multi-Agent Deep Deterministic Policy Gradient (MADDPG) algorithm in the Simple Adversary environment and studied the effect of agent numbers on convergence speed and stability, finding optimal stability at 21 agents. Designed and implemented comparative experiments inspired by the Rainbow algorithm, assessing target network strategies versus the Double Deep Q-Network (Double DQN). The results demonstrated that Double DQN significantly enhanced convergence speed, optimizing the overall learning process. Co-authored a group project paper on agent numbers and strategies effectiveness in multi-agent systems, achieving a score of 71% in the summer program (the highest in my group) and a \u0026ldquo;First Class\u0026rdquo; classification in the UK grading system. üëÅÔ∏è Deep Learning and Computer Vision Semester Project 09/2022 ‚Äì 12/2022 Independent project, supervised by Associate Prof. Guangyu Gao Designed and implemented a waste classifier using the ResNet model to improve classification accuracy and reduce resource waste. The project also enhanced understanding of transfer learning techniques with ResNet. Collected a dataset of 16 waste categories and preprocessed the images for uniformity and standardization, incorporating data augmentation techniques to enhance the dataset. Conducted experiments using ResNet34 and ResNet50 models through transfer learning, accelerating network convergence by leveraging pretrained weights. During training, techniques such as Batch Normalization and Dropout were applied to mitigate the risk of overfitting. The final model achieved an accuracy of 90% on the training set, while the performance on the test set was 61%, indicating a significant overfitting phenomenon during the training process. üéì Internship ‚öõÔ∏è Beijing Academy of Quantum Information Science 08/2023 ‚Äì 01/2024 Research Intern at Quantum Computation Department Proposed a quantum convolution kernel design based on variational quantum circuits and developed a universal quantum convolution layer, successfully integrating it into classical CNN architectures such as VGG, GoogLeNet, and ResNet. Developed and evaluated various hybrid models, including a simple model named HQCCNN-2, which achieved 84.45% accuracy on the FashionMNIST dataset, surpassing the traditional CNN\u0026rsquo;s 80.72%. This demonstrates the effectiveness of the quantum convolution layer in improving model performance. Tested on a real quantum computer further validated the effectiveness of the hybrid model, demonstrating the viable integration of quantum computing with deep learning, and highlighting the potential for leveraging quantum properties to enhance model performance. üèÖ Competition Experience ü•â China International \u0026#34;Internet \u0026#43;\u0026#34; College Students\u0026#39; Innovation Competition 08/2022 üõ°Ô∏è Zhongke Ushield: Deep Learning-based Face Privacy Protection Authentication System Responsible for constructing a localized facial feature extraction engine based on MobileFaceNet, ensuring feature extraction is completed on end devices (such as mobile phones and cameras), guaranteeing that raw data does not leave the domain and is not stored, thus enhancing user privacy protection while improving recognition efficiency. ü•â \u0026#34;Challenge Cup\u0026#34; Capital University Entrepreneurship Competition 05/2022 üå≥ Smart Orchard Responsible for the development of the fruit detection, ripeness prediction, and pest identification system, using deep convolutional neural network (CNN) technology for intelligent monitoring of crop growth conditions. Applied advanced object detection algorithms such as Faster R-CNN and YOLO to achieve high precision in apple detection and ripeness assessment, with an accuracy rate exceeding 90%, significantly enhancing the intelligence level of orchard management. Built and trained a dedicated dataset containing various pest samples, optimizing pest detection accuracy through data preprocessing (such as image normalization and resizing) and data augmentation techniques (like rotation, flipping, and noise addition), enabling the real-time monitoring system to accurately identify over 80% of pests, providing effective scientific maintenance recommendations to help farmers reduce crop losses. üìã Extracurricular Activities Vice President, Cyber Security Club, Beijing Institute of Technology 09/2021-09/2022 Backbone, Media Center of the Student Union of Beijing Institute of Technology 10/2020-06/2021 üì´ Contact üìß zongsi.xu@outlook.com üëî LinkedIn: Zongsi (Tristan) Xu üíª GitHub: BaizeXS üìç Location: Hong Kong SAR, China ","permalink":"http://localhost:1313/resume/","summary":"Personal resume of Zongsi (Tristan) Xu","title":"Zongsi (Tristan) Xu"},{"content":"‰∏Ä„ÄÅÊï∞ÂÄºÁâπÂæÅ‰∏éÁ±ªÂà´ÁâπÂæÅ Êï∞ÂÄºÁâπÂæÅ (Numeric Features) ÂÖ∑ÊúâÂèØÂä†ÂáèÁöÑÊÑè‰πâÔºå‰∏îÂ≠òÂú®Â§ßÂ∞èÈ°∫Â∫è„ÄÇ ‰æãÂ≠êÔºöÂπ¥ÈæÑ„ÄÅÊ∏©Â∫¶Á≠â„ÄÇÂèØ‰ª•Áõ¥Êé•‰øùÁïôÂÖ∂Êï¥Êï∞ÊàñÊµÆÁÇπÊï∞ÂΩ¢Âºè‰æõÊ®°Âûã‰ΩøÁî®„ÄÇ Á±ªÂà´ÁâπÂæÅ (Categorical Features) Êï∞ÊçÆÂÄºÁ¶ªÊï£Ôºå‰∏çÂÖ∑Â§á‚ÄúÊï∞ÂÄºÂ§ßÂ∞è‚ÄùÈó¥ÁöÑÂèØÊØîÊÑè‰πâ„ÄÇ ‰æãÂ≠êÔºöÂõΩÁ±çÔºàÁæéÂõΩ/‰∏≠ÂõΩ/Âç∞Â∫¶Á≠âÔºâ„ÄÅÊÄßÂà´ÔºàÁî∑/Â•≥ÔºâÁ≠â„ÄÇ ÈóÆÈ¢òÔºöËã•‰ªÖÁî®Êï¥Êï∞Ë°®Á§∫ÔºàÁæéÂõΩ=1, ‰∏≠ÂõΩ=2ÔºâÔºå‰ºöÂºïÂÖ•ÈîôËØØÁöÑÊï∞ÂÄºËøêÁÆóÂÖ≥Á≥ªÔºåÂ¶Ç ‚ÄúÁæéÂõΩ + ‰∏≠ÂõΩ = Âç∞Â∫¶‚Äù„ÄÇ ‰∫å„ÄÅOne-HotÁºñÁ†ÅÁöÑÂä®Êú∫‰∏éÊµÅÁ®ã ‰∏∫‰ªÄ‰πà‰ΩøÁî®One-Hot\nÈÄöËøáÂ∞ÜÁ±ªÂà´Êò†Â∞Ñ‰∏∫ÂêëÈáèÔºåÈÅøÂÖçÊï¥Êï∞ÁºñÁ†ÅÂºïÂÖ•ÁöÑ‰º™Êï∞ÂÄºÂÖ≥Á≥ª„ÄÇ ÂêåÊó∂‰øùÁïôÂêÑÁßçÂèØËÉΩÁ±ªÂà´ÁöÑ‰ø°ÊÅØÔºå‰∏î‰ªÖÂú®ÂØπÂ∫î‰ΩçÁΩÆ‰∏∫1ÔºåÂÖ∂‰ªñ‰ΩçÁΩÆ‰∏∫0„ÄÇ Âª∫Á´ãÊò†Â∞ÑÔºö‰ªéÁ±ªÂà´Âà∞Á¥¢Âºï\n‰∏∫ÊØè‰∏™Á±ªÂà´ÂàÜÈÖç‰∏Ä‰∏™ÂîØ‰∏ÄÁ¥¢ÂºïÔºåÈÄöÂ∏∏‰ªé1ÂºÄÂßã„ÄÇ È¢ÑÁïôÁ¥¢Âºï0Ë°®Á§∫‚ÄúÊú™Áü•‚ÄùÊàñ‚ÄúÁº∫Â§±‚ÄùÔºåÂØπÂ∫îÂÖ®0ÂêëÈáè„ÄÇ ËΩ¨Êç¢‰∏∫One-HotÂêëÈáè\nËã•Á±ªÂà´ÊÄªÊï∞‰∏∫197ÔºåÂàôÁî®197Áª¥ÂêëÈáèË°®Á§∫„ÄÇ ‰æãÂ≠êÔºöÁæéÂõΩ [1, 0, 0, 0, ‚Ä¶]Ôºå ‰∏≠ÂõΩ [0, 1, 0, 0, ‚Ä¶]„ÄÇ Á§∫‰æãÔºöË°®Á§∫‰∏Ä‰∏™‰∫∫ÁöÑÁâπÂæÅ\nÁâπÂæÅÂåÖÂê´ÔºàÂπ¥ÈæÑ, ÊÄßÂà´, ÂõΩÁ±çÔºåÂÖ∂‰∏≠ÂõΩÁ±ç197ÁßçÔºâ Áª¥Â∫¶ÊÄªÂíåÔºö1Áª¥_age + 1Áª¥_gender + 197Áª¥_nationality = 199Áª¥„ÄÇ ‰æãÂ¶Ç (28, Â•≥, ‰∏≠ÂõΩ) ‚Üí [28, 0, 0, 1, 0, ‚Ä¶, 0]„ÄÇ ‰∏â„ÄÅÊñáÊú¨Êï∞ÊçÆÂ§ÑÁêÜÊµÅÁ®ã ÊñáÊú¨Âú®Ëá™ÁÑ∂ËØ≠Ë®ÄÂ§ÑÁêÜÔºàNLPÔºâ‰∏≠‰Ωú‰∏∫Â∏∏ËßÅÁöÑÂéüÂßãËæìÂÖ•ÔºåÈúÄË¶ÅÊï∞ÂÄºÂåñÊâçËÉΩÈÄÅÂÖ•Ê®°Âûã„ÄÇ‰∏ÄËà¨Ê≠•È™§Â¶Ç‰∏ãÔºö\nÂàÜËØç (Tokenization)\nÂ∞ÜÊñáÊú¨ÊãÜÂàÜ‰∏∫‰∏Ä‰∏™‰∏™ÂçïËØçÔºàTokenÔºâ„ÄÇ ‰æãÂ≠êÔºö\u0026quot;... to be or not to be...\u0026quot; ‚Üí [\u0026quot;...\u0026quot;, \u0026quot;to\u0026quot;, \u0026quot;be\u0026quot;, \u0026quot;or\u0026quot;, \u0026quot;not\u0026quot;, \u0026quot;to\u0026quot;, \u0026quot;be\u0026quot;, \u0026quot;...\u0026quot;]„ÄÇ ÁªüËÆ°ËØçÈ¢ë \u0026amp; ÊûÑÂª∫ËØçÂÖ∏\nËØçÈ¢ëÁªüËÆ° Áî®ÂìàÂ∏åË°®/Â≠óÂÖ∏ËÆ∞ÂΩïÊØè‰∏™ÂçïËØçÂá∫Áé∞Ê¨°Êï∞„ÄÇ ÈÅçÂéÜÊñáÊú¨Êó∂ÔºåËã•ÂçïËØçÂ∞öÊú™ÂÖ•Ë°®ÔºåÂàôÊñ∞Âª∫ËÆ∞ÂΩïÔºõËã•Â∑≤Â≠òÂú®ÔºåÂàôËÆ°Êï∞+1„ÄÇ ÊéíÂ∫è‰∏éÁ¥¢Âºï ÊåâËØçÈ¢ëÈôçÂ∫èÊéíÂ∫èÔºåËØçÈ¢ëÊúÄÈ´òÁöÑÂçïËØçÊéíÂú®ÂâçÈù¢„ÄÇ Á¥¢Âºï‰ªé1ÂºÄÂßãÔºå0ÁïôÁªô‚ÄúÊú™Áü•‚Äù„ÄÇ ËØçÂÖ∏ËßÑÊ®°ÔºàvocabularyÔºâÂèØËßÜÈúÄÊ±ÇÊà™Êñ≠Ôºà‰æãÂ¶ÇÂè™‰øùÁïôTop 10kÔºâ„ÄÇ ‰∏∫‰ªÄ‰πàÁßªÈô§‰ΩéÈ¢ëËØç ‰ΩéÈ¢ëËØçÂèØËÉΩÊòØÊãºÂÜôÈîôËØØ„ÄÅÁΩïËßÅ‰∫∫ÂêçÁ≠âÔºåÂØπÊ®°ÂûãÂ∏ÆÂä©ÊúâÈôê„ÄÇ ÂáèÂ∞ëËØçÂÖ∏ËßÑÊ®°ÂèØÈôç‰ΩéËøêÁÆóÂºÄÈîÄ„ÄÅÂä†Âø´Ê®°ÂûãËÆ≠ÁªÉ‰∏éÊé®ÁêÜÈÄüÂ∫¶„ÄÇ Áã¨ÁÉ≠ÁºñÁ†Å (One-Hot Encoding)\nÂ∞ÜÊØè‰∏™ÂçïËØçÊò†Â∞Ñ‰∏∫ËØçÂÖ∏‰∏≠ÁöÑÁ¥¢ÂºïÂêéÔºàÂ¶Ç [2, 4, 1, 8, ‚Ä¶]ÔºâÔºåÂèØËøõ‰∏ÄÊ≠•ËΩ¨Êç¢ÊàêOne-HotÂêëÈáè„ÄÇ One-HotÁª¥Â∫¶ÂèñÂÜ≥‰∫é‰øùÁïô‰∏ãÊù•ÁöÑËØçÂÖ∏Â§ßÂ∞èÔºà‰æãÂ¶Ç1‰∏áÔºâ„ÄÇ Êú™Êî∂ÂΩïÂçïËØçÂèØËÉΩÁõ¥Êé•ÂøΩÁï•ÔºåÊàñÁªü‰∏ÄÁî®Á¥¢Âºï0‰ª£Êõø„ÄÇ Âõõ„ÄÅÊ†∏ÂøÉÊî∂Ëé∑‰∏éÂ∫îÁî® Á±ªÂà´ÁâπÂæÅÂøÖÈúÄÊï∞ÂÄºÂåñÔºö\n‰ΩøÁî®Êï¥Êï∞1,2,3‚Ä¶‰ªÖË°®Á§∫Á±ªÂà´‚ÄúÊ†áËØÜ‚ÄùÔºåÂπ∂‰∏ç‰ª£Ë°®ÂÆÉ‰ª¨ÂèØËøõË°åÊï∞ÂÄºËøêÁÆó„ÄÇ Âõ†Ê≠§ÈúÄË¶ÅOne-HotÁ≠âÁºñÁ†ÅÊñπÂºèÔºåÈÅøÂÖçÊï∞ÂÄºËØØËß£„ÄÇ ÊñáÊú¨Êï∞ÊçÆÈ¢ÑÂ§ÑÁêÜÔºö\nÂàÜËØç„ÄÅËØçÈ¢ëÁªüËÆ°„ÄÅÊûÑÂª∫ËØçÂÖ∏„ÄÅÁ¥¢ÂºïÂåñ„ÄÅOne-HotÊàñÂÖ∂‰ªñÊñπÂºèÔºàÂ¶ÇËØçÂµåÂÖ•ÔºâÊòØÂ∏∏ËßÅÊµÅÁ®ã„ÄÇ Ê≠£Á°ÆÁöÑÊñáÊú¨È¢ÑÂ§ÑÁêÜÂèØÊòæËëóÂΩ±ÂìçÊ®°ÂûãÊÄßËÉΩÂíåÊïàÁéá„ÄÇ ‰øùÁïôÊú™Áü•Á¥¢ÂºïÔºö\n‰øùËØÅÂØπÁº∫Â§±Êï∞ÊçÆÊàñÂ≠óÂÖ∏Â§ñÊñ∞ËØçËÉΩÊúâÂü∫Êú¨ÁöÑË°®Á§∫ÔºåÊèêÂçáÊ®°ÂûãÂÆπÈîôÊÄß„ÄÇ ÂÆûÈôÖ‰ΩøÁî®Ôºö\nÂØπ‰∫éÂ∞èËßÑÊ®°Á±ªÂà´ÂèØÁõ¥Êé•One-HotÁºñÁ†ÅÔºõÂØπ‰∫éËØçÂÖ∏ÂæàÂ§ßÁöÑÂú∫ÊôØÔºåÈÄöÂ∏∏‰ºöËøõ‰∏ÄÊ≠•ËÄÉËôëËØçÂµåÂÖ•ÔºàWord EmbeddingÔºâÊàñÈ¢ÑËÆ≠ÁªÉËØ≠Ë®ÄÊ®°Âûã„ÄÇ ","permalink":"http://localhost:1313/posts/nlp-1/","summary":"\u003ch2 id=\"‰∏ÄÊï∞ÂÄºÁâπÂæÅ‰∏éÁ±ªÂà´ÁâπÂæÅ\"\u003e‰∏Ä„ÄÅÊï∞ÂÄºÁâπÂæÅ‰∏éÁ±ªÂà´ÁâπÂæÅ\u003c/h2\u003e\n\u003col\u003e\n\u003cli\u003e\u003cstrong\u003eÊï∞ÂÄºÁâπÂæÅ (Numeric Features)\u003c/strong\u003e\n\u003cul\u003e\n\u003cli\u003eÂÖ∑ÊúâÂèØÂä†ÂáèÁöÑÊÑè‰πâÔºå‰∏îÂ≠òÂú®Â§ßÂ∞èÈ°∫Â∫è„ÄÇ\u003c/li\u003e\n\u003cli\u003e‰æãÂ≠êÔºöÂπ¥ÈæÑ„ÄÅÊ∏©Â∫¶Á≠â„ÄÇÂèØ‰ª•Áõ¥Êé•‰øùÁïôÂÖ∂Êï¥Êï∞ÊàñÊµÆÁÇπÊï∞ÂΩ¢Âºè‰æõÊ®°Âûã‰ΩøÁî®„ÄÇ\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003eÁ±ªÂà´ÁâπÂæÅ (Categorical Features)\u003c/strong\u003e\n\u003cul\u003e\n\u003cli\u003eÊï∞ÊçÆÂÄºÁ¶ªÊï£Ôºå‰∏çÂÖ∑Â§á‚ÄúÊï∞ÂÄºÂ§ßÂ∞è‚ÄùÈó¥ÁöÑÂèØÊØîÊÑè‰πâ„ÄÇ\u003c/li\u003e\n\u003cli\u003e‰æãÂ≠êÔºöÂõΩÁ±çÔºàÁæéÂõΩ/‰∏≠ÂõΩ/Âç∞Â∫¶Á≠âÔºâ„ÄÅÊÄßÂà´ÔºàÁî∑/Â•≥ÔºâÁ≠â„ÄÇ\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003eÈóÆÈ¢ò\u003c/strong\u003eÔºöËã•‰ªÖÁî®Êï¥Êï∞Ë°®Á§∫ÔºàÁæéÂõΩ=1, ‰∏≠ÂõΩ=2ÔºâÔºå‰ºöÂºïÂÖ•ÈîôËØØÁöÑÊï∞ÂÄºËøêÁÆóÂÖ≥Á≥ªÔºåÂ¶Ç ‚ÄúÁæéÂõΩ + ‰∏≠ÂõΩ = Âç∞Â∫¶‚Äù„ÄÇ\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003c/ol\u003e\n\u003ch2 id=\"‰∫åone-hotÁºñÁ†ÅÁöÑÂä®Êú∫‰∏éÊµÅÁ®ã\"\u003e‰∫å„ÄÅOne-HotÁºñÁ†ÅÁöÑÂä®Êú∫‰∏éÊµÅÁ®ã\u003c/h2\u003e\n\u003col\u003e\n\u003cli\u003e\n\u003cp\u003e\u003cstrong\u003e‰∏∫‰ªÄ‰πà‰ΩøÁî®One-Hot\u003c/strong\u003e\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eÈÄöËøáÂ∞ÜÁ±ªÂà´Êò†Â∞Ñ‰∏∫ÂêëÈáèÔºåÈÅøÂÖçÊï¥Êï∞ÁºñÁ†ÅÂºïÂÖ•ÁöÑ‰º™Êï∞ÂÄºÂÖ≥Á≥ª„ÄÇ\u003c/li\u003e\n\u003cli\u003eÂêåÊó∂‰øùÁïôÂêÑÁßçÂèØËÉΩÁ±ªÂà´ÁöÑ‰ø°ÊÅØÔºå‰∏î‰ªÖÂú®ÂØπÂ∫î‰ΩçÁΩÆ‰∏∫1ÔºåÂÖ∂‰ªñ‰ΩçÁΩÆ‰∏∫0„ÄÇ\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003e\u003cstrong\u003eÂª∫Á´ãÊò†Â∞ÑÔºö‰ªéÁ±ªÂà´Âà∞Á¥¢Âºï\u003c/strong\u003e\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e‰∏∫ÊØè‰∏™Á±ªÂà´ÂàÜÈÖç‰∏Ä‰∏™ÂîØ‰∏ÄÁ¥¢ÂºïÔºåÈÄöÂ∏∏‰ªé1ÂºÄÂßã„ÄÇ\u003c/li\u003e\n\u003cli\u003eÈ¢ÑÁïôÁ¥¢Âºï0Ë°®Á§∫‚ÄúÊú™Áü•‚ÄùÊàñ‚ÄúÁº∫Â§±‚ÄùÔºåÂØπÂ∫îÂÖ®0ÂêëÈáè„ÄÇ\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003e\u003cstrong\u003eËΩ¨Êç¢‰∏∫One-HotÂêëÈáè\u003c/strong\u003e\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eËã•Á±ªÂà´ÊÄªÊï∞‰∏∫197ÔºåÂàôÁî®197Áª¥ÂêëÈáèË°®Á§∫„ÄÇ\u003c/li\u003e\n\u003cli\u003e‰æãÂ≠êÔºöÁæéÂõΩ \u003ccode\u003e[1, 0, 0, 0, ‚Ä¶]\u003c/code\u003eÔºå ‰∏≠ÂõΩ \u003ccode\u003e[0, 1, 0, 0, ‚Ä¶]\u003c/code\u003e„ÄÇ\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003e\u003cstrong\u003eÁ§∫‰æãÔºöË°®Á§∫‰∏Ä‰∏™‰∫∫ÁöÑÁâπÂæÅ\u003c/strong\u003e\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eÁâπÂæÅÂåÖÂê´ÔºàÂπ¥ÈæÑ, ÊÄßÂà´, ÂõΩÁ±çÔºåÂÖ∂‰∏≠ÂõΩÁ±ç197ÁßçÔºâ\u003c/li\u003e\n\u003cli\u003eÁª¥Â∫¶ÊÄªÂíåÔºö1Áª¥_age + 1Áª¥_gender + 197Áª¥_nationality = 199Áª¥„ÄÇ\u003c/li\u003e\n\u003cli\u003e‰æãÂ¶Ç \u003ccode\u003e(28, Â•≥, ‰∏≠ÂõΩ)\u003c/code\u003e ‚Üí \u003ccode\u003e[28, 0, 0, 1, 0, ‚Ä¶, 0]\u003c/code\u003e„ÄÇ\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003c/ol\u003e\n\u003ch2 id=\"‰∏âÊñáÊú¨Êï∞ÊçÆÂ§ÑÁêÜÊµÅÁ®ã\"\u003e‰∏â„ÄÅÊñáÊú¨Êï∞ÊçÆÂ§ÑÁêÜÊµÅÁ®ã\u003c/h2\u003e\n\u003cp\u003eÊñáÊú¨Âú®Ëá™ÁÑ∂ËØ≠Ë®ÄÂ§ÑÁêÜÔºàNLPÔºâ‰∏≠‰Ωú‰∏∫Â∏∏ËßÅÁöÑÂéüÂßãËæìÂÖ•ÔºåÈúÄË¶ÅÊï∞ÂÄºÂåñÊâçËÉΩÈÄÅÂÖ•Ê®°Âûã„ÄÇ‰∏ÄËà¨Ê≠•È™§Â¶Ç‰∏ãÔºö\u003c/p\u003e\n\u003col\u003e\n\u003cli\u003e\n\u003cp\u003e\u003cstrong\u003eÂàÜËØç (Tokenization)\u003c/strong\u003e\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eÂ∞ÜÊñáÊú¨ÊãÜÂàÜ‰∏∫‰∏Ä‰∏™‰∏™ÂçïËØçÔºàTokenÔºâ„ÄÇ\u003c/li\u003e\n\u003cli\u003e‰æãÂ≠êÔºö\u003ccode\u003e\u0026quot;... to be or not to be...\u0026quot;\u003c/code\u003e ‚Üí \u003ccode\u003e[\u0026quot;...\u0026quot;, \u0026quot;to\u0026quot;, \u0026quot;be\u0026quot;, \u0026quot;or\u0026quot;, \u0026quot;not\u0026quot;, \u0026quot;to\u0026quot;, \u0026quot;be\u0026quot;, \u0026quot;...\u0026quot;]\u003c/code\u003e„ÄÇ\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003e\u003cstrong\u003eÁªüËÆ°ËØçÈ¢ë \u0026amp; ÊûÑÂª∫ËØçÂÖ∏\u003c/strong\u003e\u003c/p\u003e","title":""},{"content":"Text to Sequence ÊñáÊú¨Â§ÑÁêÜ\nStep1: Tokenization\nTokenization breaks a piece of text down into a list of tokens.\nHere, a token is a word. (A token can be a character in some applications.)\nTokenizationËÆ≤Á©∂ÂæàÂ§öÔºå‰æãÂ¶ÇÊòØÂê¶Â∫îËØ•ÊääÂ§ßÂÜôÊîπÊàêÂ∞èÂÜôÂë¢ÔºüËøõË°åtypo correctionÁ≠âÁ≠â\nStep2: Build Dictionary\nUse a dictionary (hash table) to count word frequencies.\nThe dictionary maps word to index.\nÂèØ‰ª•È¶ñÂÖàÁªüËÆ°ËØçÈ¢ëÂéªÊéâ‰ΩéÈ¢ëËØçÔºåÁÑ∂ÂêéËÆ©ÊØè‰∏™ËØçÂØπÂ∫î‰∏Ä‰∏™Ê≠£Êï¥Êï∞ÔºõËøôÊ†∑ÁöÑËØùÔºå‰∏ÄÂè•ËØùÂ∞±ÂèØ‰ª•Áî®‰∏Ä‰∏™Ê≠£Êï¥Êï∞ÂàóË°®Ë°®Á§∫ÔºåËøô‰∏™ÂàóË°®Â∞±Âè´sequenceÔºõÂ¶ÇÊûúÂøÖË¶ÅÂ∞±ËøòÂæóÂÅöone-hot encoding„ÄÇ\nÁªìÊûú\n‰ΩÜÊòØÈïøÂ∫¶‰∏çÁªü‰∏Ä\nStep4: ÂØπÈΩêsequence\nËß£ÂÜ≥ÊñπÊ°àÊòØËøôÊ†∑ÁöÑÔºöÂèØ‰ª•Âõ∫ÂÆöÈïøÂ∫¶‰∏∫wÔºåÂä†ÂÖ•‰∏Ä‰∏™Â∫èÂàóÈïøÂ∫¶Â§™ÈïøÔºåÂ∞±Á†çÊéâÂâçÈù¢ÁöÑËØçÔºåÂè™‰øùÁïôÊúÄÂêéw‰∏™ËØçÔºõÂ¶ÇÊûú‰∏Ä‰∏™Â∫èÂàóÂ§™Áü≠ÔºåÂ∞±ÂÅözero paddingÔºåÁî®0Â°´ÂÖÖ\nËøôÊ†∑‰∏ÄÊù•ÔºåÊâÄÊúâÁöÑÂ∫èÂàóÈïøÂ∫¶Â∞±Áªü‰∏Ä‰∫Ü\nÊñáÊú¨Â§ÑÁêÜÂÆåÊàê‰∫ÜÔºåÊé•‰∏ãÊù•ÊòØword embeddingÔºåÊääÂçïËØçË°®Á§∫‰∏∫‰∏Ä‰∏™‰ΩéÁª¥ÂêëÈáèÔºõ\nÁÑ∂ËÄåËøôÊ†∑ÂÅöÁöÑËØùÔºåÂ¶ÇÊûúÊòØ10000‰∏™ÂçïËØçÔºåÁª¥Â∫¶Â∞±ÊòØ10000Áª¥ÔºåÁª¥Â∫¶Â§™È´ò‰∫ÜÔºõÂõ†Ê≠§Ë¶ÅÂÅöword embeddingÔºõ\nÂÖ∑‰ΩìÂÅöÊ≥ïÂ∞±ÊòØÊääone-hotÂêëÈáèe_iÂíåÂèÇÊï∞Áü©ÈòµpÁõ∏‰πòÔºõÁü©ÈòµPËΩ¨ÁΩÆÁöÑÂ§ßÂ∞èÊòØd x vÔºõdÊòØËØçÂêëÈáèÁöÑÁª¥Â∫¶ÔºõvÊòØÂ≠óÂÖ∏ÈáåËØçÊ±áÁöÑÊï∞ÈáèÔºõÁªìÊûú‰∏∫x_iÔºõx_iÂ∞±ÊòØ‰∏Ä‰∏™ËØçÂêëÈáèÔºõÂ¶ÇÊûúone-hotÂêëÈáèÁöÑÁ¨¨‰∏âË°å‰∏∫1ÔºõÈÇ£‰πàx_iÂ∞±ÊòØPËΩ¨ÁΩÆÁü©ÈòµÁöÑÁ¨¨‰∏âÂàóÔºàÂÖ∂‰ΩôÂàóÈÉΩ‰∏∫0ÔºâÔºõÊâÄ‰ª•PËΩ¨ÁΩÆÊØè‰∏ÄÂàóÈÉΩÊòØ‰∏Ä‰∏™ËØçÂêëÈáèÔºõÊâÄ‰ª•Áü©ÈòµPÊú¨Ë∫´ÁöÑÊØè‰∏ÄË°åÂ∞±ÊòØ‰∏Ä‰∏™ËØçÂêëÈáèÔºõÂÖ∂Ë°åÊï∞‰∏∫vÔºõÂç≥vocabularyÔºåËØçÊ±áÈáèÔºõÊØè‰∏ÄË°åÂØπÂ∫î‰∏Ä‰∏™ÂçïËØçÔºõÁü©ÈòµÁöÑÂàóÊï∞‰∏∫dÔºõdÊòØÁî®Êà∑ÂÜ≥ÂÆöÁöÑÔºõdÁöÑÂ§ßÂ∞è‰ºöÂÜ≥ÂÆöÊú∫Âô®Â≠¶‰π†Ê®°ÂûãÁöÑË°®Áé∞ÔºõÂ∫îËØ•Áî®xxxÊù•ÈÄâÊã©‰∏Ä‰∏™ÊØîËæÉÂ•ΩÁöÑdÔºõ\nÊàë‰ª¨ÁöÑ‰ªªÂä°ÊòØÁúãËØÑËÆ∫ÊòØÊ≠£Èù¢ÁöÑËøòÊòØË¥üÈù¢ÁöÑÔºõÂèÇÊï∞Áü©ÈòµÊòØ‰ªéËÆ≠ÁªÉÊï∞ÊçÆ‰∏≠Â≠¶‰π†Âá∫Êù•ÁöÑÔºåÊâÄ‰ª•Â≠¶Âá∫Êù•ÁöÑËØçÂêëÈáèÊòØÂ∏¶ÊúâÊÑüÊÉÖËâ≤ÂΩ©ÁöÑÔºõÂÅáËÆæËøô‰∫õËØçÂêëÈáèÈÉΩÊòØ‰∫åÁª¥ÁöÑÔºåÂàôÂèØ‰ª•Âú®Âπ≥Èù¢ÂùêÊ†áÁ≥ª‰∏≠Ê†áÂá∫‰∏ãÈù¢ËØçÂêëÈáè\nkerasÊèê‰æõembeddingÂ±ÇÔºõÁî®Êà∑ÂèØ‰ª•ÊåáÂÆövocabularyÂ§ßÂ∞èÂíådÁöÑÂ§ßÂ∞èÔºõ‰ª•ÂèäÊØè‰∏Ä‰∏™sequenceÁöÑÈïøÂ∫¶ÔºõdÊòØÊ†πÊçÆÁÆóÊ≥ïÈÄâÂá∫Êù•ÁöÑ Âà∞Ëøô‰∏ÄÊ≠•ÔºåÊàë‰ª¨Â∑≤ÁªèÂÆåÊàê‰∫ÜÊñáÊú¨Â§ÑÁêÜÂíåword embedding„ÄÇÊé•‰∏ãÊù•Â∞±ÊòØÁî®Logistic Regression for Binary ClassificationÂÅö‰∫åÂàÜÁ±ªÔºõ\n","permalink":"http://localhost:1313/posts/nlp-2/","summary":"\u003ch3 id=\"text-to-sequence\"\u003eText to Sequence\u003c/h3\u003e\n\u003cp\u003eÊñáÊú¨Â§ÑÁêÜ\u003c/p\u003e\n\u003cp\u003eStep1: Tokenization\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\n\u003cp\u003eTokenization breaks a piece of text down into a list of tokens.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003eHere, a token is a word. (A token can be a character in some applications.)\u003c/p\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003eTokenizationËÆ≤Á©∂ÂæàÂ§öÔºå‰æãÂ¶ÇÊòØÂê¶Â∫îËØ•ÊääÂ§ßÂÜôÊîπÊàêÂ∞èÂÜôÂë¢ÔºüËøõË°åtypo correctionÁ≠âÁ≠â\u003c/p\u003e\n\u003cp\u003e\u003cimg alt=\"image-20250322150322238\" loading=\"lazy\" src=\"./NLP-2.assets/image-20250322150322238.png\"\u003e\u003c/p\u003e\n\u003cp\u003eStep2: Build Dictionary\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\n\u003cp\u003eUse a dictionary (hash table) to count word frequencies.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003eThe dictionary maps word to index.\u003c/p\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003eÂèØ‰ª•È¶ñÂÖàÁªüËÆ°ËØçÈ¢ëÂéªÊéâ‰ΩéÈ¢ëËØçÔºåÁÑ∂ÂêéËÆ©ÊØè‰∏™ËØçÂØπÂ∫î‰∏Ä‰∏™Ê≠£Êï¥Êï∞ÔºõËøôÊ†∑ÁöÑËØùÔºå‰∏ÄÂè•ËØùÂ∞±ÂèØ‰ª•Áî®‰∏Ä‰∏™Ê≠£Êï¥Êï∞ÂàóË°®Ë°®Á§∫ÔºåËøô‰∏™ÂàóË°®Â∞±Âè´sequenceÔºõÂ¶ÇÊûúÂøÖË¶ÅÂ∞±ËøòÂæóÂÅöone-hot encoding„ÄÇ\u003cimg alt=\"image-20250322150620890\" loading=\"lazy\" src=\"./NLP-2.assets/image-20250322150620890.png\"\u003e\u003c/p\u003e\n\u003cp\u003eÁªìÊûú\u003c/p\u003e\n\u003cp\u003e\u003cimg alt=\"image-20250322150754528\" loading=\"lazy\" src=\"./NLP-2.assets/image-20250322150754528.png\"\u003e\u003c/p\u003e\n\u003cp\u003e‰ΩÜÊòØÈïøÂ∫¶‰∏çÁªü‰∏Ä\u003c/p\u003e\n\u003cp\u003eStep4: ÂØπÈΩêsequence\u003c/p\u003e\n\u003cp\u003e\u003cimg alt=\"image-20250322150854986\" loading=\"lazy\" src=\"./NLP-2.assets/image-20250322150854986.png\"\u003e\u003c/p\u003e\n\u003cp\u003eËß£ÂÜ≥ÊñπÊ°àÊòØËøôÊ†∑ÁöÑÔºöÂèØ‰ª•Âõ∫ÂÆöÈïøÂ∫¶‰∏∫wÔºåÂä†ÂÖ•‰∏Ä‰∏™Â∫èÂàóÈïøÂ∫¶Â§™ÈïøÔºåÂ∞±Á†çÊéâÂâçÈù¢ÁöÑËØçÔºåÂè™‰øùÁïôÊúÄÂêéw‰∏™ËØçÔºõÂ¶ÇÊûú‰∏Ä‰∏™Â∫èÂàóÂ§™Áü≠ÔºåÂ∞±ÂÅözero paddingÔºåÁî®0Â°´ÂÖÖ\u003c/p\u003e\n\u003cp\u003e\u003cimg alt=\"image-20250322151030119\" loading=\"lazy\" src=\"./NLP-2.assets/image-20250322151030119.png\"\u003e\u003c/p\u003e\n\u003cp\u003eËøôÊ†∑‰∏ÄÊù•ÔºåÊâÄÊúâÁöÑÂ∫èÂàóÈïøÂ∫¶Â∞±Áªü‰∏Ä‰∫Ü\u003c/p\u003e\n\u003cp\u003e\u003cimg alt=\"image-20250322151117125\" loading=\"lazy\" src=\"./NLP-2.assets/image-20250322151117125.png\"\u003e\u003c/p\u003e\n\u003cp\u003eÊñáÊú¨Â§ÑÁêÜÂÆåÊàê‰∫ÜÔºåÊé•‰∏ãÊù•ÊòØword embeddingÔºåÊääÂçïËØçË°®Á§∫‰∏∫‰∏Ä‰∏™‰ΩéÁª¥ÂêëÈáèÔºõ\u003c/p\u003e\n\u003cp\u003e\u003cimg alt=\"image-20250322151252837\" loading=\"lazy\" src=\"./NLP-2.assets/image-20250322151252837.png\"\u003e\u003c/p\u003e","title":""},{"content":"üëã About me Hello! I\u0026rsquo;m Xu Zongsi, a passionate technology enthusiast currently pursuing my Master of Science in ECIC at The University of Hong Kong. With a solid background in Software Engineering from the Beijing Institute of Technology, I specialize in artificial intelligence areas like machine learning, deep learning, natural language processing, computer vision, and reinforcement learning.\nInspired by OpenAI\u0026rsquo;s five-step plan towards superintelligence, I am excited about AGI and have developed a keen interest in LLM agents, MLLM, and knowledge graphs. I see great potential in these fields and aspire to contribute to innovative solutions.\nüìö Education üá≠üá∞ The University of Hong Kong 09/2024 - Expected 11/2025 School of Computing and Data Science Master of Science in Electronic Commerce \u0026amp; Internet Computing Relevant Courses: Machine learning for business and e-commerce, Knowledge graphs, Financial fraud analytics, Internet infrastructure technologies, Website engineering, Blockchain and cryptocurrency, etc. üá®üá≥ Beijing Institute of Technology 09/2020 - 06/2024 School of Computer Science \u0026amp; Technology Bachelor of Engineering in Software Engineering, last two years GPA: 3.7/4 Relevant Courses: Reinforcement Learning, Deep Learning and Computer Vision, Artificial Intelligence and Robot Ethics, Almost Human: Mind, Brain and Artificial Intelligence, Mathematical Analysis for Engineering, Linear Algebra, Probability and Mathematical Statistics, etc. Skills: Python, Java, common data structures, design patterns, machine learning basics and algorithms, Linux, PyTorch, and some development tools (git, conda, etc.). üèÜ Awards \u0026amp; Honors Beijing Institute of Technology Undergraduate Scholarship (Top 20% of Grade) 06/2023 3rd Prize of China International \u0026#34;Internet \u0026#43;\u0026#34; College Student\u0026#39;s Innovation Competition 08/2022 Bronze Prize of \u0026#34;Challenge Cup\u0026#34; Capital University Entrepreneurship Competition 05/2022 üíº Project Experience üîç Online Transaction Fraud Detection 09/2024 ‚Äì 01/2025 Independent project, supervised by Dr. Vivien Chan Focused on addressing financial fraud in e-commerce to enhance the accuracy of transaction anomaly detection, while independently managing the entire case study that included data preprocessing, feature engineering, model building, evaluation, and results analysis. Effectively resolved class imbalance issues using SMOTE and ROSE techniques. Built various models including Logistic Regression, Random Forest, XGBoost, and LightGBM, ultimately selecting the LightGBM model to achieve a recall rate of 95.45% and an AUC of 99.84%. Wrote efficient and maintainable code, enhancing model training and data processing efficiency through parallel computing and logging. ü§ñ Multi-Model Intelligent Text Keyword Extraction System 08/2023 ‚Äì 09/2023 Group project, supervised by Associate Prof. Xiaolin Zhao Designed and implemented an intelligent text summary system that automatically extracts keywords from article titles and abstracts, enhancing the understanding and summarization of text information. Participated in the planning of the technical route and built a hybrid model combining extractive and generative approaches, utilizing advanced natural language processing techniques including KeyBERT, Sentence Transformer, BERT, and T5 models. Responsible for data preprocessing and tokenization, as well as the end-to-end implementation and training of the T5 model, optimizing the model architecture and hyperparameters, achieving satisfactory results after only 3 epochs of training. Model evaluation results showed that the Rouge-1, Rouge-2, and Rouge-L metrics reached 0.6345, 0.5038, and 0.5282, respectively, in the third epoch, validating the model\u0026rsquo;s effectiveness in the summarization task. üéì Cambridge University Machine Learning Summer Project 07/2023 ‚Äì 08/2023 Group project, supervised by Prof. Pietro Li√≤ Participated in the Cambridge University deep learning summer project, focusing on deep reinforcement learning; explored multi-agent learning algorithms across different environments. Reproduced the Multi-Agent Deep Deterministic Policy Gradient (MADDPG) algorithm in the Simple Adversary environment and studied the effect of agent numbers on convergence speed and stability, finding optimal stability at 21 agents. Designed and implemented comparative experiments inspired by the Rainbow algorithm, assessing target network strategies versus the Double Deep Q-Network (Double DQN). The results demonstrated that Double DQN significantly enhanced convergence speed, optimizing the overall learning process. Co-authored a group project paper on agent numbers and strategies effectiveness in multi-agent systems, achieving a score of 71% in the summer program (the highest in my group) and a \u0026ldquo;First Class\u0026rdquo; classification in the UK grading system. üëÅÔ∏è Deep Learning and Computer Vision Semester Project 09/2022 ‚Äì 12/2022 Independent project, supervised by Associate Prof. Guangyu Gao Designed and implemented a waste classifier using the ResNet model to improve classification accuracy and reduce resource waste. The project also enhanced understanding of transfer learning techniques with ResNet. Collected a dataset of 16 waste categories and preprocessed the images for uniformity and standardization, incorporating data augmentation techniques to enhance the dataset. Conducted experiments using ResNet34 and ResNet50 models through transfer learning, accelerating network convergence by leveraging pretrained weights. During training, techniques such as Batch Normalization and Dropout were applied to mitigate the risk of overfitting. The final model achieved an accuracy of 90% on the training set, while the performance on the test set was 61%, indicating a significant overfitting phenomenon during the training process. üéì Internship ‚öõÔ∏è Beijing Academy of Quantum Information Science 08/2023 ‚Äì 01/2024 Research Intern at Quantum Computation Department Proposed a quantum convolution kernel design based on variational quantum circuits and developed a universal quantum convolution layer, successfully integrating it into classical CNN architectures such as VGG, GoogLeNet, and ResNet. Developed and evaluated various hybrid models, including a simple model named HQCCNN-2, which achieved 84.45% accuracy on the FashionMNIST dataset, surpassing the traditional CNN\u0026rsquo;s 80.72%. This demonstrates the effectiveness of the quantum convolution layer in improving model performance. Tested on a real quantum computer further validated the effectiveness of the hybrid model, demonstrating the viable integration of quantum computing with deep learning, and highlighting the potential for leveraging quantum properties to enhance model performance. üèÖ Competition Experience ü•â China International \u0026#34;Internet \u0026#43;\u0026#34; College Students\u0026#39; Innovation Competition 08/2022 üõ°Ô∏è Zhongke Ushield: Deep Learning-based Face Privacy Protection Authentication System Responsible for constructing a localized facial feature extraction engine based on MobileFaceNet, ensuring feature extraction is completed on end devices (such as mobile phones and cameras), guaranteeing that raw data does not leave the domain and is not stored, thus enhancing user privacy protection while improving recognition efficiency. ü•â \u0026#34;Challenge Cup\u0026#34; Capital University Entrepreneurship Competition 05/2022 üå≥ Smart Orchard Responsible for the development of the fruit detection, ripeness prediction, and pest identification system, using deep convolutional neural network (CNN) technology for intelligent monitoring of crop growth conditions. Applied advanced object detection algorithms such as Faster R-CNN and YOLO to achieve high precision in apple detection and ripeness assessment, with an accuracy rate exceeding 90%, significantly enhancing the intelligence level of orchard management. Built and trained a dedicated dataset containing various pest samples, optimizing pest detection accuracy through data preprocessing (such as image normalization and resizing) and data augmentation techniques (like rotation, flipping, and noise addition), enabling the real-time monitoring system to accurately identify over 80% of pests, providing effective scientific maintenance recommendations to help farmers reduce crop losses. üìã Extracurricular Activities Vice President, Cyber Security Club, Beijing Institute of Technology 09/2021-09/2022 Backbone, Media Center of the Student Union of Beijing Institute of Technology 10/2020-06/2021 üì´ Contact üìß Email: zongsi.xu@outlook.com üëî LinkedIn: Zongsi (Tristan) Xu üíª GitHub: BaizeXS üìç Location: Hong Kong SAR, China ","permalink":"http://localhost:1313/resume/","summary":"Personal resume of Zongsi (Tristan) Xu","title":"Zongsi (Tristan) Xu"},{"content":"‰∏Ä„ÄÅÊï∞ÂÄºÁâπÂæÅ‰∏éÁ±ªÂà´ÁâπÂæÅ Êï∞ÂÄºÁâπÂæÅ (Numeric Features) ÂÖ∑ÊúâÂèØÂä†ÂáèÁöÑÊÑè‰πâÔºå‰∏îÂ≠òÂú®Â§ßÂ∞èÈ°∫Â∫è„ÄÇ ‰æãÂ≠êÔºöÂπ¥ÈæÑ„ÄÅÊ∏©Â∫¶Á≠â„ÄÇÂèØ‰ª•Áõ¥Êé•‰øùÁïôÂÖ∂Êï¥Êï∞ÊàñÊµÆÁÇπÊï∞ÂΩ¢Âºè‰æõÊ®°Âûã‰ΩøÁî®„ÄÇ Á±ªÂà´ÁâπÂæÅ (Categorical Features) Êï∞ÊçÆÂÄºÁ¶ªÊï£Ôºå‰∏çÂÖ∑Â§á‚ÄúÊï∞ÂÄºÂ§ßÂ∞è‚ÄùÈó¥ÁöÑÂèØÊØîÊÑè‰πâ„ÄÇ ‰æãÂ≠êÔºöÂõΩÁ±çÔºàÁæéÂõΩ/‰∏≠ÂõΩ/Âç∞Â∫¶Á≠âÔºâ„ÄÅÊÄßÂà´ÔºàÁî∑/Â•≥ÔºâÁ≠â„ÄÇ ÈóÆÈ¢òÔºöËã•‰ªÖÁî®Êï¥Êï∞Ë°®Á§∫ÔºàÁæéÂõΩ=1, ‰∏≠ÂõΩ=2ÔºâÔºå‰ºöÂºïÂÖ•ÈîôËØØÁöÑÊï∞ÂÄºËøêÁÆóÂÖ≥Á≥ªÔºåÂ¶Ç ‚ÄúÁæéÂõΩ + ‰∏≠ÂõΩ = Âç∞Â∫¶‚Äù„ÄÇ ‰∫å„ÄÅOne-HotÁºñÁ†ÅÁöÑÂä®Êú∫‰∏éÊµÅÁ®ã ‰∏∫‰ªÄ‰πà‰ΩøÁî®One-Hot\nÈÄöËøáÂ∞ÜÁ±ªÂà´Êò†Â∞Ñ‰∏∫ÂêëÈáèÔºåÈÅøÂÖçÊï¥Êï∞ÁºñÁ†ÅÂºïÂÖ•ÁöÑ‰º™Êï∞ÂÄºÂÖ≥Á≥ª„ÄÇ ÂêåÊó∂‰øùÁïôÂêÑÁßçÂèØËÉΩÁ±ªÂà´ÁöÑ‰ø°ÊÅØÔºå‰∏î‰ªÖÂú®ÂØπÂ∫î‰ΩçÁΩÆ‰∏∫1ÔºåÂÖ∂‰ªñ‰ΩçÁΩÆ‰∏∫0„ÄÇ Âª∫Á´ãÊò†Â∞ÑÔºö‰ªéÁ±ªÂà´Âà∞Á¥¢Âºï\n‰∏∫ÊØè‰∏™Á±ªÂà´ÂàÜÈÖç‰∏Ä‰∏™ÂîØ‰∏ÄÁ¥¢ÂºïÔºåÈÄöÂ∏∏‰ªé1ÂºÄÂßã„ÄÇ È¢ÑÁïôÁ¥¢Âºï0Ë°®Á§∫‚ÄúÊú™Áü•‚ÄùÊàñ‚ÄúÁº∫Â§±‚ÄùÔºåÂØπÂ∫îÂÖ®0ÂêëÈáè„ÄÇ ËΩ¨Êç¢‰∏∫One-HotÂêëÈáè\nËã•Á±ªÂà´ÊÄªÊï∞‰∏∫197ÔºåÂàôÁî®197Áª¥ÂêëÈáèË°®Á§∫„ÄÇ ‰æãÂ≠êÔºöÁæéÂõΩ [1, 0, 0, 0, ‚Ä¶]Ôºå ‰∏≠ÂõΩ [0, 1, 0, 0, ‚Ä¶]„ÄÇ Á§∫‰æãÔºöË°®Á§∫‰∏Ä‰∏™‰∫∫ÁöÑÁâπÂæÅ\nÁâπÂæÅÂåÖÂê´ÔºàÂπ¥ÈæÑ, ÊÄßÂà´, ÂõΩÁ±çÔºåÂÖ∂‰∏≠ÂõΩÁ±ç197ÁßçÔºâ Áª¥Â∫¶ÊÄªÂíåÔºö1Áª¥_age + 1Áª¥_gender + 197Áª¥_nationality = 199Áª¥„ÄÇ ‰æãÂ¶Ç (28, Â•≥, ‰∏≠ÂõΩ) ‚Üí [28, 0, 0, 1, 0, ‚Ä¶, 0]„ÄÇ ‰∏â„ÄÅÊñáÊú¨Êï∞ÊçÆÂ§ÑÁêÜÊµÅÁ®ã ÊñáÊú¨Âú®Ëá™ÁÑ∂ËØ≠Ë®ÄÂ§ÑÁêÜÔºàNLPÔºâ‰∏≠‰Ωú‰∏∫Â∏∏ËßÅÁöÑÂéüÂßãËæìÂÖ•ÔºåÈúÄË¶ÅÊï∞ÂÄºÂåñÊâçËÉΩÈÄÅÂÖ•Ê®°Âûã„ÄÇ‰∏ÄËà¨Ê≠•È™§Â¶Ç‰∏ãÔºö\nÂàÜËØç (Tokenization)\nÂ∞ÜÊñáÊú¨ÊãÜÂàÜ‰∏∫‰∏Ä‰∏™‰∏™ÂçïËØçÔºàTokenÔºâ„ÄÇ ‰æãÂ≠êÔºö\u0026quot;... to be or not to be...\u0026quot; ‚Üí [\u0026quot;...\u0026quot;, \u0026quot;to\u0026quot;, \u0026quot;be\u0026quot;, \u0026quot;or\u0026quot;, \u0026quot;not\u0026quot;, \u0026quot;to\u0026quot;, \u0026quot;be\u0026quot;, \u0026quot;...\u0026quot;]„ÄÇ ÁªüËÆ°ËØçÈ¢ë \u0026amp; ÊûÑÂª∫ËØçÂÖ∏\nËØçÈ¢ëÁªüËÆ° Áî®ÂìàÂ∏åË°®/Â≠óÂÖ∏ËÆ∞ÂΩïÊØè‰∏™ÂçïËØçÂá∫Áé∞Ê¨°Êï∞„ÄÇ ÈÅçÂéÜÊñáÊú¨Êó∂ÔºåËã•ÂçïËØçÂ∞öÊú™ÂÖ•Ë°®ÔºåÂàôÊñ∞Âª∫ËÆ∞ÂΩïÔºõËã•Â∑≤Â≠òÂú®ÔºåÂàôËÆ°Êï∞+1„ÄÇ ÊéíÂ∫è‰∏éÁ¥¢Âºï ÊåâËØçÈ¢ëÈôçÂ∫èÊéíÂ∫èÔºåËØçÈ¢ëÊúÄÈ´òÁöÑÂçïËØçÊéíÂú®ÂâçÈù¢„ÄÇ Á¥¢Âºï‰ªé1ÂºÄÂßãÔºå0ÁïôÁªô‚ÄúÊú™Áü•‚Äù„ÄÇ ËØçÂÖ∏ËßÑÊ®°ÔºàvocabularyÔºâÂèØËßÜÈúÄÊ±ÇÊà™Êñ≠Ôºà‰æãÂ¶ÇÂè™‰øùÁïôTop 10kÔºâ„ÄÇ ‰∏∫‰ªÄ‰πàÁßªÈô§‰ΩéÈ¢ëËØç ‰ΩéÈ¢ëËØçÂèØËÉΩÊòØÊãºÂÜôÈîôËØØ„ÄÅÁΩïËßÅ‰∫∫ÂêçÁ≠âÔºåÂØπÊ®°ÂûãÂ∏ÆÂä©ÊúâÈôê„ÄÇ ÂáèÂ∞ëËØçÂÖ∏ËßÑÊ®°ÂèØÈôç‰ΩéËøêÁÆóÂºÄÈîÄ„ÄÅÂä†Âø´Ê®°ÂûãËÆ≠ÁªÉ‰∏éÊé®ÁêÜÈÄüÂ∫¶„ÄÇ Áã¨ÁÉ≠ÁºñÁ†Å (One-Hot Encoding)\nÂ∞ÜÊØè‰∏™ÂçïËØçÊò†Â∞Ñ‰∏∫ËØçÂÖ∏‰∏≠ÁöÑÁ¥¢ÂºïÂêéÔºàÂ¶Ç [2, 4, 1, 8, ‚Ä¶]ÔºâÔºåÂèØËøõ‰∏ÄÊ≠•ËΩ¨Êç¢ÊàêOne-HotÂêëÈáè„ÄÇ One-HotÁª¥Â∫¶ÂèñÂÜ≥‰∫é‰øùÁïô‰∏ãÊù•ÁöÑËØçÂÖ∏Â§ßÂ∞èÔºà‰æãÂ¶Ç1‰∏áÔºâ„ÄÇ Êú™Êî∂ÂΩïÂçïËØçÂèØËÉΩÁõ¥Êé•ÂøΩÁï•ÔºåÊàñÁªü‰∏ÄÁî®Á¥¢Âºï0‰ª£Êõø„ÄÇ Âõõ„ÄÅÊ†∏ÂøÉÊî∂Ëé∑‰∏éÂ∫îÁî® Á±ªÂà´ÁâπÂæÅÂøÖÈúÄÊï∞ÂÄºÂåñÔºö\n‰ΩøÁî®Êï¥Êï∞1,2,3‚Ä¶‰ªÖË°®Á§∫Á±ªÂà´‚ÄúÊ†áËØÜ‚ÄùÔºåÂπ∂‰∏ç‰ª£Ë°®ÂÆÉ‰ª¨ÂèØËøõË°åÊï∞ÂÄºËøêÁÆó„ÄÇ Âõ†Ê≠§ÈúÄË¶ÅOne-HotÁ≠âÁºñÁ†ÅÊñπÂºèÔºåÈÅøÂÖçÊï∞ÂÄºËØØËß£„ÄÇ ÊñáÊú¨Êï∞ÊçÆÈ¢ÑÂ§ÑÁêÜÔºö\nÂàÜËØç„ÄÅËØçÈ¢ëÁªüËÆ°„ÄÅÊûÑÂª∫ËØçÂÖ∏„ÄÅÁ¥¢ÂºïÂåñ„ÄÅOne-HotÊàñÂÖ∂‰ªñÊñπÂºèÔºàÂ¶ÇËØçÂµåÂÖ•ÔºâÊòØÂ∏∏ËßÅÊµÅÁ®ã„ÄÇ Ê≠£Á°ÆÁöÑÊñáÊú¨È¢ÑÂ§ÑÁêÜÂèØÊòæËëóÂΩ±ÂìçÊ®°ÂûãÊÄßËÉΩÂíåÊïàÁéá„ÄÇ ‰øùÁïôÊú™Áü•Á¥¢ÂºïÔºö\n‰øùËØÅÂØπÁº∫Â§±Êï∞ÊçÆÊàñÂ≠óÂÖ∏Â§ñÊñ∞ËØçËÉΩÊúâÂü∫Êú¨ÁöÑË°®Á§∫ÔºåÊèêÂçáÊ®°ÂûãÂÆπÈîôÊÄß„ÄÇ ÂÆûÈôÖ‰ΩøÁî®Ôºö\nÂØπ‰∫éÂ∞èËßÑÊ®°Á±ªÂà´ÂèØÁõ¥Êé•One-HotÁºñÁ†ÅÔºõÂØπ‰∫éËØçÂÖ∏ÂæàÂ§ßÁöÑÂú∫ÊôØÔºåÈÄöÂ∏∏‰ºöËøõ‰∏ÄÊ≠•ËÄÉËôëËØçÂµåÂÖ•ÔºàWord EmbeddingÔºâÊàñÈ¢ÑËÆ≠ÁªÉËØ≠Ë®ÄÊ®°Âûã„ÄÇ ","permalink":"http://localhost:1313/posts/nlp-1/","summary":"\u003ch2 id=\"‰∏ÄÊï∞ÂÄºÁâπÂæÅ‰∏éÁ±ªÂà´ÁâπÂæÅ\"\u003e‰∏Ä„ÄÅÊï∞ÂÄºÁâπÂæÅ‰∏éÁ±ªÂà´ÁâπÂæÅ\u003c/h2\u003e\n\u003col\u003e\n\u003cli\u003e\u003cstrong\u003eÊï∞ÂÄºÁâπÂæÅ (Numeric Features)\u003c/strong\u003e\n\u003cul\u003e\n\u003cli\u003eÂÖ∑ÊúâÂèØÂä†ÂáèÁöÑÊÑè‰πâÔºå‰∏îÂ≠òÂú®Â§ßÂ∞èÈ°∫Â∫è„ÄÇ\u003c/li\u003e\n\u003cli\u003e‰æãÂ≠êÔºöÂπ¥ÈæÑ„ÄÅÊ∏©Â∫¶Á≠â„ÄÇÂèØ‰ª•Áõ¥Êé•‰øùÁïôÂÖ∂Êï¥Êï∞ÊàñÊµÆÁÇπÊï∞ÂΩ¢Âºè‰æõÊ®°Âûã‰ΩøÁî®„ÄÇ\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003eÁ±ªÂà´ÁâπÂæÅ (Categorical Features)\u003c/strong\u003e\n\u003cul\u003e\n\u003cli\u003eÊï∞ÊçÆÂÄºÁ¶ªÊï£Ôºå‰∏çÂÖ∑Â§á‚ÄúÊï∞ÂÄºÂ§ßÂ∞è‚ÄùÈó¥ÁöÑÂèØÊØîÊÑè‰πâ„ÄÇ\u003c/li\u003e\n\u003cli\u003e‰æãÂ≠êÔºöÂõΩÁ±çÔºàÁæéÂõΩ/‰∏≠ÂõΩ/Âç∞Â∫¶Á≠âÔºâ„ÄÅÊÄßÂà´ÔºàÁî∑/Â•≥ÔºâÁ≠â„ÄÇ\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003eÈóÆÈ¢ò\u003c/strong\u003eÔºöËã•‰ªÖÁî®Êï¥Êï∞Ë°®Á§∫ÔºàÁæéÂõΩ=1, ‰∏≠ÂõΩ=2ÔºâÔºå‰ºöÂºïÂÖ•ÈîôËØØÁöÑÊï∞ÂÄºËøêÁÆóÂÖ≥Á≥ªÔºåÂ¶Ç ‚ÄúÁæéÂõΩ + ‰∏≠ÂõΩ = Âç∞Â∫¶‚Äù„ÄÇ\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003c/ol\u003e\n\u003ch2 id=\"‰∫åone-hotÁºñÁ†ÅÁöÑÂä®Êú∫‰∏éÊµÅÁ®ã\"\u003e‰∫å„ÄÅOne-HotÁºñÁ†ÅÁöÑÂä®Êú∫‰∏éÊµÅÁ®ã\u003c/h2\u003e\n\u003col\u003e\n\u003cli\u003e\n\u003cp\u003e\u003cstrong\u003e‰∏∫‰ªÄ‰πà‰ΩøÁî®One-Hot\u003c/strong\u003e\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eÈÄöËøáÂ∞ÜÁ±ªÂà´Êò†Â∞Ñ‰∏∫ÂêëÈáèÔºåÈÅøÂÖçÊï¥Êï∞ÁºñÁ†ÅÂºïÂÖ•ÁöÑ‰º™Êï∞ÂÄºÂÖ≥Á≥ª„ÄÇ\u003c/li\u003e\n\u003cli\u003eÂêåÊó∂‰øùÁïôÂêÑÁßçÂèØËÉΩÁ±ªÂà´ÁöÑ‰ø°ÊÅØÔºå‰∏î‰ªÖÂú®ÂØπÂ∫î‰ΩçÁΩÆ‰∏∫1ÔºåÂÖ∂‰ªñ‰ΩçÁΩÆ‰∏∫0„ÄÇ\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003e\u003cstrong\u003eÂª∫Á´ãÊò†Â∞ÑÔºö‰ªéÁ±ªÂà´Âà∞Á¥¢Âºï\u003c/strong\u003e\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e‰∏∫ÊØè‰∏™Á±ªÂà´ÂàÜÈÖç‰∏Ä‰∏™ÂîØ‰∏ÄÁ¥¢ÂºïÔºåÈÄöÂ∏∏‰ªé1ÂºÄÂßã„ÄÇ\u003c/li\u003e\n\u003cli\u003eÈ¢ÑÁïôÁ¥¢Âºï0Ë°®Á§∫‚ÄúÊú™Áü•‚ÄùÊàñ‚ÄúÁº∫Â§±‚ÄùÔºåÂØπÂ∫îÂÖ®0ÂêëÈáè„ÄÇ\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003e\u003cstrong\u003eËΩ¨Êç¢‰∏∫One-HotÂêëÈáè\u003c/strong\u003e\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eËã•Á±ªÂà´ÊÄªÊï∞‰∏∫197ÔºåÂàôÁî®197Áª¥ÂêëÈáèË°®Á§∫„ÄÇ\u003c/li\u003e\n\u003cli\u003e‰æãÂ≠êÔºöÁæéÂõΩ \u003ccode\u003e[1, 0, 0, 0, ‚Ä¶]\u003c/code\u003eÔºå ‰∏≠ÂõΩ \u003ccode\u003e[0, 1, 0, 0, ‚Ä¶]\u003c/code\u003e„ÄÇ\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003e\u003cstrong\u003eÁ§∫‰æãÔºöË°®Á§∫‰∏Ä‰∏™‰∫∫ÁöÑÁâπÂæÅ\u003c/strong\u003e\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eÁâπÂæÅÂåÖÂê´ÔºàÂπ¥ÈæÑ, ÊÄßÂà´, ÂõΩÁ±çÔºåÂÖ∂‰∏≠ÂõΩÁ±ç197ÁßçÔºâ\u003c/li\u003e\n\u003cli\u003eÁª¥Â∫¶ÊÄªÂíåÔºö1Áª¥_age + 1Áª¥_gender + 197Áª¥_nationality = 199Áª¥„ÄÇ\u003c/li\u003e\n\u003cli\u003e‰æãÂ¶Ç \u003ccode\u003e(28, Â•≥, ‰∏≠ÂõΩ)\u003c/code\u003e ‚Üí \u003ccode\u003e[28, 0, 0, 1, 0, ‚Ä¶, 0]\u003c/code\u003e„ÄÇ\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003c/ol\u003e\n\u003ch2 id=\"‰∏âÊñáÊú¨Êï∞ÊçÆÂ§ÑÁêÜÊµÅÁ®ã\"\u003e‰∏â„ÄÅÊñáÊú¨Êï∞ÊçÆÂ§ÑÁêÜÊµÅÁ®ã\u003c/h2\u003e\n\u003cp\u003eÊñáÊú¨Âú®Ëá™ÁÑ∂ËØ≠Ë®ÄÂ§ÑÁêÜÔºàNLPÔºâ‰∏≠‰Ωú‰∏∫Â∏∏ËßÅÁöÑÂéüÂßãËæìÂÖ•ÔºåÈúÄË¶ÅÊï∞ÂÄºÂåñÊâçËÉΩÈÄÅÂÖ•Ê®°Âûã„ÄÇ‰∏ÄËà¨Ê≠•È™§Â¶Ç‰∏ãÔºö\u003c/p\u003e\n\u003col\u003e\n\u003cli\u003e\n\u003cp\u003e\u003cstrong\u003eÂàÜËØç (Tokenization)\u003c/strong\u003e\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eÂ∞ÜÊñáÊú¨ÊãÜÂàÜ‰∏∫‰∏Ä‰∏™‰∏™ÂçïËØçÔºàTokenÔºâ„ÄÇ\u003c/li\u003e\n\u003cli\u003e‰æãÂ≠êÔºö\u003ccode\u003e\u0026quot;... to be or not to be...\u0026quot;\u003c/code\u003e ‚Üí \u003ccode\u003e[\u0026quot;...\u0026quot;, \u0026quot;to\u0026quot;, \u0026quot;be\u0026quot;, \u0026quot;or\u0026quot;, \u0026quot;not\u0026quot;, \u0026quot;to\u0026quot;, \u0026quot;be\u0026quot;, \u0026quot;...\u0026quot;]\u003c/code\u003e„ÄÇ\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003e\u003cstrong\u003eÁªüËÆ°ËØçÈ¢ë \u0026amp; ÊûÑÂª∫ËØçÂÖ∏\u003c/strong\u003e\u003c/p\u003e","title":""},{"content":"Text to Sequence ÊñáÊú¨Â§ÑÁêÜ\nStep1: Tokenization\nTokenization breaks a piece of text down into a list of tokens.\nHere, a token is a word. (A token can be a character in some applications.)\nTokenizationËÆ≤Á©∂ÂæàÂ§öÔºå‰æãÂ¶ÇÊòØÂê¶Â∫îËØ•ÊääÂ§ßÂÜôÊîπÊàêÂ∞èÂÜôÂë¢ÔºüËøõË°åtypo correctionÁ≠âÁ≠â\nStep2: Build Dictionary\nUse a dictionary (hash table) to count word frequencies.\nThe dictionary maps word to index.\nÂèØ‰ª•È¶ñÂÖàÁªüËÆ°ËØçÈ¢ëÂéªÊéâ‰ΩéÈ¢ëËØçÔºåÁÑ∂ÂêéËÆ©ÊØè‰∏™ËØçÂØπÂ∫î‰∏Ä‰∏™Ê≠£Êï¥Êï∞ÔºõËøôÊ†∑ÁöÑËØùÔºå‰∏ÄÂè•ËØùÂ∞±ÂèØ‰ª•Áî®‰∏Ä‰∏™Ê≠£Êï¥Êï∞ÂàóË°®Ë°®Á§∫ÔºåËøô‰∏™ÂàóË°®Â∞±Âè´sequenceÔºõÂ¶ÇÊûúÂøÖË¶ÅÂ∞±ËøòÂæóÂÅöone-hot encoding„ÄÇ\nÁªìÊûú\n‰ΩÜÊòØÈïøÂ∫¶‰∏çÁªü‰∏Ä\nStep4: ÂØπÈΩêsequence\nËß£ÂÜ≥ÊñπÊ°àÊòØËøôÊ†∑ÁöÑÔºöÂèØ‰ª•Âõ∫ÂÆöÈïøÂ∫¶‰∏∫wÔºåÂä†ÂÖ•‰∏Ä‰∏™Â∫èÂàóÈïøÂ∫¶Â§™ÈïøÔºåÂ∞±Á†çÊéâÂâçÈù¢ÁöÑËØçÔºåÂè™‰øùÁïôÊúÄÂêéw‰∏™ËØçÔºõÂ¶ÇÊûú‰∏Ä‰∏™Â∫èÂàóÂ§™Áü≠ÔºåÂ∞±ÂÅözero paddingÔºåÁî®0Â°´ÂÖÖ\nËøôÊ†∑‰∏ÄÊù•ÔºåÊâÄÊúâÁöÑÂ∫èÂàóÈïøÂ∫¶Â∞±Áªü‰∏Ä‰∫Ü\nÊñáÊú¨Â§ÑÁêÜÂÆåÊàê‰∫ÜÔºåÊé•‰∏ãÊù•ÊòØword embeddingÔºåÊääÂçïËØçË°®Á§∫‰∏∫‰∏Ä‰∏™‰ΩéÁª¥ÂêëÈáèÔºõ\nÁÑ∂ËÄåËøôÊ†∑ÂÅöÁöÑËØùÔºåÂ¶ÇÊûúÊòØ10000‰∏™ÂçïËØçÔºåÁª¥Â∫¶Â∞±ÊòØ10000Áª¥ÔºåÁª¥Â∫¶Â§™È´ò‰∫ÜÔºõÂõ†Ê≠§Ë¶ÅÂÅöword embeddingÔºõ\nÂÖ∑‰ΩìÂÅöÊ≥ïÂ∞±ÊòØÊääone-hotÂêëÈáèe_iÂíåÂèÇÊï∞Áü©ÈòµpÁõ∏‰πòÔºõÁü©ÈòµPËΩ¨ÁΩÆÁöÑÂ§ßÂ∞èÊòØd x vÔºõdÊòØËØçÂêëÈáèÁöÑÁª¥Â∫¶ÔºõvÊòØÂ≠óÂÖ∏ÈáåËØçÊ±áÁöÑÊï∞ÈáèÔºõÁªìÊûú‰∏∫x_iÔºõx_iÂ∞±ÊòØ‰∏Ä‰∏™ËØçÂêëÈáèÔºõÂ¶ÇÊûúone-hotÂêëÈáèÁöÑÁ¨¨‰∏âË°å‰∏∫1ÔºõÈÇ£‰πàx_iÂ∞±ÊòØPËΩ¨ÁΩÆÁü©ÈòµÁöÑÁ¨¨‰∏âÂàóÔºàÂÖ∂‰ΩôÂàóÈÉΩ‰∏∫0ÔºâÔºõÊâÄ‰ª•PËΩ¨ÁΩÆÊØè‰∏ÄÂàóÈÉΩÊòØ‰∏Ä‰∏™ËØçÂêëÈáèÔºõÊâÄ‰ª•Áü©ÈòµPÊú¨Ë∫´ÁöÑÊØè‰∏ÄË°åÂ∞±ÊòØ‰∏Ä‰∏™ËØçÂêëÈáèÔºõÂÖ∂Ë°åÊï∞‰∏∫vÔºõÂç≥vocabularyÔºåËØçÊ±áÈáèÔºõÊØè‰∏ÄË°åÂØπÂ∫î‰∏Ä‰∏™ÂçïËØçÔºõÁü©ÈòµÁöÑÂàóÊï∞‰∏∫dÔºõdÊòØÁî®Êà∑ÂÜ≥ÂÆöÁöÑÔºõdÁöÑÂ§ßÂ∞è‰ºöÂÜ≥ÂÆöÊú∫Âô®Â≠¶‰π†Ê®°ÂûãÁöÑË°®Áé∞ÔºõÂ∫îËØ•Áî®xxxÊù•ÈÄâÊã©‰∏Ä‰∏™ÊØîËæÉÂ•ΩÁöÑdÔºõ\nÊàë‰ª¨ÁöÑ‰ªªÂä°ÊòØÁúãËØÑËÆ∫ÊòØÊ≠£Èù¢ÁöÑËøòÊòØË¥üÈù¢ÁöÑÔºõÂèÇÊï∞Áü©ÈòµÊòØ‰ªéËÆ≠ÁªÉÊï∞ÊçÆ‰∏≠Â≠¶‰π†Âá∫Êù•ÁöÑÔºåÊâÄ‰ª•Â≠¶Âá∫Êù•ÁöÑËØçÂêëÈáèÊòØÂ∏¶ÊúâÊÑüÊÉÖËâ≤ÂΩ©ÁöÑÔºõÂÅáËÆæËøô‰∫õËØçÂêëÈáèÈÉΩÊòØ‰∫åÁª¥ÁöÑÔºåÂàôÂèØ‰ª•Âú®Âπ≥Èù¢ÂùêÊ†áÁ≥ª‰∏≠Ê†áÂá∫‰∏ãÈù¢ËØçÂêëÈáè\nkerasÊèê‰æõembeddingÂ±ÇÔºõÁî®Êà∑ÂèØ‰ª•ÊåáÂÆövocabularyÂ§ßÂ∞èÂíådÁöÑÂ§ßÂ∞èÔºõ‰ª•ÂèäÊØè‰∏Ä‰∏™sequenceÁöÑÈïøÂ∫¶ÔºõdÊòØÊ†πÊçÆÁÆóÊ≥ïÈÄâÂá∫Êù•ÁöÑ Âà∞Ëøô‰∏ÄÊ≠•ÔºåÊàë‰ª¨Â∑≤ÁªèÂÆåÊàê‰∫ÜÊñáÊú¨Â§ÑÁêÜÂíåword embedding„ÄÇÊé•‰∏ãÊù•Â∞±ÊòØÁî®Logistic Regression for Binary ClassificationÂÅö‰∫åÂàÜÁ±ªÔºõ\n","permalink":"http://localhost:1313/posts/nlp-2/","summary":"\u003ch3 id=\"text-to-sequence\"\u003eText to Sequence\u003c/h3\u003e\n\u003cp\u003eÊñáÊú¨Â§ÑÁêÜ\u003c/p\u003e\n\u003cp\u003eStep1: Tokenization\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\n\u003cp\u003eTokenization breaks a piece of text down into a list of tokens.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003eHere, a token is a word. (A token can be a character in some applications.)\u003c/p\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003eTokenizationËÆ≤Á©∂ÂæàÂ§öÔºå‰æãÂ¶ÇÊòØÂê¶Â∫îËØ•ÊääÂ§ßÂÜôÊîπÊàêÂ∞èÂÜôÂë¢ÔºüËøõË°åtypo correctionÁ≠âÁ≠â\u003c/p\u003e\n\u003cp\u003e\u003cimg alt=\"image-20250322150322238\" loading=\"lazy\" src=\"./NLP-2.assets/image-20250322150322238.png\"\u003e\u003c/p\u003e\n\u003cp\u003eStep2: Build Dictionary\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\n\u003cp\u003eUse a dictionary (hash table) to count word frequencies.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003eThe dictionary maps word to index.\u003c/p\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003eÂèØ‰ª•È¶ñÂÖàÁªüËÆ°ËØçÈ¢ëÂéªÊéâ‰ΩéÈ¢ëËØçÔºåÁÑ∂ÂêéËÆ©ÊØè‰∏™ËØçÂØπÂ∫î‰∏Ä‰∏™Ê≠£Êï¥Êï∞ÔºõËøôÊ†∑ÁöÑËØùÔºå‰∏ÄÂè•ËØùÂ∞±ÂèØ‰ª•Áî®‰∏Ä‰∏™Ê≠£Êï¥Êï∞ÂàóË°®Ë°®Á§∫ÔºåËøô‰∏™ÂàóË°®Â∞±Âè´sequenceÔºõÂ¶ÇÊûúÂøÖË¶ÅÂ∞±ËøòÂæóÂÅöone-hot encoding„ÄÇ\u003cimg alt=\"image-20250322150620890\" loading=\"lazy\" src=\"./NLP-2.assets/image-20250322150620890.png\"\u003e\u003c/p\u003e\n\u003cp\u003eÁªìÊûú\u003c/p\u003e\n\u003cp\u003e\u003cimg alt=\"image-20250322150754528\" loading=\"lazy\" src=\"./NLP-2.assets/image-20250322150754528.png\"\u003e\u003c/p\u003e\n\u003cp\u003e‰ΩÜÊòØÈïøÂ∫¶‰∏çÁªü‰∏Ä\u003c/p\u003e\n\u003cp\u003eStep4: ÂØπÈΩêsequence\u003c/p\u003e\n\u003cp\u003e\u003cimg alt=\"image-20250322150854986\" loading=\"lazy\" src=\"./NLP-2.assets/image-20250322150854986.png\"\u003e\u003c/p\u003e\n\u003cp\u003eËß£ÂÜ≥ÊñπÊ°àÊòØËøôÊ†∑ÁöÑÔºöÂèØ‰ª•Âõ∫ÂÆöÈïøÂ∫¶‰∏∫wÔºåÂä†ÂÖ•‰∏Ä‰∏™Â∫èÂàóÈïøÂ∫¶Â§™ÈïøÔºåÂ∞±Á†çÊéâÂâçÈù¢ÁöÑËØçÔºåÂè™‰øùÁïôÊúÄÂêéw‰∏™ËØçÔºõÂ¶ÇÊûú‰∏Ä‰∏™Â∫èÂàóÂ§™Áü≠ÔºåÂ∞±ÂÅözero paddingÔºåÁî®0Â°´ÂÖÖ\u003c/p\u003e\n\u003cp\u003e\u003cimg alt=\"image-20250322151030119\" loading=\"lazy\" src=\"./NLP-2.assets/image-20250322151030119.png\"\u003e\u003c/p\u003e\n\u003cp\u003eËøôÊ†∑‰∏ÄÊù•ÔºåÊâÄÊúâÁöÑÂ∫èÂàóÈïøÂ∫¶Â∞±Áªü‰∏Ä‰∫Ü\u003c/p\u003e\n\u003cp\u003e\u003cimg alt=\"image-20250322151117125\" loading=\"lazy\" src=\"./NLP-2.assets/image-20250322151117125.png\"\u003e\u003c/p\u003e\n\u003cp\u003eÊñáÊú¨Â§ÑÁêÜÂÆåÊàê‰∫ÜÔºåÊé•‰∏ãÊù•ÊòØword embeddingÔºåÊääÂçïËØçË°®Á§∫‰∏∫‰∏Ä‰∏™‰ΩéÁª¥ÂêëÈáèÔºõ\u003c/p\u003e\n\u003cp\u003e\u003cimg alt=\"image-20250322151252837\" loading=\"lazy\" src=\"./NLP-2.assets/image-20250322151252837.png\"\u003e\u003c/p\u003e","title":""},{"content":"üëã About me Hello! I\u0026rsquo;m Xu Zongsi, a passionate technology enthusiast currently pursuing my Master of Science in ECIC at The University of Hong Kong. With a solid background in Software Engineering from the Beijing Institute of Technology, I specialize in artificial intelligence areas like machine learning, deep learning, natural language processing, computer vision, and reinforcement learning.\nInspired by OpenAI\u0026rsquo;s five-step plan towards superintelligence, I am excited about AGI and have developed a keen interest in LLM agents, MLLM, and knowledge graphs. I see great potential in these fields and aspire to contribute to innovative solutions.\nüìö Education üá≠üá∞ The University of Hong Kong 09/2024 - Expected 11/2025 School of Computing and Data Science Master of Science in Electronic Commerce \u0026amp; Internet Computing Relevant Courses: Machine learning for business and e-commerce, Knowledge graphs, Financial fraud analytics, Internet infrastructure technologies, Website engineering, Blockchain and cryptocurrency, etc. üá®üá≥ Beijing Institute of Technology 09/2020 - 06/2024 School of Computer Science \u0026amp; Technology Bachelor of Engineering in Software Engineering, last two years GPA: 3.7/4 Relevant Courses: Reinforcement Learning, Deep Learning and Computer Vision, Artificial Intelligence and Robot Ethics, Almost Human: Mind, Brain and Artificial Intelligence, Mathematical Analysis for Engineering, Linear Algebra, Probability and Mathematical Statistics, etc. Skills: Python, Java, common data structures, design patterns, machine learning basics and algorithms, Linux, PyTorch, and some development tools (git, conda, etc.). üèÜ Awards \u0026amp; Honors Beijing Institute of Technology Undergraduate Scholarship (Top 20% of Grade) 06/2023 3rd Prize of China International \u0026#34;Internet \u0026#43;\u0026#34; College Student\u0026#39;s Innovation Competition 08/2022 Bronze Prize of \u0026#34;Challenge Cup\u0026#34; Capital University Entrepreneurship Competition 05/2022 üíº Project Experience üîç Online Transaction Fraud Detection 09/2024 ‚Äì 01/2025 Independent project, supervised by Dr. Vivien Chan Focused on addressing financial fraud in e-commerce to enhance the accuracy of transaction anomaly detection, while independently managing the entire case study that included data preprocessing, feature engineering, model building, evaluation, and results analysis. Effectively resolved class imbalance issues using SMOTE and ROSE techniques. Built various models including Logistic Regression, Random Forest, XGBoost, and LightGBM, ultimately selecting the LightGBM model to achieve a recall rate of 95.45% and an AUC of 99.84%. Wrote efficient and maintainable code, enhancing model training and data processing efficiency through parallel computing and logging. ü§ñ Multi-Model Intelligent Text Keyword Extraction System 08/2023 ‚Äì 09/2023 Group project, supervised by Associate Prof. Xiaolin Zhao Designed and implemented an intelligent text summary system that automatically extracts keywords from article titles and abstracts, enhancing the understanding and summarization of text information. Participated in the planning of the technical route and built a hybrid model combining extractive and generative approaches, utilizing advanced natural language processing techniques including KeyBERT, Sentence Transformer, BERT, and T5 models. Responsible for data preprocessing and tokenization, as well as the end-to-end implementation and training of the T5 model, optimizing the model architecture and hyperparameters, achieving satisfactory results after only 3 epochs of training. Model evaluation results showed that the Rouge-1, Rouge-2, and Rouge-L metrics reached 0.6345, 0.5038, and 0.5282, respectively, in the third epoch, validating the model\u0026rsquo;s effectiveness in the summarization task. üéì Cambridge University Machine Learning Summer Project 07/2023 ‚Äì 08/2023 Group project, supervised by Prof. Pietro Li√≤ Participated in the Cambridge University deep learning summer project, focusing on deep reinforcement learning; explored multi-agent learning algorithms across different environments. Reproduced the Multi-Agent Deep Deterministic Policy Gradient (MADDPG) algorithm in the Simple Adversary environment and studied the effect of agent numbers on convergence speed and stability, finding optimal stability at 21 agents. Designed and implemented comparative experiments inspired by the Rainbow algorithm, assessing target network strategies versus the Double Deep Q-Network (Double DQN). The results demonstrated that Double DQN significantly enhanced convergence speed, optimizing the overall learning process. Co-authored a group project paper on agent numbers and strategies effectiveness in multi-agent systems, achieving a score of 71% in the summer program (the highest in my group) and a \u0026ldquo;First Class\u0026rdquo; classification in the UK grading system. üëÅÔ∏è Deep Learning and Computer Vision Semester Project 09/2022 ‚Äì 12/2022 Independent project, supervised by Associate Prof. Guangyu Gao Designed and implemented a waste classifier using the ResNet model to improve classification accuracy and reduce resource waste. The project also enhanced understanding of transfer learning techniques with ResNet. Collected a dataset of 16 waste categories and preprocessed the images for uniformity and standardization, incorporating data augmentation techniques to enhance the dataset. Conducted experiments using ResNet34 and ResNet50 models through transfer learning, accelerating network convergence by leveraging pretrained weights. During training, techniques such as Batch Normalization and Dropout were applied to mitigate the risk of overfitting. The final model achieved an accuracy of 90% on the training set, while the performance on the test set was 61%, indicating a significant overfitting phenomenon during the training process. üéì Internship ‚öõÔ∏è Beijing Academy of Quantum Information Science 08/2023 ‚Äì 01/2024 Research Intern at Quantum Computation Department Proposed a quantum convolution kernel design based on variational quantum circuits and developed a universal quantum convolution layer, successfully integrating it into classical CNN architectures such as VGG, GoogLeNet, and ResNet. Developed and evaluated various hybrid models, including a simple model named HQCCNN-2, which achieved 84.45% accuracy on the FashionMNIST dataset, surpassing the traditional CNN\u0026rsquo;s 80.72%. This demonstrates the effectiveness of the quantum convolution layer in improving model performance. Tested on a real quantum computer further validated the effectiveness of the hybrid model, demonstrating the viable integration of quantum computing with deep learning, and highlighting the potential for leveraging quantum properties to enhance model performance. üèÖ Competition Experience ü•â China International \u0026#34;Internet \u0026#43;\u0026#34; College Students\u0026#39; Innovation Competition 08/2022 üõ°Ô∏è Zhongke Ushield: Deep Learning-based Face Privacy Protection Authentication System Responsible for constructing a localized facial feature extraction engine based on MobileFaceNet, ensuring feature extraction is completed on end devices (such as mobile phones and cameras), guaranteeing that raw data does not leave the domain and is not stored, thus enhancing user privacy protection while improving recognition efficiency. ü•â \u0026#34;Challenge Cup\u0026#34; Capital University Entrepreneurship Competition 05/2022 üå≥ Smart Orchard Responsible for the development of the fruit detection, ripeness prediction, and pest identification system, using deep convolutional neural network (CNN) technology for intelligent monitoring of crop growth conditions. Applied advanced object detection algorithms such as Faster R-CNN and YOLO to achieve high precision in apple detection and ripeness assessment, with an accuracy rate exceeding 90%, significantly enhancing the intelligence level of orchard management. Built and trained a dedicated dataset containing various pest samples, optimizing pest detection accuracy through data preprocessing (such as image normalization and resizing) and data augmentation techniques (like rotation, flipping, and noise addition), enabling the real-time monitoring system to accurately identify over 80% of pests, providing effective scientific maintenance recommendations to help farmers reduce crop losses. üìã Extracurricular Activities Vice President, Cyber Security Club, Beijing Institute of Technology 09/2021-09/2022 Backbone, Media Center of the Student Union of Beijing Institute of Technology 10/2020-06/2021 üì´ Contact üìß Email: zongsi.xu@outlook.com üëî LinkedIn: Zongsi (Tristan) Xu üíª GitHub: BaizeXS üìç Location: Hong Kong SAR, China ","permalink":"http://localhost:1313/resume/","summary":"Personal resume of Zongsi (Tristan) Xu","title":"Zongsi (Tristan) Xu"},{"content":"‰∏Ä„ÄÅÊï∞ÂÄºÁâπÂæÅ‰∏éÁ±ªÂà´ÁâπÂæÅ Êï∞ÂÄºÁâπÂæÅ (Numeric Features) ÂÖ∑ÊúâÂèØÂä†ÂáèÁöÑÊÑè‰πâÔºå‰∏îÂ≠òÂú®Â§ßÂ∞èÈ°∫Â∫è„ÄÇ ‰æãÂ≠êÔºöÂπ¥ÈæÑ„ÄÅÊ∏©Â∫¶Á≠â„ÄÇÂèØ‰ª•Áõ¥Êé•‰øùÁïôÂÖ∂Êï¥Êï∞ÊàñÊµÆÁÇπÊï∞ÂΩ¢Âºè‰æõÊ®°Âûã‰ΩøÁî®„ÄÇ Á±ªÂà´ÁâπÂæÅ (Categorical Features) Êï∞ÊçÆÂÄºÁ¶ªÊï£Ôºå‰∏çÂÖ∑Â§á‚ÄúÊï∞ÂÄºÂ§ßÂ∞è‚ÄùÈó¥ÁöÑÂèØÊØîÊÑè‰πâ„ÄÇ ‰æãÂ≠êÔºöÂõΩÁ±çÔºàÁæéÂõΩ/‰∏≠ÂõΩ/Âç∞Â∫¶Á≠âÔºâ„ÄÅÊÄßÂà´ÔºàÁî∑/Â•≥ÔºâÁ≠â„ÄÇ ÈóÆÈ¢òÔºöËã•‰ªÖÁî®Êï¥Êï∞Ë°®Á§∫ÔºàÁæéÂõΩ=1, ‰∏≠ÂõΩ=2ÔºâÔºå‰ºöÂºïÂÖ•ÈîôËØØÁöÑÊï∞ÂÄºËøêÁÆóÂÖ≥Á≥ªÔºåÂ¶Ç ‚ÄúÁæéÂõΩ + ‰∏≠ÂõΩ = Âç∞Â∫¶‚Äù„ÄÇ ‰∫å„ÄÅOne-HotÁºñÁ†ÅÁöÑÂä®Êú∫‰∏éÊµÅÁ®ã ‰∏∫‰ªÄ‰πà‰ΩøÁî®One-Hot\nÈÄöËøáÂ∞ÜÁ±ªÂà´Êò†Â∞Ñ‰∏∫ÂêëÈáèÔºåÈÅøÂÖçÊï¥Êï∞ÁºñÁ†ÅÂºïÂÖ•ÁöÑ‰º™Êï∞ÂÄºÂÖ≥Á≥ª„ÄÇ ÂêåÊó∂‰øùÁïôÂêÑÁßçÂèØËÉΩÁ±ªÂà´ÁöÑ‰ø°ÊÅØÔºå‰∏î‰ªÖÂú®ÂØπÂ∫î‰ΩçÁΩÆ‰∏∫1ÔºåÂÖ∂‰ªñ‰ΩçÁΩÆ‰∏∫0„ÄÇ Âª∫Á´ãÊò†Â∞ÑÔºö‰ªéÁ±ªÂà´Âà∞Á¥¢Âºï\n‰∏∫ÊØè‰∏™Á±ªÂà´ÂàÜÈÖç‰∏Ä‰∏™ÂîØ‰∏ÄÁ¥¢ÂºïÔºåÈÄöÂ∏∏‰ªé1ÂºÄÂßã„ÄÇ È¢ÑÁïôÁ¥¢Âºï0Ë°®Á§∫‚ÄúÊú™Áü•‚ÄùÊàñ‚ÄúÁº∫Â§±‚ÄùÔºåÂØπÂ∫îÂÖ®0ÂêëÈáè„ÄÇ ËΩ¨Êç¢‰∏∫One-HotÂêëÈáè\nËã•Á±ªÂà´ÊÄªÊï∞‰∏∫197ÔºåÂàôÁî®197Áª¥ÂêëÈáèË°®Á§∫„ÄÇ ‰æãÂ≠êÔºöÁæéÂõΩ [1, 0, 0, 0, ‚Ä¶]Ôºå ‰∏≠ÂõΩ [0, 1, 0, 0, ‚Ä¶]„ÄÇ Á§∫‰æãÔºöË°®Á§∫‰∏Ä‰∏™‰∫∫ÁöÑÁâπÂæÅ\nÁâπÂæÅÂåÖÂê´ÔºàÂπ¥ÈæÑ, ÊÄßÂà´, ÂõΩÁ±çÔºåÂÖ∂‰∏≠ÂõΩÁ±ç197ÁßçÔºâ Áª¥Â∫¶ÊÄªÂíåÔºö1Áª¥_age + 1Áª¥_gender + 197Áª¥_nationality = 199Áª¥„ÄÇ ‰æãÂ¶Ç (28, Â•≥, ‰∏≠ÂõΩ) ‚Üí [28, 0, 0, 1, 0, ‚Ä¶, 0]„ÄÇ ‰∏â„ÄÅÊñáÊú¨Êï∞ÊçÆÂ§ÑÁêÜÊµÅÁ®ã ÊñáÊú¨Âú®Ëá™ÁÑ∂ËØ≠Ë®ÄÂ§ÑÁêÜÔºàNLPÔºâ‰∏≠‰Ωú‰∏∫Â∏∏ËßÅÁöÑÂéüÂßãËæìÂÖ•ÔºåÈúÄË¶ÅÊï∞ÂÄºÂåñÊâçËÉΩÈÄÅÂÖ•Ê®°Âûã„ÄÇ‰∏ÄËà¨Ê≠•È™§Â¶Ç‰∏ãÔºö\nÂàÜËØç (Tokenization)\nÂ∞ÜÊñáÊú¨ÊãÜÂàÜ‰∏∫‰∏Ä‰∏™‰∏™ÂçïËØçÔºàTokenÔºâ„ÄÇ ‰æãÂ≠êÔºö\u0026quot;... to be or not to be...\u0026quot; ‚Üí [\u0026quot;...\u0026quot;, \u0026quot;to\u0026quot;, \u0026quot;be\u0026quot;, \u0026quot;or\u0026quot;, \u0026quot;not\u0026quot;, \u0026quot;to\u0026quot;, \u0026quot;be\u0026quot;, \u0026quot;...\u0026quot;]„ÄÇ ÁªüËÆ°ËØçÈ¢ë \u0026amp; ÊûÑÂª∫ËØçÂÖ∏\nËØçÈ¢ëÁªüËÆ° Áî®ÂìàÂ∏åË°®/Â≠óÂÖ∏ËÆ∞ÂΩïÊØè‰∏™ÂçïËØçÂá∫Áé∞Ê¨°Êï∞„ÄÇ ÈÅçÂéÜÊñáÊú¨Êó∂ÔºåËã•ÂçïËØçÂ∞öÊú™ÂÖ•Ë°®ÔºåÂàôÊñ∞Âª∫ËÆ∞ÂΩïÔºõËã•Â∑≤Â≠òÂú®ÔºåÂàôËÆ°Êï∞+1„ÄÇ ÊéíÂ∫è‰∏éÁ¥¢Âºï ÊåâËØçÈ¢ëÈôçÂ∫èÊéíÂ∫èÔºåËØçÈ¢ëÊúÄÈ´òÁöÑÂçïËØçÊéíÂú®ÂâçÈù¢„ÄÇ Á¥¢Âºï‰ªé1ÂºÄÂßãÔºå0ÁïôÁªô‚ÄúÊú™Áü•‚Äù„ÄÇ ËØçÂÖ∏ËßÑÊ®°ÔºàvocabularyÔºâÂèØËßÜÈúÄÊ±ÇÊà™Êñ≠Ôºà‰æãÂ¶ÇÂè™‰øùÁïôTop 10kÔºâ„ÄÇ ‰∏∫‰ªÄ‰πàÁßªÈô§‰ΩéÈ¢ëËØç ‰ΩéÈ¢ëËØçÂèØËÉΩÊòØÊãºÂÜôÈîôËØØ„ÄÅÁΩïËßÅ‰∫∫ÂêçÁ≠âÔºåÂØπÊ®°ÂûãÂ∏ÆÂä©ÊúâÈôê„ÄÇ ÂáèÂ∞ëËØçÂÖ∏ËßÑÊ®°ÂèØÈôç‰ΩéËøêÁÆóÂºÄÈîÄ„ÄÅÂä†Âø´Ê®°ÂûãËÆ≠ÁªÉ‰∏éÊé®ÁêÜÈÄüÂ∫¶„ÄÇ Áã¨ÁÉ≠ÁºñÁ†Å (One-Hot Encoding)\nÂ∞ÜÊØè‰∏™ÂçïËØçÊò†Â∞Ñ‰∏∫ËØçÂÖ∏‰∏≠ÁöÑÁ¥¢ÂºïÂêéÔºàÂ¶Ç [2, 4, 1, 8, ‚Ä¶]ÔºâÔºåÂèØËøõ‰∏ÄÊ≠•ËΩ¨Êç¢ÊàêOne-HotÂêëÈáè„ÄÇ One-HotÁª¥Â∫¶ÂèñÂÜ≥‰∫é‰øùÁïô‰∏ãÊù•ÁöÑËØçÂÖ∏Â§ßÂ∞èÔºà‰æãÂ¶Ç1‰∏áÔºâ„ÄÇ Êú™Êî∂ÂΩïÂçïËØçÂèØËÉΩÁõ¥Êé•ÂøΩÁï•ÔºåÊàñÁªü‰∏ÄÁî®Á¥¢Âºï0‰ª£Êõø„ÄÇ Âõõ„ÄÅÊ†∏ÂøÉÊî∂Ëé∑‰∏éÂ∫îÁî® Á±ªÂà´ÁâπÂæÅÂøÖÈúÄÊï∞ÂÄºÂåñÔºö\n‰ΩøÁî®Êï¥Êï∞1,2,3‚Ä¶‰ªÖË°®Á§∫Á±ªÂà´‚ÄúÊ†áËØÜ‚ÄùÔºåÂπ∂‰∏ç‰ª£Ë°®ÂÆÉ‰ª¨ÂèØËøõË°åÊï∞ÂÄºËøêÁÆó„ÄÇ Âõ†Ê≠§ÈúÄË¶ÅOne-HotÁ≠âÁºñÁ†ÅÊñπÂºèÔºåÈÅøÂÖçÊï∞ÂÄºËØØËß£„ÄÇ ÊñáÊú¨Êï∞ÊçÆÈ¢ÑÂ§ÑÁêÜÔºö\nÂàÜËØç„ÄÅËØçÈ¢ëÁªüËÆ°„ÄÅÊûÑÂª∫ËØçÂÖ∏„ÄÅÁ¥¢ÂºïÂåñ„ÄÅOne-HotÊàñÂÖ∂‰ªñÊñπÂºèÔºàÂ¶ÇËØçÂµåÂÖ•ÔºâÊòØÂ∏∏ËßÅÊµÅÁ®ã„ÄÇ Ê≠£Á°ÆÁöÑÊñáÊú¨È¢ÑÂ§ÑÁêÜÂèØÊòæËëóÂΩ±ÂìçÊ®°ÂûãÊÄßËÉΩÂíåÊïàÁéá„ÄÇ ‰øùÁïôÊú™Áü•Á¥¢ÂºïÔºö\n‰øùËØÅÂØπÁº∫Â§±Êï∞ÊçÆÊàñÂ≠óÂÖ∏Â§ñÊñ∞ËØçËÉΩÊúâÂü∫Êú¨ÁöÑË°®Á§∫ÔºåÊèêÂçáÊ®°ÂûãÂÆπÈîôÊÄß„ÄÇ ÂÆûÈôÖ‰ΩøÁî®Ôºö\nÂØπ‰∫éÂ∞èËßÑÊ®°Á±ªÂà´ÂèØÁõ¥Êé•One-HotÁºñÁ†ÅÔºõÂØπ‰∫éËØçÂÖ∏ÂæàÂ§ßÁöÑÂú∫ÊôØÔºåÈÄöÂ∏∏‰ºöËøõ‰∏ÄÊ≠•ËÄÉËôëËØçÂµåÂÖ•ÔºàWord EmbeddingÔºâÊàñÈ¢ÑËÆ≠ÁªÉËØ≠Ë®ÄÊ®°Âûã„ÄÇ ","permalink":"http://localhost:1313/posts/nlp-1/","summary":"\u003ch2 id=\"‰∏ÄÊï∞ÂÄºÁâπÂæÅ‰∏éÁ±ªÂà´ÁâπÂæÅ\"\u003e‰∏Ä„ÄÅÊï∞ÂÄºÁâπÂæÅ‰∏éÁ±ªÂà´ÁâπÂæÅ\u003c/h2\u003e\n\u003col\u003e\n\u003cli\u003e\u003cstrong\u003eÊï∞ÂÄºÁâπÂæÅ (Numeric Features)\u003c/strong\u003e\n\u003cul\u003e\n\u003cli\u003eÂÖ∑ÊúâÂèØÂä†ÂáèÁöÑÊÑè‰πâÔºå‰∏îÂ≠òÂú®Â§ßÂ∞èÈ°∫Â∫è„ÄÇ\u003c/li\u003e\n\u003cli\u003e‰æãÂ≠êÔºöÂπ¥ÈæÑ„ÄÅÊ∏©Â∫¶Á≠â„ÄÇÂèØ‰ª•Áõ¥Êé•‰øùÁïôÂÖ∂Êï¥Êï∞ÊàñÊµÆÁÇπÊï∞ÂΩ¢Âºè‰æõÊ®°Âûã‰ΩøÁî®„ÄÇ\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003eÁ±ªÂà´ÁâπÂæÅ (Categorical Features)\u003c/strong\u003e\n\u003cul\u003e\n\u003cli\u003eÊï∞ÊçÆÂÄºÁ¶ªÊï£Ôºå‰∏çÂÖ∑Â§á‚ÄúÊï∞ÂÄºÂ§ßÂ∞è‚ÄùÈó¥ÁöÑÂèØÊØîÊÑè‰πâ„ÄÇ\u003c/li\u003e\n\u003cli\u003e‰æãÂ≠êÔºöÂõΩÁ±çÔºàÁæéÂõΩ/‰∏≠ÂõΩ/Âç∞Â∫¶Á≠âÔºâ„ÄÅÊÄßÂà´ÔºàÁî∑/Â•≥ÔºâÁ≠â„ÄÇ\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003eÈóÆÈ¢ò\u003c/strong\u003eÔºöËã•‰ªÖÁî®Êï¥Êï∞Ë°®Á§∫ÔºàÁæéÂõΩ=1, ‰∏≠ÂõΩ=2ÔºâÔºå‰ºöÂºïÂÖ•ÈîôËØØÁöÑÊï∞ÂÄºËøêÁÆóÂÖ≥Á≥ªÔºåÂ¶Ç ‚ÄúÁæéÂõΩ + ‰∏≠ÂõΩ = Âç∞Â∫¶‚Äù„ÄÇ\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003c/ol\u003e\n\u003ch2 id=\"‰∫åone-hotÁºñÁ†ÅÁöÑÂä®Êú∫‰∏éÊµÅÁ®ã\"\u003e‰∫å„ÄÅOne-HotÁºñÁ†ÅÁöÑÂä®Êú∫‰∏éÊµÅÁ®ã\u003c/h2\u003e\n\u003col\u003e\n\u003cli\u003e\n\u003cp\u003e\u003cstrong\u003e‰∏∫‰ªÄ‰πà‰ΩøÁî®One-Hot\u003c/strong\u003e\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eÈÄöËøáÂ∞ÜÁ±ªÂà´Êò†Â∞Ñ‰∏∫ÂêëÈáèÔºåÈÅøÂÖçÊï¥Êï∞ÁºñÁ†ÅÂºïÂÖ•ÁöÑ‰º™Êï∞ÂÄºÂÖ≥Á≥ª„ÄÇ\u003c/li\u003e\n\u003cli\u003eÂêåÊó∂‰øùÁïôÂêÑÁßçÂèØËÉΩÁ±ªÂà´ÁöÑ‰ø°ÊÅØÔºå‰∏î‰ªÖÂú®ÂØπÂ∫î‰ΩçÁΩÆ‰∏∫1ÔºåÂÖ∂‰ªñ‰ΩçÁΩÆ‰∏∫0„ÄÇ\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003e\u003cstrong\u003eÂª∫Á´ãÊò†Â∞ÑÔºö‰ªéÁ±ªÂà´Âà∞Á¥¢Âºï\u003c/strong\u003e\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e‰∏∫ÊØè‰∏™Á±ªÂà´ÂàÜÈÖç‰∏Ä‰∏™ÂîØ‰∏ÄÁ¥¢ÂºïÔºåÈÄöÂ∏∏‰ªé1ÂºÄÂßã„ÄÇ\u003c/li\u003e\n\u003cli\u003eÈ¢ÑÁïôÁ¥¢Âºï0Ë°®Á§∫‚ÄúÊú™Áü•‚ÄùÊàñ‚ÄúÁº∫Â§±‚ÄùÔºåÂØπÂ∫îÂÖ®0ÂêëÈáè„ÄÇ\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003e\u003cstrong\u003eËΩ¨Êç¢‰∏∫One-HotÂêëÈáè\u003c/strong\u003e\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eËã•Á±ªÂà´ÊÄªÊï∞‰∏∫197ÔºåÂàôÁî®197Áª¥ÂêëÈáèË°®Á§∫„ÄÇ\u003c/li\u003e\n\u003cli\u003e‰æãÂ≠êÔºöÁæéÂõΩ \u003ccode\u003e[1, 0, 0, 0, ‚Ä¶]\u003c/code\u003eÔºå ‰∏≠ÂõΩ \u003ccode\u003e[0, 1, 0, 0, ‚Ä¶]\u003c/code\u003e„ÄÇ\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003e\u003cstrong\u003eÁ§∫‰æãÔºöË°®Á§∫‰∏Ä‰∏™‰∫∫ÁöÑÁâπÂæÅ\u003c/strong\u003e\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eÁâπÂæÅÂåÖÂê´ÔºàÂπ¥ÈæÑ, ÊÄßÂà´, ÂõΩÁ±çÔºåÂÖ∂‰∏≠ÂõΩÁ±ç197ÁßçÔºâ\u003c/li\u003e\n\u003cli\u003eÁª¥Â∫¶ÊÄªÂíåÔºö1Áª¥_age + 1Áª¥_gender + 197Áª¥_nationality = 199Áª¥„ÄÇ\u003c/li\u003e\n\u003cli\u003e‰æãÂ¶Ç \u003ccode\u003e(28, Â•≥, ‰∏≠ÂõΩ)\u003c/code\u003e ‚Üí \u003ccode\u003e[28, 0, 0, 1, 0, ‚Ä¶, 0]\u003c/code\u003e„ÄÇ\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003c/ol\u003e\n\u003ch2 id=\"‰∏âÊñáÊú¨Êï∞ÊçÆÂ§ÑÁêÜÊµÅÁ®ã\"\u003e‰∏â„ÄÅÊñáÊú¨Êï∞ÊçÆÂ§ÑÁêÜÊµÅÁ®ã\u003c/h2\u003e\n\u003cp\u003eÊñáÊú¨Âú®Ëá™ÁÑ∂ËØ≠Ë®ÄÂ§ÑÁêÜÔºàNLPÔºâ‰∏≠‰Ωú‰∏∫Â∏∏ËßÅÁöÑÂéüÂßãËæìÂÖ•ÔºåÈúÄË¶ÅÊï∞ÂÄºÂåñÊâçËÉΩÈÄÅÂÖ•Ê®°Âûã„ÄÇ‰∏ÄËà¨Ê≠•È™§Â¶Ç‰∏ãÔºö\u003c/p\u003e\n\u003col\u003e\n\u003cli\u003e\n\u003cp\u003e\u003cstrong\u003eÂàÜËØç (Tokenization)\u003c/strong\u003e\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eÂ∞ÜÊñáÊú¨ÊãÜÂàÜ‰∏∫‰∏Ä‰∏™‰∏™ÂçïËØçÔºàTokenÔºâ„ÄÇ\u003c/li\u003e\n\u003cli\u003e‰æãÂ≠êÔºö\u003ccode\u003e\u0026quot;... to be or not to be...\u0026quot;\u003c/code\u003e ‚Üí \u003ccode\u003e[\u0026quot;...\u0026quot;, \u0026quot;to\u0026quot;, \u0026quot;be\u0026quot;, \u0026quot;or\u0026quot;, \u0026quot;not\u0026quot;, \u0026quot;to\u0026quot;, \u0026quot;be\u0026quot;, \u0026quot;...\u0026quot;]\u003c/code\u003e„ÄÇ\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003e\u003cstrong\u003eÁªüËÆ°ËØçÈ¢ë \u0026amp; ÊûÑÂª∫ËØçÂÖ∏\u003c/strong\u003e\u003c/p\u003e","title":""},{"content":"Text to Sequence ÊñáÊú¨Â§ÑÁêÜ\nStep1: Tokenization\nTokenization breaks a piece of text down into a list of tokens.\nHere, a token is a word. (A token can be a character in some applications.)\nTokenizationËÆ≤Á©∂ÂæàÂ§öÔºå‰æãÂ¶ÇÊòØÂê¶Â∫îËØ•ÊääÂ§ßÂÜôÊîπÊàêÂ∞èÂÜôÂë¢ÔºüËøõË°åtypo correctionÁ≠âÁ≠â\nStep2: Build Dictionary\nUse a dictionary (hash table) to count word frequencies.\nThe dictionary maps word to index.\nÂèØ‰ª•È¶ñÂÖàÁªüËÆ°ËØçÈ¢ëÂéªÊéâ‰ΩéÈ¢ëËØçÔºåÁÑ∂ÂêéËÆ©ÊØè‰∏™ËØçÂØπÂ∫î‰∏Ä‰∏™Ê≠£Êï¥Êï∞ÔºõËøôÊ†∑ÁöÑËØùÔºå‰∏ÄÂè•ËØùÂ∞±ÂèØ‰ª•Áî®‰∏Ä‰∏™Ê≠£Êï¥Êï∞ÂàóË°®Ë°®Á§∫ÔºåËøô‰∏™ÂàóË°®Â∞±Âè´sequenceÔºõÂ¶ÇÊûúÂøÖË¶ÅÂ∞±ËøòÂæóÂÅöone-hot encoding„ÄÇ\nÁªìÊûú\n‰ΩÜÊòØÈïøÂ∫¶‰∏çÁªü‰∏Ä\nStep4: ÂØπÈΩêsequence\nËß£ÂÜ≥ÊñπÊ°àÊòØËøôÊ†∑ÁöÑÔºöÂèØ‰ª•Âõ∫ÂÆöÈïøÂ∫¶‰∏∫wÔºåÂä†ÂÖ•‰∏Ä‰∏™Â∫èÂàóÈïøÂ∫¶Â§™ÈïøÔºåÂ∞±Á†çÊéâÂâçÈù¢ÁöÑËØçÔºåÂè™‰øùÁïôÊúÄÂêéw‰∏™ËØçÔºõÂ¶ÇÊûú‰∏Ä‰∏™Â∫èÂàóÂ§™Áü≠ÔºåÂ∞±ÂÅözero paddingÔºåÁî®0Â°´ÂÖÖ\nËøôÊ†∑‰∏ÄÊù•ÔºåÊâÄÊúâÁöÑÂ∫èÂàóÈïøÂ∫¶Â∞±Áªü‰∏Ä‰∫Ü\nÊñáÊú¨Â§ÑÁêÜÂÆåÊàê‰∫ÜÔºåÊé•‰∏ãÊù•ÊòØword embeddingÔºåÊääÂçïËØçË°®Á§∫‰∏∫‰∏Ä‰∏™‰ΩéÁª¥ÂêëÈáèÔºõ\nÁÑ∂ËÄåËøôÊ†∑ÂÅöÁöÑËØùÔºåÂ¶ÇÊûúÊòØ10000‰∏™ÂçïËØçÔºåÁª¥Â∫¶Â∞±ÊòØ10000Áª¥ÔºåÁª¥Â∫¶Â§™È´ò‰∫ÜÔºõÂõ†Ê≠§Ë¶ÅÂÅöword embeddingÔºõ\nÂÖ∑‰ΩìÂÅöÊ≥ïÂ∞±ÊòØÊääone-hotÂêëÈáèe_iÂíåÂèÇÊï∞Áü©ÈòµpÁõ∏‰πòÔºõÁü©ÈòµPËΩ¨ÁΩÆÁöÑÂ§ßÂ∞èÊòØd x vÔºõdÊòØËØçÂêëÈáèÁöÑÁª¥Â∫¶ÔºõvÊòØÂ≠óÂÖ∏ÈáåËØçÊ±áÁöÑÊï∞ÈáèÔºõÁªìÊûú‰∏∫x_iÔºõx_iÂ∞±ÊòØ‰∏Ä‰∏™ËØçÂêëÈáèÔºõÂ¶ÇÊûúone-hotÂêëÈáèÁöÑÁ¨¨‰∏âË°å‰∏∫1ÔºõÈÇ£‰πàx_iÂ∞±ÊòØPËΩ¨ÁΩÆÁü©ÈòµÁöÑÁ¨¨‰∏âÂàóÔºàÂÖ∂‰ΩôÂàóÈÉΩ‰∏∫0ÔºâÔºõÊâÄ‰ª•PËΩ¨ÁΩÆÊØè‰∏ÄÂàóÈÉΩÊòØ‰∏Ä‰∏™ËØçÂêëÈáèÔºõÊâÄ‰ª•Áü©ÈòµPÊú¨Ë∫´ÁöÑÊØè‰∏ÄË°åÂ∞±ÊòØ‰∏Ä‰∏™ËØçÂêëÈáèÔºõÂÖ∂Ë°åÊï∞‰∏∫vÔºõÂç≥vocabularyÔºåËØçÊ±áÈáèÔºõÊØè‰∏ÄË°åÂØπÂ∫î‰∏Ä‰∏™ÂçïËØçÔºõÁü©ÈòµÁöÑÂàóÊï∞‰∏∫dÔºõdÊòØÁî®Êà∑ÂÜ≥ÂÆöÁöÑÔºõdÁöÑÂ§ßÂ∞è‰ºöÂÜ≥ÂÆöÊú∫Âô®Â≠¶‰π†Ê®°ÂûãÁöÑË°®Áé∞ÔºõÂ∫îËØ•Áî®xxxÊù•ÈÄâÊã©‰∏Ä‰∏™ÊØîËæÉÂ•ΩÁöÑdÔºõ\nÊàë‰ª¨ÁöÑ‰ªªÂä°ÊòØÁúãËØÑËÆ∫ÊòØÊ≠£Èù¢ÁöÑËøòÊòØË¥üÈù¢ÁöÑÔºõÂèÇÊï∞Áü©ÈòµÊòØ‰ªéËÆ≠ÁªÉÊï∞ÊçÆ‰∏≠Â≠¶‰π†Âá∫Êù•ÁöÑÔºåÊâÄ‰ª•Â≠¶Âá∫Êù•ÁöÑËØçÂêëÈáèÊòØÂ∏¶ÊúâÊÑüÊÉÖËâ≤ÂΩ©ÁöÑÔºõÂÅáËÆæËøô‰∫õËØçÂêëÈáèÈÉΩÊòØ‰∫åÁª¥ÁöÑÔºåÂàôÂèØ‰ª•Âú®Âπ≥Èù¢ÂùêÊ†áÁ≥ª‰∏≠Ê†áÂá∫‰∏ãÈù¢ËØçÂêëÈáè\nkerasÊèê‰æõembeddingÂ±ÇÔºõÁî®Êà∑ÂèØ‰ª•ÊåáÂÆövocabularyÂ§ßÂ∞èÂíådÁöÑÂ§ßÂ∞èÔºõ‰ª•ÂèäÊØè‰∏Ä‰∏™sequenceÁöÑÈïøÂ∫¶ÔºõdÊòØÊ†πÊçÆÁÆóÊ≥ïÈÄâÂá∫Êù•ÁöÑ Âà∞Ëøô‰∏ÄÊ≠•ÔºåÊàë‰ª¨Â∑≤ÁªèÂÆåÊàê‰∫ÜÊñáÊú¨Â§ÑÁêÜÂíåword embedding„ÄÇÊé•‰∏ãÊù•Â∞±ÊòØÁî®Logistic Regression for Binary ClassificationÂÅö‰∫åÂàÜÁ±ªÔºõ\n","permalink":"http://localhost:1313/posts/nlp-2/","summary":"\u003ch3 id=\"text-to-sequence\"\u003eText to Sequence\u003c/h3\u003e\n\u003cp\u003eÊñáÊú¨Â§ÑÁêÜ\u003c/p\u003e\n\u003cp\u003eStep1: Tokenization\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\n\u003cp\u003eTokenization breaks a piece of text down into a list of tokens.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003eHere, a token is a word. (A token can be a character in some applications.)\u003c/p\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003eTokenizationËÆ≤Á©∂ÂæàÂ§öÔºå‰æãÂ¶ÇÊòØÂê¶Â∫îËØ•ÊääÂ§ßÂÜôÊîπÊàêÂ∞èÂÜôÂë¢ÔºüËøõË°åtypo correctionÁ≠âÁ≠â\u003c/p\u003e\n\u003cp\u003e\u003cimg alt=\"image-20250322150322238\" loading=\"lazy\" src=\"./NLP-2.assets/image-20250322150322238.png\"\u003e\u003c/p\u003e\n\u003cp\u003eStep2: Build Dictionary\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\n\u003cp\u003eUse a dictionary (hash table) to count word frequencies.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003eThe dictionary maps word to index.\u003c/p\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003eÂèØ‰ª•È¶ñÂÖàÁªüËÆ°ËØçÈ¢ëÂéªÊéâ‰ΩéÈ¢ëËØçÔºåÁÑ∂ÂêéËÆ©ÊØè‰∏™ËØçÂØπÂ∫î‰∏Ä‰∏™Ê≠£Êï¥Êï∞ÔºõËøôÊ†∑ÁöÑËØùÔºå‰∏ÄÂè•ËØùÂ∞±ÂèØ‰ª•Áî®‰∏Ä‰∏™Ê≠£Êï¥Êï∞ÂàóË°®Ë°®Á§∫ÔºåËøô‰∏™ÂàóË°®Â∞±Âè´sequenceÔºõÂ¶ÇÊûúÂøÖË¶ÅÂ∞±ËøòÂæóÂÅöone-hot encoding„ÄÇ\u003cimg alt=\"image-20250322150620890\" loading=\"lazy\" src=\"./NLP-2.assets/image-20250322150620890.png\"\u003e\u003c/p\u003e\n\u003cp\u003eÁªìÊûú\u003c/p\u003e\n\u003cp\u003e\u003cimg alt=\"image-20250322150754528\" loading=\"lazy\" src=\"./NLP-2.assets/image-20250322150754528.png\"\u003e\u003c/p\u003e\n\u003cp\u003e‰ΩÜÊòØÈïøÂ∫¶‰∏çÁªü‰∏Ä\u003c/p\u003e\n\u003cp\u003eStep4: ÂØπÈΩêsequence\u003c/p\u003e\n\u003cp\u003e\u003cimg alt=\"image-20250322150854986\" loading=\"lazy\" src=\"./NLP-2.assets/image-20250322150854986.png\"\u003e\u003c/p\u003e\n\u003cp\u003eËß£ÂÜ≥ÊñπÊ°àÊòØËøôÊ†∑ÁöÑÔºöÂèØ‰ª•Âõ∫ÂÆöÈïøÂ∫¶‰∏∫wÔºåÂä†ÂÖ•‰∏Ä‰∏™Â∫èÂàóÈïøÂ∫¶Â§™ÈïøÔºåÂ∞±Á†çÊéâÂâçÈù¢ÁöÑËØçÔºåÂè™‰øùÁïôÊúÄÂêéw‰∏™ËØçÔºõÂ¶ÇÊûú‰∏Ä‰∏™Â∫èÂàóÂ§™Áü≠ÔºåÂ∞±ÂÅözero paddingÔºåÁî®0Â°´ÂÖÖ\u003c/p\u003e\n\u003cp\u003e\u003cimg alt=\"image-20250322151030119\" loading=\"lazy\" src=\"./NLP-2.assets/image-20250322151030119.png\"\u003e\u003c/p\u003e\n\u003cp\u003eËøôÊ†∑‰∏ÄÊù•ÔºåÊâÄÊúâÁöÑÂ∫èÂàóÈïøÂ∫¶Â∞±Áªü‰∏Ä‰∫Ü\u003c/p\u003e\n\u003cp\u003e\u003cimg alt=\"image-20250322151117125\" loading=\"lazy\" src=\"./NLP-2.assets/image-20250322151117125.png\"\u003e\u003c/p\u003e\n\u003cp\u003eÊñáÊú¨Â§ÑÁêÜÂÆåÊàê‰∫ÜÔºåÊé•‰∏ãÊù•ÊòØword embeddingÔºåÊääÂçïËØçË°®Á§∫‰∏∫‰∏Ä‰∏™‰ΩéÁª¥ÂêëÈáèÔºõ\u003c/p\u003e\n\u003cp\u003e\u003cimg alt=\"image-20250322151252837\" loading=\"lazy\" src=\"./NLP-2.assets/image-20250322151252837.png\"\u003e\u003c/p\u003e","title":""},{"content":"üëã About me Hello! I\u0026rsquo;m Xu Zongsi, a passionate technology enthusiast currently pursuing my Master of Science in ECIC at The University of Hong Kong. With a solid background in Software Engineering from the Beijing Institute of Technology, I specialize in artificial intelligence areas like machine learning, deep learning, natural language processing, computer vision, and reinforcement learning.\nInspired by OpenAI\u0026rsquo;s five-step plan towards superintelligence, I am excited about AGI and have developed a keen interest in LLM agents, MLLM, and knowledge graphs. I see great potential in these fields and aspire to contribute to innovative solutions.\nüìö Education üá≠üá∞ The University of Hong Kong 09/2024 - Expected 11/2025 School of Computing and Data Science Master of Science in Electronic Commerce \u0026amp; Internet Computing Relevant Courses: Machine learning for business and e-commerce, Knowledge graphs, Financial fraud analytics, Internet infrastructure technologies, Website engineering, Blockchain and cryptocurrency, etc. üá®üá≥ Beijing Institute of Technology 09/2020 - 06/2024 School of Computer Science \u0026amp; Technology Bachelor of Engineering in Software Engineering, last two years GPA: 3.7/4 Relevant Courses: Reinforcement Learning, Deep Learning and Computer Vision, Artificial Intelligence and Robot Ethics, Almost Human: Mind, Brain and Artificial Intelligence, Mathematical Analysis for Engineering, Linear Algebra, Probability and Mathematical Statistics, etc. Skills: Python, Java, common data structures, design patterns, machine learning basics and algorithms, Linux, PyTorch, and some development tools (git, conda, etc.). üèÜ Awards \u0026amp; Honors Beijing Institute of Technology Undergraduate Scholarship (Top 20% of Grade) 06/2023 3rd Prize of China International \u0026#34;Internet \u0026#43;\u0026#34; College Student\u0026#39;s Innovation Competition 08/2022 Bronze Prize of \u0026#34;Challenge Cup\u0026#34; Capital University Entrepreneurship Competition 05/2022 üíº Project Experience üîç Online Transaction Fraud Detection 09/2024 ‚Äì 01/2025 Independent project, supervised by Dr. Vivien Chan Focused on addressing financial fraud in e-commerce to enhance the accuracy of transaction anomaly detection, while independently managing the entire case study that included data preprocessing, feature engineering, model building, evaluation, and results analysis. Effectively resolved class imbalance issues using SMOTE and ROSE techniques. Built various models including Logistic Regression, Random Forest, XGBoost, and LightGBM, ultimately selecting the LightGBM model to achieve a recall rate of 95.45% and an AUC of 99.84%. Wrote efficient and maintainable code, enhancing model training and data processing efficiency through parallel computing and logging. ü§ñ Multi-Model Intelligent Text Keyword Extraction System 08/2023 ‚Äì 09/2023 Group project, supervised by Associate Prof. Xiaolin Zhao Designed and implemented an intelligent text summary system that automatically extracts keywords from article titles and abstracts, enhancing the understanding and summarization of text information. Participated in the planning of the technical route and built a hybrid model combining extractive and generative approaches, utilizing advanced natural language processing techniques including KeyBERT, Sentence Transformer, BERT, and T5 models. Responsible for data preprocessing and tokenization, as well as the end-to-end implementation and training of the T5 model, optimizing the model architecture and hyperparameters, achieving satisfactory results after only 3 epochs of training. Model evaluation results showed that the Rouge-1, Rouge-2, and Rouge-L metrics reached 0.6345, 0.5038, and 0.5282, respectively, in the third epoch, validating the model\u0026rsquo;s effectiveness in the summarization task. üéì Cambridge University Machine Learning Summer Project 07/2023 ‚Äì 08/2023 Group project, supervised by Prof. Pietro Li√≤ Participated in the Cambridge University deep learning summer project, focusing on deep reinforcement learning; explored multi-agent learning algorithms across different environments. Reproduced the Multi-Agent Deep Deterministic Policy Gradient (MADDPG) algorithm in the Simple Adversary environment and studied the effect of agent numbers on convergence speed and stability, finding optimal stability at 21 agents. Designed and implemented comparative experiments inspired by the Rainbow algorithm, assessing target network strategies versus the Double Deep Q-Network (Double DQN). The results demonstrated that Double DQN significantly enhanced convergence speed, optimizing the overall learning process. Co-authored a group project paper on agent numbers and strategies effectiveness in multi-agent systems, achieving a score of 71% in the summer program (the highest in my group) and a \u0026ldquo;First Class\u0026rdquo; classification in the UK grading system. üëÅÔ∏è Deep Learning and Computer Vision Semester Project 09/2022 ‚Äì 12/2022 Independent project, supervised by Associate Prof. Guangyu Gao Designed and implemented a waste classifier using the ResNet model to improve classification accuracy and reduce resource waste. The project also enhanced understanding of transfer learning techniques with ResNet. Collected a dataset of 16 waste categories and preprocessed the images for uniformity and standardization, incorporating data augmentation techniques to enhance the dataset. Conducted experiments using ResNet34 and ResNet50 models through transfer learning, accelerating network convergence by leveraging pretrained weights. During training, techniques such as Batch Normalization and Dropout were applied to mitigate the risk of overfitting. The final model achieved an accuracy of 90% on the training set, while the performance on the test set was 61%, indicating a significant overfitting phenomenon during the training process. üéì Internship ‚öõÔ∏è Beijing Academy of Quantum Information Science 08/2023 ‚Äì 01/2024 Research Intern at Quantum Computation Department Proposed a quantum convolution kernel design based on variational quantum circuits and developed a universal quantum convolution layer, successfully integrating it into classical CNN architectures such as VGG, GoogLeNet, and ResNet. Developed and evaluated various hybrid models, including a simple model named HQCCNN-2, which achieved 84.45% accuracy on the FashionMNIST dataset, surpassing the traditional CNN\u0026rsquo;s 80.72%. This demonstrates the effectiveness of the quantum convolution layer in improving model performance. Tested on a real quantum computer further validated the effectiveness of the hybrid model, demonstrating the viable integration of quantum computing with deep learning, and highlighting the potential for leveraging quantum properties to enhance model performance. üèÖ Competition Experience ü•â China International \u0026#34;Internet \u0026#43;\u0026#34; College Students\u0026#39; Innovation Competition 08/2022 üõ°Ô∏è Zhongke Ushield: Deep Learning-based Face Privacy Protection Authentication System Responsible for constructing a localized facial feature extraction engine based on MobileFaceNet, ensuring feature extraction is completed on end devices (such as mobile phones and cameras), guaranteeing that raw data does not leave the domain and is not stored, thus enhancing user privacy protection while improving recognition efficiency. ü•â \u0026#34;Challenge Cup\u0026#34; Capital University Entrepreneurship Competition 05/2022 üå≥ Smart Orchard Responsible for the development of the fruit detection, ripeness prediction, and pest identification system, using deep convolutional neural network (CNN) technology for intelligent monitoring of crop growth conditions. Applied advanced object detection algorithms such as Faster R-CNN and YOLO to achieve high precision in apple detection and ripeness assessment, with an accuracy rate exceeding 90%, significantly enhancing the intelligence level of orchard management. Built and trained a dedicated dataset containing various pest samples, optimizing pest detection accuracy through data preprocessing (such as image normalization and resizing) and data augmentation techniques (like rotation, flipping, and noise addition), enabling the real-time monitoring system to accurately identify over 80% of pests, providing effective scientific maintenance recommendations to help farmers reduce crop losses. üìã Extracurricular Activities Vice President, Cyber Security Club, Beijing Institute of Technology 09/2021-09/2022 Backbone, Media Center of the Student Union of Beijing Institute of Technology 10/2020-06/2021 üì´ Contact üìß Email: zongsi.xu@outlook.com üëî LinkedIn: Zongsi (Tristan) Xu üíª GitHub: BaizeXS üìç Location: Hong Kong SAR, China ","permalink":"http://localhost:1313/resume/","summary":"Personal resume of Zongsi (Tristan) Xu","title":"Zongsi (Tristan) Xu"},{"content":"‰∏Ä„ÄÅÊï∞ÂÄºÁâπÂæÅ‰∏éÁ±ªÂà´ÁâπÂæÅ Êï∞ÂÄºÁâπÂæÅ (Numeric Features) ÂÖ∑ÊúâÂèØÂä†ÂáèÁöÑÊÑè‰πâÔºå‰∏îÂ≠òÂú®Â§ßÂ∞èÈ°∫Â∫è„ÄÇ ‰æãÂ≠êÔºöÂπ¥ÈæÑ„ÄÅÊ∏©Â∫¶Á≠â„ÄÇÂèØ‰ª•Áõ¥Êé•‰øùÁïôÂÖ∂Êï¥Êï∞ÊàñÊµÆÁÇπÊï∞ÂΩ¢Âºè‰æõÊ®°Âûã‰ΩøÁî®„ÄÇ Á±ªÂà´ÁâπÂæÅ (Categorical Features) Êï∞ÊçÆÂÄºÁ¶ªÊï£Ôºå‰∏çÂÖ∑Â§á‚ÄúÊï∞ÂÄºÂ§ßÂ∞è‚ÄùÈó¥ÁöÑÂèØÊØîÊÑè‰πâ„ÄÇ ‰æãÂ≠êÔºöÂõΩÁ±çÔºàÁæéÂõΩ/‰∏≠ÂõΩ/Âç∞Â∫¶Á≠âÔºâ„ÄÅÊÄßÂà´ÔºàÁî∑/Â•≥ÔºâÁ≠â„ÄÇ ÈóÆÈ¢òÔºöËã•‰ªÖÁî®Êï¥Êï∞Ë°®Á§∫ÔºàÁæéÂõΩ=1, ‰∏≠ÂõΩ=2ÔºâÔºå‰ºöÂºïÂÖ•ÈîôËØØÁöÑÊï∞ÂÄºËøêÁÆóÂÖ≥Á≥ªÔºåÂ¶Ç ‚ÄúÁæéÂõΩ + ‰∏≠ÂõΩ = Âç∞Â∫¶‚Äù„ÄÇ ‰∫å„ÄÅOne-HotÁºñÁ†ÅÁöÑÂä®Êú∫‰∏éÊµÅÁ®ã ‰∏∫‰ªÄ‰πà‰ΩøÁî®One-Hot\nÈÄöËøáÂ∞ÜÁ±ªÂà´Êò†Â∞Ñ‰∏∫ÂêëÈáèÔºåÈÅøÂÖçÊï¥Êï∞ÁºñÁ†ÅÂºïÂÖ•ÁöÑ‰º™Êï∞ÂÄºÂÖ≥Á≥ª„ÄÇ ÂêåÊó∂‰øùÁïôÂêÑÁßçÂèØËÉΩÁ±ªÂà´ÁöÑ‰ø°ÊÅØÔºå‰∏î‰ªÖÂú®ÂØπÂ∫î‰ΩçÁΩÆ‰∏∫1ÔºåÂÖ∂‰ªñ‰ΩçÁΩÆ‰∏∫0„ÄÇ Âª∫Á´ãÊò†Â∞ÑÔºö‰ªéÁ±ªÂà´Âà∞Á¥¢Âºï\n‰∏∫ÊØè‰∏™Á±ªÂà´ÂàÜÈÖç‰∏Ä‰∏™ÂîØ‰∏ÄÁ¥¢ÂºïÔºåÈÄöÂ∏∏‰ªé1ÂºÄÂßã„ÄÇ È¢ÑÁïôÁ¥¢Âºï0Ë°®Á§∫‚ÄúÊú™Áü•‚ÄùÊàñ‚ÄúÁº∫Â§±‚ÄùÔºåÂØπÂ∫îÂÖ®0ÂêëÈáè„ÄÇ ËΩ¨Êç¢‰∏∫One-HotÂêëÈáè\nËã•Á±ªÂà´ÊÄªÊï∞‰∏∫197ÔºåÂàôÁî®197Áª¥ÂêëÈáèË°®Á§∫„ÄÇ ‰æãÂ≠êÔºöÁæéÂõΩ [1, 0, 0, 0, ‚Ä¶]Ôºå ‰∏≠ÂõΩ [0, 1, 0, 0, ‚Ä¶]„ÄÇ Á§∫‰æãÔºöË°®Á§∫‰∏Ä‰∏™‰∫∫ÁöÑÁâπÂæÅ\nÁâπÂæÅÂåÖÂê´ÔºàÂπ¥ÈæÑ, ÊÄßÂà´, ÂõΩÁ±çÔºåÂÖ∂‰∏≠ÂõΩÁ±ç197ÁßçÔºâ Áª¥Â∫¶ÊÄªÂíåÔºö1Áª¥_age + 1Áª¥_gender + 197Áª¥_nationality = 199Áª¥„ÄÇ ‰æãÂ¶Ç (28, Â•≥, ‰∏≠ÂõΩ) ‚Üí [28, 0, 0, 1, 0, ‚Ä¶, 0]„ÄÇ ‰∏â„ÄÅÊñáÊú¨Êï∞ÊçÆÂ§ÑÁêÜÊµÅÁ®ã ÊñáÊú¨Âú®Ëá™ÁÑ∂ËØ≠Ë®ÄÂ§ÑÁêÜÔºàNLPÔºâ‰∏≠‰Ωú‰∏∫Â∏∏ËßÅÁöÑÂéüÂßãËæìÂÖ•ÔºåÈúÄË¶ÅÊï∞ÂÄºÂåñÊâçËÉΩÈÄÅÂÖ•Ê®°Âûã„ÄÇ‰∏ÄËà¨Ê≠•È™§Â¶Ç‰∏ãÔºö\nÂàÜËØç (Tokenization)\nÂ∞ÜÊñáÊú¨ÊãÜÂàÜ‰∏∫‰∏Ä‰∏™‰∏™ÂçïËØçÔºàTokenÔºâ„ÄÇ ‰æãÂ≠êÔºö\u0026quot;... to be or not to be...\u0026quot; ‚Üí [\u0026quot;...\u0026quot;, \u0026quot;to\u0026quot;, \u0026quot;be\u0026quot;, \u0026quot;or\u0026quot;, \u0026quot;not\u0026quot;, \u0026quot;to\u0026quot;, \u0026quot;be\u0026quot;, \u0026quot;...\u0026quot;]„ÄÇ ÁªüËÆ°ËØçÈ¢ë \u0026amp; ÊûÑÂª∫ËØçÂÖ∏\nËØçÈ¢ëÁªüËÆ° Áî®ÂìàÂ∏åË°®/Â≠óÂÖ∏ËÆ∞ÂΩïÊØè‰∏™ÂçïËØçÂá∫Áé∞Ê¨°Êï∞„ÄÇ ÈÅçÂéÜÊñáÊú¨Êó∂ÔºåËã•ÂçïËØçÂ∞öÊú™ÂÖ•Ë°®ÔºåÂàôÊñ∞Âª∫ËÆ∞ÂΩïÔºõËã•Â∑≤Â≠òÂú®ÔºåÂàôËÆ°Êï∞+1„ÄÇ ÊéíÂ∫è‰∏éÁ¥¢Âºï ÊåâËØçÈ¢ëÈôçÂ∫èÊéíÂ∫èÔºåËØçÈ¢ëÊúÄÈ´òÁöÑÂçïËØçÊéíÂú®ÂâçÈù¢„ÄÇ Á¥¢Âºï‰ªé1ÂºÄÂßãÔºå0ÁïôÁªô‚ÄúÊú™Áü•‚Äù„ÄÇ ËØçÂÖ∏ËßÑÊ®°ÔºàvocabularyÔºâÂèØËßÜÈúÄÊ±ÇÊà™Êñ≠Ôºà‰æãÂ¶ÇÂè™‰øùÁïôTop 10kÔºâ„ÄÇ ‰∏∫‰ªÄ‰πàÁßªÈô§‰ΩéÈ¢ëËØç ‰ΩéÈ¢ëËØçÂèØËÉΩÊòØÊãºÂÜôÈîôËØØ„ÄÅÁΩïËßÅ‰∫∫ÂêçÁ≠âÔºåÂØπÊ®°ÂûãÂ∏ÆÂä©ÊúâÈôê„ÄÇ ÂáèÂ∞ëËØçÂÖ∏ËßÑÊ®°ÂèØÈôç‰ΩéËøêÁÆóÂºÄÈîÄ„ÄÅÂä†Âø´Ê®°ÂûãËÆ≠ÁªÉ‰∏éÊé®ÁêÜÈÄüÂ∫¶„ÄÇ Áã¨ÁÉ≠ÁºñÁ†Å (One-Hot Encoding)\nÂ∞ÜÊØè‰∏™ÂçïËØçÊò†Â∞Ñ‰∏∫ËØçÂÖ∏‰∏≠ÁöÑÁ¥¢ÂºïÂêéÔºàÂ¶Ç [2, 4, 1, 8, ‚Ä¶]ÔºâÔºåÂèØËøõ‰∏ÄÊ≠•ËΩ¨Êç¢ÊàêOne-HotÂêëÈáè„ÄÇ One-HotÁª¥Â∫¶ÂèñÂÜ≥‰∫é‰øùÁïô‰∏ãÊù•ÁöÑËØçÂÖ∏Â§ßÂ∞èÔºà‰æãÂ¶Ç1‰∏áÔºâ„ÄÇ Êú™Êî∂ÂΩïÂçïËØçÂèØËÉΩÁõ¥Êé•ÂøΩÁï•ÔºåÊàñÁªü‰∏ÄÁî®Á¥¢Âºï0‰ª£Êõø„ÄÇ Âõõ„ÄÅÊ†∏ÂøÉÊî∂Ëé∑‰∏éÂ∫îÁî® Á±ªÂà´ÁâπÂæÅÂøÖÈúÄÊï∞ÂÄºÂåñÔºö\n‰ΩøÁî®Êï¥Êï∞1,2,3‚Ä¶‰ªÖË°®Á§∫Á±ªÂà´‚ÄúÊ†áËØÜ‚ÄùÔºåÂπ∂‰∏ç‰ª£Ë°®ÂÆÉ‰ª¨ÂèØËøõË°åÊï∞ÂÄºËøêÁÆó„ÄÇ Âõ†Ê≠§ÈúÄË¶ÅOne-HotÁ≠âÁºñÁ†ÅÊñπÂºèÔºåÈÅøÂÖçÊï∞ÂÄºËØØËß£„ÄÇ ÊñáÊú¨Êï∞ÊçÆÈ¢ÑÂ§ÑÁêÜÔºö\nÂàÜËØç„ÄÅËØçÈ¢ëÁªüËÆ°„ÄÅÊûÑÂª∫ËØçÂÖ∏„ÄÅÁ¥¢ÂºïÂåñ„ÄÅOne-HotÊàñÂÖ∂‰ªñÊñπÂºèÔºàÂ¶ÇËØçÂµåÂÖ•ÔºâÊòØÂ∏∏ËßÅÊµÅÁ®ã„ÄÇ Ê≠£Á°ÆÁöÑÊñáÊú¨È¢ÑÂ§ÑÁêÜÂèØÊòæËëóÂΩ±ÂìçÊ®°ÂûãÊÄßËÉΩÂíåÊïàÁéá„ÄÇ ‰øùÁïôÊú™Áü•Á¥¢ÂºïÔºö\n‰øùËØÅÂØπÁº∫Â§±Êï∞ÊçÆÊàñÂ≠óÂÖ∏Â§ñÊñ∞ËØçËÉΩÊúâÂü∫Êú¨ÁöÑË°®Á§∫ÔºåÊèêÂçáÊ®°ÂûãÂÆπÈîôÊÄß„ÄÇ ÂÆûÈôÖ‰ΩøÁî®Ôºö\nÂØπ‰∫éÂ∞èËßÑÊ®°Á±ªÂà´ÂèØÁõ¥Êé•One-HotÁºñÁ†ÅÔºõÂØπ‰∫éËØçÂÖ∏ÂæàÂ§ßÁöÑÂú∫ÊôØÔºåÈÄöÂ∏∏‰ºöËøõ‰∏ÄÊ≠•ËÄÉËôëËØçÂµåÂÖ•ÔºàWord EmbeddingÔºâÊàñÈ¢ÑËÆ≠ÁªÉËØ≠Ë®ÄÊ®°Âûã„ÄÇ ","permalink":"http://localhost:1313/posts/nlp-1/","summary":"\u003ch2 id=\"‰∏ÄÊï∞ÂÄºÁâπÂæÅ‰∏éÁ±ªÂà´ÁâπÂæÅ\"\u003e‰∏Ä„ÄÅÊï∞ÂÄºÁâπÂæÅ‰∏éÁ±ªÂà´ÁâπÂæÅ\u003c/h2\u003e\n\u003col\u003e\n\u003cli\u003e\u003cstrong\u003eÊï∞ÂÄºÁâπÂæÅ (Numeric Features)\u003c/strong\u003e\n\u003cul\u003e\n\u003cli\u003eÂÖ∑ÊúâÂèØÂä†ÂáèÁöÑÊÑè‰πâÔºå‰∏îÂ≠òÂú®Â§ßÂ∞èÈ°∫Â∫è„ÄÇ\u003c/li\u003e\n\u003cli\u003e‰æãÂ≠êÔºöÂπ¥ÈæÑ„ÄÅÊ∏©Â∫¶Á≠â„ÄÇÂèØ‰ª•Áõ¥Êé•‰øùÁïôÂÖ∂Êï¥Êï∞ÊàñÊµÆÁÇπÊï∞ÂΩ¢Âºè‰æõÊ®°Âûã‰ΩøÁî®„ÄÇ\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003eÁ±ªÂà´ÁâπÂæÅ (Categorical Features)\u003c/strong\u003e\n\u003cul\u003e\n\u003cli\u003eÊï∞ÊçÆÂÄºÁ¶ªÊï£Ôºå‰∏çÂÖ∑Â§á‚ÄúÊï∞ÂÄºÂ§ßÂ∞è‚ÄùÈó¥ÁöÑÂèØÊØîÊÑè‰πâ„ÄÇ\u003c/li\u003e\n\u003cli\u003e‰æãÂ≠êÔºöÂõΩÁ±çÔºàÁæéÂõΩ/‰∏≠ÂõΩ/Âç∞Â∫¶Á≠âÔºâ„ÄÅÊÄßÂà´ÔºàÁî∑/Â•≥ÔºâÁ≠â„ÄÇ\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003eÈóÆÈ¢ò\u003c/strong\u003eÔºöËã•‰ªÖÁî®Êï¥Êï∞Ë°®Á§∫ÔºàÁæéÂõΩ=1, ‰∏≠ÂõΩ=2ÔºâÔºå‰ºöÂºïÂÖ•ÈîôËØØÁöÑÊï∞ÂÄºËøêÁÆóÂÖ≥Á≥ªÔºåÂ¶Ç ‚ÄúÁæéÂõΩ + ‰∏≠ÂõΩ = Âç∞Â∫¶‚Äù„ÄÇ\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003c/ol\u003e\n\u003ch2 id=\"‰∫åone-hotÁºñÁ†ÅÁöÑÂä®Êú∫‰∏éÊµÅÁ®ã\"\u003e‰∫å„ÄÅOne-HotÁºñÁ†ÅÁöÑÂä®Êú∫‰∏éÊµÅÁ®ã\u003c/h2\u003e\n\u003col\u003e\n\u003cli\u003e\n\u003cp\u003e\u003cstrong\u003e‰∏∫‰ªÄ‰πà‰ΩøÁî®One-Hot\u003c/strong\u003e\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eÈÄöËøáÂ∞ÜÁ±ªÂà´Êò†Â∞Ñ‰∏∫ÂêëÈáèÔºåÈÅøÂÖçÊï¥Êï∞ÁºñÁ†ÅÂºïÂÖ•ÁöÑ‰º™Êï∞ÂÄºÂÖ≥Á≥ª„ÄÇ\u003c/li\u003e\n\u003cli\u003eÂêåÊó∂‰øùÁïôÂêÑÁßçÂèØËÉΩÁ±ªÂà´ÁöÑ‰ø°ÊÅØÔºå‰∏î‰ªÖÂú®ÂØπÂ∫î‰ΩçÁΩÆ‰∏∫1ÔºåÂÖ∂‰ªñ‰ΩçÁΩÆ‰∏∫0„ÄÇ\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003e\u003cstrong\u003eÂª∫Á´ãÊò†Â∞ÑÔºö‰ªéÁ±ªÂà´Âà∞Á¥¢Âºï\u003c/strong\u003e\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e‰∏∫ÊØè‰∏™Á±ªÂà´ÂàÜÈÖç‰∏Ä‰∏™ÂîØ‰∏ÄÁ¥¢ÂºïÔºåÈÄöÂ∏∏‰ªé1ÂºÄÂßã„ÄÇ\u003c/li\u003e\n\u003cli\u003eÈ¢ÑÁïôÁ¥¢Âºï0Ë°®Á§∫‚ÄúÊú™Áü•‚ÄùÊàñ‚ÄúÁº∫Â§±‚ÄùÔºåÂØπÂ∫îÂÖ®0ÂêëÈáè„ÄÇ\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003e\u003cstrong\u003eËΩ¨Êç¢‰∏∫One-HotÂêëÈáè\u003c/strong\u003e\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eËã•Á±ªÂà´ÊÄªÊï∞‰∏∫197ÔºåÂàôÁî®197Áª¥ÂêëÈáèË°®Á§∫„ÄÇ\u003c/li\u003e\n\u003cli\u003e‰æãÂ≠êÔºöÁæéÂõΩ \u003ccode\u003e[1, 0, 0, 0, ‚Ä¶]\u003c/code\u003eÔºå ‰∏≠ÂõΩ \u003ccode\u003e[0, 1, 0, 0, ‚Ä¶]\u003c/code\u003e„ÄÇ\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003e\u003cstrong\u003eÁ§∫‰æãÔºöË°®Á§∫‰∏Ä‰∏™‰∫∫ÁöÑÁâπÂæÅ\u003c/strong\u003e\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eÁâπÂæÅÂåÖÂê´ÔºàÂπ¥ÈæÑ, ÊÄßÂà´, ÂõΩÁ±çÔºåÂÖ∂‰∏≠ÂõΩÁ±ç197ÁßçÔºâ\u003c/li\u003e\n\u003cli\u003eÁª¥Â∫¶ÊÄªÂíåÔºö1Áª¥_age + 1Áª¥_gender + 197Áª¥_nationality = 199Áª¥„ÄÇ\u003c/li\u003e\n\u003cli\u003e‰æãÂ¶Ç \u003ccode\u003e(28, Â•≥, ‰∏≠ÂõΩ)\u003c/code\u003e ‚Üí \u003ccode\u003e[28, 0, 0, 1, 0, ‚Ä¶, 0]\u003c/code\u003e„ÄÇ\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003c/ol\u003e\n\u003ch2 id=\"‰∏âÊñáÊú¨Êï∞ÊçÆÂ§ÑÁêÜÊµÅÁ®ã\"\u003e‰∏â„ÄÅÊñáÊú¨Êï∞ÊçÆÂ§ÑÁêÜÊµÅÁ®ã\u003c/h2\u003e\n\u003cp\u003eÊñáÊú¨Âú®Ëá™ÁÑ∂ËØ≠Ë®ÄÂ§ÑÁêÜÔºàNLPÔºâ‰∏≠‰Ωú‰∏∫Â∏∏ËßÅÁöÑÂéüÂßãËæìÂÖ•ÔºåÈúÄË¶ÅÊï∞ÂÄºÂåñÊâçËÉΩÈÄÅÂÖ•Ê®°Âûã„ÄÇ‰∏ÄËà¨Ê≠•È™§Â¶Ç‰∏ãÔºö\u003c/p\u003e\n\u003col\u003e\n\u003cli\u003e\n\u003cp\u003e\u003cstrong\u003eÂàÜËØç (Tokenization)\u003c/strong\u003e\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eÂ∞ÜÊñáÊú¨ÊãÜÂàÜ‰∏∫‰∏Ä‰∏™‰∏™ÂçïËØçÔºàTokenÔºâ„ÄÇ\u003c/li\u003e\n\u003cli\u003e‰æãÂ≠êÔºö\u003ccode\u003e\u0026quot;... to be or not to be...\u0026quot;\u003c/code\u003e ‚Üí \u003ccode\u003e[\u0026quot;...\u0026quot;, \u0026quot;to\u0026quot;, \u0026quot;be\u0026quot;, \u0026quot;or\u0026quot;, \u0026quot;not\u0026quot;, \u0026quot;to\u0026quot;, \u0026quot;be\u0026quot;, \u0026quot;...\u0026quot;]\u003c/code\u003e„ÄÇ\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003e\u003cstrong\u003eÁªüËÆ°ËØçÈ¢ë \u0026amp; ÊûÑÂª∫ËØçÂÖ∏\u003c/strong\u003e\u003c/p\u003e","title":""},{"content":"Text to Sequence ÊñáÊú¨Â§ÑÁêÜ\nStep1: Tokenization\nTokenization breaks a piece of text down into a list of tokens.\nHere, a token is a word. (A token can be a character in some applications.)\nTokenizationËÆ≤Á©∂ÂæàÂ§öÔºå‰æãÂ¶ÇÊòØÂê¶Â∫îËØ•ÊääÂ§ßÂÜôÊîπÊàêÂ∞èÂÜôÂë¢ÔºüËøõË°åtypo correctionÁ≠âÁ≠â\nStep2: Build Dictionary\nUse a dictionary (hash table) to count word frequencies.\nThe dictionary maps word to index.\nÂèØ‰ª•È¶ñÂÖàÁªüËÆ°ËØçÈ¢ëÂéªÊéâ‰ΩéÈ¢ëËØçÔºåÁÑ∂ÂêéËÆ©ÊØè‰∏™ËØçÂØπÂ∫î‰∏Ä‰∏™Ê≠£Êï¥Êï∞ÔºõËøôÊ†∑ÁöÑËØùÔºå‰∏ÄÂè•ËØùÂ∞±ÂèØ‰ª•Áî®‰∏Ä‰∏™Ê≠£Êï¥Êï∞ÂàóË°®Ë°®Á§∫ÔºåËøô‰∏™ÂàóË°®Â∞±Âè´sequenceÔºõÂ¶ÇÊûúÂøÖË¶ÅÂ∞±ËøòÂæóÂÅöone-hot encoding„ÄÇ\nÁªìÊûú\n‰ΩÜÊòØÈïøÂ∫¶‰∏çÁªü‰∏Ä\nStep4: ÂØπÈΩêsequence\nËß£ÂÜ≥ÊñπÊ°àÊòØËøôÊ†∑ÁöÑÔºöÂèØ‰ª•Âõ∫ÂÆöÈïøÂ∫¶‰∏∫wÔºåÂä†ÂÖ•‰∏Ä‰∏™Â∫èÂàóÈïøÂ∫¶Â§™ÈïøÔºåÂ∞±Á†çÊéâÂâçÈù¢ÁöÑËØçÔºåÂè™‰øùÁïôÊúÄÂêéw‰∏™ËØçÔºõÂ¶ÇÊûú‰∏Ä‰∏™Â∫èÂàóÂ§™Áü≠ÔºåÂ∞±ÂÅözero paddingÔºåÁî®0Â°´ÂÖÖ\nËøôÊ†∑‰∏ÄÊù•ÔºåÊâÄÊúâÁöÑÂ∫èÂàóÈïøÂ∫¶Â∞±Áªü‰∏Ä‰∫Ü\nÊñáÊú¨Â§ÑÁêÜÂÆåÊàê‰∫ÜÔºåÊé•‰∏ãÊù•ÊòØword embeddingÔºåÊääÂçïËØçË°®Á§∫‰∏∫‰∏Ä‰∏™‰ΩéÁª¥ÂêëÈáèÔºõ\nÁÑ∂ËÄåËøôÊ†∑ÂÅöÁöÑËØùÔºåÂ¶ÇÊûúÊòØ10000‰∏™ÂçïËØçÔºåÁª¥Â∫¶Â∞±ÊòØ10000Áª¥ÔºåÁª¥Â∫¶Â§™È´ò‰∫ÜÔºõÂõ†Ê≠§Ë¶ÅÂÅöword embeddingÔºõ\nÂÖ∑‰ΩìÂÅöÊ≥ïÂ∞±ÊòØÊääone-hotÂêëÈáèe_iÂíåÂèÇÊï∞Áü©ÈòµpÁõ∏‰πòÔºõÁü©ÈòµPËΩ¨ÁΩÆÁöÑÂ§ßÂ∞èÊòØd x vÔºõdÊòØËØçÂêëÈáèÁöÑÁª¥Â∫¶ÔºõvÊòØÂ≠óÂÖ∏ÈáåËØçÊ±áÁöÑÊï∞ÈáèÔºõÁªìÊûú‰∏∫x_iÔºõx_iÂ∞±ÊòØ‰∏Ä‰∏™ËØçÂêëÈáèÔºõÂ¶ÇÊûúone-hotÂêëÈáèÁöÑÁ¨¨‰∏âË°å‰∏∫1ÔºõÈÇ£‰πàx_iÂ∞±ÊòØPËΩ¨ÁΩÆÁü©ÈòµÁöÑÁ¨¨‰∏âÂàóÔºàÂÖ∂‰ΩôÂàóÈÉΩ‰∏∫0ÔºâÔºõÊâÄ‰ª•PËΩ¨ÁΩÆÊØè‰∏ÄÂàóÈÉΩÊòØ‰∏Ä‰∏™ËØçÂêëÈáèÔºõÊâÄ‰ª•Áü©ÈòµPÊú¨Ë∫´ÁöÑÊØè‰∏ÄË°åÂ∞±ÊòØ‰∏Ä‰∏™ËØçÂêëÈáèÔºõÂÖ∂Ë°åÊï∞‰∏∫vÔºõÂç≥vocabularyÔºåËØçÊ±áÈáèÔºõÊØè‰∏ÄË°åÂØπÂ∫î‰∏Ä‰∏™ÂçïËØçÔºõÁü©ÈòµÁöÑÂàóÊï∞‰∏∫dÔºõdÊòØÁî®Êà∑ÂÜ≥ÂÆöÁöÑÔºõdÁöÑÂ§ßÂ∞è‰ºöÂÜ≥ÂÆöÊú∫Âô®Â≠¶‰π†Ê®°ÂûãÁöÑË°®Áé∞ÔºõÂ∫îËØ•Áî®xxxÊù•ÈÄâÊã©‰∏Ä‰∏™ÊØîËæÉÂ•ΩÁöÑdÔºõ\nÊàë‰ª¨ÁöÑ‰ªªÂä°ÊòØÁúãËØÑËÆ∫ÊòØÊ≠£Èù¢ÁöÑËøòÊòØË¥üÈù¢ÁöÑÔºõÂèÇÊï∞Áü©ÈòµÊòØ‰ªéËÆ≠ÁªÉÊï∞ÊçÆ‰∏≠Â≠¶‰π†Âá∫Êù•ÁöÑÔºåÊâÄ‰ª•Â≠¶Âá∫Êù•ÁöÑËØçÂêëÈáèÊòØÂ∏¶ÊúâÊÑüÊÉÖËâ≤ÂΩ©ÁöÑÔºõÂÅáËÆæËøô‰∫õËØçÂêëÈáèÈÉΩÊòØ‰∫åÁª¥ÁöÑÔºåÂàôÂèØ‰ª•Âú®Âπ≥Èù¢ÂùêÊ†áÁ≥ª‰∏≠Ê†áÂá∫‰∏ãÈù¢ËØçÂêëÈáè\nkerasÊèê‰æõembeddingÂ±ÇÔºõÁî®Êà∑ÂèØ‰ª•ÊåáÂÆövocabularyÂ§ßÂ∞èÂíådÁöÑÂ§ßÂ∞èÔºõ‰ª•ÂèäÊØè‰∏Ä‰∏™sequenceÁöÑÈïøÂ∫¶ÔºõdÊòØÊ†πÊçÆÁÆóÊ≥ïÈÄâÂá∫Êù•ÁöÑ Âà∞Ëøô‰∏ÄÊ≠•ÔºåÊàë‰ª¨Â∑≤ÁªèÂÆåÊàê‰∫ÜÊñáÊú¨Â§ÑÁêÜÂíåword embedding„ÄÇÊé•‰∏ãÊù•Â∞±ÊòØÁî®Logistic Regression for Binary ClassificationÂÅö‰∫åÂàÜÁ±ªÔºõ\n","permalink":"http://localhost:1313/posts/nlp-2/","summary":"\u003ch3 id=\"text-to-sequence\"\u003eText to Sequence\u003c/h3\u003e\n\u003cp\u003eÊñáÊú¨Â§ÑÁêÜ\u003c/p\u003e\n\u003cp\u003eStep1: Tokenization\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\n\u003cp\u003eTokenization breaks a piece of text down into a list of tokens.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003eHere, a token is a word. (A token can be a character in some applications.)\u003c/p\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003eTokenizationËÆ≤Á©∂ÂæàÂ§öÔºå‰æãÂ¶ÇÊòØÂê¶Â∫îËØ•ÊääÂ§ßÂÜôÊîπÊàêÂ∞èÂÜôÂë¢ÔºüËøõË°åtypo correctionÁ≠âÁ≠â\u003c/p\u003e\n\u003cp\u003e\u003cimg alt=\"image-20250322150322238\" loading=\"lazy\" src=\"./NLP-2.assets/image-20250322150322238.png\"\u003e\u003c/p\u003e\n\u003cp\u003eStep2: Build Dictionary\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\n\u003cp\u003eUse a dictionary (hash table) to count word frequencies.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003eThe dictionary maps word to index.\u003c/p\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003eÂèØ‰ª•È¶ñÂÖàÁªüËÆ°ËØçÈ¢ëÂéªÊéâ‰ΩéÈ¢ëËØçÔºåÁÑ∂ÂêéËÆ©ÊØè‰∏™ËØçÂØπÂ∫î‰∏Ä‰∏™Ê≠£Êï¥Êï∞ÔºõËøôÊ†∑ÁöÑËØùÔºå‰∏ÄÂè•ËØùÂ∞±ÂèØ‰ª•Áî®‰∏Ä‰∏™Ê≠£Êï¥Êï∞ÂàóË°®Ë°®Á§∫ÔºåËøô‰∏™ÂàóË°®Â∞±Âè´sequenceÔºõÂ¶ÇÊûúÂøÖË¶ÅÂ∞±ËøòÂæóÂÅöone-hot encoding„ÄÇ\u003cimg alt=\"image-20250322150620890\" loading=\"lazy\" src=\"./NLP-2.assets/image-20250322150620890.png\"\u003e\u003c/p\u003e\n\u003cp\u003eÁªìÊûú\u003c/p\u003e\n\u003cp\u003e\u003cimg alt=\"image-20250322150754528\" loading=\"lazy\" src=\"./NLP-2.assets/image-20250322150754528.png\"\u003e\u003c/p\u003e\n\u003cp\u003e‰ΩÜÊòØÈïøÂ∫¶‰∏çÁªü‰∏Ä\u003c/p\u003e\n\u003cp\u003eStep4: ÂØπÈΩêsequence\u003c/p\u003e\n\u003cp\u003e\u003cimg alt=\"image-20250322150854986\" loading=\"lazy\" src=\"./NLP-2.assets/image-20250322150854986.png\"\u003e\u003c/p\u003e\n\u003cp\u003eËß£ÂÜ≥ÊñπÊ°àÊòØËøôÊ†∑ÁöÑÔºöÂèØ‰ª•Âõ∫ÂÆöÈïøÂ∫¶‰∏∫wÔºåÂä†ÂÖ•‰∏Ä‰∏™Â∫èÂàóÈïøÂ∫¶Â§™ÈïøÔºåÂ∞±Á†çÊéâÂâçÈù¢ÁöÑËØçÔºåÂè™‰øùÁïôÊúÄÂêéw‰∏™ËØçÔºõÂ¶ÇÊûú‰∏Ä‰∏™Â∫èÂàóÂ§™Áü≠ÔºåÂ∞±ÂÅözero paddingÔºåÁî®0Â°´ÂÖÖ\u003c/p\u003e\n\u003cp\u003e\u003cimg alt=\"image-20250322151030119\" loading=\"lazy\" src=\"./NLP-2.assets/image-20250322151030119.png\"\u003e\u003c/p\u003e\n\u003cp\u003eËøôÊ†∑‰∏ÄÊù•ÔºåÊâÄÊúâÁöÑÂ∫èÂàóÈïøÂ∫¶Â∞±Áªü‰∏Ä‰∫Ü\u003c/p\u003e\n\u003cp\u003e\u003cimg alt=\"image-20250322151117125\" loading=\"lazy\" src=\"./NLP-2.assets/image-20250322151117125.png\"\u003e\u003c/p\u003e\n\u003cp\u003eÊñáÊú¨Â§ÑÁêÜÂÆåÊàê‰∫ÜÔºåÊé•‰∏ãÊù•ÊòØword embeddingÔºåÊääÂçïËØçË°®Á§∫‰∏∫‰∏Ä‰∏™‰ΩéÁª¥ÂêëÈáèÔºõ\u003c/p\u003e\n\u003cp\u003e\u003cimg alt=\"image-20250322151252837\" loading=\"lazy\" src=\"./NLP-2.assets/image-20250322151252837.png\"\u003e\u003c/p\u003e","title":""},{"content":"üëã About me Hello! I\u0026rsquo;m Xu Zongsi, a passionate technology enthusiast currently pursuing my Master of Science in ECIC at The University of Hong Kong. With a solid background in Software Engineering from the Beijing Institute of Technology, I specialize in artificial intelligence areas like machine learning, deep learning, natural language processing, computer vision, and reinforcement learning.\nInspired by OpenAI\u0026rsquo;s five-step plan towards superintelligence, I am excited about AGI and have developed a keen interest in LLM agents, MLLM, and knowledge graphs. I see great potential in these fields and aspire to contribute to innovative solutions.\nüìö Education üá≠üá∞ The University of Hong Kong 09/2024 - Expected 11/2025 School of Computing and Data Science Master of Science in Electronic Commerce \u0026amp; Internet Computing Relevant Courses: Machine learning for business and e-commerce, Knowledge graphs, Financial fraud analytics, Internet infrastructure technologies, Website engineering, Blockchain and cryptocurrency, etc. üá®üá≥ Beijing Institute of Technology 09/2020 - 06/2024 School of Computer Science \u0026amp; Technology Bachelor of Engineering in Software Engineering, last two years GPA: 3.7/4 Relevant Courses: Reinforcement Learning, Deep Learning and Computer Vision, Artificial Intelligence and Robot Ethics, Almost Human: Mind, Brain and Artificial Intelligence, Mathematical Analysis for Engineering, Linear Algebra, Probability and Mathematical Statistics, etc. Skills: Python, Java, common data structures, design patterns, machine learning basics and algorithms, Linux, PyTorch, and some development tools (git, conda, etc.). üèÜ Awards \u0026amp; Honors Beijing Institute of Technology Undergraduate Scholarship (Top 20% of Grade) 06/2023 3rd Prize of China International \u0026#34;Internet \u0026#43;\u0026#34; College Student\u0026#39;s Innovation Competition 08/2022 Bronze Prize of \u0026#34;Challenge Cup\u0026#34; Capital University Entrepreneurship Competition 05/2022 üíº Project Experience üîç Online Transaction Fraud Detection 09/2024 ‚Äì 01/2025 Independent project, supervised by Dr. Vivien Chan Focused on addressing financial fraud in e-commerce to enhance the accuracy of transaction anomaly detection, while independently managing the entire case study that included data preprocessing, feature engineering, model building, evaluation, and results analysis. Effectively resolved class imbalance issues using SMOTE and ROSE techniques. Built various models including Logistic Regression, Random Forest, XGBoost, and LightGBM, ultimately selecting the LightGBM model to achieve a recall rate of 95.45% and an AUC of 99.84%. Wrote efficient and maintainable code, enhancing model training and data processing efficiency through parallel computing and logging. ü§ñ Multi-Model Intelligent Text Keyword Extraction System 08/2023 ‚Äì 09/2023 Group project, supervised by Associate Prof. Xiaolin Zhao Designed and implemented an intelligent text summary system that automatically extracts keywords from article titles and abstracts, enhancing the understanding and summarization of text information. Participated in the planning of the technical route and built a hybrid model combining extractive and generative approaches, utilizing advanced natural language processing techniques including KeyBERT, Sentence Transformer, BERT, and T5 models. Responsible for data preprocessing and tokenization, as well as the end-to-end implementation and training of the T5 model, optimizing the model architecture and hyperparameters, achieving satisfactory results after only 3 epochs of training. Model evaluation results showed that the Rouge-1, Rouge-2, and Rouge-L metrics reached 0.6345, 0.5038, and 0.5282, respectively, in the third epoch, validating the model\u0026rsquo;s effectiveness in the summarization task. üéì Cambridge University Machine Learning Summer Project 07/2023 ‚Äì 08/2023 Group project, supervised by Prof. Pietro Li√≤ Participated in the Cambridge University deep learning summer project, focusing on deep reinforcement learning; explored multi-agent learning algorithms across different environments. Reproduced the Multi-Agent Deep Deterministic Policy Gradient (MADDPG) algorithm in the Simple Adversary environment and studied the effect of agent numbers on convergence speed and stability, finding optimal stability at 21 agents. Designed and implemented comparative experiments inspired by the Rainbow algorithm, assessing target network strategies versus the Double Deep Q-Network (Double DQN). The results demonstrated that Double DQN significantly enhanced convergence speed, optimizing the overall learning process. Co-authored a group project paper on agent numbers and strategies effectiveness in multi-agent systems, achieving a score of 71% in the summer program (the highest in my group) and a \u0026ldquo;First Class\u0026rdquo; classification in the UK grading system. üëÅÔ∏è Deep Learning and Computer Vision Semester Project 09/2022 ‚Äì 12/2022 Independent project, supervised by Associate Prof. Guangyu Gao Designed and implemented a waste classifier using the ResNet model to improve classification accuracy and reduce resource waste. The project also enhanced understanding of transfer learning techniques with ResNet. Collected a dataset of 16 waste categories and preprocessed the images for uniformity and standardization, incorporating data augmentation techniques to enhance the dataset. Conducted experiments using ResNet34 and ResNet50 models through transfer learning, accelerating network convergence by leveraging pretrained weights. During training, techniques such as Batch Normalization and Dropout were applied to mitigate the risk of overfitting. The final model achieved an accuracy of 90% on the training set, while the performance on the test set was 61%, indicating a significant overfitting phenomenon during the training process. üéì Internship ‚öõÔ∏è Beijing Academy of Quantum Information Science 08/2023 ‚Äì 01/2024 Research Intern at Quantum Computation Department Proposed a quantum convolution kernel design based on variational quantum circuits and developed a universal quantum convolution layer, successfully integrating it into classical CNN architectures such as VGG, GoogLeNet, and ResNet. Developed and evaluated various hybrid models, including a simple model named HQCCNN-2, which achieved 84.45% accuracy on the FashionMNIST dataset, surpassing the traditional CNN\u0026rsquo;s 80.72%. This demonstrates the effectiveness of the quantum convolution layer in improving model performance. Tested on a real quantum computer further validated the effectiveness of the hybrid model, demonstrating the viable integration of quantum computing with deep learning, and highlighting the potential for leveraging quantum properties to enhance model performance. üèÖ Competition Experience ü•â China International \u0026#34;Internet \u0026#43;\u0026#34; College Students\u0026#39; Innovation Competition 08/2022 üõ°Ô∏è Zhongke Ushield: Deep Learning-based Face Privacy Protection Authentication System Responsible for constructing a localized facial feature extraction engine based on MobileFaceNet, ensuring feature extraction is completed on end devices (such as mobile phones and cameras), guaranteeing that raw data does not leave the domain and is not stored, thus enhancing user privacy protection while improving recognition efficiency. ü•â \u0026#34;Challenge Cup\u0026#34; Capital University Entrepreneurship Competition 05/2022 üå≥ Smart Orchard Responsible for the development of the fruit detection, ripeness prediction, and pest identification system, using deep convolutional neural network (CNN) technology for intelligent monitoring of crop growth conditions. Applied advanced object detection algorithms such as Faster R-CNN and YOLO to achieve high precision in apple detection and ripeness assessment, with an accuracy rate exceeding 90%, significantly enhancing the intelligence level of orchard management. Built and trained a dedicated dataset containing various pest samples, optimizing pest detection accuracy through data preprocessing (such as image normalization and resizing) and data augmentation techniques (like rotation, flipping, and noise addition), enabling the real-time monitoring system to accurately identify over 80% of pests, providing effective scientific maintenance recommendations to help farmers reduce crop losses. üìã Extracurricular Activities Vice President, Cyber Security Club, Beijing Institute of Technology 09/2021-09/2022 Backbone, Media Center of the Student Union of Beijing Institute of Technology 10/2020-06/2021 üì´ Contact üìß Email: zongsi.xu@outlook.com üëî LinkedIn: Zongsi (Tristan) Xu üíª GitHub: BaizeXS üìç Location: Hong Kong SAR, China ","permalink":"http://localhost:1313/resume/","summary":"Personal resume of Zongsi (Tristan) Xu","title":"Zongsi (Tristan) Xu"},{"content":"‰∏Ä„ÄÅÊï∞ÂÄºÁâπÂæÅ‰∏éÁ±ªÂà´ÁâπÂæÅ Êï∞ÂÄºÁâπÂæÅ (Numeric Features) ÂÖ∑ÊúâÂèØÂä†ÂáèÁöÑÊÑè‰πâÔºå‰∏îÂ≠òÂú®Â§ßÂ∞èÈ°∫Â∫è„ÄÇ ‰æãÂ≠êÔºöÂπ¥ÈæÑ„ÄÅÊ∏©Â∫¶Á≠â„ÄÇÂèØ‰ª•Áõ¥Êé•‰øùÁïôÂÖ∂Êï¥Êï∞ÊàñÊµÆÁÇπÊï∞ÂΩ¢Âºè‰æõÊ®°Âûã‰ΩøÁî®„ÄÇ Á±ªÂà´ÁâπÂæÅ (Categorical Features) Êï∞ÊçÆÂÄºÁ¶ªÊï£Ôºå‰∏çÂÖ∑Â§á‚ÄúÊï∞ÂÄºÂ§ßÂ∞è‚ÄùÈó¥ÁöÑÂèØÊØîÊÑè‰πâ„ÄÇ ‰æãÂ≠êÔºöÂõΩÁ±çÔºàÁæéÂõΩ/‰∏≠ÂõΩ/Âç∞Â∫¶Á≠âÔºâ„ÄÅÊÄßÂà´ÔºàÁî∑/Â•≥ÔºâÁ≠â„ÄÇ ÈóÆÈ¢òÔºöËã•‰ªÖÁî®Êï¥Êï∞Ë°®Á§∫ÔºàÁæéÂõΩ=1, ‰∏≠ÂõΩ=2ÔºâÔºå‰ºöÂºïÂÖ•ÈîôËØØÁöÑÊï∞ÂÄºËøêÁÆóÂÖ≥Á≥ªÔºåÂ¶Ç ‚ÄúÁæéÂõΩ + ‰∏≠ÂõΩ = Âç∞Â∫¶‚Äù„ÄÇ ‰∫å„ÄÅOne-HotÁºñÁ†ÅÁöÑÂä®Êú∫‰∏éÊµÅÁ®ã ‰∏∫‰ªÄ‰πà‰ΩøÁî®One-Hot\nÈÄöËøáÂ∞ÜÁ±ªÂà´Êò†Â∞Ñ‰∏∫ÂêëÈáèÔºåÈÅøÂÖçÊï¥Êï∞ÁºñÁ†ÅÂºïÂÖ•ÁöÑ‰º™Êï∞ÂÄºÂÖ≥Á≥ª„ÄÇ ÂêåÊó∂‰øùÁïôÂêÑÁßçÂèØËÉΩÁ±ªÂà´ÁöÑ‰ø°ÊÅØÔºå‰∏î‰ªÖÂú®ÂØπÂ∫î‰ΩçÁΩÆ‰∏∫1ÔºåÂÖ∂‰ªñ‰ΩçÁΩÆ‰∏∫0„ÄÇ Âª∫Á´ãÊò†Â∞ÑÔºö‰ªéÁ±ªÂà´Âà∞Á¥¢Âºï\n‰∏∫ÊØè‰∏™Á±ªÂà´ÂàÜÈÖç‰∏Ä‰∏™ÂîØ‰∏ÄÁ¥¢ÂºïÔºåÈÄöÂ∏∏‰ªé1ÂºÄÂßã„ÄÇ È¢ÑÁïôÁ¥¢Âºï0Ë°®Á§∫‚ÄúÊú™Áü•‚ÄùÊàñ‚ÄúÁº∫Â§±‚ÄùÔºåÂØπÂ∫îÂÖ®0ÂêëÈáè„ÄÇ ËΩ¨Êç¢‰∏∫One-HotÂêëÈáè\nËã•Á±ªÂà´ÊÄªÊï∞‰∏∫197ÔºåÂàôÁî®197Áª¥ÂêëÈáèË°®Á§∫„ÄÇ ‰æãÂ≠êÔºöÁæéÂõΩ [1, 0, 0, 0, ‚Ä¶]Ôºå ‰∏≠ÂõΩ [0, 1, 0, 0, ‚Ä¶]„ÄÇ Á§∫‰æãÔºöË°®Á§∫‰∏Ä‰∏™‰∫∫ÁöÑÁâπÂæÅ\nÁâπÂæÅÂåÖÂê´ÔºàÂπ¥ÈæÑ, ÊÄßÂà´, ÂõΩÁ±çÔºåÂÖ∂‰∏≠ÂõΩÁ±ç197ÁßçÔºâ Áª¥Â∫¶ÊÄªÂíåÔºö1Áª¥_age + 1Áª¥_gender + 197Áª¥_nationality = 199Áª¥„ÄÇ ‰æãÂ¶Ç (28, Â•≥, ‰∏≠ÂõΩ) ‚Üí [28, 0, 0, 1, 0, ‚Ä¶, 0]„ÄÇ ‰∏â„ÄÅÊñáÊú¨Êï∞ÊçÆÂ§ÑÁêÜÊµÅÁ®ã ÊñáÊú¨Âú®Ëá™ÁÑ∂ËØ≠Ë®ÄÂ§ÑÁêÜÔºàNLPÔºâ‰∏≠‰Ωú‰∏∫Â∏∏ËßÅÁöÑÂéüÂßãËæìÂÖ•ÔºåÈúÄË¶ÅÊï∞ÂÄºÂåñÊâçËÉΩÈÄÅÂÖ•Ê®°Âûã„ÄÇ‰∏ÄËà¨Ê≠•È™§Â¶Ç‰∏ãÔºö\nÂàÜËØç (Tokenization)\nÂ∞ÜÊñáÊú¨ÊãÜÂàÜ‰∏∫‰∏Ä‰∏™‰∏™ÂçïËØçÔºàTokenÔºâ„ÄÇ ‰æãÂ≠êÔºö\u0026quot;... to be or not to be...\u0026quot; ‚Üí [\u0026quot;...\u0026quot;, \u0026quot;to\u0026quot;, \u0026quot;be\u0026quot;, \u0026quot;or\u0026quot;, \u0026quot;not\u0026quot;, \u0026quot;to\u0026quot;, \u0026quot;be\u0026quot;, \u0026quot;...\u0026quot;]„ÄÇ ÁªüËÆ°ËØçÈ¢ë \u0026amp; ÊûÑÂª∫ËØçÂÖ∏\nËØçÈ¢ëÁªüËÆ° Áî®ÂìàÂ∏åË°®/Â≠óÂÖ∏ËÆ∞ÂΩïÊØè‰∏™ÂçïËØçÂá∫Áé∞Ê¨°Êï∞„ÄÇ ÈÅçÂéÜÊñáÊú¨Êó∂ÔºåËã•ÂçïËØçÂ∞öÊú™ÂÖ•Ë°®ÔºåÂàôÊñ∞Âª∫ËÆ∞ÂΩïÔºõËã•Â∑≤Â≠òÂú®ÔºåÂàôËÆ°Êï∞+1„ÄÇ ÊéíÂ∫è‰∏éÁ¥¢Âºï ÊåâËØçÈ¢ëÈôçÂ∫èÊéíÂ∫èÔºåËØçÈ¢ëÊúÄÈ´òÁöÑÂçïËØçÊéíÂú®ÂâçÈù¢„ÄÇ Á¥¢Âºï‰ªé1ÂºÄÂßãÔºå0ÁïôÁªô‚ÄúÊú™Áü•‚Äù„ÄÇ ËØçÂÖ∏ËßÑÊ®°ÔºàvocabularyÔºâÂèØËßÜÈúÄÊ±ÇÊà™Êñ≠Ôºà‰æãÂ¶ÇÂè™‰øùÁïôTop 10kÔºâ„ÄÇ ‰∏∫‰ªÄ‰πàÁßªÈô§‰ΩéÈ¢ëËØç ‰ΩéÈ¢ëËØçÂèØËÉΩÊòØÊãºÂÜôÈîôËØØ„ÄÅÁΩïËßÅ‰∫∫ÂêçÁ≠âÔºåÂØπÊ®°ÂûãÂ∏ÆÂä©ÊúâÈôê„ÄÇ ÂáèÂ∞ëËØçÂÖ∏ËßÑÊ®°ÂèØÈôç‰ΩéËøêÁÆóÂºÄÈîÄ„ÄÅÂä†Âø´Ê®°ÂûãËÆ≠ÁªÉ‰∏éÊé®ÁêÜÈÄüÂ∫¶„ÄÇ Áã¨ÁÉ≠ÁºñÁ†Å (One-Hot Encoding)\nÂ∞ÜÊØè‰∏™ÂçïËØçÊò†Â∞Ñ‰∏∫ËØçÂÖ∏‰∏≠ÁöÑÁ¥¢ÂºïÂêéÔºàÂ¶Ç [2, 4, 1, 8, ‚Ä¶]ÔºâÔºåÂèØËøõ‰∏ÄÊ≠•ËΩ¨Êç¢ÊàêOne-HotÂêëÈáè„ÄÇ One-HotÁª¥Â∫¶ÂèñÂÜ≥‰∫é‰øùÁïô‰∏ãÊù•ÁöÑËØçÂÖ∏Â§ßÂ∞èÔºà‰æãÂ¶Ç1‰∏áÔºâ„ÄÇ Êú™Êî∂ÂΩïÂçïËØçÂèØËÉΩÁõ¥Êé•ÂøΩÁï•ÔºåÊàñÁªü‰∏ÄÁî®Á¥¢Âºï0‰ª£Êõø„ÄÇ Âõõ„ÄÅÊ†∏ÂøÉÊî∂Ëé∑‰∏éÂ∫îÁî® Á±ªÂà´ÁâπÂæÅÂøÖÈúÄÊï∞ÂÄºÂåñÔºö\n‰ΩøÁî®Êï¥Êï∞1,2,3‚Ä¶‰ªÖË°®Á§∫Á±ªÂà´‚ÄúÊ†áËØÜ‚ÄùÔºåÂπ∂‰∏ç‰ª£Ë°®ÂÆÉ‰ª¨ÂèØËøõË°åÊï∞ÂÄºËøêÁÆó„ÄÇ Âõ†Ê≠§ÈúÄË¶ÅOne-HotÁ≠âÁºñÁ†ÅÊñπÂºèÔºåÈÅøÂÖçÊï∞ÂÄºËØØËß£„ÄÇ ÊñáÊú¨Êï∞ÊçÆÈ¢ÑÂ§ÑÁêÜÔºö\nÂàÜËØç„ÄÅËØçÈ¢ëÁªüËÆ°„ÄÅÊûÑÂª∫ËØçÂÖ∏„ÄÅÁ¥¢ÂºïÂåñ„ÄÅOne-HotÊàñÂÖ∂‰ªñÊñπÂºèÔºàÂ¶ÇËØçÂµåÂÖ•ÔºâÊòØÂ∏∏ËßÅÊµÅÁ®ã„ÄÇ Ê≠£Á°ÆÁöÑÊñáÊú¨È¢ÑÂ§ÑÁêÜÂèØÊòæËëóÂΩ±ÂìçÊ®°ÂûãÊÄßËÉΩÂíåÊïàÁéá„ÄÇ ‰øùÁïôÊú™Áü•Á¥¢ÂºïÔºö\n‰øùËØÅÂØπÁº∫Â§±Êï∞ÊçÆÊàñÂ≠óÂÖ∏Â§ñÊñ∞ËØçËÉΩÊúâÂü∫Êú¨ÁöÑË°®Á§∫ÔºåÊèêÂçáÊ®°ÂûãÂÆπÈîôÊÄß„ÄÇ ÂÆûÈôÖ‰ΩøÁî®Ôºö\nÂØπ‰∫éÂ∞èËßÑÊ®°Á±ªÂà´ÂèØÁõ¥Êé•One-HotÁºñÁ†ÅÔºõÂØπ‰∫éËØçÂÖ∏ÂæàÂ§ßÁöÑÂú∫ÊôØÔºåÈÄöÂ∏∏‰ºöËøõ‰∏ÄÊ≠•ËÄÉËôëËØçÂµåÂÖ•ÔºàWord EmbeddingÔºâÊàñÈ¢ÑËÆ≠ÁªÉËØ≠Ë®ÄÊ®°Âûã„ÄÇ ","permalink":"http://localhost:1313/posts/nlp-1/","summary":"\u003ch2 id=\"‰∏ÄÊï∞ÂÄºÁâπÂæÅ‰∏éÁ±ªÂà´ÁâπÂæÅ\"\u003e‰∏Ä„ÄÅÊï∞ÂÄºÁâπÂæÅ‰∏éÁ±ªÂà´ÁâπÂæÅ\u003c/h2\u003e\n\u003col\u003e\n\u003cli\u003e\u003cstrong\u003eÊï∞ÂÄºÁâπÂæÅ (Numeric Features)\u003c/strong\u003e\n\u003cul\u003e\n\u003cli\u003eÂÖ∑ÊúâÂèØÂä†ÂáèÁöÑÊÑè‰πâÔºå‰∏îÂ≠òÂú®Â§ßÂ∞èÈ°∫Â∫è„ÄÇ\u003c/li\u003e\n\u003cli\u003e‰æãÂ≠êÔºöÂπ¥ÈæÑ„ÄÅÊ∏©Â∫¶Á≠â„ÄÇÂèØ‰ª•Áõ¥Êé•‰øùÁïôÂÖ∂Êï¥Êï∞ÊàñÊµÆÁÇπÊï∞ÂΩ¢Âºè‰æõÊ®°Âûã‰ΩøÁî®„ÄÇ\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003eÁ±ªÂà´ÁâπÂæÅ (Categorical Features)\u003c/strong\u003e\n\u003cul\u003e\n\u003cli\u003eÊï∞ÊçÆÂÄºÁ¶ªÊï£Ôºå‰∏çÂÖ∑Â§á‚ÄúÊï∞ÂÄºÂ§ßÂ∞è‚ÄùÈó¥ÁöÑÂèØÊØîÊÑè‰πâ„ÄÇ\u003c/li\u003e\n\u003cli\u003e‰æãÂ≠êÔºöÂõΩÁ±çÔºàÁæéÂõΩ/‰∏≠ÂõΩ/Âç∞Â∫¶Á≠âÔºâ„ÄÅÊÄßÂà´ÔºàÁî∑/Â•≥ÔºâÁ≠â„ÄÇ\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003eÈóÆÈ¢ò\u003c/strong\u003eÔºöËã•‰ªÖÁî®Êï¥Êï∞Ë°®Á§∫ÔºàÁæéÂõΩ=1, ‰∏≠ÂõΩ=2ÔºâÔºå‰ºöÂºïÂÖ•ÈîôËØØÁöÑÊï∞ÂÄºËøêÁÆóÂÖ≥Á≥ªÔºåÂ¶Ç ‚ÄúÁæéÂõΩ + ‰∏≠ÂõΩ = Âç∞Â∫¶‚Äù„ÄÇ\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003c/ol\u003e\n\u003ch2 id=\"‰∫åone-hotÁºñÁ†ÅÁöÑÂä®Êú∫‰∏éÊµÅÁ®ã\"\u003e‰∫å„ÄÅOne-HotÁºñÁ†ÅÁöÑÂä®Êú∫‰∏éÊµÅÁ®ã\u003c/h2\u003e\n\u003col\u003e\n\u003cli\u003e\n\u003cp\u003e\u003cstrong\u003e‰∏∫‰ªÄ‰πà‰ΩøÁî®One-Hot\u003c/strong\u003e\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eÈÄöËøáÂ∞ÜÁ±ªÂà´Êò†Â∞Ñ‰∏∫ÂêëÈáèÔºåÈÅøÂÖçÊï¥Êï∞ÁºñÁ†ÅÂºïÂÖ•ÁöÑ‰º™Êï∞ÂÄºÂÖ≥Á≥ª„ÄÇ\u003c/li\u003e\n\u003cli\u003eÂêåÊó∂‰øùÁïôÂêÑÁßçÂèØËÉΩÁ±ªÂà´ÁöÑ‰ø°ÊÅØÔºå‰∏î‰ªÖÂú®ÂØπÂ∫î‰ΩçÁΩÆ‰∏∫1ÔºåÂÖ∂‰ªñ‰ΩçÁΩÆ‰∏∫0„ÄÇ\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003e\u003cstrong\u003eÂª∫Á´ãÊò†Â∞ÑÔºö‰ªéÁ±ªÂà´Âà∞Á¥¢Âºï\u003c/strong\u003e\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e‰∏∫ÊØè‰∏™Á±ªÂà´ÂàÜÈÖç‰∏Ä‰∏™ÂîØ‰∏ÄÁ¥¢ÂºïÔºåÈÄöÂ∏∏‰ªé1ÂºÄÂßã„ÄÇ\u003c/li\u003e\n\u003cli\u003eÈ¢ÑÁïôÁ¥¢Âºï0Ë°®Á§∫‚ÄúÊú™Áü•‚ÄùÊàñ‚ÄúÁº∫Â§±‚ÄùÔºåÂØπÂ∫îÂÖ®0ÂêëÈáè„ÄÇ\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003e\u003cstrong\u003eËΩ¨Êç¢‰∏∫One-HotÂêëÈáè\u003c/strong\u003e\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eËã•Á±ªÂà´ÊÄªÊï∞‰∏∫197ÔºåÂàôÁî®197Áª¥ÂêëÈáèË°®Á§∫„ÄÇ\u003c/li\u003e\n\u003cli\u003e‰æãÂ≠êÔºöÁæéÂõΩ \u003ccode\u003e[1, 0, 0, 0, ‚Ä¶]\u003c/code\u003eÔºå ‰∏≠ÂõΩ \u003ccode\u003e[0, 1, 0, 0, ‚Ä¶]\u003c/code\u003e„ÄÇ\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003e\u003cstrong\u003eÁ§∫‰æãÔºöË°®Á§∫‰∏Ä‰∏™‰∫∫ÁöÑÁâπÂæÅ\u003c/strong\u003e\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eÁâπÂæÅÂåÖÂê´ÔºàÂπ¥ÈæÑ, ÊÄßÂà´, ÂõΩÁ±çÔºåÂÖ∂‰∏≠ÂõΩÁ±ç197ÁßçÔºâ\u003c/li\u003e\n\u003cli\u003eÁª¥Â∫¶ÊÄªÂíåÔºö1Áª¥_age + 1Áª¥_gender + 197Áª¥_nationality = 199Áª¥„ÄÇ\u003c/li\u003e\n\u003cli\u003e‰æãÂ¶Ç \u003ccode\u003e(28, Â•≥, ‰∏≠ÂõΩ)\u003c/code\u003e ‚Üí \u003ccode\u003e[28, 0, 0, 1, 0, ‚Ä¶, 0]\u003c/code\u003e„ÄÇ\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003c/ol\u003e\n\u003ch2 id=\"‰∏âÊñáÊú¨Êï∞ÊçÆÂ§ÑÁêÜÊµÅÁ®ã\"\u003e‰∏â„ÄÅÊñáÊú¨Êï∞ÊçÆÂ§ÑÁêÜÊµÅÁ®ã\u003c/h2\u003e\n\u003cp\u003eÊñáÊú¨Âú®Ëá™ÁÑ∂ËØ≠Ë®ÄÂ§ÑÁêÜÔºàNLPÔºâ‰∏≠‰Ωú‰∏∫Â∏∏ËßÅÁöÑÂéüÂßãËæìÂÖ•ÔºåÈúÄË¶ÅÊï∞ÂÄºÂåñÊâçËÉΩÈÄÅÂÖ•Ê®°Âûã„ÄÇ‰∏ÄËà¨Ê≠•È™§Â¶Ç‰∏ãÔºö\u003c/p\u003e\n\u003col\u003e\n\u003cli\u003e\n\u003cp\u003e\u003cstrong\u003eÂàÜËØç (Tokenization)\u003c/strong\u003e\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eÂ∞ÜÊñáÊú¨ÊãÜÂàÜ‰∏∫‰∏Ä‰∏™‰∏™ÂçïËØçÔºàTokenÔºâ„ÄÇ\u003c/li\u003e\n\u003cli\u003e‰æãÂ≠êÔºö\u003ccode\u003e\u0026quot;... to be or not to be...\u0026quot;\u003c/code\u003e ‚Üí \u003ccode\u003e[\u0026quot;...\u0026quot;, \u0026quot;to\u0026quot;, \u0026quot;be\u0026quot;, \u0026quot;or\u0026quot;, \u0026quot;not\u0026quot;, \u0026quot;to\u0026quot;, \u0026quot;be\u0026quot;, \u0026quot;...\u0026quot;]\u003c/code\u003e„ÄÇ\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003e\u003cstrong\u003eÁªüËÆ°ËØçÈ¢ë \u0026amp; ÊûÑÂª∫ËØçÂÖ∏\u003c/strong\u003e\u003c/p\u003e","title":""},{"content":"Text to Sequence ÊñáÊú¨Â§ÑÁêÜ\nStep1: Tokenization\nTokenization breaks a piece of text down into a list of tokens.\nHere, a token is a word. (A token can be a character in some applications.)\nTokenizationËÆ≤Á©∂ÂæàÂ§öÔºå‰æãÂ¶ÇÊòØÂê¶Â∫îËØ•ÊääÂ§ßÂÜôÊîπÊàêÂ∞èÂÜôÂë¢ÔºüËøõË°åtypo correctionÁ≠âÁ≠â\nStep2: Build Dictionary\nUse a dictionary (hash table) to count word frequencies.\nThe dictionary maps word to index.\nÂèØ‰ª•È¶ñÂÖàÁªüËÆ°ËØçÈ¢ëÂéªÊéâ‰ΩéÈ¢ëËØçÔºåÁÑ∂ÂêéËÆ©ÊØè‰∏™ËØçÂØπÂ∫î‰∏Ä‰∏™Ê≠£Êï¥Êï∞ÔºõËøôÊ†∑ÁöÑËØùÔºå‰∏ÄÂè•ËØùÂ∞±ÂèØ‰ª•Áî®‰∏Ä‰∏™Ê≠£Êï¥Êï∞ÂàóË°®Ë°®Á§∫ÔºåËøô‰∏™ÂàóË°®Â∞±Âè´sequenceÔºõÂ¶ÇÊûúÂøÖË¶ÅÂ∞±ËøòÂæóÂÅöone-hot encoding„ÄÇ\nÁªìÊûú\n‰ΩÜÊòØÈïøÂ∫¶‰∏çÁªü‰∏Ä\nStep4: ÂØπÈΩêsequence\nËß£ÂÜ≥ÊñπÊ°àÊòØËøôÊ†∑ÁöÑÔºöÂèØ‰ª•Âõ∫ÂÆöÈïøÂ∫¶‰∏∫wÔºåÂä†ÂÖ•‰∏Ä‰∏™Â∫èÂàóÈïøÂ∫¶Â§™ÈïøÔºåÂ∞±Á†çÊéâÂâçÈù¢ÁöÑËØçÔºåÂè™‰øùÁïôÊúÄÂêéw‰∏™ËØçÔºõÂ¶ÇÊûú‰∏Ä‰∏™Â∫èÂàóÂ§™Áü≠ÔºåÂ∞±ÂÅözero paddingÔºåÁî®0Â°´ÂÖÖ\nËøôÊ†∑‰∏ÄÊù•ÔºåÊâÄÊúâÁöÑÂ∫èÂàóÈïøÂ∫¶Â∞±Áªü‰∏Ä‰∫Ü\nÊñáÊú¨Â§ÑÁêÜÂÆåÊàê‰∫ÜÔºåÊé•‰∏ãÊù•ÊòØword embeddingÔºåÊääÂçïËØçË°®Á§∫‰∏∫‰∏Ä‰∏™‰ΩéÁª¥ÂêëÈáèÔºõ\nÁÑ∂ËÄåËøôÊ†∑ÂÅöÁöÑËØùÔºåÂ¶ÇÊûúÊòØ10000‰∏™ÂçïËØçÔºåÁª¥Â∫¶Â∞±ÊòØ10000Áª¥ÔºåÁª¥Â∫¶Â§™È´ò‰∫ÜÔºõÂõ†Ê≠§Ë¶ÅÂÅöword embeddingÔºõ\nÂÖ∑‰ΩìÂÅöÊ≥ïÂ∞±ÊòØÊääone-hotÂêëÈáèe_iÂíåÂèÇÊï∞Áü©ÈòµpÁõ∏‰πòÔºõÁü©ÈòµPËΩ¨ÁΩÆÁöÑÂ§ßÂ∞èÊòØd x vÔºõdÊòØËØçÂêëÈáèÁöÑÁª¥Â∫¶ÔºõvÊòØÂ≠óÂÖ∏ÈáåËØçÊ±áÁöÑÊï∞ÈáèÔºõÁªìÊûú‰∏∫x_iÔºõx_iÂ∞±ÊòØ‰∏Ä‰∏™ËØçÂêëÈáèÔºõÂ¶ÇÊûúone-hotÂêëÈáèÁöÑÁ¨¨‰∏âË°å‰∏∫1ÔºõÈÇ£‰πàx_iÂ∞±ÊòØPËΩ¨ÁΩÆÁü©ÈòµÁöÑÁ¨¨‰∏âÂàóÔºàÂÖ∂‰ΩôÂàóÈÉΩ‰∏∫0ÔºâÔºõÊâÄ‰ª•PËΩ¨ÁΩÆÊØè‰∏ÄÂàóÈÉΩÊòØ‰∏Ä‰∏™ËØçÂêëÈáèÔºõÊâÄ‰ª•Áü©ÈòµPÊú¨Ë∫´ÁöÑÊØè‰∏ÄË°åÂ∞±ÊòØ‰∏Ä‰∏™ËØçÂêëÈáèÔºõÂÖ∂Ë°åÊï∞‰∏∫vÔºõÂç≥vocabularyÔºåËØçÊ±áÈáèÔºõÊØè‰∏ÄË°åÂØπÂ∫î‰∏Ä‰∏™ÂçïËØçÔºõÁü©ÈòµÁöÑÂàóÊï∞‰∏∫dÔºõdÊòØÁî®Êà∑ÂÜ≥ÂÆöÁöÑÔºõdÁöÑÂ§ßÂ∞è‰ºöÂÜ≥ÂÆöÊú∫Âô®Â≠¶‰π†Ê®°ÂûãÁöÑË°®Áé∞ÔºõÂ∫îËØ•Áî®xxxÊù•ÈÄâÊã©‰∏Ä‰∏™ÊØîËæÉÂ•ΩÁöÑdÔºõ\nÊàë‰ª¨ÁöÑ‰ªªÂä°ÊòØÁúãËØÑËÆ∫ÊòØÊ≠£Èù¢ÁöÑËøòÊòØË¥üÈù¢ÁöÑÔºõÂèÇÊï∞Áü©ÈòµÊòØ‰ªéËÆ≠ÁªÉÊï∞ÊçÆ‰∏≠Â≠¶‰π†Âá∫Êù•ÁöÑÔºåÊâÄ‰ª•Â≠¶Âá∫Êù•ÁöÑËØçÂêëÈáèÊòØÂ∏¶ÊúâÊÑüÊÉÖËâ≤ÂΩ©ÁöÑÔºõÂÅáËÆæËøô‰∫õËØçÂêëÈáèÈÉΩÊòØ‰∫åÁª¥ÁöÑÔºåÂàôÂèØ‰ª•Âú®Âπ≥Èù¢ÂùêÊ†áÁ≥ª‰∏≠Ê†áÂá∫‰∏ãÈù¢ËØçÂêëÈáè\nkerasÊèê‰æõembeddingÂ±ÇÔºõÁî®Êà∑ÂèØ‰ª•ÊåáÂÆövocabularyÂ§ßÂ∞èÂíådÁöÑÂ§ßÂ∞èÔºõ‰ª•ÂèäÊØè‰∏Ä‰∏™sequenceÁöÑÈïøÂ∫¶ÔºõdÊòØÊ†πÊçÆÁÆóÊ≥ïÈÄâÂá∫Êù•ÁöÑ Âà∞Ëøô‰∏ÄÊ≠•ÔºåÊàë‰ª¨Â∑≤ÁªèÂÆåÊàê‰∫ÜÊñáÊú¨Â§ÑÁêÜÂíåword embedding„ÄÇÊé•‰∏ãÊù•Â∞±ÊòØÁî®Logistic Regression for Binary ClassificationÂÅö‰∫åÂàÜÁ±ªÔºõ\n","permalink":"http://localhost:1313/posts/nlp-2/","summary":"\u003ch3 id=\"text-to-sequence\"\u003eText to Sequence\u003c/h3\u003e\n\u003cp\u003eÊñáÊú¨Â§ÑÁêÜ\u003c/p\u003e\n\u003cp\u003eStep1: Tokenization\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\n\u003cp\u003eTokenization breaks a piece of text down into a list of tokens.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003eHere, a token is a word. (A token can be a character in some applications.)\u003c/p\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003eTokenizationËÆ≤Á©∂ÂæàÂ§öÔºå‰æãÂ¶ÇÊòØÂê¶Â∫îËØ•ÊääÂ§ßÂÜôÊîπÊàêÂ∞èÂÜôÂë¢ÔºüËøõË°åtypo correctionÁ≠âÁ≠â\u003c/p\u003e\n\u003cp\u003e\u003cimg alt=\"image-20250322150322238\" loading=\"lazy\" src=\"./NLP-2.assets/image-20250322150322238.png\"\u003e\u003c/p\u003e\n\u003cp\u003eStep2: Build Dictionary\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\n\u003cp\u003eUse a dictionary (hash table) to count word frequencies.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003eThe dictionary maps word to index.\u003c/p\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003eÂèØ‰ª•È¶ñÂÖàÁªüËÆ°ËØçÈ¢ëÂéªÊéâ‰ΩéÈ¢ëËØçÔºåÁÑ∂ÂêéËÆ©ÊØè‰∏™ËØçÂØπÂ∫î‰∏Ä‰∏™Ê≠£Êï¥Êï∞ÔºõËøôÊ†∑ÁöÑËØùÔºå‰∏ÄÂè•ËØùÂ∞±ÂèØ‰ª•Áî®‰∏Ä‰∏™Ê≠£Êï¥Êï∞ÂàóË°®Ë°®Á§∫ÔºåËøô‰∏™ÂàóË°®Â∞±Âè´sequenceÔºõÂ¶ÇÊûúÂøÖË¶ÅÂ∞±ËøòÂæóÂÅöone-hot encoding„ÄÇ\u003cimg alt=\"image-20250322150620890\" loading=\"lazy\" src=\"./NLP-2.assets/image-20250322150620890.png\"\u003e\u003c/p\u003e\n\u003cp\u003eÁªìÊûú\u003c/p\u003e\n\u003cp\u003e\u003cimg alt=\"image-20250322150754528\" loading=\"lazy\" src=\"./NLP-2.assets/image-20250322150754528.png\"\u003e\u003c/p\u003e\n\u003cp\u003e‰ΩÜÊòØÈïøÂ∫¶‰∏çÁªü‰∏Ä\u003c/p\u003e\n\u003cp\u003eStep4: ÂØπÈΩêsequence\u003c/p\u003e\n\u003cp\u003e\u003cimg alt=\"image-20250322150854986\" loading=\"lazy\" src=\"./NLP-2.assets/image-20250322150854986.png\"\u003e\u003c/p\u003e\n\u003cp\u003eËß£ÂÜ≥ÊñπÊ°àÊòØËøôÊ†∑ÁöÑÔºöÂèØ‰ª•Âõ∫ÂÆöÈïøÂ∫¶‰∏∫wÔºåÂä†ÂÖ•‰∏Ä‰∏™Â∫èÂàóÈïøÂ∫¶Â§™ÈïøÔºåÂ∞±Á†çÊéâÂâçÈù¢ÁöÑËØçÔºåÂè™‰øùÁïôÊúÄÂêéw‰∏™ËØçÔºõÂ¶ÇÊûú‰∏Ä‰∏™Â∫èÂàóÂ§™Áü≠ÔºåÂ∞±ÂÅözero paddingÔºåÁî®0Â°´ÂÖÖ\u003c/p\u003e\n\u003cp\u003e\u003cimg alt=\"image-20250322151030119\" loading=\"lazy\" src=\"./NLP-2.assets/image-20250322151030119.png\"\u003e\u003c/p\u003e\n\u003cp\u003eËøôÊ†∑‰∏ÄÊù•ÔºåÊâÄÊúâÁöÑÂ∫èÂàóÈïøÂ∫¶Â∞±Áªü‰∏Ä‰∫Ü\u003c/p\u003e\n\u003cp\u003e\u003cimg alt=\"image-20250322151117125\" loading=\"lazy\" src=\"./NLP-2.assets/image-20250322151117125.png\"\u003e\u003c/p\u003e\n\u003cp\u003eÊñáÊú¨Â§ÑÁêÜÂÆåÊàê‰∫ÜÔºåÊé•‰∏ãÊù•ÊòØword embeddingÔºåÊääÂçïËØçË°®Á§∫‰∏∫‰∏Ä‰∏™‰ΩéÁª¥ÂêëÈáèÔºõ\u003c/p\u003e\n\u003cp\u003e\u003cimg alt=\"image-20250322151252837\" loading=\"lazy\" src=\"./NLP-2.assets/image-20250322151252837.png\"\u003e\u003c/p\u003e","title":""},{"content":"üëã About me Hello! I\u0026rsquo;m Xu Zongsi, a passionate technology enthusiast currently pursuing my Master of Science in ECIC at The University of Hong Kong. With a solid background in Software Engineering from the Beijing Institute of Technology, I specialize in artificial intelligence areas like machine learning, deep learning, natural language processing, computer vision, and reinforcement learning.\nInspired by OpenAI\u0026rsquo;s five-step plan towards superintelligence, I am excited about AGI and have developed a keen interest in LLM agents, MLLM, and knowledge graphs. I see great potential in these fields and aspire to contribute to innovative solutions.\nüìö Education üá≠üá∞ The University of Hong Kong 09/2024 - Expected 11/2025 School of Computing and Data Science Master of Science in Electronic Commerce \u0026amp; Internet Computing Relevant Courses: Machine learning for business and e-commerce, Knowledge graphs, Financial fraud analytics, Internet infrastructure technologies, Website engineering, Blockchain and cryptocurrency, etc. üá®üá≥ Beijing Institute of Technology 09/2020 - 06/2024 School of Computer Science \u0026amp; Technology Bachelor of Engineering in Software Engineering, last two years GPA: 3.7/4 Relevant Courses: Reinforcement Learning, Deep Learning and Computer Vision, Artificial Intelligence and Robot Ethics, Almost Human: Mind, Brain and Artificial Intelligence, Mathematical Analysis for Engineering, Linear Algebra, Probability and Mathematical Statistics, etc. Skills: Python, Java, common data structures, design patterns, machine learning basics and algorithms, Linux, PyTorch, and some development tools (git, conda, etc.). üèÜ Awards \u0026amp; Honors Beijing Institute of Technology Undergraduate Scholarship (Top 20% of Grade) 06/2023 3rd Prize of China International \u0026#34;Internet \u0026#43;\u0026#34; College Student\u0026#39;s Innovation Competition 08/2022 Bronze Prize of \u0026#34;Challenge Cup\u0026#34; Capital University Entrepreneurship Competition 05/2022 üíº Project Experience üîç Online Transaction Fraud Detection 09/2024 ‚Äì 01/2025 Independent project, supervised by Dr. Vivien Chan Focused on addressing financial fraud in e-commerce to enhance the accuracy of transaction anomaly detection, while independently managing the entire case study that included data preprocessing, feature engineering, model building, evaluation, and results analysis. Effectively resolved class imbalance issues using SMOTE and ROSE techniques. Built various models including Logistic Regression, Random Forest, XGBoost, and LightGBM, ultimately selecting the LightGBM model to achieve a recall rate of 95.45% and an AUC of 99.84%. Wrote efficient and maintainable code, enhancing model training and data processing efficiency through parallel computing and logging. ü§ñ Multi-Model Intelligent Text Keyword Extraction System 08/2023 ‚Äì 09/2023 Group project, supervised by Associate Prof. Xiaolin Zhao Designed and implemented an intelligent text summary system that automatically extracts keywords from article titles and abstracts, enhancing the understanding and summarization of text information. Participated in the planning of the technical route and built a hybrid model combining extractive and generative approaches, utilizing advanced natural language processing techniques including KeyBERT, Sentence Transformer, BERT, and T5 models. Responsible for data preprocessing and tokenization, as well as the end-to-end implementation and training of the T5 model, optimizing the model architecture and hyperparameters, achieving satisfactory results after only 3 epochs of training. Model evaluation results showed that the Rouge-1, Rouge-2, and Rouge-L metrics reached 0.6345, 0.5038, and 0.5282, respectively, in the third epoch, validating the model\u0026rsquo;s effectiveness in the summarization task. üéì Cambridge University Machine Learning Summer Project 07/2023 ‚Äì 08/2023 Group project, supervised by Prof. Pietro Li√≤ Participated in the Cambridge University deep learning summer project, focusing on deep reinforcement learning; explored multi-agent learning algorithms across different environments. Reproduced the Multi-Agent Deep Deterministic Policy Gradient (MADDPG) algorithm in the Simple Adversary environment and studied the effect of agent numbers on convergence speed and stability, finding optimal stability at 21 agents. Designed and implemented comparative experiments inspired by the Rainbow algorithm, assessing target network strategies versus the Double Deep Q-Network (Double DQN). The results demonstrated that Double DQN significantly enhanced convergence speed, optimizing the overall learning process. Co-authored a group project paper on agent numbers and strategies effectiveness in multi-agent systems, achieving a score of 71% in the summer program (the highest in my group) and a \u0026ldquo;First Class\u0026rdquo; classification in the UK grading system. üëÅÔ∏è Deep Learning and Computer Vision Semester Project 09/2022 ‚Äì 12/2022 Independent project, supervised by Associate Prof. Guangyu Gao Designed and implemented a waste classifier using the ResNet model to improve classification accuracy and reduce resource waste. The project also enhanced understanding of transfer learning techniques with ResNet. Collected a dataset of 16 waste categories and preprocessed the images for uniformity and standardization, incorporating data augmentation techniques to enhance the dataset. Conducted experiments using ResNet34 and ResNet50 models through transfer learning, accelerating network convergence by leveraging pretrained weights. During training, techniques such as Batch Normalization and Dropout were applied to mitigate the risk of overfitting. The final model achieved an accuracy of 90% on the training set, while the performance on the test set was 61%, indicating a significant overfitting phenomenon during the training process. üéì Internship ‚öõÔ∏è Beijing Academy of Quantum Information Science 08/2023 ‚Äì 01/2024 Research Intern at Quantum Computation Department Proposed a quantum convolution kernel design based on variational quantum circuits and developed a universal quantum convolution layer, successfully integrating it into classical CNN architectures such as VGG, GoogLeNet, and ResNet. Developed and evaluated various hybrid models, including a simple model named HQCCNN-2, which achieved 84.45% accuracy on the FashionMNIST dataset, surpassing the traditional CNN\u0026rsquo;s 80.72%. This demonstrates the effectiveness of the quantum convolution layer in improving model performance. Tested on a real quantum computer further validated the effectiveness of the hybrid model, demonstrating the viable integration of quantum computing with deep learning, and highlighting the potential for leveraging quantum properties to enhance model performance. üèÖ Competition Experience ü•â China International \u0026#34;Internet \u0026#43;\u0026#34; College Students\u0026#39; Innovation Competition 08/2022 üõ°Ô∏è Zhongke Ushield: Deep Learning-based Face Privacy Protection Authentication System Responsible for constructing a localized facial feature extraction engine based on MobileFaceNet, ensuring feature extraction is completed on end devices (such as mobile phones and cameras), guaranteeing that raw data does not leave the domain and is not stored, thus enhancing user privacy protection while improving recognition efficiency. ü•â \u0026#34;Challenge Cup\u0026#34; Capital University Entrepreneurship Competition 05/2022 üå≥ Smart Orchard Responsible for the development of the fruit detection, ripeness prediction, and pest identification system, using deep convolutional neural network (CNN) technology for intelligent monitoring of crop growth conditions. Applied advanced object detection algorithms such as Faster R-CNN and YOLO to achieve high precision in apple detection and ripeness assessment, with an accuracy rate exceeding 90%, significantly enhancing the intelligence level of orchard management. Built and trained a dedicated dataset containing various pest samples, optimizing pest detection accuracy through data preprocessing (such as image normalization and resizing) and data augmentation techniques (like rotation, flipping, and noise addition), enabling the real-time monitoring system to accurately identify over 80% of pests, providing effective scientific maintenance recommendations to help farmers reduce crop losses. üìã Extracurricular Activities Vice President, Cyber Security Club, Beijing Institute of Technology 09/2021-09/2022 Backbone, Media Center of the Student Union of Beijing Institute of Technology 10/2020-06/2021 üì´ Contact üìß Email: zongsi.xu@outlook.com üëî LinkedIn: Zongsi (Tristan) Xu üíª GitHub: BaizeXS üìç Location: Hong Kong SAR, China ","permalink":"http://localhost:1313/resume/","summary":"Personal resume of Zongsi (Tristan) Xu","title":"Zongsi (Tristan) Xu"},{"content":"‰∏Ä„ÄÅÊï∞ÂÄºÁâπÂæÅ‰∏éÁ±ªÂà´ÁâπÂæÅ Êï∞ÂÄºÁâπÂæÅ (Numeric Features) ÂÖ∑ÊúâÂèØÂä†ÂáèÁöÑÊÑè‰πâÔºå‰∏îÂ≠òÂú®Â§ßÂ∞èÈ°∫Â∫è„ÄÇ ‰æãÂ≠êÔºöÂπ¥ÈæÑ„ÄÅÊ∏©Â∫¶Á≠â„ÄÇÂèØ‰ª•Áõ¥Êé•‰øùÁïôÂÖ∂Êï¥Êï∞ÊàñÊµÆÁÇπÊï∞ÂΩ¢Âºè‰æõÊ®°Âûã‰ΩøÁî®„ÄÇ Á±ªÂà´ÁâπÂæÅ (Categorical Features) Êï∞ÊçÆÂÄºÁ¶ªÊï£Ôºå‰∏çÂÖ∑Â§á‚ÄúÊï∞ÂÄºÂ§ßÂ∞è‚ÄùÈó¥ÁöÑÂèØÊØîÊÑè‰πâ„ÄÇ ‰æãÂ≠êÔºöÂõΩÁ±çÔºàÁæéÂõΩ/‰∏≠ÂõΩ/Âç∞Â∫¶Á≠âÔºâ„ÄÅÊÄßÂà´ÔºàÁî∑/Â•≥ÔºâÁ≠â„ÄÇ ÈóÆÈ¢òÔºöËã•‰ªÖÁî®Êï¥Êï∞Ë°®Á§∫ÔºàÁæéÂõΩ=1, ‰∏≠ÂõΩ=2ÔºâÔºå‰ºöÂºïÂÖ•ÈîôËØØÁöÑÊï∞ÂÄºËøêÁÆóÂÖ≥Á≥ªÔºåÂ¶Ç ‚ÄúÁæéÂõΩ + ‰∏≠ÂõΩ = Âç∞Â∫¶‚Äù„ÄÇ ‰∫å„ÄÅOne-HotÁºñÁ†ÅÁöÑÂä®Êú∫‰∏éÊµÅÁ®ã ‰∏∫‰ªÄ‰πà‰ΩøÁî®One-Hot\nÈÄöËøáÂ∞ÜÁ±ªÂà´Êò†Â∞Ñ‰∏∫ÂêëÈáèÔºåÈÅøÂÖçÊï¥Êï∞ÁºñÁ†ÅÂºïÂÖ•ÁöÑ‰º™Êï∞ÂÄºÂÖ≥Á≥ª„ÄÇ ÂêåÊó∂‰øùÁïôÂêÑÁßçÂèØËÉΩÁ±ªÂà´ÁöÑ‰ø°ÊÅØÔºå‰∏î‰ªÖÂú®ÂØπÂ∫î‰ΩçÁΩÆ‰∏∫1ÔºåÂÖ∂‰ªñ‰ΩçÁΩÆ‰∏∫0„ÄÇ Âª∫Á´ãÊò†Â∞ÑÔºö‰ªéÁ±ªÂà´Âà∞Á¥¢Âºï\n‰∏∫ÊØè‰∏™Á±ªÂà´ÂàÜÈÖç‰∏Ä‰∏™ÂîØ‰∏ÄÁ¥¢ÂºïÔºåÈÄöÂ∏∏‰ªé1ÂºÄÂßã„ÄÇ È¢ÑÁïôÁ¥¢Âºï0Ë°®Á§∫‚ÄúÊú™Áü•‚ÄùÊàñ‚ÄúÁº∫Â§±‚ÄùÔºåÂØπÂ∫îÂÖ®0ÂêëÈáè„ÄÇ ËΩ¨Êç¢‰∏∫One-HotÂêëÈáè\nËã•Á±ªÂà´ÊÄªÊï∞‰∏∫197ÔºåÂàôÁî®197Áª¥ÂêëÈáèË°®Á§∫„ÄÇ ‰æãÂ≠êÔºöÁæéÂõΩ [1, 0, 0, 0, ‚Ä¶]Ôºå ‰∏≠ÂõΩ [0, 1, 0, 0, ‚Ä¶]„ÄÇ Á§∫‰æãÔºöË°®Á§∫‰∏Ä‰∏™‰∫∫ÁöÑÁâπÂæÅ\nÁâπÂæÅÂåÖÂê´ÔºàÂπ¥ÈæÑ, ÊÄßÂà´, ÂõΩÁ±çÔºåÂÖ∂‰∏≠ÂõΩÁ±ç197ÁßçÔºâ Áª¥Â∫¶ÊÄªÂíåÔºö1Áª¥_age + 1Áª¥_gender + 197Áª¥_nationality = 199Áª¥„ÄÇ ‰æãÂ¶Ç (28, Â•≥, ‰∏≠ÂõΩ) ‚Üí [28, 0, 0, 1, 0, ‚Ä¶, 0]„ÄÇ ‰∏â„ÄÅÊñáÊú¨Êï∞ÊçÆÂ§ÑÁêÜÊµÅÁ®ã ÊñáÊú¨Âú®Ëá™ÁÑ∂ËØ≠Ë®ÄÂ§ÑÁêÜÔºàNLPÔºâ‰∏≠‰Ωú‰∏∫Â∏∏ËßÅÁöÑÂéüÂßãËæìÂÖ•ÔºåÈúÄË¶ÅÊï∞ÂÄºÂåñÊâçËÉΩÈÄÅÂÖ•Ê®°Âûã„ÄÇ‰∏ÄËà¨Ê≠•È™§Â¶Ç‰∏ãÔºö\nÂàÜËØç (Tokenization)\nÂ∞ÜÊñáÊú¨ÊãÜÂàÜ‰∏∫‰∏Ä‰∏™‰∏™ÂçïËØçÔºàTokenÔºâ„ÄÇ ‰æãÂ≠êÔºö\u0026quot;... to be or not to be...\u0026quot; ‚Üí [\u0026quot;...\u0026quot;, \u0026quot;to\u0026quot;, \u0026quot;be\u0026quot;, \u0026quot;or\u0026quot;, \u0026quot;not\u0026quot;, \u0026quot;to\u0026quot;, \u0026quot;be\u0026quot;, \u0026quot;...\u0026quot;]„ÄÇ ÁªüËÆ°ËØçÈ¢ë \u0026amp; ÊûÑÂª∫ËØçÂÖ∏\nËØçÈ¢ëÁªüËÆ° Áî®ÂìàÂ∏åË°®/Â≠óÂÖ∏ËÆ∞ÂΩïÊØè‰∏™ÂçïËØçÂá∫Áé∞Ê¨°Êï∞„ÄÇ ÈÅçÂéÜÊñáÊú¨Êó∂ÔºåËã•ÂçïËØçÂ∞öÊú™ÂÖ•Ë°®ÔºåÂàôÊñ∞Âª∫ËÆ∞ÂΩïÔºõËã•Â∑≤Â≠òÂú®ÔºåÂàôËÆ°Êï∞+1„ÄÇ ÊéíÂ∫è‰∏éÁ¥¢Âºï ÊåâËØçÈ¢ëÈôçÂ∫èÊéíÂ∫èÔºåËØçÈ¢ëÊúÄÈ´òÁöÑÂçïËØçÊéíÂú®ÂâçÈù¢„ÄÇ Á¥¢Âºï‰ªé1ÂºÄÂßãÔºå0ÁïôÁªô‚ÄúÊú™Áü•‚Äù„ÄÇ ËØçÂÖ∏ËßÑÊ®°ÔºàvocabularyÔºâÂèØËßÜÈúÄÊ±ÇÊà™Êñ≠Ôºà‰æãÂ¶ÇÂè™‰øùÁïôTop 10kÔºâ„ÄÇ ‰∏∫‰ªÄ‰πàÁßªÈô§‰ΩéÈ¢ëËØç ‰ΩéÈ¢ëËØçÂèØËÉΩÊòØÊãºÂÜôÈîôËØØ„ÄÅÁΩïËßÅ‰∫∫ÂêçÁ≠âÔºåÂØπÊ®°ÂûãÂ∏ÆÂä©ÊúâÈôê„ÄÇ ÂáèÂ∞ëËØçÂÖ∏ËßÑÊ®°ÂèØÈôç‰ΩéËøêÁÆóÂºÄÈîÄ„ÄÅÂä†Âø´Ê®°ÂûãËÆ≠ÁªÉ‰∏éÊé®ÁêÜÈÄüÂ∫¶„ÄÇ Áã¨ÁÉ≠ÁºñÁ†Å (One-Hot Encoding)\nÂ∞ÜÊØè‰∏™ÂçïËØçÊò†Â∞Ñ‰∏∫ËØçÂÖ∏‰∏≠ÁöÑÁ¥¢ÂºïÂêéÔºàÂ¶Ç [2, 4, 1, 8, ‚Ä¶]ÔºâÔºåÂèØËøõ‰∏ÄÊ≠•ËΩ¨Êç¢ÊàêOne-HotÂêëÈáè„ÄÇ One-HotÁª¥Â∫¶ÂèñÂÜ≥‰∫é‰øùÁïô‰∏ãÊù•ÁöÑËØçÂÖ∏Â§ßÂ∞èÔºà‰æãÂ¶Ç1‰∏áÔºâ„ÄÇ Êú™Êî∂ÂΩïÂçïËØçÂèØËÉΩÁõ¥Êé•ÂøΩÁï•ÔºåÊàñÁªü‰∏ÄÁî®Á¥¢Âºï0‰ª£Êõø„ÄÇ Âõõ„ÄÅÊ†∏ÂøÉÊî∂Ëé∑‰∏éÂ∫îÁî® Á±ªÂà´ÁâπÂæÅÂøÖÈúÄÊï∞ÂÄºÂåñÔºö\n‰ΩøÁî®Êï¥Êï∞1,2,3‚Ä¶‰ªÖË°®Á§∫Á±ªÂà´‚ÄúÊ†áËØÜ‚ÄùÔºåÂπ∂‰∏ç‰ª£Ë°®ÂÆÉ‰ª¨ÂèØËøõË°åÊï∞ÂÄºËøêÁÆó„ÄÇ Âõ†Ê≠§ÈúÄË¶ÅOne-HotÁ≠âÁºñÁ†ÅÊñπÂºèÔºåÈÅøÂÖçÊï∞ÂÄºËØØËß£„ÄÇ ÊñáÊú¨Êï∞ÊçÆÈ¢ÑÂ§ÑÁêÜÔºö\nÂàÜËØç„ÄÅËØçÈ¢ëÁªüËÆ°„ÄÅÊûÑÂª∫ËØçÂÖ∏„ÄÅÁ¥¢ÂºïÂåñ„ÄÅOne-HotÊàñÂÖ∂‰ªñÊñπÂºèÔºàÂ¶ÇËØçÂµåÂÖ•ÔºâÊòØÂ∏∏ËßÅÊµÅÁ®ã„ÄÇ Ê≠£Á°ÆÁöÑÊñáÊú¨È¢ÑÂ§ÑÁêÜÂèØÊòæËëóÂΩ±ÂìçÊ®°ÂûãÊÄßËÉΩÂíåÊïàÁéá„ÄÇ ‰øùÁïôÊú™Áü•Á¥¢ÂºïÔºö\n‰øùËØÅÂØπÁº∫Â§±Êï∞ÊçÆÊàñÂ≠óÂÖ∏Â§ñÊñ∞ËØçËÉΩÊúâÂü∫Êú¨ÁöÑË°®Á§∫ÔºåÊèêÂçáÊ®°ÂûãÂÆπÈîôÊÄß„ÄÇ ÂÆûÈôÖ‰ΩøÁî®Ôºö\nÂØπ‰∫éÂ∞èËßÑÊ®°Á±ªÂà´ÂèØÁõ¥Êé•One-HotÁºñÁ†ÅÔºõÂØπ‰∫éËØçÂÖ∏ÂæàÂ§ßÁöÑÂú∫ÊôØÔºåÈÄöÂ∏∏‰ºöËøõ‰∏ÄÊ≠•ËÄÉËôëËØçÂµåÂÖ•ÔºàWord EmbeddingÔºâÊàñÈ¢ÑËÆ≠ÁªÉËØ≠Ë®ÄÊ®°Âûã„ÄÇ ","permalink":"http://localhost:1313/posts/nlp-1/","summary":"\u003ch2 id=\"‰∏ÄÊï∞ÂÄºÁâπÂæÅ‰∏éÁ±ªÂà´ÁâπÂæÅ\"\u003e‰∏Ä„ÄÅÊï∞ÂÄºÁâπÂæÅ‰∏éÁ±ªÂà´ÁâπÂæÅ\u003c/h2\u003e\n\u003col\u003e\n\u003cli\u003e\u003cstrong\u003eÊï∞ÂÄºÁâπÂæÅ (Numeric Features)\u003c/strong\u003e\n\u003cul\u003e\n\u003cli\u003eÂÖ∑ÊúâÂèØÂä†ÂáèÁöÑÊÑè‰πâÔºå‰∏îÂ≠òÂú®Â§ßÂ∞èÈ°∫Â∫è„ÄÇ\u003c/li\u003e\n\u003cli\u003e‰æãÂ≠êÔºöÂπ¥ÈæÑ„ÄÅÊ∏©Â∫¶Á≠â„ÄÇÂèØ‰ª•Áõ¥Êé•‰øùÁïôÂÖ∂Êï¥Êï∞ÊàñÊµÆÁÇπÊï∞ÂΩ¢Âºè‰æõÊ®°Âûã‰ΩøÁî®„ÄÇ\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003eÁ±ªÂà´ÁâπÂæÅ (Categorical Features)\u003c/strong\u003e\n\u003cul\u003e\n\u003cli\u003eÊï∞ÊçÆÂÄºÁ¶ªÊï£Ôºå‰∏çÂÖ∑Â§á‚ÄúÊï∞ÂÄºÂ§ßÂ∞è‚ÄùÈó¥ÁöÑÂèØÊØîÊÑè‰πâ„ÄÇ\u003c/li\u003e\n\u003cli\u003e‰æãÂ≠êÔºöÂõΩÁ±çÔºàÁæéÂõΩ/‰∏≠ÂõΩ/Âç∞Â∫¶Á≠âÔºâ„ÄÅÊÄßÂà´ÔºàÁî∑/Â•≥ÔºâÁ≠â„ÄÇ\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003eÈóÆÈ¢ò\u003c/strong\u003eÔºöËã•‰ªÖÁî®Êï¥Êï∞Ë°®Á§∫ÔºàÁæéÂõΩ=1, ‰∏≠ÂõΩ=2ÔºâÔºå‰ºöÂºïÂÖ•ÈîôËØØÁöÑÊï∞ÂÄºËøêÁÆóÂÖ≥Á≥ªÔºåÂ¶Ç ‚ÄúÁæéÂõΩ + ‰∏≠ÂõΩ = Âç∞Â∫¶‚Äù„ÄÇ\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003c/ol\u003e\n\u003ch2 id=\"‰∫åone-hotÁºñÁ†ÅÁöÑÂä®Êú∫‰∏éÊµÅÁ®ã\"\u003e‰∫å„ÄÅOne-HotÁºñÁ†ÅÁöÑÂä®Êú∫‰∏éÊµÅÁ®ã\u003c/h2\u003e\n\u003col\u003e\n\u003cli\u003e\n\u003cp\u003e\u003cstrong\u003e‰∏∫‰ªÄ‰πà‰ΩøÁî®One-Hot\u003c/strong\u003e\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eÈÄöËøáÂ∞ÜÁ±ªÂà´Êò†Â∞Ñ‰∏∫ÂêëÈáèÔºåÈÅøÂÖçÊï¥Êï∞ÁºñÁ†ÅÂºïÂÖ•ÁöÑ‰º™Êï∞ÂÄºÂÖ≥Á≥ª„ÄÇ\u003c/li\u003e\n\u003cli\u003eÂêåÊó∂‰øùÁïôÂêÑÁßçÂèØËÉΩÁ±ªÂà´ÁöÑ‰ø°ÊÅØÔºå‰∏î‰ªÖÂú®ÂØπÂ∫î‰ΩçÁΩÆ‰∏∫1ÔºåÂÖ∂‰ªñ‰ΩçÁΩÆ‰∏∫0„ÄÇ\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003e\u003cstrong\u003eÂª∫Á´ãÊò†Â∞ÑÔºö‰ªéÁ±ªÂà´Âà∞Á¥¢Âºï\u003c/strong\u003e\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e‰∏∫ÊØè‰∏™Á±ªÂà´ÂàÜÈÖç‰∏Ä‰∏™ÂîØ‰∏ÄÁ¥¢ÂºïÔºåÈÄöÂ∏∏‰ªé1ÂºÄÂßã„ÄÇ\u003c/li\u003e\n\u003cli\u003eÈ¢ÑÁïôÁ¥¢Âºï0Ë°®Á§∫‚ÄúÊú™Áü•‚ÄùÊàñ‚ÄúÁº∫Â§±‚ÄùÔºåÂØπÂ∫îÂÖ®0ÂêëÈáè„ÄÇ\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003e\u003cstrong\u003eËΩ¨Êç¢‰∏∫One-HotÂêëÈáè\u003c/strong\u003e\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eËã•Á±ªÂà´ÊÄªÊï∞‰∏∫197ÔºåÂàôÁî®197Áª¥ÂêëÈáèË°®Á§∫„ÄÇ\u003c/li\u003e\n\u003cli\u003e‰æãÂ≠êÔºöÁæéÂõΩ \u003ccode\u003e[1, 0, 0, 0, ‚Ä¶]\u003c/code\u003eÔºå ‰∏≠ÂõΩ \u003ccode\u003e[0, 1, 0, 0, ‚Ä¶]\u003c/code\u003e„ÄÇ\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003e\u003cstrong\u003eÁ§∫‰æãÔºöË°®Á§∫‰∏Ä‰∏™‰∫∫ÁöÑÁâπÂæÅ\u003c/strong\u003e\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eÁâπÂæÅÂåÖÂê´ÔºàÂπ¥ÈæÑ, ÊÄßÂà´, ÂõΩÁ±çÔºåÂÖ∂‰∏≠ÂõΩÁ±ç197ÁßçÔºâ\u003c/li\u003e\n\u003cli\u003eÁª¥Â∫¶ÊÄªÂíåÔºö1Áª¥_age + 1Áª¥_gender + 197Áª¥_nationality = 199Áª¥„ÄÇ\u003c/li\u003e\n\u003cli\u003e‰æãÂ¶Ç \u003ccode\u003e(28, Â•≥, ‰∏≠ÂõΩ)\u003c/code\u003e ‚Üí \u003ccode\u003e[28, 0, 0, 1, 0, ‚Ä¶, 0]\u003c/code\u003e„ÄÇ\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003c/ol\u003e\n\u003ch2 id=\"‰∏âÊñáÊú¨Êï∞ÊçÆÂ§ÑÁêÜÊµÅÁ®ã\"\u003e‰∏â„ÄÅÊñáÊú¨Êï∞ÊçÆÂ§ÑÁêÜÊµÅÁ®ã\u003c/h2\u003e\n\u003cp\u003eÊñáÊú¨Âú®Ëá™ÁÑ∂ËØ≠Ë®ÄÂ§ÑÁêÜÔºàNLPÔºâ‰∏≠‰Ωú‰∏∫Â∏∏ËßÅÁöÑÂéüÂßãËæìÂÖ•ÔºåÈúÄË¶ÅÊï∞ÂÄºÂåñÊâçËÉΩÈÄÅÂÖ•Ê®°Âûã„ÄÇ‰∏ÄËà¨Ê≠•È™§Â¶Ç‰∏ãÔºö\u003c/p\u003e\n\u003col\u003e\n\u003cli\u003e\n\u003cp\u003e\u003cstrong\u003eÂàÜËØç (Tokenization)\u003c/strong\u003e\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eÂ∞ÜÊñáÊú¨ÊãÜÂàÜ‰∏∫‰∏Ä‰∏™‰∏™ÂçïËØçÔºàTokenÔºâ„ÄÇ\u003c/li\u003e\n\u003cli\u003e‰æãÂ≠êÔºö\u003ccode\u003e\u0026quot;... to be or not to be...\u0026quot;\u003c/code\u003e ‚Üí \u003ccode\u003e[\u0026quot;...\u0026quot;, \u0026quot;to\u0026quot;, \u0026quot;be\u0026quot;, \u0026quot;or\u0026quot;, \u0026quot;not\u0026quot;, \u0026quot;to\u0026quot;, \u0026quot;be\u0026quot;, \u0026quot;...\u0026quot;]\u003c/code\u003e„ÄÇ\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003e\u003cstrong\u003eÁªüËÆ°ËØçÈ¢ë \u0026amp; ÊûÑÂª∫ËØçÂÖ∏\u003c/strong\u003e\u003c/p\u003e","title":""},{"content":"Text to Sequence ÊñáÊú¨Â§ÑÁêÜ\nStep1: Tokenization\nTokenization breaks a piece of text down into a list of tokens.\nHere, a token is a word. (A token can be a character in some applications.)\nTokenizationËÆ≤Á©∂ÂæàÂ§öÔºå‰æãÂ¶ÇÊòØÂê¶Â∫îËØ•ÊääÂ§ßÂÜôÊîπÊàêÂ∞èÂÜôÂë¢ÔºüËøõË°åtypo correctionÁ≠âÁ≠â\nStep2: Build Dictionary\nUse a dictionary (hash table) to count word frequencies.\nThe dictionary maps word to index.\nÂèØ‰ª•È¶ñÂÖàÁªüËÆ°ËØçÈ¢ëÂéªÊéâ‰ΩéÈ¢ëËØçÔºåÁÑ∂ÂêéËÆ©ÊØè‰∏™ËØçÂØπÂ∫î‰∏Ä‰∏™Ê≠£Êï¥Êï∞ÔºõËøôÊ†∑ÁöÑËØùÔºå‰∏ÄÂè•ËØùÂ∞±ÂèØ‰ª•Áî®‰∏Ä‰∏™Ê≠£Êï¥Êï∞ÂàóË°®Ë°®Á§∫ÔºåËøô‰∏™ÂàóË°®Â∞±Âè´sequenceÔºõÂ¶ÇÊûúÂøÖË¶ÅÂ∞±ËøòÂæóÂÅöone-hot encoding„ÄÇ\nÁªìÊûú\n‰ΩÜÊòØÈïøÂ∫¶‰∏çÁªü‰∏Ä\nStep4: ÂØπÈΩêsequence\nËß£ÂÜ≥ÊñπÊ°àÊòØËøôÊ†∑ÁöÑÔºöÂèØ‰ª•Âõ∫ÂÆöÈïøÂ∫¶‰∏∫wÔºåÂä†ÂÖ•‰∏Ä‰∏™Â∫èÂàóÈïøÂ∫¶Â§™ÈïøÔºåÂ∞±Á†çÊéâÂâçÈù¢ÁöÑËØçÔºåÂè™‰øùÁïôÊúÄÂêéw‰∏™ËØçÔºõÂ¶ÇÊûú‰∏Ä‰∏™Â∫èÂàóÂ§™Áü≠ÔºåÂ∞±ÂÅözero paddingÔºåÁî®0Â°´ÂÖÖ\nËøôÊ†∑‰∏ÄÊù•ÔºåÊâÄÊúâÁöÑÂ∫èÂàóÈïøÂ∫¶Â∞±Áªü‰∏Ä‰∫Ü\nÊñáÊú¨Â§ÑÁêÜÂÆåÊàê‰∫ÜÔºåÊé•‰∏ãÊù•ÊòØword embeddingÔºåÊääÂçïËØçË°®Á§∫‰∏∫‰∏Ä‰∏™‰ΩéÁª¥ÂêëÈáèÔºõ\nÁÑ∂ËÄåËøôÊ†∑ÂÅöÁöÑËØùÔºåÂ¶ÇÊûúÊòØ10000‰∏™ÂçïËØçÔºåÁª¥Â∫¶Â∞±ÊòØ10000Áª¥ÔºåÁª¥Â∫¶Â§™È´ò‰∫ÜÔºõÂõ†Ê≠§Ë¶ÅÂÅöword embeddingÔºõ\nÂÖ∑‰ΩìÂÅöÊ≥ïÂ∞±ÊòØÊääone-hotÂêëÈáèe_iÂíåÂèÇÊï∞Áü©ÈòµpÁõ∏‰πòÔºõÁü©ÈòµPËΩ¨ÁΩÆÁöÑÂ§ßÂ∞èÊòØd x vÔºõdÊòØËØçÂêëÈáèÁöÑÁª¥Â∫¶ÔºõvÊòØÂ≠óÂÖ∏ÈáåËØçÊ±áÁöÑÊï∞ÈáèÔºõÁªìÊûú‰∏∫x_iÔºõx_iÂ∞±ÊòØ‰∏Ä‰∏™ËØçÂêëÈáèÔºõÂ¶ÇÊûúone-hotÂêëÈáèÁöÑÁ¨¨‰∏âË°å‰∏∫1ÔºõÈÇ£‰πàx_iÂ∞±ÊòØPËΩ¨ÁΩÆÁü©ÈòµÁöÑÁ¨¨‰∏âÂàóÔºàÂÖ∂‰ΩôÂàóÈÉΩ‰∏∫0ÔºâÔºõÊâÄ‰ª•PËΩ¨ÁΩÆÊØè‰∏ÄÂàóÈÉΩÊòØ‰∏Ä‰∏™ËØçÂêëÈáèÔºõÊâÄ‰ª•Áü©ÈòµPÊú¨Ë∫´ÁöÑÊØè‰∏ÄË°åÂ∞±ÊòØ‰∏Ä‰∏™ËØçÂêëÈáèÔºõÂÖ∂Ë°åÊï∞‰∏∫vÔºõÂç≥vocabularyÔºåËØçÊ±áÈáèÔºõÊØè‰∏ÄË°åÂØπÂ∫î‰∏Ä‰∏™ÂçïËØçÔºõÁü©ÈòµÁöÑÂàóÊï∞‰∏∫dÔºõdÊòØÁî®Êà∑ÂÜ≥ÂÆöÁöÑÔºõdÁöÑÂ§ßÂ∞è‰ºöÂÜ≥ÂÆöÊú∫Âô®Â≠¶‰π†Ê®°ÂûãÁöÑË°®Áé∞ÔºõÂ∫îËØ•Áî®xxxÊù•ÈÄâÊã©‰∏Ä‰∏™ÊØîËæÉÂ•ΩÁöÑdÔºõ\nÊàë‰ª¨ÁöÑ‰ªªÂä°ÊòØÁúãËØÑËÆ∫ÊòØÊ≠£Èù¢ÁöÑËøòÊòØË¥üÈù¢ÁöÑÔºõÂèÇÊï∞Áü©ÈòµÊòØ‰ªéËÆ≠ÁªÉÊï∞ÊçÆ‰∏≠Â≠¶‰π†Âá∫Êù•ÁöÑÔºåÊâÄ‰ª•Â≠¶Âá∫Êù•ÁöÑËØçÂêëÈáèÊòØÂ∏¶ÊúâÊÑüÊÉÖËâ≤ÂΩ©ÁöÑÔºõÂÅáËÆæËøô‰∫õËØçÂêëÈáèÈÉΩÊòØ‰∫åÁª¥ÁöÑÔºåÂàôÂèØ‰ª•Âú®Âπ≥Èù¢ÂùêÊ†áÁ≥ª‰∏≠Ê†áÂá∫‰∏ãÈù¢ËØçÂêëÈáè\nkerasÊèê‰æõembeddingÂ±ÇÔºõÁî®Êà∑ÂèØ‰ª•ÊåáÂÆövocabularyÂ§ßÂ∞èÂíådÁöÑÂ§ßÂ∞èÔºõ‰ª•ÂèäÊØè‰∏Ä‰∏™sequenceÁöÑÈïøÂ∫¶ÔºõdÊòØÊ†πÊçÆÁÆóÊ≥ïÈÄâÂá∫Êù•ÁöÑ Âà∞Ëøô‰∏ÄÊ≠•ÔºåÊàë‰ª¨Â∑≤ÁªèÂÆåÊàê‰∫ÜÊñáÊú¨Â§ÑÁêÜÂíåword embedding„ÄÇÊé•‰∏ãÊù•Â∞±ÊòØÁî®Logistic Regression for Binary ClassificationÂÅö‰∫åÂàÜÁ±ªÔºõ\n","permalink":"http://localhost:1313/posts/nlp-2/","summary":"\u003ch3 id=\"text-to-sequence\"\u003eText to Sequence\u003c/h3\u003e\n\u003cp\u003eÊñáÊú¨Â§ÑÁêÜ\u003c/p\u003e\n\u003cp\u003eStep1: Tokenization\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\n\u003cp\u003eTokenization breaks a piece of text down into a list of tokens.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003eHere, a token is a word. (A token can be a character in some applications.)\u003c/p\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003eTokenizationËÆ≤Á©∂ÂæàÂ§öÔºå‰æãÂ¶ÇÊòØÂê¶Â∫îËØ•ÊääÂ§ßÂÜôÊîπÊàêÂ∞èÂÜôÂë¢ÔºüËøõË°åtypo correctionÁ≠âÁ≠â\u003c/p\u003e\n\u003cp\u003e\u003cimg alt=\"image-20250322150322238\" loading=\"lazy\" src=\"./NLP-2.assets/image-20250322150322238.png\"\u003e\u003c/p\u003e\n\u003cp\u003eStep2: Build Dictionary\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\n\u003cp\u003eUse a dictionary (hash table) to count word frequencies.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003eThe dictionary maps word to index.\u003c/p\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003eÂèØ‰ª•È¶ñÂÖàÁªüËÆ°ËØçÈ¢ëÂéªÊéâ‰ΩéÈ¢ëËØçÔºåÁÑ∂ÂêéËÆ©ÊØè‰∏™ËØçÂØπÂ∫î‰∏Ä‰∏™Ê≠£Êï¥Êï∞ÔºõËøôÊ†∑ÁöÑËØùÔºå‰∏ÄÂè•ËØùÂ∞±ÂèØ‰ª•Áî®‰∏Ä‰∏™Ê≠£Êï¥Êï∞ÂàóË°®Ë°®Á§∫ÔºåËøô‰∏™ÂàóË°®Â∞±Âè´sequenceÔºõÂ¶ÇÊûúÂøÖË¶ÅÂ∞±ËøòÂæóÂÅöone-hot encoding„ÄÇ\u003cimg alt=\"image-20250322150620890\" loading=\"lazy\" src=\"./NLP-2.assets/image-20250322150620890.png\"\u003e\u003c/p\u003e\n\u003cp\u003eÁªìÊûú\u003c/p\u003e\n\u003cp\u003e\u003cimg alt=\"image-20250322150754528\" loading=\"lazy\" src=\"./NLP-2.assets/image-20250322150754528.png\"\u003e\u003c/p\u003e\n\u003cp\u003e‰ΩÜÊòØÈïøÂ∫¶‰∏çÁªü‰∏Ä\u003c/p\u003e\n\u003cp\u003eStep4: ÂØπÈΩêsequence\u003c/p\u003e\n\u003cp\u003e\u003cimg alt=\"image-20250322150854986\" loading=\"lazy\" src=\"./NLP-2.assets/image-20250322150854986.png\"\u003e\u003c/p\u003e\n\u003cp\u003eËß£ÂÜ≥ÊñπÊ°àÊòØËøôÊ†∑ÁöÑÔºöÂèØ‰ª•Âõ∫ÂÆöÈïøÂ∫¶‰∏∫wÔºåÂä†ÂÖ•‰∏Ä‰∏™Â∫èÂàóÈïøÂ∫¶Â§™ÈïøÔºåÂ∞±Á†çÊéâÂâçÈù¢ÁöÑËØçÔºåÂè™‰øùÁïôÊúÄÂêéw‰∏™ËØçÔºõÂ¶ÇÊûú‰∏Ä‰∏™Â∫èÂàóÂ§™Áü≠ÔºåÂ∞±ÂÅözero paddingÔºåÁî®0Â°´ÂÖÖ\u003c/p\u003e\n\u003cp\u003e\u003cimg alt=\"image-20250322151030119\" loading=\"lazy\" src=\"./NLP-2.assets/image-20250322151030119.png\"\u003e\u003c/p\u003e\n\u003cp\u003eËøôÊ†∑‰∏ÄÊù•ÔºåÊâÄÊúâÁöÑÂ∫èÂàóÈïøÂ∫¶Â∞±Áªü‰∏Ä‰∫Ü\u003c/p\u003e\n\u003cp\u003e\u003cimg alt=\"image-20250322151117125\" loading=\"lazy\" src=\"./NLP-2.assets/image-20250322151117125.png\"\u003e\u003c/p\u003e\n\u003cp\u003eÊñáÊú¨Â§ÑÁêÜÂÆåÊàê‰∫ÜÔºåÊé•‰∏ãÊù•ÊòØword embeddingÔºåÊääÂçïËØçË°®Á§∫‰∏∫‰∏Ä‰∏™‰ΩéÁª¥ÂêëÈáèÔºõ\u003c/p\u003e\n\u003cp\u003e\u003cimg alt=\"image-20250322151252837\" loading=\"lazy\" src=\"./NLP-2.assets/image-20250322151252837.png\"\u003e\u003c/p\u003e","title":""},{"content":"üëã About me Hello! I\u0026rsquo;m Xu Zongsi, a passionate technology enthusiast currently pursuing my Master of Science in ECIC at The University of Hong Kong. With a solid background in Software Engineering from the Beijing Institute of Technology, I specialize in artificial intelligence areas like machine learning, deep learning, natural language processing, computer vision, and reinforcement learning.\nInspired by OpenAI\u0026rsquo;s five-step plan towards superintelligence, I am excited about AGI and have developed a keen interest in LLM agents, MLLM, and knowledge graphs. I see great potential in these fields and aspire to contribute to innovative solutions.\nüìö Education üá≠üá∞ The University of Hong Kong 09/2024 - Expected 11/2025 School of Computing and Data Science Master of Science in Electronic Commerce \u0026amp; Internet Computing Relevant Courses: Machine learning for business and e-commerce, Knowledge graphs, Financial fraud analytics, Internet infrastructure technologies, Website engineering, Blockchain and cryptocurrency, etc. üá®üá≥ Beijing Institute of Technology 09/2020 - 06/2024 School of Computer Science \u0026amp; Technology Bachelor of Engineering in Software Engineering, last two years GPA: 3.7/4 Relevant Courses: Reinforcement Learning, Deep Learning and Computer Vision, Artificial Intelligence and Robot Ethics, Almost Human: Mind, Brain and Artificial Intelligence, Mathematical Analysis for Engineering, Linear Algebra, Probability and Mathematical Statistics, etc. Skills: Python, Java, common data structures, design patterns, machine learning basics and algorithms, Linux, PyTorch, and some development tools (git, conda, etc.). üèÜ Awards \u0026amp; Honors Beijing Institute of Technology Undergraduate Scholarship (Top 20% of Grade) 06/2023 3rd Prize of China International \u0026#34;Internet \u0026#43;\u0026#34; College Student\u0026#39;s Innovation Competition 08/2022 Bronze Prize of \u0026#34;Challenge Cup\u0026#34; Capital University Entrepreneurship Competition 05/2022 üíº Project Experience üîç Online Transaction Fraud Detection 09/2024 ‚Äì 01/2025 Independent project, supervised by Dr. Vivien Chan Focused on addressing financial fraud in e-commerce to enhance the accuracy of transaction anomaly detection, while independently managing the entire case study that included data preprocessing, feature engineering, model building, evaluation, and results analysis. Effectively resolved class imbalance issues using SMOTE and ROSE techniques. Built various models including Logistic Regression, Random Forest, XGBoost, and LightGBM, ultimately selecting the LightGBM model to achieve a recall rate of 95.45% and an AUC of 99.84%. Wrote efficient and maintainable code, enhancing model training and data processing efficiency through parallel computing and logging. ü§ñ Multi-Model Intelligent Text Keyword Extraction System 08/2023 ‚Äì 09/2023 Group project, supervised by Associate Prof. Xiaolin Zhao Designed and implemented an intelligent text summary system that automatically extracts keywords from article titles and abstracts, enhancing the understanding and summarization of text information. Participated in the planning of the technical route and built a hybrid model combining extractive and generative approaches, utilizing advanced natural language processing techniques including KeyBERT, Sentence Transformer, BERT, and T5 models. Responsible for data preprocessing and tokenization, as well as the end-to-end implementation and training of the T5 model, optimizing the model architecture and hyperparameters, achieving satisfactory results after only 3 epochs of training. Model evaluation results showed that the Rouge-1, Rouge-2, and Rouge-L metrics reached 0.6345, 0.5038, and 0.5282, respectively, in the third epoch, validating the model\u0026rsquo;s effectiveness in the summarization task. üéì Cambridge University Machine Learning Summer Project 07/2023 ‚Äì 08/2023 Group project, supervised by Prof. Pietro Li√≤ Participated in the Cambridge University deep learning summer project, focusing on deep reinforcement learning; explored multi-agent learning algorithms across different environments. Reproduced the Multi-Agent Deep Deterministic Policy Gradient (MADDPG) algorithm in the Simple Adversary environment and studied the effect of agent numbers on convergence speed and stability, finding optimal stability at 21 agents. Designed and implemented comparative experiments inspired by the Rainbow algorithm, assessing target network strategies versus the Double Deep Q-Network (Double DQN). The results demonstrated that Double DQN significantly enhanced convergence speed, optimizing the overall learning process. Co-authored a group project paper on agent numbers and strategies effectiveness in multi-agent systems, achieving a score of 71% in the summer program (the highest in my group) and a \u0026ldquo;First Class\u0026rdquo; classification in the UK grading system. üëÅÔ∏è Deep Learning and Computer Vision Semester Project 09/2022 ‚Äì 12/2022 Independent project, supervised by Associate Prof. Guangyu Gao Designed and implemented a waste classifier using the ResNet model to improve classification accuracy and reduce resource waste. The project also enhanced understanding of transfer learning techniques with ResNet. Collected a dataset of 16 waste categories and preprocessed the images for uniformity and standardization, incorporating data augmentation techniques to enhance the dataset. Conducted experiments using ResNet34 and ResNet50 models through transfer learning, accelerating network convergence by leveraging pretrained weights. During training, techniques such as Batch Normalization and Dropout were applied to mitigate the risk of overfitting. The final model achieved an accuracy of 90% on the training set, while the performance on the test set was 61%, indicating a significant overfitting phenomenon during the training process. üéì Internship ‚öõÔ∏è Beijing Academy of Quantum Information Science 08/2023 ‚Äì 01/2024 Research Intern at Quantum Computation Department Proposed a quantum convolution kernel design based on variational quantum circuits and developed a universal quantum convolution layer, successfully integrating it into classical CNN architectures such as VGG, GoogLeNet, and ResNet. Developed and evaluated various hybrid models, including a simple model named HQCCNN-2, which achieved 84.45% accuracy on the FashionMNIST dataset, surpassing the traditional CNN\u0026rsquo;s 80.72%. This demonstrates the effectiveness of the quantum convolution layer in improving model performance. Tested on a real quantum computer further validated the effectiveness of the hybrid model, demonstrating the viable integration of quantum computing with deep learning, and highlighting the potential for leveraging quantum properties to enhance model performance. üèÖ Competition Experience ü•â China International \u0026#34;Internet \u0026#43;\u0026#34; College Students\u0026#39; Innovation Competition 08/2022 üõ°Ô∏è Zhongke Ushield: Deep Learning-based Face Privacy Protection Authentication System Responsible for constructing a localized facial feature extraction engine based on MobileFaceNet, ensuring feature extraction is completed on end devices (such as mobile phones and cameras), guaranteeing that raw data does not leave the domain and is not stored, thus enhancing user privacy protection while improving recognition efficiency. ü•â \u0026#34;Challenge Cup\u0026#34; Capital University Entrepreneurship Competition 05/2022 üå≥ Smart Orchard Responsible for the development of the fruit detection, ripeness prediction, and pest identification system, using deep convolutional neural network (CNN) technology for intelligent monitoring of crop growth conditions. Applied advanced object detection algorithms such as Faster R-CNN and YOLO to achieve high precision in apple detection and ripeness assessment, with an accuracy rate exceeding 90%, significantly enhancing the intelligence level of orchard management. Built and trained a dedicated dataset containing various pest samples, optimizing pest detection accuracy through data preprocessing (such as image normalization and resizing) and data augmentation techniques (like rotation, flipping, and noise addition), enabling the real-time monitoring system to accurately identify over 80% of pests, providing effective scientific maintenance recommendations to help farmers reduce crop losses. üìã Extracurricular Activities Vice President, Cyber Security Club, Beijing Institute of Technology 09/2021-09/2022 Backbone, Media Center of the Student Union of Beijing Institute of Technology 10/2020-06/2021 üì´ Contact üìß Email: zongsi.xu@outlook.com üëî LinkedIn: Zongsi (Tristan) Xu üíª GitHub: BaizeXS üìç Location: Hong Kong SAR, China ","permalink":"http://localhost:1313/resume/","summary":"Personal resume of Zongsi (Tristan) Xu","title":"Zongsi (Tristan) Xu"},{"content":"‰∏Ä„ÄÅÊï∞ÂÄºÁâπÂæÅ‰∏éÁ±ªÂà´ÁâπÂæÅ Êï∞ÂÄºÁâπÂæÅ (Numeric Features) ÂÖ∑ÊúâÂèØÂä†ÂáèÁöÑÊÑè‰πâÔºå‰∏îÂ≠òÂú®Â§ßÂ∞èÈ°∫Â∫è„ÄÇ ‰æãÂ≠êÔºöÂπ¥ÈæÑ„ÄÅÊ∏©Â∫¶Á≠â„ÄÇÂèØ‰ª•Áõ¥Êé•‰øùÁïôÂÖ∂Êï¥Êï∞ÊàñÊµÆÁÇπÊï∞ÂΩ¢Âºè‰æõÊ®°Âûã‰ΩøÁî®„ÄÇ Á±ªÂà´ÁâπÂæÅ (Categorical Features) Êï∞ÊçÆÂÄºÁ¶ªÊï£Ôºå‰∏çÂÖ∑Â§á‚ÄúÊï∞ÂÄºÂ§ßÂ∞è‚ÄùÈó¥ÁöÑÂèØÊØîÊÑè‰πâ„ÄÇ ‰æãÂ≠êÔºöÂõΩÁ±çÔºàÁæéÂõΩ/‰∏≠ÂõΩ/Âç∞Â∫¶Á≠âÔºâ„ÄÅÊÄßÂà´ÔºàÁî∑/Â•≥ÔºâÁ≠â„ÄÇ ÈóÆÈ¢òÔºöËã•‰ªÖÁî®Êï¥Êï∞Ë°®Á§∫ÔºàÁæéÂõΩ=1, ‰∏≠ÂõΩ=2ÔºâÔºå‰ºöÂºïÂÖ•ÈîôËØØÁöÑÊï∞ÂÄºËøêÁÆóÂÖ≥Á≥ªÔºåÂ¶Ç ‚ÄúÁæéÂõΩ + ‰∏≠ÂõΩ = Âç∞Â∫¶‚Äù„ÄÇ ‰∫å„ÄÅOne-HotÁºñÁ†ÅÁöÑÂä®Êú∫‰∏éÊµÅÁ®ã ‰∏∫‰ªÄ‰πà‰ΩøÁî®One-Hot\nÈÄöËøáÂ∞ÜÁ±ªÂà´Êò†Â∞Ñ‰∏∫ÂêëÈáèÔºåÈÅøÂÖçÊï¥Êï∞ÁºñÁ†ÅÂºïÂÖ•ÁöÑ‰º™Êï∞ÂÄºÂÖ≥Á≥ª„ÄÇ ÂêåÊó∂‰øùÁïôÂêÑÁßçÂèØËÉΩÁ±ªÂà´ÁöÑ‰ø°ÊÅØÔºå‰∏î‰ªÖÂú®ÂØπÂ∫î‰ΩçÁΩÆ‰∏∫1ÔºåÂÖ∂‰ªñ‰ΩçÁΩÆ‰∏∫0„ÄÇ Âª∫Á´ãÊò†Â∞ÑÔºö‰ªéÁ±ªÂà´Âà∞Á¥¢Âºï\n‰∏∫ÊØè‰∏™Á±ªÂà´ÂàÜÈÖç‰∏Ä‰∏™ÂîØ‰∏ÄÁ¥¢ÂºïÔºåÈÄöÂ∏∏‰ªé1ÂºÄÂßã„ÄÇ È¢ÑÁïôÁ¥¢Âºï0Ë°®Á§∫‚ÄúÊú™Áü•‚ÄùÊàñ‚ÄúÁº∫Â§±‚ÄùÔºåÂØπÂ∫îÂÖ®0ÂêëÈáè„ÄÇ ËΩ¨Êç¢‰∏∫One-HotÂêëÈáè\nËã•Á±ªÂà´ÊÄªÊï∞‰∏∫197ÔºåÂàôÁî®197Áª¥ÂêëÈáèË°®Á§∫„ÄÇ ‰æãÂ≠êÔºöÁæéÂõΩ [1, 0, 0, 0, ‚Ä¶]Ôºå ‰∏≠ÂõΩ [0, 1, 0, 0, ‚Ä¶]„ÄÇ Á§∫‰æãÔºöË°®Á§∫‰∏Ä‰∏™‰∫∫ÁöÑÁâπÂæÅ\nÁâπÂæÅÂåÖÂê´ÔºàÂπ¥ÈæÑ, ÊÄßÂà´, ÂõΩÁ±çÔºåÂÖ∂‰∏≠ÂõΩÁ±ç197ÁßçÔºâ Áª¥Â∫¶ÊÄªÂíåÔºö1Áª¥_age + 1Áª¥_gender + 197Áª¥_nationality = 199Áª¥„ÄÇ ‰æãÂ¶Ç (28, Â•≥, ‰∏≠ÂõΩ) ‚Üí [28, 0, 0, 1, 0, ‚Ä¶, 0]„ÄÇ ‰∏â„ÄÅÊñáÊú¨Êï∞ÊçÆÂ§ÑÁêÜÊµÅÁ®ã ÊñáÊú¨Âú®Ëá™ÁÑ∂ËØ≠Ë®ÄÂ§ÑÁêÜÔºàNLPÔºâ‰∏≠‰Ωú‰∏∫Â∏∏ËßÅÁöÑÂéüÂßãËæìÂÖ•ÔºåÈúÄË¶ÅÊï∞ÂÄºÂåñÊâçËÉΩÈÄÅÂÖ•Ê®°Âûã„ÄÇ‰∏ÄËà¨Ê≠•È™§Â¶Ç‰∏ãÔºö\nÂàÜËØç (Tokenization)\nÂ∞ÜÊñáÊú¨ÊãÜÂàÜ‰∏∫‰∏Ä‰∏™‰∏™ÂçïËØçÔºàTokenÔºâ„ÄÇ ‰æãÂ≠êÔºö\u0026quot;... to be or not to be...\u0026quot; ‚Üí [\u0026quot;...\u0026quot;, \u0026quot;to\u0026quot;, \u0026quot;be\u0026quot;, \u0026quot;or\u0026quot;, \u0026quot;not\u0026quot;, \u0026quot;to\u0026quot;, \u0026quot;be\u0026quot;, \u0026quot;...\u0026quot;]„ÄÇ ÁªüËÆ°ËØçÈ¢ë \u0026amp; ÊûÑÂª∫ËØçÂÖ∏\nËØçÈ¢ëÁªüËÆ° Áî®ÂìàÂ∏åË°®/Â≠óÂÖ∏ËÆ∞ÂΩïÊØè‰∏™ÂçïËØçÂá∫Áé∞Ê¨°Êï∞„ÄÇ ÈÅçÂéÜÊñáÊú¨Êó∂ÔºåËã•ÂçïËØçÂ∞öÊú™ÂÖ•Ë°®ÔºåÂàôÊñ∞Âª∫ËÆ∞ÂΩïÔºõËã•Â∑≤Â≠òÂú®ÔºåÂàôËÆ°Êï∞+1„ÄÇ ÊéíÂ∫è‰∏éÁ¥¢Âºï ÊåâËØçÈ¢ëÈôçÂ∫èÊéíÂ∫èÔºåËØçÈ¢ëÊúÄÈ´òÁöÑÂçïËØçÊéíÂú®ÂâçÈù¢„ÄÇ Á¥¢Âºï‰ªé1ÂºÄÂßãÔºå0ÁïôÁªô‚ÄúÊú™Áü•‚Äù„ÄÇ ËØçÂÖ∏ËßÑÊ®°ÔºàvocabularyÔºâÂèØËßÜÈúÄÊ±ÇÊà™Êñ≠Ôºà‰æãÂ¶ÇÂè™‰øùÁïôTop 10kÔºâ„ÄÇ ‰∏∫‰ªÄ‰πàÁßªÈô§‰ΩéÈ¢ëËØç ‰ΩéÈ¢ëËØçÂèØËÉΩÊòØÊãºÂÜôÈîôËØØ„ÄÅÁΩïËßÅ‰∫∫ÂêçÁ≠âÔºåÂØπÊ®°ÂûãÂ∏ÆÂä©ÊúâÈôê„ÄÇ ÂáèÂ∞ëËØçÂÖ∏ËßÑÊ®°ÂèØÈôç‰ΩéËøêÁÆóÂºÄÈîÄ„ÄÅÂä†Âø´Ê®°ÂûãËÆ≠ÁªÉ‰∏éÊé®ÁêÜÈÄüÂ∫¶„ÄÇ Áã¨ÁÉ≠ÁºñÁ†Å (One-Hot Encoding)\nÂ∞ÜÊØè‰∏™ÂçïËØçÊò†Â∞Ñ‰∏∫ËØçÂÖ∏‰∏≠ÁöÑÁ¥¢ÂºïÂêéÔºàÂ¶Ç [2, 4, 1, 8, ‚Ä¶]ÔºâÔºåÂèØËøõ‰∏ÄÊ≠•ËΩ¨Êç¢ÊàêOne-HotÂêëÈáè„ÄÇ One-HotÁª¥Â∫¶ÂèñÂÜ≥‰∫é‰øùÁïô‰∏ãÊù•ÁöÑËØçÂÖ∏Â§ßÂ∞èÔºà‰æãÂ¶Ç1‰∏áÔºâ„ÄÇ Êú™Êî∂ÂΩïÂçïËØçÂèØËÉΩÁõ¥Êé•ÂøΩÁï•ÔºåÊàñÁªü‰∏ÄÁî®Á¥¢Âºï0‰ª£Êõø„ÄÇ Âõõ„ÄÅÊ†∏ÂøÉÊî∂Ëé∑‰∏éÂ∫îÁî® Á±ªÂà´ÁâπÂæÅÂøÖÈúÄÊï∞ÂÄºÂåñÔºö\n‰ΩøÁî®Êï¥Êï∞1,2,3‚Ä¶‰ªÖË°®Á§∫Á±ªÂà´‚ÄúÊ†áËØÜ‚ÄùÔºåÂπ∂‰∏ç‰ª£Ë°®ÂÆÉ‰ª¨ÂèØËøõË°åÊï∞ÂÄºËøêÁÆó„ÄÇ Âõ†Ê≠§ÈúÄË¶ÅOne-HotÁ≠âÁºñÁ†ÅÊñπÂºèÔºåÈÅøÂÖçÊï∞ÂÄºËØØËß£„ÄÇ ÊñáÊú¨Êï∞ÊçÆÈ¢ÑÂ§ÑÁêÜÔºö\nÂàÜËØç„ÄÅËØçÈ¢ëÁªüËÆ°„ÄÅÊûÑÂª∫ËØçÂÖ∏„ÄÅÁ¥¢ÂºïÂåñ„ÄÅOne-HotÊàñÂÖ∂‰ªñÊñπÂºèÔºàÂ¶ÇËØçÂµåÂÖ•ÔºâÊòØÂ∏∏ËßÅÊµÅÁ®ã„ÄÇ Ê≠£Á°ÆÁöÑÊñáÊú¨È¢ÑÂ§ÑÁêÜÂèØÊòæËëóÂΩ±ÂìçÊ®°ÂûãÊÄßËÉΩÂíåÊïàÁéá„ÄÇ ‰øùÁïôÊú™Áü•Á¥¢ÂºïÔºö\n‰øùËØÅÂØπÁº∫Â§±Êï∞ÊçÆÊàñÂ≠óÂÖ∏Â§ñÊñ∞ËØçËÉΩÊúâÂü∫Êú¨ÁöÑË°®Á§∫ÔºåÊèêÂçáÊ®°ÂûãÂÆπÈîôÊÄß„ÄÇ ÂÆûÈôÖ‰ΩøÁî®Ôºö\nÂØπ‰∫éÂ∞èËßÑÊ®°Á±ªÂà´ÂèØÁõ¥Êé•One-HotÁºñÁ†ÅÔºõÂØπ‰∫éËØçÂÖ∏ÂæàÂ§ßÁöÑÂú∫ÊôØÔºåÈÄöÂ∏∏‰ºöËøõ‰∏ÄÊ≠•ËÄÉËôëËØçÂµåÂÖ•ÔºàWord EmbeddingÔºâÊàñÈ¢ÑËÆ≠ÁªÉËØ≠Ë®ÄÊ®°Âûã„ÄÇ ","permalink":"http://localhost:1313/posts/nlp-1/","summary":"\u003ch2 id=\"‰∏ÄÊï∞ÂÄºÁâπÂæÅ‰∏éÁ±ªÂà´ÁâπÂæÅ\"\u003e‰∏Ä„ÄÅÊï∞ÂÄºÁâπÂæÅ‰∏éÁ±ªÂà´ÁâπÂæÅ\u003c/h2\u003e\n\u003col\u003e\n\u003cli\u003e\u003cstrong\u003eÊï∞ÂÄºÁâπÂæÅ (Numeric Features)\u003c/strong\u003e\n\u003cul\u003e\n\u003cli\u003eÂÖ∑ÊúâÂèØÂä†ÂáèÁöÑÊÑè‰πâÔºå‰∏îÂ≠òÂú®Â§ßÂ∞èÈ°∫Â∫è„ÄÇ\u003c/li\u003e\n\u003cli\u003e‰æãÂ≠êÔºöÂπ¥ÈæÑ„ÄÅÊ∏©Â∫¶Á≠â„ÄÇÂèØ‰ª•Áõ¥Êé•‰øùÁïôÂÖ∂Êï¥Êï∞ÊàñÊµÆÁÇπÊï∞ÂΩ¢Âºè‰æõÊ®°Âûã‰ΩøÁî®„ÄÇ\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003eÁ±ªÂà´ÁâπÂæÅ (Categorical Features)\u003c/strong\u003e\n\u003cul\u003e\n\u003cli\u003eÊï∞ÊçÆÂÄºÁ¶ªÊï£Ôºå‰∏çÂÖ∑Â§á‚ÄúÊï∞ÂÄºÂ§ßÂ∞è‚ÄùÈó¥ÁöÑÂèØÊØîÊÑè‰πâ„ÄÇ\u003c/li\u003e\n\u003cli\u003e‰æãÂ≠êÔºöÂõΩÁ±çÔºàÁæéÂõΩ/‰∏≠ÂõΩ/Âç∞Â∫¶Á≠âÔºâ„ÄÅÊÄßÂà´ÔºàÁî∑/Â•≥ÔºâÁ≠â„ÄÇ\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003eÈóÆÈ¢ò\u003c/strong\u003eÔºöËã•‰ªÖÁî®Êï¥Êï∞Ë°®Á§∫ÔºàÁæéÂõΩ=1, ‰∏≠ÂõΩ=2ÔºâÔºå‰ºöÂºïÂÖ•ÈîôËØØÁöÑÊï∞ÂÄºËøêÁÆóÂÖ≥Á≥ªÔºåÂ¶Ç ‚ÄúÁæéÂõΩ + ‰∏≠ÂõΩ = Âç∞Â∫¶‚Äù„ÄÇ\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003c/ol\u003e\n\u003ch2 id=\"‰∫åone-hotÁºñÁ†ÅÁöÑÂä®Êú∫‰∏éÊµÅÁ®ã\"\u003e‰∫å„ÄÅOne-HotÁºñÁ†ÅÁöÑÂä®Êú∫‰∏éÊµÅÁ®ã\u003c/h2\u003e\n\u003col\u003e\n\u003cli\u003e\n\u003cp\u003e\u003cstrong\u003e‰∏∫‰ªÄ‰πà‰ΩøÁî®One-Hot\u003c/strong\u003e\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eÈÄöËøáÂ∞ÜÁ±ªÂà´Êò†Â∞Ñ‰∏∫ÂêëÈáèÔºåÈÅøÂÖçÊï¥Êï∞ÁºñÁ†ÅÂºïÂÖ•ÁöÑ‰º™Êï∞ÂÄºÂÖ≥Á≥ª„ÄÇ\u003c/li\u003e\n\u003cli\u003eÂêåÊó∂‰øùÁïôÂêÑÁßçÂèØËÉΩÁ±ªÂà´ÁöÑ‰ø°ÊÅØÔºå‰∏î‰ªÖÂú®ÂØπÂ∫î‰ΩçÁΩÆ‰∏∫1ÔºåÂÖ∂‰ªñ‰ΩçÁΩÆ‰∏∫0„ÄÇ\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003e\u003cstrong\u003eÂª∫Á´ãÊò†Â∞ÑÔºö‰ªéÁ±ªÂà´Âà∞Á¥¢Âºï\u003c/strong\u003e\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e‰∏∫ÊØè‰∏™Á±ªÂà´ÂàÜÈÖç‰∏Ä‰∏™ÂîØ‰∏ÄÁ¥¢ÂºïÔºåÈÄöÂ∏∏‰ªé1ÂºÄÂßã„ÄÇ\u003c/li\u003e\n\u003cli\u003eÈ¢ÑÁïôÁ¥¢Âºï0Ë°®Á§∫‚ÄúÊú™Áü•‚ÄùÊàñ‚ÄúÁº∫Â§±‚ÄùÔºåÂØπÂ∫îÂÖ®0ÂêëÈáè„ÄÇ\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003e\u003cstrong\u003eËΩ¨Êç¢‰∏∫One-HotÂêëÈáè\u003c/strong\u003e\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eËã•Á±ªÂà´ÊÄªÊï∞‰∏∫197ÔºåÂàôÁî®197Áª¥ÂêëÈáèË°®Á§∫„ÄÇ\u003c/li\u003e\n\u003cli\u003e‰æãÂ≠êÔºöÁæéÂõΩ \u003ccode\u003e[1, 0, 0, 0, ‚Ä¶]\u003c/code\u003eÔºå ‰∏≠ÂõΩ \u003ccode\u003e[0, 1, 0, 0, ‚Ä¶]\u003c/code\u003e„ÄÇ\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003e\u003cstrong\u003eÁ§∫‰æãÔºöË°®Á§∫‰∏Ä‰∏™‰∫∫ÁöÑÁâπÂæÅ\u003c/strong\u003e\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eÁâπÂæÅÂåÖÂê´ÔºàÂπ¥ÈæÑ, ÊÄßÂà´, ÂõΩÁ±çÔºåÂÖ∂‰∏≠ÂõΩÁ±ç197ÁßçÔºâ\u003c/li\u003e\n\u003cli\u003eÁª¥Â∫¶ÊÄªÂíåÔºö1Áª¥_age + 1Áª¥_gender + 197Áª¥_nationality = 199Áª¥„ÄÇ\u003c/li\u003e\n\u003cli\u003e‰æãÂ¶Ç \u003ccode\u003e(28, Â•≥, ‰∏≠ÂõΩ)\u003c/code\u003e ‚Üí \u003ccode\u003e[28, 0, 0, 1, 0, ‚Ä¶, 0]\u003c/code\u003e„ÄÇ\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003c/ol\u003e\n\u003ch2 id=\"‰∏âÊñáÊú¨Êï∞ÊçÆÂ§ÑÁêÜÊµÅÁ®ã\"\u003e‰∏â„ÄÅÊñáÊú¨Êï∞ÊçÆÂ§ÑÁêÜÊµÅÁ®ã\u003c/h2\u003e\n\u003cp\u003eÊñáÊú¨Âú®Ëá™ÁÑ∂ËØ≠Ë®ÄÂ§ÑÁêÜÔºàNLPÔºâ‰∏≠‰Ωú‰∏∫Â∏∏ËßÅÁöÑÂéüÂßãËæìÂÖ•ÔºåÈúÄË¶ÅÊï∞ÂÄºÂåñÊâçËÉΩÈÄÅÂÖ•Ê®°Âûã„ÄÇ‰∏ÄËà¨Ê≠•È™§Â¶Ç‰∏ãÔºö\u003c/p\u003e\n\u003col\u003e\n\u003cli\u003e\n\u003cp\u003e\u003cstrong\u003eÂàÜËØç (Tokenization)\u003c/strong\u003e\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eÂ∞ÜÊñáÊú¨ÊãÜÂàÜ‰∏∫‰∏Ä‰∏™‰∏™ÂçïËØçÔºàTokenÔºâ„ÄÇ\u003c/li\u003e\n\u003cli\u003e‰æãÂ≠êÔºö\u003ccode\u003e\u0026quot;... to be or not to be...\u0026quot;\u003c/code\u003e ‚Üí \u003ccode\u003e[\u0026quot;...\u0026quot;, \u0026quot;to\u0026quot;, \u0026quot;be\u0026quot;, \u0026quot;or\u0026quot;, \u0026quot;not\u0026quot;, \u0026quot;to\u0026quot;, \u0026quot;be\u0026quot;, \u0026quot;...\u0026quot;]\u003c/code\u003e„ÄÇ\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003e\u003cstrong\u003eÁªüËÆ°ËØçÈ¢ë \u0026amp; ÊûÑÂª∫ËØçÂÖ∏\u003c/strong\u003e\u003c/p\u003e","title":""},{"content":"Text to Sequence ÊñáÊú¨Â§ÑÁêÜ\nStep1: Tokenization\nTokenization breaks a piece of text down into a list of tokens.\nHere, a token is a word. (A token can be a character in some applications.)\nTokenizationËÆ≤Á©∂ÂæàÂ§öÔºå‰æãÂ¶ÇÊòØÂê¶Â∫îËØ•ÊääÂ§ßÂÜôÊîπÊàêÂ∞èÂÜôÂë¢ÔºüËøõË°åtypo correctionÁ≠âÁ≠â\nStep2: Build Dictionary\nUse a dictionary (hash table) to count word frequencies.\nThe dictionary maps word to index.\nÂèØ‰ª•È¶ñÂÖàÁªüËÆ°ËØçÈ¢ëÂéªÊéâ‰ΩéÈ¢ëËØçÔºåÁÑ∂ÂêéËÆ©ÊØè‰∏™ËØçÂØπÂ∫î‰∏Ä‰∏™Ê≠£Êï¥Êï∞ÔºõËøôÊ†∑ÁöÑËØùÔºå‰∏ÄÂè•ËØùÂ∞±ÂèØ‰ª•Áî®‰∏Ä‰∏™Ê≠£Êï¥Êï∞ÂàóË°®Ë°®Á§∫ÔºåËøô‰∏™ÂàóË°®Â∞±Âè´sequenceÔºõÂ¶ÇÊûúÂøÖË¶ÅÂ∞±ËøòÂæóÂÅöone-hot encoding„ÄÇ\nÁªìÊûú\n‰ΩÜÊòØÈïøÂ∫¶‰∏çÁªü‰∏Ä\nStep4: ÂØπÈΩêsequence\nËß£ÂÜ≥ÊñπÊ°àÊòØËøôÊ†∑ÁöÑÔºöÂèØ‰ª•Âõ∫ÂÆöÈïøÂ∫¶‰∏∫wÔºåÂä†ÂÖ•‰∏Ä‰∏™Â∫èÂàóÈïøÂ∫¶Â§™ÈïøÔºåÂ∞±Á†çÊéâÂâçÈù¢ÁöÑËØçÔºåÂè™‰øùÁïôÊúÄÂêéw‰∏™ËØçÔºõÂ¶ÇÊûú‰∏Ä‰∏™Â∫èÂàóÂ§™Áü≠ÔºåÂ∞±ÂÅözero paddingÔºåÁî®0Â°´ÂÖÖ\nËøôÊ†∑‰∏ÄÊù•ÔºåÊâÄÊúâÁöÑÂ∫èÂàóÈïøÂ∫¶Â∞±Áªü‰∏Ä‰∫Ü\nÊñáÊú¨Â§ÑÁêÜÂÆåÊàê‰∫ÜÔºåÊé•‰∏ãÊù•ÊòØword embeddingÔºåÊääÂçïËØçË°®Á§∫‰∏∫‰∏Ä‰∏™‰ΩéÁª¥ÂêëÈáèÔºõ\nÁÑ∂ËÄåËøôÊ†∑ÂÅöÁöÑËØùÔºåÂ¶ÇÊûúÊòØ10000‰∏™ÂçïËØçÔºåÁª¥Â∫¶Â∞±ÊòØ10000Áª¥ÔºåÁª¥Â∫¶Â§™È´ò‰∫ÜÔºõÂõ†Ê≠§Ë¶ÅÂÅöword embeddingÔºõ\nÂÖ∑‰ΩìÂÅöÊ≥ïÂ∞±ÊòØÊääone-hotÂêëÈáèe_iÂíåÂèÇÊï∞Áü©ÈòµpÁõ∏‰πòÔºõÁü©ÈòµPËΩ¨ÁΩÆÁöÑÂ§ßÂ∞èÊòØd x vÔºõdÊòØËØçÂêëÈáèÁöÑÁª¥Â∫¶ÔºõvÊòØÂ≠óÂÖ∏ÈáåËØçÊ±áÁöÑÊï∞ÈáèÔºõÁªìÊûú‰∏∫x_iÔºõx_iÂ∞±ÊòØ‰∏Ä‰∏™ËØçÂêëÈáèÔºõÂ¶ÇÊûúone-hotÂêëÈáèÁöÑÁ¨¨‰∏âË°å‰∏∫1ÔºõÈÇ£‰πàx_iÂ∞±ÊòØPËΩ¨ÁΩÆÁü©ÈòµÁöÑÁ¨¨‰∏âÂàóÔºàÂÖ∂‰ΩôÂàóÈÉΩ‰∏∫0ÔºâÔºõÊâÄ‰ª•PËΩ¨ÁΩÆÊØè‰∏ÄÂàóÈÉΩÊòØ‰∏Ä‰∏™ËØçÂêëÈáèÔºõÊâÄ‰ª•Áü©ÈòµPÊú¨Ë∫´ÁöÑÊØè‰∏ÄË°åÂ∞±ÊòØ‰∏Ä‰∏™ËØçÂêëÈáèÔºõÂÖ∂Ë°åÊï∞‰∏∫vÔºõÂç≥vocabularyÔºåËØçÊ±áÈáèÔºõÊØè‰∏ÄË°åÂØπÂ∫î‰∏Ä‰∏™ÂçïËØçÔºõÁü©ÈòµÁöÑÂàóÊï∞‰∏∫dÔºõdÊòØÁî®Êà∑ÂÜ≥ÂÆöÁöÑÔºõdÁöÑÂ§ßÂ∞è‰ºöÂÜ≥ÂÆöÊú∫Âô®Â≠¶‰π†Ê®°ÂûãÁöÑË°®Áé∞ÔºõÂ∫îËØ•Áî®xxxÊù•ÈÄâÊã©‰∏Ä‰∏™ÊØîËæÉÂ•ΩÁöÑdÔºõ\nÊàë‰ª¨ÁöÑ‰ªªÂä°ÊòØÁúãËØÑËÆ∫ÊòØÊ≠£Èù¢ÁöÑËøòÊòØË¥üÈù¢ÁöÑÔºõÂèÇÊï∞Áü©ÈòµÊòØ‰ªéËÆ≠ÁªÉÊï∞ÊçÆ‰∏≠Â≠¶‰π†Âá∫Êù•ÁöÑÔºåÊâÄ‰ª•Â≠¶Âá∫Êù•ÁöÑËØçÂêëÈáèÊòØÂ∏¶ÊúâÊÑüÊÉÖËâ≤ÂΩ©ÁöÑÔºõÂÅáËÆæËøô‰∫õËØçÂêëÈáèÈÉΩÊòØ‰∫åÁª¥ÁöÑÔºåÂàôÂèØ‰ª•Âú®Âπ≥Èù¢ÂùêÊ†áÁ≥ª‰∏≠Ê†áÂá∫‰∏ãÈù¢ËØçÂêëÈáè\nkerasÊèê‰æõembeddingÂ±ÇÔºõÁî®Êà∑ÂèØ‰ª•ÊåáÂÆövocabularyÂ§ßÂ∞èÂíådÁöÑÂ§ßÂ∞èÔºõ‰ª•ÂèäÊØè‰∏Ä‰∏™sequenceÁöÑÈïøÂ∫¶ÔºõdÊòØÊ†πÊçÆÁÆóÊ≥ïÈÄâÂá∫Êù•ÁöÑ Âà∞Ëøô‰∏ÄÊ≠•ÔºåÊàë‰ª¨Â∑≤ÁªèÂÆåÊàê‰∫ÜÊñáÊú¨Â§ÑÁêÜÂíåword embedding„ÄÇÊé•‰∏ãÊù•Â∞±ÊòØÁî®Logistic Regression for Binary ClassificationÂÅö‰∫åÂàÜÁ±ªÔºõ\n","permalink":"http://localhost:1313/posts/nlp-2/","summary":"\u003ch3 id=\"text-to-sequence\"\u003eText to Sequence\u003c/h3\u003e\n\u003cp\u003eÊñáÊú¨Â§ÑÁêÜ\u003c/p\u003e\n\u003cp\u003eStep1: Tokenization\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\n\u003cp\u003eTokenization breaks a piece of text down into a list of tokens.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003eHere, a token is a word. (A token can be a character in some applications.)\u003c/p\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003eTokenizationËÆ≤Á©∂ÂæàÂ§öÔºå‰æãÂ¶ÇÊòØÂê¶Â∫îËØ•ÊääÂ§ßÂÜôÊîπÊàêÂ∞èÂÜôÂë¢ÔºüËøõË°åtypo correctionÁ≠âÁ≠â\u003c/p\u003e\n\u003cp\u003e\u003cimg alt=\"image-20250322150322238\" loading=\"lazy\" src=\"./NLP-2.assets/image-20250322150322238.png\"\u003e\u003c/p\u003e\n\u003cp\u003eStep2: Build Dictionary\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\n\u003cp\u003eUse a dictionary (hash table) to count word frequencies.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003eThe dictionary maps word to index.\u003c/p\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003eÂèØ‰ª•È¶ñÂÖàÁªüËÆ°ËØçÈ¢ëÂéªÊéâ‰ΩéÈ¢ëËØçÔºåÁÑ∂ÂêéËÆ©ÊØè‰∏™ËØçÂØπÂ∫î‰∏Ä‰∏™Ê≠£Êï¥Êï∞ÔºõËøôÊ†∑ÁöÑËØùÔºå‰∏ÄÂè•ËØùÂ∞±ÂèØ‰ª•Áî®‰∏Ä‰∏™Ê≠£Êï¥Êï∞ÂàóË°®Ë°®Á§∫ÔºåËøô‰∏™ÂàóË°®Â∞±Âè´sequenceÔºõÂ¶ÇÊûúÂøÖË¶ÅÂ∞±ËøòÂæóÂÅöone-hot encoding„ÄÇ\u003cimg alt=\"image-20250322150620890\" loading=\"lazy\" src=\"./NLP-2.assets/image-20250322150620890.png\"\u003e\u003c/p\u003e\n\u003cp\u003eÁªìÊûú\u003c/p\u003e\n\u003cp\u003e\u003cimg alt=\"image-20250322150754528\" loading=\"lazy\" src=\"./NLP-2.assets/image-20250322150754528.png\"\u003e\u003c/p\u003e\n\u003cp\u003e‰ΩÜÊòØÈïøÂ∫¶‰∏çÁªü‰∏Ä\u003c/p\u003e\n\u003cp\u003eStep4: ÂØπÈΩêsequence\u003c/p\u003e\n\u003cp\u003e\u003cimg alt=\"image-20250322150854986\" loading=\"lazy\" src=\"./NLP-2.assets/image-20250322150854986.png\"\u003e\u003c/p\u003e\n\u003cp\u003eËß£ÂÜ≥ÊñπÊ°àÊòØËøôÊ†∑ÁöÑÔºöÂèØ‰ª•Âõ∫ÂÆöÈïøÂ∫¶‰∏∫wÔºåÂä†ÂÖ•‰∏Ä‰∏™Â∫èÂàóÈïøÂ∫¶Â§™ÈïøÔºåÂ∞±Á†çÊéâÂâçÈù¢ÁöÑËØçÔºåÂè™‰øùÁïôÊúÄÂêéw‰∏™ËØçÔºõÂ¶ÇÊûú‰∏Ä‰∏™Â∫èÂàóÂ§™Áü≠ÔºåÂ∞±ÂÅözero paddingÔºåÁî®0Â°´ÂÖÖ\u003c/p\u003e\n\u003cp\u003e\u003cimg alt=\"image-20250322151030119\" loading=\"lazy\" src=\"./NLP-2.assets/image-20250322151030119.png\"\u003e\u003c/p\u003e\n\u003cp\u003eËøôÊ†∑‰∏ÄÊù•ÔºåÊâÄÊúâÁöÑÂ∫èÂàóÈïøÂ∫¶Â∞±Áªü‰∏Ä‰∫Ü\u003c/p\u003e\n\u003cp\u003e\u003cimg alt=\"image-20250322151117125\" loading=\"lazy\" src=\"./NLP-2.assets/image-20250322151117125.png\"\u003e\u003c/p\u003e\n\u003cp\u003eÊñáÊú¨Â§ÑÁêÜÂÆåÊàê‰∫ÜÔºåÊé•‰∏ãÊù•ÊòØword embeddingÔºåÊääÂçïËØçË°®Á§∫‰∏∫‰∏Ä‰∏™‰ΩéÁª¥ÂêëÈáèÔºõ\u003c/p\u003e\n\u003cp\u003e\u003cimg alt=\"image-20250322151252837\" loading=\"lazy\" src=\"./NLP-2.assets/image-20250322151252837.png\"\u003e\u003c/p\u003e","title":""},{"content":"üëã About me Hello! I\u0026rsquo;m Xu Zongsi, a passionate technology enthusiast currently pursuing my Master of Science in ECIC at The University of Hong Kong. With a solid background in Software Engineering from the Beijing Institute of Technology, I specialize in artificial intelligence areas like machine learning, deep learning, natural language processing, computer vision, and reinforcement learning.\nInspired by OpenAI\u0026rsquo;s five-step plan towards superintelligence, I am excited about AGI and have developed a keen interest in LLM agents, MLLM, and knowledge graphs. I see great potential in these fields and aspire to contribute to innovative solutions.\nüìö Education üá≠üá∞ The University of Hong Kong 09/2024 - Expected 11/2025 School of Computing and Data Science Master of Science in Electronic Commerce \u0026amp; Internet Computing Relevant Courses: Machine learning for business and e-commerce, Knowledge graphs, Financial fraud analytics, Internet infrastructure technologies, Website engineering, Blockchain and cryptocurrency, etc. üá®üá≥ Beijing Institute of Technology 09/2020 - 06/2024 School of Computer Science \u0026amp; Technology Bachelor of Engineering in Software Engineering, last two years GPA: 3.7/4 Relevant Courses: Reinforcement Learning, Deep Learning and Computer Vision, Artificial Intelligence and Robot Ethics, Almost Human: Mind, Brain and Artificial Intelligence, Mathematical Analysis for Engineering, Linear Algebra, Probability and Mathematical Statistics, etc. Skills: Python, Java, common data structures, design patterns, machine learning basics and algorithms, Linux, PyTorch, and some development tools (git, conda, etc.). üèÜ Awards \u0026amp; Honors Beijing Institute of Technology Undergraduate Scholarship (Top 20% of Grade) 06/2023 3rd Prize of China International \u0026#34;Internet \u0026#43;\u0026#34; College Student\u0026#39;s Innovation Competition 08/2022 Bronze Prize of \u0026#34;Challenge Cup\u0026#34; Capital University Entrepreneurship Competition 05/2022 üíº Project Experience üîç Online Transaction Fraud Detection 09/2024 ‚Äì 01/2025 Independent project, supervised by Dr. Vivien Chan Focused on addressing financial fraud in e-commerce to enhance the accuracy of transaction anomaly detection, while independently managing the entire case study that included data preprocessing, feature engineering, model building, evaluation, and results analysis. Effectively resolved class imbalance issues using SMOTE and ROSE techniques. Built various models including Logistic Regression, Random Forest, XGBoost, and LightGBM, ultimately selecting the LightGBM model to achieve a recall rate of 95.45% and an AUC of 99.84%. Wrote efficient and maintainable code, enhancing model training and data processing efficiency through parallel computing and logging. ü§ñ Multi-Model Intelligent Text Keyword Extraction System 08/2023 ‚Äì 09/2023 Group project, supervised by Associate Prof. Xiaolin Zhao Designed and implemented an intelligent text summary system that automatically extracts keywords from article titles and abstracts, enhancing the understanding and summarization of text information. Participated in the planning of the technical route and built a hybrid model combining extractive and generative approaches, utilizing advanced natural language processing techniques including KeyBERT, Sentence Transformer, BERT, and T5 models. Responsible for data preprocessing and tokenization, as well as the end-to-end implementation and training of the T5 model, optimizing the model architecture and hyperparameters, achieving satisfactory results after only 3 epochs of training. Model evaluation results showed that the Rouge-1, Rouge-2, and Rouge-L metrics reached 0.6345, 0.5038, and 0.5282, respectively, in the third epoch, validating the model\u0026rsquo;s effectiveness in the summarization task. üéì Cambridge University Machine Learning Summer Project 07/2023 ‚Äì 08/2023 Group project, supervised by Prof. Pietro Li√≤ Participated in the Cambridge University deep learning summer project, focusing on deep reinforcement learning; explored multi-agent learning algorithms across different environments. Reproduced the Multi-Agent Deep Deterministic Policy Gradient (MADDPG) algorithm in the Simple Adversary environment and studied the effect of agent numbers on convergence speed and stability, finding optimal stability at 21 agents. Designed and implemented comparative experiments inspired by the Rainbow algorithm, assessing target network strategies versus the Double Deep Q-Network (Double DQN). The results demonstrated that Double DQN significantly enhanced convergence speed, optimizing the overall learning process. Co-authored a group project paper on agent numbers and strategies effectiveness in multi-agent systems, achieving a score of 71% in the summer program (the highest in my group) and a \u0026ldquo;First Class\u0026rdquo; classification in the UK grading system. üëÅÔ∏è Deep Learning and Computer Vision Semester Project 09/2022 ‚Äì 12/2022 Independent project, supervised by Associate Prof. Guangyu Gao Designed and implemented a waste classifier using the ResNet model to improve classification accuracy and reduce resource waste. The project also enhanced understanding of transfer learning techniques with ResNet. Collected a dataset of 16 waste categories and preprocessed the images for uniformity and standardization, incorporating data augmentation techniques to enhance the dataset. Conducted experiments using ResNet34 and ResNet50 models through transfer learning, accelerating network convergence by leveraging pretrained weights. During training, techniques such as Batch Normalization and Dropout were applied to mitigate the risk of overfitting. The final model achieved an accuracy of 90% on the training set, while the performance on the test set was 61%, indicating a significant overfitting phenomenon during the training process. üéì Internship ‚öõÔ∏è Beijing Academy of Quantum Information Science 08/2023 ‚Äì 01/2024 Research Intern at Quantum Computation Department Proposed a quantum convolution kernel design based on variational quantum circuits and developed a universal quantum convolution layer, successfully integrating it into classical CNN architectures such as VGG, GoogLeNet, and ResNet. Developed and evaluated various hybrid models, including a simple model named HQCCNN-2, which achieved 84.45% accuracy on the FashionMNIST dataset, surpassing the traditional CNN\u0026rsquo;s 80.72%. This demonstrates the effectiveness of the quantum convolution layer in improving model performance. Tested on a real quantum computer further validated the effectiveness of the hybrid model, demonstrating the viable integration of quantum computing with deep learning, and highlighting the potential for leveraging quantum properties to enhance model performance. üèÖ Competition Experience ü•â China International \u0026#34;Internet \u0026#43;\u0026#34; College Students\u0026#39; Innovation Competition 08/2022 üõ°Ô∏è Zhongke Ushield: Deep Learning-based Face Privacy Protection Authentication System Responsible for constructing a localized facial feature extraction engine based on MobileFaceNet, ensuring feature extraction is completed on end devices (such as mobile phones and cameras), guaranteeing that raw data does not leave the domain and is not stored, thus enhancing user privacy protection while improving recognition efficiency. ü•â \u0026#34;Challenge Cup\u0026#34; Capital University Entrepreneurship Competition 05/2022 üå≥ Smart Orchard Responsible for the development of the fruit detection, ripeness prediction, and pest identification system, using deep convolutional neural network (CNN) technology for intelligent monitoring of crop growth conditions. Applied advanced object detection algorithms such as Faster R-CNN and YOLO to achieve high precision in apple detection and ripeness assessment, with an accuracy rate exceeding 90%, significantly enhancing the intelligence level of orchard management. Built and trained a dedicated dataset containing various pest samples, optimizing pest detection accuracy through data preprocessing (such as image normalization and resizing) and data augmentation techniques (like rotation, flipping, and noise addition), enabling the real-time monitoring system to accurately identify over 80% of pests, providing effective scientific maintenance recommendations to help farmers reduce crop losses. üìã Extracurricular Activities Vice President, Cyber Security Club, Beijing Institute of Technology 09/2021-09/2022 Backbone, Media Center of the Student Union of Beijing Institute of Technology 10/2020-06/2021 üì´ Contact üìß Email: zongsi.xu@outlook.com üëî LinkedIn: Zongsi (Tristan) Xu üíª GitHub: BaizeXS üìç Location: Hong Kong SAR, China ","permalink":"http://localhost:1313/resume/","summary":"Personal resume of Zongsi (Tristan) Xu","title":"Zongsi (Tristan) Xu"},{"content":"‰∏Ä„ÄÅÊï∞ÂÄºÁâπÂæÅ‰∏éÁ±ªÂà´ÁâπÂæÅ Êï∞ÂÄºÁâπÂæÅ (Numeric Features) ÂÖ∑ÊúâÂèØÂä†ÂáèÁöÑÊÑè‰πâÔºå‰∏îÂ≠òÂú®Â§ßÂ∞èÈ°∫Â∫è„ÄÇ ‰æãÂ≠êÔºöÂπ¥ÈæÑ„ÄÅÊ∏©Â∫¶Á≠â„ÄÇÂèØ‰ª•Áõ¥Êé•‰øùÁïôÂÖ∂Êï¥Êï∞ÊàñÊµÆÁÇπÊï∞ÂΩ¢Âºè‰æõÊ®°Âûã‰ΩøÁî®„ÄÇ Á±ªÂà´ÁâπÂæÅ (Categorical Features) Êï∞ÊçÆÂÄºÁ¶ªÊï£Ôºå‰∏çÂÖ∑Â§á‚ÄúÊï∞ÂÄºÂ§ßÂ∞è‚ÄùÈó¥ÁöÑÂèØÊØîÊÑè‰πâ„ÄÇ ‰æãÂ≠êÔºöÂõΩÁ±çÔºàÁæéÂõΩ/‰∏≠ÂõΩ/Âç∞Â∫¶Á≠âÔºâ„ÄÅÊÄßÂà´ÔºàÁî∑/Â•≥ÔºâÁ≠â„ÄÇ ÈóÆÈ¢òÔºöËã•‰ªÖÁî®Êï¥Êï∞Ë°®Á§∫ÔºàÁæéÂõΩ=1, ‰∏≠ÂõΩ=2ÔºâÔºå‰ºöÂºïÂÖ•ÈîôËØØÁöÑÊï∞ÂÄºËøêÁÆóÂÖ≥Á≥ªÔºåÂ¶Ç ‚ÄúÁæéÂõΩ + ‰∏≠ÂõΩ = Âç∞Â∫¶‚Äù„ÄÇ ‰∫å„ÄÅOne-HotÁºñÁ†ÅÁöÑÂä®Êú∫‰∏éÊµÅÁ®ã ‰∏∫‰ªÄ‰πà‰ΩøÁî®One-Hot\nÈÄöËøáÂ∞ÜÁ±ªÂà´Êò†Â∞Ñ‰∏∫ÂêëÈáèÔºåÈÅøÂÖçÊï¥Êï∞ÁºñÁ†ÅÂºïÂÖ•ÁöÑ‰º™Êï∞ÂÄºÂÖ≥Á≥ª„ÄÇ ÂêåÊó∂‰øùÁïôÂêÑÁßçÂèØËÉΩÁ±ªÂà´ÁöÑ‰ø°ÊÅØÔºå‰∏î‰ªÖÂú®ÂØπÂ∫î‰ΩçÁΩÆ‰∏∫1ÔºåÂÖ∂‰ªñ‰ΩçÁΩÆ‰∏∫0„ÄÇ Âª∫Á´ãÊò†Â∞ÑÔºö‰ªéÁ±ªÂà´Âà∞Á¥¢Âºï\n‰∏∫ÊØè‰∏™Á±ªÂà´ÂàÜÈÖç‰∏Ä‰∏™ÂîØ‰∏ÄÁ¥¢ÂºïÔºåÈÄöÂ∏∏‰ªé1ÂºÄÂßã„ÄÇ È¢ÑÁïôÁ¥¢Âºï0Ë°®Á§∫‚ÄúÊú™Áü•‚ÄùÊàñ‚ÄúÁº∫Â§±‚ÄùÔºåÂØπÂ∫îÂÖ®0ÂêëÈáè„ÄÇ ËΩ¨Êç¢‰∏∫One-HotÂêëÈáè\nËã•Á±ªÂà´ÊÄªÊï∞‰∏∫197ÔºåÂàôÁî®197Áª¥ÂêëÈáèË°®Á§∫„ÄÇ ‰æãÂ≠êÔºöÁæéÂõΩ [1, 0, 0, 0, ‚Ä¶]Ôºå ‰∏≠ÂõΩ [0, 1, 0, 0, ‚Ä¶]„ÄÇ Á§∫‰æãÔºöË°®Á§∫‰∏Ä‰∏™‰∫∫ÁöÑÁâπÂæÅ\nÁâπÂæÅÂåÖÂê´ÔºàÂπ¥ÈæÑ, ÊÄßÂà´, ÂõΩÁ±çÔºåÂÖ∂‰∏≠ÂõΩÁ±ç197ÁßçÔºâ Áª¥Â∫¶ÊÄªÂíåÔºö1Áª¥_age + 1Áª¥_gender + 197Áª¥_nationality = 199Áª¥„ÄÇ ‰æãÂ¶Ç (28, Â•≥, ‰∏≠ÂõΩ) ‚Üí [28, 0, 0, 1, 0, ‚Ä¶, 0]„ÄÇ ‰∏â„ÄÅÊñáÊú¨Êï∞ÊçÆÂ§ÑÁêÜÊµÅÁ®ã ÊñáÊú¨Âú®Ëá™ÁÑ∂ËØ≠Ë®ÄÂ§ÑÁêÜÔºàNLPÔºâ‰∏≠‰Ωú‰∏∫Â∏∏ËßÅÁöÑÂéüÂßãËæìÂÖ•ÔºåÈúÄË¶ÅÊï∞ÂÄºÂåñÊâçËÉΩÈÄÅÂÖ•Ê®°Âûã„ÄÇ‰∏ÄËà¨Ê≠•È™§Â¶Ç‰∏ãÔºö\nÂàÜËØç (Tokenization)\nÂ∞ÜÊñáÊú¨ÊãÜÂàÜ‰∏∫‰∏Ä‰∏™‰∏™ÂçïËØçÔºàTokenÔºâ„ÄÇ ‰æãÂ≠êÔºö\u0026quot;... to be or not to be...\u0026quot; ‚Üí [\u0026quot;...\u0026quot;, \u0026quot;to\u0026quot;, \u0026quot;be\u0026quot;, \u0026quot;or\u0026quot;, \u0026quot;not\u0026quot;, \u0026quot;to\u0026quot;, \u0026quot;be\u0026quot;, \u0026quot;...\u0026quot;]„ÄÇ ÁªüËÆ°ËØçÈ¢ë \u0026amp; ÊûÑÂª∫ËØçÂÖ∏\nËØçÈ¢ëÁªüËÆ° Áî®ÂìàÂ∏åË°®/Â≠óÂÖ∏ËÆ∞ÂΩïÊØè‰∏™ÂçïËØçÂá∫Áé∞Ê¨°Êï∞„ÄÇ ÈÅçÂéÜÊñáÊú¨Êó∂ÔºåËã•ÂçïËØçÂ∞öÊú™ÂÖ•Ë°®ÔºåÂàôÊñ∞Âª∫ËÆ∞ÂΩïÔºõËã•Â∑≤Â≠òÂú®ÔºåÂàôËÆ°Êï∞+1„ÄÇ ÊéíÂ∫è‰∏éÁ¥¢Âºï ÊåâËØçÈ¢ëÈôçÂ∫èÊéíÂ∫èÔºåËØçÈ¢ëÊúÄÈ´òÁöÑÂçïËØçÊéíÂú®ÂâçÈù¢„ÄÇ Á¥¢Âºï‰ªé1ÂºÄÂßãÔºå0ÁïôÁªô‚ÄúÊú™Áü•‚Äù„ÄÇ ËØçÂÖ∏ËßÑÊ®°ÔºàvocabularyÔºâÂèØËßÜÈúÄÊ±ÇÊà™Êñ≠Ôºà‰æãÂ¶ÇÂè™‰øùÁïôTop 10kÔºâ„ÄÇ ‰∏∫‰ªÄ‰πàÁßªÈô§‰ΩéÈ¢ëËØç ‰ΩéÈ¢ëËØçÂèØËÉΩÊòØÊãºÂÜôÈîôËØØ„ÄÅÁΩïËßÅ‰∫∫ÂêçÁ≠âÔºåÂØπÊ®°ÂûãÂ∏ÆÂä©ÊúâÈôê„ÄÇ ÂáèÂ∞ëËØçÂÖ∏ËßÑÊ®°ÂèØÈôç‰ΩéËøêÁÆóÂºÄÈîÄ„ÄÅÂä†Âø´Ê®°ÂûãËÆ≠ÁªÉ‰∏éÊé®ÁêÜÈÄüÂ∫¶„ÄÇ Áã¨ÁÉ≠ÁºñÁ†Å (One-Hot Encoding)\nÂ∞ÜÊØè‰∏™ÂçïËØçÊò†Â∞Ñ‰∏∫ËØçÂÖ∏‰∏≠ÁöÑÁ¥¢ÂºïÂêéÔºàÂ¶Ç [2, 4, 1, 8, ‚Ä¶]ÔºâÔºåÂèØËøõ‰∏ÄÊ≠•ËΩ¨Êç¢ÊàêOne-HotÂêëÈáè„ÄÇ One-HotÁª¥Â∫¶ÂèñÂÜ≥‰∫é‰øùÁïô‰∏ãÊù•ÁöÑËØçÂÖ∏Â§ßÂ∞èÔºà‰æãÂ¶Ç1‰∏áÔºâ„ÄÇ Êú™Êî∂ÂΩïÂçïËØçÂèØËÉΩÁõ¥Êé•ÂøΩÁï•ÔºåÊàñÁªü‰∏ÄÁî®Á¥¢Âºï0‰ª£Êõø„ÄÇ Âõõ„ÄÅÊ†∏ÂøÉÊî∂Ëé∑‰∏éÂ∫îÁî® Á±ªÂà´ÁâπÂæÅÂøÖÈúÄÊï∞ÂÄºÂåñÔºö\n‰ΩøÁî®Êï¥Êï∞1,2,3‚Ä¶‰ªÖË°®Á§∫Á±ªÂà´‚ÄúÊ†áËØÜ‚ÄùÔºåÂπ∂‰∏ç‰ª£Ë°®ÂÆÉ‰ª¨ÂèØËøõË°åÊï∞ÂÄºËøêÁÆó„ÄÇ Âõ†Ê≠§ÈúÄË¶ÅOne-HotÁ≠âÁºñÁ†ÅÊñπÂºèÔºåÈÅøÂÖçÊï∞ÂÄºËØØËß£„ÄÇ ÊñáÊú¨Êï∞ÊçÆÈ¢ÑÂ§ÑÁêÜÔºö\nÂàÜËØç„ÄÅËØçÈ¢ëÁªüËÆ°„ÄÅÊûÑÂª∫ËØçÂÖ∏„ÄÅÁ¥¢ÂºïÂåñ„ÄÅOne-HotÊàñÂÖ∂‰ªñÊñπÂºèÔºàÂ¶ÇËØçÂµåÂÖ•ÔºâÊòØÂ∏∏ËßÅÊµÅÁ®ã„ÄÇ Ê≠£Á°ÆÁöÑÊñáÊú¨È¢ÑÂ§ÑÁêÜÂèØÊòæËëóÂΩ±ÂìçÊ®°ÂûãÊÄßËÉΩÂíåÊïàÁéá„ÄÇ ‰øùÁïôÊú™Áü•Á¥¢ÂºïÔºö\n‰øùËØÅÂØπÁº∫Â§±Êï∞ÊçÆÊàñÂ≠óÂÖ∏Â§ñÊñ∞ËØçËÉΩÊúâÂü∫Êú¨ÁöÑË°®Á§∫ÔºåÊèêÂçáÊ®°ÂûãÂÆπÈîôÊÄß„ÄÇ ÂÆûÈôÖ‰ΩøÁî®Ôºö\nÂØπ‰∫éÂ∞èËßÑÊ®°Á±ªÂà´ÂèØÁõ¥Êé•One-HotÁºñÁ†ÅÔºõÂØπ‰∫éËØçÂÖ∏ÂæàÂ§ßÁöÑÂú∫ÊôØÔºåÈÄöÂ∏∏‰ºöËøõ‰∏ÄÊ≠•ËÄÉËôëËØçÂµåÂÖ•ÔºàWord EmbeddingÔºâÊàñÈ¢ÑËÆ≠ÁªÉËØ≠Ë®ÄÊ®°Âûã„ÄÇ ","permalink":"http://localhost:1313/posts/nlp-1/","summary":"\u003ch2 id=\"‰∏ÄÊï∞ÂÄºÁâπÂæÅ‰∏éÁ±ªÂà´ÁâπÂæÅ\"\u003e‰∏Ä„ÄÅÊï∞ÂÄºÁâπÂæÅ‰∏éÁ±ªÂà´ÁâπÂæÅ\u003c/h2\u003e\n\u003col\u003e\n\u003cli\u003e\u003cstrong\u003eÊï∞ÂÄºÁâπÂæÅ (Numeric Features)\u003c/strong\u003e\n\u003cul\u003e\n\u003cli\u003eÂÖ∑ÊúâÂèØÂä†ÂáèÁöÑÊÑè‰πâÔºå‰∏îÂ≠òÂú®Â§ßÂ∞èÈ°∫Â∫è„ÄÇ\u003c/li\u003e\n\u003cli\u003e‰æãÂ≠êÔºöÂπ¥ÈæÑ„ÄÅÊ∏©Â∫¶Á≠â„ÄÇÂèØ‰ª•Áõ¥Êé•‰øùÁïôÂÖ∂Êï¥Êï∞ÊàñÊµÆÁÇπÊï∞ÂΩ¢Âºè‰æõÊ®°Âûã‰ΩøÁî®„ÄÇ\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003eÁ±ªÂà´ÁâπÂæÅ (Categorical Features)\u003c/strong\u003e\n\u003cul\u003e\n\u003cli\u003eÊï∞ÊçÆÂÄºÁ¶ªÊï£Ôºå‰∏çÂÖ∑Â§á‚ÄúÊï∞ÂÄºÂ§ßÂ∞è‚ÄùÈó¥ÁöÑÂèØÊØîÊÑè‰πâ„ÄÇ\u003c/li\u003e\n\u003cli\u003e‰æãÂ≠êÔºöÂõΩÁ±çÔºàÁæéÂõΩ/‰∏≠ÂõΩ/Âç∞Â∫¶Á≠âÔºâ„ÄÅÊÄßÂà´ÔºàÁî∑/Â•≥ÔºâÁ≠â„ÄÇ\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003eÈóÆÈ¢ò\u003c/strong\u003eÔºöËã•‰ªÖÁî®Êï¥Êï∞Ë°®Á§∫ÔºàÁæéÂõΩ=1, ‰∏≠ÂõΩ=2ÔºâÔºå‰ºöÂºïÂÖ•ÈîôËØØÁöÑÊï∞ÂÄºËøêÁÆóÂÖ≥Á≥ªÔºåÂ¶Ç ‚ÄúÁæéÂõΩ + ‰∏≠ÂõΩ = Âç∞Â∫¶‚Äù„ÄÇ\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003c/ol\u003e\n\u003ch2 id=\"‰∫åone-hotÁºñÁ†ÅÁöÑÂä®Êú∫‰∏éÊµÅÁ®ã\"\u003e‰∫å„ÄÅOne-HotÁºñÁ†ÅÁöÑÂä®Êú∫‰∏éÊµÅÁ®ã\u003c/h2\u003e\n\u003col\u003e\n\u003cli\u003e\n\u003cp\u003e\u003cstrong\u003e‰∏∫‰ªÄ‰πà‰ΩøÁî®One-Hot\u003c/strong\u003e\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eÈÄöËøáÂ∞ÜÁ±ªÂà´Êò†Â∞Ñ‰∏∫ÂêëÈáèÔºåÈÅøÂÖçÊï¥Êï∞ÁºñÁ†ÅÂºïÂÖ•ÁöÑ‰º™Êï∞ÂÄºÂÖ≥Á≥ª„ÄÇ\u003c/li\u003e\n\u003cli\u003eÂêåÊó∂‰øùÁïôÂêÑÁßçÂèØËÉΩÁ±ªÂà´ÁöÑ‰ø°ÊÅØÔºå‰∏î‰ªÖÂú®ÂØπÂ∫î‰ΩçÁΩÆ‰∏∫1ÔºåÂÖ∂‰ªñ‰ΩçÁΩÆ‰∏∫0„ÄÇ\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003e\u003cstrong\u003eÂª∫Á´ãÊò†Â∞ÑÔºö‰ªéÁ±ªÂà´Âà∞Á¥¢Âºï\u003c/strong\u003e\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e‰∏∫ÊØè‰∏™Á±ªÂà´ÂàÜÈÖç‰∏Ä‰∏™ÂîØ‰∏ÄÁ¥¢ÂºïÔºåÈÄöÂ∏∏‰ªé1ÂºÄÂßã„ÄÇ\u003c/li\u003e\n\u003cli\u003eÈ¢ÑÁïôÁ¥¢Âºï0Ë°®Á§∫‚ÄúÊú™Áü•‚ÄùÊàñ‚ÄúÁº∫Â§±‚ÄùÔºåÂØπÂ∫îÂÖ®0ÂêëÈáè„ÄÇ\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003e\u003cstrong\u003eËΩ¨Êç¢‰∏∫One-HotÂêëÈáè\u003c/strong\u003e\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eËã•Á±ªÂà´ÊÄªÊï∞‰∏∫197ÔºåÂàôÁî®197Áª¥ÂêëÈáèË°®Á§∫„ÄÇ\u003c/li\u003e\n\u003cli\u003e‰æãÂ≠êÔºöÁæéÂõΩ \u003ccode\u003e[1, 0, 0, 0, ‚Ä¶]\u003c/code\u003eÔºå ‰∏≠ÂõΩ \u003ccode\u003e[0, 1, 0, 0, ‚Ä¶]\u003c/code\u003e„ÄÇ\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003e\u003cstrong\u003eÁ§∫‰æãÔºöË°®Á§∫‰∏Ä‰∏™‰∫∫ÁöÑÁâπÂæÅ\u003c/strong\u003e\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eÁâπÂæÅÂåÖÂê´ÔºàÂπ¥ÈæÑ, ÊÄßÂà´, ÂõΩÁ±çÔºåÂÖ∂‰∏≠ÂõΩÁ±ç197ÁßçÔºâ\u003c/li\u003e\n\u003cli\u003eÁª¥Â∫¶ÊÄªÂíåÔºö1Áª¥_age + 1Áª¥_gender + 197Áª¥_nationality = 199Áª¥„ÄÇ\u003c/li\u003e\n\u003cli\u003e‰æãÂ¶Ç \u003ccode\u003e(28, Â•≥, ‰∏≠ÂõΩ)\u003c/code\u003e ‚Üí \u003ccode\u003e[28, 0, 0, 1, 0, ‚Ä¶, 0]\u003c/code\u003e„ÄÇ\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003c/ol\u003e\n\u003ch2 id=\"‰∏âÊñáÊú¨Êï∞ÊçÆÂ§ÑÁêÜÊµÅÁ®ã\"\u003e‰∏â„ÄÅÊñáÊú¨Êï∞ÊçÆÂ§ÑÁêÜÊµÅÁ®ã\u003c/h2\u003e\n\u003cp\u003eÊñáÊú¨Âú®Ëá™ÁÑ∂ËØ≠Ë®ÄÂ§ÑÁêÜÔºàNLPÔºâ‰∏≠‰Ωú‰∏∫Â∏∏ËßÅÁöÑÂéüÂßãËæìÂÖ•ÔºåÈúÄË¶ÅÊï∞ÂÄºÂåñÊâçËÉΩÈÄÅÂÖ•Ê®°Âûã„ÄÇ‰∏ÄËà¨Ê≠•È™§Â¶Ç‰∏ãÔºö\u003c/p\u003e\n\u003col\u003e\n\u003cli\u003e\n\u003cp\u003e\u003cstrong\u003eÂàÜËØç (Tokenization)\u003c/strong\u003e\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eÂ∞ÜÊñáÊú¨ÊãÜÂàÜ‰∏∫‰∏Ä‰∏™‰∏™ÂçïËØçÔºàTokenÔºâ„ÄÇ\u003c/li\u003e\n\u003cli\u003e‰æãÂ≠êÔºö\u003ccode\u003e\u0026quot;... to be or not to be...\u0026quot;\u003c/code\u003e ‚Üí \u003ccode\u003e[\u0026quot;...\u0026quot;, \u0026quot;to\u0026quot;, \u0026quot;be\u0026quot;, \u0026quot;or\u0026quot;, \u0026quot;not\u0026quot;, \u0026quot;to\u0026quot;, \u0026quot;be\u0026quot;, \u0026quot;...\u0026quot;]\u003c/code\u003e„ÄÇ\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003e\u003cstrong\u003eÁªüËÆ°ËØçÈ¢ë \u0026amp; ÊûÑÂª∫ËØçÂÖ∏\u003c/strong\u003e\u003c/p\u003e","title":""},{"content":"Text to Sequence ÊñáÊú¨Â§ÑÁêÜ\nStep1: Tokenization\nTokenization breaks a piece of text down into a list of tokens.\nHere, a token is a word. (A token can be a character in some applications.)\nTokenizationËÆ≤Á©∂ÂæàÂ§öÔºå‰æãÂ¶ÇÊòØÂê¶Â∫îËØ•ÊääÂ§ßÂÜôÊîπÊàêÂ∞èÂÜôÂë¢ÔºüËøõË°åtypo correctionÁ≠âÁ≠â\nStep2: Build Dictionary\nUse a dictionary (hash table) to count word frequencies.\nThe dictionary maps word to index.\nÂèØ‰ª•È¶ñÂÖàÁªüËÆ°ËØçÈ¢ëÂéªÊéâ‰ΩéÈ¢ëËØçÔºåÁÑ∂ÂêéËÆ©ÊØè‰∏™ËØçÂØπÂ∫î‰∏Ä‰∏™Ê≠£Êï¥Êï∞ÔºõËøôÊ†∑ÁöÑËØùÔºå‰∏ÄÂè•ËØùÂ∞±ÂèØ‰ª•Áî®‰∏Ä‰∏™Ê≠£Êï¥Êï∞ÂàóË°®Ë°®Á§∫ÔºåËøô‰∏™ÂàóË°®Â∞±Âè´sequenceÔºõÂ¶ÇÊûúÂøÖË¶ÅÂ∞±ËøòÂæóÂÅöone-hot encoding„ÄÇ\nÁªìÊûú\n‰ΩÜÊòØÈïøÂ∫¶‰∏çÁªü‰∏Ä\nStep4: ÂØπÈΩêsequence\nËß£ÂÜ≥ÊñπÊ°àÊòØËøôÊ†∑ÁöÑÔºöÂèØ‰ª•Âõ∫ÂÆöÈïøÂ∫¶‰∏∫wÔºåÂä†ÂÖ•‰∏Ä‰∏™Â∫èÂàóÈïøÂ∫¶Â§™ÈïøÔºåÂ∞±Á†çÊéâÂâçÈù¢ÁöÑËØçÔºåÂè™‰øùÁïôÊúÄÂêéw‰∏™ËØçÔºõÂ¶ÇÊûú‰∏Ä‰∏™Â∫èÂàóÂ§™Áü≠ÔºåÂ∞±ÂÅözero paddingÔºåÁî®0Â°´ÂÖÖ\nËøôÊ†∑‰∏ÄÊù•ÔºåÊâÄÊúâÁöÑÂ∫èÂàóÈïøÂ∫¶Â∞±Áªü‰∏Ä‰∫Ü\nÊñáÊú¨Â§ÑÁêÜÂÆåÊàê‰∫ÜÔºåÊé•‰∏ãÊù•ÊòØword embeddingÔºåÊääÂçïËØçË°®Á§∫‰∏∫‰∏Ä‰∏™‰ΩéÁª¥ÂêëÈáèÔºõ\nÁÑ∂ËÄåËøôÊ†∑ÂÅöÁöÑËØùÔºåÂ¶ÇÊûúÊòØ10000‰∏™ÂçïËØçÔºåÁª¥Â∫¶Â∞±ÊòØ10000Áª¥ÔºåÁª¥Â∫¶Â§™È´ò‰∫ÜÔºõÂõ†Ê≠§Ë¶ÅÂÅöword embeddingÔºõ\nÂÖ∑‰ΩìÂÅöÊ≥ïÂ∞±ÊòØÊääone-hotÂêëÈáèe_iÂíåÂèÇÊï∞Áü©ÈòµpÁõ∏‰πòÔºõÁü©ÈòµPËΩ¨ÁΩÆÁöÑÂ§ßÂ∞èÊòØd x vÔºõdÊòØËØçÂêëÈáèÁöÑÁª¥Â∫¶ÔºõvÊòØÂ≠óÂÖ∏ÈáåËØçÊ±áÁöÑÊï∞ÈáèÔºõÁªìÊûú‰∏∫x_iÔºõx_iÂ∞±ÊòØ‰∏Ä‰∏™ËØçÂêëÈáèÔºõÂ¶ÇÊûúone-hotÂêëÈáèÁöÑÁ¨¨‰∏âË°å‰∏∫1ÔºõÈÇ£‰πàx_iÂ∞±ÊòØPËΩ¨ÁΩÆÁü©ÈòµÁöÑÁ¨¨‰∏âÂàóÔºàÂÖ∂‰ΩôÂàóÈÉΩ‰∏∫0ÔºâÔºõÊâÄ‰ª•PËΩ¨ÁΩÆÊØè‰∏ÄÂàóÈÉΩÊòØ‰∏Ä‰∏™ËØçÂêëÈáèÔºõÊâÄ‰ª•Áü©ÈòµPÊú¨Ë∫´ÁöÑÊØè‰∏ÄË°åÂ∞±ÊòØ‰∏Ä‰∏™ËØçÂêëÈáèÔºõÂÖ∂Ë°åÊï∞‰∏∫vÔºõÂç≥vocabularyÔºåËØçÊ±áÈáèÔºõÊØè‰∏ÄË°åÂØπÂ∫î‰∏Ä‰∏™ÂçïËØçÔºõÁü©ÈòµÁöÑÂàóÊï∞‰∏∫dÔºõdÊòØÁî®Êà∑ÂÜ≥ÂÆöÁöÑÔºõdÁöÑÂ§ßÂ∞è‰ºöÂÜ≥ÂÆöÊú∫Âô®Â≠¶‰π†Ê®°ÂûãÁöÑË°®Áé∞ÔºõÂ∫îËØ•Áî®xxxÊù•ÈÄâÊã©‰∏Ä‰∏™ÊØîËæÉÂ•ΩÁöÑdÔºõ\nÊàë‰ª¨ÁöÑ‰ªªÂä°ÊòØÁúãËØÑËÆ∫ÊòØÊ≠£Èù¢ÁöÑËøòÊòØË¥üÈù¢ÁöÑÔºõÂèÇÊï∞Áü©ÈòµÊòØ‰ªéËÆ≠ÁªÉÊï∞ÊçÆ‰∏≠Â≠¶‰π†Âá∫Êù•ÁöÑÔºåÊâÄ‰ª•Â≠¶Âá∫Êù•ÁöÑËØçÂêëÈáèÊòØÂ∏¶ÊúâÊÑüÊÉÖËâ≤ÂΩ©ÁöÑÔºõÂÅáËÆæËøô‰∫õËØçÂêëÈáèÈÉΩÊòØ‰∫åÁª¥ÁöÑÔºåÂàôÂèØ‰ª•Âú®Âπ≥Èù¢ÂùêÊ†áÁ≥ª‰∏≠Ê†áÂá∫‰∏ãÈù¢ËØçÂêëÈáè\nkerasÊèê‰æõembeddingÂ±ÇÔºõÁî®Êà∑ÂèØ‰ª•ÊåáÂÆövocabularyÂ§ßÂ∞èÂíådÁöÑÂ§ßÂ∞èÔºõ‰ª•ÂèäÊØè‰∏Ä‰∏™sequenceÁöÑÈïøÂ∫¶ÔºõdÊòØÊ†πÊçÆÁÆóÊ≥ïÈÄâÂá∫Êù•ÁöÑ Âà∞Ëøô‰∏ÄÊ≠•ÔºåÊàë‰ª¨Â∑≤ÁªèÂÆåÊàê‰∫ÜÊñáÊú¨Â§ÑÁêÜÂíåword embedding„ÄÇÊé•‰∏ãÊù•Â∞±ÊòØÁî®Logistic Regression for Binary ClassificationÂÅö‰∫åÂàÜÁ±ªÔºõ\n","permalink":"http://localhost:1313/posts/nlp-2/","summary":"\u003ch3 id=\"text-to-sequence\"\u003eText to Sequence\u003c/h3\u003e\n\u003cp\u003eÊñáÊú¨Â§ÑÁêÜ\u003c/p\u003e\n\u003cp\u003eStep1: Tokenization\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\n\u003cp\u003eTokenization breaks a piece of text down into a list of tokens.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003eHere, a token is a word. (A token can be a character in some applications.)\u003c/p\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003eTokenizationËÆ≤Á©∂ÂæàÂ§öÔºå‰æãÂ¶ÇÊòØÂê¶Â∫îËØ•ÊääÂ§ßÂÜôÊîπÊàêÂ∞èÂÜôÂë¢ÔºüËøõË°åtypo correctionÁ≠âÁ≠â\u003c/p\u003e\n\u003cp\u003e\u003cimg alt=\"image-20250322150322238\" loading=\"lazy\" src=\"./NLP-2.assets/image-20250322150322238.png\"\u003e\u003c/p\u003e\n\u003cp\u003eStep2: Build Dictionary\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\n\u003cp\u003eUse a dictionary (hash table) to count word frequencies.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003eThe dictionary maps word to index.\u003c/p\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003eÂèØ‰ª•È¶ñÂÖàÁªüËÆ°ËØçÈ¢ëÂéªÊéâ‰ΩéÈ¢ëËØçÔºåÁÑ∂ÂêéËÆ©ÊØè‰∏™ËØçÂØπÂ∫î‰∏Ä‰∏™Ê≠£Êï¥Êï∞ÔºõËøôÊ†∑ÁöÑËØùÔºå‰∏ÄÂè•ËØùÂ∞±ÂèØ‰ª•Áî®‰∏Ä‰∏™Ê≠£Êï¥Êï∞ÂàóË°®Ë°®Á§∫ÔºåËøô‰∏™ÂàóË°®Â∞±Âè´sequenceÔºõÂ¶ÇÊûúÂøÖË¶ÅÂ∞±ËøòÂæóÂÅöone-hot encoding„ÄÇ\u003cimg alt=\"image-20250322150620890\" loading=\"lazy\" src=\"./NLP-2.assets/image-20250322150620890.png\"\u003e\u003c/p\u003e\n\u003cp\u003eÁªìÊûú\u003c/p\u003e\n\u003cp\u003e\u003cimg alt=\"image-20250322150754528\" loading=\"lazy\" src=\"./NLP-2.assets/image-20250322150754528.png\"\u003e\u003c/p\u003e\n\u003cp\u003e‰ΩÜÊòØÈïøÂ∫¶‰∏çÁªü‰∏Ä\u003c/p\u003e\n\u003cp\u003eStep4: ÂØπÈΩêsequence\u003c/p\u003e\n\u003cp\u003e\u003cimg alt=\"image-20250322150854986\" loading=\"lazy\" src=\"./NLP-2.assets/image-20250322150854986.png\"\u003e\u003c/p\u003e\n\u003cp\u003eËß£ÂÜ≥ÊñπÊ°àÊòØËøôÊ†∑ÁöÑÔºöÂèØ‰ª•Âõ∫ÂÆöÈïøÂ∫¶‰∏∫wÔºåÂä†ÂÖ•‰∏Ä‰∏™Â∫èÂàóÈïøÂ∫¶Â§™ÈïøÔºåÂ∞±Á†çÊéâÂâçÈù¢ÁöÑËØçÔºåÂè™‰øùÁïôÊúÄÂêéw‰∏™ËØçÔºõÂ¶ÇÊûú‰∏Ä‰∏™Â∫èÂàóÂ§™Áü≠ÔºåÂ∞±ÂÅözero paddingÔºåÁî®0Â°´ÂÖÖ\u003c/p\u003e\n\u003cp\u003e\u003cimg alt=\"image-20250322151030119\" loading=\"lazy\" src=\"./NLP-2.assets/image-20250322151030119.png\"\u003e\u003c/p\u003e\n\u003cp\u003eËøôÊ†∑‰∏ÄÊù•ÔºåÊâÄÊúâÁöÑÂ∫èÂàóÈïøÂ∫¶Â∞±Áªü‰∏Ä‰∫Ü\u003c/p\u003e\n\u003cp\u003e\u003cimg alt=\"image-20250322151117125\" loading=\"lazy\" src=\"./NLP-2.assets/image-20250322151117125.png\"\u003e\u003c/p\u003e\n\u003cp\u003eÊñáÊú¨Â§ÑÁêÜÂÆåÊàê‰∫ÜÔºåÊé•‰∏ãÊù•ÊòØword embeddingÔºåÊääÂçïËØçË°®Á§∫‰∏∫‰∏Ä‰∏™‰ΩéÁª¥ÂêëÈáèÔºõ\u003c/p\u003e\n\u003cp\u003e\u003cimg alt=\"image-20250322151252837\" loading=\"lazy\" src=\"./NLP-2.assets/image-20250322151252837.png\"\u003e\u003c/p\u003e","title":""},{"content":"üëã About me Hello! I\u0026rsquo;m Xu Zongsi, a passionate technology enthusiast currently pursuing my Master of Science in ECIC at The University of Hong Kong. With a solid background in Software Engineering from the Beijing Institute of Technology, I specialize in artificial intelligence areas like machine learning, deep learning, natural language processing, computer vision, and reinforcement learning.\nInspired by OpenAI\u0026rsquo;s five-step plan towards superintelligence, I am excited about AGI and have developed a keen interest in LLM agents, MLLM, and knowledge graphs. I see great potential in these fields and aspire to contribute to innovative solutions.\nüìö Education üá≠üá∞ The University of Hong Kong 09/2024 - Expected 11/2025 School of Computing and Data Science Master of Science in Electronic Commerce \u0026amp; Internet Computing Relevant Courses: Machine learning for business and e-commerce, Knowledge graphs, Financial fraud analytics, Internet infrastructure technologies, Website engineering, Blockchain and cryptocurrency, etc. üá®üá≥ Beijing Institute of Technology 09/2020 - 06/2024 School of Computer Science \u0026amp; Technology Bachelor of Engineering in Software Engineering, last two years GPA: 3.7/4 Relevant Courses: Reinforcement Learning, Deep Learning and Computer Vision, Artificial Intelligence and Robot Ethics, Almost Human: Mind, Brain and Artificial Intelligence, Mathematical Analysis for Engineering, Linear Algebra, Probability and Mathematical Statistics, etc. Skills: Python, Java, common data structures, design patterns, machine learning basics and algorithms, Linux, PyTorch, and some development tools (git, conda, etc.). üèÜ Awards \u0026amp; Honors Beijing Institute of Technology Undergraduate Scholarship (Top 20% of Grade) 06/2023 3rd Prize of China International \u0026#34;Internet \u0026#43;\u0026#34; College Student\u0026#39;s Innovation Competition 08/2022 Bronze Prize of \u0026#34;Challenge Cup\u0026#34; Capital University Entrepreneurship Competition 05/2022 üíº Project Experience üîç Online Transaction Fraud Detection 09/2024 ‚Äì 01/2025 Independent project, supervised by Dr. Vivien Chan Focused on addressing financial fraud in e-commerce to enhance the accuracy of transaction anomaly detection, while independently managing the entire case study that included data preprocessing, feature engineering, model building, evaluation, and results analysis. Effectively resolved class imbalance issues using SMOTE and ROSE techniques. Built various models including Logistic Regression, Random Forest, XGBoost, and LightGBM, ultimately selecting the LightGBM model to achieve a recall rate of 95.45% and an AUC of 99.84%. Wrote efficient and maintainable code, enhancing model training and data processing efficiency through parallel computing and logging. ü§ñ Multi-Model Intelligent Text Keyword Extraction System 08/2023 ‚Äì 09/2023 Group project, supervised by Associate Prof. Xiaolin Zhao Designed and implemented an intelligent text summary system that automatically extracts keywords from article titles and abstracts, enhancing the understanding and summarization of text information. Participated in the planning of the technical route and built a hybrid model combining extractive and generative approaches, utilizing advanced natural language processing techniques including KeyBERT, Sentence Transformer, BERT, and T5 models. Responsible for data preprocessing and tokenization, as well as the end-to-end implementation and training of the T5 model, optimizing the model architecture and hyperparameters, achieving satisfactory results after only 3 epochs of training. Model evaluation results showed that the Rouge-1, Rouge-2, and Rouge-L metrics reached 0.6345, 0.5038, and 0.5282, respectively, in the third epoch, validating the model\u0026rsquo;s effectiveness in the summarization task. üéì Cambridge University Machine Learning Summer Project 07/2023 ‚Äì 08/2023 Group project, supervised by Prof. Pietro Li√≤ Participated in the Cambridge University deep learning summer project, focusing on deep reinforcement learning; explored multi-agent learning algorithms across different environments. Reproduced the Multi-Agent Deep Deterministic Policy Gradient (MADDPG) algorithm in the Simple Adversary environment and studied the effect of agent numbers on convergence speed and stability, finding optimal stability at 21 agents. Designed and implemented comparative experiments inspired by the Rainbow algorithm, assessing target network strategies versus the Double Deep Q-Network (Double DQN). The results demonstrated that Double DQN significantly enhanced convergence speed, optimizing the overall learning process. Co-authored a group project paper on agent numbers and strategies effectiveness in multi-agent systems, achieving a score of 71% in the summer program (the highest in my group) and a \u0026ldquo;First Class\u0026rdquo; classification in the UK grading system. üëÅÔ∏è Deep Learning and Computer Vision Semester Project 09/2022 ‚Äì 12/2022 Independent project, supervised by Associate Prof. Guangyu Gao Designed and implemented a waste classifier using the ResNet model to improve classification accuracy and reduce resource waste. The project also enhanced understanding of transfer learning techniques with ResNet. Collected a dataset of 16 waste categories and preprocessed the images for uniformity and standardization, incorporating data augmentation techniques to enhance the dataset. Conducted experiments using ResNet34 and ResNet50 models through transfer learning, accelerating network convergence by leveraging pretrained weights. During training, techniques such as Batch Normalization and Dropout were applied to mitigate the risk of overfitting. The final model achieved an accuracy of 90% on the training set, while the performance on the test set was 61%, indicating a significant overfitting phenomenon during the training process. üéì Internship ‚öõÔ∏è Beijing Academy of Quantum Information Science 08/2023 ‚Äì 01/2024 Research Intern at Quantum Computation Department Proposed a quantum convolution kernel design based on variational quantum circuits and developed a universal quantum convolution layer, successfully integrating it into classical CNN architectures such as VGG, GoogLeNet, and ResNet. Developed and evaluated various hybrid models, including a simple model named HQCCNN-2, which achieved 84.45% accuracy on the FashionMNIST dataset, surpassing the traditional CNN\u0026rsquo;s 80.72%. This demonstrates the effectiveness of the quantum convolution layer in improving model performance. Tested on a real quantum computer further validated the effectiveness of the hybrid model, demonstrating the viable integration of quantum computing with deep learning, and highlighting the potential for leveraging quantum properties to enhance model performance. üèÖ Competition Experience ü•â China International \u0026#34;Internet \u0026#43;\u0026#34; College Students\u0026#39; Innovation Competition 08/2022 üõ°Ô∏è Zhongke Ushield: Deep Learning-based Face Privacy Protection Authentication System Responsible for constructing a localized facial feature extraction engine based on MobileFaceNet, ensuring feature extraction is completed on end devices (such as mobile phones and cameras), guaranteeing that raw data does not leave the domain and is not stored, thus enhancing user privacy protection while improving recognition efficiency. ü•â \u0026#34;Challenge Cup\u0026#34; Capital University Entrepreneurship Competition 05/2022 üå≥ Smart Orchard Responsible for the development of the fruit detection, ripeness prediction, and pest identification system, using deep convolutional neural network (CNN) technology for intelligent monitoring of crop growth conditions. Applied advanced object detection algorithms such as Faster R-CNN and YOLO to achieve high precision in apple detection and ripeness assessment, with an accuracy rate exceeding 90%, significantly enhancing the intelligence level of orchard management. Built and trained a dedicated dataset containing various pest samples, optimizing pest detection accuracy through data preprocessing (such as image normalization and resizing) and data augmentation techniques (like rotation, flipping, and noise addition), enabling the real-time monitoring system to accurately identify over 80% of pests, providing effective scientific maintenance recommendations to help farmers reduce crop losses. üìã Extracurricular Activities Vice President, Cyber Security Club, Beijing Institute of Technology 09/2021-09/2022 Backbone, Media Center of the Student Union of Beijing Institute of Technology 10/2020-06/2021 üì´ Contact üìß Email: zongsi.xu@outlook.com üëî LinkedIn: Zongsi (Tristan) Xu üíª GitHub: BaizeXS üìç Location: Hong Kong SAR, China ","permalink":"http://localhost:1313/resume/","summary":"Personal resume of Zongsi (Tristan) Xu","title":"Zongsi (Tristan) Xu"},{"content":"‰∏Ä„ÄÅÊï∞ÂÄºÁâπÂæÅ‰∏éÁ±ªÂà´ÁâπÂæÅ Êï∞ÂÄºÁâπÂæÅ (Numeric Features) ÂÖ∑ÊúâÂèØÂä†ÂáèÁöÑÊÑè‰πâÔºå‰∏îÂ≠òÂú®Â§ßÂ∞èÈ°∫Â∫è„ÄÇ ‰æãÂ≠êÔºöÂπ¥ÈæÑ„ÄÅÊ∏©Â∫¶Á≠â„ÄÇÂèØ‰ª•Áõ¥Êé•‰øùÁïôÂÖ∂Êï¥Êï∞ÊàñÊµÆÁÇπÊï∞ÂΩ¢Âºè‰æõÊ®°Âûã‰ΩøÁî®„ÄÇ Á±ªÂà´ÁâπÂæÅ (Categorical Features) Êï∞ÊçÆÂÄºÁ¶ªÊï£Ôºå‰∏çÂÖ∑Â§á‚ÄúÊï∞ÂÄºÂ§ßÂ∞è‚ÄùÈó¥ÁöÑÂèØÊØîÊÑè‰πâ„ÄÇ ‰æãÂ≠êÔºöÂõΩÁ±çÔºàÁæéÂõΩ/‰∏≠ÂõΩ/Âç∞Â∫¶Á≠âÔºâ„ÄÅÊÄßÂà´ÔºàÁî∑/Â•≥ÔºâÁ≠â„ÄÇ ÈóÆÈ¢òÔºöËã•‰ªÖÁî®Êï¥Êï∞Ë°®Á§∫ÔºàÁæéÂõΩ=1, ‰∏≠ÂõΩ=2ÔºâÔºå‰ºöÂºïÂÖ•ÈîôËØØÁöÑÊï∞ÂÄºËøêÁÆóÂÖ≥Á≥ªÔºåÂ¶Ç ‚ÄúÁæéÂõΩ + ‰∏≠ÂõΩ = Âç∞Â∫¶‚Äù„ÄÇ ‰∫å„ÄÅOne-HotÁºñÁ†ÅÁöÑÂä®Êú∫‰∏éÊµÅÁ®ã ‰∏∫‰ªÄ‰πà‰ΩøÁî®One-Hot\nÈÄöËøáÂ∞ÜÁ±ªÂà´Êò†Â∞Ñ‰∏∫ÂêëÈáèÔºåÈÅøÂÖçÊï¥Êï∞ÁºñÁ†ÅÂºïÂÖ•ÁöÑ‰º™Êï∞ÂÄºÂÖ≥Á≥ª„ÄÇ ÂêåÊó∂‰øùÁïôÂêÑÁßçÂèØËÉΩÁ±ªÂà´ÁöÑ‰ø°ÊÅØÔºå‰∏î‰ªÖÂú®ÂØπÂ∫î‰ΩçÁΩÆ‰∏∫1ÔºåÂÖ∂‰ªñ‰ΩçÁΩÆ‰∏∫0„ÄÇ Âª∫Á´ãÊò†Â∞ÑÔºö‰ªéÁ±ªÂà´Âà∞Á¥¢Âºï\n‰∏∫ÊØè‰∏™Á±ªÂà´ÂàÜÈÖç‰∏Ä‰∏™ÂîØ‰∏ÄÁ¥¢ÂºïÔºåÈÄöÂ∏∏‰ªé1ÂºÄÂßã„ÄÇ È¢ÑÁïôÁ¥¢Âºï0Ë°®Á§∫‚ÄúÊú™Áü•‚ÄùÊàñ‚ÄúÁº∫Â§±‚ÄùÔºåÂØπÂ∫îÂÖ®0ÂêëÈáè„ÄÇ ËΩ¨Êç¢‰∏∫One-HotÂêëÈáè\nËã•Á±ªÂà´ÊÄªÊï∞‰∏∫197ÔºåÂàôÁî®197Áª¥ÂêëÈáèË°®Á§∫„ÄÇ ‰æãÂ≠êÔºöÁæéÂõΩ [1, 0, 0, 0, ‚Ä¶]Ôºå ‰∏≠ÂõΩ [0, 1, 0, 0, ‚Ä¶]„ÄÇ Á§∫‰æãÔºöË°®Á§∫‰∏Ä‰∏™‰∫∫ÁöÑÁâπÂæÅ\nÁâπÂæÅÂåÖÂê´ÔºàÂπ¥ÈæÑ, ÊÄßÂà´, ÂõΩÁ±çÔºåÂÖ∂‰∏≠ÂõΩÁ±ç197ÁßçÔºâ Áª¥Â∫¶ÊÄªÂíåÔºö1Áª¥_age + 1Áª¥_gender + 197Áª¥_nationality = 199Áª¥„ÄÇ ‰æãÂ¶Ç (28, Â•≥, ‰∏≠ÂõΩ) ‚Üí [28, 0, 0, 1, 0, ‚Ä¶, 0]„ÄÇ ‰∏â„ÄÅÊñáÊú¨Êï∞ÊçÆÂ§ÑÁêÜÊµÅÁ®ã ÊñáÊú¨Âú®Ëá™ÁÑ∂ËØ≠Ë®ÄÂ§ÑÁêÜÔºàNLPÔºâ‰∏≠‰Ωú‰∏∫Â∏∏ËßÅÁöÑÂéüÂßãËæìÂÖ•ÔºåÈúÄË¶ÅÊï∞ÂÄºÂåñÊâçËÉΩÈÄÅÂÖ•Ê®°Âûã„ÄÇ‰∏ÄËà¨Ê≠•È™§Â¶Ç‰∏ãÔºö\nÂàÜËØç (Tokenization)\nÂ∞ÜÊñáÊú¨ÊãÜÂàÜ‰∏∫‰∏Ä‰∏™‰∏™ÂçïËØçÔºàTokenÔºâ„ÄÇ ‰æãÂ≠êÔºö\u0026quot;... to be or not to be...\u0026quot; ‚Üí [\u0026quot;...\u0026quot;, \u0026quot;to\u0026quot;, \u0026quot;be\u0026quot;, \u0026quot;or\u0026quot;, \u0026quot;not\u0026quot;, \u0026quot;to\u0026quot;, \u0026quot;be\u0026quot;, \u0026quot;...\u0026quot;]„ÄÇ ÁªüËÆ°ËØçÈ¢ë \u0026amp; ÊûÑÂª∫ËØçÂÖ∏\nËØçÈ¢ëÁªüËÆ° Áî®ÂìàÂ∏åË°®/Â≠óÂÖ∏ËÆ∞ÂΩïÊØè‰∏™ÂçïËØçÂá∫Áé∞Ê¨°Êï∞„ÄÇ ÈÅçÂéÜÊñáÊú¨Êó∂ÔºåËã•ÂçïËØçÂ∞öÊú™ÂÖ•Ë°®ÔºåÂàôÊñ∞Âª∫ËÆ∞ÂΩïÔºõËã•Â∑≤Â≠òÂú®ÔºåÂàôËÆ°Êï∞+1„ÄÇ ÊéíÂ∫è‰∏éÁ¥¢Âºï ÊåâËØçÈ¢ëÈôçÂ∫èÊéíÂ∫èÔºåËØçÈ¢ëÊúÄÈ´òÁöÑÂçïËØçÊéíÂú®ÂâçÈù¢„ÄÇ Á¥¢Âºï‰ªé1ÂºÄÂßãÔºå0ÁïôÁªô‚ÄúÊú™Áü•‚Äù„ÄÇ ËØçÂÖ∏ËßÑÊ®°ÔºàvocabularyÔºâÂèØËßÜÈúÄÊ±ÇÊà™Êñ≠Ôºà‰æãÂ¶ÇÂè™‰øùÁïôTop 10kÔºâ„ÄÇ ‰∏∫‰ªÄ‰πàÁßªÈô§‰ΩéÈ¢ëËØç ‰ΩéÈ¢ëËØçÂèØËÉΩÊòØÊãºÂÜôÈîôËØØ„ÄÅÁΩïËßÅ‰∫∫ÂêçÁ≠âÔºåÂØπÊ®°ÂûãÂ∏ÆÂä©ÊúâÈôê„ÄÇ ÂáèÂ∞ëËØçÂÖ∏ËßÑÊ®°ÂèØÈôç‰ΩéËøêÁÆóÂºÄÈîÄ„ÄÅÂä†Âø´Ê®°ÂûãËÆ≠ÁªÉ‰∏éÊé®ÁêÜÈÄüÂ∫¶„ÄÇ Áã¨ÁÉ≠ÁºñÁ†Å (One-Hot Encoding)\nÂ∞ÜÊØè‰∏™ÂçïËØçÊò†Â∞Ñ‰∏∫ËØçÂÖ∏‰∏≠ÁöÑÁ¥¢ÂºïÂêéÔºàÂ¶Ç [2, 4, 1, 8, ‚Ä¶]ÔºâÔºåÂèØËøõ‰∏ÄÊ≠•ËΩ¨Êç¢ÊàêOne-HotÂêëÈáè„ÄÇ One-HotÁª¥Â∫¶ÂèñÂÜ≥‰∫é‰øùÁïô‰∏ãÊù•ÁöÑËØçÂÖ∏Â§ßÂ∞èÔºà‰æãÂ¶Ç1‰∏áÔºâ„ÄÇ Êú™Êî∂ÂΩïÂçïËØçÂèØËÉΩÁõ¥Êé•ÂøΩÁï•ÔºåÊàñÁªü‰∏ÄÁî®Á¥¢Âºï0‰ª£Êõø„ÄÇ Âõõ„ÄÅÊ†∏ÂøÉÊî∂Ëé∑‰∏éÂ∫îÁî® Á±ªÂà´ÁâπÂæÅÂøÖÈúÄÊï∞ÂÄºÂåñÔºö\n‰ΩøÁî®Êï¥Êï∞1,2,3‚Ä¶‰ªÖË°®Á§∫Á±ªÂà´‚ÄúÊ†áËØÜ‚ÄùÔºåÂπ∂‰∏ç‰ª£Ë°®ÂÆÉ‰ª¨ÂèØËøõË°åÊï∞ÂÄºËøêÁÆó„ÄÇ Âõ†Ê≠§ÈúÄË¶ÅOne-HotÁ≠âÁºñÁ†ÅÊñπÂºèÔºåÈÅøÂÖçÊï∞ÂÄºËØØËß£„ÄÇ ÊñáÊú¨Êï∞ÊçÆÈ¢ÑÂ§ÑÁêÜÔºö\nÂàÜËØç„ÄÅËØçÈ¢ëÁªüËÆ°„ÄÅÊûÑÂª∫ËØçÂÖ∏„ÄÅÁ¥¢ÂºïÂåñ„ÄÅOne-HotÊàñÂÖ∂‰ªñÊñπÂºèÔºàÂ¶ÇËØçÂµåÂÖ•ÔºâÊòØÂ∏∏ËßÅÊµÅÁ®ã„ÄÇ Ê≠£Á°ÆÁöÑÊñáÊú¨È¢ÑÂ§ÑÁêÜÂèØÊòæËëóÂΩ±ÂìçÊ®°ÂûãÊÄßËÉΩÂíåÊïàÁéá„ÄÇ ‰øùÁïôÊú™Áü•Á¥¢ÂºïÔºö\n‰øùËØÅÂØπÁº∫Â§±Êï∞ÊçÆÊàñÂ≠óÂÖ∏Â§ñÊñ∞ËØçËÉΩÊúâÂü∫Êú¨ÁöÑË°®Á§∫ÔºåÊèêÂçáÊ®°ÂûãÂÆπÈîôÊÄß„ÄÇ ÂÆûÈôÖ‰ΩøÁî®Ôºö\nÂØπ‰∫éÂ∞èËßÑÊ®°Á±ªÂà´ÂèØÁõ¥Êé•One-HotÁºñÁ†ÅÔºõÂØπ‰∫éËØçÂÖ∏ÂæàÂ§ßÁöÑÂú∫ÊôØÔºåÈÄöÂ∏∏‰ºöËøõ‰∏ÄÊ≠•ËÄÉËôëËØçÂµåÂÖ•ÔºàWord EmbeddingÔºâÊàñÈ¢ÑËÆ≠ÁªÉËØ≠Ë®ÄÊ®°Âûã„ÄÇ ","permalink":"http://localhost:1313/posts/nlp-1/","summary":"\u003ch2 id=\"‰∏ÄÊï∞ÂÄºÁâπÂæÅ‰∏éÁ±ªÂà´ÁâπÂæÅ\"\u003e‰∏Ä„ÄÅÊï∞ÂÄºÁâπÂæÅ‰∏éÁ±ªÂà´ÁâπÂæÅ\u003c/h2\u003e\n\u003col\u003e\n\u003cli\u003e\u003cstrong\u003eÊï∞ÂÄºÁâπÂæÅ (Numeric Features)\u003c/strong\u003e\n\u003cul\u003e\n\u003cli\u003eÂÖ∑ÊúâÂèØÂä†ÂáèÁöÑÊÑè‰πâÔºå‰∏îÂ≠òÂú®Â§ßÂ∞èÈ°∫Â∫è„ÄÇ\u003c/li\u003e\n\u003cli\u003e‰æãÂ≠êÔºöÂπ¥ÈæÑ„ÄÅÊ∏©Â∫¶Á≠â„ÄÇÂèØ‰ª•Áõ¥Êé•‰øùÁïôÂÖ∂Êï¥Êï∞ÊàñÊµÆÁÇπÊï∞ÂΩ¢Âºè‰æõÊ®°Âûã‰ΩøÁî®„ÄÇ\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003eÁ±ªÂà´ÁâπÂæÅ (Categorical Features)\u003c/strong\u003e\n\u003cul\u003e\n\u003cli\u003eÊï∞ÊçÆÂÄºÁ¶ªÊï£Ôºå‰∏çÂÖ∑Â§á‚ÄúÊï∞ÂÄºÂ§ßÂ∞è‚ÄùÈó¥ÁöÑÂèØÊØîÊÑè‰πâ„ÄÇ\u003c/li\u003e\n\u003cli\u003e‰æãÂ≠êÔºöÂõΩÁ±çÔºàÁæéÂõΩ/‰∏≠ÂõΩ/Âç∞Â∫¶Á≠âÔºâ„ÄÅÊÄßÂà´ÔºàÁî∑/Â•≥ÔºâÁ≠â„ÄÇ\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003eÈóÆÈ¢ò\u003c/strong\u003eÔºöËã•‰ªÖÁî®Êï¥Êï∞Ë°®Á§∫ÔºàÁæéÂõΩ=1, ‰∏≠ÂõΩ=2ÔºâÔºå‰ºöÂºïÂÖ•ÈîôËØØÁöÑÊï∞ÂÄºËøêÁÆóÂÖ≥Á≥ªÔºåÂ¶Ç ‚ÄúÁæéÂõΩ + ‰∏≠ÂõΩ = Âç∞Â∫¶‚Äù„ÄÇ\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003c/ol\u003e\n\u003ch2 id=\"‰∫åone-hotÁºñÁ†ÅÁöÑÂä®Êú∫‰∏éÊµÅÁ®ã\"\u003e‰∫å„ÄÅOne-HotÁºñÁ†ÅÁöÑÂä®Êú∫‰∏éÊµÅÁ®ã\u003c/h2\u003e\n\u003col\u003e\n\u003cli\u003e\n\u003cp\u003e\u003cstrong\u003e‰∏∫‰ªÄ‰πà‰ΩøÁî®One-Hot\u003c/strong\u003e\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eÈÄöËøáÂ∞ÜÁ±ªÂà´Êò†Â∞Ñ‰∏∫ÂêëÈáèÔºåÈÅøÂÖçÊï¥Êï∞ÁºñÁ†ÅÂºïÂÖ•ÁöÑ‰º™Êï∞ÂÄºÂÖ≥Á≥ª„ÄÇ\u003c/li\u003e\n\u003cli\u003eÂêåÊó∂‰øùÁïôÂêÑÁßçÂèØËÉΩÁ±ªÂà´ÁöÑ‰ø°ÊÅØÔºå‰∏î‰ªÖÂú®ÂØπÂ∫î‰ΩçÁΩÆ‰∏∫1ÔºåÂÖ∂‰ªñ‰ΩçÁΩÆ‰∏∫0„ÄÇ\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003e\u003cstrong\u003eÂª∫Á´ãÊò†Â∞ÑÔºö‰ªéÁ±ªÂà´Âà∞Á¥¢Âºï\u003c/strong\u003e\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e‰∏∫ÊØè‰∏™Á±ªÂà´ÂàÜÈÖç‰∏Ä‰∏™ÂîØ‰∏ÄÁ¥¢ÂºïÔºåÈÄöÂ∏∏‰ªé1ÂºÄÂßã„ÄÇ\u003c/li\u003e\n\u003cli\u003eÈ¢ÑÁïôÁ¥¢Âºï0Ë°®Á§∫‚ÄúÊú™Áü•‚ÄùÊàñ‚ÄúÁº∫Â§±‚ÄùÔºåÂØπÂ∫îÂÖ®0ÂêëÈáè„ÄÇ\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003e\u003cstrong\u003eËΩ¨Êç¢‰∏∫One-HotÂêëÈáè\u003c/strong\u003e\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eËã•Á±ªÂà´ÊÄªÊï∞‰∏∫197ÔºåÂàôÁî®197Áª¥ÂêëÈáèË°®Á§∫„ÄÇ\u003c/li\u003e\n\u003cli\u003e‰æãÂ≠êÔºöÁæéÂõΩ \u003ccode\u003e[1, 0, 0, 0, ‚Ä¶]\u003c/code\u003eÔºå ‰∏≠ÂõΩ \u003ccode\u003e[0, 1, 0, 0, ‚Ä¶]\u003c/code\u003e„ÄÇ\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003e\u003cstrong\u003eÁ§∫‰æãÔºöË°®Á§∫‰∏Ä‰∏™‰∫∫ÁöÑÁâπÂæÅ\u003c/strong\u003e\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eÁâπÂæÅÂåÖÂê´ÔºàÂπ¥ÈæÑ, ÊÄßÂà´, ÂõΩÁ±çÔºåÂÖ∂‰∏≠ÂõΩÁ±ç197ÁßçÔºâ\u003c/li\u003e\n\u003cli\u003eÁª¥Â∫¶ÊÄªÂíåÔºö1Áª¥_age + 1Áª¥_gender + 197Áª¥_nationality = 199Áª¥„ÄÇ\u003c/li\u003e\n\u003cli\u003e‰æãÂ¶Ç \u003ccode\u003e(28, Â•≥, ‰∏≠ÂõΩ)\u003c/code\u003e ‚Üí \u003ccode\u003e[28, 0, 0, 1, 0, ‚Ä¶, 0]\u003c/code\u003e„ÄÇ\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003c/ol\u003e\n\u003ch2 id=\"‰∏âÊñáÊú¨Êï∞ÊçÆÂ§ÑÁêÜÊµÅÁ®ã\"\u003e‰∏â„ÄÅÊñáÊú¨Êï∞ÊçÆÂ§ÑÁêÜÊµÅÁ®ã\u003c/h2\u003e\n\u003cp\u003eÊñáÊú¨Âú®Ëá™ÁÑ∂ËØ≠Ë®ÄÂ§ÑÁêÜÔºàNLPÔºâ‰∏≠‰Ωú‰∏∫Â∏∏ËßÅÁöÑÂéüÂßãËæìÂÖ•ÔºåÈúÄË¶ÅÊï∞ÂÄºÂåñÊâçËÉΩÈÄÅÂÖ•Ê®°Âûã„ÄÇ‰∏ÄËà¨Ê≠•È™§Â¶Ç‰∏ãÔºö\u003c/p\u003e\n\u003col\u003e\n\u003cli\u003e\n\u003cp\u003e\u003cstrong\u003eÂàÜËØç (Tokenization)\u003c/strong\u003e\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eÂ∞ÜÊñáÊú¨ÊãÜÂàÜ‰∏∫‰∏Ä‰∏™‰∏™ÂçïËØçÔºàTokenÔºâ„ÄÇ\u003c/li\u003e\n\u003cli\u003e‰æãÂ≠êÔºö\u003ccode\u003e\u0026quot;... to be or not to be...\u0026quot;\u003c/code\u003e ‚Üí \u003ccode\u003e[\u0026quot;...\u0026quot;, \u0026quot;to\u0026quot;, \u0026quot;be\u0026quot;, \u0026quot;or\u0026quot;, \u0026quot;not\u0026quot;, \u0026quot;to\u0026quot;, \u0026quot;be\u0026quot;, \u0026quot;...\u0026quot;]\u003c/code\u003e„ÄÇ\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003e\u003cstrong\u003eÁªüËÆ°ËØçÈ¢ë \u0026amp; ÊûÑÂª∫ËØçÂÖ∏\u003c/strong\u003e\u003c/p\u003e","title":""},{"content":"Text to Sequence ÊñáÊú¨Â§ÑÁêÜ\nStep1: Tokenization\nTokenization breaks a piece of text down into a list of tokens.\nHere, a token is a word. (A token can be a character in some applications.)\nTokenizationËÆ≤Á©∂ÂæàÂ§öÔºå‰æãÂ¶ÇÊòØÂê¶Â∫îËØ•ÊääÂ§ßÂÜôÊîπÊàêÂ∞èÂÜôÂë¢ÔºüËøõË°åtypo correctionÁ≠âÁ≠â\nStep2: Build Dictionary\nUse a dictionary (hash table) to count word frequencies.\nThe dictionary maps word to index.\nÂèØ‰ª•È¶ñÂÖàÁªüËÆ°ËØçÈ¢ëÂéªÊéâ‰ΩéÈ¢ëËØçÔºåÁÑ∂ÂêéËÆ©ÊØè‰∏™ËØçÂØπÂ∫î‰∏Ä‰∏™Ê≠£Êï¥Êï∞ÔºõËøôÊ†∑ÁöÑËØùÔºå‰∏ÄÂè•ËØùÂ∞±ÂèØ‰ª•Áî®‰∏Ä‰∏™Ê≠£Êï¥Êï∞ÂàóË°®Ë°®Á§∫ÔºåËøô‰∏™ÂàóË°®Â∞±Âè´sequenceÔºõÂ¶ÇÊûúÂøÖË¶ÅÂ∞±ËøòÂæóÂÅöone-hot encoding„ÄÇ\nÁªìÊûú\n‰ΩÜÊòØÈïøÂ∫¶‰∏çÁªü‰∏Ä\nStep4: ÂØπÈΩêsequence\nËß£ÂÜ≥ÊñπÊ°àÊòØËøôÊ†∑ÁöÑÔºöÂèØ‰ª•Âõ∫ÂÆöÈïøÂ∫¶‰∏∫wÔºåÂä†ÂÖ•‰∏Ä‰∏™Â∫èÂàóÈïøÂ∫¶Â§™ÈïøÔºåÂ∞±Á†çÊéâÂâçÈù¢ÁöÑËØçÔºåÂè™‰øùÁïôÊúÄÂêéw‰∏™ËØçÔºõÂ¶ÇÊûú‰∏Ä‰∏™Â∫èÂàóÂ§™Áü≠ÔºåÂ∞±ÂÅözero paddingÔºåÁî®0Â°´ÂÖÖ\nËøôÊ†∑‰∏ÄÊù•ÔºåÊâÄÊúâÁöÑÂ∫èÂàóÈïøÂ∫¶Â∞±Áªü‰∏Ä‰∫Ü\nÊñáÊú¨Â§ÑÁêÜÂÆåÊàê‰∫ÜÔºåÊé•‰∏ãÊù•ÊòØword embeddingÔºåÊääÂçïËØçË°®Á§∫‰∏∫‰∏Ä‰∏™‰ΩéÁª¥ÂêëÈáèÔºõ\nÁÑ∂ËÄåËøôÊ†∑ÂÅöÁöÑËØùÔºåÂ¶ÇÊûúÊòØ10000‰∏™ÂçïËØçÔºåÁª¥Â∫¶Â∞±ÊòØ10000Áª¥ÔºåÁª¥Â∫¶Â§™È´ò‰∫ÜÔºõÂõ†Ê≠§Ë¶ÅÂÅöword embeddingÔºõ\nÂÖ∑‰ΩìÂÅöÊ≥ïÂ∞±ÊòØÊääone-hotÂêëÈáèe_iÂíåÂèÇÊï∞Áü©ÈòµpÁõ∏‰πòÔºõÁü©ÈòµPËΩ¨ÁΩÆÁöÑÂ§ßÂ∞èÊòØd x vÔºõdÊòØËØçÂêëÈáèÁöÑÁª¥Â∫¶ÔºõvÊòØÂ≠óÂÖ∏ÈáåËØçÊ±áÁöÑÊï∞ÈáèÔºõÁªìÊûú‰∏∫x_iÔºõx_iÂ∞±ÊòØ‰∏Ä‰∏™ËØçÂêëÈáèÔºõÂ¶ÇÊûúone-hotÂêëÈáèÁöÑÁ¨¨‰∏âË°å‰∏∫1ÔºõÈÇ£‰πàx_iÂ∞±ÊòØPËΩ¨ÁΩÆÁü©ÈòµÁöÑÁ¨¨‰∏âÂàóÔºàÂÖ∂‰ΩôÂàóÈÉΩ‰∏∫0ÔºâÔºõÊâÄ‰ª•PËΩ¨ÁΩÆÊØè‰∏ÄÂàóÈÉΩÊòØ‰∏Ä‰∏™ËØçÂêëÈáèÔºõÊâÄ‰ª•Áü©ÈòµPÊú¨Ë∫´ÁöÑÊØè‰∏ÄË°åÂ∞±ÊòØ‰∏Ä‰∏™ËØçÂêëÈáèÔºõÂÖ∂Ë°åÊï∞‰∏∫vÔºõÂç≥vocabularyÔºåËØçÊ±áÈáèÔºõÊØè‰∏ÄË°åÂØπÂ∫î‰∏Ä‰∏™ÂçïËØçÔºõÁü©ÈòµÁöÑÂàóÊï∞‰∏∫dÔºõdÊòØÁî®Êà∑ÂÜ≥ÂÆöÁöÑÔºõdÁöÑÂ§ßÂ∞è‰ºöÂÜ≥ÂÆöÊú∫Âô®Â≠¶‰π†Ê®°ÂûãÁöÑË°®Áé∞ÔºõÂ∫îËØ•Áî®xxxÊù•ÈÄâÊã©‰∏Ä‰∏™ÊØîËæÉÂ•ΩÁöÑdÔºõ\nÊàë‰ª¨ÁöÑ‰ªªÂä°ÊòØÁúãËØÑËÆ∫ÊòØÊ≠£Èù¢ÁöÑËøòÊòØË¥üÈù¢ÁöÑÔºõÂèÇÊï∞Áü©ÈòµÊòØ‰ªéËÆ≠ÁªÉÊï∞ÊçÆ‰∏≠Â≠¶‰π†Âá∫Êù•ÁöÑÔºåÊâÄ‰ª•Â≠¶Âá∫Êù•ÁöÑËØçÂêëÈáèÊòØÂ∏¶ÊúâÊÑüÊÉÖËâ≤ÂΩ©ÁöÑÔºõÂÅáËÆæËøô‰∫õËØçÂêëÈáèÈÉΩÊòØ‰∫åÁª¥ÁöÑÔºåÂàôÂèØ‰ª•Âú®Âπ≥Èù¢ÂùêÊ†áÁ≥ª‰∏≠Ê†áÂá∫‰∏ãÈù¢ËØçÂêëÈáè\nkerasÊèê‰æõembeddingÂ±ÇÔºõÁî®Êà∑ÂèØ‰ª•ÊåáÂÆövocabularyÂ§ßÂ∞èÂíådÁöÑÂ§ßÂ∞èÔºõ‰ª•ÂèäÊØè‰∏Ä‰∏™sequenceÁöÑÈïøÂ∫¶ÔºõdÊòØÊ†πÊçÆÁÆóÊ≥ïÈÄâÂá∫Êù•ÁöÑ Âà∞Ëøô‰∏ÄÊ≠•ÔºåÊàë‰ª¨Â∑≤ÁªèÂÆåÊàê‰∫ÜÊñáÊú¨Â§ÑÁêÜÂíåword embedding„ÄÇÊé•‰∏ãÊù•Â∞±ÊòØÁî®Logistic Regression for Binary ClassificationÂÅö‰∫åÂàÜÁ±ªÔºõ\n","permalink":"http://localhost:1313/posts/nlp-2/","summary":"\u003ch3 id=\"text-to-sequence\"\u003eText to Sequence\u003c/h3\u003e\n\u003cp\u003eÊñáÊú¨Â§ÑÁêÜ\u003c/p\u003e\n\u003cp\u003eStep1: Tokenization\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\n\u003cp\u003eTokenization breaks a piece of text down into a list of tokens.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003eHere, a token is a word. (A token can be a character in some applications.)\u003c/p\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003eTokenizationËÆ≤Á©∂ÂæàÂ§öÔºå‰æãÂ¶ÇÊòØÂê¶Â∫îËØ•ÊääÂ§ßÂÜôÊîπÊàêÂ∞èÂÜôÂë¢ÔºüËøõË°åtypo correctionÁ≠âÁ≠â\u003c/p\u003e\n\u003cp\u003e\u003cimg alt=\"image-20250322150322238\" loading=\"lazy\" src=\"./NLP-2.assets/image-20250322150322238.png\"\u003e\u003c/p\u003e\n\u003cp\u003eStep2: Build Dictionary\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\n\u003cp\u003eUse a dictionary (hash table) to count word frequencies.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003eThe dictionary maps word to index.\u003c/p\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003eÂèØ‰ª•È¶ñÂÖàÁªüËÆ°ËØçÈ¢ëÂéªÊéâ‰ΩéÈ¢ëËØçÔºåÁÑ∂ÂêéËÆ©ÊØè‰∏™ËØçÂØπÂ∫î‰∏Ä‰∏™Ê≠£Êï¥Êï∞ÔºõËøôÊ†∑ÁöÑËØùÔºå‰∏ÄÂè•ËØùÂ∞±ÂèØ‰ª•Áî®‰∏Ä‰∏™Ê≠£Êï¥Êï∞ÂàóË°®Ë°®Á§∫ÔºåËøô‰∏™ÂàóË°®Â∞±Âè´sequenceÔºõÂ¶ÇÊûúÂøÖË¶ÅÂ∞±ËøòÂæóÂÅöone-hot encoding„ÄÇ\u003cimg alt=\"image-20250322150620890\" loading=\"lazy\" src=\"./NLP-2.assets/image-20250322150620890.png\"\u003e\u003c/p\u003e\n\u003cp\u003eÁªìÊûú\u003c/p\u003e\n\u003cp\u003e\u003cimg alt=\"image-20250322150754528\" loading=\"lazy\" src=\"./NLP-2.assets/image-20250322150754528.png\"\u003e\u003c/p\u003e\n\u003cp\u003e‰ΩÜÊòØÈïøÂ∫¶‰∏çÁªü‰∏Ä\u003c/p\u003e\n\u003cp\u003eStep4: ÂØπÈΩêsequence\u003c/p\u003e\n\u003cp\u003e\u003cimg alt=\"image-20250322150854986\" loading=\"lazy\" src=\"./NLP-2.assets/image-20250322150854986.png\"\u003e\u003c/p\u003e\n\u003cp\u003eËß£ÂÜ≥ÊñπÊ°àÊòØËøôÊ†∑ÁöÑÔºöÂèØ‰ª•Âõ∫ÂÆöÈïøÂ∫¶‰∏∫wÔºåÂä†ÂÖ•‰∏Ä‰∏™Â∫èÂàóÈïøÂ∫¶Â§™ÈïøÔºåÂ∞±Á†çÊéâÂâçÈù¢ÁöÑËØçÔºåÂè™‰øùÁïôÊúÄÂêéw‰∏™ËØçÔºõÂ¶ÇÊûú‰∏Ä‰∏™Â∫èÂàóÂ§™Áü≠ÔºåÂ∞±ÂÅözero paddingÔºåÁî®0Â°´ÂÖÖ\u003c/p\u003e\n\u003cp\u003e\u003cimg alt=\"image-20250322151030119\" loading=\"lazy\" src=\"./NLP-2.assets/image-20250322151030119.png\"\u003e\u003c/p\u003e\n\u003cp\u003eËøôÊ†∑‰∏ÄÊù•ÔºåÊâÄÊúâÁöÑÂ∫èÂàóÈïøÂ∫¶Â∞±Áªü‰∏Ä‰∫Ü\u003c/p\u003e\n\u003cp\u003e\u003cimg alt=\"image-20250322151117125\" loading=\"lazy\" src=\"./NLP-2.assets/image-20250322151117125.png\"\u003e\u003c/p\u003e\n\u003cp\u003eÊñáÊú¨Â§ÑÁêÜÂÆåÊàê‰∫ÜÔºåÊé•‰∏ãÊù•ÊòØword embeddingÔºåÊääÂçïËØçË°®Á§∫‰∏∫‰∏Ä‰∏™‰ΩéÁª¥ÂêëÈáèÔºõ\u003c/p\u003e\n\u003cp\u003e\u003cimg alt=\"image-20250322151252837\" loading=\"lazy\" src=\"./NLP-2.assets/image-20250322151252837.png\"\u003e\u003c/p\u003e","title":""},{"content":"üëã About me Hello! I\u0026rsquo;m Xu Zongsi, a passionate technology enthusiast currently pursuing my Master of Science in ECIC at The University of Hong Kong. With a solid background in Software Engineering from the Beijing Institute of Technology, I specialize in artificial intelligence areas like machine learning, deep learning, natural language processing, computer vision, and reinforcement learning.\nInspired by OpenAI\u0026rsquo;s five-step plan towards superintelligence, I am excited about AGI and have developed a keen interest in LLM agents, MLLM, and knowledge graphs. I see great potential in these fields and aspire to contribute to innovative solutions.\nüìö Education üá≠üá∞ The University of Hong Kong 09/2024 - Expected 11/2025 School of Computing and Data Science Master of Science in Electronic Commerce \u0026amp; Internet Computing Relevant Courses: Machine learning for business and e-commerce, Knowledge graphs, Financial fraud analytics, Internet infrastructure technologies, Website engineering, Blockchain and cryptocurrency, etc. üá®üá≥ Beijing Institute of Technology 09/2020 - 06/2024 School of Computer Science \u0026amp; Technology Bachelor of Engineering in Software Engineering, last two years GPA: 3.7/4 Relevant Courses: Reinforcement Learning, Deep Learning and Computer Vision, Artificial Intelligence and Robot Ethics, Almost Human: Mind, Brain and Artificial Intelligence, Mathematical Analysis for Engineering, Linear Algebra, Probability and Mathematical Statistics, etc. Skills: Python, Java, common data structures, design patterns, machine learning basics and algorithms, Linux, PyTorch, and some development tools (git, conda, etc.). üèÜ Awards \u0026amp; Honors Beijing Institute of Technology Undergraduate Scholarship (Top 20% of Grade) 06/2023 3rd Prize of China International \u0026#34;Internet \u0026#43;\u0026#34; College Student\u0026#39;s Innovation Competition 08/2022 Bronze Prize of \u0026#34;Challenge Cup\u0026#34; Capital University Entrepreneurship Competition 05/2022 üíº Project Experience üîç Online Transaction Fraud Detection 09/2024 ‚Äì 01/2025 Independent project, supervised by Dr. Vivien Chan Focused on addressing financial fraud in e-commerce to enhance the accuracy of transaction anomaly detection, while independently managing the entire case study that included data preprocessing, feature engineering, model building, evaluation, and results analysis. Effectively resolved class imbalance issues using SMOTE and ROSE techniques. Built various models including Logistic Regression, Random Forest, XGBoost, and LightGBM, ultimately selecting the LightGBM model to achieve a recall rate of 95.45% and an AUC of 99.84%. Wrote efficient and maintainable code, enhancing model training and data processing efficiency through parallel computing and logging. ü§ñ Multi-Model Intelligent Text Keyword Extraction System 08/2023 ‚Äì 09/2023 Group project, supervised by Associate Prof. Xiaolin Zhao Designed and implemented an intelligent text summary system that automatically extracts keywords from article titles and abstracts, enhancing the understanding and summarization of text information. Participated in the planning of the technical route and built a hybrid model combining extractive and generative approaches, utilizing advanced natural language processing techniques including KeyBERT, Sentence Transformer, BERT, and T5 models. Responsible for data preprocessing and tokenization, as well as the end-to-end implementation and training of the T5 model, optimizing the model architecture and hyperparameters, achieving satisfactory results after only 3 epochs of training. Model evaluation results showed that the Rouge-1, Rouge-2, and Rouge-L metrics reached 0.6345, 0.5038, and 0.5282, respectively, in the third epoch, validating the model\u0026rsquo;s effectiveness in the summarization task. üéì Cambridge University Machine Learning Summer Project 07/2023 ‚Äì 08/2023 Group project, supervised by Prof. Pietro Li√≤ Participated in the Cambridge University deep learning summer project, focusing on deep reinforcement learning; explored multi-agent learning algorithms across different environments. Reproduced the Multi-Agent Deep Deterministic Policy Gradient (MADDPG) algorithm in the Simple Adversary environment and studied the effect of agent numbers on convergence speed and stability, finding optimal stability at 21 agents. Designed and implemented comparative experiments inspired by the Rainbow algorithm, assessing target network strategies versus the Double Deep Q-Network (Double DQN). The results demonstrated that Double DQN significantly enhanced convergence speed, optimizing the overall learning process. Co-authored a group project paper on agent numbers and strategies effectiveness in multi-agent systems, achieving a score of 71% in the summer program (the highest in my group) and a \u0026ldquo;First Class\u0026rdquo; classification in the UK grading system. üëÅÔ∏è Deep Learning and Computer Vision Semester Project 09/2022 ‚Äì 12/2022 Independent project, supervised by Associate Prof. Guangyu Gao Designed and implemented a waste classifier using the ResNet model to improve classification accuracy and reduce resource waste. The project also enhanced understanding of transfer learning techniques with ResNet. Collected a dataset of 16 waste categories and preprocessed the images for uniformity and standardization, incorporating data augmentation techniques to enhance the dataset. Conducted experiments using ResNet34 and ResNet50 models through transfer learning, accelerating network convergence by leveraging pretrained weights. During training, techniques such as Batch Normalization and Dropout were applied to mitigate the risk of overfitting. The final model achieved an accuracy of 90% on the training set, while the performance on the test set was 61%, indicating a significant overfitting phenomenon during the training process. üéì Internship ‚öõÔ∏è Beijing Academy of Quantum Information Science 08/2023 ‚Äì 01/2024 Research Intern at Quantum Computation Department Proposed a quantum convolution kernel design based on variational quantum circuits and developed a universal quantum convolution layer, successfully integrating it into classical CNN architectures such as VGG, GoogLeNet, and ResNet. Developed and evaluated various hybrid models, including a simple model named HQCCNN-2, which achieved 84.45% accuracy on the FashionMNIST dataset, surpassing the traditional CNN\u0026rsquo;s 80.72%. This demonstrates the effectiveness of the quantum convolution layer in improving model performance. Tested on a real quantum computer further validated the effectiveness of the hybrid model, demonstrating the viable integration of quantum computing with deep learning, and highlighting the potential for leveraging quantum properties to enhance model performance. üèÖ Competition Experience ü•â China International \u0026#34;Internet \u0026#43;\u0026#34; College Students\u0026#39; Innovation Competition 08/2022 üõ°Ô∏è Zhongke Ushield: Deep Learning-based Face Privacy Protection Authentication System Responsible for constructing a localized facial feature extraction engine based on MobileFaceNet, ensuring feature extraction is completed on end devices (such as mobile phones and cameras), guaranteeing that raw data does not leave the domain and is not stored, thus enhancing user privacy protection while improving recognition efficiency. ü•â \u0026#34;Challenge Cup\u0026#34; Capital University Entrepreneurship Competition 05/2022 üå≥ Smart Orchard Responsible for the development of the fruit detection, ripeness prediction, and pest identification system, using deep convolutional neural network (CNN) technology for intelligent monitoring of crop growth conditions. Applied advanced object detection algorithms such as Faster R-CNN and YOLO to achieve high precision in apple detection and ripeness assessment, with an accuracy rate exceeding 90%, significantly enhancing the intelligence level of orchard management. Built and trained a dedicated dataset containing various pest samples, optimizing pest detection accuracy through data preprocessing (such as image normalization and resizing) and data augmentation techniques (like rotation, flipping, and noise addition), enabling the real-time monitoring system to accurately identify over 80% of pests, providing effective scientific maintenance recommendations to help farmers reduce crop losses. üìã Extracurricular Activities Vice President, Cyber Security Club, Beijing Institute of Technology 09/2021-09/2022 Backbone, Media Center of the Student Union of Beijing Institute of Technology 10/2020-06/2021 üì´ Contact üìß Email: zongsi.xu@outlook.com üëî LinkedIn: Zongsi (Tristan) Xu üíª GitHub: BaizeXS üìç Location: Hong Kong SAR, China ","permalink":"http://localhost:1313/resume/","summary":"Personal resume of Zongsi (Tristan) Xu","title":"Zongsi (Tristan) Xu"},{"content":"‰∏Ä„ÄÅÊï∞ÂÄºÁâπÂæÅ‰∏éÁ±ªÂà´ÁâπÂæÅ Êï∞ÂÄºÁâπÂæÅ (Numeric Features) ÂÖ∑ÊúâÂèØÂä†ÂáèÁöÑÊÑè‰πâÔºå‰∏îÂ≠òÂú®Â§ßÂ∞èÈ°∫Â∫è„ÄÇ ‰æãÂ≠êÔºöÂπ¥ÈæÑ„ÄÅÊ∏©Â∫¶Á≠â„ÄÇÂèØ‰ª•Áõ¥Êé•‰øùÁïôÂÖ∂Êï¥Êï∞ÊàñÊµÆÁÇπÊï∞ÂΩ¢Âºè‰æõÊ®°Âûã‰ΩøÁî®„ÄÇ Á±ªÂà´ÁâπÂæÅ (Categorical Features) Êï∞ÊçÆÂÄºÁ¶ªÊï£Ôºå‰∏çÂÖ∑Â§á‚ÄúÊï∞ÂÄºÂ§ßÂ∞è‚ÄùÈó¥ÁöÑÂèØÊØîÊÑè‰πâ„ÄÇ ‰æãÂ≠êÔºöÂõΩÁ±çÔºàÁæéÂõΩ/‰∏≠ÂõΩ/Âç∞Â∫¶Á≠âÔºâ„ÄÅÊÄßÂà´ÔºàÁî∑/Â•≥ÔºâÁ≠â„ÄÇ ÈóÆÈ¢òÔºöËã•‰ªÖÁî®Êï¥Êï∞Ë°®Á§∫ÔºàÁæéÂõΩ=1, ‰∏≠ÂõΩ=2ÔºâÔºå‰ºöÂºïÂÖ•ÈîôËØØÁöÑÊï∞ÂÄºËøêÁÆóÂÖ≥Á≥ªÔºåÂ¶Ç ‚ÄúÁæéÂõΩ + ‰∏≠ÂõΩ = Âç∞Â∫¶‚Äù„ÄÇ ‰∫å„ÄÅOne-HotÁºñÁ†ÅÁöÑÂä®Êú∫‰∏éÊµÅÁ®ã ‰∏∫‰ªÄ‰πà‰ΩøÁî®One-Hot\nÈÄöËøáÂ∞ÜÁ±ªÂà´Êò†Â∞Ñ‰∏∫ÂêëÈáèÔºåÈÅøÂÖçÊï¥Êï∞ÁºñÁ†ÅÂºïÂÖ•ÁöÑ‰º™Êï∞ÂÄºÂÖ≥Á≥ª„ÄÇ ÂêåÊó∂‰øùÁïôÂêÑÁßçÂèØËÉΩÁ±ªÂà´ÁöÑ‰ø°ÊÅØÔºå‰∏î‰ªÖÂú®ÂØπÂ∫î‰ΩçÁΩÆ‰∏∫1ÔºåÂÖ∂‰ªñ‰ΩçÁΩÆ‰∏∫0„ÄÇ Âª∫Á´ãÊò†Â∞ÑÔºö‰ªéÁ±ªÂà´Âà∞Á¥¢Âºï\n‰∏∫ÊØè‰∏™Á±ªÂà´ÂàÜÈÖç‰∏Ä‰∏™ÂîØ‰∏ÄÁ¥¢ÂºïÔºåÈÄöÂ∏∏‰ªé1ÂºÄÂßã„ÄÇ È¢ÑÁïôÁ¥¢Âºï0Ë°®Á§∫‚ÄúÊú™Áü•‚ÄùÊàñ‚ÄúÁº∫Â§±‚ÄùÔºåÂØπÂ∫îÂÖ®0ÂêëÈáè„ÄÇ ËΩ¨Êç¢‰∏∫One-HotÂêëÈáè\nËã•Á±ªÂà´ÊÄªÊï∞‰∏∫197ÔºåÂàôÁî®197Áª¥ÂêëÈáèË°®Á§∫„ÄÇ ‰æãÂ≠êÔºöÁæéÂõΩ [1, 0, 0, 0, ‚Ä¶]Ôºå ‰∏≠ÂõΩ [0, 1, 0, 0, ‚Ä¶]„ÄÇ Á§∫‰æãÔºöË°®Á§∫‰∏Ä‰∏™‰∫∫ÁöÑÁâπÂæÅ\nÁâπÂæÅÂåÖÂê´ÔºàÂπ¥ÈæÑ, ÊÄßÂà´, ÂõΩÁ±çÔºåÂÖ∂‰∏≠ÂõΩÁ±ç197ÁßçÔºâ Áª¥Â∫¶ÊÄªÂíåÔºö1Áª¥_age + 1Áª¥_gender + 197Áª¥_nationality = 199Áª¥„ÄÇ ‰æãÂ¶Ç (28, Â•≥, ‰∏≠ÂõΩ) ‚Üí [28, 0, 0, 1, 0, ‚Ä¶, 0]„ÄÇ ‰∏â„ÄÅÊñáÊú¨Êï∞ÊçÆÂ§ÑÁêÜÊµÅÁ®ã ÊñáÊú¨Âú®Ëá™ÁÑ∂ËØ≠Ë®ÄÂ§ÑÁêÜÔºàNLPÔºâ‰∏≠‰Ωú‰∏∫Â∏∏ËßÅÁöÑÂéüÂßãËæìÂÖ•ÔºåÈúÄË¶ÅÊï∞ÂÄºÂåñÊâçËÉΩÈÄÅÂÖ•Ê®°Âûã„ÄÇ‰∏ÄËà¨Ê≠•È™§Â¶Ç‰∏ãÔºö\nÂàÜËØç (Tokenization)\nÂ∞ÜÊñáÊú¨ÊãÜÂàÜ‰∏∫‰∏Ä‰∏™‰∏™ÂçïËØçÔºàTokenÔºâ„ÄÇ ‰æãÂ≠êÔºö\u0026quot;... to be or not to be...\u0026quot; ‚Üí [\u0026quot;...\u0026quot;, \u0026quot;to\u0026quot;, \u0026quot;be\u0026quot;, \u0026quot;or\u0026quot;, \u0026quot;not\u0026quot;, \u0026quot;to\u0026quot;, \u0026quot;be\u0026quot;, \u0026quot;...\u0026quot;]„ÄÇ ÁªüËÆ°ËØçÈ¢ë \u0026amp; ÊûÑÂª∫ËØçÂÖ∏\nËØçÈ¢ëÁªüËÆ° Áî®ÂìàÂ∏åË°®/Â≠óÂÖ∏ËÆ∞ÂΩïÊØè‰∏™ÂçïËØçÂá∫Áé∞Ê¨°Êï∞„ÄÇ ÈÅçÂéÜÊñáÊú¨Êó∂ÔºåËã•ÂçïËØçÂ∞öÊú™ÂÖ•Ë°®ÔºåÂàôÊñ∞Âª∫ËÆ∞ÂΩïÔºõËã•Â∑≤Â≠òÂú®ÔºåÂàôËÆ°Êï∞+1„ÄÇ ÊéíÂ∫è‰∏éÁ¥¢Âºï ÊåâËØçÈ¢ëÈôçÂ∫èÊéíÂ∫èÔºåËØçÈ¢ëÊúÄÈ´òÁöÑÂçïËØçÊéíÂú®ÂâçÈù¢„ÄÇ Á¥¢Âºï‰ªé1ÂºÄÂßãÔºå0ÁïôÁªô‚ÄúÊú™Áü•‚Äù„ÄÇ ËØçÂÖ∏ËßÑÊ®°ÔºàvocabularyÔºâÂèØËßÜÈúÄÊ±ÇÊà™Êñ≠Ôºà‰æãÂ¶ÇÂè™‰øùÁïôTop 10kÔºâ„ÄÇ ‰∏∫‰ªÄ‰πàÁßªÈô§‰ΩéÈ¢ëËØç ‰ΩéÈ¢ëËØçÂèØËÉΩÊòØÊãºÂÜôÈîôËØØ„ÄÅÁΩïËßÅ‰∫∫ÂêçÁ≠âÔºåÂØπÊ®°ÂûãÂ∏ÆÂä©ÊúâÈôê„ÄÇ ÂáèÂ∞ëËØçÂÖ∏ËßÑÊ®°ÂèØÈôç‰ΩéËøêÁÆóÂºÄÈîÄ„ÄÅÂä†Âø´Ê®°ÂûãËÆ≠ÁªÉ‰∏éÊé®ÁêÜÈÄüÂ∫¶„ÄÇ Áã¨ÁÉ≠ÁºñÁ†Å (One-Hot Encoding)\nÂ∞ÜÊØè‰∏™ÂçïËØçÊò†Â∞Ñ‰∏∫ËØçÂÖ∏‰∏≠ÁöÑÁ¥¢ÂºïÂêéÔºàÂ¶Ç [2, 4, 1, 8, ‚Ä¶]ÔºâÔºåÂèØËøõ‰∏ÄÊ≠•ËΩ¨Êç¢ÊàêOne-HotÂêëÈáè„ÄÇ One-HotÁª¥Â∫¶ÂèñÂÜ≥‰∫é‰øùÁïô‰∏ãÊù•ÁöÑËØçÂÖ∏Â§ßÂ∞èÔºà‰æãÂ¶Ç1‰∏áÔºâ„ÄÇ Êú™Êî∂ÂΩïÂçïËØçÂèØËÉΩÁõ¥Êé•ÂøΩÁï•ÔºåÊàñÁªü‰∏ÄÁî®Á¥¢Âºï0‰ª£Êõø„ÄÇ Âõõ„ÄÅÊ†∏ÂøÉÊî∂Ëé∑‰∏éÂ∫îÁî® Á±ªÂà´ÁâπÂæÅÂøÖÈúÄÊï∞ÂÄºÂåñÔºö\n‰ΩøÁî®Êï¥Êï∞1,2,3‚Ä¶‰ªÖË°®Á§∫Á±ªÂà´‚ÄúÊ†áËØÜ‚ÄùÔºåÂπ∂‰∏ç‰ª£Ë°®ÂÆÉ‰ª¨ÂèØËøõË°åÊï∞ÂÄºËøêÁÆó„ÄÇ Âõ†Ê≠§ÈúÄË¶ÅOne-HotÁ≠âÁºñÁ†ÅÊñπÂºèÔºåÈÅøÂÖçÊï∞ÂÄºËØØËß£„ÄÇ ÊñáÊú¨Êï∞ÊçÆÈ¢ÑÂ§ÑÁêÜÔºö\nÂàÜËØç„ÄÅËØçÈ¢ëÁªüËÆ°„ÄÅÊûÑÂª∫ËØçÂÖ∏„ÄÅÁ¥¢ÂºïÂåñ„ÄÅOne-HotÊàñÂÖ∂‰ªñÊñπÂºèÔºàÂ¶ÇËØçÂµåÂÖ•ÔºâÊòØÂ∏∏ËßÅÊµÅÁ®ã„ÄÇ Ê≠£Á°ÆÁöÑÊñáÊú¨È¢ÑÂ§ÑÁêÜÂèØÊòæËëóÂΩ±ÂìçÊ®°ÂûãÊÄßËÉΩÂíåÊïàÁéá„ÄÇ ‰øùÁïôÊú™Áü•Á¥¢ÂºïÔºö\n‰øùËØÅÂØπÁº∫Â§±Êï∞ÊçÆÊàñÂ≠óÂÖ∏Â§ñÊñ∞ËØçËÉΩÊúâÂü∫Êú¨ÁöÑË°®Á§∫ÔºåÊèêÂçáÊ®°ÂûãÂÆπÈîôÊÄß„ÄÇ ÂÆûÈôÖ‰ΩøÁî®Ôºö\nÂØπ‰∫éÂ∞èËßÑÊ®°Á±ªÂà´ÂèØÁõ¥Êé•One-HotÁºñÁ†ÅÔºõÂØπ‰∫éËØçÂÖ∏ÂæàÂ§ßÁöÑÂú∫ÊôØÔºåÈÄöÂ∏∏‰ºöËøõ‰∏ÄÊ≠•ËÄÉËôëËØçÂµåÂÖ•ÔºàWord EmbeddingÔºâÊàñÈ¢ÑËÆ≠ÁªÉËØ≠Ë®ÄÊ®°Âûã„ÄÇ ","permalink":"http://localhost:1313/posts/nlp-1/","summary":"\u003ch2 id=\"‰∏ÄÊï∞ÂÄºÁâπÂæÅ‰∏éÁ±ªÂà´ÁâπÂæÅ\"\u003e‰∏Ä„ÄÅÊï∞ÂÄºÁâπÂæÅ‰∏éÁ±ªÂà´ÁâπÂæÅ\u003c/h2\u003e\n\u003col\u003e\n\u003cli\u003e\u003cstrong\u003eÊï∞ÂÄºÁâπÂæÅ (Numeric Features)\u003c/strong\u003e\n\u003cul\u003e\n\u003cli\u003eÂÖ∑ÊúâÂèØÂä†ÂáèÁöÑÊÑè‰πâÔºå‰∏îÂ≠òÂú®Â§ßÂ∞èÈ°∫Â∫è„ÄÇ\u003c/li\u003e\n\u003cli\u003e‰æãÂ≠êÔºöÂπ¥ÈæÑ„ÄÅÊ∏©Â∫¶Á≠â„ÄÇÂèØ‰ª•Áõ¥Êé•‰øùÁïôÂÖ∂Êï¥Êï∞ÊàñÊµÆÁÇπÊï∞ÂΩ¢Âºè‰æõÊ®°Âûã‰ΩøÁî®„ÄÇ\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003eÁ±ªÂà´ÁâπÂæÅ (Categorical Features)\u003c/strong\u003e\n\u003cul\u003e\n\u003cli\u003eÊï∞ÊçÆÂÄºÁ¶ªÊï£Ôºå‰∏çÂÖ∑Â§á‚ÄúÊï∞ÂÄºÂ§ßÂ∞è‚ÄùÈó¥ÁöÑÂèØÊØîÊÑè‰πâ„ÄÇ\u003c/li\u003e\n\u003cli\u003e‰æãÂ≠êÔºöÂõΩÁ±çÔºàÁæéÂõΩ/‰∏≠ÂõΩ/Âç∞Â∫¶Á≠âÔºâ„ÄÅÊÄßÂà´ÔºàÁî∑/Â•≥ÔºâÁ≠â„ÄÇ\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003eÈóÆÈ¢ò\u003c/strong\u003eÔºöËã•‰ªÖÁî®Êï¥Êï∞Ë°®Á§∫ÔºàÁæéÂõΩ=1, ‰∏≠ÂõΩ=2ÔºâÔºå‰ºöÂºïÂÖ•ÈîôËØØÁöÑÊï∞ÂÄºËøêÁÆóÂÖ≥Á≥ªÔºåÂ¶Ç ‚ÄúÁæéÂõΩ + ‰∏≠ÂõΩ = Âç∞Â∫¶‚Äù„ÄÇ\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003c/ol\u003e\n\u003ch2 id=\"‰∫åone-hotÁºñÁ†ÅÁöÑÂä®Êú∫‰∏éÊµÅÁ®ã\"\u003e‰∫å„ÄÅOne-HotÁºñÁ†ÅÁöÑÂä®Êú∫‰∏éÊµÅÁ®ã\u003c/h2\u003e\n\u003col\u003e\n\u003cli\u003e\n\u003cp\u003e\u003cstrong\u003e‰∏∫‰ªÄ‰πà‰ΩøÁî®One-Hot\u003c/strong\u003e\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eÈÄöËøáÂ∞ÜÁ±ªÂà´Êò†Â∞Ñ‰∏∫ÂêëÈáèÔºåÈÅøÂÖçÊï¥Êï∞ÁºñÁ†ÅÂºïÂÖ•ÁöÑ‰º™Êï∞ÂÄºÂÖ≥Á≥ª„ÄÇ\u003c/li\u003e\n\u003cli\u003eÂêåÊó∂‰øùÁïôÂêÑÁßçÂèØËÉΩÁ±ªÂà´ÁöÑ‰ø°ÊÅØÔºå‰∏î‰ªÖÂú®ÂØπÂ∫î‰ΩçÁΩÆ‰∏∫1ÔºåÂÖ∂‰ªñ‰ΩçÁΩÆ‰∏∫0„ÄÇ\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003e\u003cstrong\u003eÂª∫Á´ãÊò†Â∞ÑÔºö‰ªéÁ±ªÂà´Âà∞Á¥¢Âºï\u003c/strong\u003e\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e‰∏∫ÊØè‰∏™Á±ªÂà´ÂàÜÈÖç‰∏Ä‰∏™ÂîØ‰∏ÄÁ¥¢ÂºïÔºåÈÄöÂ∏∏‰ªé1ÂºÄÂßã„ÄÇ\u003c/li\u003e\n\u003cli\u003eÈ¢ÑÁïôÁ¥¢Âºï0Ë°®Á§∫‚ÄúÊú™Áü•‚ÄùÊàñ‚ÄúÁº∫Â§±‚ÄùÔºåÂØπÂ∫îÂÖ®0ÂêëÈáè„ÄÇ\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003e\u003cstrong\u003eËΩ¨Êç¢‰∏∫One-HotÂêëÈáè\u003c/strong\u003e\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eËã•Á±ªÂà´ÊÄªÊï∞‰∏∫197ÔºåÂàôÁî®197Áª¥ÂêëÈáèË°®Á§∫„ÄÇ\u003c/li\u003e\n\u003cli\u003e‰æãÂ≠êÔºöÁæéÂõΩ \u003ccode\u003e[1, 0, 0, 0, ‚Ä¶]\u003c/code\u003eÔºå ‰∏≠ÂõΩ \u003ccode\u003e[0, 1, 0, 0, ‚Ä¶]\u003c/code\u003e„ÄÇ\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003e\u003cstrong\u003eÁ§∫‰æãÔºöË°®Á§∫‰∏Ä‰∏™‰∫∫ÁöÑÁâπÂæÅ\u003c/strong\u003e\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eÁâπÂæÅÂåÖÂê´ÔºàÂπ¥ÈæÑ, ÊÄßÂà´, ÂõΩÁ±çÔºåÂÖ∂‰∏≠ÂõΩÁ±ç197ÁßçÔºâ\u003c/li\u003e\n\u003cli\u003eÁª¥Â∫¶ÊÄªÂíåÔºö1Áª¥_age + 1Áª¥_gender + 197Áª¥_nationality = 199Áª¥„ÄÇ\u003c/li\u003e\n\u003cli\u003e‰æãÂ¶Ç \u003ccode\u003e(28, Â•≥, ‰∏≠ÂõΩ)\u003c/code\u003e ‚Üí \u003ccode\u003e[28, 0, 0, 1, 0, ‚Ä¶, 0]\u003c/code\u003e„ÄÇ\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003c/ol\u003e\n\u003ch2 id=\"‰∏âÊñáÊú¨Êï∞ÊçÆÂ§ÑÁêÜÊµÅÁ®ã\"\u003e‰∏â„ÄÅÊñáÊú¨Êï∞ÊçÆÂ§ÑÁêÜÊµÅÁ®ã\u003c/h2\u003e\n\u003cp\u003eÊñáÊú¨Âú®Ëá™ÁÑ∂ËØ≠Ë®ÄÂ§ÑÁêÜÔºàNLPÔºâ‰∏≠‰Ωú‰∏∫Â∏∏ËßÅÁöÑÂéüÂßãËæìÂÖ•ÔºåÈúÄË¶ÅÊï∞ÂÄºÂåñÊâçËÉΩÈÄÅÂÖ•Ê®°Âûã„ÄÇ‰∏ÄËà¨Ê≠•È™§Â¶Ç‰∏ãÔºö\u003c/p\u003e\n\u003col\u003e\n\u003cli\u003e\n\u003cp\u003e\u003cstrong\u003eÂàÜËØç (Tokenization)\u003c/strong\u003e\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eÂ∞ÜÊñáÊú¨ÊãÜÂàÜ‰∏∫‰∏Ä‰∏™‰∏™ÂçïËØçÔºàTokenÔºâ„ÄÇ\u003c/li\u003e\n\u003cli\u003e‰æãÂ≠êÔºö\u003ccode\u003e\u0026quot;... to be or not to be...\u0026quot;\u003c/code\u003e ‚Üí \u003ccode\u003e[\u0026quot;...\u0026quot;, \u0026quot;to\u0026quot;, \u0026quot;be\u0026quot;, \u0026quot;or\u0026quot;, \u0026quot;not\u0026quot;, \u0026quot;to\u0026quot;, \u0026quot;be\u0026quot;, \u0026quot;...\u0026quot;]\u003c/code\u003e„ÄÇ\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003e\u003cstrong\u003eÁªüËÆ°ËØçÈ¢ë \u0026amp; ÊûÑÂª∫ËØçÂÖ∏\u003c/strong\u003e\u003c/p\u003e","title":""},{"content":"Text to Sequence ÊñáÊú¨Â§ÑÁêÜ\nStep1: Tokenization\nTokenization breaks a piece of text down into a list of tokens.\nHere, a token is a word. (A token can be a character in some applications.)\nTokenizationËÆ≤Á©∂ÂæàÂ§öÔºå‰æãÂ¶ÇÊòØÂê¶Â∫îËØ•ÊääÂ§ßÂÜôÊîπÊàêÂ∞èÂÜôÂë¢ÔºüËøõË°åtypo correctionÁ≠âÁ≠â\nStep2: Build Dictionary\nUse a dictionary (hash table) to count word frequencies.\nThe dictionary maps word to index.\nÂèØ‰ª•È¶ñÂÖàÁªüËÆ°ËØçÈ¢ëÂéªÊéâ‰ΩéÈ¢ëËØçÔºåÁÑ∂ÂêéËÆ©ÊØè‰∏™ËØçÂØπÂ∫î‰∏Ä‰∏™Ê≠£Êï¥Êï∞ÔºõËøôÊ†∑ÁöÑËØùÔºå‰∏ÄÂè•ËØùÂ∞±ÂèØ‰ª•Áî®‰∏Ä‰∏™Ê≠£Êï¥Êï∞ÂàóË°®Ë°®Á§∫ÔºåËøô‰∏™ÂàóË°®Â∞±Âè´sequenceÔºõÂ¶ÇÊûúÂøÖË¶ÅÂ∞±ËøòÂæóÂÅöone-hot encoding„ÄÇ\nÁªìÊûú\n‰ΩÜÊòØÈïøÂ∫¶‰∏çÁªü‰∏Ä\nStep4: ÂØπÈΩêsequence\nËß£ÂÜ≥ÊñπÊ°àÊòØËøôÊ†∑ÁöÑÔºöÂèØ‰ª•Âõ∫ÂÆöÈïøÂ∫¶‰∏∫wÔºåÂä†ÂÖ•‰∏Ä‰∏™Â∫èÂàóÈïøÂ∫¶Â§™ÈïøÔºåÂ∞±Á†çÊéâÂâçÈù¢ÁöÑËØçÔºåÂè™‰øùÁïôÊúÄÂêéw‰∏™ËØçÔºõÂ¶ÇÊûú‰∏Ä‰∏™Â∫èÂàóÂ§™Áü≠ÔºåÂ∞±ÂÅözero paddingÔºåÁî®0Â°´ÂÖÖ\nËøôÊ†∑‰∏ÄÊù•ÔºåÊâÄÊúâÁöÑÂ∫èÂàóÈïøÂ∫¶Â∞±Áªü‰∏Ä‰∫Ü\nÊñáÊú¨Â§ÑÁêÜÂÆåÊàê‰∫ÜÔºåÊé•‰∏ãÊù•ÊòØword embeddingÔºåÊääÂçïËØçË°®Á§∫‰∏∫‰∏Ä‰∏™‰ΩéÁª¥ÂêëÈáèÔºõ\nÁÑ∂ËÄåËøôÊ†∑ÂÅöÁöÑËØùÔºåÂ¶ÇÊûúÊòØ10000‰∏™ÂçïËØçÔºåÁª¥Â∫¶Â∞±ÊòØ10000Áª¥ÔºåÁª¥Â∫¶Â§™È´ò‰∫ÜÔºõÂõ†Ê≠§Ë¶ÅÂÅöword embeddingÔºõ\nÂÖ∑‰ΩìÂÅöÊ≥ïÂ∞±ÊòØÊääone-hotÂêëÈáèe_iÂíåÂèÇÊï∞Áü©ÈòµpÁõ∏‰πòÔºõÁü©ÈòµPËΩ¨ÁΩÆÁöÑÂ§ßÂ∞èÊòØd x vÔºõdÊòØËØçÂêëÈáèÁöÑÁª¥Â∫¶ÔºõvÊòØÂ≠óÂÖ∏ÈáåËØçÊ±áÁöÑÊï∞ÈáèÔºõÁªìÊûú‰∏∫x_iÔºõx_iÂ∞±ÊòØ‰∏Ä‰∏™ËØçÂêëÈáèÔºõÂ¶ÇÊûúone-hotÂêëÈáèÁöÑÁ¨¨‰∏âË°å‰∏∫1ÔºõÈÇ£‰πàx_iÂ∞±ÊòØPËΩ¨ÁΩÆÁü©ÈòµÁöÑÁ¨¨‰∏âÂàóÔºàÂÖ∂‰ΩôÂàóÈÉΩ‰∏∫0ÔºâÔºõÊâÄ‰ª•PËΩ¨ÁΩÆÊØè‰∏ÄÂàóÈÉΩÊòØ‰∏Ä‰∏™ËØçÂêëÈáèÔºõÊâÄ‰ª•Áü©ÈòµPÊú¨Ë∫´ÁöÑÊØè‰∏ÄË°åÂ∞±ÊòØ‰∏Ä‰∏™ËØçÂêëÈáèÔºõÂÖ∂Ë°åÊï∞‰∏∫vÔºõÂç≥vocabularyÔºåËØçÊ±áÈáèÔºõÊØè‰∏ÄË°åÂØπÂ∫î‰∏Ä‰∏™ÂçïËØçÔºõÁü©ÈòµÁöÑÂàóÊï∞‰∏∫dÔºõdÊòØÁî®Êà∑ÂÜ≥ÂÆöÁöÑÔºõdÁöÑÂ§ßÂ∞è‰ºöÂÜ≥ÂÆöÊú∫Âô®Â≠¶‰π†Ê®°ÂûãÁöÑË°®Áé∞ÔºõÂ∫îËØ•Áî®xxxÊù•ÈÄâÊã©‰∏Ä‰∏™ÊØîËæÉÂ•ΩÁöÑdÔºõ\nÊàë‰ª¨ÁöÑ‰ªªÂä°ÊòØÁúãËØÑËÆ∫ÊòØÊ≠£Èù¢ÁöÑËøòÊòØË¥üÈù¢ÁöÑÔºõÂèÇÊï∞Áü©ÈòµÊòØ‰ªéËÆ≠ÁªÉÊï∞ÊçÆ‰∏≠Â≠¶‰π†Âá∫Êù•ÁöÑÔºåÊâÄ‰ª•Â≠¶Âá∫Êù•ÁöÑËØçÂêëÈáèÊòØÂ∏¶ÊúâÊÑüÊÉÖËâ≤ÂΩ©ÁöÑÔºõÂÅáËÆæËøô‰∫õËØçÂêëÈáèÈÉΩÊòØ‰∫åÁª¥ÁöÑÔºåÂàôÂèØ‰ª•Âú®Âπ≥Èù¢ÂùêÊ†áÁ≥ª‰∏≠Ê†áÂá∫‰∏ãÈù¢ËØçÂêëÈáè\nkerasÊèê‰æõembeddingÂ±ÇÔºõÁî®Êà∑ÂèØ‰ª•ÊåáÂÆövocabularyÂ§ßÂ∞èÂíådÁöÑÂ§ßÂ∞èÔºõ‰ª•ÂèäÊØè‰∏Ä‰∏™sequenceÁöÑÈïøÂ∫¶ÔºõdÊòØÊ†πÊçÆÁÆóÊ≥ïÈÄâÂá∫Êù•ÁöÑ Âà∞Ëøô‰∏ÄÊ≠•ÔºåÊàë‰ª¨Â∑≤ÁªèÂÆåÊàê‰∫ÜÊñáÊú¨Â§ÑÁêÜÂíåword embedding„ÄÇÊé•‰∏ãÊù•Â∞±ÊòØÁî®Logistic Regression for Binary ClassificationÂÅö‰∫åÂàÜÁ±ªÔºõ\n","permalink":"http://localhost:1313/posts/nlp-2/","summary":"\u003ch3 id=\"text-to-sequence\"\u003eText to Sequence\u003c/h3\u003e\n\u003cp\u003eÊñáÊú¨Â§ÑÁêÜ\u003c/p\u003e\n\u003cp\u003eStep1: Tokenization\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\n\u003cp\u003eTokenization breaks a piece of text down into a list of tokens.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003eHere, a token is a word. (A token can be a character in some applications.)\u003c/p\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003eTokenizationËÆ≤Á©∂ÂæàÂ§öÔºå‰æãÂ¶ÇÊòØÂê¶Â∫îËØ•ÊääÂ§ßÂÜôÊîπÊàêÂ∞èÂÜôÂë¢ÔºüËøõË°åtypo correctionÁ≠âÁ≠â\u003c/p\u003e\n\u003cp\u003e\u003cimg alt=\"image-20250322150322238\" loading=\"lazy\" src=\"./NLP-2.assets/image-20250322150322238.png\"\u003e\u003c/p\u003e\n\u003cp\u003eStep2: Build Dictionary\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\n\u003cp\u003eUse a dictionary (hash table) to count word frequencies.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003eThe dictionary maps word to index.\u003c/p\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003eÂèØ‰ª•È¶ñÂÖàÁªüËÆ°ËØçÈ¢ëÂéªÊéâ‰ΩéÈ¢ëËØçÔºåÁÑ∂ÂêéËÆ©ÊØè‰∏™ËØçÂØπÂ∫î‰∏Ä‰∏™Ê≠£Êï¥Êï∞ÔºõËøôÊ†∑ÁöÑËØùÔºå‰∏ÄÂè•ËØùÂ∞±ÂèØ‰ª•Áî®‰∏Ä‰∏™Ê≠£Êï¥Êï∞ÂàóË°®Ë°®Á§∫ÔºåËøô‰∏™ÂàóË°®Â∞±Âè´sequenceÔºõÂ¶ÇÊûúÂøÖË¶ÅÂ∞±ËøòÂæóÂÅöone-hot encoding„ÄÇ\u003cimg alt=\"image-20250322150620890\" loading=\"lazy\" src=\"./NLP-2.assets/image-20250322150620890.png\"\u003e\u003c/p\u003e\n\u003cp\u003eÁªìÊûú\u003c/p\u003e\n\u003cp\u003e\u003cimg alt=\"image-20250322150754528\" loading=\"lazy\" src=\"./NLP-2.assets/image-20250322150754528.png\"\u003e\u003c/p\u003e\n\u003cp\u003e‰ΩÜÊòØÈïøÂ∫¶‰∏çÁªü‰∏Ä\u003c/p\u003e\n\u003cp\u003eStep4: ÂØπÈΩêsequence\u003c/p\u003e\n\u003cp\u003e\u003cimg alt=\"image-20250322150854986\" loading=\"lazy\" src=\"./NLP-2.assets/image-20250322150854986.png\"\u003e\u003c/p\u003e\n\u003cp\u003eËß£ÂÜ≥ÊñπÊ°àÊòØËøôÊ†∑ÁöÑÔºöÂèØ‰ª•Âõ∫ÂÆöÈïøÂ∫¶‰∏∫wÔºåÂä†ÂÖ•‰∏Ä‰∏™Â∫èÂàóÈïøÂ∫¶Â§™ÈïøÔºåÂ∞±Á†çÊéâÂâçÈù¢ÁöÑËØçÔºåÂè™‰øùÁïôÊúÄÂêéw‰∏™ËØçÔºõÂ¶ÇÊûú‰∏Ä‰∏™Â∫èÂàóÂ§™Áü≠ÔºåÂ∞±ÂÅözero paddingÔºåÁî®0Â°´ÂÖÖ\u003c/p\u003e\n\u003cp\u003e\u003cimg alt=\"image-20250322151030119\" loading=\"lazy\" src=\"./NLP-2.assets/image-20250322151030119.png\"\u003e\u003c/p\u003e\n\u003cp\u003eËøôÊ†∑‰∏ÄÊù•ÔºåÊâÄÊúâÁöÑÂ∫èÂàóÈïøÂ∫¶Â∞±Áªü‰∏Ä‰∫Ü\u003c/p\u003e\n\u003cp\u003e\u003cimg alt=\"image-20250322151117125\" loading=\"lazy\" src=\"./NLP-2.assets/image-20250322151117125.png\"\u003e\u003c/p\u003e\n\u003cp\u003eÊñáÊú¨Â§ÑÁêÜÂÆåÊàê‰∫ÜÔºåÊé•‰∏ãÊù•ÊòØword embeddingÔºåÊääÂçïËØçË°®Á§∫‰∏∫‰∏Ä‰∏™‰ΩéÁª¥ÂêëÈáèÔºõ\u003c/p\u003e\n\u003cp\u003e\u003cimg alt=\"image-20250322151252837\" loading=\"lazy\" src=\"./NLP-2.assets/image-20250322151252837.png\"\u003e\u003c/p\u003e","title":""},{"content":"üëã About me Hello! I\u0026rsquo;m Xu Zongsi, a passionate technology enthusiast currently pursuing my Master of Science in ECIC at The University of Hong Kong. With a solid background in Software Engineering from the Beijing Institute of Technology, I specialize in artificial intelligence areas like machine learning, deep learning, natural language processing, computer vision, and reinforcement learning.\nInspired by OpenAI\u0026rsquo;s five-step plan towards superintelligence, I am excited about AGI and have developed a keen interest in LLM agents, MLLM, and knowledge graphs. I see great potential in these fields and aspire to contribute to innovative solutions.\nüìö Education üá≠üá∞ The University of Hong Kong 09/2024 - Expected 11/2025 School of Computing and Data Science Master of Science in Electronic Commerce \u0026amp; Internet Computing Relevant Courses: Machine learning for business and e-commerce, Knowledge graphs, Financial fraud analytics, Internet infrastructure technologies, Website engineering, Blockchain and cryptocurrency, etc. üá®üá≥ Beijing Institute of Technology 09/2020 - 06/2024 School of Computer Science \u0026amp; Technology Bachelor of Engineering in Software Engineering, last two years GPA: 3.7/4 Relevant Courses: Reinforcement Learning, Deep Learning and Computer Vision, Artificial Intelligence and Robot Ethics, Almost Human: Mind, Brain and Artificial Intelligence, Mathematical Analysis for Engineering, Linear Algebra, Probability and Mathematical Statistics, etc. Skills: Python, Java, common data structures, design patterns, machine learning basics and algorithms, Linux, PyTorch, and some development tools (git, conda, etc.). üèÜ Awards \u0026amp; Honors Beijing Institute of Technology Undergraduate Scholarship (Top 20% of Grade) 06/2023 3rd Prize of China International \u0026#34;Internet \u0026#43;\u0026#34; College Student\u0026#39;s Innovation Competition 08/2022 Bronze Prize of \u0026#34;Challenge Cup\u0026#34; Capital University Entrepreneurship Competition 05/2022 üíº Project Experience üîç Online Transaction Fraud Detection 09/2024 ‚Äì 01/2025 Independent project, supervised by Dr. Vivien Chan Focused on addressing financial fraud in e-commerce to enhance the accuracy of transaction anomaly detection, while independently managing the entire case study that included data preprocessing, feature engineering, model building, evaluation, and results analysis. Effectively resolved class imbalance issues using SMOTE and ROSE techniques. Built various models including Logistic Regression, Random Forest, XGBoost, and LightGBM, ultimately selecting the LightGBM model to achieve a recall rate of 95.45% and an AUC of 99.84%. Wrote efficient and maintainable code, enhancing model training and data processing efficiency through parallel computing and logging. ü§ñ Multi-Model Intelligent Text Keyword Extraction System 08/2023 ‚Äì 09/2023 Group project, supervised by Associate Prof. Xiaolin Zhao Designed and implemented an intelligent text summary system that automatically extracts keywords from article titles and abstracts, enhancing the understanding and summarization of text information. Participated in the planning of the technical route and built a hybrid model combining extractive and generative approaches, utilizing advanced natural language processing techniques including KeyBERT, Sentence Transformer, BERT, and T5 models. Responsible for data preprocessing and tokenization, as well as the end-to-end implementation and training of the T5 model, optimizing the model architecture and hyperparameters, achieving satisfactory results after only 3 epochs of training. Model evaluation results showed that the Rouge-1, Rouge-2, and Rouge-L metrics reached 0.6345, 0.5038, and 0.5282, respectively, in the third epoch, validating the model\u0026rsquo;s effectiveness in the summarization task. üéì Cambridge University Machine Learning Summer Project 07/2023 ‚Äì 08/2023 Group project, supervised by Prof. Pietro Li√≤ Participated in the Cambridge University deep learning summer project, focusing on deep reinforcement learning; explored multi-agent learning algorithms across different environments. Reproduced the Multi-Agent Deep Deterministic Policy Gradient (MADDPG) algorithm in the Simple Adversary environment and studied the effect of agent numbers on convergence speed and stability, finding optimal stability at 21 agents. Designed and implemented comparative experiments inspired by the Rainbow algorithm, assessing target network strategies versus the Double Deep Q-Network (Double DQN). The results demonstrated that Double DQN significantly enhanced convergence speed, optimizing the overall learning process. Co-authored a group project paper on agent numbers and strategies effectiveness in multi-agent systems, achieving a score of 71% in the summer program (the highest in my group) and a \u0026ldquo;First Class\u0026rdquo; classification in the UK grading system. üëÅÔ∏è Deep Learning and Computer Vision Semester Project 09/2022 ‚Äì 12/2022 Independent project, supervised by Associate Prof. Guangyu Gao Designed and implemented a waste classifier using the ResNet model to improve classification accuracy and reduce resource waste. The project also enhanced understanding of transfer learning techniques with ResNet. Collected a dataset of 16 waste categories and preprocessed the images for uniformity and standardization, incorporating data augmentation techniques to enhance the dataset. Conducted experiments using ResNet34 and ResNet50 models through transfer learning, accelerating network convergence by leveraging pretrained weights. During training, techniques such as Batch Normalization and Dropout were applied to mitigate the risk of overfitting. The final model achieved an accuracy of 90% on the training set, while the performance on the test set was 61%, indicating a significant overfitting phenomenon during the training process. üéì Internship ‚öõÔ∏è Beijing Academy of Quantum Information Science 08/2023 ‚Äì 01/2024 Research Intern at Quantum Computation Department Proposed a quantum convolution kernel design based on variational quantum circuits and developed a universal quantum convolution layer, successfully integrating it into classical CNN architectures such as VGG, GoogLeNet, and ResNet. Developed and evaluated various hybrid models, including a simple model named HQCCNN-2, which achieved 84.45% accuracy on the FashionMNIST dataset, surpassing the traditional CNN\u0026rsquo;s 80.72%. This demonstrates the effectiveness of the quantum convolution layer in improving model performance. Tested on a real quantum computer further validated the effectiveness of the hybrid model, demonstrating the viable integration of quantum computing with deep learning, and highlighting the potential for leveraging quantum properties to enhance model performance. üèÖ Competition Experience ü•â China International \u0026#34;Internet \u0026#43;\u0026#34; College Students\u0026#39; Innovation Competition 08/2022 üõ°Ô∏è Zhongke Ushield: Deep Learning-based Face Privacy Protection Authentication System Responsible for constructing a localized facial feature extraction engine based on MobileFaceNet, ensuring feature extraction is completed on end devices (such as mobile phones and cameras), guaranteeing that raw data does not leave the domain and is not stored, thus enhancing user privacy protection while improving recognition efficiency. ü•â \u0026#34;Challenge Cup\u0026#34; Capital University Entrepreneurship Competition 05/2022 üå≥ Smart Orchard Responsible for the development of the fruit detection, ripeness prediction, and pest identification system, using deep convolutional neural network (CNN) technology for intelligent monitoring of crop growth conditions. Applied advanced object detection algorithms such as Faster R-CNN and YOLO to achieve high precision in apple detection and ripeness assessment, with an accuracy rate exceeding 90%, significantly enhancing the intelligence level of orchard management. Built and trained a dedicated dataset containing various pest samples, optimizing pest detection accuracy through data preprocessing (such as image normalization and resizing) and data augmentation techniques (like rotation, flipping, and noise addition), enabling the real-time monitoring system to accurately identify over 80% of pests, providing effective scientific maintenance recommendations to help farmers reduce crop losses. üìã Extracurricular Activities Vice President, Cyber Security Club, Beijing Institute of Technology 09/2021-09/2022 Backbone, Media Center of the Student Union of Beijing Institute of Technology 10/2020-06/2021 üì´ Contact üìß Email: zongsi.xu@outlook.com üëî LinkedIn: Zongsi (Tristan) Xu üíª GitHub: BaizeXS üìç Location: Hong Kong SAR, China ","permalink":"http://localhost:1313/resume/","summary":"Personal resume of Zongsi (Tristan) Xu","title":"Zongsi (Tristan) Xu"},{"content":"‰∏Ä„ÄÅÊï∞ÂÄºÁâπÂæÅ‰∏éÁ±ªÂà´ÁâπÂæÅ Êï∞ÂÄºÁâπÂæÅ (Numeric Features) ÂÖ∑ÊúâÂèØÂä†ÂáèÁöÑÊÑè‰πâÔºå‰∏îÂ≠òÂú®Â§ßÂ∞èÈ°∫Â∫è„ÄÇ ‰æãÂ≠êÔºöÂπ¥ÈæÑ„ÄÅÊ∏©Â∫¶Á≠â„ÄÇÂèØ‰ª•Áõ¥Êé•‰øùÁïôÂÖ∂Êï¥Êï∞ÊàñÊµÆÁÇπÊï∞ÂΩ¢Âºè‰æõÊ®°Âûã‰ΩøÁî®„ÄÇ Á±ªÂà´ÁâπÂæÅ (Categorical Features) Êï∞ÊçÆÂÄºÁ¶ªÊï£Ôºå‰∏çÂÖ∑Â§á‚ÄúÊï∞ÂÄºÂ§ßÂ∞è‚ÄùÈó¥ÁöÑÂèØÊØîÊÑè‰πâ„ÄÇ ‰æãÂ≠êÔºöÂõΩÁ±çÔºàÁæéÂõΩ/‰∏≠ÂõΩ/Âç∞Â∫¶Á≠âÔºâ„ÄÅÊÄßÂà´ÔºàÁî∑/Â•≥ÔºâÁ≠â„ÄÇ ÈóÆÈ¢òÔºöËã•‰ªÖÁî®Êï¥Êï∞Ë°®Á§∫ÔºàÁæéÂõΩ=1, ‰∏≠ÂõΩ=2ÔºâÔºå‰ºöÂºïÂÖ•ÈîôËØØÁöÑÊï∞ÂÄºËøêÁÆóÂÖ≥Á≥ªÔºåÂ¶Ç ‚ÄúÁæéÂõΩ + ‰∏≠ÂõΩ = Âç∞Â∫¶‚Äù„ÄÇ ‰∫å„ÄÅOne-HotÁºñÁ†ÅÁöÑÂä®Êú∫‰∏éÊµÅÁ®ã ‰∏∫‰ªÄ‰πà‰ΩøÁî®One-Hot\nÈÄöËøáÂ∞ÜÁ±ªÂà´Êò†Â∞Ñ‰∏∫ÂêëÈáèÔºåÈÅøÂÖçÊï¥Êï∞ÁºñÁ†ÅÂºïÂÖ•ÁöÑ‰º™Êï∞ÂÄºÂÖ≥Á≥ª„ÄÇ ÂêåÊó∂‰øùÁïôÂêÑÁßçÂèØËÉΩÁ±ªÂà´ÁöÑ‰ø°ÊÅØÔºå‰∏î‰ªÖÂú®ÂØπÂ∫î‰ΩçÁΩÆ‰∏∫1ÔºåÂÖ∂‰ªñ‰ΩçÁΩÆ‰∏∫0„ÄÇ Âª∫Á´ãÊò†Â∞ÑÔºö‰ªéÁ±ªÂà´Âà∞Á¥¢Âºï\n‰∏∫ÊØè‰∏™Á±ªÂà´ÂàÜÈÖç‰∏Ä‰∏™ÂîØ‰∏ÄÁ¥¢ÂºïÔºåÈÄöÂ∏∏‰ªé1ÂºÄÂßã„ÄÇ È¢ÑÁïôÁ¥¢Âºï0Ë°®Á§∫‚ÄúÊú™Áü•‚ÄùÊàñ‚ÄúÁº∫Â§±‚ÄùÔºåÂØπÂ∫îÂÖ®0ÂêëÈáè„ÄÇ ËΩ¨Êç¢‰∏∫One-HotÂêëÈáè\nËã•Á±ªÂà´ÊÄªÊï∞‰∏∫197ÔºåÂàôÁî®197Áª¥ÂêëÈáèË°®Á§∫„ÄÇ ‰æãÂ≠êÔºöÁæéÂõΩ [1, 0, 0, 0, ‚Ä¶]Ôºå ‰∏≠ÂõΩ [0, 1, 0, 0, ‚Ä¶]„ÄÇ Á§∫‰æãÔºöË°®Á§∫‰∏Ä‰∏™‰∫∫ÁöÑÁâπÂæÅ\nÁâπÂæÅÂåÖÂê´ÔºàÂπ¥ÈæÑ, ÊÄßÂà´, ÂõΩÁ±çÔºåÂÖ∂‰∏≠ÂõΩÁ±ç197ÁßçÔºâ Áª¥Â∫¶ÊÄªÂíåÔºö1Áª¥_age + 1Áª¥_gender + 197Áª¥_nationality = 199Áª¥„ÄÇ ‰æãÂ¶Ç (28, Â•≥, ‰∏≠ÂõΩ) ‚Üí [28, 0, 0, 1, 0, ‚Ä¶, 0]„ÄÇ ‰∏â„ÄÅÊñáÊú¨Êï∞ÊçÆÂ§ÑÁêÜÊµÅÁ®ã ÊñáÊú¨Âú®Ëá™ÁÑ∂ËØ≠Ë®ÄÂ§ÑÁêÜÔºàNLPÔºâ‰∏≠‰Ωú‰∏∫Â∏∏ËßÅÁöÑÂéüÂßãËæìÂÖ•ÔºåÈúÄË¶ÅÊï∞ÂÄºÂåñÊâçËÉΩÈÄÅÂÖ•Ê®°Âûã„ÄÇ‰∏ÄËà¨Ê≠•È™§Â¶Ç‰∏ãÔºö\nÂàÜËØç (Tokenization)\nÂ∞ÜÊñáÊú¨ÊãÜÂàÜ‰∏∫‰∏Ä‰∏™‰∏™ÂçïËØçÔºàTokenÔºâ„ÄÇ ‰æãÂ≠êÔºö\u0026quot;... to be or not to be...\u0026quot; ‚Üí [\u0026quot;...\u0026quot;, \u0026quot;to\u0026quot;, \u0026quot;be\u0026quot;, \u0026quot;or\u0026quot;, \u0026quot;not\u0026quot;, \u0026quot;to\u0026quot;, \u0026quot;be\u0026quot;, \u0026quot;...\u0026quot;]„ÄÇ ÁªüËÆ°ËØçÈ¢ë \u0026amp; ÊûÑÂª∫ËØçÂÖ∏\nËØçÈ¢ëÁªüËÆ° Áî®ÂìàÂ∏åË°®/Â≠óÂÖ∏ËÆ∞ÂΩïÊØè‰∏™ÂçïËØçÂá∫Áé∞Ê¨°Êï∞„ÄÇ ÈÅçÂéÜÊñáÊú¨Êó∂ÔºåËã•ÂçïËØçÂ∞öÊú™ÂÖ•Ë°®ÔºåÂàôÊñ∞Âª∫ËÆ∞ÂΩïÔºõËã•Â∑≤Â≠òÂú®ÔºåÂàôËÆ°Êï∞+1„ÄÇ ÊéíÂ∫è‰∏éÁ¥¢Âºï ÊåâËØçÈ¢ëÈôçÂ∫èÊéíÂ∫èÔºåËØçÈ¢ëÊúÄÈ´òÁöÑÂçïËØçÊéíÂú®ÂâçÈù¢„ÄÇ Á¥¢Âºï‰ªé1ÂºÄÂßãÔºå0ÁïôÁªô‚ÄúÊú™Áü•‚Äù„ÄÇ ËØçÂÖ∏ËßÑÊ®°ÔºàvocabularyÔºâÂèØËßÜÈúÄÊ±ÇÊà™Êñ≠Ôºà‰æãÂ¶ÇÂè™‰øùÁïôTop 10kÔºâ„ÄÇ ‰∏∫‰ªÄ‰πàÁßªÈô§‰ΩéÈ¢ëËØç ‰ΩéÈ¢ëËØçÂèØËÉΩÊòØÊãºÂÜôÈîôËØØ„ÄÅÁΩïËßÅ‰∫∫ÂêçÁ≠âÔºåÂØπÊ®°ÂûãÂ∏ÆÂä©ÊúâÈôê„ÄÇ ÂáèÂ∞ëËØçÂÖ∏ËßÑÊ®°ÂèØÈôç‰ΩéËøêÁÆóÂºÄÈîÄ„ÄÅÂä†Âø´Ê®°ÂûãËÆ≠ÁªÉ‰∏éÊé®ÁêÜÈÄüÂ∫¶„ÄÇ Áã¨ÁÉ≠ÁºñÁ†Å (One-Hot Encoding)\nÂ∞ÜÊØè‰∏™ÂçïËØçÊò†Â∞Ñ‰∏∫ËØçÂÖ∏‰∏≠ÁöÑÁ¥¢ÂºïÂêéÔºàÂ¶Ç [2, 4, 1, 8, ‚Ä¶]ÔºâÔºåÂèØËøõ‰∏ÄÊ≠•ËΩ¨Êç¢ÊàêOne-HotÂêëÈáè„ÄÇ One-HotÁª¥Â∫¶ÂèñÂÜ≥‰∫é‰øùÁïô‰∏ãÊù•ÁöÑËØçÂÖ∏Â§ßÂ∞èÔºà‰æãÂ¶Ç1‰∏áÔºâ„ÄÇ Êú™Êî∂ÂΩïÂçïËØçÂèØËÉΩÁõ¥Êé•ÂøΩÁï•ÔºåÊàñÁªü‰∏ÄÁî®Á¥¢Âºï0‰ª£Êõø„ÄÇ Âõõ„ÄÅÊ†∏ÂøÉÊî∂Ëé∑‰∏éÂ∫îÁî® Á±ªÂà´ÁâπÂæÅÂøÖÈúÄÊï∞ÂÄºÂåñÔºö\n‰ΩøÁî®Êï¥Êï∞1,2,3‚Ä¶‰ªÖË°®Á§∫Á±ªÂà´‚ÄúÊ†áËØÜ‚ÄùÔºåÂπ∂‰∏ç‰ª£Ë°®ÂÆÉ‰ª¨ÂèØËøõË°åÊï∞ÂÄºËøêÁÆó„ÄÇ Âõ†Ê≠§ÈúÄË¶ÅOne-HotÁ≠âÁºñÁ†ÅÊñπÂºèÔºåÈÅøÂÖçÊï∞ÂÄºËØØËß£„ÄÇ ÊñáÊú¨Êï∞ÊçÆÈ¢ÑÂ§ÑÁêÜÔºö\nÂàÜËØç„ÄÅËØçÈ¢ëÁªüËÆ°„ÄÅÊûÑÂª∫ËØçÂÖ∏„ÄÅÁ¥¢ÂºïÂåñ„ÄÅOne-HotÊàñÂÖ∂‰ªñÊñπÂºèÔºàÂ¶ÇËØçÂµåÂÖ•ÔºâÊòØÂ∏∏ËßÅÊµÅÁ®ã„ÄÇ Ê≠£Á°ÆÁöÑÊñáÊú¨È¢ÑÂ§ÑÁêÜÂèØÊòæËëóÂΩ±ÂìçÊ®°ÂûãÊÄßËÉΩÂíåÊïàÁéá„ÄÇ ‰øùÁïôÊú™Áü•Á¥¢ÂºïÔºö\n‰øùËØÅÂØπÁº∫Â§±Êï∞ÊçÆÊàñÂ≠óÂÖ∏Â§ñÊñ∞ËØçËÉΩÊúâÂü∫Êú¨ÁöÑË°®Á§∫ÔºåÊèêÂçáÊ®°ÂûãÂÆπÈîôÊÄß„ÄÇ ÂÆûÈôÖ‰ΩøÁî®Ôºö\nÂØπ‰∫éÂ∞èËßÑÊ®°Á±ªÂà´ÂèØÁõ¥Êé•One-HotÁºñÁ†ÅÔºõÂØπ‰∫éËØçÂÖ∏ÂæàÂ§ßÁöÑÂú∫ÊôØÔºåÈÄöÂ∏∏‰ºöËøõ‰∏ÄÊ≠•ËÄÉËôëËØçÂµåÂÖ•ÔºàWord EmbeddingÔºâÊàñÈ¢ÑËÆ≠ÁªÉËØ≠Ë®ÄÊ®°Âûã„ÄÇ ","permalink":"http://localhost:1313/posts/nlp-1/","summary":"\u003ch2 id=\"‰∏ÄÊï∞ÂÄºÁâπÂæÅ‰∏éÁ±ªÂà´ÁâπÂæÅ\"\u003e‰∏Ä„ÄÅÊï∞ÂÄºÁâπÂæÅ‰∏éÁ±ªÂà´ÁâπÂæÅ\u003c/h2\u003e\n\u003col\u003e\n\u003cli\u003e\u003cstrong\u003eÊï∞ÂÄºÁâπÂæÅ (Numeric Features)\u003c/strong\u003e\n\u003cul\u003e\n\u003cli\u003eÂÖ∑ÊúâÂèØÂä†ÂáèÁöÑÊÑè‰πâÔºå‰∏îÂ≠òÂú®Â§ßÂ∞èÈ°∫Â∫è„ÄÇ\u003c/li\u003e\n\u003cli\u003e‰æãÂ≠êÔºöÂπ¥ÈæÑ„ÄÅÊ∏©Â∫¶Á≠â„ÄÇÂèØ‰ª•Áõ¥Êé•‰øùÁïôÂÖ∂Êï¥Êï∞ÊàñÊµÆÁÇπÊï∞ÂΩ¢Âºè‰æõÊ®°Âûã‰ΩøÁî®„ÄÇ\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003eÁ±ªÂà´ÁâπÂæÅ (Categorical Features)\u003c/strong\u003e\n\u003cul\u003e\n\u003cli\u003eÊï∞ÊçÆÂÄºÁ¶ªÊï£Ôºå‰∏çÂÖ∑Â§á‚ÄúÊï∞ÂÄºÂ§ßÂ∞è‚ÄùÈó¥ÁöÑÂèØÊØîÊÑè‰πâ„ÄÇ\u003c/li\u003e\n\u003cli\u003e‰æãÂ≠êÔºöÂõΩÁ±çÔºàÁæéÂõΩ/‰∏≠ÂõΩ/Âç∞Â∫¶Á≠âÔºâ„ÄÅÊÄßÂà´ÔºàÁî∑/Â•≥ÔºâÁ≠â„ÄÇ\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003eÈóÆÈ¢ò\u003c/strong\u003eÔºöËã•‰ªÖÁî®Êï¥Êï∞Ë°®Á§∫ÔºàÁæéÂõΩ=1, ‰∏≠ÂõΩ=2ÔºâÔºå‰ºöÂºïÂÖ•ÈîôËØØÁöÑÊï∞ÂÄºËøêÁÆóÂÖ≥Á≥ªÔºåÂ¶Ç ‚ÄúÁæéÂõΩ + ‰∏≠ÂõΩ = Âç∞Â∫¶‚Äù„ÄÇ\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003c/ol\u003e\n\u003ch2 id=\"‰∫åone-hotÁºñÁ†ÅÁöÑÂä®Êú∫‰∏éÊµÅÁ®ã\"\u003e‰∫å„ÄÅOne-HotÁºñÁ†ÅÁöÑÂä®Êú∫‰∏éÊµÅÁ®ã\u003c/h2\u003e\n\u003col\u003e\n\u003cli\u003e\n\u003cp\u003e\u003cstrong\u003e‰∏∫‰ªÄ‰πà‰ΩøÁî®One-Hot\u003c/strong\u003e\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eÈÄöËøáÂ∞ÜÁ±ªÂà´Êò†Â∞Ñ‰∏∫ÂêëÈáèÔºåÈÅøÂÖçÊï¥Êï∞ÁºñÁ†ÅÂºïÂÖ•ÁöÑ‰º™Êï∞ÂÄºÂÖ≥Á≥ª„ÄÇ\u003c/li\u003e\n\u003cli\u003eÂêåÊó∂‰øùÁïôÂêÑÁßçÂèØËÉΩÁ±ªÂà´ÁöÑ‰ø°ÊÅØÔºå‰∏î‰ªÖÂú®ÂØπÂ∫î‰ΩçÁΩÆ‰∏∫1ÔºåÂÖ∂‰ªñ‰ΩçÁΩÆ‰∏∫0„ÄÇ\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003e\u003cstrong\u003eÂª∫Á´ãÊò†Â∞ÑÔºö‰ªéÁ±ªÂà´Âà∞Á¥¢Âºï\u003c/strong\u003e\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e‰∏∫ÊØè‰∏™Á±ªÂà´ÂàÜÈÖç‰∏Ä‰∏™ÂîØ‰∏ÄÁ¥¢ÂºïÔºåÈÄöÂ∏∏‰ªé1ÂºÄÂßã„ÄÇ\u003c/li\u003e\n\u003cli\u003eÈ¢ÑÁïôÁ¥¢Âºï0Ë°®Á§∫‚ÄúÊú™Áü•‚ÄùÊàñ‚ÄúÁº∫Â§±‚ÄùÔºåÂØπÂ∫îÂÖ®0ÂêëÈáè„ÄÇ\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003e\u003cstrong\u003eËΩ¨Êç¢‰∏∫One-HotÂêëÈáè\u003c/strong\u003e\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eËã•Á±ªÂà´ÊÄªÊï∞‰∏∫197ÔºåÂàôÁî®197Áª¥ÂêëÈáèË°®Á§∫„ÄÇ\u003c/li\u003e\n\u003cli\u003e‰æãÂ≠êÔºöÁæéÂõΩ \u003ccode\u003e[1, 0, 0, 0, ‚Ä¶]\u003c/code\u003eÔºå ‰∏≠ÂõΩ \u003ccode\u003e[0, 1, 0, 0, ‚Ä¶]\u003c/code\u003e„ÄÇ\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003e\u003cstrong\u003eÁ§∫‰æãÔºöË°®Á§∫‰∏Ä‰∏™‰∫∫ÁöÑÁâπÂæÅ\u003c/strong\u003e\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eÁâπÂæÅÂåÖÂê´ÔºàÂπ¥ÈæÑ, ÊÄßÂà´, ÂõΩÁ±çÔºåÂÖ∂‰∏≠ÂõΩÁ±ç197ÁßçÔºâ\u003c/li\u003e\n\u003cli\u003eÁª¥Â∫¶ÊÄªÂíåÔºö1Áª¥_age + 1Áª¥_gender + 197Áª¥_nationality = 199Áª¥„ÄÇ\u003c/li\u003e\n\u003cli\u003e‰æãÂ¶Ç \u003ccode\u003e(28, Â•≥, ‰∏≠ÂõΩ)\u003c/code\u003e ‚Üí \u003ccode\u003e[28, 0, 0, 1, 0, ‚Ä¶, 0]\u003c/code\u003e„ÄÇ\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003c/ol\u003e\n\u003ch2 id=\"‰∏âÊñáÊú¨Êï∞ÊçÆÂ§ÑÁêÜÊµÅÁ®ã\"\u003e‰∏â„ÄÅÊñáÊú¨Êï∞ÊçÆÂ§ÑÁêÜÊµÅÁ®ã\u003c/h2\u003e\n\u003cp\u003eÊñáÊú¨Âú®Ëá™ÁÑ∂ËØ≠Ë®ÄÂ§ÑÁêÜÔºàNLPÔºâ‰∏≠‰Ωú‰∏∫Â∏∏ËßÅÁöÑÂéüÂßãËæìÂÖ•ÔºåÈúÄË¶ÅÊï∞ÂÄºÂåñÊâçËÉΩÈÄÅÂÖ•Ê®°Âûã„ÄÇ‰∏ÄËà¨Ê≠•È™§Â¶Ç‰∏ãÔºö\u003c/p\u003e\n\u003col\u003e\n\u003cli\u003e\n\u003cp\u003e\u003cstrong\u003eÂàÜËØç (Tokenization)\u003c/strong\u003e\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eÂ∞ÜÊñáÊú¨ÊãÜÂàÜ‰∏∫‰∏Ä‰∏™‰∏™ÂçïËØçÔºàTokenÔºâ„ÄÇ\u003c/li\u003e\n\u003cli\u003e‰æãÂ≠êÔºö\u003ccode\u003e\u0026quot;... to be or not to be...\u0026quot;\u003c/code\u003e ‚Üí \u003ccode\u003e[\u0026quot;...\u0026quot;, \u0026quot;to\u0026quot;, \u0026quot;be\u0026quot;, \u0026quot;or\u0026quot;, \u0026quot;not\u0026quot;, \u0026quot;to\u0026quot;, \u0026quot;be\u0026quot;, \u0026quot;...\u0026quot;]\u003c/code\u003e„ÄÇ\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003e\u003cstrong\u003eÁªüËÆ°ËØçÈ¢ë \u0026amp; ÊûÑÂª∫ËØçÂÖ∏\u003c/strong\u003e\u003c/p\u003e","title":""},{"content":"Text to Sequence ÊñáÊú¨Â§ÑÁêÜ\nStep1: Tokenization\nTokenization breaks a piece of text down into a list of tokens.\nHere, a token is a word. (A token can be a character in some applications.)\nTokenizationËÆ≤Á©∂ÂæàÂ§öÔºå‰æãÂ¶ÇÊòØÂê¶Â∫îËØ•ÊääÂ§ßÂÜôÊîπÊàêÂ∞èÂÜôÂë¢ÔºüËøõË°åtypo correctionÁ≠âÁ≠â\nStep2: Build Dictionary\nUse a dictionary (hash table) to count word frequencies.\nThe dictionary maps word to index.\nÂèØ‰ª•È¶ñÂÖàÁªüËÆ°ËØçÈ¢ëÂéªÊéâ‰ΩéÈ¢ëËØçÔºåÁÑ∂ÂêéËÆ©ÊØè‰∏™ËØçÂØπÂ∫î‰∏Ä‰∏™Ê≠£Êï¥Êï∞ÔºõËøôÊ†∑ÁöÑËØùÔºå‰∏ÄÂè•ËØùÂ∞±ÂèØ‰ª•Áî®‰∏Ä‰∏™Ê≠£Êï¥Êï∞ÂàóË°®Ë°®Á§∫ÔºåËøô‰∏™ÂàóË°®Â∞±Âè´sequenceÔºõÂ¶ÇÊûúÂøÖË¶ÅÂ∞±ËøòÂæóÂÅöone-hot encoding„ÄÇ\nÁªìÊûú\n‰ΩÜÊòØÈïøÂ∫¶‰∏çÁªü‰∏Ä\nStep4: ÂØπÈΩêsequence\nËß£ÂÜ≥ÊñπÊ°àÊòØËøôÊ†∑ÁöÑÔºöÂèØ‰ª•Âõ∫ÂÆöÈïøÂ∫¶‰∏∫wÔºåÂä†ÂÖ•‰∏Ä‰∏™Â∫èÂàóÈïøÂ∫¶Â§™ÈïøÔºåÂ∞±Á†çÊéâÂâçÈù¢ÁöÑËØçÔºåÂè™‰øùÁïôÊúÄÂêéw‰∏™ËØçÔºõÂ¶ÇÊûú‰∏Ä‰∏™Â∫èÂàóÂ§™Áü≠ÔºåÂ∞±ÂÅözero paddingÔºåÁî®0Â°´ÂÖÖ\nËøôÊ†∑‰∏ÄÊù•ÔºåÊâÄÊúâÁöÑÂ∫èÂàóÈïøÂ∫¶Â∞±Áªü‰∏Ä‰∫Ü\nÊñáÊú¨Â§ÑÁêÜÂÆåÊàê‰∫ÜÔºåÊé•‰∏ãÊù•ÊòØword embeddingÔºåÊääÂçïËØçË°®Á§∫‰∏∫‰∏Ä‰∏™‰ΩéÁª¥ÂêëÈáèÔºõ\nÁÑ∂ËÄåËøôÊ†∑ÂÅöÁöÑËØùÔºåÂ¶ÇÊûúÊòØ10000‰∏™ÂçïËØçÔºåÁª¥Â∫¶Â∞±ÊòØ10000Áª¥ÔºåÁª¥Â∫¶Â§™È´ò‰∫ÜÔºõÂõ†Ê≠§Ë¶ÅÂÅöword embeddingÔºõ\nÂÖ∑‰ΩìÂÅöÊ≥ïÂ∞±ÊòØÊääone-hotÂêëÈáèe_iÂíåÂèÇÊï∞Áü©ÈòµpÁõ∏‰πòÔºõÁü©ÈòµPËΩ¨ÁΩÆÁöÑÂ§ßÂ∞èÊòØd x vÔºõdÊòØËØçÂêëÈáèÁöÑÁª¥Â∫¶ÔºõvÊòØÂ≠óÂÖ∏ÈáåËØçÊ±áÁöÑÊï∞ÈáèÔºõÁªìÊûú‰∏∫x_iÔºõx_iÂ∞±ÊòØ‰∏Ä‰∏™ËØçÂêëÈáèÔºõÂ¶ÇÊûúone-hotÂêëÈáèÁöÑÁ¨¨‰∏âË°å‰∏∫1ÔºõÈÇ£‰πàx_iÂ∞±ÊòØPËΩ¨ÁΩÆÁü©ÈòµÁöÑÁ¨¨‰∏âÂàóÔºàÂÖ∂‰ΩôÂàóÈÉΩ‰∏∫0ÔºâÔºõÊâÄ‰ª•PËΩ¨ÁΩÆÊØè‰∏ÄÂàóÈÉΩÊòØ‰∏Ä‰∏™ËØçÂêëÈáèÔºõÊâÄ‰ª•Áü©ÈòµPÊú¨Ë∫´ÁöÑÊØè‰∏ÄË°åÂ∞±ÊòØ‰∏Ä‰∏™ËØçÂêëÈáèÔºõÂÖ∂Ë°åÊï∞‰∏∫vÔºõÂç≥vocabularyÔºåËØçÊ±áÈáèÔºõÊØè‰∏ÄË°åÂØπÂ∫î‰∏Ä‰∏™ÂçïËØçÔºõÁü©ÈòµÁöÑÂàóÊï∞‰∏∫dÔºõdÊòØÁî®Êà∑ÂÜ≥ÂÆöÁöÑÔºõdÁöÑÂ§ßÂ∞è‰ºöÂÜ≥ÂÆöÊú∫Âô®Â≠¶‰π†Ê®°ÂûãÁöÑË°®Áé∞ÔºõÂ∫îËØ•Áî®xxxÊù•ÈÄâÊã©‰∏Ä‰∏™ÊØîËæÉÂ•ΩÁöÑdÔºõ\nÊàë‰ª¨ÁöÑ‰ªªÂä°ÊòØÁúãËØÑËÆ∫ÊòØÊ≠£Èù¢ÁöÑËøòÊòØË¥üÈù¢ÁöÑÔºõÂèÇÊï∞Áü©ÈòµÊòØ‰ªéËÆ≠ÁªÉÊï∞ÊçÆ‰∏≠Â≠¶‰π†Âá∫Êù•ÁöÑÔºåÊâÄ‰ª•Â≠¶Âá∫Êù•ÁöÑËØçÂêëÈáèÊòØÂ∏¶ÊúâÊÑüÊÉÖËâ≤ÂΩ©ÁöÑÔºõÂÅáËÆæËøô‰∫õËØçÂêëÈáèÈÉΩÊòØ‰∫åÁª¥ÁöÑÔºåÂàôÂèØ‰ª•Âú®Âπ≥Èù¢ÂùêÊ†áÁ≥ª‰∏≠Ê†áÂá∫‰∏ãÈù¢ËØçÂêëÈáè\nkerasÊèê‰æõembeddingÂ±ÇÔºõÁî®Êà∑ÂèØ‰ª•ÊåáÂÆövocabularyÂ§ßÂ∞èÂíådÁöÑÂ§ßÂ∞èÔºõ‰ª•ÂèäÊØè‰∏Ä‰∏™sequenceÁöÑÈïøÂ∫¶ÔºõdÊòØÊ†πÊçÆÁÆóÊ≥ïÈÄâÂá∫Êù•ÁöÑ Âà∞Ëøô‰∏ÄÊ≠•ÔºåÊàë‰ª¨Â∑≤ÁªèÂÆåÊàê‰∫ÜÊñáÊú¨Â§ÑÁêÜÂíåword embedding„ÄÇÊé•‰∏ãÊù•Â∞±ÊòØÁî®Logistic Regression for Binary ClassificationÂÅö‰∫åÂàÜÁ±ªÔºõ\n","permalink":"http://localhost:1313/posts/nlp-2/","summary":"\u003ch3 id=\"text-to-sequence\"\u003eText to Sequence\u003c/h3\u003e\n\u003cp\u003eÊñáÊú¨Â§ÑÁêÜ\u003c/p\u003e\n\u003cp\u003eStep1: Tokenization\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\n\u003cp\u003eTokenization breaks a piece of text down into a list of tokens.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003eHere, a token is a word. (A token can be a character in some applications.)\u003c/p\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003eTokenizationËÆ≤Á©∂ÂæàÂ§öÔºå‰æãÂ¶ÇÊòØÂê¶Â∫îËØ•ÊääÂ§ßÂÜôÊîπÊàêÂ∞èÂÜôÂë¢ÔºüËøõË°åtypo correctionÁ≠âÁ≠â\u003c/p\u003e\n\u003cp\u003e\u003cimg alt=\"image-20250322150322238\" loading=\"lazy\" src=\"./NLP-2.assets/image-20250322150322238.png\"\u003e\u003c/p\u003e\n\u003cp\u003eStep2: Build Dictionary\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\n\u003cp\u003eUse a dictionary (hash table) to count word frequencies.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003eThe dictionary maps word to index.\u003c/p\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003eÂèØ‰ª•È¶ñÂÖàÁªüËÆ°ËØçÈ¢ëÂéªÊéâ‰ΩéÈ¢ëËØçÔºåÁÑ∂ÂêéËÆ©ÊØè‰∏™ËØçÂØπÂ∫î‰∏Ä‰∏™Ê≠£Êï¥Êï∞ÔºõËøôÊ†∑ÁöÑËØùÔºå‰∏ÄÂè•ËØùÂ∞±ÂèØ‰ª•Áî®‰∏Ä‰∏™Ê≠£Êï¥Êï∞ÂàóË°®Ë°®Á§∫ÔºåËøô‰∏™ÂàóË°®Â∞±Âè´sequenceÔºõÂ¶ÇÊûúÂøÖË¶ÅÂ∞±ËøòÂæóÂÅöone-hot encoding„ÄÇ\u003cimg alt=\"image-20250322150620890\" loading=\"lazy\" src=\"./NLP-2.assets/image-20250322150620890.png\"\u003e\u003c/p\u003e\n\u003cp\u003eÁªìÊûú\u003c/p\u003e\n\u003cp\u003e\u003cimg alt=\"image-20250322150754528\" loading=\"lazy\" src=\"./NLP-2.assets/image-20250322150754528.png\"\u003e\u003c/p\u003e\n\u003cp\u003e‰ΩÜÊòØÈïøÂ∫¶‰∏çÁªü‰∏Ä\u003c/p\u003e\n\u003cp\u003eStep4: ÂØπÈΩêsequence\u003c/p\u003e\n\u003cp\u003e\u003cimg alt=\"image-20250322150854986\" loading=\"lazy\" src=\"./NLP-2.assets/image-20250322150854986.png\"\u003e\u003c/p\u003e\n\u003cp\u003eËß£ÂÜ≥ÊñπÊ°àÊòØËøôÊ†∑ÁöÑÔºöÂèØ‰ª•Âõ∫ÂÆöÈïøÂ∫¶‰∏∫wÔºåÂä†ÂÖ•‰∏Ä‰∏™Â∫èÂàóÈïøÂ∫¶Â§™ÈïøÔºåÂ∞±Á†çÊéâÂâçÈù¢ÁöÑËØçÔºåÂè™‰øùÁïôÊúÄÂêéw‰∏™ËØçÔºõÂ¶ÇÊûú‰∏Ä‰∏™Â∫èÂàóÂ§™Áü≠ÔºåÂ∞±ÂÅözero paddingÔºåÁî®0Â°´ÂÖÖ\u003c/p\u003e\n\u003cp\u003e\u003cimg alt=\"image-20250322151030119\" loading=\"lazy\" src=\"./NLP-2.assets/image-20250322151030119.png\"\u003e\u003c/p\u003e\n\u003cp\u003eËøôÊ†∑‰∏ÄÊù•ÔºåÊâÄÊúâÁöÑÂ∫èÂàóÈïøÂ∫¶Â∞±Áªü‰∏Ä‰∫Ü\u003c/p\u003e\n\u003cp\u003e\u003cimg alt=\"image-20250322151117125\" loading=\"lazy\" src=\"./NLP-2.assets/image-20250322151117125.png\"\u003e\u003c/p\u003e\n\u003cp\u003eÊñáÊú¨Â§ÑÁêÜÂÆåÊàê‰∫ÜÔºåÊé•‰∏ãÊù•ÊòØword embeddingÔºåÊääÂçïËØçË°®Á§∫‰∏∫‰∏Ä‰∏™‰ΩéÁª¥ÂêëÈáèÔºõ\u003c/p\u003e\n\u003cp\u003e\u003cimg alt=\"image-20250322151252837\" loading=\"lazy\" src=\"./NLP-2.assets/image-20250322151252837.png\"\u003e\u003c/p\u003e","title":""},{"content":"üëã About me Hello! I\u0026rsquo;m Xu Zongsi, a passionate technology enthusiast currently pursuing my Master of Science in ECIC at The University of Hong Kong. With a solid background in Software Engineering from the Beijing Institute of Technology, I specialize in artificial intelligence areas like machine learning, deep learning, natural language processing, computer vision, and reinforcement learning.\nInspired by OpenAI\u0026rsquo;s five-step plan towards superintelligence, I am excited about AGI and have developed a keen interest in LLM agents, MLLM, and knowledge graphs. I see great potential in these fields and aspire to contribute to innovative solutions.\nüìö Education üá≠üá∞ The University of Hong Kong 09/2024 - Expected 11/2025 School of Computing and Data Science Master of Science in Electronic Commerce \u0026amp; Internet Computing Relevant Courses: Machine learning for business and e-commerce, Knowledge graphs, Financial fraud analytics, Internet infrastructure technologies, Website engineering, Blockchain and cryptocurrency, etc. üá®üá≥ Beijing Institute of Technology 09/2020 - 06/2024 School of Computer Science \u0026amp; Technology Bachelor of Engineering in Software Engineering, last two years GPA: 3.7/4 Relevant Courses: Reinforcement Learning, Deep Learning and Computer Vision, Artificial Intelligence and Robot Ethics, Almost Human: Mind, Brain and Artificial Intelligence, Mathematical Analysis for Engineering, Linear Algebra, Probability and Mathematical Statistics, etc. Skills: Python, Java, common data structures, design patterns, machine learning basics and algorithms, Linux, PyTorch, and some development tools (git, conda, etc.). üèÜ Awards \u0026amp; Honors Beijing Institute of Technology Undergraduate Scholarship (Top 20% of Grade) 06/2023 3rd Prize of China International \u0026#34;Internet \u0026#43;\u0026#34; College Student\u0026#39;s Innovation Competition 08/2022 Bronze Prize of \u0026#34;Challenge Cup\u0026#34; Capital University Entrepreneurship Competition 05/2022 üíº Project Experience üîç Online Transaction Fraud Detection 09/2024 ‚Äì 01/2025 Independent project, supervised by Dr. Vivien Chan Focused on addressing financial fraud in e-commerce to enhance the accuracy of transaction anomaly detection, while independently managing the entire case study that included data preprocessing, feature engineering, model building, evaluation, and results analysis. Effectively resolved class imbalance issues using SMOTE and ROSE techniques. Built various models including Logistic Regression, Random Forest, XGBoost, and LightGBM, ultimately selecting the LightGBM model to achieve a recall rate of 95.45% and an AUC of 99.84%. Wrote efficient and maintainable code, enhancing model training and data processing efficiency through parallel computing and logging. ü§ñ Multi-Model Intelligent Text Keyword Extraction System 08/2023 ‚Äì 09/2023 Group project, supervised by Associate Prof. Xiaolin Zhao Designed and implemented an intelligent text summary system that automatically extracts keywords from article titles and abstracts, enhancing the understanding and summarization of text information. Participated in the planning of the technical route and built a hybrid model combining extractive and generative approaches, utilizing advanced natural language processing techniques including KeyBERT, Sentence Transformer, BERT, and T5 models. Responsible for data preprocessing and tokenization, as well as the end-to-end implementation and training of the T5 model, optimizing the model architecture and hyperparameters, achieving satisfactory results after only 3 epochs of training. Model evaluation results showed that the Rouge-1, Rouge-2, and Rouge-L metrics reached 0.6345, 0.5038, and 0.5282, respectively, in the third epoch, validating the model\u0026rsquo;s effectiveness in the summarization task. üéì Cambridge University Machine Learning Summer Project 07/2023 ‚Äì 08/2023 Group project, supervised by Prof. Pietro Li√≤ Participated in the Cambridge University deep learning summer project, focusing on deep reinforcement learning; explored multi-agent learning algorithms across different environments. Reproduced the Multi-Agent Deep Deterministic Policy Gradient (MADDPG) algorithm in the Simple Adversary environment and studied the effect of agent numbers on convergence speed and stability, finding optimal stability at 21 agents. Designed and implemented comparative experiments inspired by the Rainbow algorithm, assessing target network strategies versus the Double Deep Q-Network (Double DQN). The results demonstrated that Double DQN significantly enhanced convergence speed, optimizing the overall learning process. Co-authored a group project paper on agent numbers and strategies effectiveness in multi-agent systems, achieving a score of 71% in the summer program (the highest in my group) and a \u0026ldquo;First Class\u0026rdquo; classification in the UK grading system. üëÅÔ∏è Deep Learning and Computer Vision Semester Project 09/2022 ‚Äì 12/2022 Independent project, supervised by Associate Prof. Guangyu Gao Designed and implemented a waste classifier using the ResNet model to improve classification accuracy and reduce resource waste. The project also enhanced understanding of transfer learning techniques with ResNet. Collected a dataset of 16 waste categories and preprocessed the images for uniformity and standardization, incorporating data augmentation techniques to enhance the dataset. Conducted experiments using ResNet34 and ResNet50 models through transfer learning, accelerating network convergence by leveraging pretrained weights. During training, techniques such as Batch Normalization and Dropout were applied to mitigate the risk of overfitting. The final model achieved an accuracy of 90% on the training set, while the performance on the test set was 61%, indicating a significant overfitting phenomenon during the training process. üéì Internship ‚öõÔ∏è Beijing Academy of Quantum Information Science 08/2023 ‚Äì 01/2024 Research Intern at Quantum Computation Department Proposed a quantum convolution kernel design based on variational quantum circuits and developed a universal quantum convolution layer, successfully integrating it into classical CNN architectures such as VGG, GoogLeNet, and ResNet. Developed and evaluated various hybrid models, including a simple model named HQCCNN-2, which achieved 84.45% accuracy on the FashionMNIST dataset, surpassing the traditional CNN\u0026rsquo;s 80.72%. This demonstrates the effectiveness of the quantum convolution layer in improving model performance. Tested on a real quantum computer further validated the effectiveness of the hybrid model, demonstrating the viable integration of quantum computing with deep learning, and highlighting the potential for leveraging quantum properties to enhance model performance. üèÖ Competition Experience ü•â China International \u0026#34;Internet \u0026#43;\u0026#34; College Students\u0026#39; Innovation Competition 08/2022 üõ°Ô∏è Zhongke Ushield: Deep Learning-based Face Privacy Protection Authentication System Responsible for constructing a localized facial feature extraction engine based on MobileFaceNet, ensuring feature extraction is completed on end devices (such as mobile phones and cameras), guaranteeing that raw data does not leave the domain and is not stored, thus enhancing user privacy protection while improving recognition efficiency. ü•â \u0026#34;Challenge Cup\u0026#34; Capital University Entrepreneurship Competition 05/2022 üå≥ Smart Orchard Responsible for the development of the fruit detection, ripeness prediction, and pest identification system, using deep convolutional neural network (CNN) technology for intelligent monitoring of crop growth conditions. Applied advanced object detection algorithms such as Faster R-CNN and YOLO to achieve high precision in apple detection and ripeness assessment, with an accuracy rate exceeding 90%, significantly enhancing the intelligence level of orchard management. Built and trained a dedicated dataset containing various pest samples, optimizing pest detection accuracy through data preprocessing (such as image normalization and resizing) and data augmentation techniques (like rotation, flipping, and noise addition), enabling the real-time monitoring system to accurately identify over 80% of pests, providing effective scientific maintenance recommendations to help farmers reduce crop losses. üìã Extracurricular Activities Vice President, Cyber Security Club, Beijing Institute of Technology 09/2021-09/2022 Backbone, Media Center of the Student Union of Beijing Institute of Technology 10/2020-06/2021 üì´ Contact üìß Email: zongsi.xu@outlook.com üëî LinkedIn: Zongsi (Tristan) Xu üíª GitHub: BaizeXS üìç Location: Hong Kong SAR, China ","permalink":"http://localhost:1313/resume/","summary":"Personal resume of Zongsi (Tristan) Xu","title":"Zongsi (Tristan) Xu"},{"content":"‰∏Ä„ÄÅÊï∞ÂÄºÁâπÂæÅ‰∏éÁ±ªÂà´ÁâπÂæÅ Êï∞ÂÄºÁâπÂæÅ (Numeric Features) ÂÖ∑ÊúâÂèØÂä†ÂáèÁöÑÊÑè‰πâÔºå‰∏îÂ≠òÂú®Â§ßÂ∞èÈ°∫Â∫è„ÄÇ ‰æãÂ≠êÔºöÂπ¥ÈæÑ„ÄÅÊ∏©Â∫¶Á≠â„ÄÇÂèØ‰ª•Áõ¥Êé•‰øùÁïôÂÖ∂Êï¥Êï∞ÊàñÊµÆÁÇπÊï∞ÂΩ¢Âºè‰æõÊ®°Âûã‰ΩøÁî®„ÄÇ Á±ªÂà´ÁâπÂæÅ (Categorical Features) Êï∞ÊçÆÂÄºÁ¶ªÊï£Ôºå‰∏çÂÖ∑Â§á‚ÄúÊï∞ÂÄºÂ§ßÂ∞è‚ÄùÈó¥ÁöÑÂèØÊØîÊÑè‰πâ„ÄÇ ‰æãÂ≠êÔºöÂõΩÁ±çÔºàÁæéÂõΩ/‰∏≠ÂõΩ/Âç∞Â∫¶Á≠âÔºâ„ÄÅÊÄßÂà´ÔºàÁî∑/Â•≥ÔºâÁ≠â„ÄÇ ÈóÆÈ¢òÔºöËã•‰ªÖÁî®Êï¥Êï∞Ë°®Á§∫ÔºàÁæéÂõΩ=1, ‰∏≠ÂõΩ=2ÔºâÔºå‰ºöÂºïÂÖ•ÈîôËØØÁöÑÊï∞ÂÄºËøêÁÆóÂÖ≥Á≥ªÔºåÂ¶Ç ‚ÄúÁæéÂõΩ + ‰∏≠ÂõΩ = Âç∞Â∫¶‚Äù„ÄÇ ‰∫å„ÄÅOne-HotÁºñÁ†ÅÁöÑÂä®Êú∫‰∏éÊµÅÁ®ã ‰∏∫‰ªÄ‰πà‰ΩøÁî®One-Hot\nÈÄöËøáÂ∞ÜÁ±ªÂà´Êò†Â∞Ñ‰∏∫ÂêëÈáèÔºåÈÅøÂÖçÊï¥Êï∞ÁºñÁ†ÅÂºïÂÖ•ÁöÑ‰º™Êï∞ÂÄºÂÖ≥Á≥ª„ÄÇ ÂêåÊó∂‰øùÁïôÂêÑÁßçÂèØËÉΩÁ±ªÂà´ÁöÑ‰ø°ÊÅØÔºå‰∏î‰ªÖÂú®ÂØπÂ∫î‰ΩçÁΩÆ‰∏∫1ÔºåÂÖ∂‰ªñ‰ΩçÁΩÆ‰∏∫0„ÄÇ Âª∫Á´ãÊò†Â∞ÑÔºö‰ªéÁ±ªÂà´Âà∞Á¥¢Âºï\n‰∏∫ÊØè‰∏™Á±ªÂà´ÂàÜÈÖç‰∏Ä‰∏™ÂîØ‰∏ÄÁ¥¢ÂºïÔºåÈÄöÂ∏∏‰ªé1ÂºÄÂßã„ÄÇ È¢ÑÁïôÁ¥¢Âºï0Ë°®Á§∫‚ÄúÊú™Áü•‚ÄùÊàñ‚ÄúÁº∫Â§±‚ÄùÔºåÂØπÂ∫îÂÖ®0ÂêëÈáè„ÄÇ ËΩ¨Êç¢‰∏∫One-HotÂêëÈáè\nËã•Á±ªÂà´ÊÄªÊï∞‰∏∫197ÔºåÂàôÁî®197Áª¥ÂêëÈáèË°®Á§∫„ÄÇ ‰æãÂ≠êÔºöÁæéÂõΩ [1, 0, 0, 0, ‚Ä¶]Ôºå ‰∏≠ÂõΩ [0, 1, 0, 0, ‚Ä¶]„ÄÇ Á§∫‰æãÔºöË°®Á§∫‰∏Ä‰∏™‰∫∫ÁöÑÁâπÂæÅ\nÁâπÂæÅÂåÖÂê´ÔºàÂπ¥ÈæÑ, ÊÄßÂà´, ÂõΩÁ±çÔºåÂÖ∂‰∏≠ÂõΩÁ±ç197ÁßçÔºâ Áª¥Â∫¶ÊÄªÂíåÔºö1Áª¥_age + 1Áª¥_gender + 197Áª¥_nationality = 199Áª¥„ÄÇ ‰æãÂ¶Ç (28, Â•≥, ‰∏≠ÂõΩ) ‚Üí [28, 0, 0, 1, 0, ‚Ä¶, 0]„ÄÇ ‰∏â„ÄÅÊñáÊú¨Êï∞ÊçÆÂ§ÑÁêÜÊµÅÁ®ã ÊñáÊú¨Âú®Ëá™ÁÑ∂ËØ≠Ë®ÄÂ§ÑÁêÜÔºàNLPÔºâ‰∏≠‰Ωú‰∏∫Â∏∏ËßÅÁöÑÂéüÂßãËæìÂÖ•ÔºåÈúÄË¶ÅÊï∞ÂÄºÂåñÊâçËÉΩÈÄÅÂÖ•Ê®°Âûã„ÄÇ‰∏ÄËà¨Ê≠•È™§Â¶Ç‰∏ãÔºö\nÂàÜËØç (Tokenization)\nÂ∞ÜÊñáÊú¨ÊãÜÂàÜ‰∏∫‰∏Ä‰∏™‰∏™ÂçïËØçÔºàTokenÔºâ„ÄÇ ‰æãÂ≠êÔºö\u0026quot;... to be or not to be...\u0026quot; ‚Üí [\u0026quot;...\u0026quot;, \u0026quot;to\u0026quot;, \u0026quot;be\u0026quot;, \u0026quot;or\u0026quot;, \u0026quot;not\u0026quot;, \u0026quot;to\u0026quot;, \u0026quot;be\u0026quot;, \u0026quot;...\u0026quot;]„ÄÇ ÁªüËÆ°ËØçÈ¢ë \u0026amp; ÊûÑÂª∫ËØçÂÖ∏\nËØçÈ¢ëÁªüËÆ° Áî®ÂìàÂ∏åË°®/Â≠óÂÖ∏ËÆ∞ÂΩïÊØè‰∏™ÂçïËØçÂá∫Áé∞Ê¨°Êï∞„ÄÇ ÈÅçÂéÜÊñáÊú¨Êó∂ÔºåËã•ÂçïËØçÂ∞öÊú™ÂÖ•Ë°®ÔºåÂàôÊñ∞Âª∫ËÆ∞ÂΩïÔºõËã•Â∑≤Â≠òÂú®ÔºåÂàôËÆ°Êï∞+1„ÄÇ ÊéíÂ∫è‰∏éÁ¥¢Âºï ÊåâËØçÈ¢ëÈôçÂ∫èÊéíÂ∫èÔºåËØçÈ¢ëÊúÄÈ´òÁöÑÂçïËØçÊéíÂú®ÂâçÈù¢„ÄÇ Á¥¢Âºï‰ªé1ÂºÄÂßãÔºå0ÁïôÁªô‚ÄúÊú™Áü•‚Äù„ÄÇ ËØçÂÖ∏ËßÑÊ®°ÔºàvocabularyÔºâÂèØËßÜÈúÄÊ±ÇÊà™Êñ≠Ôºà‰æãÂ¶ÇÂè™‰øùÁïôTop 10kÔºâ„ÄÇ ‰∏∫‰ªÄ‰πàÁßªÈô§‰ΩéÈ¢ëËØç ‰ΩéÈ¢ëËØçÂèØËÉΩÊòØÊãºÂÜôÈîôËØØ„ÄÅÁΩïËßÅ‰∫∫ÂêçÁ≠âÔºåÂØπÊ®°ÂûãÂ∏ÆÂä©ÊúâÈôê„ÄÇ ÂáèÂ∞ëËØçÂÖ∏ËßÑÊ®°ÂèØÈôç‰ΩéËøêÁÆóÂºÄÈîÄ„ÄÅÂä†Âø´Ê®°ÂûãËÆ≠ÁªÉ‰∏éÊé®ÁêÜÈÄüÂ∫¶„ÄÇ Áã¨ÁÉ≠ÁºñÁ†Å (One-Hot Encoding)\nÂ∞ÜÊØè‰∏™ÂçïËØçÊò†Â∞Ñ‰∏∫ËØçÂÖ∏‰∏≠ÁöÑÁ¥¢ÂºïÂêéÔºàÂ¶Ç [2, 4, 1, 8, ‚Ä¶]ÔºâÔºåÂèØËøõ‰∏ÄÊ≠•ËΩ¨Êç¢ÊàêOne-HotÂêëÈáè„ÄÇ One-HotÁª¥Â∫¶ÂèñÂÜ≥‰∫é‰øùÁïô‰∏ãÊù•ÁöÑËØçÂÖ∏Â§ßÂ∞èÔºà‰æãÂ¶Ç1‰∏áÔºâ„ÄÇ Êú™Êî∂ÂΩïÂçïËØçÂèØËÉΩÁõ¥Êé•ÂøΩÁï•ÔºåÊàñÁªü‰∏ÄÁî®Á¥¢Âºï0‰ª£Êõø„ÄÇ Âõõ„ÄÅÊ†∏ÂøÉÊî∂Ëé∑‰∏éÂ∫îÁî® Á±ªÂà´ÁâπÂæÅÂøÖÈúÄÊï∞ÂÄºÂåñÔºö\n‰ΩøÁî®Êï¥Êï∞1,2,3‚Ä¶‰ªÖË°®Á§∫Á±ªÂà´‚ÄúÊ†áËØÜ‚ÄùÔºåÂπ∂‰∏ç‰ª£Ë°®ÂÆÉ‰ª¨ÂèØËøõË°åÊï∞ÂÄºËøêÁÆó„ÄÇ Âõ†Ê≠§ÈúÄË¶ÅOne-HotÁ≠âÁºñÁ†ÅÊñπÂºèÔºåÈÅøÂÖçÊï∞ÂÄºËØØËß£„ÄÇ ÊñáÊú¨Êï∞ÊçÆÈ¢ÑÂ§ÑÁêÜÔºö\nÂàÜËØç„ÄÅËØçÈ¢ëÁªüËÆ°„ÄÅÊûÑÂª∫ËØçÂÖ∏„ÄÅÁ¥¢ÂºïÂåñ„ÄÅOne-HotÊàñÂÖ∂‰ªñÊñπÂºèÔºàÂ¶ÇËØçÂµåÂÖ•ÔºâÊòØÂ∏∏ËßÅÊµÅÁ®ã„ÄÇ Ê≠£Á°ÆÁöÑÊñáÊú¨È¢ÑÂ§ÑÁêÜÂèØÊòæËëóÂΩ±ÂìçÊ®°ÂûãÊÄßËÉΩÂíåÊïàÁéá„ÄÇ ‰øùÁïôÊú™Áü•Á¥¢ÂºïÔºö\n‰øùËØÅÂØπÁº∫Â§±Êï∞ÊçÆÊàñÂ≠óÂÖ∏Â§ñÊñ∞ËØçËÉΩÊúâÂü∫Êú¨ÁöÑË°®Á§∫ÔºåÊèêÂçáÊ®°ÂûãÂÆπÈîôÊÄß„ÄÇ ÂÆûÈôÖ‰ΩøÁî®Ôºö\nÂØπ‰∫éÂ∞èËßÑÊ®°Á±ªÂà´ÂèØÁõ¥Êé•One-HotÁºñÁ†ÅÔºõÂØπ‰∫éËØçÂÖ∏ÂæàÂ§ßÁöÑÂú∫ÊôØÔºåÈÄöÂ∏∏‰ºöËøõ‰∏ÄÊ≠•ËÄÉËôëËØçÂµåÂÖ•ÔºàWord EmbeddingÔºâÊàñÈ¢ÑËÆ≠ÁªÉËØ≠Ë®ÄÊ®°Âûã„ÄÇ ","permalink":"http://localhost:1313/posts/nlp-1/","summary":"\u003ch2 id=\"‰∏ÄÊï∞ÂÄºÁâπÂæÅ‰∏éÁ±ªÂà´ÁâπÂæÅ\"\u003e‰∏Ä„ÄÅÊï∞ÂÄºÁâπÂæÅ‰∏éÁ±ªÂà´ÁâπÂæÅ\u003c/h2\u003e\n\u003col\u003e\n\u003cli\u003e\u003cstrong\u003eÊï∞ÂÄºÁâπÂæÅ (Numeric Features)\u003c/strong\u003e\n\u003cul\u003e\n\u003cli\u003eÂÖ∑ÊúâÂèØÂä†ÂáèÁöÑÊÑè‰πâÔºå‰∏îÂ≠òÂú®Â§ßÂ∞èÈ°∫Â∫è„ÄÇ\u003c/li\u003e\n\u003cli\u003e‰æãÂ≠êÔºöÂπ¥ÈæÑ„ÄÅÊ∏©Â∫¶Á≠â„ÄÇÂèØ‰ª•Áõ¥Êé•‰øùÁïôÂÖ∂Êï¥Êï∞ÊàñÊµÆÁÇπÊï∞ÂΩ¢Âºè‰æõÊ®°Âûã‰ΩøÁî®„ÄÇ\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003eÁ±ªÂà´ÁâπÂæÅ (Categorical Features)\u003c/strong\u003e\n\u003cul\u003e\n\u003cli\u003eÊï∞ÊçÆÂÄºÁ¶ªÊï£Ôºå‰∏çÂÖ∑Â§á‚ÄúÊï∞ÂÄºÂ§ßÂ∞è‚ÄùÈó¥ÁöÑÂèØÊØîÊÑè‰πâ„ÄÇ\u003c/li\u003e\n\u003cli\u003e‰æãÂ≠êÔºöÂõΩÁ±çÔºàÁæéÂõΩ/‰∏≠ÂõΩ/Âç∞Â∫¶Á≠âÔºâ„ÄÅÊÄßÂà´ÔºàÁî∑/Â•≥ÔºâÁ≠â„ÄÇ\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003eÈóÆÈ¢ò\u003c/strong\u003eÔºöËã•‰ªÖÁî®Êï¥Êï∞Ë°®Á§∫ÔºàÁæéÂõΩ=1, ‰∏≠ÂõΩ=2ÔºâÔºå‰ºöÂºïÂÖ•ÈîôËØØÁöÑÊï∞ÂÄºËøêÁÆóÂÖ≥Á≥ªÔºåÂ¶Ç ‚ÄúÁæéÂõΩ + ‰∏≠ÂõΩ = Âç∞Â∫¶‚Äù„ÄÇ\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003c/ol\u003e\n\u003ch2 id=\"‰∫åone-hotÁºñÁ†ÅÁöÑÂä®Êú∫‰∏éÊµÅÁ®ã\"\u003e‰∫å„ÄÅOne-HotÁºñÁ†ÅÁöÑÂä®Êú∫‰∏éÊµÅÁ®ã\u003c/h2\u003e\n\u003col\u003e\n\u003cli\u003e\n\u003cp\u003e\u003cstrong\u003e‰∏∫‰ªÄ‰πà‰ΩøÁî®One-Hot\u003c/strong\u003e\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eÈÄöËøáÂ∞ÜÁ±ªÂà´Êò†Â∞Ñ‰∏∫ÂêëÈáèÔºåÈÅøÂÖçÊï¥Êï∞ÁºñÁ†ÅÂºïÂÖ•ÁöÑ‰º™Êï∞ÂÄºÂÖ≥Á≥ª„ÄÇ\u003c/li\u003e\n\u003cli\u003eÂêåÊó∂‰øùÁïôÂêÑÁßçÂèØËÉΩÁ±ªÂà´ÁöÑ‰ø°ÊÅØÔºå‰∏î‰ªÖÂú®ÂØπÂ∫î‰ΩçÁΩÆ‰∏∫1ÔºåÂÖ∂‰ªñ‰ΩçÁΩÆ‰∏∫0„ÄÇ\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003e\u003cstrong\u003eÂª∫Á´ãÊò†Â∞ÑÔºö‰ªéÁ±ªÂà´Âà∞Á¥¢Âºï\u003c/strong\u003e\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e‰∏∫ÊØè‰∏™Á±ªÂà´ÂàÜÈÖç‰∏Ä‰∏™ÂîØ‰∏ÄÁ¥¢ÂºïÔºåÈÄöÂ∏∏‰ªé1ÂºÄÂßã„ÄÇ\u003c/li\u003e\n\u003cli\u003eÈ¢ÑÁïôÁ¥¢Âºï0Ë°®Á§∫‚ÄúÊú™Áü•‚ÄùÊàñ‚ÄúÁº∫Â§±‚ÄùÔºåÂØπÂ∫îÂÖ®0ÂêëÈáè„ÄÇ\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003e\u003cstrong\u003eËΩ¨Êç¢‰∏∫One-HotÂêëÈáè\u003c/strong\u003e\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eËã•Á±ªÂà´ÊÄªÊï∞‰∏∫197ÔºåÂàôÁî®197Áª¥ÂêëÈáèË°®Á§∫„ÄÇ\u003c/li\u003e\n\u003cli\u003e‰æãÂ≠êÔºöÁæéÂõΩ \u003ccode\u003e[1, 0, 0, 0, ‚Ä¶]\u003c/code\u003eÔºå ‰∏≠ÂõΩ \u003ccode\u003e[0, 1, 0, 0, ‚Ä¶]\u003c/code\u003e„ÄÇ\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003e\u003cstrong\u003eÁ§∫‰æãÔºöË°®Á§∫‰∏Ä‰∏™‰∫∫ÁöÑÁâπÂæÅ\u003c/strong\u003e\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eÁâπÂæÅÂåÖÂê´ÔºàÂπ¥ÈæÑ, ÊÄßÂà´, ÂõΩÁ±çÔºåÂÖ∂‰∏≠ÂõΩÁ±ç197ÁßçÔºâ\u003c/li\u003e\n\u003cli\u003eÁª¥Â∫¶ÊÄªÂíåÔºö1Áª¥_age + 1Áª¥_gender + 197Áª¥_nationality = 199Áª¥„ÄÇ\u003c/li\u003e\n\u003cli\u003e‰æãÂ¶Ç \u003ccode\u003e(28, Â•≥, ‰∏≠ÂõΩ)\u003c/code\u003e ‚Üí \u003ccode\u003e[28, 0, 0, 1, 0, ‚Ä¶, 0]\u003c/code\u003e„ÄÇ\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003c/ol\u003e\n\u003ch2 id=\"‰∏âÊñáÊú¨Êï∞ÊçÆÂ§ÑÁêÜÊµÅÁ®ã\"\u003e‰∏â„ÄÅÊñáÊú¨Êï∞ÊçÆÂ§ÑÁêÜÊµÅÁ®ã\u003c/h2\u003e\n\u003cp\u003eÊñáÊú¨Âú®Ëá™ÁÑ∂ËØ≠Ë®ÄÂ§ÑÁêÜÔºàNLPÔºâ‰∏≠‰Ωú‰∏∫Â∏∏ËßÅÁöÑÂéüÂßãËæìÂÖ•ÔºåÈúÄË¶ÅÊï∞ÂÄºÂåñÊâçËÉΩÈÄÅÂÖ•Ê®°Âûã„ÄÇ‰∏ÄËà¨Ê≠•È™§Â¶Ç‰∏ãÔºö\u003c/p\u003e\n\u003col\u003e\n\u003cli\u003e\n\u003cp\u003e\u003cstrong\u003eÂàÜËØç (Tokenization)\u003c/strong\u003e\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eÂ∞ÜÊñáÊú¨ÊãÜÂàÜ‰∏∫‰∏Ä‰∏™‰∏™ÂçïËØçÔºàTokenÔºâ„ÄÇ\u003c/li\u003e\n\u003cli\u003e‰æãÂ≠êÔºö\u003ccode\u003e\u0026quot;... to be or not to be...\u0026quot;\u003c/code\u003e ‚Üí \u003ccode\u003e[\u0026quot;...\u0026quot;, \u0026quot;to\u0026quot;, \u0026quot;be\u0026quot;, \u0026quot;or\u0026quot;, \u0026quot;not\u0026quot;, \u0026quot;to\u0026quot;, \u0026quot;be\u0026quot;, \u0026quot;...\u0026quot;]\u003c/code\u003e„ÄÇ\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003e\u003cstrong\u003eÁªüËÆ°ËØçÈ¢ë \u0026amp; ÊûÑÂª∫ËØçÂÖ∏\u003c/strong\u003e\u003c/p\u003e","title":""},{"content":"Text to Sequence ÊñáÊú¨Â§ÑÁêÜ\nStep1: Tokenization\nTokenization breaks a piece of text down into a list of tokens.\nHere, a token is a word. (A token can be a character in some applications.)\nTokenizationËÆ≤Á©∂ÂæàÂ§öÔºå‰æãÂ¶ÇÊòØÂê¶Â∫îËØ•ÊääÂ§ßÂÜôÊîπÊàêÂ∞èÂÜôÂë¢ÔºüËøõË°åtypo correctionÁ≠âÁ≠â\nStep2: Build Dictionary\nUse a dictionary (hash table) to count word frequencies.\nThe dictionary maps word to index.\nÂèØ‰ª•È¶ñÂÖàÁªüËÆ°ËØçÈ¢ëÂéªÊéâ‰ΩéÈ¢ëËØçÔºåÁÑ∂ÂêéËÆ©ÊØè‰∏™ËØçÂØπÂ∫î‰∏Ä‰∏™Ê≠£Êï¥Êï∞ÔºõËøôÊ†∑ÁöÑËØùÔºå‰∏ÄÂè•ËØùÂ∞±ÂèØ‰ª•Áî®‰∏Ä‰∏™Ê≠£Êï¥Êï∞ÂàóË°®Ë°®Á§∫ÔºåËøô‰∏™ÂàóË°®Â∞±Âè´sequenceÔºõÂ¶ÇÊûúÂøÖË¶ÅÂ∞±ËøòÂæóÂÅöone-hot encoding„ÄÇ\nÁªìÊûú\n‰ΩÜÊòØÈïøÂ∫¶‰∏çÁªü‰∏Ä\nStep4: ÂØπÈΩêsequence\nËß£ÂÜ≥ÊñπÊ°àÊòØËøôÊ†∑ÁöÑÔºöÂèØ‰ª•Âõ∫ÂÆöÈïøÂ∫¶‰∏∫wÔºåÂä†ÂÖ•‰∏Ä‰∏™Â∫èÂàóÈïøÂ∫¶Â§™ÈïøÔºåÂ∞±Á†çÊéâÂâçÈù¢ÁöÑËØçÔºåÂè™‰øùÁïôÊúÄÂêéw‰∏™ËØçÔºõÂ¶ÇÊûú‰∏Ä‰∏™Â∫èÂàóÂ§™Áü≠ÔºåÂ∞±ÂÅözero paddingÔºåÁî®0Â°´ÂÖÖ\nËøôÊ†∑‰∏ÄÊù•ÔºåÊâÄÊúâÁöÑÂ∫èÂàóÈïøÂ∫¶Â∞±Áªü‰∏Ä‰∫Ü\nÊñáÊú¨Â§ÑÁêÜÂÆåÊàê‰∫ÜÔºåÊé•‰∏ãÊù•ÊòØword embeddingÔºåÊääÂçïËØçË°®Á§∫‰∏∫‰∏Ä‰∏™‰ΩéÁª¥ÂêëÈáèÔºõ\nÁÑ∂ËÄåËøôÊ†∑ÂÅöÁöÑËØùÔºåÂ¶ÇÊûúÊòØ10000‰∏™ÂçïËØçÔºåÁª¥Â∫¶Â∞±ÊòØ10000Áª¥ÔºåÁª¥Â∫¶Â§™È´ò‰∫ÜÔºõÂõ†Ê≠§Ë¶ÅÂÅöword embeddingÔºõ\nÂÖ∑‰ΩìÂÅöÊ≥ïÂ∞±ÊòØÊääone-hotÂêëÈáèe_iÂíåÂèÇÊï∞Áü©ÈòµpÁõ∏‰πòÔºõÁü©ÈòµPËΩ¨ÁΩÆÁöÑÂ§ßÂ∞èÊòØd x vÔºõdÊòØËØçÂêëÈáèÁöÑÁª¥Â∫¶ÔºõvÊòØÂ≠óÂÖ∏ÈáåËØçÊ±áÁöÑÊï∞ÈáèÔºõÁªìÊûú‰∏∫x_iÔºõx_iÂ∞±ÊòØ‰∏Ä‰∏™ËØçÂêëÈáèÔºõÂ¶ÇÊûúone-hotÂêëÈáèÁöÑÁ¨¨‰∏âË°å‰∏∫1ÔºõÈÇ£‰πàx_iÂ∞±ÊòØPËΩ¨ÁΩÆÁü©ÈòµÁöÑÁ¨¨‰∏âÂàóÔºàÂÖ∂‰ΩôÂàóÈÉΩ‰∏∫0ÔºâÔºõÊâÄ‰ª•PËΩ¨ÁΩÆÊØè‰∏ÄÂàóÈÉΩÊòØ‰∏Ä‰∏™ËØçÂêëÈáèÔºõÊâÄ‰ª•Áü©ÈòµPÊú¨Ë∫´ÁöÑÊØè‰∏ÄË°åÂ∞±ÊòØ‰∏Ä‰∏™ËØçÂêëÈáèÔºõÂÖ∂Ë°åÊï∞‰∏∫vÔºõÂç≥vocabularyÔºåËØçÊ±áÈáèÔºõÊØè‰∏ÄË°åÂØπÂ∫î‰∏Ä‰∏™ÂçïËØçÔºõÁü©ÈòµÁöÑÂàóÊï∞‰∏∫dÔºõdÊòØÁî®Êà∑ÂÜ≥ÂÆöÁöÑÔºõdÁöÑÂ§ßÂ∞è‰ºöÂÜ≥ÂÆöÊú∫Âô®Â≠¶‰π†Ê®°ÂûãÁöÑË°®Áé∞ÔºõÂ∫îËØ•Áî®xxxÊù•ÈÄâÊã©‰∏Ä‰∏™ÊØîËæÉÂ•ΩÁöÑdÔºõ\nÊàë‰ª¨ÁöÑ‰ªªÂä°ÊòØÁúãËØÑËÆ∫ÊòØÊ≠£Èù¢ÁöÑËøòÊòØË¥üÈù¢ÁöÑÔºõÂèÇÊï∞Áü©ÈòµÊòØ‰ªéËÆ≠ÁªÉÊï∞ÊçÆ‰∏≠Â≠¶‰π†Âá∫Êù•ÁöÑÔºåÊâÄ‰ª•Â≠¶Âá∫Êù•ÁöÑËØçÂêëÈáèÊòØÂ∏¶ÊúâÊÑüÊÉÖËâ≤ÂΩ©ÁöÑÔºõÂÅáËÆæËøô‰∫õËØçÂêëÈáèÈÉΩÊòØ‰∫åÁª¥ÁöÑÔºåÂàôÂèØ‰ª•Âú®Âπ≥Èù¢ÂùêÊ†áÁ≥ª‰∏≠Ê†áÂá∫‰∏ãÈù¢ËØçÂêëÈáè\nkerasÊèê‰æõembeddingÂ±ÇÔºõÁî®Êà∑ÂèØ‰ª•ÊåáÂÆövocabularyÂ§ßÂ∞èÂíådÁöÑÂ§ßÂ∞èÔºõ‰ª•ÂèäÊØè‰∏Ä‰∏™sequenceÁöÑÈïøÂ∫¶ÔºõdÊòØÊ†πÊçÆÁÆóÊ≥ïÈÄâÂá∫Êù•ÁöÑ Âà∞Ëøô‰∏ÄÊ≠•ÔºåÊàë‰ª¨Â∑≤ÁªèÂÆåÊàê‰∫ÜÊñáÊú¨Â§ÑÁêÜÂíåword embedding„ÄÇÊé•‰∏ãÊù•Â∞±ÊòØÁî®Logistic Regression for Binary ClassificationÂÅö‰∫åÂàÜÁ±ªÔºõ\n","permalink":"http://localhost:1313/posts/nlp-2/","summary":"\u003ch3 id=\"text-to-sequence\"\u003eText to Sequence\u003c/h3\u003e\n\u003cp\u003eÊñáÊú¨Â§ÑÁêÜ\u003c/p\u003e\n\u003cp\u003eStep1: Tokenization\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\n\u003cp\u003eTokenization breaks a piece of text down into a list of tokens.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003eHere, a token is a word. (A token can be a character in some applications.)\u003c/p\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003eTokenizationËÆ≤Á©∂ÂæàÂ§öÔºå‰æãÂ¶ÇÊòØÂê¶Â∫îËØ•ÊääÂ§ßÂÜôÊîπÊàêÂ∞èÂÜôÂë¢ÔºüËøõË°åtypo correctionÁ≠âÁ≠â\u003c/p\u003e\n\u003cp\u003e\u003cimg alt=\"image-20250322150322238\" loading=\"lazy\" src=\"./NLP-2.assets/image-20250322150322238.png\"\u003e\u003c/p\u003e\n\u003cp\u003eStep2: Build Dictionary\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\n\u003cp\u003eUse a dictionary (hash table) to count word frequencies.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003eThe dictionary maps word to index.\u003c/p\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003eÂèØ‰ª•È¶ñÂÖàÁªüËÆ°ËØçÈ¢ëÂéªÊéâ‰ΩéÈ¢ëËØçÔºåÁÑ∂ÂêéËÆ©ÊØè‰∏™ËØçÂØπÂ∫î‰∏Ä‰∏™Ê≠£Êï¥Êï∞ÔºõËøôÊ†∑ÁöÑËØùÔºå‰∏ÄÂè•ËØùÂ∞±ÂèØ‰ª•Áî®‰∏Ä‰∏™Ê≠£Êï¥Êï∞ÂàóË°®Ë°®Á§∫ÔºåËøô‰∏™ÂàóË°®Â∞±Âè´sequenceÔºõÂ¶ÇÊûúÂøÖË¶ÅÂ∞±ËøòÂæóÂÅöone-hot encoding„ÄÇ\u003cimg alt=\"image-20250322150620890\" loading=\"lazy\" src=\"./NLP-2.assets/image-20250322150620890.png\"\u003e\u003c/p\u003e\n\u003cp\u003eÁªìÊûú\u003c/p\u003e\n\u003cp\u003e\u003cimg alt=\"image-20250322150754528\" loading=\"lazy\" src=\"./NLP-2.assets/image-20250322150754528.png\"\u003e\u003c/p\u003e\n\u003cp\u003e‰ΩÜÊòØÈïøÂ∫¶‰∏çÁªü‰∏Ä\u003c/p\u003e\n\u003cp\u003eStep4: ÂØπÈΩêsequence\u003c/p\u003e\n\u003cp\u003e\u003cimg alt=\"image-20250322150854986\" loading=\"lazy\" src=\"./NLP-2.assets/image-20250322150854986.png\"\u003e\u003c/p\u003e\n\u003cp\u003eËß£ÂÜ≥ÊñπÊ°àÊòØËøôÊ†∑ÁöÑÔºöÂèØ‰ª•Âõ∫ÂÆöÈïøÂ∫¶‰∏∫wÔºåÂä†ÂÖ•‰∏Ä‰∏™Â∫èÂàóÈïøÂ∫¶Â§™ÈïøÔºåÂ∞±Á†çÊéâÂâçÈù¢ÁöÑËØçÔºåÂè™‰øùÁïôÊúÄÂêéw‰∏™ËØçÔºõÂ¶ÇÊûú‰∏Ä‰∏™Â∫èÂàóÂ§™Áü≠ÔºåÂ∞±ÂÅözero paddingÔºåÁî®0Â°´ÂÖÖ\u003c/p\u003e\n\u003cp\u003e\u003cimg alt=\"image-20250322151030119\" loading=\"lazy\" src=\"./NLP-2.assets/image-20250322151030119.png\"\u003e\u003c/p\u003e\n\u003cp\u003eËøôÊ†∑‰∏ÄÊù•ÔºåÊâÄÊúâÁöÑÂ∫èÂàóÈïøÂ∫¶Â∞±Áªü‰∏Ä‰∫Ü\u003c/p\u003e\n\u003cp\u003e\u003cimg alt=\"image-20250322151117125\" loading=\"lazy\" src=\"./NLP-2.assets/image-20250322151117125.png\"\u003e\u003c/p\u003e\n\u003cp\u003eÊñáÊú¨Â§ÑÁêÜÂÆåÊàê‰∫ÜÔºåÊé•‰∏ãÊù•ÊòØword embeddingÔºåÊääÂçïËØçË°®Á§∫‰∏∫‰∏Ä‰∏™‰ΩéÁª¥ÂêëÈáèÔºõ\u003c/p\u003e\n\u003cp\u003e\u003cimg alt=\"image-20250322151252837\" loading=\"lazy\" src=\"./NLP-2.assets/image-20250322151252837.png\"\u003e\u003c/p\u003e","title":""},{"content":"üëã About me Hello! I\u0026rsquo;m Xu Zongsi, a passionate technology enthusiast currently pursuing my Master of Science in ECIC at The University of Hong Kong. With a solid background in Software Engineering from the Beijing Institute of Technology, I specialize in artificial intelligence areas like machine learning, deep learning, natural language processing, computer vision, and reinforcement learning.\nInspired by OpenAI\u0026rsquo;s five-step plan towards superintelligence, I am excited about AGI and have developed a keen interest in LLM agents, MLLM, and knowledge graphs. I see great potential in these fields and aspire to contribute to innovative solutions.\nüìö Education üá≠üá∞ The University of Hong Kong 09/2024 - Expected 11/2025 School of Computing and Data Science Master of Science in Electronic Commerce \u0026amp; Internet Computing Relevant Courses: Machine learning for business and e-commerce, Knowledge graphs, Financial fraud analytics, Internet infrastructure technologies, Website engineering, Blockchain and cryptocurrency, etc. üá®üá≥ Beijing Institute of Technology 09/2020 - 06/2024 School of Computer Science \u0026amp; Technology Bachelor of Engineering in Software Engineering, last two years GPA: 3.7/4 Relevant Courses: Reinforcement Learning, Deep Learning and Computer Vision, Artificial Intelligence and Robot Ethics, Almost Human: Mind, Brain and Artificial Intelligence, Mathematical Analysis for Engineering, Linear Algebra, Probability and Mathematical Statistics, etc. Skills: Python, Java, common data structures, design patterns, machine learning basics and algorithms, Linux, PyTorch, and some development tools (git, conda, etc.). üèÜ Awards \u0026amp; Honors Beijing Institute of Technology Undergraduate Scholarship (Top 20% of Grade) 06/2023 3rd Prize of China International \u0026#34;Internet \u0026#43;\u0026#34; College Student\u0026#39;s Innovation Competition 08/2022 Bronze Prize of \u0026#34;Challenge Cup\u0026#34; Capital University Entrepreneurship Competition 05/2022 üíº Project Experience üîç Online Transaction Fraud Detection 09/2024 ‚Äì 01/2025 Independent project, supervised by Dr. Vivien Chan Focused on addressing financial fraud in e-commerce to enhance the accuracy of transaction anomaly detection, while independently managing the entire case study that included data preprocessing, feature engineering, model building, evaluation, and results analysis. Effectively resolved class imbalance issues using SMOTE and ROSE techniques. Built various models including Logistic Regression, Random Forest, XGBoost, and LightGBM, ultimately selecting the LightGBM model to achieve a recall rate of 95.45% and an AUC of 99.84%. Wrote efficient and maintainable code, enhancing model training and data processing efficiency through parallel computing and logging. ü§ñ Multi-Model Intelligent Text Keyword Extraction System 08/2023 ‚Äì 09/2023 Group project, supervised by Associate Prof. Xiaolin Zhao Designed and implemented an intelligent text summary system that automatically extracts keywords from article titles and abstracts, enhancing the understanding and summarization of text information. Participated in the planning of the technical route and built a hybrid model combining extractive and generative approaches, utilizing advanced natural language processing techniques including KeyBERT, Sentence Transformer, BERT, and T5 models. Responsible for data preprocessing and tokenization, as well as the end-to-end implementation and training of the T5 model, optimizing the model architecture and hyperparameters, achieving satisfactory results after only 3 epochs of training. Model evaluation results showed that the Rouge-1, Rouge-2, and Rouge-L metrics reached 0.6345, 0.5038, and 0.5282, respectively, in the third epoch, validating the model\u0026rsquo;s effectiveness in the summarization task. üéì Cambridge University Machine Learning Summer Project 07/2023 ‚Äì 08/2023 Group project, supervised by Prof. Pietro Li√≤ Participated in the Cambridge University deep learning summer project, focusing on deep reinforcement learning; explored multi-agent learning algorithms across different environments. Reproduced the Multi-Agent Deep Deterministic Policy Gradient (MADDPG) algorithm in the Simple Adversary environment and studied the effect of agent numbers on convergence speed and stability, finding optimal stability at 21 agents. Designed and implemented comparative experiments inspired by the Rainbow algorithm, assessing target network strategies versus the Double Deep Q-Network (Double DQN). The results demonstrated that Double DQN significantly enhanced convergence speed, optimizing the overall learning process. Co-authored a group project paper on agent numbers and strategies effectiveness in multi-agent systems, achieving a score of 71% in the summer program (the highest in my group) and a \u0026ldquo;First Class\u0026rdquo; classification in the UK grading system. üëÅÔ∏è Deep Learning and Computer Vision Semester Project 09/2022 ‚Äì 12/2022 Independent project, supervised by Associate Prof. Guangyu Gao Designed and implemented a waste classifier using the ResNet model to improve classification accuracy and reduce resource waste. The project also enhanced understanding of transfer learning techniques with ResNet. Collected a dataset of 16 waste categories and preprocessed the images for uniformity and standardization, incorporating data augmentation techniques to enhance the dataset. Conducted experiments using ResNet34 and ResNet50 models through transfer learning, accelerating network convergence by leveraging pretrained weights. During training, techniques such as Batch Normalization and Dropout were applied to mitigate the risk of overfitting. The final model achieved an accuracy of 90% on the training set, while the performance on the test set was 61%, indicating a significant overfitting phenomenon during the training process. üéì Internship ‚öõÔ∏è Beijing Academy of Quantum Information Science 08/2023 ‚Äì 01/2024 Research Intern at Quantum Computation Department Proposed a quantum convolution kernel design based on variational quantum circuits and developed a universal quantum convolution layer, successfully integrating it into classical CNN architectures such as VGG, GoogLeNet, and ResNet. Developed and evaluated various hybrid models, including a simple model named HQCCNN-2, which achieved 84.45% accuracy on the FashionMNIST dataset, surpassing the traditional CNN\u0026rsquo;s 80.72%. This demonstrates the effectiveness of the quantum convolution layer in improving model performance. Tested on a real quantum computer further validated the effectiveness of the hybrid model, demonstrating the viable integration of quantum computing with deep learning, and highlighting the potential for leveraging quantum properties to enhance model performance. üèÖ Competition Experience ü•â China International \u0026#34;Internet \u0026#43;\u0026#34; College Students\u0026#39; Innovation Competition 08/2022 üõ°Ô∏è Zhongke Ushield: Deep Learning-based Face Privacy Protection Authentication System Responsible for constructing a localized facial feature extraction engine based on MobileFaceNet, ensuring feature extraction is completed on end devices (such as mobile phones and cameras), guaranteeing that raw data does not leave the domain and is not stored, thus enhancing user privacy protection while improving recognition efficiency. ü•â \u0026#34;Challenge Cup\u0026#34; Capital University Entrepreneurship Competition 05/2022 üå≥ Smart Orchard Responsible for the development of the fruit detection, ripeness prediction, and pest identification system, using deep convolutional neural network (CNN) technology for intelligent monitoring of crop growth conditions. Applied advanced object detection algorithms such as Faster R-CNN and YOLO to achieve high precision in apple detection and ripeness assessment, with an accuracy rate exceeding 90%, significantly enhancing the intelligence level of orchard management. Built and trained a dedicated dataset containing various pest samples, optimizing pest detection accuracy through data preprocessing (such as image normalization and resizing) and data augmentation techniques (like rotation, flipping, and noise addition), enabling the real-time monitoring system to accurately identify over 80% of pests, providing effective scientific maintenance recommendations to help farmers reduce crop losses. üìã Extracurricular Activities Vice President, Cyber Security Club, Beijing Institute of Technology 09/2021-09/2022 Backbone, Media Center of the Student Union of Beijing Institute of Technology 10/2020-06/2021 üì´ Contact üìß Email: zongsi.xu@outlook.com üëî LinkedIn: Zongsi (Tristan) Xu üíª GitHub: BaizeXS üìç Location: Hong Kong SAR, China ","permalink":"http://localhost:1313/resume/","summary":"Personal resume of Zongsi (Tristan) Xu","title":"Zongsi (Tristan) Xu"},{"content":"‰∏Ä„ÄÅÊï∞ÂÄºÁâπÂæÅ‰∏éÁ±ªÂà´ÁâπÂæÅ Êï∞ÂÄºÁâπÂæÅ (Numeric Features) ÂÖ∑ÊúâÂèØÂä†ÂáèÁöÑÊÑè‰πâÔºå‰∏îÂ≠òÂú®Â§ßÂ∞èÈ°∫Â∫è„ÄÇ ‰æãÂ≠êÔºöÂπ¥ÈæÑ„ÄÅÊ∏©Â∫¶Á≠â„ÄÇÂèØ‰ª•Áõ¥Êé•‰øùÁïôÂÖ∂Êï¥Êï∞ÊàñÊµÆÁÇπÊï∞ÂΩ¢Âºè‰æõÊ®°Âûã‰ΩøÁî®„ÄÇ Á±ªÂà´ÁâπÂæÅ (Categorical Features) Êï∞ÊçÆÂÄºÁ¶ªÊï£Ôºå‰∏çÂÖ∑Â§á‚ÄúÊï∞ÂÄºÂ§ßÂ∞è‚ÄùÈó¥ÁöÑÂèØÊØîÊÑè‰πâ„ÄÇ ‰æãÂ≠êÔºöÂõΩÁ±çÔºàÁæéÂõΩ/‰∏≠ÂõΩ/Âç∞Â∫¶Á≠âÔºâ„ÄÅÊÄßÂà´ÔºàÁî∑/Â•≥ÔºâÁ≠â„ÄÇ ÈóÆÈ¢òÔºöËã•‰ªÖÁî®Êï¥Êï∞Ë°®Á§∫ÔºàÁæéÂõΩ=1, ‰∏≠ÂõΩ=2ÔºâÔºå‰ºöÂºïÂÖ•ÈîôËØØÁöÑÊï∞ÂÄºËøêÁÆóÂÖ≥Á≥ªÔºåÂ¶Ç ‚ÄúÁæéÂõΩ + ‰∏≠ÂõΩ = Âç∞Â∫¶‚Äù„ÄÇ ‰∫å„ÄÅOne-HotÁºñÁ†ÅÁöÑÂä®Êú∫‰∏éÊµÅÁ®ã ‰∏∫‰ªÄ‰πà‰ΩøÁî®One-Hot\nÈÄöËøáÂ∞ÜÁ±ªÂà´Êò†Â∞Ñ‰∏∫ÂêëÈáèÔºåÈÅøÂÖçÊï¥Êï∞ÁºñÁ†ÅÂºïÂÖ•ÁöÑ‰º™Êï∞ÂÄºÂÖ≥Á≥ª„ÄÇ ÂêåÊó∂‰øùÁïôÂêÑÁßçÂèØËÉΩÁ±ªÂà´ÁöÑ‰ø°ÊÅØÔºå‰∏î‰ªÖÂú®ÂØπÂ∫î‰ΩçÁΩÆ‰∏∫1ÔºåÂÖ∂‰ªñ‰ΩçÁΩÆ‰∏∫0„ÄÇ Âª∫Á´ãÊò†Â∞ÑÔºö‰ªéÁ±ªÂà´Âà∞Á¥¢Âºï\n‰∏∫ÊØè‰∏™Á±ªÂà´ÂàÜÈÖç‰∏Ä‰∏™ÂîØ‰∏ÄÁ¥¢ÂºïÔºåÈÄöÂ∏∏‰ªé1ÂºÄÂßã„ÄÇ È¢ÑÁïôÁ¥¢Âºï0Ë°®Á§∫‚ÄúÊú™Áü•‚ÄùÊàñ‚ÄúÁº∫Â§±‚ÄùÔºåÂØπÂ∫îÂÖ®0ÂêëÈáè„ÄÇ ËΩ¨Êç¢‰∏∫One-HotÂêëÈáè\nËã•Á±ªÂà´ÊÄªÊï∞‰∏∫197ÔºåÂàôÁî®197Áª¥ÂêëÈáèË°®Á§∫„ÄÇ ‰æãÂ≠êÔºöÁæéÂõΩ [1, 0, 0, 0, ‚Ä¶]Ôºå ‰∏≠ÂõΩ [0, 1, 0, 0, ‚Ä¶]„ÄÇ Á§∫‰æãÔºöË°®Á§∫‰∏Ä‰∏™‰∫∫ÁöÑÁâπÂæÅ\nÁâπÂæÅÂåÖÂê´ÔºàÂπ¥ÈæÑ, ÊÄßÂà´, ÂõΩÁ±çÔºåÂÖ∂‰∏≠ÂõΩÁ±ç197ÁßçÔºâ Áª¥Â∫¶ÊÄªÂíåÔºö1Áª¥_age + 1Áª¥_gender + 197Áª¥_nationality = 199Áª¥„ÄÇ ‰æãÂ¶Ç (28, Â•≥, ‰∏≠ÂõΩ) ‚Üí [28, 0, 0, 1, 0, ‚Ä¶, 0]„ÄÇ ‰∏â„ÄÅÊñáÊú¨Êï∞ÊçÆÂ§ÑÁêÜÊµÅÁ®ã ÊñáÊú¨Âú®Ëá™ÁÑ∂ËØ≠Ë®ÄÂ§ÑÁêÜÔºàNLPÔºâ‰∏≠‰Ωú‰∏∫Â∏∏ËßÅÁöÑÂéüÂßãËæìÂÖ•ÔºåÈúÄË¶ÅÊï∞ÂÄºÂåñÊâçËÉΩÈÄÅÂÖ•Ê®°Âûã„ÄÇ‰∏ÄËà¨Ê≠•È™§Â¶Ç‰∏ãÔºö\nÂàÜËØç (Tokenization)\nÂ∞ÜÊñáÊú¨ÊãÜÂàÜ‰∏∫‰∏Ä‰∏™‰∏™ÂçïËØçÔºàTokenÔºâ„ÄÇ ‰æãÂ≠êÔºö\u0026quot;... to be or not to be...\u0026quot; ‚Üí [\u0026quot;...\u0026quot;, \u0026quot;to\u0026quot;, \u0026quot;be\u0026quot;, \u0026quot;or\u0026quot;, \u0026quot;not\u0026quot;, \u0026quot;to\u0026quot;, \u0026quot;be\u0026quot;, \u0026quot;...\u0026quot;]„ÄÇ ÁªüËÆ°ËØçÈ¢ë \u0026amp; ÊûÑÂª∫ËØçÂÖ∏\nËØçÈ¢ëÁªüËÆ° Áî®ÂìàÂ∏åË°®/Â≠óÂÖ∏ËÆ∞ÂΩïÊØè‰∏™ÂçïËØçÂá∫Áé∞Ê¨°Êï∞„ÄÇ ÈÅçÂéÜÊñáÊú¨Êó∂ÔºåËã•ÂçïËØçÂ∞öÊú™ÂÖ•Ë°®ÔºåÂàôÊñ∞Âª∫ËÆ∞ÂΩïÔºõËã•Â∑≤Â≠òÂú®ÔºåÂàôËÆ°Êï∞+1„ÄÇ ÊéíÂ∫è‰∏éÁ¥¢Âºï ÊåâËØçÈ¢ëÈôçÂ∫èÊéíÂ∫èÔºåËØçÈ¢ëÊúÄÈ´òÁöÑÂçïËØçÊéíÂú®ÂâçÈù¢„ÄÇ Á¥¢Âºï‰ªé1ÂºÄÂßãÔºå0ÁïôÁªô‚ÄúÊú™Áü•‚Äù„ÄÇ ËØçÂÖ∏ËßÑÊ®°ÔºàvocabularyÔºâÂèØËßÜÈúÄÊ±ÇÊà™Êñ≠Ôºà‰æãÂ¶ÇÂè™‰øùÁïôTop 10kÔºâ„ÄÇ ‰∏∫‰ªÄ‰πàÁßªÈô§‰ΩéÈ¢ëËØç ‰ΩéÈ¢ëËØçÂèØËÉΩÊòØÊãºÂÜôÈîôËØØ„ÄÅÁΩïËßÅ‰∫∫ÂêçÁ≠âÔºåÂØπÊ®°ÂûãÂ∏ÆÂä©ÊúâÈôê„ÄÇ ÂáèÂ∞ëËØçÂÖ∏ËßÑÊ®°ÂèØÈôç‰ΩéËøêÁÆóÂºÄÈîÄ„ÄÅÂä†Âø´Ê®°ÂûãËÆ≠ÁªÉ‰∏éÊé®ÁêÜÈÄüÂ∫¶„ÄÇ Áã¨ÁÉ≠ÁºñÁ†Å (One-Hot Encoding)\nÂ∞ÜÊØè‰∏™ÂçïËØçÊò†Â∞Ñ‰∏∫ËØçÂÖ∏‰∏≠ÁöÑÁ¥¢ÂºïÂêéÔºàÂ¶Ç [2, 4, 1, 8, ‚Ä¶]ÔºâÔºåÂèØËøõ‰∏ÄÊ≠•ËΩ¨Êç¢ÊàêOne-HotÂêëÈáè„ÄÇ One-HotÁª¥Â∫¶ÂèñÂÜ≥‰∫é‰øùÁïô‰∏ãÊù•ÁöÑËØçÂÖ∏Â§ßÂ∞èÔºà‰æãÂ¶Ç1‰∏áÔºâ„ÄÇ Êú™Êî∂ÂΩïÂçïËØçÂèØËÉΩÁõ¥Êé•ÂøΩÁï•ÔºåÊàñÁªü‰∏ÄÁî®Á¥¢Âºï0‰ª£Êõø„ÄÇ Âõõ„ÄÅÊ†∏ÂøÉÊî∂Ëé∑‰∏éÂ∫îÁî® Á±ªÂà´ÁâπÂæÅÂøÖÈúÄÊï∞ÂÄºÂåñÔºö\n‰ΩøÁî®Êï¥Êï∞1,2,3‚Ä¶‰ªÖË°®Á§∫Á±ªÂà´‚ÄúÊ†áËØÜ‚ÄùÔºåÂπ∂‰∏ç‰ª£Ë°®ÂÆÉ‰ª¨ÂèØËøõË°åÊï∞ÂÄºËøêÁÆó„ÄÇ Âõ†Ê≠§ÈúÄË¶ÅOne-HotÁ≠âÁºñÁ†ÅÊñπÂºèÔºåÈÅøÂÖçÊï∞ÂÄºËØØËß£„ÄÇ ÊñáÊú¨Êï∞ÊçÆÈ¢ÑÂ§ÑÁêÜÔºö\nÂàÜËØç„ÄÅËØçÈ¢ëÁªüËÆ°„ÄÅÊûÑÂª∫ËØçÂÖ∏„ÄÅÁ¥¢ÂºïÂåñ„ÄÅOne-HotÊàñÂÖ∂‰ªñÊñπÂºèÔºàÂ¶ÇËØçÂµåÂÖ•ÔºâÊòØÂ∏∏ËßÅÊµÅÁ®ã„ÄÇ Ê≠£Á°ÆÁöÑÊñáÊú¨È¢ÑÂ§ÑÁêÜÂèØÊòæËëóÂΩ±ÂìçÊ®°ÂûãÊÄßËÉΩÂíåÊïàÁéá„ÄÇ ‰øùÁïôÊú™Áü•Á¥¢ÂºïÔºö\n‰øùËØÅÂØπÁº∫Â§±Êï∞ÊçÆÊàñÂ≠óÂÖ∏Â§ñÊñ∞ËØçËÉΩÊúâÂü∫Êú¨ÁöÑË°®Á§∫ÔºåÊèêÂçáÊ®°ÂûãÂÆπÈîôÊÄß„ÄÇ ÂÆûÈôÖ‰ΩøÁî®Ôºö\nÂØπ‰∫éÂ∞èËßÑÊ®°Á±ªÂà´ÂèØÁõ¥Êé•One-HotÁºñÁ†ÅÔºõÂØπ‰∫éËØçÂÖ∏ÂæàÂ§ßÁöÑÂú∫ÊôØÔºåÈÄöÂ∏∏‰ºöËøõ‰∏ÄÊ≠•ËÄÉËôëËØçÂµåÂÖ•ÔºàWord EmbeddingÔºâÊàñÈ¢ÑËÆ≠ÁªÉËØ≠Ë®ÄÊ®°Âûã„ÄÇ ","permalink":"http://localhost:1313/posts/nlp-1/","summary":"\u003ch2 id=\"‰∏ÄÊï∞ÂÄºÁâπÂæÅ‰∏éÁ±ªÂà´ÁâπÂæÅ\"\u003e‰∏Ä„ÄÅÊï∞ÂÄºÁâπÂæÅ‰∏éÁ±ªÂà´ÁâπÂæÅ\u003c/h2\u003e\n\u003col\u003e\n\u003cli\u003e\u003cstrong\u003eÊï∞ÂÄºÁâπÂæÅ (Numeric Features)\u003c/strong\u003e\n\u003cul\u003e\n\u003cli\u003eÂÖ∑ÊúâÂèØÂä†ÂáèÁöÑÊÑè‰πâÔºå‰∏îÂ≠òÂú®Â§ßÂ∞èÈ°∫Â∫è„ÄÇ\u003c/li\u003e\n\u003cli\u003e‰æãÂ≠êÔºöÂπ¥ÈæÑ„ÄÅÊ∏©Â∫¶Á≠â„ÄÇÂèØ‰ª•Áõ¥Êé•‰øùÁïôÂÖ∂Êï¥Êï∞ÊàñÊµÆÁÇπÊï∞ÂΩ¢Âºè‰æõÊ®°Âûã‰ΩøÁî®„ÄÇ\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003eÁ±ªÂà´ÁâπÂæÅ (Categorical Features)\u003c/strong\u003e\n\u003cul\u003e\n\u003cli\u003eÊï∞ÊçÆÂÄºÁ¶ªÊï£Ôºå‰∏çÂÖ∑Â§á‚ÄúÊï∞ÂÄºÂ§ßÂ∞è‚ÄùÈó¥ÁöÑÂèØÊØîÊÑè‰πâ„ÄÇ\u003c/li\u003e\n\u003cli\u003e‰æãÂ≠êÔºöÂõΩÁ±çÔºàÁæéÂõΩ/‰∏≠ÂõΩ/Âç∞Â∫¶Á≠âÔºâ„ÄÅÊÄßÂà´ÔºàÁî∑/Â•≥ÔºâÁ≠â„ÄÇ\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003eÈóÆÈ¢ò\u003c/strong\u003eÔºöËã•‰ªÖÁî®Êï¥Êï∞Ë°®Á§∫ÔºàÁæéÂõΩ=1, ‰∏≠ÂõΩ=2ÔºâÔºå‰ºöÂºïÂÖ•ÈîôËØØÁöÑÊï∞ÂÄºËøêÁÆóÂÖ≥Á≥ªÔºåÂ¶Ç ‚ÄúÁæéÂõΩ + ‰∏≠ÂõΩ = Âç∞Â∫¶‚Äù„ÄÇ\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003c/ol\u003e\n\u003ch2 id=\"‰∫åone-hotÁºñÁ†ÅÁöÑÂä®Êú∫‰∏éÊµÅÁ®ã\"\u003e‰∫å„ÄÅOne-HotÁºñÁ†ÅÁöÑÂä®Êú∫‰∏éÊµÅÁ®ã\u003c/h2\u003e\n\u003col\u003e\n\u003cli\u003e\n\u003cp\u003e\u003cstrong\u003e‰∏∫‰ªÄ‰πà‰ΩøÁî®One-Hot\u003c/strong\u003e\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eÈÄöËøáÂ∞ÜÁ±ªÂà´Êò†Â∞Ñ‰∏∫ÂêëÈáèÔºåÈÅøÂÖçÊï¥Êï∞ÁºñÁ†ÅÂºïÂÖ•ÁöÑ‰º™Êï∞ÂÄºÂÖ≥Á≥ª„ÄÇ\u003c/li\u003e\n\u003cli\u003eÂêåÊó∂‰øùÁïôÂêÑÁßçÂèØËÉΩÁ±ªÂà´ÁöÑ‰ø°ÊÅØÔºå‰∏î‰ªÖÂú®ÂØπÂ∫î‰ΩçÁΩÆ‰∏∫1ÔºåÂÖ∂‰ªñ‰ΩçÁΩÆ‰∏∫0„ÄÇ\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003e\u003cstrong\u003eÂª∫Á´ãÊò†Â∞ÑÔºö‰ªéÁ±ªÂà´Âà∞Á¥¢Âºï\u003c/strong\u003e\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e‰∏∫ÊØè‰∏™Á±ªÂà´ÂàÜÈÖç‰∏Ä‰∏™ÂîØ‰∏ÄÁ¥¢ÂºïÔºåÈÄöÂ∏∏‰ªé1ÂºÄÂßã„ÄÇ\u003c/li\u003e\n\u003cli\u003eÈ¢ÑÁïôÁ¥¢Âºï0Ë°®Á§∫‚ÄúÊú™Áü•‚ÄùÊàñ‚ÄúÁº∫Â§±‚ÄùÔºåÂØπÂ∫îÂÖ®0ÂêëÈáè„ÄÇ\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003e\u003cstrong\u003eËΩ¨Êç¢‰∏∫One-HotÂêëÈáè\u003c/strong\u003e\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eËã•Á±ªÂà´ÊÄªÊï∞‰∏∫197ÔºåÂàôÁî®197Áª¥ÂêëÈáèË°®Á§∫„ÄÇ\u003c/li\u003e\n\u003cli\u003e‰æãÂ≠êÔºöÁæéÂõΩ \u003ccode\u003e[1, 0, 0, 0, ‚Ä¶]\u003c/code\u003eÔºå ‰∏≠ÂõΩ \u003ccode\u003e[0, 1, 0, 0, ‚Ä¶]\u003c/code\u003e„ÄÇ\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003e\u003cstrong\u003eÁ§∫‰æãÔºöË°®Á§∫‰∏Ä‰∏™‰∫∫ÁöÑÁâπÂæÅ\u003c/strong\u003e\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eÁâπÂæÅÂåÖÂê´ÔºàÂπ¥ÈæÑ, ÊÄßÂà´, ÂõΩÁ±çÔºåÂÖ∂‰∏≠ÂõΩÁ±ç197ÁßçÔºâ\u003c/li\u003e\n\u003cli\u003eÁª¥Â∫¶ÊÄªÂíåÔºö1Áª¥_age + 1Áª¥_gender + 197Áª¥_nationality = 199Áª¥„ÄÇ\u003c/li\u003e\n\u003cli\u003e‰æãÂ¶Ç \u003ccode\u003e(28, Â•≥, ‰∏≠ÂõΩ)\u003c/code\u003e ‚Üí \u003ccode\u003e[28, 0, 0, 1, 0, ‚Ä¶, 0]\u003c/code\u003e„ÄÇ\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003c/ol\u003e\n\u003ch2 id=\"‰∏âÊñáÊú¨Êï∞ÊçÆÂ§ÑÁêÜÊµÅÁ®ã\"\u003e‰∏â„ÄÅÊñáÊú¨Êï∞ÊçÆÂ§ÑÁêÜÊµÅÁ®ã\u003c/h2\u003e\n\u003cp\u003eÊñáÊú¨Âú®Ëá™ÁÑ∂ËØ≠Ë®ÄÂ§ÑÁêÜÔºàNLPÔºâ‰∏≠‰Ωú‰∏∫Â∏∏ËßÅÁöÑÂéüÂßãËæìÂÖ•ÔºåÈúÄË¶ÅÊï∞ÂÄºÂåñÊâçËÉΩÈÄÅÂÖ•Ê®°Âûã„ÄÇ‰∏ÄËà¨Ê≠•È™§Â¶Ç‰∏ãÔºö\u003c/p\u003e\n\u003col\u003e\n\u003cli\u003e\n\u003cp\u003e\u003cstrong\u003eÂàÜËØç (Tokenization)\u003c/strong\u003e\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eÂ∞ÜÊñáÊú¨ÊãÜÂàÜ‰∏∫‰∏Ä‰∏™‰∏™ÂçïËØçÔºàTokenÔºâ„ÄÇ\u003c/li\u003e\n\u003cli\u003e‰æãÂ≠êÔºö\u003ccode\u003e\u0026quot;... to be or not to be...\u0026quot;\u003c/code\u003e ‚Üí \u003ccode\u003e[\u0026quot;...\u0026quot;, \u0026quot;to\u0026quot;, \u0026quot;be\u0026quot;, \u0026quot;or\u0026quot;, \u0026quot;not\u0026quot;, \u0026quot;to\u0026quot;, \u0026quot;be\u0026quot;, \u0026quot;...\u0026quot;]\u003c/code\u003e„ÄÇ\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003e\u003cstrong\u003eÁªüËÆ°ËØçÈ¢ë \u0026amp; ÊûÑÂª∫ËØçÂÖ∏\u003c/strong\u003e\u003c/p\u003e","title":""},{"content":"Text to Sequence ÊñáÊú¨Â§ÑÁêÜ\nStep1: Tokenization\nTokenization breaks a piece of text down into a list of tokens.\nHere, a token is a word. (A token can be a character in some applications.)\nTokenizationËÆ≤Á©∂ÂæàÂ§öÔºå‰æãÂ¶ÇÊòØÂê¶Â∫îËØ•ÊääÂ§ßÂÜôÊîπÊàêÂ∞èÂÜôÂë¢ÔºüËøõË°åtypo correctionÁ≠âÁ≠â\nStep2: Build Dictionary\nUse a dictionary (hash table) to count word frequencies.\nThe dictionary maps word to index.\nÂèØ‰ª•È¶ñÂÖàÁªüËÆ°ËØçÈ¢ëÂéªÊéâ‰ΩéÈ¢ëËØçÔºåÁÑ∂ÂêéËÆ©ÊØè‰∏™ËØçÂØπÂ∫î‰∏Ä‰∏™Ê≠£Êï¥Êï∞ÔºõËøôÊ†∑ÁöÑËØùÔºå‰∏ÄÂè•ËØùÂ∞±ÂèØ‰ª•Áî®‰∏Ä‰∏™Ê≠£Êï¥Êï∞ÂàóË°®Ë°®Á§∫ÔºåËøô‰∏™ÂàóË°®Â∞±Âè´sequenceÔºõÂ¶ÇÊûúÂøÖË¶ÅÂ∞±ËøòÂæóÂÅöone-hot encoding„ÄÇ\nÁªìÊûú\n‰ΩÜÊòØÈïøÂ∫¶‰∏çÁªü‰∏Ä\nStep4: ÂØπÈΩêsequence\nËß£ÂÜ≥ÊñπÊ°àÊòØËøôÊ†∑ÁöÑÔºöÂèØ‰ª•Âõ∫ÂÆöÈïøÂ∫¶‰∏∫wÔºåÂä†ÂÖ•‰∏Ä‰∏™Â∫èÂàóÈïøÂ∫¶Â§™ÈïøÔºåÂ∞±Á†çÊéâÂâçÈù¢ÁöÑËØçÔºåÂè™‰øùÁïôÊúÄÂêéw‰∏™ËØçÔºõÂ¶ÇÊûú‰∏Ä‰∏™Â∫èÂàóÂ§™Áü≠ÔºåÂ∞±ÂÅözero paddingÔºåÁî®0Â°´ÂÖÖ\nËøôÊ†∑‰∏ÄÊù•ÔºåÊâÄÊúâÁöÑÂ∫èÂàóÈïøÂ∫¶Â∞±Áªü‰∏Ä‰∫Ü\nÊñáÊú¨Â§ÑÁêÜÂÆåÊàê‰∫ÜÔºåÊé•‰∏ãÊù•ÊòØword embeddingÔºåÊääÂçïËØçË°®Á§∫‰∏∫‰∏Ä‰∏™‰ΩéÁª¥ÂêëÈáèÔºõ\nÁÑ∂ËÄåËøôÊ†∑ÂÅöÁöÑËØùÔºåÂ¶ÇÊûúÊòØ10000‰∏™ÂçïËØçÔºåÁª¥Â∫¶Â∞±ÊòØ10000Áª¥ÔºåÁª¥Â∫¶Â§™È´ò‰∫ÜÔºõÂõ†Ê≠§Ë¶ÅÂÅöword embeddingÔºõ\nÂÖ∑‰ΩìÂÅöÊ≥ïÂ∞±ÊòØÊääone-hotÂêëÈáèe_iÂíåÂèÇÊï∞Áü©ÈòµpÁõ∏‰πòÔºõÁü©ÈòµPËΩ¨ÁΩÆÁöÑÂ§ßÂ∞èÊòØd x vÔºõdÊòØËØçÂêëÈáèÁöÑÁª¥Â∫¶ÔºõvÊòØÂ≠óÂÖ∏ÈáåËØçÊ±áÁöÑÊï∞ÈáèÔºõÁªìÊûú‰∏∫x_iÔºõx_iÂ∞±ÊòØ‰∏Ä‰∏™ËØçÂêëÈáèÔºõÂ¶ÇÊûúone-hotÂêëÈáèÁöÑÁ¨¨‰∏âË°å‰∏∫1ÔºõÈÇ£‰πàx_iÂ∞±ÊòØPËΩ¨ÁΩÆÁü©ÈòµÁöÑÁ¨¨‰∏âÂàóÔºàÂÖ∂‰ΩôÂàóÈÉΩ‰∏∫0ÔºâÔºõÊâÄ‰ª•PËΩ¨ÁΩÆÊØè‰∏ÄÂàóÈÉΩÊòØ‰∏Ä‰∏™ËØçÂêëÈáèÔºõÊâÄ‰ª•Áü©ÈòµPÊú¨Ë∫´ÁöÑÊØè‰∏ÄË°åÂ∞±ÊòØ‰∏Ä‰∏™ËØçÂêëÈáèÔºõÂÖ∂Ë°åÊï∞‰∏∫vÔºõÂç≥vocabularyÔºåËØçÊ±áÈáèÔºõÊØè‰∏ÄË°åÂØπÂ∫î‰∏Ä‰∏™ÂçïËØçÔºõÁü©ÈòµÁöÑÂàóÊï∞‰∏∫dÔºõdÊòØÁî®Êà∑ÂÜ≥ÂÆöÁöÑÔºõdÁöÑÂ§ßÂ∞è‰ºöÂÜ≥ÂÆöÊú∫Âô®Â≠¶‰π†Ê®°ÂûãÁöÑË°®Áé∞ÔºõÂ∫îËØ•Áî®xxxÊù•ÈÄâÊã©‰∏Ä‰∏™ÊØîËæÉÂ•ΩÁöÑdÔºõ\nÊàë‰ª¨ÁöÑ‰ªªÂä°ÊòØÁúãËØÑËÆ∫ÊòØÊ≠£Èù¢ÁöÑËøòÊòØË¥üÈù¢ÁöÑÔºõÂèÇÊï∞Áü©ÈòµÊòØ‰ªéËÆ≠ÁªÉÊï∞ÊçÆ‰∏≠Â≠¶‰π†Âá∫Êù•ÁöÑÔºåÊâÄ‰ª•Â≠¶Âá∫Êù•ÁöÑËØçÂêëÈáèÊòØÂ∏¶ÊúâÊÑüÊÉÖËâ≤ÂΩ©ÁöÑÔºõÂÅáËÆæËøô‰∫õËØçÂêëÈáèÈÉΩÊòØ‰∫åÁª¥ÁöÑÔºåÂàôÂèØ‰ª•Âú®Âπ≥Èù¢ÂùêÊ†áÁ≥ª‰∏≠Ê†áÂá∫‰∏ãÈù¢ËØçÂêëÈáè\nkerasÊèê‰æõembeddingÂ±ÇÔºõÁî®Êà∑ÂèØ‰ª•ÊåáÂÆövocabularyÂ§ßÂ∞èÂíådÁöÑÂ§ßÂ∞èÔºõ‰ª•ÂèäÊØè‰∏Ä‰∏™sequenceÁöÑÈïøÂ∫¶ÔºõdÊòØÊ†πÊçÆÁÆóÊ≥ïÈÄâÂá∫Êù•ÁöÑ Âà∞Ëøô‰∏ÄÊ≠•ÔºåÊàë‰ª¨Â∑≤ÁªèÂÆåÊàê‰∫ÜÊñáÊú¨Â§ÑÁêÜÂíåword embedding„ÄÇÊé•‰∏ãÊù•Â∞±ÊòØÁî®Logistic Regression for Binary ClassificationÂÅö‰∫åÂàÜÁ±ªÔºõ\n","permalink":"http://localhost:1313/posts/nlp-2/","summary":"\u003ch3 id=\"text-to-sequence\"\u003eText to Sequence\u003c/h3\u003e\n\u003cp\u003eÊñáÊú¨Â§ÑÁêÜ\u003c/p\u003e\n\u003cp\u003eStep1: Tokenization\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\n\u003cp\u003eTokenization breaks a piece of text down into a list of tokens.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003eHere, a token is a word. (A token can be a character in some applications.)\u003c/p\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003eTokenizationËÆ≤Á©∂ÂæàÂ§öÔºå‰æãÂ¶ÇÊòØÂê¶Â∫îËØ•ÊääÂ§ßÂÜôÊîπÊàêÂ∞èÂÜôÂë¢ÔºüËøõË°åtypo correctionÁ≠âÁ≠â\u003c/p\u003e\n\u003cp\u003e\u003cimg alt=\"image-20250322150322238\" loading=\"lazy\" src=\"./NLP-2.assets/image-20250322150322238.png\"\u003e\u003c/p\u003e\n\u003cp\u003eStep2: Build Dictionary\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\n\u003cp\u003eUse a dictionary (hash table) to count word frequencies.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003eThe dictionary maps word to index.\u003c/p\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003eÂèØ‰ª•È¶ñÂÖàÁªüËÆ°ËØçÈ¢ëÂéªÊéâ‰ΩéÈ¢ëËØçÔºåÁÑ∂ÂêéËÆ©ÊØè‰∏™ËØçÂØπÂ∫î‰∏Ä‰∏™Ê≠£Êï¥Êï∞ÔºõËøôÊ†∑ÁöÑËØùÔºå‰∏ÄÂè•ËØùÂ∞±ÂèØ‰ª•Áî®‰∏Ä‰∏™Ê≠£Êï¥Êï∞ÂàóË°®Ë°®Á§∫ÔºåËøô‰∏™ÂàóË°®Â∞±Âè´sequenceÔºõÂ¶ÇÊûúÂøÖË¶ÅÂ∞±ËøòÂæóÂÅöone-hot encoding„ÄÇ\u003cimg alt=\"image-20250322150620890\" loading=\"lazy\" src=\"./NLP-2.assets/image-20250322150620890.png\"\u003e\u003c/p\u003e\n\u003cp\u003eÁªìÊûú\u003c/p\u003e\n\u003cp\u003e\u003cimg alt=\"image-20250322150754528\" loading=\"lazy\" src=\"./NLP-2.assets/image-20250322150754528.png\"\u003e\u003c/p\u003e\n\u003cp\u003e‰ΩÜÊòØÈïøÂ∫¶‰∏çÁªü‰∏Ä\u003c/p\u003e\n\u003cp\u003eStep4: ÂØπÈΩêsequence\u003c/p\u003e\n\u003cp\u003e\u003cimg alt=\"image-20250322150854986\" loading=\"lazy\" src=\"./NLP-2.assets/image-20250322150854986.png\"\u003e\u003c/p\u003e\n\u003cp\u003eËß£ÂÜ≥ÊñπÊ°àÊòØËøôÊ†∑ÁöÑÔºöÂèØ‰ª•Âõ∫ÂÆöÈïøÂ∫¶‰∏∫wÔºåÂä†ÂÖ•‰∏Ä‰∏™Â∫èÂàóÈïøÂ∫¶Â§™ÈïøÔºåÂ∞±Á†çÊéâÂâçÈù¢ÁöÑËØçÔºåÂè™‰øùÁïôÊúÄÂêéw‰∏™ËØçÔºõÂ¶ÇÊûú‰∏Ä‰∏™Â∫èÂàóÂ§™Áü≠ÔºåÂ∞±ÂÅözero paddingÔºåÁî®0Â°´ÂÖÖ\u003c/p\u003e\n\u003cp\u003e\u003cimg alt=\"image-20250322151030119\" loading=\"lazy\" src=\"./NLP-2.assets/image-20250322151030119.png\"\u003e\u003c/p\u003e\n\u003cp\u003eËøôÊ†∑‰∏ÄÊù•ÔºåÊâÄÊúâÁöÑÂ∫èÂàóÈïøÂ∫¶Â∞±Áªü‰∏Ä‰∫Ü\u003c/p\u003e\n\u003cp\u003e\u003cimg alt=\"image-20250322151117125\" loading=\"lazy\" src=\"./NLP-2.assets/image-20250322151117125.png\"\u003e\u003c/p\u003e\n\u003cp\u003eÊñáÊú¨Â§ÑÁêÜÂÆåÊàê‰∫ÜÔºåÊé•‰∏ãÊù•ÊòØword embeddingÔºåÊääÂçïËØçË°®Á§∫‰∏∫‰∏Ä‰∏™‰ΩéÁª¥ÂêëÈáèÔºõ\u003c/p\u003e\n\u003cp\u003e\u003cimg alt=\"image-20250322151252837\" loading=\"lazy\" src=\"./NLP-2.assets/image-20250322151252837.png\"\u003e\u003c/p\u003e","title":""},{"content":"üëã About me Hello! I\u0026rsquo;m Xu Zongsi, a passionate technology enthusiast currently pursuing my Master of Science in ECIC at The University of Hong Kong. With a solid background in Software Engineering from the Beijing Institute of Technology, I specialize in artificial intelligence areas like machine learning, deep learning, natural language processing, computer vision, and reinforcement learning.\nInspired by OpenAI\u0026rsquo;s five-step plan towards superintelligence, I am excited about AGI and have developed a keen interest in LLM agents, MLLM, and knowledge graphs. I see great potential in these fields and aspire to contribute to innovative solutions.\nüìö Education üá≠üá∞ The University of Hong Kong 09/2024 - Expected 11/2025 School of Computing and Data Science Master of Science in Electronic Commerce \u0026amp; Internet Computing Relevant Courses: Machine learning for business and e-commerce, Knowledge graphs, Financial fraud analytics, Internet infrastructure technologies, Website engineering, Blockchain and cryptocurrency, etc. üá®üá≥ Beijing Institute of Technology 09/2020 - 06/2024 School of Computer Science \u0026amp; Technology Bachelor of Engineering in Software Engineering, last two years GPA: 3.7/4 Relevant Courses: Reinforcement Learning, Deep Learning and Computer Vision, Artificial Intelligence and Robot Ethics, Almost Human: Mind, Brain and Artificial Intelligence, Mathematical Analysis for Engineering, Linear Algebra, Probability and Mathematical Statistics, etc. Skills: Python, Java, common data structures, design patterns, machine learning basics and algorithms, Linux, PyTorch, and some development tools (git, conda, etc.). üèÜ Awards \u0026amp; Honors Beijing Institute of Technology Undergraduate Scholarship (Top 20% of Grade) 06/2023 3rd Prize of China International \u0026#34;Internet \u0026#43;\u0026#34; College Student\u0026#39;s Innovation Competition 08/2022 Bronze Prize of \u0026#34;Challenge Cup\u0026#34; Capital University Entrepreneurship Competition 05/2022 üíº Project Experience üîç Online Transaction Fraud Detection 09/2024 ‚Äì 01/2025 Independent project, supervised by Dr. Vivien Chan Focused on addressing financial fraud in e-commerce to enhance the accuracy of transaction anomaly detection, while independently managing the entire case study that included data preprocessing, feature engineering, model building, evaluation, and results analysis. Effectively resolved class imbalance issues using SMOTE and ROSE techniques. Built various models including Logistic Regression, Random Forest, XGBoost, and LightGBM, ultimately selecting the LightGBM model to achieve a recall rate of 95.45% and an AUC of 99.84%. Wrote efficient and maintainable code, enhancing model training and data processing efficiency through parallel computing and logging. ü§ñ Multi-Model Intelligent Text Keyword Extraction System 08/2023 ‚Äì 09/2023 Group project, supervised by Associate Prof. Xiaolin Zhao Designed and implemented an intelligent text summary system that automatically extracts keywords from article titles and abstracts, enhancing the understanding and summarization of text information. Participated in the planning of the technical route and built a hybrid model combining extractive and generative approaches, utilizing advanced natural language processing techniques including KeyBERT, Sentence Transformer, BERT, and T5 models. Responsible for data preprocessing and tokenization, as well as the end-to-end implementation and training of the T5 model, optimizing the model architecture and hyperparameters, achieving satisfactory results after only 3 epochs of training. Model evaluation results showed that the Rouge-1, Rouge-2, and Rouge-L metrics reached 0.6345, 0.5038, and 0.5282, respectively, in the third epoch, validating the model\u0026rsquo;s effectiveness in the summarization task. üéì Cambridge University Machine Learning Summer Project 07/2023 ‚Äì 08/2023 Group project, supervised by Prof. Pietro Li√≤ Participated in the Cambridge University deep learning summer project, focusing on deep reinforcement learning; explored multi-agent learning algorithms across different environments. Reproduced the Multi-Agent Deep Deterministic Policy Gradient (MADDPG) algorithm in the Simple Adversary environment and studied the effect of agent numbers on convergence speed and stability, finding optimal stability at 21 agents. Designed and implemented comparative experiments inspired by the Rainbow algorithm, assessing target network strategies versus the Double Deep Q-Network (Double DQN). The results demonstrated that Double DQN significantly enhanced convergence speed, optimizing the overall learning process. Co-authored a group project paper on agent numbers and strategies effectiveness in multi-agent systems, achieving a score of 71% in the summer program (the highest in my group) and a \u0026ldquo;First Class\u0026rdquo; classification in the UK grading system. üëÅÔ∏è Deep Learning and Computer Vision Semester Project 09/2022 ‚Äì 12/2022 Independent project, supervised by Associate Prof. Guangyu Gao Designed and implemented a waste classifier using the ResNet model to improve classification accuracy and reduce resource waste. The project also enhanced understanding of transfer learning techniques with ResNet. Collected a dataset of 16 waste categories and preprocessed the images for uniformity and standardization, incorporating data augmentation techniques to enhance the dataset. Conducted experiments using ResNet34 and ResNet50 models through transfer learning, accelerating network convergence by leveraging pretrained weights. During training, techniques such as Batch Normalization and Dropout were applied to mitigate the risk of overfitting. The final model achieved an accuracy of 90% on the training set, while the performance on the test set was 61%, indicating a significant overfitting phenomenon during the training process. üéì Internship ‚öõÔ∏è Beijing Academy of Quantum Information Science 08/2023 ‚Äì 01/2024 Research Intern at Quantum Computation Department Proposed a quantum convolution kernel design based on variational quantum circuits and developed a universal quantum convolution layer, successfully integrating it into classical CNN architectures such as VGG, GoogLeNet, and ResNet. Developed and evaluated various hybrid models, including a simple model named HQCCNN-2, which achieved 84.45% accuracy on the FashionMNIST dataset, surpassing the traditional CNN\u0026rsquo;s 80.72%. This demonstrates the effectiveness of the quantum convolution layer in improving model performance. Tested on a real quantum computer further validated the effectiveness of the hybrid model, demonstrating the viable integration of quantum computing with deep learning, and highlighting the potential for leveraging quantum properties to enhance model performance. üèÖ Competition Experience ü•â China International \u0026#34;Internet \u0026#43;\u0026#34; College Students\u0026#39; Innovation Competition 08/2022 üõ°Ô∏è Zhongke Ushield: Deep Learning-based Face Privacy Protection Authentication System Responsible for constructing a localized facial feature extraction engine based on MobileFaceNet, ensuring feature extraction is completed on end devices (such as mobile phones and cameras), guaranteeing that raw data does not leave the domain and is not stored, thus enhancing user privacy protection while improving recognition efficiency. ü•â \u0026#34;Challenge Cup\u0026#34; Capital University Entrepreneurship Competition 05/2022 üå≥ Smart Orchard Responsible for the development of the fruit detection, ripeness prediction, and pest identification system, using deep convolutional neural network (CNN) technology for intelligent monitoring of crop growth conditions. Applied advanced object detection algorithms such as Faster R-CNN and YOLO to achieve high precision in apple detection and ripeness assessment, with an accuracy rate exceeding 90%, significantly enhancing the intelligence level of orchard management. Built and trained a dedicated dataset containing various pest samples, optimizing pest detection accuracy through data preprocessing (such as image normalization and resizing) and data augmentation techniques (like rotation, flipping, and noise addition), enabling the real-time monitoring system to accurately identify over 80% of pests, providing effective scientific maintenance recommendations to help farmers reduce crop losses. üìã Extracurricular Activities Vice President, Cyber Security Club, Beijing Institute of Technology 09/2021-09/2022 Backbone, Media Center of the Student Union of Beijing Institute of Technology 10/2020-06/2021 üì´ Contact üìß Email: zongsi.xu@outlook.com üëî LinkedIn: Zongsi (Tristan) Xu üíª GitHub: BaizeXS üìç Location: Hong Kong SAR, China ","permalink":"http://localhost:1313/resume/","summary":"Personal resume of Zongsi (Tristan) Xu","title":"Zongsi (Tristan) Xu"},{"content":"‰∏Ä„ÄÅÊï∞ÂÄºÁâπÂæÅ‰∏éÁ±ªÂà´ÁâπÂæÅ Êï∞ÂÄºÁâπÂæÅ (Numeric Features) ÂÖ∑ÊúâÂèØÂä†ÂáèÁöÑÊÑè‰πâÔºå‰∏îÂ≠òÂú®Â§ßÂ∞èÈ°∫Â∫è„ÄÇ ‰æãÂ≠êÔºöÂπ¥ÈæÑ„ÄÅÊ∏©Â∫¶Á≠â„ÄÇÂèØ‰ª•Áõ¥Êé•‰øùÁïôÂÖ∂Êï¥Êï∞ÊàñÊµÆÁÇπÊï∞ÂΩ¢Âºè‰æõÊ®°Âûã‰ΩøÁî®„ÄÇ Á±ªÂà´ÁâπÂæÅ (Categorical Features) Êï∞ÊçÆÂÄºÁ¶ªÊï£Ôºå‰∏çÂÖ∑Â§á‚ÄúÊï∞ÂÄºÂ§ßÂ∞è‚ÄùÈó¥ÁöÑÂèØÊØîÊÑè‰πâ„ÄÇ ‰æãÂ≠êÔºöÂõΩÁ±çÔºàÁæéÂõΩ/‰∏≠ÂõΩ/Âç∞Â∫¶Á≠âÔºâ„ÄÅÊÄßÂà´ÔºàÁî∑/Â•≥ÔºâÁ≠â„ÄÇ ÈóÆÈ¢òÔºöËã•‰ªÖÁî®Êï¥Êï∞Ë°®Á§∫ÔºàÁæéÂõΩ=1, ‰∏≠ÂõΩ=2ÔºâÔºå‰ºöÂºïÂÖ•ÈîôËØØÁöÑÊï∞ÂÄºËøêÁÆóÂÖ≥Á≥ªÔºåÂ¶Ç ‚ÄúÁæéÂõΩ + ‰∏≠ÂõΩ = Âç∞Â∫¶‚Äù„ÄÇ ‰∫å„ÄÅOne-HotÁºñÁ†ÅÁöÑÂä®Êú∫‰∏éÊµÅÁ®ã ‰∏∫‰ªÄ‰πà‰ΩøÁî®One-Hot\nÈÄöËøáÂ∞ÜÁ±ªÂà´Êò†Â∞Ñ‰∏∫ÂêëÈáèÔºåÈÅøÂÖçÊï¥Êï∞ÁºñÁ†ÅÂºïÂÖ•ÁöÑ‰º™Êï∞ÂÄºÂÖ≥Á≥ª„ÄÇ ÂêåÊó∂‰øùÁïôÂêÑÁßçÂèØËÉΩÁ±ªÂà´ÁöÑ‰ø°ÊÅØÔºå‰∏î‰ªÖÂú®ÂØπÂ∫î‰ΩçÁΩÆ‰∏∫1ÔºåÂÖ∂‰ªñ‰ΩçÁΩÆ‰∏∫0„ÄÇ Âª∫Á´ãÊò†Â∞ÑÔºö‰ªéÁ±ªÂà´Âà∞Á¥¢Âºï\n‰∏∫ÊØè‰∏™Á±ªÂà´ÂàÜÈÖç‰∏Ä‰∏™ÂîØ‰∏ÄÁ¥¢ÂºïÔºåÈÄöÂ∏∏‰ªé1ÂºÄÂßã„ÄÇ È¢ÑÁïôÁ¥¢Âºï0Ë°®Á§∫‚ÄúÊú™Áü•‚ÄùÊàñ‚ÄúÁº∫Â§±‚ÄùÔºåÂØπÂ∫îÂÖ®0ÂêëÈáè„ÄÇ ËΩ¨Êç¢‰∏∫One-HotÂêëÈáè\nËã•Á±ªÂà´ÊÄªÊï∞‰∏∫197ÔºåÂàôÁî®197Áª¥ÂêëÈáèË°®Á§∫„ÄÇ ‰æãÂ≠êÔºöÁæéÂõΩ [1, 0, 0, 0, ‚Ä¶]Ôºå ‰∏≠ÂõΩ [0, 1, 0, 0, ‚Ä¶]„ÄÇ Á§∫‰æãÔºöË°®Á§∫‰∏Ä‰∏™‰∫∫ÁöÑÁâπÂæÅ\nÁâπÂæÅÂåÖÂê´ÔºàÂπ¥ÈæÑ, ÊÄßÂà´, ÂõΩÁ±çÔºåÂÖ∂‰∏≠ÂõΩÁ±ç197ÁßçÔºâ Áª¥Â∫¶ÊÄªÂíåÔºö1Áª¥_age + 1Áª¥_gender + 197Áª¥_nationality = 199Áª¥„ÄÇ ‰æãÂ¶Ç (28, Â•≥, ‰∏≠ÂõΩ) ‚Üí [28, 0, 0, 1, 0, ‚Ä¶, 0]„ÄÇ ‰∏â„ÄÅÊñáÊú¨Êï∞ÊçÆÂ§ÑÁêÜÊµÅÁ®ã ÊñáÊú¨Âú®Ëá™ÁÑ∂ËØ≠Ë®ÄÂ§ÑÁêÜÔºàNLPÔºâ‰∏≠‰Ωú‰∏∫Â∏∏ËßÅÁöÑÂéüÂßãËæìÂÖ•ÔºåÈúÄË¶ÅÊï∞ÂÄºÂåñÊâçËÉΩÈÄÅÂÖ•Ê®°Âûã„ÄÇ‰∏ÄËà¨Ê≠•È™§Â¶Ç‰∏ãÔºö\nÂàÜËØç (Tokenization)\nÂ∞ÜÊñáÊú¨ÊãÜÂàÜ‰∏∫‰∏Ä‰∏™‰∏™ÂçïËØçÔºàTokenÔºâ„ÄÇ ‰æãÂ≠êÔºö\u0026quot;... to be or not to be...\u0026quot; ‚Üí [\u0026quot;...\u0026quot;, \u0026quot;to\u0026quot;, \u0026quot;be\u0026quot;, \u0026quot;or\u0026quot;, \u0026quot;not\u0026quot;, \u0026quot;to\u0026quot;, \u0026quot;be\u0026quot;, \u0026quot;...\u0026quot;]„ÄÇ ÁªüËÆ°ËØçÈ¢ë \u0026amp; ÊûÑÂª∫ËØçÂÖ∏\nËØçÈ¢ëÁªüËÆ° Áî®ÂìàÂ∏åË°®/Â≠óÂÖ∏ËÆ∞ÂΩïÊØè‰∏™ÂçïËØçÂá∫Áé∞Ê¨°Êï∞„ÄÇ ÈÅçÂéÜÊñáÊú¨Êó∂ÔºåËã•ÂçïËØçÂ∞öÊú™ÂÖ•Ë°®ÔºåÂàôÊñ∞Âª∫ËÆ∞ÂΩïÔºõËã•Â∑≤Â≠òÂú®ÔºåÂàôËÆ°Êï∞+1„ÄÇ ÊéíÂ∫è‰∏éÁ¥¢Âºï ÊåâËØçÈ¢ëÈôçÂ∫èÊéíÂ∫èÔºåËØçÈ¢ëÊúÄÈ´òÁöÑÂçïËØçÊéíÂú®ÂâçÈù¢„ÄÇ Á¥¢Âºï‰ªé1ÂºÄÂßãÔºå0ÁïôÁªô‚ÄúÊú™Áü•‚Äù„ÄÇ ËØçÂÖ∏ËßÑÊ®°ÔºàvocabularyÔºâÂèØËßÜÈúÄÊ±ÇÊà™Êñ≠Ôºà‰æãÂ¶ÇÂè™‰øùÁïôTop 10kÔºâ„ÄÇ ‰∏∫‰ªÄ‰πàÁßªÈô§‰ΩéÈ¢ëËØç ‰ΩéÈ¢ëËØçÂèØËÉΩÊòØÊãºÂÜôÈîôËØØ„ÄÅÁΩïËßÅ‰∫∫ÂêçÁ≠âÔºåÂØπÊ®°ÂûãÂ∏ÆÂä©ÊúâÈôê„ÄÇ ÂáèÂ∞ëËØçÂÖ∏ËßÑÊ®°ÂèØÈôç‰ΩéËøêÁÆóÂºÄÈîÄ„ÄÅÂä†Âø´Ê®°ÂûãËÆ≠ÁªÉ‰∏éÊé®ÁêÜÈÄüÂ∫¶„ÄÇ Áã¨ÁÉ≠ÁºñÁ†Å (One-Hot Encoding)\nÂ∞ÜÊØè‰∏™ÂçïËØçÊò†Â∞Ñ‰∏∫ËØçÂÖ∏‰∏≠ÁöÑÁ¥¢ÂºïÂêéÔºàÂ¶Ç [2, 4, 1, 8, ‚Ä¶]ÔºâÔºåÂèØËøõ‰∏ÄÊ≠•ËΩ¨Êç¢ÊàêOne-HotÂêëÈáè„ÄÇ One-HotÁª¥Â∫¶ÂèñÂÜ≥‰∫é‰øùÁïô‰∏ãÊù•ÁöÑËØçÂÖ∏Â§ßÂ∞èÔºà‰æãÂ¶Ç1‰∏áÔºâ„ÄÇ Êú™Êî∂ÂΩïÂçïËØçÂèØËÉΩÁõ¥Êé•ÂøΩÁï•ÔºåÊàñÁªü‰∏ÄÁî®Á¥¢Âºï0‰ª£Êõø„ÄÇ Âõõ„ÄÅÊ†∏ÂøÉÊî∂Ëé∑‰∏éÂ∫îÁî® Á±ªÂà´ÁâπÂæÅÂøÖÈúÄÊï∞ÂÄºÂåñÔºö\n‰ΩøÁî®Êï¥Êï∞1,2,3‚Ä¶‰ªÖË°®Á§∫Á±ªÂà´‚ÄúÊ†áËØÜ‚ÄùÔºåÂπ∂‰∏ç‰ª£Ë°®ÂÆÉ‰ª¨ÂèØËøõË°åÊï∞ÂÄºËøêÁÆó„ÄÇ Âõ†Ê≠§ÈúÄË¶ÅOne-HotÁ≠âÁºñÁ†ÅÊñπÂºèÔºåÈÅøÂÖçÊï∞ÂÄºËØØËß£„ÄÇ ÊñáÊú¨Êï∞ÊçÆÈ¢ÑÂ§ÑÁêÜÔºö\nÂàÜËØç„ÄÅËØçÈ¢ëÁªüËÆ°„ÄÅÊûÑÂª∫ËØçÂÖ∏„ÄÅÁ¥¢ÂºïÂåñ„ÄÅOne-HotÊàñÂÖ∂‰ªñÊñπÂºèÔºàÂ¶ÇËØçÂµåÂÖ•ÔºâÊòØÂ∏∏ËßÅÊµÅÁ®ã„ÄÇ Ê≠£Á°ÆÁöÑÊñáÊú¨È¢ÑÂ§ÑÁêÜÂèØÊòæËëóÂΩ±ÂìçÊ®°ÂûãÊÄßËÉΩÂíåÊïàÁéá„ÄÇ ‰øùÁïôÊú™Áü•Á¥¢ÂºïÔºö\n‰øùËØÅÂØπÁº∫Â§±Êï∞ÊçÆÊàñÂ≠óÂÖ∏Â§ñÊñ∞ËØçËÉΩÊúâÂü∫Êú¨ÁöÑË°®Á§∫ÔºåÊèêÂçáÊ®°ÂûãÂÆπÈîôÊÄß„ÄÇ ÂÆûÈôÖ‰ΩøÁî®Ôºö\nÂØπ‰∫éÂ∞èËßÑÊ®°Á±ªÂà´ÂèØÁõ¥Êé•One-HotÁºñÁ†ÅÔºõÂØπ‰∫éËØçÂÖ∏ÂæàÂ§ßÁöÑÂú∫ÊôØÔºåÈÄöÂ∏∏‰ºöËøõ‰∏ÄÊ≠•ËÄÉËôëËØçÂµåÂÖ•ÔºàWord EmbeddingÔºâÊàñÈ¢ÑËÆ≠ÁªÉËØ≠Ë®ÄÊ®°Âûã„ÄÇ ","permalink":"http://localhost:1313/posts/nlp-1/","summary":"\u003ch2 id=\"‰∏ÄÊï∞ÂÄºÁâπÂæÅ‰∏éÁ±ªÂà´ÁâπÂæÅ\"\u003e‰∏Ä„ÄÅÊï∞ÂÄºÁâπÂæÅ‰∏éÁ±ªÂà´ÁâπÂæÅ\u003c/h2\u003e\n\u003col\u003e\n\u003cli\u003e\u003cstrong\u003eÊï∞ÂÄºÁâπÂæÅ (Numeric Features)\u003c/strong\u003e\n\u003cul\u003e\n\u003cli\u003eÂÖ∑ÊúâÂèØÂä†ÂáèÁöÑÊÑè‰πâÔºå‰∏îÂ≠òÂú®Â§ßÂ∞èÈ°∫Â∫è„ÄÇ\u003c/li\u003e\n\u003cli\u003e‰æãÂ≠êÔºöÂπ¥ÈæÑ„ÄÅÊ∏©Â∫¶Á≠â„ÄÇÂèØ‰ª•Áõ¥Êé•‰øùÁïôÂÖ∂Êï¥Êï∞ÊàñÊµÆÁÇπÊï∞ÂΩ¢Âºè‰æõÊ®°Âûã‰ΩøÁî®„ÄÇ\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003eÁ±ªÂà´ÁâπÂæÅ (Categorical Features)\u003c/strong\u003e\n\u003cul\u003e\n\u003cli\u003eÊï∞ÊçÆÂÄºÁ¶ªÊï£Ôºå‰∏çÂÖ∑Â§á‚ÄúÊï∞ÂÄºÂ§ßÂ∞è‚ÄùÈó¥ÁöÑÂèØÊØîÊÑè‰πâ„ÄÇ\u003c/li\u003e\n\u003cli\u003e‰æãÂ≠êÔºöÂõΩÁ±çÔºàÁæéÂõΩ/‰∏≠ÂõΩ/Âç∞Â∫¶Á≠âÔºâ„ÄÅÊÄßÂà´ÔºàÁî∑/Â•≥ÔºâÁ≠â„ÄÇ\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003eÈóÆÈ¢ò\u003c/strong\u003eÔºöËã•‰ªÖÁî®Êï¥Êï∞Ë°®Á§∫ÔºàÁæéÂõΩ=1, ‰∏≠ÂõΩ=2ÔºâÔºå‰ºöÂºïÂÖ•ÈîôËØØÁöÑÊï∞ÂÄºËøêÁÆóÂÖ≥Á≥ªÔºåÂ¶Ç ‚ÄúÁæéÂõΩ + ‰∏≠ÂõΩ = Âç∞Â∫¶‚Äù„ÄÇ\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003c/ol\u003e\n\u003ch2 id=\"‰∫åone-hotÁºñÁ†ÅÁöÑÂä®Êú∫‰∏éÊµÅÁ®ã\"\u003e‰∫å„ÄÅOne-HotÁºñÁ†ÅÁöÑÂä®Êú∫‰∏éÊµÅÁ®ã\u003c/h2\u003e\n\u003col\u003e\n\u003cli\u003e\n\u003cp\u003e\u003cstrong\u003e‰∏∫‰ªÄ‰πà‰ΩøÁî®One-Hot\u003c/strong\u003e\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eÈÄöËøáÂ∞ÜÁ±ªÂà´Êò†Â∞Ñ‰∏∫ÂêëÈáèÔºåÈÅøÂÖçÊï¥Êï∞ÁºñÁ†ÅÂºïÂÖ•ÁöÑ‰º™Êï∞ÂÄºÂÖ≥Á≥ª„ÄÇ\u003c/li\u003e\n\u003cli\u003eÂêåÊó∂‰øùÁïôÂêÑÁßçÂèØËÉΩÁ±ªÂà´ÁöÑ‰ø°ÊÅØÔºå‰∏î‰ªÖÂú®ÂØπÂ∫î‰ΩçÁΩÆ‰∏∫1ÔºåÂÖ∂‰ªñ‰ΩçÁΩÆ‰∏∫0„ÄÇ\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003e\u003cstrong\u003eÂª∫Á´ãÊò†Â∞ÑÔºö‰ªéÁ±ªÂà´Âà∞Á¥¢Âºï\u003c/strong\u003e\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e‰∏∫ÊØè‰∏™Á±ªÂà´ÂàÜÈÖç‰∏Ä‰∏™ÂîØ‰∏ÄÁ¥¢ÂºïÔºåÈÄöÂ∏∏‰ªé1ÂºÄÂßã„ÄÇ\u003c/li\u003e\n\u003cli\u003eÈ¢ÑÁïôÁ¥¢Âºï0Ë°®Á§∫‚ÄúÊú™Áü•‚ÄùÊàñ‚ÄúÁº∫Â§±‚ÄùÔºåÂØπÂ∫îÂÖ®0ÂêëÈáè„ÄÇ\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003e\u003cstrong\u003eËΩ¨Êç¢‰∏∫One-HotÂêëÈáè\u003c/strong\u003e\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eËã•Á±ªÂà´ÊÄªÊï∞‰∏∫197ÔºåÂàôÁî®197Áª¥ÂêëÈáèË°®Á§∫„ÄÇ\u003c/li\u003e\n\u003cli\u003e‰æãÂ≠êÔºöÁæéÂõΩ \u003ccode\u003e[1, 0, 0, 0, ‚Ä¶]\u003c/code\u003eÔºå ‰∏≠ÂõΩ \u003ccode\u003e[0, 1, 0, 0, ‚Ä¶]\u003c/code\u003e„ÄÇ\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003e\u003cstrong\u003eÁ§∫‰æãÔºöË°®Á§∫‰∏Ä‰∏™‰∫∫ÁöÑÁâπÂæÅ\u003c/strong\u003e\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eÁâπÂæÅÂåÖÂê´ÔºàÂπ¥ÈæÑ, ÊÄßÂà´, ÂõΩÁ±çÔºåÂÖ∂‰∏≠ÂõΩÁ±ç197ÁßçÔºâ\u003c/li\u003e\n\u003cli\u003eÁª¥Â∫¶ÊÄªÂíåÔºö1Áª¥_age + 1Áª¥_gender + 197Áª¥_nationality = 199Áª¥„ÄÇ\u003c/li\u003e\n\u003cli\u003e‰æãÂ¶Ç \u003ccode\u003e(28, Â•≥, ‰∏≠ÂõΩ)\u003c/code\u003e ‚Üí \u003ccode\u003e[28, 0, 0, 1, 0, ‚Ä¶, 0]\u003c/code\u003e„ÄÇ\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003c/ol\u003e\n\u003ch2 id=\"‰∏âÊñáÊú¨Êï∞ÊçÆÂ§ÑÁêÜÊµÅÁ®ã\"\u003e‰∏â„ÄÅÊñáÊú¨Êï∞ÊçÆÂ§ÑÁêÜÊµÅÁ®ã\u003c/h2\u003e\n\u003cp\u003eÊñáÊú¨Âú®Ëá™ÁÑ∂ËØ≠Ë®ÄÂ§ÑÁêÜÔºàNLPÔºâ‰∏≠‰Ωú‰∏∫Â∏∏ËßÅÁöÑÂéüÂßãËæìÂÖ•ÔºåÈúÄË¶ÅÊï∞ÂÄºÂåñÊâçËÉΩÈÄÅÂÖ•Ê®°Âûã„ÄÇ‰∏ÄËà¨Ê≠•È™§Â¶Ç‰∏ãÔºö\u003c/p\u003e\n\u003col\u003e\n\u003cli\u003e\n\u003cp\u003e\u003cstrong\u003eÂàÜËØç (Tokenization)\u003c/strong\u003e\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eÂ∞ÜÊñáÊú¨ÊãÜÂàÜ‰∏∫‰∏Ä‰∏™‰∏™ÂçïËØçÔºàTokenÔºâ„ÄÇ\u003c/li\u003e\n\u003cli\u003e‰æãÂ≠êÔºö\u003ccode\u003e\u0026quot;... to be or not to be...\u0026quot;\u003c/code\u003e ‚Üí \u003ccode\u003e[\u0026quot;...\u0026quot;, \u0026quot;to\u0026quot;, \u0026quot;be\u0026quot;, \u0026quot;or\u0026quot;, \u0026quot;not\u0026quot;, \u0026quot;to\u0026quot;, \u0026quot;be\u0026quot;, \u0026quot;...\u0026quot;]\u003c/code\u003e„ÄÇ\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003e\u003cstrong\u003eÁªüËÆ°ËØçÈ¢ë \u0026amp; ÊûÑÂª∫ËØçÂÖ∏\u003c/strong\u003e\u003c/p\u003e","title":""},{"content":"Text to Sequence ÊñáÊú¨Â§ÑÁêÜ\nStep1: Tokenization\nTokenization breaks a piece of text down into a list of tokens.\nHere, a token is a word. (A token can be a character in some applications.)\nTokenizationËÆ≤Á©∂ÂæàÂ§öÔºå‰æãÂ¶ÇÊòØÂê¶Â∫îËØ•ÊääÂ§ßÂÜôÊîπÊàêÂ∞èÂÜôÂë¢ÔºüËøõË°åtypo correctionÁ≠âÁ≠â\nStep2: Build Dictionary\nUse a dictionary (hash table) to count word frequencies.\nThe dictionary maps word to index.\nÂèØ‰ª•È¶ñÂÖàÁªüËÆ°ËØçÈ¢ëÂéªÊéâ‰ΩéÈ¢ëËØçÔºåÁÑ∂ÂêéËÆ©ÊØè‰∏™ËØçÂØπÂ∫î‰∏Ä‰∏™Ê≠£Êï¥Êï∞ÔºõËøôÊ†∑ÁöÑËØùÔºå‰∏ÄÂè•ËØùÂ∞±ÂèØ‰ª•Áî®‰∏Ä‰∏™Ê≠£Êï¥Êï∞ÂàóË°®Ë°®Á§∫ÔºåËøô‰∏™ÂàóË°®Â∞±Âè´sequenceÔºõÂ¶ÇÊûúÂøÖË¶ÅÂ∞±ËøòÂæóÂÅöone-hot encoding„ÄÇ\nÁªìÊûú\n‰ΩÜÊòØÈïøÂ∫¶‰∏çÁªü‰∏Ä\nStep4: ÂØπÈΩêsequence\nËß£ÂÜ≥ÊñπÊ°àÊòØËøôÊ†∑ÁöÑÔºöÂèØ‰ª•Âõ∫ÂÆöÈïøÂ∫¶‰∏∫wÔºåÂä†ÂÖ•‰∏Ä‰∏™Â∫èÂàóÈïøÂ∫¶Â§™ÈïøÔºåÂ∞±Á†çÊéâÂâçÈù¢ÁöÑËØçÔºåÂè™‰øùÁïôÊúÄÂêéw‰∏™ËØçÔºõÂ¶ÇÊûú‰∏Ä‰∏™Â∫èÂàóÂ§™Áü≠ÔºåÂ∞±ÂÅözero paddingÔºåÁî®0Â°´ÂÖÖ\nËøôÊ†∑‰∏ÄÊù•ÔºåÊâÄÊúâÁöÑÂ∫èÂàóÈïøÂ∫¶Â∞±Áªü‰∏Ä‰∫Ü\nÊñáÊú¨Â§ÑÁêÜÂÆåÊàê‰∫ÜÔºåÊé•‰∏ãÊù•ÊòØword embeddingÔºåÊääÂçïËØçË°®Á§∫‰∏∫‰∏Ä‰∏™‰ΩéÁª¥ÂêëÈáèÔºõ\nÁÑ∂ËÄåËøôÊ†∑ÂÅöÁöÑËØùÔºåÂ¶ÇÊûúÊòØ10000‰∏™ÂçïËØçÔºåÁª¥Â∫¶Â∞±ÊòØ10000Áª¥ÔºåÁª¥Â∫¶Â§™È´ò‰∫ÜÔºõÂõ†Ê≠§Ë¶ÅÂÅöword embeddingÔºõ\nÂÖ∑‰ΩìÂÅöÊ≥ïÂ∞±ÊòØÊääone-hotÂêëÈáèe_iÂíåÂèÇÊï∞Áü©ÈòµpÁõ∏‰πòÔºõÁü©ÈòµPËΩ¨ÁΩÆÁöÑÂ§ßÂ∞èÊòØd x vÔºõdÊòØËØçÂêëÈáèÁöÑÁª¥Â∫¶ÔºõvÊòØÂ≠óÂÖ∏ÈáåËØçÊ±áÁöÑÊï∞ÈáèÔºõÁªìÊûú‰∏∫x_iÔºõx_iÂ∞±ÊòØ‰∏Ä‰∏™ËØçÂêëÈáèÔºõÂ¶ÇÊûúone-hotÂêëÈáèÁöÑÁ¨¨‰∏âË°å‰∏∫1ÔºõÈÇ£‰πàx_iÂ∞±ÊòØPËΩ¨ÁΩÆÁü©ÈòµÁöÑÁ¨¨‰∏âÂàóÔºàÂÖ∂‰ΩôÂàóÈÉΩ‰∏∫0ÔºâÔºõÊâÄ‰ª•PËΩ¨ÁΩÆÊØè‰∏ÄÂàóÈÉΩÊòØ‰∏Ä‰∏™ËØçÂêëÈáèÔºõÊâÄ‰ª•Áü©ÈòµPÊú¨Ë∫´ÁöÑÊØè‰∏ÄË°åÂ∞±ÊòØ‰∏Ä‰∏™ËØçÂêëÈáèÔºõÂÖ∂Ë°åÊï∞‰∏∫vÔºõÂç≥vocabularyÔºåËØçÊ±áÈáèÔºõÊØè‰∏ÄË°åÂØπÂ∫î‰∏Ä‰∏™ÂçïËØçÔºõÁü©ÈòµÁöÑÂàóÊï∞‰∏∫dÔºõdÊòØÁî®Êà∑ÂÜ≥ÂÆöÁöÑÔºõdÁöÑÂ§ßÂ∞è‰ºöÂÜ≥ÂÆöÊú∫Âô®Â≠¶‰π†Ê®°ÂûãÁöÑË°®Áé∞ÔºõÂ∫îËØ•Áî®xxxÊù•ÈÄâÊã©‰∏Ä‰∏™ÊØîËæÉÂ•ΩÁöÑdÔºõ\nÊàë‰ª¨ÁöÑ‰ªªÂä°ÊòØÁúãËØÑËÆ∫ÊòØÊ≠£Èù¢ÁöÑËøòÊòØË¥üÈù¢ÁöÑÔºõÂèÇÊï∞Áü©ÈòµÊòØ‰ªéËÆ≠ÁªÉÊï∞ÊçÆ‰∏≠Â≠¶‰π†Âá∫Êù•ÁöÑÔºåÊâÄ‰ª•Â≠¶Âá∫Êù•ÁöÑËØçÂêëÈáèÊòØÂ∏¶ÊúâÊÑüÊÉÖËâ≤ÂΩ©ÁöÑÔºõÂÅáËÆæËøô‰∫õËØçÂêëÈáèÈÉΩÊòØ‰∫åÁª¥ÁöÑÔºåÂàôÂèØ‰ª•Âú®Âπ≥Èù¢ÂùêÊ†áÁ≥ª‰∏≠Ê†áÂá∫‰∏ãÈù¢ËØçÂêëÈáè\nkerasÊèê‰æõembeddingÂ±ÇÔºõÁî®Êà∑ÂèØ‰ª•ÊåáÂÆövocabularyÂ§ßÂ∞èÂíådÁöÑÂ§ßÂ∞èÔºõ‰ª•ÂèäÊØè‰∏Ä‰∏™sequenceÁöÑÈïøÂ∫¶ÔºõdÊòØÊ†πÊçÆÁÆóÊ≥ïÈÄâÂá∫Êù•ÁöÑ Âà∞Ëøô‰∏ÄÊ≠•ÔºåÊàë‰ª¨Â∑≤ÁªèÂÆåÊàê‰∫ÜÊñáÊú¨Â§ÑÁêÜÂíåword embedding„ÄÇÊé•‰∏ãÊù•Â∞±ÊòØÁî®Logistic Regression for Binary ClassificationÂÅö‰∫åÂàÜÁ±ªÔºõ\n","permalink":"http://localhost:1313/posts/nlp-2/","summary":"\u003ch3 id=\"text-to-sequence\"\u003eText to Sequence\u003c/h3\u003e\n\u003cp\u003eÊñáÊú¨Â§ÑÁêÜ\u003c/p\u003e\n\u003cp\u003eStep1: Tokenization\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\n\u003cp\u003eTokenization breaks a piece of text down into a list of tokens.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003eHere, a token is a word. (A token can be a character in some applications.)\u003c/p\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003eTokenizationËÆ≤Á©∂ÂæàÂ§öÔºå‰æãÂ¶ÇÊòØÂê¶Â∫îËØ•ÊääÂ§ßÂÜôÊîπÊàêÂ∞èÂÜôÂë¢ÔºüËøõË°åtypo correctionÁ≠âÁ≠â\u003c/p\u003e\n\u003cp\u003e\u003cimg alt=\"image-20250322150322238\" loading=\"lazy\" src=\"./NLP-2.assets/image-20250322150322238.png\"\u003e\u003c/p\u003e\n\u003cp\u003eStep2: Build Dictionary\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\n\u003cp\u003eUse a dictionary (hash table) to count word frequencies.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003eThe dictionary maps word to index.\u003c/p\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003eÂèØ‰ª•È¶ñÂÖàÁªüËÆ°ËØçÈ¢ëÂéªÊéâ‰ΩéÈ¢ëËØçÔºåÁÑ∂ÂêéËÆ©ÊØè‰∏™ËØçÂØπÂ∫î‰∏Ä‰∏™Ê≠£Êï¥Êï∞ÔºõËøôÊ†∑ÁöÑËØùÔºå‰∏ÄÂè•ËØùÂ∞±ÂèØ‰ª•Áî®‰∏Ä‰∏™Ê≠£Êï¥Êï∞ÂàóË°®Ë°®Á§∫ÔºåËøô‰∏™ÂàóË°®Â∞±Âè´sequenceÔºõÂ¶ÇÊûúÂøÖË¶ÅÂ∞±ËøòÂæóÂÅöone-hot encoding„ÄÇ\u003cimg alt=\"image-20250322150620890\" loading=\"lazy\" src=\"./NLP-2.assets/image-20250322150620890.png\"\u003e\u003c/p\u003e\n\u003cp\u003eÁªìÊûú\u003c/p\u003e\n\u003cp\u003e\u003cimg alt=\"image-20250322150754528\" loading=\"lazy\" src=\"./NLP-2.assets/image-20250322150754528.png\"\u003e\u003c/p\u003e\n\u003cp\u003e‰ΩÜÊòØÈïøÂ∫¶‰∏çÁªü‰∏Ä\u003c/p\u003e\n\u003cp\u003eStep4: ÂØπÈΩêsequence\u003c/p\u003e\n\u003cp\u003e\u003cimg alt=\"image-20250322150854986\" loading=\"lazy\" src=\"./NLP-2.assets/image-20250322150854986.png\"\u003e\u003c/p\u003e\n\u003cp\u003eËß£ÂÜ≥ÊñπÊ°àÊòØËøôÊ†∑ÁöÑÔºöÂèØ‰ª•Âõ∫ÂÆöÈïøÂ∫¶‰∏∫wÔºåÂä†ÂÖ•‰∏Ä‰∏™Â∫èÂàóÈïøÂ∫¶Â§™ÈïøÔºåÂ∞±Á†çÊéâÂâçÈù¢ÁöÑËØçÔºåÂè™‰øùÁïôÊúÄÂêéw‰∏™ËØçÔºõÂ¶ÇÊûú‰∏Ä‰∏™Â∫èÂàóÂ§™Áü≠ÔºåÂ∞±ÂÅözero paddingÔºåÁî®0Â°´ÂÖÖ\u003c/p\u003e\n\u003cp\u003e\u003cimg alt=\"image-20250322151030119\" loading=\"lazy\" src=\"./NLP-2.assets/image-20250322151030119.png\"\u003e\u003c/p\u003e\n\u003cp\u003eËøôÊ†∑‰∏ÄÊù•ÔºåÊâÄÊúâÁöÑÂ∫èÂàóÈïøÂ∫¶Â∞±Áªü‰∏Ä‰∫Ü\u003c/p\u003e\n\u003cp\u003e\u003cimg alt=\"image-20250322151117125\" loading=\"lazy\" src=\"./NLP-2.assets/image-20250322151117125.png\"\u003e\u003c/p\u003e\n\u003cp\u003eÊñáÊú¨Â§ÑÁêÜÂÆåÊàê‰∫ÜÔºåÊé•‰∏ãÊù•ÊòØword embeddingÔºåÊääÂçïËØçË°®Á§∫‰∏∫‰∏Ä‰∏™‰ΩéÁª¥ÂêëÈáèÔºõ\u003c/p\u003e\n\u003cp\u003e\u003cimg alt=\"image-20250322151252837\" loading=\"lazy\" src=\"./NLP-2.assets/image-20250322151252837.png\"\u003e\u003c/p\u003e","title":""},{"content":"üëã About me Hello! I\u0026rsquo;m Xu Zongsi, a passionate technology enthusiast currently pursuing my Master of Science in ECIC at The University of Hong Kong. With a solid background in Software Engineering from the Beijing Institute of Technology, I specialize in artificial intelligence areas like machine learning, deep learning, natural language processing, computer vision, and reinforcement learning.\nInspired by OpenAI\u0026rsquo;s five-step plan towards superintelligence, I am excited about AGI and have developed a keen interest in LLM agents, MLLM, and knowledge graphs. I see great potential in these fields and aspire to contribute to innovative solutions.\nüìö Education üá≠üá∞ The University of Hong Kong 09/2024 - Expected 11/2025 School of Computing and Data Science Master of Science in Electronic Commerce \u0026amp; Internet Computing Relevant Courses: Machine learning for business and e-commerce, Knowledge graphs, Financial fraud analytics, Internet infrastructure technologies, Website engineering, Blockchain and cryptocurrency, etc. üá®üá≥ Beijing Institute of Technology 09/2020 - 06/2024 School of Computer Science \u0026amp; Technology Bachelor of Engineering in Software Engineering, last two years GPA: 3.7/4 Relevant Courses: Reinforcement Learning, Deep Learning and Computer Vision, Artificial Intelligence and Robot Ethics, Almost Human: Mind, Brain and Artificial Intelligence, Mathematical Analysis for Engineering, Linear Algebra, Probability and Mathematical Statistics, etc. Skills: Python, Java, common data structures, design patterns, machine learning basics and algorithms, Linux, PyTorch, and some development tools (git, conda, etc.). üèÜ Awards \u0026amp; Honors Beijing Institute of Technology Undergraduate Scholarship (Top 20% of Grade) 06/2023 3rd Prize of China International \u0026#34;Internet \u0026#43;\u0026#34; College Student\u0026#39;s Innovation Competition 08/2022 Bronze Prize of \u0026#34;Challenge Cup\u0026#34; Capital University Entrepreneurship Competition 05/2022 üíº Project Experience üîç Online Transaction Fraud Detection 09/2024 ‚Äì 01/2025 Independent project, supervised by Dr. Vivien Chan Focused on addressing financial fraud in e-commerce to enhance the accuracy of transaction anomaly detection, while independently managing the entire case study that included data preprocessing, feature engineering, model building, evaluation, and results analysis. Effectively resolved class imbalance issues using SMOTE and ROSE techniques. Built various models including Logistic Regression, Random Forest, XGBoost, and LightGBM, ultimately selecting the LightGBM model to achieve a recall rate of 95.45% and an AUC of 99.84%. Wrote efficient and maintainable code, enhancing model training and data processing efficiency through parallel computing and logging. ü§ñ Multi-Model Intelligent Text Keyword Extraction System 08/2023 ‚Äì 09/2023 Group project, supervised by Associate Prof. Xiaolin Zhao Designed and implemented an intelligent text summary system that automatically extracts keywords from article titles and abstracts, enhancing the understanding and summarization of text information. Participated in the planning of the technical route and built a hybrid model combining extractive and generative approaches, utilizing advanced natural language processing techniques including KeyBERT, Sentence Transformer, BERT, and T5 models. Responsible for data preprocessing and tokenization, as well as the end-to-end implementation and training of the T5 model, optimizing the model architecture and hyperparameters, achieving satisfactory results after only 3 epochs of training. Model evaluation results showed that the Rouge-1, Rouge-2, and Rouge-L metrics reached 0.6345, 0.5038, and 0.5282, respectively, in the third epoch, validating the model\u0026rsquo;s effectiveness in the summarization task. üéì Cambridge University Machine Learning Summer Project 07/2023 ‚Äì 08/2023 Group project, supervised by Prof. Pietro Li√≤ Participated in the Cambridge University deep learning summer project, focusing on deep reinforcement learning; explored multi-agent learning algorithms across different environments. Reproduced the Multi-Agent Deep Deterministic Policy Gradient (MADDPG) algorithm in the Simple Adversary environment and studied the effect of agent numbers on convergence speed and stability, finding optimal stability at 21 agents. Designed and implemented comparative experiments inspired by the Rainbow algorithm, assessing target network strategies versus the Double Deep Q-Network (Double DQN). The results demonstrated that Double DQN significantly enhanced convergence speed, optimizing the overall learning process. Co-authored a group project paper on agent numbers and strategies effectiveness in multi-agent systems, achieving a score of 71% in the summer program (the highest in my group) and a \u0026ldquo;First Class\u0026rdquo; classification in the UK grading system. üëÅÔ∏è Deep Learning and Computer Vision Semester Project 09/2022 ‚Äì 12/2022 Independent project, supervised by Associate Prof. Guangyu Gao Designed and implemented a waste classifier using the ResNet model to improve classification accuracy and reduce resource waste. The project also enhanced understanding of transfer learning techniques with ResNet. Collected a dataset of 16 waste categories and preprocessed the images for uniformity and standardization, incorporating data augmentation techniques to enhance the dataset. Conducted experiments using ResNet34 and ResNet50 models through transfer learning, accelerating network convergence by leveraging pretrained weights. During training, techniques such as Batch Normalization and Dropout were applied to mitigate the risk of overfitting. The final model achieved an accuracy of 90% on the training set, while the performance on the test set was 61%, indicating a significant overfitting phenomenon during the training process. üéì Internship ‚öõÔ∏è Beijing Academy of Quantum Information Science 08/2023 ‚Äì 01/2024 Research Intern at Quantum Computation Department Proposed a quantum convolution kernel design based on variational quantum circuits and developed a universal quantum convolution layer, successfully integrating it into classical CNN architectures such as VGG, GoogLeNet, and ResNet. Developed and evaluated various hybrid models, including a simple model named HQCCNN-2, which achieved 84.45% accuracy on the FashionMNIST dataset, surpassing the traditional CNN\u0026rsquo;s 80.72%. This demonstrates the effectiveness of the quantum convolution layer in improving model performance. Tested on a real quantum computer further validated the effectiveness of the hybrid model, demonstrating the viable integration of quantum computing with deep learning, and highlighting the potential for leveraging quantum properties to enhance model performance. üèÖ Competition Experience ü•â China International \u0026#34;Internet \u0026#43;\u0026#34; College Students\u0026#39; Innovation Competition 08/2022 üõ°Ô∏è Zhongke Ushield: Deep Learning-based Face Privacy Protection Authentication System Responsible for constructing a localized facial feature extraction engine based on MobileFaceNet, ensuring feature extraction is completed on end devices (such as mobile phones and cameras), guaranteeing that raw data does not leave the domain and is not stored, thus enhancing user privacy protection while improving recognition efficiency. ü•â \u0026#34;Challenge Cup\u0026#34; Capital University Entrepreneurship Competition 05/2022 üå≥ Smart Orchard Responsible for the development of the fruit detection, ripeness prediction, and pest identification system, using deep convolutional neural network (CNN) technology for intelligent monitoring of crop growth conditions. Applied advanced object detection algorithms such as Faster R-CNN and YOLO to achieve high precision in apple detection and ripeness assessment, with an accuracy rate exceeding 90%, significantly enhancing the intelligence level of orchard management. Built and trained a dedicated dataset containing various pest samples, optimizing pest detection accuracy through data preprocessing (such as image normalization and resizing) and data augmentation techniques (like rotation, flipping, and noise addition), enabling the real-time monitoring system to accurately identify over 80% of pests, providing effective scientific maintenance recommendations to help farmers reduce crop losses. üìã Extracurricular Activities Vice President, Cyber Security Club, Beijing Institute of Technology 09/2021-09/2022 Backbone, Media Center of the Student Union of Beijing Institute of Technology 10/2020-06/2021 üì´ Contact üìß Email: zongsi.xu@outlook.com üëî LinkedIn: Zongsi (Tristan) Xu üíª GitHub: BaizeXS üìç Location: Hong Kong SAR, China ","permalink":"http://localhost:1313/resume/","summary":"Personal resume of Zongsi (Tristan) Xu","title":"Zongsi (Tristan) Xu"},{"content":"‰∏Ä„ÄÅÊï∞ÂÄºÁâπÂæÅ‰∏éÁ±ªÂà´ÁâπÂæÅ Êï∞ÂÄºÁâπÂæÅ (Numeric Features) ÂÖ∑ÊúâÂèØÂä†ÂáèÁöÑÊÑè‰πâÔºå‰∏îÂ≠òÂú®Â§ßÂ∞èÈ°∫Â∫è„ÄÇ ‰æãÂ≠êÔºöÂπ¥ÈæÑ„ÄÅÊ∏©Â∫¶Á≠â„ÄÇÂèØ‰ª•Áõ¥Êé•‰øùÁïôÂÖ∂Êï¥Êï∞ÊàñÊµÆÁÇπÊï∞ÂΩ¢Âºè‰æõÊ®°Âûã‰ΩøÁî®„ÄÇ Á±ªÂà´ÁâπÂæÅ (Categorical Features) Êï∞ÊçÆÂÄºÁ¶ªÊï£Ôºå‰∏çÂÖ∑Â§á‚ÄúÊï∞ÂÄºÂ§ßÂ∞è‚ÄùÈó¥ÁöÑÂèØÊØîÊÑè‰πâ„ÄÇ ‰æãÂ≠êÔºöÂõΩÁ±çÔºàÁæéÂõΩ/‰∏≠ÂõΩ/Âç∞Â∫¶Á≠âÔºâ„ÄÅÊÄßÂà´ÔºàÁî∑/Â•≥ÔºâÁ≠â„ÄÇ ÈóÆÈ¢òÔºöËã•‰ªÖÁî®Êï¥Êï∞Ë°®Á§∫ÔºàÁæéÂõΩ=1, ‰∏≠ÂõΩ=2ÔºâÔºå‰ºöÂºïÂÖ•ÈîôËØØÁöÑÊï∞ÂÄºËøêÁÆóÂÖ≥Á≥ªÔºåÂ¶Ç ‚ÄúÁæéÂõΩ + ‰∏≠ÂõΩ = Âç∞Â∫¶‚Äù„ÄÇ ‰∫å„ÄÅOne-HotÁºñÁ†ÅÁöÑÂä®Êú∫‰∏éÊµÅÁ®ã ‰∏∫‰ªÄ‰πà‰ΩøÁî®One-Hot\nÈÄöËøáÂ∞ÜÁ±ªÂà´Êò†Â∞Ñ‰∏∫ÂêëÈáèÔºåÈÅøÂÖçÊï¥Êï∞ÁºñÁ†ÅÂºïÂÖ•ÁöÑ‰º™Êï∞ÂÄºÂÖ≥Á≥ª„ÄÇ ÂêåÊó∂‰øùÁïôÂêÑÁßçÂèØËÉΩÁ±ªÂà´ÁöÑ‰ø°ÊÅØÔºå‰∏î‰ªÖÂú®ÂØπÂ∫î‰ΩçÁΩÆ‰∏∫1ÔºåÂÖ∂‰ªñ‰ΩçÁΩÆ‰∏∫0„ÄÇ Âª∫Á´ãÊò†Â∞ÑÔºö‰ªéÁ±ªÂà´Âà∞Á¥¢Âºï\n‰∏∫ÊØè‰∏™Á±ªÂà´ÂàÜÈÖç‰∏Ä‰∏™ÂîØ‰∏ÄÁ¥¢ÂºïÔºåÈÄöÂ∏∏‰ªé1ÂºÄÂßã„ÄÇ È¢ÑÁïôÁ¥¢Âºï0Ë°®Á§∫‚ÄúÊú™Áü•‚ÄùÊàñ‚ÄúÁº∫Â§±‚ÄùÔºåÂØπÂ∫îÂÖ®0ÂêëÈáè„ÄÇ ËΩ¨Êç¢‰∏∫One-HotÂêëÈáè\nËã•Á±ªÂà´ÊÄªÊï∞‰∏∫197ÔºåÂàôÁî®197Áª¥ÂêëÈáèË°®Á§∫„ÄÇ ‰æãÂ≠êÔºöÁæéÂõΩ [1, 0, 0, 0, ‚Ä¶]Ôºå ‰∏≠ÂõΩ [0, 1, 0, 0, ‚Ä¶]„ÄÇ Á§∫‰æãÔºöË°®Á§∫‰∏Ä‰∏™‰∫∫ÁöÑÁâπÂæÅ\nÁâπÂæÅÂåÖÂê´ÔºàÂπ¥ÈæÑ, ÊÄßÂà´, ÂõΩÁ±çÔºåÂÖ∂‰∏≠ÂõΩÁ±ç197ÁßçÔºâ Áª¥Â∫¶ÊÄªÂíåÔºö1Áª¥_age + 1Áª¥_gender + 197Áª¥_nationality = 199Áª¥„ÄÇ ‰æãÂ¶Ç (28, Â•≥, ‰∏≠ÂõΩ) ‚Üí [28, 0, 0, 1, 0, ‚Ä¶, 0]„ÄÇ ‰∏â„ÄÅÊñáÊú¨Êï∞ÊçÆÂ§ÑÁêÜÊµÅÁ®ã ÊñáÊú¨Âú®Ëá™ÁÑ∂ËØ≠Ë®ÄÂ§ÑÁêÜÔºàNLPÔºâ‰∏≠‰Ωú‰∏∫Â∏∏ËßÅÁöÑÂéüÂßãËæìÂÖ•ÔºåÈúÄË¶ÅÊï∞ÂÄºÂåñÊâçËÉΩÈÄÅÂÖ•Ê®°Âûã„ÄÇ‰∏ÄËà¨Ê≠•È™§Â¶Ç‰∏ãÔºö\nÂàÜËØç (Tokenization)\nÂ∞ÜÊñáÊú¨ÊãÜÂàÜ‰∏∫‰∏Ä‰∏™‰∏™ÂçïËØçÔºàTokenÔºâ„ÄÇ ‰æãÂ≠êÔºö\u0026quot;... to be or not to be...\u0026quot; ‚Üí [\u0026quot;...\u0026quot;, \u0026quot;to\u0026quot;, \u0026quot;be\u0026quot;, \u0026quot;or\u0026quot;, \u0026quot;not\u0026quot;, \u0026quot;to\u0026quot;, \u0026quot;be\u0026quot;, \u0026quot;...\u0026quot;]„ÄÇ ÁªüËÆ°ËØçÈ¢ë \u0026amp; ÊûÑÂª∫ËØçÂÖ∏\nËØçÈ¢ëÁªüËÆ° Áî®ÂìàÂ∏åË°®/Â≠óÂÖ∏ËÆ∞ÂΩïÊØè‰∏™ÂçïËØçÂá∫Áé∞Ê¨°Êï∞„ÄÇ ÈÅçÂéÜÊñáÊú¨Êó∂ÔºåËã•ÂçïËØçÂ∞öÊú™ÂÖ•Ë°®ÔºåÂàôÊñ∞Âª∫ËÆ∞ÂΩïÔºõËã•Â∑≤Â≠òÂú®ÔºåÂàôËÆ°Êï∞+1„ÄÇ ÊéíÂ∫è‰∏éÁ¥¢Âºï ÊåâËØçÈ¢ëÈôçÂ∫èÊéíÂ∫èÔºåËØçÈ¢ëÊúÄÈ´òÁöÑÂçïËØçÊéíÂú®ÂâçÈù¢„ÄÇ Á¥¢Âºï‰ªé1ÂºÄÂßãÔºå0ÁïôÁªô‚ÄúÊú™Áü•‚Äù„ÄÇ ËØçÂÖ∏ËßÑÊ®°ÔºàvocabularyÔºâÂèØËßÜÈúÄÊ±ÇÊà™Êñ≠Ôºà‰æãÂ¶ÇÂè™‰øùÁïôTop 10kÔºâ„ÄÇ ‰∏∫‰ªÄ‰πàÁßªÈô§‰ΩéÈ¢ëËØç ‰ΩéÈ¢ëËØçÂèØËÉΩÊòØÊãºÂÜôÈîôËØØ„ÄÅÁΩïËßÅ‰∫∫ÂêçÁ≠âÔºåÂØπÊ®°ÂûãÂ∏ÆÂä©ÊúâÈôê„ÄÇ ÂáèÂ∞ëËØçÂÖ∏ËßÑÊ®°ÂèØÈôç‰ΩéËøêÁÆóÂºÄÈîÄ„ÄÅÂä†Âø´Ê®°ÂûãËÆ≠ÁªÉ‰∏éÊé®ÁêÜÈÄüÂ∫¶„ÄÇ Áã¨ÁÉ≠ÁºñÁ†Å (One-Hot Encoding)\nÂ∞ÜÊØè‰∏™ÂçïËØçÊò†Â∞Ñ‰∏∫ËØçÂÖ∏‰∏≠ÁöÑÁ¥¢ÂºïÂêéÔºàÂ¶Ç [2, 4, 1, 8, ‚Ä¶]ÔºâÔºåÂèØËøõ‰∏ÄÊ≠•ËΩ¨Êç¢ÊàêOne-HotÂêëÈáè„ÄÇ One-HotÁª¥Â∫¶ÂèñÂÜ≥‰∫é‰øùÁïô‰∏ãÊù•ÁöÑËØçÂÖ∏Â§ßÂ∞èÔºà‰æãÂ¶Ç1‰∏áÔºâ„ÄÇ Êú™Êî∂ÂΩïÂçïËØçÂèØËÉΩÁõ¥Êé•ÂøΩÁï•ÔºåÊàñÁªü‰∏ÄÁî®Á¥¢Âºï0‰ª£Êõø„ÄÇ Âõõ„ÄÅÊ†∏ÂøÉÊî∂Ëé∑‰∏éÂ∫îÁî® Á±ªÂà´ÁâπÂæÅÂøÖÈúÄÊï∞ÂÄºÂåñÔºö\n‰ΩøÁî®Êï¥Êï∞1,2,3‚Ä¶‰ªÖË°®Á§∫Á±ªÂà´‚ÄúÊ†áËØÜ‚ÄùÔºåÂπ∂‰∏ç‰ª£Ë°®ÂÆÉ‰ª¨ÂèØËøõË°åÊï∞ÂÄºËøêÁÆó„ÄÇ Âõ†Ê≠§ÈúÄË¶ÅOne-HotÁ≠âÁºñÁ†ÅÊñπÂºèÔºåÈÅøÂÖçÊï∞ÂÄºËØØËß£„ÄÇ ÊñáÊú¨Êï∞ÊçÆÈ¢ÑÂ§ÑÁêÜÔºö\nÂàÜËØç„ÄÅËØçÈ¢ëÁªüËÆ°„ÄÅÊûÑÂª∫ËØçÂÖ∏„ÄÅÁ¥¢ÂºïÂåñ„ÄÅOne-HotÊàñÂÖ∂‰ªñÊñπÂºèÔºàÂ¶ÇËØçÂµåÂÖ•ÔºâÊòØÂ∏∏ËßÅÊµÅÁ®ã„ÄÇ Ê≠£Á°ÆÁöÑÊñáÊú¨È¢ÑÂ§ÑÁêÜÂèØÊòæËëóÂΩ±ÂìçÊ®°ÂûãÊÄßËÉΩÂíåÊïàÁéá„ÄÇ ‰øùÁïôÊú™Áü•Á¥¢ÂºïÔºö\n‰øùËØÅÂØπÁº∫Â§±Êï∞ÊçÆÊàñÂ≠óÂÖ∏Â§ñÊñ∞ËØçËÉΩÊúâÂü∫Êú¨ÁöÑË°®Á§∫ÔºåÊèêÂçáÊ®°ÂûãÂÆπÈîôÊÄß„ÄÇ ÂÆûÈôÖ‰ΩøÁî®Ôºö\nÂØπ‰∫éÂ∞èËßÑÊ®°Á±ªÂà´ÂèØÁõ¥Êé•One-HotÁºñÁ†ÅÔºõÂØπ‰∫éËØçÂÖ∏ÂæàÂ§ßÁöÑÂú∫ÊôØÔºåÈÄöÂ∏∏‰ºöËøõ‰∏ÄÊ≠•ËÄÉËôëËØçÂµåÂÖ•ÔºàWord EmbeddingÔºâÊàñÈ¢ÑËÆ≠ÁªÉËØ≠Ë®ÄÊ®°Âûã„ÄÇ ","permalink":"http://localhost:1313/posts/nlp-1/","summary":"\u003ch2 id=\"‰∏ÄÊï∞ÂÄºÁâπÂæÅ‰∏éÁ±ªÂà´ÁâπÂæÅ\"\u003e‰∏Ä„ÄÅÊï∞ÂÄºÁâπÂæÅ‰∏éÁ±ªÂà´ÁâπÂæÅ\u003c/h2\u003e\n\u003col\u003e\n\u003cli\u003e\u003cstrong\u003eÊï∞ÂÄºÁâπÂæÅ (Numeric Features)\u003c/strong\u003e\n\u003cul\u003e\n\u003cli\u003eÂÖ∑ÊúâÂèØÂä†ÂáèÁöÑÊÑè‰πâÔºå‰∏îÂ≠òÂú®Â§ßÂ∞èÈ°∫Â∫è„ÄÇ\u003c/li\u003e\n\u003cli\u003e‰æãÂ≠êÔºöÂπ¥ÈæÑ„ÄÅÊ∏©Â∫¶Á≠â„ÄÇÂèØ‰ª•Áõ¥Êé•‰øùÁïôÂÖ∂Êï¥Êï∞ÊàñÊµÆÁÇπÊï∞ÂΩ¢Âºè‰æõÊ®°Âûã‰ΩøÁî®„ÄÇ\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003eÁ±ªÂà´ÁâπÂæÅ (Categorical Features)\u003c/strong\u003e\n\u003cul\u003e\n\u003cli\u003eÊï∞ÊçÆÂÄºÁ¶ªÊï£Ôºå‰∏çÂÖ∑Â§á‚ÄúÊï∞ÂÄºÂ§ßÂ∞è‚ÄùÈó¥ÁöÑÂèØÊØîÊÑè‰πâ„ÄÇ\u003c/li\u003e\n\u003cli\u003e‰æãÂ≠êÔºöÂõΩÁ±çÔºàÁæéÂõΩ/‰∏≠ÂõΩ/Âç∞Â∫¶Á≠âÔºâ„ÄÅÊÄßÂà´ÔºàÁî∑/Â•≥ÔºâÁ≠â„ÄÇ\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003eÈóÆÈ¢ò\u003c/strong\u003eÔºöËã•‰ªÖÁî®Êï¥Êï∞Ë°®Á§∫ÔºàÁæéÂõΩ=1, ‰∏≠ÂõΩ=2ÔºâÔºå‰ºöÂºïÂÖ•ÈîôËØØÁöÑÊï∞ÂÄºËøêÁÆóÂÖ≥Á≥ªÔºåÂ¶Ç ‚ÄúÁæéÂõΩ + ‰∏≠ÂõΩ = Âç∞Â∫¶‚Äù„ÄÇ\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003c/ol\u003e\n\u003ch2 id=\"‰∫åone-hotÁºñÁ†ÅÁöÑÂä®Êú∫‰∏éÊµÅÁ®ã\"\u003e‰∫å„ÄÅOne-HotÁºñÁ†ÅÁöÑÂä®Êú∫‰∏éÊµÅÁ®ã\u003c/h2\u003e\n\u003col\u003e\n\u003cli\u003e\n\u003cp\u003e\u003cstrong\u003e‰∏∫‰ªÄ‰πà‰ΩøÁî®One-Hot\u003c/strong\u003e\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eÈÄöËøáÂ∞ÜÁ±ªÂà´Êò†Â∞Ñ‰∏∫ÂêëÈáèÔºåÈÅøÂÖçÊï¥Êï∞ÁºñÁ†ÅÂºïÂÖ•ÁöÑ‰º™Êï∞ÂÄºÂÖ≥Á≥ª„ÄÇ\u003c/li\u003e\n\u003cli\u003eÂêåÊó∂‰øùÁïôÂêÑÁßçÂèØËÉΩÁ±ªÂà´ÁöÑ‰ø°ÊÅØÔºå‰∏î‰ªÖÂú®ÂØπÂ∫î‰ΩçÁΩÆ‰∏∫1ÔºåÂÖ∂‰ªñ‰ΩçÁΩÆ‰∏∫0„ÄÇ\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003e\u003cstrong\u003eÂª∫Á´ãÊò†Â∞ÑÔºö‰ªéÁ±ªÂà´Âà∞Á¥¢Âºï\u003c/strong\u003e\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e‰∏∫ÊØè‰∏™Á±ªÂà´ÂàÜÈÖç‰∏Ä‰∏™ÂîØ‰∏ÄÁ¥¢ÂºïÔºåÈÄöÂ∏∏‰ªé1ÂºÄÂßã„ÄÇ\u003c/li\u003e\n\u003cli\u003eÈ¢ÑÁïôÁ¥¢Âºï0Ë°®Á§∫‚ÄúÊú™Áü•‚ÄùÊàñ‚ÄúÁº∫Â§±‚ÄùÔºåÂØπÂ∫îÂÖ®0ÂêëÈáè„ÄÇ\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003e\u003cstrong\u003eËΩ¨Êç¢‰∏∫One-HotÂêëÈáè\u003c/strong\u003e\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eËã•Á±ªÂà´ÊÄªÊï∞‰∏∫197ÔºåÂàôÁî®197Áª¥ÂêëÈáèË°®Á§∫„ÄÇ\u003c/li\u003e\n\u003cli\u003e‰æãÂ≠êÔºöÁæéÂõΩ \u003ccode\u003e[1, 0, 0, 0, ‚Ä¶]\u003c/code\u003eÔºå ‰∏≠ÂõΩ \u003ccode\u003e[0, 1, 0, 0, ‚Ä¶]\u003c/code\u003e„ÄÇ\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003e\u003cstrong\u003eÁ§∫‰æãÔºöË°®Á§∫‰∏Ä‰∏™‰∫∫ÁöÑÁâπÂæÅ\u003c/strong\u003e\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eÁâπÂæÅÂåÖÂê´ÔºàÂπ¥ÈæÑ, ÊÄßÂà´, ÂõΩÁ±çÔºåÂÖ∂‰∏≠ÂõΩÁ±ç197ÁßçÔºâ\u003c/li\u003e\n\u003cli\u003eÁª¥Â∫¶ÊÄªÂíåÔºö1Áª¥_age + 1Áª¥_gender + 197Áª¥_nationality = 199Áª¥„ÄÇ\u003c/li\u003e\n\u003cli\u003e‰æãÂ¶Ç \u003ccode\u003e(28, Â•≥, ‰∏≠ÂõΩ)\u003c/code\u003e ‚Üí \u003ccode\u003e[28, 0, 0, 1, 0, ‚Ä¶, 0]\u003c/code\u003e„ÄÇ\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003c/ol\u003e\n\u003ch2 id=\"‰∏âÊñáÊú¨Êï∞ÊçÆÂ§ÑÁêÜÊµÅÁ®ã\"\u003e‰∏â„ÄÅÊñáÊú¨Êï∞ÊçÆÂ§ÑÁêÜÊµÅÁ®ã\u003c/h2\u003e\n\u003cp\u003eÊñáÊú¨Âú®Ëá™ÁÑ∂ËØ≠Ë®ÄÂ§ÑÁêÜÔºàNLPÔºâ‰∏≠‰Ωú‰∏∫Â∏∏ËßÅÁöÑÂéüÂßãËæìÂÖ•ÔºåÈúÄË¶ÅÊï∞ÂÄºÂåñÊâçËÉΩÈÄÅÂÖ•Ê®°Âûã„ÄÇ‰∏ÄËà¨Ê≠•È™§Â¶Ç‰∏ãÔºö\u003c/p\u003e\n\u003col\u003e\n\u003cli\u003e\n\u003cp\u003e\u003cstrong\u003eÂàÜËØç (Tokenization)\u003c/strong\u003e\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eÂ∞ÜÊñáÊú¨ÊãÜÂàÜ‰∏∫‰∏Ä‰∏™‰∏™ÂçïËØçÔºàTokenÔºâ„ÄÇ\u003c/li\u003e\n\u003cli\u003e‰æãÂ≠êÔºö\u003ccode\u003e\u0026quot;... to be or not to be...\u0026quot;\u003c/code\u003e ‚Üí \u003ccode\u003e[\u0026quot;...\u0026quot;, \u0026quot;to\u0026quot;, \u0026quot;be\u0026quot;, \u0026quot;or\u0026quot;, \u0026quot;not\u0026quot;, \u0026quot;to\u0026quot;, \u0026quot;be\u0026quot;, \u0026quot;...\u0026quot;]\u003c/code\u003e„ÄÇ\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003e\u003cstrong\u003eÁªüËÆ°ËØçÈ¢ë \u0026amp; ÊûÑÂª∫ËØçÂÖ∏\u003c/strong\u003e\u003c/p\u003e","title":""},{"content":"Text to Sequence ÊñáÊú¨Â§ÑÁêÜ\nStep1: Tokenization\nTokenization breaks a piece of text down into a list of tokens.\nHere, a token is a word. (A token can be a character in some applications.)\nTokenizationËÆ≤Á©∂ÂæàÂ§öÔºå‰æãÂ¶ÇÊòØÂê¶Â∫îËØ•ÊääÂ§ßÂÜôÊîπÊàêÂ∞èÂÜôÂë¢ÔºüËøõË°åtypo correctionÁ≠âÁ≠â\nStep2: Build Dictionary\nUse a dictionary (hash table) to count word frequencies.\nThe dictionary maps word to index.\nÂèØ‰ª•È¶ñÂÖàÁªüËÆ°ËØçÈ¢ëÂéªÊéâ‰ΩéÈ¢ëËØçÔºåÁÑ∂ÂêéËÆ©ÊØè‰∏™ËØçÂØπÂ∫î‰∏Ä‰∏™Ê≠£Êï¥Êï∞ÔºõËøôÊ†∑ÁöÑËØùÔºå‰∏ÄÂè•ËØùÂ∞±ÂèØ‰ª•Áî®‰∏Ä‰∏™Ê≠£Êï¥Êï∞ÂàóË°®Ë°®Á§∫ÔºåËøô‰∏™ÂàóË°®Â∞±Âè´sequenceÔºõÂ¶ÇÊûúÂøÖË¶ÅÂ∞±ËøòÂæóÂÅöone-hot encoding„ÄÇ\nÁªìÊûú\n‰ΩÜÊòØÈïøÂ∫¶‰∏çÁªü‰∏Ä\nStep4: ÂØπÈΩêsequence\nËß£ÂÜ≥ÊñπÊ°àÊòØËøôÊ†∑ÁöÑÔºöÂèØ‰ª•Âõ∫ÂÆöÈïøÂ∫¶‰∏∫wÔºåÂä†ÂÖ•‰∏Ä‰∏™Â∫èÂàóÈïøÂ∫¶Â§™ÈïøÔºåÂ∞±Á†çÊéâÂâçÈù¢ÁöÑËØçÔºåÂè™‰øùÁïôÊúÄÂêéw‰∏™ËØçÔºõÂ¶ÇÊûú‰∏Ä‰∏™Â∫èÂàóÂ§™Áü≠ÔºåÂ∞±ÂÅözero paddingÔºåÁî®0Â°´ÂÖÖ\nËøôÊ†∑‰∏ÄÊù•ÔºåÊâÄÊúâÁöÑÂ∫èÂàóÈïøÂ∫¶Â∞±Áªü‰∏Ä‰∫Ü\nÊñáÊú¨Â§ÑÁêÜÂÆåÊàê‰∫ÜÔºåÊé•‰∏ãÊù•ÊòØword embeddingÔºåÊääÂçïËØçË°®Á§∫‰∏∫‰∏Ä‰∏™‰ΩéÁª¥ÂêëÈáèÔºõ\nÁÑ∂ËÄåËøôÊ†∑ÂÅöÁöÑËØùÔºåÂ¶ÇÊûúÊòØ10000‰∏™ÂçïËØçÔºåÁª¥Â∫¶Â∞±ÊòØ10000Áª¥ÔºåÁª¥Â∫¶Â§™È´ò‰∫ÜÔºõÂõ†Ê≠§Ë¶ÅÂÅöword embeddingÔºõ\nÂÖ∑‰ΩìÂÅöÊ≥ïÂ∞±ÊòØÊääone-hotÂêëÈáèe_iÂíåÂèÇÊï∞Áü©ÈòµpÁõ∏‰πòÔºõÁü©ÈòµPËΩ¨ÁΩÆÁöÑÂ§ßÂ∞èÊòØd x vÔºõdÊòØËØçÂêëÈáèÁöÑÁª¥Â∫¶ÔºõvÊòØÂ≠óÂÖ∏ÈáåËØçÊ±áÁöÑÊï∞ÈáèÔºõÁªìÊûú‰∏∫x_iÔºõx_iÂ∞±ÊòØ‰∏Ä‰∏™ËØçÂêëÈáèÔºõÂ¶ÇÊûúone-hotÂêëÈáèÁöÑÁ¨¨‰∏âË°å‰∏∫1ÔºõÈÇ£‰πàx_iÂ∞±ÊòØPËΩ¨ÁΩÆÁü©ÈòµÁöÑÁ¨¨‰∏âÂàóÔºàÂÖ∂‰ΩôÂàóÈÉΩ‰∏∫0ÔºâÔºõÊâÄ‰ª•PËΩ¨ÁΩÆÊØè‰∏ÄÂàóÈÉΩÊòØ‰∏Ä‰∏™ËØçÂêëÈáèÔºõÊâÄ‰ª•Áü©ÈòµPÊú¨Ë∫´ÁöÑÊØè‰∏ÄË°åÂ∞±ÊòØ‰∏Ä‰∏™ËØçÂêëÈáèÔºõÂÖ∂Ë°åÊï∞‰∏∫vÔºõÂç≥vocabularyÔºåËØçÊ±áÈáèÔºõÊØè‰∏ÄË°åÂØπÂ∫î‰∏Ä‰∏™ÂçïËØçÔºõÁü©ÈòµÁöÑÂàóÊï∞‰∏∫dÔºõdÊòØÁî®Êà∑ÂÜ≥ÂÆöÁöÑÔºõdÁöÑÂ§ßÂ∞è‰ºöÂÜ≥ÂÆöÊú∫Âô®Â≠¶‰π†Ê®°ÂûãÁöÑË°®Áé∞ÔºõÂ∫îËØ•Áî®xxxÊù•ÈÄâÊã©‰∏Ä‰∏™ÊØîËæÉÂ•ΩÁöÑdÔºõ\nÊàë‰ª¨ÁöÑ‰ªªÂä°ÊòØÁúãËØÑËÆ∫ÊòØÊ≠£Èù¢ÁöÑËøòÊòØË¥üÈù¢ÁöÑÔºõÂèÇÊï∞Áü©ÈòµÊòØ‰ªéËÆ≠ÁªÉÊï∞ÊçÆ‰∏≠Â≠¶‰π†Âá∫Êù•ÁöÑÔºåÊâÄ‰ª•Â≠¶Âá∫Êù•ÁöÑËØçÂêëÈáèÊòØÂ∏¶ÊúâÊÑüÊÉÖËâ≤ÂΩ©ÁöÑÔºõÂÅáËÆæËøô‰∫õËØçÂêëÈáèÈÉΩÊòØ‰∫åÁª¥ÁöÑÔºåÂàôÂèØ‰ª•Âú®Âπ≥Èù¢ÂùêÊ†áÁ≥ª‰∏≠Ê†áÂá∫‰∏ãÈù¢ËØçÂêëÈáè\nkerasÊèê‰æõembeddingÂ±ÇÔºõÁî®Êà∑ÂèØ‰ª•ÊåáÂÆövocabularyÂ§ßÂ∞èÂíådÁöÑÂ§ßÂ∞èÔºõ‰ª•ÂèäÊØè‰∏Ä‰∏™sequenceÁöÑÈïøÂ∫¶ÔºõdÊòØÊ†πÊçÆÁÆóÊ≥ïÈÄâÂá∫Êù•ÁöÑ Âà∞Ëøô‰∏ÄÊ≠•ÔºåÊàë‰ª¨Â∑≤ÁªèÂÆåÊàê‰∫ÜÊñáÊú¨Â§ÑÁêÜÂíåword embedding„ÄÇÊé•‰∏ãÊù•Â∞±ÊòØÁî®Logistic Regression for Binary ClassificationÂÅö‰∫åÂàÜÁ±ªÔºõ\n","permalink":"http://localhost:1313/posts/nlp-2/","summary":"\u003ch3 id=\"text-to-sequence\"\u003eText to Sequence\u003c/h3\u003e\n\u003cp\u003eÊñáÊú¨Â§ÑÁêÜ\u003c/p\u003e\n\u003cp\u003eStep1: Tokenization\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\n\u003cp\u003eTokenization breaks a piece of text down into a list of tokens.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003eHere, a token is a word. (A token can be a character in some applications.)\u003c/p\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003eTokenizationËÆ≤Á©∂ÂæàÂ§öÔºå‰æãÂ¶ÇÊòØÂê¶Â∫îËØ•ÊääÂ§ßÂÜôÊîπÊàêÂ∞èÂÜôÂë¢ÔºüËøõË°åtypo correctionÁ≠âÁ≠â\u003c/p\u003e\n\u003cp\u003e\u003cimg alt=\"image-20250322150322238\" loading=\"lazy\" src=\"./NLP-2.assets/image-20250322150322238.png\"\u003e\u003c/p\u003e\n\u003cp\u003eStep2: Build Dictionary\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\n\u003cp\u003eUse a dictionary (hash table) to count word frequencies.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003eThe dictionary maps word to index.\u003c/p\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003eÂèØ‰ª•È¶ñÂÖàÁªüËÆ°ËØçÈ¢ëÂéªÊéâ‰ΩéÈ¢ëËØçÔºåÁÑ∂ÂêéËÆ©ÊØè‰∏™ËØçÂØπÂ∫î‰∏Ä‰∏™Ê≠£Êï¥Êï∞ÔºõËøôÊ†∑ÁöÑËØùÔºå‰∏ÄÂè•ËØùÂ∞±ÂèØ‰ª•Áî®‰∏Ä‰∏™Ê≠£Êï¥Êï∞ÂàóË°®Ë°®Á§∫ÔºåËøô‰∏™ÂàóË°®Â∞±Âè´sequenceÔºõÂ¶ÇÊûúÂøÖË¶ÅÂ∞±ËøòÂæóÂÅöone-hot encoding„ÄÇ\u003cimg alt=\"image-20250322150620890\" loading=\"lazy\" src=\"./NLP-2.assets/image-20250322150620890.png\"\u003e\u003c/p\u003e\n\u003cp\u003eÁªìÊûú\u003c/p\u003e\n\u003cp\u003e\u003cimg alt=\"image-20250322150754528\" loading=\"lazy\" src=\"./NLP-2.assets/image-20250322150754528.png\"\u003e\u003c/p\u003e\n\u003cp\u003e‰ΩÜÊòØÈïøÂ∫¶‰∏çÁªü‰∏Ä\u003c/p\u003e\n\u003cp\u003eStep4: ÂØπÈΩêsequence\u003c/p\u003e\n\u003cp\u003e\u003cimg alt=\"image-20250322150854986\" loading=\"lazy\" src=\"./NLP-2.assets/image-20250322150854986.png\"\u003e\u003c/p\u003e\n\u003cp\u003eËß£ÂÜ≥ÊñπÊ°àÊòØËøôÊ†∑ÁöÑÔºöÂèØ‰ª•Âõ∫ÂÆöÈïøÂ∫¶‰∏∫wÔºåÂä†ÂÖ•‰∏Ä‰∏™Â∫èÂàóÈïøÂ∫¶Â§™ÈïøÔºåÂ∞±Á†çÊéâÂâçÈù¢ÁöÑËØçÔºåÂè™‰øùÁïôÊúÄÂêéw‰∏™ËØçÔºõÂ¶ÇÊûú‰∏Ä‰∏™Â∫èÂàóÂ§™Áü≠ÔºåÂ∞±ÂÅözero paddingÔºåÁî®0Â°´ÂÖÖ\u003c/p\u003e\n\u003cp\u003e\u003cimg alt=\"image-20250322151030119\" loading=\"lazy\" src=\"./NLP-2.assets/image-20250322151030119.png\"\u003e\u003c/p\u003e\n\u003cp\u003eËøôÊ†∑‰∏ÄÊù•ÔºåÊâÄÊúâÁöÑÂ∫èÂàóÈïøÂ∫¶Â∞±Áªü‰∏Ä‰∫Ü\u003c/p\u003e\n\u003cp\u003e\u003cimg alt=\"image-20250322151117125\" loading=\"lazy\" src=\"./NLP-2.assets/image-20250322151117125.png\"\u003e\u003c/p\u003e\n\u003cp\u003eÊñáÊú¨Â§ÑÁêÜÂÆåÊàê‰∫ÜÔºåÊé•‰∏ãÊù•ÊòØword embeddingÔºåÊääÂçïËØçË°®Á§∫‰∏∫‰∏Ä‰∏™‰ΩéÁª¥ÂêëÈáèÔºõ\u003c/p\u003e\n\u003cp\u003e\u003cimg alt=\"image-20250322151252837\" loading=\"lazy\" src=\"./NLP-2.assets/image-20250322151252837.png\"\u003e\u003c/p\u003e","title":""},{"content":"üëã About me Hello! I\u0026rsquo;m Xu Zongsi, a passionate technology enthusiast currently pursuing my Master of Science in ECIC at The University of Hong Kong. With a solid background in Software Engineering from the Beijing Institute of Technology, I specialize in artificial intelligence areas like machine learning, deep learning, natural language processing, computer vision, and reinforcement learning.\nInspired by OpenAI\u0026rsquo;s five-step plan towards superintelligence, I am excited about AGI and have developed a keen interest in LLM agents, MLLM, and knowledge graphs. I see great potential in these fields and aspire to contribute to innovative solutions.\nüìö Education üá≠üá∞ The University of Hong Kong 09/2024 - Expected 11/2025 School of Computing and Data Science Master of Science in Electronic Commerce \u0026amp; Internet Computing Relevant Courses: Machine learning for business and e-commerce, Knowledge graphs, Financial fraud analytics, Internet infrastructure technologies, Website engineering, Blockchain and cryptocurrency, etc. üá®üá≥ Beijing Institute of Technology 09/2020 - 06/2024 School of Computer Science \u0026amp; Technology Bachelor of Engineering in Software Engineering, last two years GPA: 3.7/4 Relevant Courses: Reinforcement Learning, Deep Learning and Computer Vision, Artificial Intelligence and Robot Ethics, Almost Human: Mind, Brain and Artificial Intelligence, Mathematical Analysis for Engineering, Linear Algebra, Probability and Mathematical Statistics, etc. Skills: Python, Java, common data structures, design patterns, machine learning basics and algorithms, Linux, PyTorch, and some development tools (git, conda, etc.). üèÜ Awards \u0026amp; Honors Beijing Institute of Technology Undergraduate Scholarship (Top 20% of Grade) 06/2023 3rd Prize of China International \u0026#34;Internet \u0026#43;\u0026#34; College Student\u0026#39;s Innovation Competition 08/2022 Bronze Prize of \u0026#34;Challenge Cup\u0026#34; Capital University Entrepreneurship Competition 05/2022 üíº Project Experience üîç Online Transaction Fraud Detection 09/2024 ‚Äì 01/2025 Independent project, supervised by Dr. Vivien Chan Focused on addressing financial fraud in e-commerce to enhance the accuracy of transaction anomaly detection, while independently managing the entire case study that included data preprocessing, feature engineering, model building, evaluation, and results analysis. Effectively resolved class imbalance issues using SMOTE and ROSE techniques. Built various models including Logistic Regression, Random Forest, XGBoost, and LightGBM, ultimately selecting the LightGBM model to achieve a recall rate of 95.45% and an AUC of 99.84%. Wrote efficient and maintainable code, enhancing model training and data processing efficiency through parallel computing and logging. ü§ñ Multi-Model Intelligent Text Keyword Extraction System 08/2023 ‚Äì 09/2023 Group project, supervised by Associate Prof. Xiaolin Zhao Designed and implemented an intelligent text summary system that automatically extracts keywords from article titles and abstracts, enhancing the understanding and summarization of text information. Participated in the planning of the technical route and built a hybrid model combining extractive and generative approaches, utilizing advanced natural language processing techniques including KeyBERT, Sentence Transformer, BERT, and T5 models. Responsible for data preprocessing and tokenization, as well as the end-to-end implementation and training of the T5 model, optimizing the model architecture and hyperparameters, achieving satisfactory results after only 3 epochs of training. Model evaluation results showed that the Rouge-1, Rouge-2, and Rouge-L metrics reached 0.6345, 0.5038, and 0.5282, respectively, in the third epoch, validating the model\u0026rsquo;s effectiveness in the summarization task. üéì Cambridge University Machine Learning Summer Project 07/2023 ‚Äì 08/2023 Group project, supervised by Prof. Pietro Li√≤ Participated in the Cambridge University deep learning summer project, focusing on deep reinforcement learning; explored multi-agent learning algorithms across different environments. Reproduced the Multi-Agent Deep Deterministic Policy Gradient (MADDPG) algorithm in the Simple Adversary environment and studied the effect of agent numbers on convergence speed and stability, finding optimal stability at 21 agents. Designed and implemented comparative experiments inspired by the Rainbow algorithm, assessing target network strategies versus the Double Deep Q-Network (Double DQN). The results demonstrated that Double DQN significantly enhanced convergence speed, optimizing the overall learning process. Co-authored a group project paper on agent numbers and strategies effectiveness in multi-agent systems, achieving a score of 71% in the summer program (the highest in my group) and a \u0026ldquo;First Class\u0026rdquo; classification in the UK grading system. üëÅÔ∏è Deep Learning and Computer Vision Semester Project 09/2022 ‚Äì 12/2022 Independent project, supervised by Associate Prof. Guangyu Gao Designed and implemented a waste classifier using the ResNet model to improve classification accuracy and reduce resource waste. The project also enhanced understanding of transfer learning techniques with ResNet. Collected a dataset of 16 waste categories and preprocessed the images for uniformity and standardization, incorporating data augmentation techniques to enhance the dataset. Conducted experiments using ResNet34 and ResNet50 models through transfer learning, accelerating network convergence by leveraging pretrained weights. During training, techniques such as Batch Normalization and Dropout were applied to mitigate the risk of overfitting. The final model achieved an accuracy of 90% on the training set, while the performance on the test set was 61%, indicating a significant overfitting phenomenon during the training process. üéì Internship ‚öõÔ∏è Beijing Academy of Quantum Information Science 08/2023 ‚Äì 01/2024 Research Intern at Quantum Computation Department Proposed a quantum convolution kernel design based on variational quantum circuits and developed a universal quantum convolution layer, successfully integrating it into classical CNN architectures such as VGG, GoogLeNet, and ResNet. Developed and evaluated various hybrid models, including a simple model named HQCCNN-2, which achieved 84.45% accuracy on the FashionMNIST dataset, surpassing the traditional CNN\u0026rsquo;s 80.72%. This demonstrates the effectiveness of the quantum convolution layer in improving model performance. Tested on a real quantum computer further validated the effectiveness of the hybrid model, demonstrating the viable integration of quantum computing with deep learning, and highlighting the potential for leveraging quantum properties to enhance model performance. üèÖ Competition Experience ü•â China International \u0026#34;Internet \u0026#43;\u0026#34; College Students\u0026#39; Innovation Competition 08/2022 üõ°Ô∏è Zhongke Ushield: Deep Learning-based Face Privacy Protection Authentication System Responsible for constructing a localized facial feature extraction engine based on MobileFaceNet, ensuring feature extraction is completed on end devices (such as mobile phones and cameras), guaranteeing that raw data does not leave the domain and is not stored, thus enhancing user privacy protection while improving recognition efficiency. ü•â \u0026#34;Challenge Cup\u0026#34; Capital University Entrepreneurship Competition 05/2022 üå≥ Smart Orchard Responsible for the development of the fruit detection, ripeness prediction, and pest identification system, using deep convolutional neural network (CNN) technology for intelligent monitoring of crop growth conditions. Applied advanced object detection algorithms such as Faster R-CNN and YOLO to achieve high precision in apple detection and ripeness assessment, with an accuracy rate exceeding 90%, significantly enhancing the intelligence level of orchard management. Built and trained a dedicated dataset containing various pest samples, optimizing pest detection accuracy through data preprocessing (such as image normalization and resizing) and data augmentation techniques (like rotation, flipping, and noise addition), enabling the real-time monitoring system to accurately identify over 80% of pests, providing effective scientific maintenance recommendations to help farmers reduce crop losses. üìã Extracurricular Activities Vice President, Cyber Security Club, Beijing Institute of Technology 09/2021-09/2022 Backbone, Media Center of the Student Union of Beijing Institute of Technology 10/2020-06/2021 üì´ Contact üìß Email: zongsi.xu@outlook.com üëî LinkedIn: Zongsi (Tristan) Xu üíª GitHub: BaizeXS üìç Location: Hong Kong SAR, China ","permalink":"http://localhost:1313/resume/","summary":"Personal resume of Zongsi (Tristan) Xu","title":"Zongsi (Tristan) Xu"},{"content":"‰∏Ä„ÄÅÊï∞ÂÄºÁâπÂæÅ‰∏éÁ±ªÂà´ÁâπÂæÅ Êï∞ÂÄºÁâπÂæÅ (Numeric Features) ÂÖ∑ÊúâÂèØÂä†ÂáèÁöÑÊÑè‰πâÔºå‰∏îÂ≠òÂú®Â§ßÂ∞èÈ°∫Â∫è„ÄÇ ‰æãÂ≠êÔºöÂπ¥ÈæÑ„ÄÅÊ∏©Â∫¶Á≠â„ÄÇÂèØ‰ª•Áõ¥Êé•‰øùÁïôÂÖ∂Êï¥Êï∞ÊàñÊµÆÁÇπÊï∞ÂΩ¢Âºè‰æõÊ®°Âûã‰ΩøÁî®„ÄÇ Á±ªÂà´ÁâπÂæÅ (Categorical Features) Êï∞ÊçÆÂÄºÁ¶ªÊï£Ôºå‰∏çÂÖ∑Â§á‚ÄúÊï∞ÂÄºÂ§ßÂ∞è‚ÄùÈó¥ÁöÑÂèØÊØîÊÑè‰πâ„ÄÇ ‰æãÂ≠êÔºöÂõΩÁ±çÔºàÁæéÂõΩ/‰∏≠ÂõΩ/Âç∞Â∫¶Á≠âÔºâ„ÄÅÊÄßÂà´ÔºàÁî∑/Â•≥ÔºâÁ≠â„ÄÇ ÈóÆÈ¢òÔºöËã•‰ªÖÁî®Êï¥Êï∞Ë°®Á§∫ÔºàÁæéÂõΩ=1, ‰∏≠ÂõΩ=2ÔºâÔºå‰ºöÂºïÂÖ•ÈîôËØØÁöÑÊï∞ÂÄºËøêÁÆóÂÖ≥Á≥ªÔºåÂ¶Ç ‚ÄúÁæéÂõΩ + ‰∏≠ÂõΩ = Âç∞Â∫¶‚Äù„ÄÇ ‰∫å„ÄÅOne-HotÁºñÁ†ÅÁöÑÂä®Êú∫‰∏éÊµÅÁ®ã ‰∏∫‰ªÄ‰πà‰ΩøÁî®One-Hot\nÈÄöËøáÂ∞ÜÁ±ªÂà´Êò†Â∞Ñ‰∏∫ÂêëÈáèÔºåÈÅøÂÖçÊï¥Êï∞ÁºñÁ†ÅÂºïÂÖ•ÁöÑ‰º™Êï∞ÂÄºÂÖ≥Á≥ª„ÄÇ ÂêåÊó∂‰øùÁïôÂêÑÁßçÂèØËÉΩÁ±ªÂà´ÁöÑ‰ø°ÊÅØÔºå‰∏î‰ªÖÂú®ÂØπÂ∫î‰ΩçÁΩÆ‰∏∫1ÔºåÂÖ∂‰ªñ‰ΩçÁΩÆ‰∏∫0„ÄÇ Âª∫Á´ãÊò†Â∞ÑÔºö‰ªéÁ±ªÂà´Âà∞Á¥¢Âºï\n‰∏∫ÊØè‰∏™Á±ªÂà´ÂàÜÈÖç‰∏Ä‰∏™ÂîØ‰∏ÄÁ¥¢ÂºïÔºåÈÄöÂ∏∏‰ªé1ÂºÄÂßã„ÄÇ È¢ÑÁïôÁ¥¢Âºï0Ë°®Á§∫‚ÄúÊú™Áü•‚ÄùÊàñ‚ÄúÁº∫Â§±‚ÄùÔºåÂØπÂ∫îÂÖ®0ÂêëÈáè„ÄÇ ËΩ¨Êç¢‰∏∫One-HotÂêëÈáè\nËã•Á±ªÂà´ÊÄªÊï∞‰∏∫197ÔºåÂàôÁî®197Áª¥ÂêëÈáèË°®Á§∫„ÄÇ ‰æãÂ≠êÔºöÁæéÂõΩ [1, 0, 0, 0, ‚Ä¶]Ôºå ‰∏≠ÂõΩ [0, 1, 0, 0, ‚Ä¶]„ÄÇ Á§∫‰æãÔºöË°®Á§∫‰∏Ä‰∏™‰∫∫ÁöÑÁâπÂæÅ\nÁâπÂæÅÂåÖÂê´ÔºàÂπ¥ÈæÑ, ÊÄßÂà´, ÂõΩÁ±çÔºåÂÖ∂‰∏≠ÂõΩÁ±ç197ÁßçÔºâ Áª¥Â∫¶ÊÄªÂíåÔºö1Áª¥_age + 1Áª¥_gender + 197Áª¥_nationality = 199Áª¥„ÄÇ ‰æãÂ¶Ç (28, Â•≥, ‰∏≠ÂõΩ) ‚Üí [28, 0, 0, 1, 0, ‚Ä¶, 0]„ÄÇ ‰∏â„ÄÅÊñáÊú¨Êï∞ÊçÆÂ§ÑÁêÜÊµÅÁ®ã ÊñáÊú¨Âú®Ëá™ÁÑ∂ËØ≠Ë®ÄÂ§ÑÁêÜÔºàNLPÔºâ‰∏≠‰Ωú‰∏∫Â∏∏ËßÅÁöÑÂéüÂßãËæìÂÖ•ÔºåÈúÄË¶ÅÊï∞ÂÄºÂåñÊâçËÉΩÈÄÅÂÖ•Ê®°Âûã„ÄÇ‰∏ÄËà¨Ê≠•È™§Â¶Ç‰∏ãÔºö\nÂàÜËØç (Tokenization)\nÂ∞ÜÊñáÊú¨ÊãÜÂàÜ‰∏∫‰∏Ä‰∏™‰∏™ÂçïËØçÔºàTokenÔºâ„ÄÇ ‰æãÂ≠êÔºö\u0026quot;... to be or not to be...\u0026quot; ‚Üí [\u0026quot;...\u0026quot;, \u0026quot;to\u0026quot;, \u0026quot;be\u0026quot;, \u0026quot;or\u0026quot;, \u0026quot;not\u0026quot;, \u0026quot;to\u0026quot;, \u0026quot;be\u0026quot;, \u0026quot;...\u0026quot;]„ÄÇ ÁªüËÆ°ËØçÈ¢ë \u0026amp; ÊûÑÂª∫ËØçÂÖ∏\nËØçÈ¢ëÁªüËÆ° Áî®ÂìàÂ∏åË°®/Â≠óÂÖ∏ËÆ∞ÂΩïÊØè‰∏™ÂçïËØçÂá∫Áé∞Ê¨°Êï∞„ÄÇ ÈÅçÂéÜÊñáÊú¨Êó∂ÔºåËã•ÂçïËØçÂ∞öÊú™ÂÖ•Ë°®ÔºåÂàôÊñ∞Âª∫ËÆ∞ÂΩïÔºõËã•Â∑≤Â≠òÂú®ÔºåÂàôËÆ°Êï∞+1„ÄÇ ÊéíÂ∫è‰∏éÁ¥¢Âºï ÊåâËØçÈ¢ëÈôçÂ∫èÊéíÂ∫èÔºåËØçÈ¢ëÊúÄÈ´òÁöÑÂçïËØçÊéíÂú®ÂâçÈù¢„ÄÇ Á¥¢Âºï‰ªé1ÂºÄÂßãÔºå0ÁïôÁªô‚ÄúÊú™Áü•‚Äù„ÄÇ ËØçÂÖ∏ËßÑÊ®°ÔºàvocabularyÔºâÂèØËßÜÈúÄÊ±ÇÊà™Êñ≠Ôºà‰æãÂ¶ÇÂè™‰øùÁïôTop 10kÔºâ„ÄÇ ‰∏∫‰ªÄ‰πàÁßªÈô§‰ΩéÈ¢ëËØç ‰ΩéÈ¢ëËØçÂèØËÉΩÊòØÊãºÂÜôÈîôËØØ„ÄÅÁΩïËßÅ‰∫∫ÂêçÁ≠âÔºåÂØπÊ®°ÂûãÂ∏ÆÂä©ÊúâÈôê„ÄÇ ÂáèÂ∞ëËØçÂÖ∏ËßÑÊ®°ÂèØÈôç‰ΩéËøêÁÆóÂºÄÈîÄ„ÄÅÂä†Âø´Ê®°ÂûãËÆ≠ÁªÉ‰∏éÊé®ÁêÜÈÄüÂ∫¶„ÄÇ Áã¨ÁÉ≠ÁºñÁ†Å (One-Hot Encoding)\nÂ∞ÜÊØè‰∏™ÂçïËØçÊò†Â∞Ñ‰∏∫ËØçÂÖ∏‰∏≠ÁöÑÁ¥¢ÂºïÂêéÔºàÂ¶Ç [2, 4, 1, 8, ‚Ä¶]ÔºâÔºåÂèØËøõ‰∏ÄÊ≠•ËΩ¨Êç¢ÊàêOne-HotÂêëÈáè„ÄÇ One-HotÁª¥Â∫¶ÂèñÂÜ≥‰∫é‰øùÁïô‰∏ãÊù•ÁöÑËØçÂÖ∏Â§ßÂ∞èÔºà‰æãÂ¶Ç1‰∏áÔºâ„ÄÇ Êú™Êî∂ÂΩïÂçïËØçÂèØËÉΩÁõ¥Êé•ÂøΩÁï•ÔºåÊàñÁªü‰∏ÄÁî®Á¥¢Âºï0‰ª£Êõø„ÄÇ Âõõ„ÄÅÊ†∏ÂøÉÊî∂Ëé∑‰∏éÂ∫îÁî® Á±ªÂà´ÁâπÂæÅÂøÖÈúÄÊï∞ÂÄºÂåñÔºö\n‰ΩøÁî®Êï¥Êï∞1,2,3‚Ä¶‰ªÖË°®Á§∫Á±ªÂà´‚ÄúÊ†áËØÜ‚ÄùÔºåÂπ∂‰∏ç‰ª£Ë°®ÂÆÉ‰ª¨ÂèØËøõË°åÊï∞ÂÄºËøêÁÆó„ÄÇ Âõ†Ê≠§ÈúÄË¶ÅOne-HotÁ≠âÁºñÁ†ÅÊñπÂºèÔºåÈÅøÂÖçÊï∞ÂÄºËØØËß£„ÄÇ ÊñáÊú¨Êï∞ÊçÆÈ¢ÑÂ§ÑÁêÜÔºö\nÂàÜËØç„ÄÅËØçÈ¢ëÁªüËÆ°„ÄÅÊûÑÂª∫ËØçÂÖ∏„ÄÅÁ¥¢ÂºïÂåñ„ÄÅOne-HotÊàñÂÖ∂‰ªñÊñπÂºèÔºàÂ¶ÇËØçÂµåÂÖ•ÔºâÊòØÂ∏∏ËßÅÊµÅÁ®ã„ÄÇ Ê≠£Á°ÆÁöÑÊñáÊú¨È¢ÑÂ§ÑÁêÜÂèØÊòæËëóÂΩ±ÂìçÊ®°ÂûãÊÄßËÉΩÂíåÊïàÁéá„ÄÇ ‰øùÁïôÊú™Áü•Á¥¢ÂºïÔºö\n‰øùËØÅÂØπÁº∫Â§±Êï∞ÊçÆÊàñÂ≠óÂÖ∏Â§ñÊñ∞ËØçËÉΩÊúâÂü∫Êú¨ÁöÑË°®Á§∫ÔºåÊèêÂçáÊ®°ÂûãÂÆπÈîôÊÄß„ÄÇ ÂÆûÈôÖ‰ΩøÁî®Ôºö\nÂØπ‰∫éÂ∞èËßÑÊ®°Á±ªÂà´ÂèØÁõ¥Êé•One-HotÁºñÁ†ÅÔºõÂØπ‰∫éËØçÂÖ∏ÂæàÂ§ßÁöÑÂú∫ÊôØÔºåÈÄöÂ∏∏‰ºöËøõ‰∏ÄÊ≠•ËÄÉËôëËØçÂµåÂÖ•ÔºàWord EmbeddingÔºâÊàñÈ¢ÑËÆ≠ÁªÉËØ≠Ë®ÄÊ®°Âûã„ÄÇ ","permalink":"http://localhost:1313/posts/nlp-1/","summary":"\u003ch2 id=\"‰∏ÄÊï∞ÂÄºÁâπÂæÅ‰∏éÁ±ªÂà´ÁâπÂæÅ\"\u003e‰∏Ä„ÄÅÊï∞ÂÄºÁâπÂæÅ‰∏éÁ±ªÂà´ÁâπÂæÅ\u003c/h2\u003e\n\u003col\u003e\n\u003cli\u003e\u003cstrong\u003eÊï∞ÂÄºÁâπÂæÅ (Numeric Features)\u003c/strong\u003e\n\u003cul\u003e\n\u003cli\u003eÂÖ∑ÊúâÂèØÂä†ÂáèÁöÑÊÑè‰πâÔºå‰∏îÂ≠òÂú®Â§ßÂ∞èÈ°∫Â∫è„ÄÇ\u003c/li\u003e\n\u003cli\u003e‰æãÂ≠êÔºöÂπ¥ÈæÑ„ÄÅÊ∏©Â∫¶Á≠â„ÄÇÂèØ‰ª•Áõ¥Êé•‰øùÁïôÂÖ∂Êï¥Êï∞ÊàñÊµÆÁÇπÊï∞ÂΩ¢Âºè‰æõÊ®°Âûã‰ΩøÁî®„ÄÇ\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003eÁ±ªÂà´ÁâπÂæÅ (Categorical Features)\u003c/strong\u003e\n\u003cul\u003e\n\u003cli\u003eÊï∞ÊçÆÂÄºÁ¶ªÊï£Ôºå‰∏çÂÖ∑Â§á‚ÄúÊï∞ÂÄºÂ§ßÂ∞è‚ÄùÈó¥ÁöÑÂèØÊØîÊÑè‰πâ„ÄÇ\u003c/li\u003e\n\u003cli\u003e‰æãÂ≠êÔºöÂõΩÁ±çÔºàÁæéÂõΩ/‰∏≠ÂõΩ/Âç∞Â∫¶Á≠âÔºâ„ÄÅÊÄßÂà´ÔºàÁî∑/Â•≥ÔºâÁ≠â„ÄÇ\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003eÈóÆÈ¢ò\u003c/strong\u003eÔºöËã•‰ªÖÁî®Êï¥Êï∞Ë°®Á§∫ÔºàÁæéÂõΩ=1, ‰∏≠ÂõΩ=2ÔºâÔºå‰ºöÂºïÂÖ•ÈîôËØØÁöÑÊï∞ÂÄºËøêÁÆóÂÖ≥Á≥ªÔºåÂ¶Ç ‚ÄúÁæéÂõΩ + ‰∏≠ÂõΩ = Âç∞Â∫¶‚Äù„ÄÇ\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003c/ol\u003e\n\u003ch2 id=\"‰∫åone-hotÁºñÁ†ÅÁöÑÂä®Êú∫‰∏éÊµÅÁ®ã\"\u003e‰∫å„ÄÅOne-HotÁºñÁ†ÅÁöÑÂä®Êú∫‰∏éÊµÅÁ®ã\u003c/h2\u003e\n\u003col\u003e\n\u003cli\u003e\n\u003cp\u003e\u003cstrong\u003e‰∏∫‰ªÄ‰πà‰ΩøÁî®One-Hot\u003c/strong\u003e\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eÈÄöËøáÂ∞ÜÁ±ªÂà´Êò†Â∞Ñ‰∏∫ÂêëÈáèÔºåÈÅøÂÖçÊï¥Êï∞ÁºñÁ†ÅÂºïÂÖ•ÁöÑ‰º™Êï∞ÂÄºÂÖ≥Á≥ª„ÄÇ\u003c/li\u003e\n\u003cli\u003eÂêåÊó∂‰øùÁïôÂêÑÁßçÂèØËÉΩÁ±ªÂà´ÁöÑ‰ø°ÊÅØÔºå‰∏î‰ªÖÂú®ÂØπÂ∫î‰ΩçÁΩÆ‰∏∫1ÔºåÂÖ∂‰ªñ‰ΩçÁΩÆ‰∏∫0„ÄÇ\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003e\u003cstrong\u003eÂª∫Á´ãÊò†Â∞ÑÔºö‰ªéÁ±ªÂà´Âà∞Á¥¢Âºï\u003c/strong\u003e\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e‰∏∫ÊØè‰∏™Á±ªÂà´ÂàÜÈÖç‰∏Ä‰∏™ÂîØ‰∏ÄÁ¥¢ÂºïÔºåÈÄöÂ∏∏‰ªé1ÂºÄÂßã„ÄÇ\u003c/li\u003e\n\u003cli\u003eÈ¢ÑÁïôÁ¥¢Âºï0Ë°®Á§∫‚ÄúÊú™Áü•‚ÄùÊàñ‚ÄúÁº∫Â§±‚ÄùÔºåÂØπÂ∫îÂÖ®0ÂêëÈáè„ÄÇ\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003e\u003cstrong\u003eËΩ¨Êç¢‰∏∫One-HotÂêëÈáè\u003c/strong\u003e\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eËã•Á±ªÂà´ÊÄªÊï∞‰∏∫197ÔºåÂàôÁî®197Áª¥ÂêëÈáèË°®Á§∫„ÄÇ\u003c/li\u003e\n\u003cli\u003e‰æãÂ≠êÔºöÁæéÂõΩ \u003ccode\u003e[1, 0, 0, 0, ‚Ä¶]\u003c/code\u003eÔºå ‰∏≠ÂõΩ \u003ccode\u003e[0, 1, 0, 0, ‚Ä¶]\u003c/code\u003e„ÄÇ\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003e\u003cstrong\u003eÁ§∫‰æãÔºöË°®Á§∫‰∏Ä‰∏™‰∫∫ÁöÑÁâπÂæÅ\u003c/strong\u003e\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eÁâπÂæÅÂåÖÂê´ÔºàÂπ¥ÈæÑ, ÊÄßÂà´, ÂõΩÁ±çÔºåÂÖ∂‰∏≠ÂõΩÁ±ç197ÁßçÔºâ\u003c/li\u003e\n\u003cli\u003eÁª¥Â∫¶ÊÄªÂíåÔºö1Áª¥_age + 1Áª¥_gender + 197Áª¥_nationality = 199Áª¥„ÄÇ\u003c/li\u003e\n\u003cli\u003e‰æãÂ¶Ç \u003ccode\u003e(28, Â•≥, ‰∏≠ÂõΩ)\u003c/code\u003e ‚Üí \u003ccode\u003e[28, 0, 0, 1, 0, ‚Ä¶, 0]\u003c/code\u003e„ÄÇ\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003c/ol\u003e\n\u003ch2 id=\"‰∏âÊñáÊú¨Êï∞ÊçÆÂ§ÑÁêÜÊµÅÁ®ã\"\u003e‰∏â„ÄÅÊñáÊú¨Êï∞ÊçÆÂ§ÑÁêÜÊµÅÁ®ã\u003c/h2\u003e\n\u003cp\u003eÊñáÊú¨Âú®Ëá™ÁÑ∂ËØ≠Ë®ÄÂ§ÑÁêÜÔºàNLPÔºâ‰∏≠‰Ωú‰∏∫Â∏∏ËßÅÁöÑÂéüÂßãËæìÂÖ•ÔºåÈúÄË¶ÅÊï∞ÂÄºÂåñÊâçËÉΩÈÄÅÂÖ•Ê®°Âûã„ÄÇ‰∏ÄËà¨Ê≠•È™§Â¶Ç‰∏ãÔºö\u003c/p\u003e\n\u003col\u003e\n\u003cli\u003e\n\u003cp\u003e\u003cstrong\u003eÂàÜËØç (Tokenization)\u003c/strong\u003e\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eÂ∞ÜÊñáÊú¨ÊãÜÂàÜ‰∏∫‰∏Ä‰∏™‰∏™ÂçïËØçÔºàTokenÔºâ„ÄÇ\u003c/li\u003e\n\u003cli\u003e‰æãÂ≠êÔºö\u003ccode\u003e\u0026quot;... to be or not to be...\u0026quot;\u003c/code\u003e ‚Üí \u003ccode\u003e[\u0026quot;...\u0026quot;, \u0026quot;to\u0026quot;, \u0026quot;be\u0026quot;, \u0026quot;or\u0026quot;, \u0026quot;not\u0026quot;, \u0026quot;to\u0026quot;, \u0026quot;be\u0026quot;, \u0026quot;...\u0026quot;]\u003c/code\u003e„ÄÇ\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003e\u003cstrong\u003eÁªüËÆ°ËØçÈ¢ë \u0026amp; ÊûÑÂª∫ËØçÂÖ∏\u003c/strong\u003e\u003c/p\u003e","title":""},{"content":"Text to Sequence ÊñáÊú¨Â§ÑÁêÜ\nStep1: Tokenization\nTokenization breaks a piece of text down into a list of tokens.\nHere, a token is a word. (A token can be a character in some applications.)\nTokenizationËÆ≤Á©∂ÂæàÂ§öÔºå‰æãÂ¶ÇÊòØÂê¶Â∫îËØ•ÊääÂ§ßÂÜôÊîπÊàêÂ∞èÂÜôÂë¢ÔºüËøõË°åtypo correctionÁ≠âÁ≠â\nStep2: Build Dictionary\nUse a dictionary (hash table) to count word frequencies.\nThe dictionary maps word to index.\nÂèØ‰ª•È¶ñÂÖàÁªüËÆ°ËØçÈ¢ëÂéªÊéâ‰ΩéÈ¢ëËØçÔºåÁÑ∂ÂêéËÆ©ÊØè‰∏™ËØçÂØπÂ∫î‰∏Ä‰∏™Ê≠£Êï¥Êï∞ÔºõËøôÊ†∑ÁöÑËØùÔºå‰∏ÄÂè•ËØùÂ∞±ÂèØ‰ª•Áî®‰∏Ä‰∏™Ê≠£Êï¥Êï∞ÂàóË°®Ë°®Á§∫ÔºåËøô‰∏™ÂàóË°®Â∞±Âè´sequenceÔºõÂ¶ÇÊûúÂøÖË¶ÅÂ∞±ËøòÂæóÂÅöone-hot encoding„ÄÇ\nÁªìÊûú\n‰ΩÜÊòØÈïøÂ∫¶‰∏çÁªü‰∏Ä\nStep4: ÂØπÈΩêsequence\nËß£ÂÜ≥ÊñπÊ°àÊòØËøôÊ†∑ÁöÑÔºöÂèØ‰ª•Âõ∫ÂÆöÈïøÂ∫¶‰∏∫wÔºåÂä†ÂÖ•‰∏Ä‰∏™Â∫èÂàóÈïøÂ∫¶Â§™ÈïøÔºåÂ∞±Á†çÊéâÂâçÈù¢ÁöÑËØçÔºåÂè™‰øùÁïôÊúÄÂêéw‰∏™ËØçÔºõÂ¶ÇÊûú‰∏Ä‰∏™Â∫èÂàóÂ§™Áü≠ÔºåÂ∞±ÂÅözero paddingÔºåÁî®0Â°´ÂÖÖ\nËøôÊ†∑‰∏ÄÊù•ÔºåÊâÄÊúâÁöÑÂ∫èÂàóÈïøÂ∫¶Â∞±Áªü‰∏Ä‰∫Ü\nÊñáÊú¨Â§ÑÁêÜÂÆåÊàê‰∫ÜÔºåÊé•‰∏ãÊù•ÊòØword embeddingÔºåÊääÂçïËØçË°®Á§∫‰∏∫‰∏Ä‰∏™‰ΩéÁª¥ÂêëÈáèÔºõ\nÁÑ∂ËÄåËøôÊ†∑ÂÅöÁöÑËØùÔºåÂ¶ÇÊûúÊòØ10000‰∏™ÂçïËØçÔºåÁª¥Â∫¶Â∞±ÊòØ10000Áª¥ÔºåÁª¥Â∫¶Â§™È´ò‰∫ÜÔºõÂõ†Ê≠§Ë¶ÅÂÅöword embeddingÔºõ\nÂÖ∑‰ΩìÂÅöÊ≥ïÂ∞±ÊòØÊääone-hotÂêëÈáèe_iÂíåÂèÇÊï∞Áü©ÈòµpÁõ∏‰πòÔºõÁü©ÈòµPËΩ¨ÁΩÆÁöÑÂ§ßÂ∞èÊòØd x vÔºõdÊòØËØçÂêëÈáèÁöÑÁª¥Â∫¶ÔºõvÊòØÂ≠óÂÖ∏ÈáåËØçÊ±áÁöÑÊï∞ÈáèÔºõÁªìÊûú‰∏∫x_iÔºõx_iÂ∞±ÊòØ‰∏Ä‰∏™ËØçÂêëÈáèÔºõÂ¶ÇÊûúone-hotÂêëÈáèÁöÑÁ¨¨‰∏âË°å‰∏∫1ÔºõÈÇ£‰πàx_iÂ∞±ÊòØPËΩ¨ÁΩÆÁü©ÈòµÁöÑÁ¨¨‰∏âÂàóÔºàÂÖ∂‰ΩôÂàóÈÉΩ‰∏∫0ÔºâÔºõÊâÄ‰ª•PËΩ¨ÁΩÆÊØè‰∏ÄÂàóÈÉΩÊòØ‰∏Ä‰∏™ËØçÂêëÈáèÔºõÊâÄ‰ª•Áü©ÈòµPÊú¨Ë∫´ÁöÑÊØè‰∏ÄË°åÂ∞±ÊòØ‰∏Ä‰∏™ËØçÂêëÈáèÔºõÂÖ∂Ë°åÊï∞‰∏∫vÔºõÂç≥vocabularyÔºåËØçÊ±áÈáèÔºõÊØè‰∏ÄË°åÂØπÂ∫î‰∏Ä‰∏™ÂçïËØçÔºõÁü©ÈòµÁöÑÂàóÊï∞‰∏∫dÔºõdÊòØÁî®Êà∑ÂÜ≥ÂÆöÁöÑÔºõdÁöÑÂ§ßÂ∞è‰ºöÂÜ≥ÂÆöÊú∫Âô®Â≠¶‰π†Ê®°ÂûãÁöÑË°®Áé∞ÔºõÂ∫îËØ•Áî®xxxÊù•ÈÄâÊã©‰∏Ä‰∏™ÊØîËæÉÂ•ΩÁöÑdÔºõ\nÊàë‰ª¨ÁöÑ‰ªªÂä°ÊòØÁúãËØÑËÆ∫ÊòØÊ≠£Èù¢ÁöÑËøòÊòØË¥üÈù¢ÁöÑÔºõÂèÇÊï∞Áü©ÈòµÊòØ‰ªéËÆ≠ÁªÉÊï∞ÊçÆ‰∏≠Â≠¶‰π†Âá∫Êù•ÁöÑÔºåÊâÄ‰ª•Â≠¶Âá∫Êù•ÁöÑËØçÂêëÈáèÊòØÂ∏¶ÊúâÊÑüÊÉÖËâ≤ÂΩ©ÁöÑÔºõÂÅáËÆæËøô‰∫õËØçÂêëÈáèÈÉΩÊòØ‰∫åÁª¥ÁöÑÔºåÂàôÂèØ‰ª•Âú®Âπ≥Èù¢ÂùêÊ†áÁ≥ª‰∏≠Ê†áÂá∫‰∏ãÈù¢ËØçÂêëÈáè\nkerasÊèê‰æõembeddingÂ±ÇÔºõÁî®Êà∑ÂèØ‰ª•ÊåáÂÆövocabularyÂ§ßÂ∞èÂíådÁöÑÂ§ßÂ∞èÔºõ‰ª•ÂèäÊØè‰∏Ä‰∏™sequenceÁöÑÈïøÂ∫¶ÔºõdÊòØÊ†πÊçÆÁÆóÊ≥ïÈÄâÂá∫Êù•ÁöÑ Âà∞Ëøô‰∏ÄÊ≠•ÔºåÊàë‰ª¨Â∑≤ÁªèÂÆåÊàê‰∫ÜÊñáÊú¨Â§ÑÁêÜÂíåword embedding„ÄÇÊé•‰∏ãÊù•Â∞±ÊòØÁî®Logistic Regression for Binary ClassificationÂÅö‰∫åÂàÜÁ±ªÔºõ\n","permalink":"http://localhost:1313/posts/nlp-2/","summary":"\u003ch3 id=\"text-to-sequence\"\u003eText to Sequence\u003c/h3\u003e\n\u003cp\u003eÊñáÊú¨Â§ÑÁêÜ\u003c/p\u003e\n\u003cp\u003eStep1: Tokenization\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\n\u003cp\u003eTokenization breaks a piece of text down into a list of tokens.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003eHere, a token is a word. (A token can be a character in some applications.)\u003c/p\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003eTokenizationËÆ≤Á©∂ÂæàÂ§öÔºå‰æãÂ¶ÇÊòØÂê¶Â∫îËØ•ÊääÂ§ßÂÜôÊîπÊàêÂ∞èÂÜôÂë¢ÔºüËøõË°åtypo correctionÁ≠âÁ≠â\u003c/p\u003e\n\u003cp\u003e\u003cimg alt=\"image-20250322150322238\" loading=\"lazy\" src=\"./NLP-2.assets/image-20250322150322238.png\"\u003e\u003c/p\u003e\n\u003cp\u003eStep2: Build Dictionary\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\n\u003cp\u003eUse a dictionary (hash table) to count word frequencies.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003eThe dictionary maps word to index.\u003c/p\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003eÂèØ‰ª•È¶ñÂÖàÁªüËÆ°ËØçÈ¢ëÂéªÊéâ‰ΩéÈ¢ëËØçÔºåÁÑ∂ÂêéËÆ©ÊØè‰∏™ËØçÂØπÂ∫î‰∏Ä‰∏™Ê≠£Êï¥Êï∞ÔºõËøôÊ†∑ÁöÑËØùÔºå‰∏ÄÂè•ËØùÂ∞±ÂèØ‰ª•Áî®‰∏Ä‰∏™Ê≠£Êï¥Êï∞ÂàóË°®Ë°®Á§∫ÔºåËøô‰∏™ÂàóË°®Â∞±Âè´sequenceÔºõÂ¶ÇÊûúÂøÖË¶ÅÂ∞±ËøòÂæóÂÅöone-hot encoding„ÄÇ\u003cimg alt=\"image-20250322150620890\" loading=\"lazy\" src=\"./NLP-2.assets/image-20250322150620890.png\"\u003e\u003c/p\u003e\n\u003cp\u003eÁªìÊûú\u003c/p\u003e\n\u003cp\u003e\u003cimg alt=\"image-20250322150754528\" loading=\"lazy\" src=\"./NLP-2.assets/image-20250322150754528.png\"\u003e\u003c/p\u003e\n\u003cp\u003e‰ΩÜÊòØÈïøÂ∫¶‰∏çÁªü‰∏Ä\u003c/p\u003e\n\u003cp\u003eStep4: ÂØπÈΩêsequence\u003c/p\u003e\n\u003cp\u003e\u003cimg alt=\"image-20250322150854986\" loading=\"lazy\" src=\"./NLP-2.assets/image-20250322150854986.png\"\u003e\u003c/p\u003e\n\u003cp\u003eËß£ÂÜ≥ÊñπÊ°àÊòØËøôÊ†∑ÁöÑÔºöÂèØ‰ª•Âõ∫ÂÆöÈïøÂ∫¶‰∏∫wÔºåÂä†ÂÖ•‰∏Ä‰∏™Â∫èÂàóÈïøÂ∫¶Â§™ÈïøÔºåÂ∞±Á†çÊéâÂâçÈù¢ÁöÑËØçÔºåÂè™‰øùÁïôÊúÄÂêéw‰∏™ËØçÔºõÂ¶ÇÊûú‰∏Ä‰∏™Â∫èÂàóÂ§™Áü≠ÔºåÂ∞±ÂÅözero paddingÔºåÁî®0Â°´ÂÖÖ\u003c/p\u003e\n\u003cp\u003e\u003cimg alt=\"image-20250322151030119\" loading=\"lazy\" src=\"./NLP-2.assets/image-20250322151030119.png\"\u003e\u003c/p\u003e\n\u003cp\u003eËøôÊ†∑‰∏ÄÊù•ÔºåÊâÄÊúâÁöÑÂ∫èÂàóÈïøÂ∫¶Â∞±Áªü‰∏Ä‰∫Ü\u003c/p\u003e\n\u003cp\u003e\u003cimg alt=\"image-20250322151117125\" loading=\"lazy\" src=\"./NLP-2.assets/image-20250322151117125.png\"\u003e\u003c/p\u003e\n\u003cp\u003eÊñáÊú¨Â§ÑÁêÜÂÆåÊàê‰∫ÜÔºåÊé•‰∏ãÊù•ÊòØword embeddingÔºåÊääÂçïËØçË°®Á§∫‰∏∫‰∏Ä‰∏™‰ΩéÁª¥ÂêëÈáèÔºõ\u003c/p\u003e\n\u003cp\u003e\u003cimg alt=\"image-20250322151252837\" loading=\"lazy\" src=\"./NLP-2.assets/image-20250322151252837.png\"\u003e\u003c/p\u003e","title":""},{"content":"üëã About me Hello! I\u0026rsquo;m Xu Zongsi, a passionate technology enthusiast currently pursuing my Master of Science in ECIC at The University of Hong Kong. With a solid background in Software Engineering from the Beijing Institute of Technology, I specialize in artificial intelligence areas like machine learning, deep learning, natural language processing, computer vision, and reinforcement learning.\nInspired by OpenAI\u0026rsquo;s five-step plan towards superintelligence, I am excited about AGI and have developed a keen interest in LLM agents, MLLM, and knowledge graphs. I see great potential in these fields and aspire to contribute to innovative solutions.\nüìö Education üá≠üá∞ The University of Hong Kong 09/2024 - Expected 11/2025 School of Computing and Data Science Master of Science in Electronic Commerce \u0026amp; Internet Computing Relevant Courses: Machine learning for business and e-commerce, Knowledge graphs, Financial fraud analytics, Internet infrastructure technologies, Website engineering, Blockchain and cryptocurrency, etc. üá®üá≥ Beijing Institute of Technology 09/2020 - 06/2024 School of Computer Science \u0026amp; Technology Bachelor of Engineering in Software Engineering, last two years GPA: 3.7/4 Relevant Courses: Reinforcement Learning, Deep Learning and Computer Vision, Artificial Intelligence and Robot Ethics, Almost Human: Mind, Brain and Artificial Intelligence, Mathematical Analysis for Engineering, Linear Algebra, Probability and Mathematical Statistics, etc. Skills: Python, Java, common data structures, design patterns, machine learning basics and algorithms, Linux, PyTorch, and some development tools (git, conda, etc.). üèÜ Awards \u0026amp; Honors Beijing Institute of Technology Undergraduate Scholarship (Top 20% of Grade) 06/2023 3rd Prize of China International \u0026#34;Internet \u0026#43;\u0026#34; College Student\u0026#39;s Innovation Competition 08/2022 Bronze Prize of \u0026#34;Challenge Cup\u0026#34; Capital University Entrepreneurship Competition 05/2022 üíº Project Experience üîç Online Transaction Fraud Detection 09/2024 ‚Äì 01/2025 Independent project, supervised by Dr. Vivien Chan Focused on addressing financial fraud in e-commerce to enhance the accuracy of transaction anomaly detection, while independently managing the entire case study that included data preprocessing, feature engineering, model building, evaluation, and results analysis. Effectively resolved class imbalance issues using SMOTE and ROSE techniques. Built various models including Logistic Regression, Random Forest, XGBoost, and LightGBM, ultimately selecting the LightGBM model to achieve a recall rate of 95.45% and an AUC of 99.84%. Wrote efficient and maintainable code, enhancing model training and data processing efficiency through parallel computing and logging. ü§ñ Multi-Model Intelligent Text Keyword Extraction System 08/2023 ‚Äì 09/2023 Group project, supervised by Associate Prof. Xiaolin Zhao Designed and implemented an intelligent text summary system that automatically extracts keywords from article titles and abstracts, enhancing the understanding and summarization of text information. Participated in the planning of the technical route and built a hybrid model combining extractive and generative approaches, utilizing advanced natural language processing techniques including KeyBERT, Sentence Transformer, BERT, and T5 models. Responsible for data preprocessing and tokenization, as well as the end-to-end implementation and training of the T5 model, optimizing the model architecture and hyperparameters, achieving satisfactory results after only 3 epochs of training. Model evaluation results showed that the Rouge-1, Rouge-2, and Rouge-L metrics reached 0.6345, 0.5038, and 0.5282, respectively, in the third epoch, validating the model\u0026rsquo;s effectiveness in the summarization task. üéì Cambridge University Machine Learning Summer Project 07/2023 ‚Äì 08/2023 Group project, supervised by Prof. Pietro Li√≤ Participated in the Cambridge University deep learning summer project, focusing on deep reinforcement learning; explored multi-agent learning algorithms across different environments. Reproduced the Multi-Agent Deep Deterministic Policy Gradient (MADDPG) algorithm in the Simple Adversary environment and studied the effect of agent numbers on convergence speed and stability, finding optimal stability at 21 agents. Designed and implemented comparative experiments inspired by the Rainbow algorithm, assessing target network strategies versus the Double Deep Q-Network (Double DQN). The results demonstrated that Double DQN significantly enhanced convergence speed, optimizing the overall learning process. Co-authored a group project paper on agent numbers and strategies effectiveness in multi-agent systems, achieving a score of 71% in the summer program (the highest in my group) and a \u0026ldquo;First Class\u0026rdquo; classification in the UK grading system. üëÅÔ∏è Deep Learning and Computer Vision Semester Project 09/2022 ‚Äì 12/2022 Independent project, supervised by Associate Prof. Guangyu Gao Designed and implemented a waste classifier using the ResNet model to improve classification accuracy and reduce resource waste. The project also enhanced understanding of transfer learning techniques with ResNet. Collected a dataset of 16 waste categories and preprocessed the images for uniformity and standardization, incorporating data augmentation techniques to enhance the dataset. Conducted experiments using ResNet34 and ResNet50 models through transfer learning, accelerating network convergence by leveraging pretrained weights. During training, techniques such as Batch Normalization and Dropout were applied to mitigate the risk of overfitting. The final model achieved an accuracy of 90% on the training set, while the performance on the test set was 61%, indicating a significant overfitting phenomenon during the training process. üéì Internship ‚öõÔ∏è Beijing Academy of Quantum Information Science 08/2023 ‚Äì 01/2024 Research Intern at Quantum Computation Department Proposed a quantum convolution kernel design based on variational quantum circuits and developed a universal quantum convolution layer, successfully integrating it into classical CNN architectures such as VGG, GoogLeNet, and ResNet. Developed and evaluated various hybrid models, including a simple model named HQCCNN-2, which achieved 84.45% accuracy on the FashionMNIST dataset, surpassing the traditional CNN\u0026rsquo;s 80.72%. This demonstrates the effectiveness of the quantum convolution layer in improving model performance. Tested on a real quantum computer further validated the effectiveness of the hybrid model, demonstrating the viable integration of quantum computing with deep learning, and highlighting the potential for leveraging quantum properties to enhance model performance. üèÖ Competition Experience ü•â China International \u0026#34;Internet \u0026#43;\u0026#34; College Students\u0026#39; Innovation Competition 08/2022 üõ°Ô∏è Zhongke Ushield: Deep Learning-based Face Privacy Protection Authentication System Responsible for constructing a localized facial feature extraction engine based on MobileFaceNet, ensuring feature extraction is completed on end devices (such as mobile phones and cameras), guaranteeing that raw data does not leave the domain and is not stored, thus enhancing user privacy protection while improving recognition efficiency. ü•â \u0026#34;Challenge Cup\u0026#34; Capital University Entrepreneurship Competition 05/2022 üå≥ Smart Orchard Responsible for the development of the fruit detection, ripeness prediction, and pest identification system, using deep convolutional neural network (CNN) technology for intelligent monitoring of crop growth conditions. Applied advanced object detection algorithms such as Faster R-CNN and YOLO to achieve high precision in apple detection and ripeness assessment, with an accuracy rate exceeding 90%, significantly enhancing the intelligence level of orchard management. Built and trained a dedicated dataset containing various pest samples, optimizing pest detection accuracy through data preprocessing (such as image normalization and resizing) and data augmentation techniques (like rotation, flipping, and noise addition), enabling the real-time monitoring system to accurately identify over 80% of pests, providing effective scientific maintenance recommendations to help farmers reduce crop losses. üìã Extracurricular Activities Vice President, Cyber Security Club, Beijing Institute of Technology 09/2021-09/2022 Backbone, Media Center of the Student Union of Beijing Institute of Technology 10/2020-06/2021 üì´ Contact üìß Email: zongsi.xu@outlook.com üëî LinkedIn: Zongsi (Tristan) Xu üíª GitHub: BaizeXS üìç Location: Hong Kong SAR, China ","permalink":"http://localhost:1313/resume/","summary":"Personal resume of Zongsi (Tristan) Xu","title":"Zongsi (Tristan) Xu"},{"content":"‰∏Ä„ÄÅÊï∞ÂÄºÁâπÂæÅ‰∏éÁ±ªÂà´ÁâπÂæÅ Êï∞ÂÄºÁâπÂæÅ (Numeric Features) ÂÖ∑ÊúâÂèØÂä†ÂáèÁöÑÊÑè‰πâÔºå‰∏îÂ≠òÂú®Â§ßÂ∞èÈ°∫Â∫è„ÄÇ ‰æãÂ≠êÔºöÂπ¥ÈæÑ„ÄÅÊ∏©Â∫¶Á≠â„ÄÇÂèØ‰ª•Áõ¥Êé•‰øùÁïôÂÖ∂Êï¥Êï∞ÊàñÊµÆÁÇπÊï∞ÂΩ¢Âºè‰æõÊ®°Âûã‰ΩøÁî®„ÄÇ Á±ªÂà´ÁâπÂæÅ (Categorical Features) Êï∞ÊçÆÂÄºÁ¶ªÊï£Ôºå‰∏çÂÖ∑Â§á‚ÄúÊï∞ÂÄºÂ§ßÂ∞è‚ÄùÈó¥ÁöÑÂèØÊØîÊÑè‰πâ„ÄÇ ‰æãÂ≠êÔºöÂõΩÁ±çÔºàÁæéÂõΩ/‰∏≠ÂõΩ/Âç∞Â∫¶Á≠âÔºâ„ÄÅÊÄßÂà´ÔºàÁî∑/Â•≥ÔºâÁ≠â„ÄÇ ÈóÆÈ¢òÔºöËã•‰ªÖÁî®Êï¥Êï∞Ë°®Á§∫ÔºàÁæéÂõΩ=1, ‰∏≠ÂõΩ=2ÔºâÔºå‰ºöÂºïÂÖ•ÈîôËØØÁöÑÊï∞ÂÄºËøêÁÆóÂÖ≥Á≥ªÔºåÂ¶Ç ‚ÄúÁæéÂõΩ + ‰∏≠ÂõΩ = Âç∞Â∫¶‚Äù„ÄÇ ‰∫å„ÄÅOne-HotÁºñÁ†ÅÁöÑÂä®Êú∫‰∏éÊµÅÁ®ã ‰∏∫‰ªÄ‰πà‰ΩøÁî®One-Hot\nÈÄöËøáÂ∞ÜÁ±ªÂà´Êò†Â∞Ñ‰∏∫ÂêëÈáèÔºåÈÅøÂÖçÊï¥Êï∞ÁºñÁ†ÅÂºïÂÖ•ÁöÑ‰º™Êï∞ÂÄºÂÖ≥Á≥ª„ÄÇ ÂêåÊó∂‰øùÁïôÂêÑÁßçÂèØËÉΩÁ±ªÂà´ÁöÑ‰ø°ÊÅØÔºå‰∏î‰ªÖÂú®ÂØπÂ∫î‰ΩçÁΩÆ‰∏∫1ÔºåÂÖ∂‰ªñ‰ΩçÁΩÆ‰∏∫0„ÄÇ Âª∫Á´ãÊò†Â∞ÑÔºö‰ªéÁ±ªÂà´Âà∞Á¥¢Âºï\n‰∏∫ÊØè‰∏™Á±ªÂà´ÂàÜÈÖç‰∏Ä‰∏™ÂîØ‰∏ÄÁ¥¢ÂºïÔºåÈÄöÂ∏∏‰ªé1ÂºÄÂßã„ÄÇ È¢ÑÁïôÁ¥¢Âºï0Ë°®Á§∫‚ÄúÊú™Áü•‚ÄùÊàñ‚ÄúÁº∫Â§±‚ÄùÔºåÂØπÂ∫îÂÖ®0ÂêëÈáè„ÄÇ ËΩ¨Êç¢‰∏∫One-HotÂêëÈáè\nËã•Á±ªÂà´ÊÄªÊï∞‰∏∫197ÔºåÂàôÁî®197Áª¥ÂêëÈáèË°®Á§∫„ÄÇ ‰æãÂ≠êÔºöÁæéÂõΩ [1, 0, 0, 0, ‚Ä¶]Ôºå ‰∏≠ÂõΩ [0, 1, 0, 0, ‚Ä¶]„ÄÇ Á§∫‰æãÔºöË°®Á§∫‰∏Ä‰∏™‰∫∫ÁöÑÁâπÂæÅ\nÁâπÂæÅÂåÖÂê´ÔºàÂπ¥ÈæÑ, ÊÄßÂà´, ÂõΩÁ±çÔºåÂÖ∂‰∏≠ÂõΩÁ±ç197ÁßçÔºâ Áª¥Â∫¶ÊÄªÂíåÔºö1Áª¥_age + 1Áª¥_gender + 197Áª¥_nationality = 199Áª¥„ÄÇ ‰æãÂ¶Ç (28, Â•≥, ‰∏≠ÂõΩ) ‚Üí [28, 0, 0, 1, 0, ‚Ä¶, 0]„ÄÇ ‰∏â„ÄÅÊñáÊú¨Êï∞ÊçÆÂ§ÑÁêÜÊµÅÁ®ã ÊñáÊú¨Âú®Ëá™ÁÑ∂ËØ≠Ë®ÄÂ§ÑÁêÜÔºàNLPÔºâ‰∏≠‰Ωú‰∏∫Â∏∏ËßÅÁöÑÂéüÂßãËæìÂÖ•ÔºåÈúÄË¶ÅÊï∞ÂÄºÂåñÊâçËÉΩÈÄÅÂÖ•Ê®°Âûã„ÄÇ‰∏ÄËà¨Ê≠•È™§Â¶Ç‰∏ãÔºö\nÂàÜËØç (Tokenization)\nÂ∞ÜÊñáÊú¨ÊãÜÂàÜ‰∏∫‰∏Ä‰∏™‰∏™ÂçïËØçÔºàTokenÔºâ„ÄÇ ‰æãÂ≠êÔºö\u0026quot;... to be or not to be...\u0026quot; ‚Üí [\u0026quot;...\u0026quot;, \u0026quot;to\u0026quot;, \u0026quot;be\u0026quot;, \u0026quot;or\u0026quot;, \u0026quot;not\u0026quot;, \u0026quot;to\u0026quot;, \u0026quot;be\u0026quot;, \u0026quot;...\u0026quot;]„ÄÇ ÁªüËÆ°ËØçÈ¢ë \u0026amp; ÊûÑÂª∫ËØçÂÖ∏\nËØçÈ¢ëÁªüËÆ° Áî®ÂìàÂ∏åË°®/Â≠óÂÖ∏ËÆ∞ÂΩïÊØè‰∏™ÂçïËØçÂá∫Áé∞Ê¨°Êï∞„ÄÇ ÈÅçÂéÜÊñáÊú¨Êó∂ÔºåËã•ÂçïËØçÂ∞öÊú™ÂÖ•Ë°®ÔºåÂàôÊñ∞Âª∫ËÆ∞ÂΩïÔºõËã•Â∑≤Â≠òÂú®ÔºåÂàôËÆ°Êï∞+1„ÄÇ ÊéíÂ∫è‰∏éÁ¥¢Âºï ÊåâËØçÈ¢ëÈôçÂ∫èÊéíÂ∫èÔºåËØçÈ¢ëÊúÄÈ´òÁöÑÂçïËØçÊéíÂú®ÂâçÈù¢„ÄÇ Á¥¢Âºï‰ªé1ÂºÄÂßãÔºå0ÁïôÁªô‚ÄúÊú™Áü•‚Äù„ÄÇ ËØçÂÖ∏ËßÑÊ®°ÔºàvocabularyÔºâÂèØËßÜÈúÄÊ±ÇÊà™Êñ≠Ôºà‰æãÂ¶ÇÂè™‰øùÁïôTop 10kÔºâ„ÄÇ ‰∏∫‰ªÄ‰πàÁßªÈô§‰ΩéÈ¢ëËØç ‰ΩéÈ¢ëËØçÂèØËÉΩÊòØÊãºÂÜôÈîôËØØ„ÄÅÁΩïËßÅ‰∫∫ÂêçÁ≠âÔºåÂØπÊ®°ÂûãÂ∏ÆÂä©ÊúâÈôê„ÄÇ ÂáèÂ∞ëËØçÂÖ∏ËßÑÊ®°ÂèØÈôç‰ΩéËøêÁÆóÂºÄÈîÄ„ÄÅÂä†Âø´Ê®°ÂûãËÆ≠ÁªÉ‰∏éÊé®ÁêÜÈÄüÂ∫¶„ÄÇ Áã¨ÁÉ≠ÁºñÁ†Å (One-Hot Encoding)\nÂ∞ÜÊØè‰∏™ÂçïËØçÊò†Â∞Ñ‰∏∫ËØçÂÖ∏‰∏≠ÁöÑÁ¥¢ÂºïÂêéÔºàÂ¶Ç [2, 4, 1, 8, ‚Ä¶]ÔºâÔºåÂèØËøõ‰∏ÄÊ≠•ËΩ¨Êç¢ÊàêOne-HotÂêëÈáè„ÄÇ One-HotÁª¥Â∫¶ÂèñÂÜ≥‰∫é‰øùÁïô‰∏ãÊù•ÁöÑËØçÂÖ∏Â§ßÂ∞èÔºà‰æãÂ¶Ç1‰∏áÔºâ„ÄÇ Êú™Êî∂ÂΩïÂçïËØçÂèØËÉΩÁõ¥Êé•ÂøΩÁï•ÔºåÊàñÁªü‰∏ÄÁî®Á¥¢Âºï0‰ª£Êõø„ÄÇ Âõõ„ÄÅÊ†∏ÂøÉÊî∂Ëé∑‰∏éÂ∫îÁî® Á±ªÂà´ÁâπÂæÅÂøÖÈúÄÊï∞ÂÄºÂåñÔºö\n‰ΩøÁî®Êï¥Êï∞1,2,3‚Ä¶‰ªÖË°®Á§∫Á±ªÂà´‚ÄúÊ†áËØÜ‚ÄùÔºåÂπ∂‰∏ç‰ª£Ë°®ÂÆÉ‰ª¨ÂèØËøõË°åÊï∞ÂÄºËøêÁÆó„ÄÇ Âõ†Ê≠§ÈúÄË¶ÅOne-HotÁ≠âÁºñÁ†ÅÊñπÂºèÔºåÈÅøÂÖçÊï∞ÂÄºËØØËß£„ÄÇ ÊñáÊú¨Êï∞ÊçÆÈ¢ÑÂ§ÑÁêÜÔºö\nÂàÜËØç„ÄÅËØçÈ¢ëÁªüËÆ°„ÄÅÊûÑÂª∫ËØçÂÖ∏„ÄÅÁ¥¢ÂºïÂåñ„ÄÅOne-HotÊàñÂÖ∂‰ªñÊñπÂºèÔºàÂ¶ÇËØçÂµåÂÖ•ÔºâÊòØÂ∏∏ËßÅÊµÅÁ®ã„ÄÇ Ê≠£Á°ÆÁöÑÊñáÊú¨È¢ÑÂ§ÑÁêÜÂèØÊòæËëóÂΩ±ÂìçÊ®°ÂûãÊÄßËÉΩÂíåÊïàÁéá„ÄÇ ‰øùÁïôÊú™Áü•Á¥¢ÂºïÔºö\n‰øùËØÅÂØπÁº∫Â§±Êï∞ÊçÆÊàñÂ≠óÂÖ∏Â§ñÊñ∞ËØçËÉΩÊúâÂü∫Êú¨ÁöÑË°®Á§∫ÔºåÊèêÂçáÊ®°ÂûãÂÆπÈîôÊÄß„ÄÇ ÂÆûÈôÖ‰ΩøÁî®Ôºö\nÂØπ‰∫éÂ∞èËßÑÊ®°Á±ªÂà´ÂèØÁõ¥Êé•One-HotÁºñÁ†ÅÔºõÂØπ‰∫éËØçÂÖ∏ÂæàÂ§ßÁöÑÂú∫ÊôØÔºåÈÄöÂ∏∏‰ºöËøõ‰∏ÄÊ≠•ËÄÉËôëËØçÂµåÂÖ•ÔºàWord EmbeddingÔºâÊàñÈ¢ÑËÆ≠ÁªÉËØ≠Ë®ÄÊ®°Âûã„ÄÇ ","permalink":"http://localhost:1313/posts/nlp-1/","summary":"\u003ch2 id=\"‰∏ÄÊï∞ÂÄºÁâπÂæÅ‰∏éÁ±ªÂà´ÁâπÂæÅ\"\u003e‰∏Ä„ÄÅÊï∞ÂÄºÁâπÂæÅ‰∏éÁ±ªÂà´ÁâπÂæÅ\u003c/h2\u003e\n\u003col\u003e\n\u003cli\u003e\u003cstrong\u003eÊï∞ÂÄºÁâπÂæÅ (Numeric Features)\u003c/strong\u003e\n\u003cul\u003e\n\u003cli\u003eÂÖ∑ÊúâÂèØÂä†ÂáèÁöÑÊÑè‰πâÔºå‰∏îÂ≠òÂú®Â§ßÂ∞èÈ°∫Â∫è„ÄÇ\u003c/li\u003e\n\u003cli\u003e‰æãÂ≠êÔºöÂπ¥ÈæÑ„ÄÅÊ∏©Â∫¶Á≠â„ÄÇÂèØ‰ª•Áõ¥Êé•‰øùÁïôÂÖ∂Êï¥Êï∞ÊàñÊµÆÁÇπÊï∞ÂΩ¢Âºè‰æõÊ®°Âûã‰ΩøÁî®„ÄÇ\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003eÁ±ªÂà´ÁâπÂæÅ (Categorical Features)\u003c/strong\u003e\n\u003cul\u003e\n\u003cli\u003eÊï∞ÊçÆÂÄºÁ¶ªÊï£Ôºå‰∏çÂÖ∑Â§á‚ÄúÊï∞ÂÄºÂ§ßÂ∞è‚ÄùÈó¥ÁöÑÂèØÊØîÊÑè‰πâ„ÄÇ\u003c/li\u003e\n\u003cli\u003e‰æãÂ≠êÔºöÂõΩÁ±çÔºàÁæéÂõΩ/‰∏≠ÂõΩ/Âç∞Â∫¶Á≠âÔºâ„ÄÅÊÄßÂà´ÔºàÁî∑/Â•≥ÔºâÁ≠â„ÄÇ\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003eÈóÆÈ¢ò\u003c/strong\u003eÔºöËã•‰ªÖÁî®Êï¥Êï∞Ë°®Á§∫ÔºàÁæéÂõΩ=1, ‰∏≠ÂõΩ=2ÔºâÔºå‰ºöÂºïÂÖ•ÈîôËØØÁöÑÊï∞ÂÄºËøêÁÆóÂÖ≥Á≥ªÔºåÂ¶Ç ‚ÄúÁæéÂõΩ + ‰∏≠ÂõΩ = Âç∞Â∫¶‚Äù„ÄÇ\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003c/ol\u003e\n\u003ch2 id=\"‰∫åone-hotÁºñÁ†ÅÁöÑÂä®Êú∫‰∏éÊµÅÁ®ã\"\u003e‰∫å„ÄÅOne-HotÁºñÁ†ÅÁöÑÂä®Êú∫‰∏éÊµÅÁ®ã\u003c/h2\u003e\n\u003col\u003e\n\u003cli\u003e\n\u003cp\u003e\u003cstrong\u003e‰∏∫‰ªÄ‰πà‰ΩøÁî®One-Hot\u003c/strong\u003e\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eÈÄöËøáÂ∞ÜÁ±ªÂà´Êò†Â∞Ñ‰∏∫ÂêëÈáèÔºåÈÅøÂÖçÊï¥Êï∞ÁºñÁ†ÅÂºïÂÖ•ÁöÑ‰º™Êï∞ÂÄºÂÖ≥Á≥ª„ÄÇ\u003c/li\u003e\n\u003cli\u003eÂêåÊó∂‰øùÁïôÂêÑÁßçÂèØËÉΩÁ±ªÂà´ÁöÑ‰ø°ÊÅØÔºå‰∏î‰ªÖÂú®ÂØπÂ∫î‰ΩçÁΩÆ‰∏∫1ÔºåÂÖ∂‰ªñ‰ΩçÁΩÆ‰∏∫0„ÄÇ\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003e\u003cstrong\u003eÂª∫Á´ãÊò†Â∞ÑÔºö‰ªéÁ±ªÂà´Âà∞Á¥¢Âºï\u003c/strong\u003e\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e‰∏∫ÊØè‰∏™Á±ªÂà´ÂàÜÈÖç‰∏Ä‰∏™ÂîØ‰∏ÄÁ¥¢ÂºïÔºåÈÄöÂ∏∏‰ªé1ÂºÄÂßã„ÄÇ\u003c/li\u003e\n\u003cli\u003eÈ¢ÑÁïôÁ¥¢Âºï0Ë°®Á§∫‚ÄúÊú™Áü•‚ÄùÊàñ‚ÄúÁº∫Â§±‚ÄùÔºåÂØπÂ∫îÂÖ®0ÂêëÈáè„ÄÇ\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003e\u003cstrong\u003eËΩ¨Êç¢‰∏∫One-HotÂêëÈáè\u003c/strong\u003e\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eËã•Á±ªÂà´ÊÄªÊï∞‰∏∫197ÔºåÂàôÁî®197Áª¥ÂêëÈáèË°®Á§∫„ÄÇ\u003c/li\u003e\n\u003cli\u003e‰æãÂ≠êÔºöÁæéÂõΩ \u003ccode\u003e[1, 0, 0, 0, ‚Ä¶]\u003c/code\u003eÔºå ‰∏≠ÂõΩ \u003ccode\u003e[0, 1, 0, 0, ‚Ä¶]\u003c/code\u003e„ÄÇ\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003e\u003cstrong\u003eÁ§∫‰æãÔºöË°®Á§∫‰∏Ä‰∏™‰∫∫ÁöÑÁâπÂæÅ\u003c/strong\u003e\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eÁâπÂæÅÂåÖÂê´ÔºàÂπ¥ÈæÑ, ÊÄßÂà´, ÂõΩÁ±çÔºåÂÖ∂‰∏≠ÂõΩÁ±ç197ÁßçÔºâ\u003c/li\u003e\n\u003cli\u003eÁª¥Â∫¶ÊÄªÂíåÔºö1Áª¥_age + 1Áª¥_gender + 197Áª¥_nationality = 199Áª¥„ÄÇ\u003c/li\u003e\n\u003cli\u003e‰æãÂ¶Ç \u003ccode\u003e(28, Â•≥, ‰∏≠ÂõΩ)\u003c/code\u003e ‚Üí \u003ccode\u003e[28, 0, 0, 1, 0, ‚Ä¶, 0]\u003c/code\u003e„ÄÇ\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003c/ol\u003e\n\u003ch2 id=\"‰∏âÊñáÊú¨Êï∞ÊçÆÂ§ÑÁêÜÊµÅÁ®ã\"\u003e‰∏â„ÄÅÊñáÊú¨Êï∞ÊçÆÂ§ÑÁêÜÊµÅÁ®ã\u003c/h2\u003e\n\u003cp\u003eÊñáÊú¨Âú®Ëá™ÁÑ∂ËØ≠Ë®ÄÂ§ÑÁêÜÔºàNLPÔºâ‰∏≠‰Ωú‰∏∫Â∏∏ËßÅÁöÑÂéüÂßãËæìÂÖ•ÔºåÈúÄË¶ÅÊï∞ÂÄºÂåñÊâçËÉΩÈÄÅÂÖ•Ê®°Âûã„ÄÇ‰∏ÄËà¨Ê≠•È™§Â¶Ç‰∏ãÔºö\u003c/p\u003e\n\u003col\u003e\n\u003cli\u003e\n\u003cp\u003e\u003cstrong\u003eÂàÜËØç (Tokenization)\u003c/strong\u003e\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eÂ∞ÜÊñáÊú¨ÊãÜÂàÜ‰∏∫‰∏Ä‰∏™‰∏™ÂçïËØçÔºàTokenÔºâ„ÄÇ\u003c/li\u003e\n\u003cli\u003e‰æãÂ≠êÔºö\u003ccode\u003e\u0026quot;... to be or not to be...\u0026quot;\u003c/code\u003e ‚Üí \u003ccode\u003e[\u0026quot;...\u0026quot;, \u0026quot;to\u0026quot;, \u0026quot;be\u0026quot;, \u0026quot;or\u0026quot;, \u0026quot;not\u0026quot;, \u0026quot;to\u0026quot;, \u0026quot;be\u0026quot;, \u0026quot;...\u0026quot;]\u003c/code\u003e„ÄÇ\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003e\u003cstrong\u003eÁªüËÆ°ËØçÈ¢ë \u0026amp; ÊûÑÂª∫ËØçÂÖ∏\u003c/strong\u003e\u003c/p\u003e","title":""},{"content":"Text to Sequence ÊñáÊú¨Â§ÑÁêÜ\nStep1: Tokenization\nTokenization breaks a piece of text down into a list of tokens.\nHere, a token is a word. (A token can be a character in some applications.)\nTokenizationËÆ≤Á©∂ÂæàÂ§öÔºå‰æãÂ¶ÇÊòØÂê¶Â∫îËØ•ÊääÂ§ßÂÜôÊîπÊàêÂ∞èÂÜôÂë¢ÔºüËøõË°åtypo correctionÁ≠âÁ≠â\nStep2: Build Dictionary\nUse a dictionary (hash table) to count word frequencies.\nThe dictionary maps word to index.\nÂèØ‰ª•È¶ñÂÖàÁªüËÆ°ËØçÈ¢ëÂéªÊéâ‰ΩéÈ¢ëËØçÔºåÁÑ∂ÂêéËÆ©ÊØè‰∏™ËØçÂØπÂ∫î‰∏Ä‰∏™Ê≠£Êï¥Êï∞ÔºõËøôÊ†∑ÁöÑËØùÔºå‰∏ÄÂè•ËØùÂ∞±ÂèØ‰ª•Áî®‰∏Ä‰∏™Ê≠£Êï¥Êï∞ÂàóË°®Ë°®Á§∫ÔºåËøô‰∏™ÂàóË°®Â∞±Âè´sequenceÔºõÂ¶ÇÊûúÂøÖË¶ÅÂ∞±ËøòÂæóÂÅöone-hot encoding„ÄÇ\nÁªìÊûú\n‰ΩÜÊòØÈïøÂ∫¶‰∏çÁªü‰∏Ä\nStep4: ÂØπÈΩêsequence\nËß£ÂÜ≥ÊñπÊ°àÊòØËøôÊ†∑ÁöÑÔºöÂèØ‰ª•Âõ∫ÂÆöÈïøÂ∫¶‰∏∫wÔºåÂä†ÂÖ•‰∏Ä‰∏™Â∫èÂàóÈïøÂ∫¶Â§™ÈïøÔºåÂ∞±Á†çÊéâÂâçÈù¢ÁöÑËØçÔºåÂè™‰øùÁïôÊúÄÂêéw‰∏™ËØçÔºõÂ¶ÇÊûú‰∏Ä‰∏™Â∫èÂàóÂ§™Áü≠ÔºåÂ∞±ÂÅözero paddingÔºåÁî®0Â°´ÂÖÖ\nËøôÊ†∑‰∏ÄÊù•ÔºåÊâÄÊúâÁöÑÂ∫èÂàóÈïøÂ∫¶Â∞±Áªü‰∏Ä‰∫Ü\nÊñáÊú¨Â§ÑÁêÜÂÆåÊàê‰∫ÜÔºåÊé•‰∏ãÊù•ÊòØword embeddingÔºåÊääÂçïËØçË°®Á§∫‰∏∫‰∏Ä‰∏™‰ΩéÁª¥ÂêëÈáèÔºõ\nÁÑ∂ËÄåËøôÊ†∑ÂÅöÁöÑËØùÔºåÂ¶ÇÊûúÊòØ10000‰∏™ÂçïËØçÔºåÁª¥Â∫¶Â∞±ÊòØ10000Áª¥ÔºåÁª¥Â∫¶Â§™È´ò‰∫ÜÔºõÂõ†Ê≠§Ë¶ÅÂÅöword embeddingÔºõ\nÂÖ∑‰ΩìÂÅöÊ≥ïÂ∞±ÊòØÊääone-hotÂêëÈáèe_iÂíåÂèÇÊï∞Áü©ÈòµpÁõ∏‰πòÔºõÁü©ÈòµPËΩ¨ÁΩÆÁöÑÂ§ßÂ∞èÊòØd x vÔºõdÊòØËØçÂêëÈáèÁöÑÁª¥Â∫¶ÔºõvÊòØÂ≠óÂÖ∏ÈáåËØçÊ±áÁöÑÊï∞ÈáèÔºõÁªìÊûú‰∏∫x_iÔºõx_iÂ∞±ÊòØ‰∏Ä‰∏™ËØçÂêëÈáèÔºõÂ¶ÇÊûúone-hotÂêëÈáèÁöÑÁ¨¨‰∏âË°å‰∏∫1ÔºõÈÇ£‰πàx_iÂ∞±ÊòØPËΩ¨ÁΩÆÁü©ÈòµÁöÑÁ¨¨‰∏âÂàóÔºàÂÖ∂‰ΩôÂàóÈÉΩ‰∏∫0ÔºâÔºõÊâÄ‰ª•PËΩ¨ÁΩÆÊØè‰∏ÄÂàóÈÉΩÊòØ‰∏Ä‰∏™ËØçÂêëÈáèÔºõÊâÄ‰ª•Áü©ÈòµPÊú¨Ë∫´ÁöÑÊØè‰∏ÄË°åÂ∞±ÊòØ‰∏Ä‰∏™ËØçÂêëÈáèÔºõÂÖ∂Ë°åÊï∞‰∏∫vÔºõÂç≥vocabularyÔºåËØçÊ±áÈáèÔºõÊØè‰∏ÄË°åÂØπÂ∫î‰∏Ä‰∏™ÂçïËØçÔºõÁü©ÈòµÁöÑÂàóÊï∞‰∏∫dÔºõdÊòØÁî®Êà∑ÂÜ≥ÂÆöÁöÑÔºõdÁöÑÂ§ßÂ∞è‰ºöÂÜ≥ÂÆöÊú∫Âô®Â≠¶‰π†Ê®°ÂûãÁöÑË°®Áé∞ÔºõÂ∫îËØ•Áî®xxxÊù•ÈÄâÊã©‰∏Ä‰∏™ÊØîËæÉÂ•ΩÁöÑdÔºõ\nÊàë‰ª¨ÁöÑ‰ªªÂä°ÊòØÁúãËØÑËÆ∫ÊòØÊ≠£Èù¢ÁöÑËøòÊòØË¥üÈù¢ÁöÑÔºõÂèÇÊï∞Áü©ÈòµÊòØ‰ªéËÆ≠ÁªÉÊï∞ÊçÆ‰∏≠Â≠¶‰π†Âá∫Êù•ÁöÑÔºåÊâÄ‰ª•Â≠¶Âá∫Êù•ÁöÑËØçÂêëÈáèÊòØÂ∏¶ÊúâÊÑüÊÉÖËâ≤ÂΩ©ÁöÑÔºõÂÅáËÆæËøô‰∫õËØçÂêëÈáèÈÉΩÊòØ‰∫åÁª¥ÁöÑÔºåÂàôÂèØ‰ª•Âú®Âπ≥Èù¢ÂùêÊ†áÁ≥ª‰∏≠Ê†áÂá∫‰∏ãÈù¢ËØçÂêëÈáè\nkerasÊèê‰æõembeddingÂ±ÇÔºõÁî®Êà∑ÂèØ‰ª•ÊåáÂÆövocabularyÂ§ßÂ∞èÂíådÁöÑÂ§ßÂ∞èÔºõ‰ª•ÂèäÊØè‰∏Ä‰∏™sequenceÁöÑÈïøÂ∫¶ÔºõdÊòØÊ†πÊçÆÁÆóÊ≥ïÈÄâÂá∫Êù•ÁöÑ Âà∞Ëøô‰∏ÄÊ≠•ÔºåÊàë‰ª¨Â∑≤ÁªèÂÆåÊàê‰∫ÜÊñáÊú¨Â§ÑÁêÜÂíåword embedding„ÄÇÊé•‰∏ãÊù•Â∞±ÊòØÁî®Logistic Regression for Binary ClassificationÂÅö‰∫åÂàÜÁ±ªÔºõ\n","permalink":"http://localhost:1313/posts/nlp-2/","summary":"\u003ch3 id=\"text-to-sequence\"\u003eText to Sequence\u003c/h3\u003e\n\u003cp\u003eÊñáÊú¨Â§ÑÁêÜ\u003c/p\u003e\n\u003cp\u003eStep1: Tokenization\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\n\u003cp\u003eTokenization breaks a piece of text down into a list of tokens.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003eHere, a token is a word. (A token can be a character in some applications.)\u003c/p\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003eTokenizationËÆ≤Á©∂ÂæàÂ§öÔºå‰æãÂ¶ÇÊòØÂê¶Â∫îËØ•ÊääÂ§ßÂÜôÊîπÊàêÂ∞èÂÜôÂë¢ÔºüËøõË°åtypo correctionÁ≠âÁ≠â\u003c/p\u003e\n\u003cp\u003e\u003cimg alt=\"image-20250322150322238\" loading=\"lazy\" src=\"./NLP-2.assets/image-20250322150322238.png\"\u003e\u003c/p\u003e\n\u003cp\u003eStep2: Build Dictionary\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\n\u003cp\u003eUse a dictionary (hash table) to count word frequencies.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003eThe dictionary maps word to index.\u003c/p\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003eÂèØ‰ª•È¶ñÂÖàÁªüËÆ°ËØçÈ¢ëÂéªÊéâ‰ΩéÈ¢ëËØçÔºåÁÑ∂ÂêéËÆ©ÊØè‰∏™ËØçÂØπÂ∫î‰∏Ä‰∏™Ê≠£Êï¥Êï∞ÔºõËøôÊ†∑ÁöÑËØùÔºå‰∏ÄÂè•ËØùÂ∞±ÂèØ‰ª•Áî®‰∏Ä‰∏™Ê≠£Êï¥Êï∞ÂàóË°®Ë°®Á§∫ÔºåËøô‰∏™ÂàóË°®Â∞±Âè´sequenceÔºõÂ¶ÇÊûúÂøÖË¶ÅÂ∞±ËøòÂæóÂÅöone-hot encoding„ÄÇ\u003cimg alt=\"image-20250322150620890\" loading=\"lazy\" src=\"./NLP-2.assets/image-20250322150620890.png\"\u003e\u003c/p\u003e\n\u003cp\u003eÁªìÊûú\u003c/p\u003e\n\u003cp\u003e\u003cimg alt=\"image-20250322150754528\" loading=\"lazy\" src=\"./NLP-2.assets/image-20250322150754528.png\"\u003e\u003c/p\u003e\n\u003cp\u003e‰ΩÜÊòØÈïøÂ∫¶‰∏çÁªü‰∏Ä\u003c/p\u003e\n\u003cp\u003eStep4: ÂØπÈΩêsequence\u003c/p\u003e\n\u003cp\u003e\u003cimg alt=\"image-20250322150854986\" loading=\"lazy\" src=\"./NLP-2.assets/image-20250322150854986.png\"\u003e\u003c/p\u003e\n\u003cp\u003eËß£ÂÜ≥ÊñπÊ°àÊòØËøôÊ†∑ÁöÑÔºöÂèØ‰ª•Âõ∫ÂÆöÈïøÂ∫¶‰∏∫wÔºåÂä†ÂÖ•‰∏Ä‰∏™Â∫èÂàóÈïøÂ∫¶Â§™ÈïøÔºåÂ∞±Á†çÊéâÂâçÈù¢ÁöÑËØçÔºåÂè™‰øùÁïôÊúÄÂêéw‰∏™ËØçÔºõÂ¶ÇÊûú‰∏Ä‰∏™Â∫èÂàóÂ§™Áü≠ÔºåÂ∞±ÂÅözero paddingÔºåÁî®0Â°´ÂÖÖ\u003c/p\u003e\n\u003cp\u003e\u003cimg alt=\"image-20250322151030119\" loading=\"lazy\" src=\"./NLP-2.assets/image-20250322151030119.png\"\u003e\u003c/p\u003e\n\u003cp\u003eËøôÊ†∑‰∏ÄÊù•ÔºåÊâÄÊúâÁöÑÂ∫èÂàóÈïøÂ∫¶Â∞±Áªü‰∏Ä‰∫Ü\u003c/p\u003e\n\u003cp\u003e\u003cimg alt=\"image-20250322151117125\" loading=\"lazy\" src=\"./NLP-2.assets/image-20250322151117125.png\"\u003e\u003c/p\u003e\n\u003cp\u003eÊñáÊú¨Â§ÑÁêÜÂÆåÊàê‰∫ÜÔºåÊé•‰∏ãÊù•ÊòØword embeddingÔºåÊääÂçïËØçË°®Á§∫‰∏∫‰∏Ä‰∏™‰ΩéÁª¥ÂêëÈáèÔºõ\u003c/p\u003e\n\u003cp\u003e\u003cimg alt=\"image-20250322151252837\" loading=\"lazy\" src=\"./NLP-2.assets/image-20250322151252837.png\"\u003e\u003c/p\u003e","title":""},{"content":"üëã About me Hello! I\u0026rsquo;m Xu Zongsi, a passionate technology enthusiast currently pursuing my Master of Science in ECIC at The University of Hong Kong. With a solid background in Software Engineering from the Beijing Institute of Technology, I specialize in artificial intelligence areas like machine learning, deep learning, natural language processing, computer vision, and reinforcement learning.\nInspired by OpenAI\u0026rsquo;s five-step plan towards superintelligence, I am excited about AGI and have developed a keen interest in LLM agents, MLLM, and knowledge graphs. I see great potential in these fields and aspire to contribute to innovative solutions.\nüìö Education üá≠üá∞ The University of Hong Kong 09/2024 - Expected 11/2025 School of Computing and Data Science Master of Science in Electronic Commerce \u0026amp; Internet Computing Relevant Courses: Machine learning for business and e-commerce, Knowledge graphs, Financial fraud analytics, Internet infrastructure technologies, Website engineering, Blockchain and cryptocurrency, etc. üá®üá≥ Beijing Institute of Technology 09/2020 - 06/2024 School of Computer Science \u0026amp; Technology Bachelor of Engineering in Software Engineering, last two years GPA: 3.7/4 Relevant Courses: Reinforcement Learning, Deep Learning and Computer Vision, Artificial Intelligence and Robot Ethics, Almost Human: Mind, Brain and Artificial Intelligence, Mathematical Analysis for Engineering, Linear Algebra, Probability and Mathematical Statistics, etc. Skills: Python, Java, common data structures, design patterns, machine learning basics and algorithms, Linux, PyTorch, and some development tools (git, conda, etc.). üèÜ Awards \u0026amp; Honors Beijing Institute of Technology Undergraduate Scholarship (Top 20% of Grade) 06/2023 3rd Prize of China International \u0026#34;Internet \u0026#43;\u0026#34; College Student\u0026#39;s Innovation Competition 08/2022 Bronze Prize of \u0026#34;Challenge Cup\u0026#34; Capital University Entrepreneurship Competition 05/2022 üíº Project Experience üîç Online Transaction Fraud Detection 09/2024 ‚Äì 01/2025 Independent project, supervised by Dr. Vivien Chan Focused on addressing financial fraud in e-commerce to enhance the accuracy of transaction anomaly detection, while independently managing the entire case study that included data preprocessing, feature engineering, model building, evaluation, and results analysis. Effectively resolved class imbalance issues using SMOTE and ROSE techniques. Built various models including Logistic Regression, Random Forest, XGBoost, and LightGBM, ultimately selecting the LightGBM model to achieve a recall rate of 95.45% and an AUC of 99.84%. Wrote efficient and maintainable code, enhancing model training and data processing efficiency through parallel computing and logging. ü§ñ Multi-Model Intelligent Text Keyword Extraction System 08/2023 ‚Äì 09/2023 Group project, supervised by Associate Prof. Xiaolin Zhao Designed and implemented an intelligent text summary system that automatically extracts keywords from article titles and abstracts, enhancing the understanding and summarization of text information. Participated in the planning of the technical route and built a hybrid model combining extractive and generative approaches, utilizing advanced natural language processing techniques including KeyBERT, Sentence Transformer, BERT, and T5 models. Responsible for data preprocessing and tokenization, as well as the end-to-end implementation and training of the T5 model, optimizing the model architecture and hyperparameters, achieving satisfactory results after only 3 epochs of training. Model evaluation results showed that the Rouge-1, Rouge-2, and Rouge-L metrics reached 0.6345, 0.5038, and 0.5282, respectively, in the third epoch, validating the model\u0026rsquo;s effectiveness in the summarization task. üéì Cambridge University Machine Learning Summer Project 07/2023 ‚Äì 08/2023 Group project, supervised by Prof. Pietro Li√≤ Participated in the Cambridge University deep learning summer project, focusing on deep reinforcement learning; explored multi-agent learning algorithms across different environments. Reproduced the Multi-Agent Deep Deterministic Policy Gradient (MADDPG) algorithm in the Simple Adversary environment and studied the effect of agent numbers on convergence speed and stability, finding optimal stability at 21 agents. Designed and implemented comparative experiments inspired by the Rainbow algorithm, assessing target network strategies versus the Double Deep Q-Network (Double DQN). The results demonstrated that Double DQN significantly enhanced convergence speed, optimizing the overall learning process. Co-authored a group project paper on agent numbers and strategies effectiveness in multi-agent systems, achieving a score of 71% in the summer program (the highest in my group) and a \u0026ldquo;First Class\u0026rdquo; classification in the UK grading system. üëÅÔ∏è Deep Learning and Computer Vision Semester Project 09/2022 ‚Äì 12/2022 Independent project, supervised by Associate Prof. Guangyu Gao Designed and implemented a waste classifier using the ResNet model to improve classification accuracy and reduce resource waste. The project also enhanced understanding of transfer learning techniques with ResNet. Collected a dataset of 16 waste categories and preprocessed the images for uniformity and standardization, incorporating data augmentation techniques to enhance the dataset. Conducted experiments using ResNet34 and ResNet50 models through transfer learning, accelerating network convergence by leveraging pretrained weights. During training, techniques such as Batch Normalization and Dropout were applied to mitigate the risk of overfitting. The final model achieved an accuracy of 90% on the training set, while the performance on the test set was 61%, indicating a significant overfitting phenomenon during the training process. üéì Internship ‚öõÔ∏è Beijing Academy of Quantum Information Science 08/2023 ‚Äì 01/2024 Research Intern at Quantum Computation Department Proposed a quantum convolution kernel design based on variational quantum circuits and developed a universal quantum convolution layer, successfully integrating it into classical CNN architectures such as VGG, GoogLeNet, and ResNet. Developed and evaluated various hybrid models, including a simple model named HQCCNN-2, which achieved 84.45% accuracy on the FashionMNIST dataset, surpassing the traditional CNN\u0026rsquo;s 80.72%. This demonstrates the effectiveness of the quantum convolution layer in improving model performance. Tested on a real quantum computer further validated the effectiveness of the hybrid model, demonstrating the viable integration of quantum computing with deep learning, and highlighting the potential for leveraging quantum properties to enhance model performance. üèÖ Competition Experience ü•â China International \u0026#34;Internet \u0026#43;\u0026#34; College Students\u0026#39; Innovation Competition 08/2022 üõ°Ô∏è Zhongke Ushield: Deep Learning-based Face Privacy Protection Authentication System Responsible for constructing a localized facial feature extraction engine based on MobileFaceNet, ensuring feature extraction is completed on end devices (such as mobile phones and cameras), guaranteeing that raw data does not leave the domain and is not stored, thus enhancing user privacy protection while improving recognition efficiency. ü•â \u0026#34;Challenge Cup\u0026#34; Capital University Entrepreneurship Competition 05/2022 üå≥ Smart Orchard Responsible for the development of the fruit detection, ripeness prediction, and pest identification system, using deep convolutional neural network (CNN) technology for intelligent monitoring of crop growth conditions. Applied advanced object detection algorithms such as Faster R-CNN and YOLO to achieve high precision in apple detection and ripeness assessment, with an accuracy rate exceeding 90%, significantly enhancing the intelligence level of orchard management. Built and trained a dedicated dataset containing various pest samples, optimizing pest detection accuracy through data preprocessing (such as image normalization and resizing) and data augmentation techniques (like rotation, flipping, and noise addition), enabling the real-time monitoring system to accurately identify over 80% of pests, providing effective scientific maintenance recommendations to help farmers reduce crop losses. üìã Extracurricular Activities Vice President, Cyber Security Club, Beijing Institute of Technology 09/2021-09/2022 Backbone, Media Center of the Student Union of Beijing Institute of Technology 10/2020-06/2021 üì´ Contact üìß Email: zongsi.xu@outlook.com üëî LinkedIn: Zongsi (Tristan) Xu üíª GitHub: BaizeXS üìç Location: Hong Kong SAR, China ","permalink":"http://localhost:1313/resume/","summary":"Personal resume of Zongsi (Tristan) Xu","title":"Zongsi (Tristan) Xu"},{"content":"‰∏Ä„ÄÅÊï∞ÂÄºÁâπÂæÅ‰∏éÁ±ªÂà´ÁâπÂæÅ Êï∞ÂÄºÁâπÂæÅ (Numeric Features) ÂÖ∑ÊúâÂèØÂä†ÂáèÁöÑÊÑè‰πâÔºå‰∏îÂ≠òÂú®Â§ßÂ∞èÈ°∫Â∫è„ÄÇ ‰æãÂ≠êÔºöÂπ¥ÈæÑ„ÄÅÊ∏©Â∫¶Á≠â„ÄÇÂèØ‰ª•Áõ¥Êé•‰øùÁïôÂÖ∂Êï¥Êï∞ÊàñÊµÆÁÇπÊï∞ÂΩ¢Âºè‰æõÊ®°Âûã‰ΩøÁî®„ÄÇ Á±ªÂà´ÁâπÂæÅ (Categorical Features) Êï∞ÊçÆÂÄºÁ¶ªÊï£Ôºå‰∏çÂÖ∑Â§á‚ÄúÊï∞ÂÄºÂ§ßÂ∞è‚ÄùÈó¥ÁöÑÂèØÊØîÊÑè‰πâ„ÄÇ ‰æãÂ≠êÔºöÂõΩÁ±çÔºàÁæéÂõΩ/‰∏≠ÂõΩ/Âç∞Â∫¶Á≠âÔºâ„ÄÅÊÄßÂà´ÔºàÁî∑/Â•≥ÔºâÁ≠â„ÄÇ ÈóÆÈ¢òÔºöËã•‰ªÖÁî®Êï¥Êï∞Ë°®Á§∫ÔºàÁæéÂõΩ=1, ‰∏≠ÂõΩ=2ÔºâÔºå‰ºöÂºïÂÖ•ÈîôËØØÁöÑÊï∞ÂÄºËøêÁÆóÂÖ≥Á≥ªÔºåÂ¶Ç ‚ÄúÁæéÂõΩ + ‰∏≠ÂõΩ = Âç∞Â∫¶‚Äù„ÄÇ ‰∫å„ÄÅOne-HotÁºñÁ†ÅÁöÑÂä®Êú∫‰∏éÊµÅÁ®ã ‰∏∫‰ªÄ‰πà‰ΩøÁî®One-Hot\nÈÄöËøáÂ∞ÜÁ±ªÂà´Êò†Â∞Ñ‰∏∫ÂêëÈáèÔºåÈÅøÂÖçÊï¥Êï∞ÁºñÁ†ÅÂºïÂÖ•ÁöÑ‰º™Êï∞ÂÄºÂÖ≥Á≥ª„ÄÇ ÂêåÊó∂‰øùÁïôÂêÑÁßçÂèØËÉΩÁ±ªÂà´ÁöÑ‰ø°ÊÅØÔºå‰∏î‰ªÖÂú®ÂØπÂ∫î‰ΩçÁΩÆ‰∏∫1ÔºåÂÖ∂‰ªñ‰ΩçÁΩÆ‰∏∫0„ÄÇ Âª∫Á´ãÊò†Â∞ÑÔºö‰ªéÁ±ªÂà´Âà∞Á¥¢Âºï\n‰∏∫ÊØè‰∏™Á±ªÂà´ÂàÜÈÖç‰∏Ä‰∏™ÂîØ‰∏ÄÁ¥¢ÂºïÔºåÈÄöÂ∏∏‰ªé1ÂºÄÂßã„ÄÇ È¢ÑÁïôÁ¥¢Âºï0Ë°®Á§∫‚ÄúÊú™Áü•‚ÄùÊàñ‚ÄúÁº∫Â§±‚ÄùÔºåÂØπÂ∫îÂÖ®0ÂêëÈáè„ÄÇ ËΩ¨Êç¢‰∏∫One-HotÂêëÈáè\nËã•Á±ªÂà´ÊÄªÊï∞‰∏∫197ÔºåÂàôÁî®197Áª¥ÂêëÈáèË°®Á§∫„ÄÇ ‰æãÂ≠êÔºöÁæéÂõΩ [1, 0, 0, 0, ‚Ä¶]Ôºå ‰∏≠ÂõΩ [0, 1, 0, 0, ‚Ä¶]„ÄÇ Á§∫‰æãÔºöË°®Á§∫‰∏Ä‰∏™‰∫∫ÁöÑÁâπÂæÅ\nÁâπÂæÅÂåÖÂê´ÔºàÂπ¥ÈæÑ, ÊÄßÂà´, ÂõΩÁ±çÔºåÂÖ∂‰∏≠ÂõΩÁ±ç197ÁßçÔºâ Áª¥Â∫¶ÊÄªÂíåÔºö1Áª¥_age + 1Áª¥_gender + 197Áª¥_nationality = 199Áª¥„ÄÇ ‰æãÂ¶Ç (28, Â•≥, ‰∏≠ÂõΩ) ‚Üí [28, 0, 0, 1, 0, ‚Ä¶, 0]„ÄÇ ‰∏â„ÄÅÊñáÊú¨Êï∞ÊçÆÂ§ÑÁêÜÊµÅÁ®ã ÊñáÊú¨Âú®Ëá™ÁÑ∂ËØ≠Ë®ÄÂ§ÑÁêÜÔºàNLPÔºâ‰∏≠‰Ωú‰∏∫Â∏∏ËßÅÁöÑÂéüÂßãËæìÂÖ•ÔºåÈúÄË¶ÅÊï∞ÂÄºÂåñÊâçËÉΩÈÄÅÂÖ•Ê®°Âûã„ÄÇ‰∏ÄËà¨Ê≠•È™§Â¶Ç‰∏ãÔºö\nÂàÜËØç (Tokenization)\nÂ∞ÜÊñáÊú¨ÊãÜÂàÜ‰∏∫‰∏Ä‰∏™‰∏™ÂçïËØçÔºàTokenÔºâ„ÄÇ ‰æãÂ≠êÔºö\u0026quot;... to be or not to be...\u0026quot; ‚Üí [\u0026quot;...\u0026quot;, \u0026quot;to\u0026quot;, \u0026quot;be\u0026quot;, \u0026quot;or\u0026quot;, \u0026quot;not\u0026quot;, \u0026quot;to\u0026quot;, \u0026quot;be\u0026quot;, \u0026quot;...\u0026quot;]„ÄÇ ÁªüËÆ°ËØçÈ¢ë \u0026amp; ÊûÑÂª∫ËØçÂÖ∏\nËØçÈ¢ëÁªüËÆ° Áî®ÂìàÂ∏åË°®/Â≠óÂÖ∏ËÆ∞ÂΩïÊØè‰∏™ÂçïËØçÂá∫Áé∞Ê¨°Êï∞„ÄÇ ÈÅçÂéÜÊñáÊú¨Êó∂ÔºåËã•ÂçïËØçÂ∞öÊú™ÂÖ•Ë°®ÔºåÂàôÊñ∞Âª∫ËÆ∞ÂΩïÔºõËã•Â∑≤Â≠òÂú®ÔºåÂàôËÆ°Êï∞+1„ÄÇ ÊéíÂ∫è‰∏éÁ¥¢Âºï ÊåâËØçÈ¢ëÈôçÂ∫èÊéíÂ∫èÔºåËØçÈ¢ëÊúÄÈ´òÁöÑÂçïËØçÊéíÂú®ÂâçÈù¢„ÄÇ Á¥¢Âºï‰ªé1ÂºÄÂßãÔºå0ÁïôÁªô‚ÄúÊú™Áü•‚Äù„ÄÇ ËØçÂÖ∏ËßÑÊ®°ÔºàvocabularyÔºâÂèØËßÜÈúÄÊ±ÇÊà™Êñ≠Ôºà‰æãÂ¶ÇÂè™‰øùÁïôTop 10kÔºâ„ÄÇ ‰∏∫‰ªÄ‰πàÁßªÈô§‰ΩéÈ¢ëËØç ‰ΩéÈ¢ëËØçÂèØËÉΩÊòØÊãºÂÜôÈîôËØØ„ÄÅÁΩïËßÅ‰∫∫ÂêçÁ≠âÔºåÂØπÊ®°ÂûãÂ∏ÆÂä©ÊúâÈôê„ÄÇ ÂáèÂ∞ëËØçÂÖ∏ËßÑÊ®°ÂèØÈôç‰ΩéËøêÁÆóÂºÄÈîÄ„ÄÅÂä†Âø´Ê®°ÂûãËÆ≠ÁªÉ‰∏éÊé®ÁêÜÈÄüÂ∫¶„ÄÇ Áã¨ÁÉ≠ÁºñÁ†Å (One-Hot Encoding)\nÂ∞ÜÊØè‰∏™ÂçïËØçÊò†Â∞Ñ‰∏∫ËØçÂÖ∏‰∏≠ÁöÑÁ¥¢ÂºïÂêéÔºàÂ¶Ç [2, 4, 1, 8, ‚Ä¶]ÔºâÔºåÂèØËøõ‰∏ÄÊ≠•ËΩ¨Êç¢ÊàêOne-HotÂêëÈáè„ÄÇ One-HotÁª¥Â∫¶ÂèñÂÜ≥‰∫é‰øùÁïô‰∏ãÊù•ÁöÑËØçÂÖ∏Â§ßÂ∞èÔºà‰æãÂ¶Ç1‰∏áÔºâ„ÄÇ Êú™Êî∂ÂΩïÂçïËØçÂèØËÉΩÁõ¥Êé•ÂøΩÁï•ÔºåÊàñÁªü‰∏ÄÁî®Á¥¢Âºï0‰ª£Êõø„ÄÇ Âõõ„ÄÅÊ†∏ÂøÉÊî∂Ëé∑‰∏éÂ∫îÁî® Á±ªÂà´ÁâπÂæÅÂøÖÈúÄÊï∞ÂÄºÂåñÔºö\n‰ΩøÁî®Êï¥Êï∞1,2,3‚Ä¶‰ªÖË°®Á§∫Á±ªÂà´‚ÄúÊ†áËØÜ‚ÄùÔºåÂπ∂‰∏ç‰ª£Ë°®ÂÆÉ‰ª¨ÂèØËøõË°åÊï∞ÂÄºËøêÁÆó„ÄÇ Âõ†Ê≠§ÈúÄË¶ÅOne-HotÁ≠âÁºñÁ†ÅÊñπÂºèÔºåÈÅøÂÖçÊï∞ÂÄºËØØËß£„ÄÇ ÊñáÊú¨Êï∞ÊçÆÈ¢ÑÂ§ÑÁêÜÔºö\nÂàÜËØç„ÄÅËØçÈ¢ëÁªüËÆ°„ÄÅÊûÑÂª∫ËØçÂÖ∏„ÄÅÁ¥¢ÂºïÂåñ„ÄÅOne-HotÊàñÂÖ∂‰ªñÊñπÂºèÔºàÂ¶ÇËØçÂµåÂÖ•ÔºâÊòØÂ∏∏ËßÅÊµÅÁ®ã„ÄÇ Ê≠£Á°ÆÁöÑÊñáÊú¨È¢ÑÂ§ÑÁêÜÂèØÊòæËëóÂΩ±ÂìçÊ®°ÂûãÊÄßËÉΩÂíåÊïàÁéá„ÄÇ ‰øùÁïôÊú™Áü•Á¥¢ÂºïÔºö\n‰øùËØÅÂØπÁº∫Â§±Êï∞ÊçÆÊàñÂ≠óÂÖ∏Â§ñÊñ∞ËØçËÉΩÊúâÂü∫Êú¨ÁöÑË°®Á§∫ÔºåÊèêÂçáÊ®°ÂûãÂÆπÈîôÊÄß„ÄÇ ÂÆûÈôÖ‰ΩøÁî®Ôºö\nÂØπ‰∫éÂ∞èËßÑÊ®°Á±ªÂà´ÂèØÁõ¥Êé•One-HotÁºñÁ†ÅÔºõÂØπ‰∫éËØçÂÖ∏ÂæàÂ§ßÁöÑÂú∫ÊôØÔºåÈÄöÂ∏∏‰ºöËøõ‰∏ÄÊ≠•ËÄÉËôëËØçÂµåÂÖ•ÔºàWord EmbeddingÔºâÊàñÈ¢ÑËÆ≠ÁªÉËØ≠Ë®ÄÊ®°Âûã„ÄÇ ","permalink":"http://localhost:1313/posts/nlp-1/","summary":"\u003ch2 id=\"‰∏ÄÊï∞ÂÄºÁâπÂæÅ‰∏éÁ±ªÂà´ÁâπÂæÅ\"\u003e‰∏Ä„ÄÅÊï∞ÂÄºÁâπÂæÅ‰∏éÁ±ªÂà´ÁâπÂæÅ\u003c/h2\u003e\n\u003col\u003e\n\u003cli\u003e\u003cstrong\u003eÊï∞ÂÄºÁâπÂæÅ (Numeric Features)\u003c/strong\u003e\n\u003cul\u003e\n\u003cli\u003eÂÖ∑ÊúâÂèØÂä†ÂáèÁöÑÊÑè‰πâÔºå‰∏îÂ≠òÂú®Â§ßÂ∞èÈ°∫Â∫è„ÄÇ\u003c/li\u003e\n\u003cli\u003e‰æãÂ≠êÔºöÂπ¥ÈæÑ„ÄÅÊ∏©Â∫¶Á≠â„ÄÇÂèØ‰ª•Áõ¥Êé•‰øùÁïôÂÖ∂Êï¥Êï∞ÊàñÊµÆÁÇπÊï∞ÂΩ¢Âºè‰æõÊ®°Âûã‰ΩøÁî®„ÄÇ\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003eÁ±ªÂà´ÁâπÂæÅ (Categorical Features)\u003c/strong\u003e\n\u003cul\u003e\n\u003cli\u003eÊï∞ÊçÆÂÄºÁ¶ªÊï£Ôºå‰∏çÂÖ∑Â§á‚ÄúÊï∞ÂÄºÂ§ßÂ∞è‚ÄùÈó¥ÁöÑÂèØÊØîÊÑè‰πâ„ÄÇ\u003c/li\u003e\n\u003cli\u003e‰æãÂ≠êÔºöÂõΩÁ±çÔºàÁæéÂõΩ/‰∏≠ÂõΩ/Âç∞Â∫¶Á≠âÔºâ„ÄÅÊÄßÂà´ÔºàÁî∑/Â•≥ÔºâÁ≠â„ÄÇ\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003eÈóÆÈ¢ò\u003c/strong\u003eÔºöËã•‰ªÖÁî®Êï¥Êï∞Ë°®Á§∫ÔºàÁæéÂõΩ=1, ‰∏≠ÂõΩ=2ÔºâÔºå‰ºöÂºïÂÖ•ÈîôËØØÁöÑÊï∞ÂÄºËøêÁÆóÂÖ≥Á≥ªÔºåÂ¶Ç ‚ÄúÁæéÂõΩ + ‰∏≠ÂõΩ = Âç∞Â∫¶‚Äù„ÄÇ\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003c/ol\u003e\n\u003ch2 id=\"‰∫åone-hotÁºñÁ†ÅÁöÑÂä®Êú∫‰∏éÊµÅÁ®ã\"\u003e‰∫å„ÄÅOne-HotÁºñÁ†ÅÁöÑÂä®Êú∫‰∏éÊµÅÁ®ã\u003c/h2\u003e\n\u003col\u003e\n\u003cli\u003e\n\u003cp\u003e\u003cstrong\u003e‰∏∫‰ªÄ‰πà‰ΩøÁî®One-Hot\u003c/strong\u003e\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eÈÄöËøáÂ∞ÜÁ±ªÂà´Êò†Â∞Ñ‰∏∫ÂêëÈáèÔºåÈÅøÂÖçÊï¥Êï∞ÁºñÁ†ÅÂºïÂÖ•ÁöÑ‰º™Êï∞ÂÄºÂÖ≥Á≥ª„ÄÇ\u003c/li\u003e\n\u003cli\u003eÂêåÊó∂‰øùÁïôÂêÑÁßçÂèØËÉΩÁ±ªÂà´ÁöÑ‰ø°ÊÅØÔºå‰∏î‰ªÖÂú®ÂØπÂ∫î‰ΩçÁΩÆ‰∏∫1ÔºåÂÖ∂‰ªñ‰ΩçÁΩÆ‰∏∫0„ÄÇ\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003e\u003cstrong\u003eÂª∫Á´ãÊò†Â∞ÑÔºö‰ªéÁ±ªÂà´Âà∞Á¥¢Âºï\u003c/strong\u003e\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e‰∏∫ÊØè‰∏™Á±ªÂà´ÂàÜÈÖç‰∏Ä‰∏™ÂîØ‰∏ÄÁ¥¢ÂºïÔºåÈÄöÂ∏∏‰ªé1ÂºÄÂßã„ÄÇ\u003c/li\u003e\n\u003cli\u003eÈ¢ÑÁïôÁ¥¢Âºï0Ë°®Á§∫‚ÄúÊú™Áü•‚ÄùÊàñ‚ÄúÁº∫Â§±‚ÄùÔºåÂØπÂ∫îÂÖ®0ÂêëÈáè„ÄÇ\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003e\u003cstrong\u003eËΩ¨Êç¢‰∏∫One-HotÂêëÈáè\u003c/strong\u003e\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eËã•Á±ªÂà´ÊÄªÊï∞‰∏∫197ÔºåÂàôÁî®197Áª¥ÂêëÈáèË°®Á§∫„ÄÇ\u003c/li\u003e\n\u003cli\u003e‰æãÂ≠êÔºöÁæéÂõΩ \u003ccode\u003e[1, 0, 0, 0, ‚Ä¶]\u003c/code\u003eÔºå ‰∏≠ÂõΩ \u003ccode\u003e[0, 1, 0, 0, ‚Ä¶]\u003c/code\u003e„ÄÇ\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003e\u003cstrong\u003eÁ§∫‰æãÔºöË°®Á§∫‰∏Ä‰∏™‰∫∫ÁöÑÁâπÂæÅ\u003c/strong\u003e\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eÁâπÂæÅÂåÖÂê´ÔºàÂπ¥ÈæÑ, ÊÄßÂà´, ÂõΩÁ±çÔºåÂÖ∂‰∏≠ÂõΩÁ±ç197ÁßçÔºâ\u003c/li\u003e\n\u003cli\u003eÁª¥Â∫¶ÊÄªÂíåÔºö1Áª¥_age + 1Áª¥_gender + 197Áª¥_nationality = 199Áª¥„ÄÇ\u003c/li\u003e\n\u003cli\u003e‰æãÂ¶Ç \u003ccode\u003e(28, Â•≥, ‰∏≠ÂõΩ)\u003c/code\u003e ‚Üí \u003ccode\u003e[28, 0, 0, 1, 0, ‚Ä¶, 0]\u003c/code\u003e„ÄÇ\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003c/ol\u003e\n\u003ch2 id=\"‰∏âÊñáÊú¨Êï∞ÊçÆÂ§ÑÁêÜÊµÅÁ®ã\"\u003e‰∏â„ÄÅÊñáÊú¨Êï∞ÊçÆÂ§ÑÁêÜÊµÅÁ®ã\u003c/h2\u003e\n\u003cp\u003eÊñáÊú¨Âú®Ëá™ÁÑ∂ËØ≠Ë®ÄÂ§ÑÁêÜÔºàNLPÔºâ‰∏≠‰Ωú‰∏∫Â∏∏ËßÅÁöÑÂéüÂßãËæìÂÖ•ÔºåÈúÄË¶ÅÊï∞ÂÄºÂåñÊâçËÉΩÈÄÅÂÖ•Ê®°Âûã„ÄÇ‰∏ÄËà¨Ê≠•È™§Â¶Ç‰∏ãÔºö\u003c/p\u003e\n\u003col\u003e\n\u003cli\u003e\n\u003cp\u003e\u003cstrong\u003eÂàÜËØç (Tokenization)\u003c/strong\u003e\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eÂ∞ÜÊñáÊú¨ÊãÜÂàÜ‰∏∫‰∏Ä‰∏™‰∏™ÂçïËØçÔºàTokenÔºâ„ÄÇ\u003c/li\u003e\n\u003cli\u003e‰æãÂ≠êÔºö\u003ccode\u003e\u0026quot;... to be or not to be...\u0026quot;\u003c/code\u003e ‚Üí \u003ccode\u003e[\u0026quot;...\u0026quot;, \u0026quot;to\u0026quot;, \u0026quot;be\u0026quot;, \u0026quot;or\u0026quot;, \u0026quot;not\u0026quot;, \u0026quot;to\u0026quot;, \u0026quot;be\u0026quot;, \u0026quot;...\u0026quot;]\u003c/code\u003e„ÄÇ\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003e\u003cstrong\u003eÁªüËÆ°ËØçÈ¢ë \u0026amp; ÊûÑÂª∫ËØçÂÖ∏\u003c/strong\u003e\u003c/p\u003e","title":""},{"content":"Text to Sequence ÊñáÊú¨Â§ÑÁêÜ\nStep1: Tokenization\nTokenization breaks a piece of text down into a list of tokens.\nHere, a token is a word. (A token can be a character in some applications.)\nTokenizationËÆ≤Á©∂ÂæàÂ§öÔºå‰æãÂ¶ÇÊòØÂê¶Â∫îËØ•ÊääÂ§ßÂÜôÊîπÊàêÂ∞èÂÜôÂë¢ÔºüËøõË°åtypo correctionÁ≠âÁ≠â\nStep2: Build Dictionary\nUse a dictionary (hash table) to count word frequencies.\nThe dictionary maps word to index.\nÂèØ‰ª•È¶ñÂÖàÁªüËÆ°ËØçÈ¢ëÂéªÊéâ‰ΩéÈ¢ëËØçÔºåÁÑ∂ÂêéËÆ©ÊØè‰∏™ËØçÂØπÂ∫î‰∏Ä‰∏™Ê≠£Êï¥Êï∞ÔºõËøôÊ†∑ÁöÑËØùÔºå‰∏ÄÂè•ËØùÂ∞±ÂèØ‰ª•Áî®‰∏Ä‰∏™Ê≠£Êï¥Êï∞ÂàóË°®Ë°®Á§∫ÔºåËøô‰∏™ÂàóË°®Â∞±Âè´sequenceÔºõÂ¶ÇÊûúÂøÖË¶ÅÂ∞±ËøòÂæóÂÅöone-hot encoding„ÄÇ\nÁªìÊûú\n‰ΩÜÊòØÈïøÂ∫¶‰∏çÁªü‰∏Ä\nStep4: ÂØπÈΩêsequence\nËß£ÂÜ≥ÊñπÊ°àÊòØËøôÊ†∑ÁöÑÔºöÂèØ‰ª•Âõ∫ÂÆöÈïøÂ∫¶‰∏∫wÔºåÂä†ÂÖ•‰∏Ä‰∏™Â∫èÂàóÈïøÂ∫¶Â§™ÈïøÔºåÂ∞±Á†çÊéâÂâçÈù¢ÁöÑËØçÔºåÂè™‰øùÁïôÊúÄÂêéw‰∏™ËØçÔºõÂ¶ÇÊûú‰∏Ä‰∏™Â∫èÂàóÂ§™Áü≠ÔºåÂ∞±ÂÅözero paddingÔºåÁî®0Â°´ÂÖÖ\nËøôÊ†∑‰∏ÄÊù•ÔºåÊâÄÊúâÁöÑÂ∫èÂàóÈïøÂ∫¶Â∞±Áªü‰∏Ä‰∫Ü\nÊñáÊú¨Â§ÑÁêÜÂÆåÊàê‰∫ÜÔºåÊé•‰∏ãÊù•ÊòØword embeddingÔºåÊääÂçïËØçË°®Á§∫‰∏∫‰∏Ä‰∏™‰ΩéÁª¥ÂêëÈáèÔºõ\nÁÑ∂ËÄåËøôÊ†∑ÂÅöÁöÑËØùÔºåÂ¶ÇÊûúÊòØ10000‰∏™ÂçïËØçÔºåÁª¥Â∫¶Â∞±ÊòØ10000Áª¥ÔºåÁª¥Â∫¶Â§™È´ò‰∫ÜÔºõÂõ†Ê≠§Ë¶ÅÂÅöword embeddingÔºõ\nÂÖ∑‰ΩìÂÅöÊ≥ïÂ∞±ÊòØÊääone-hotÂêëÈáèe_iÂíåÂèÇÊï∞Áü©ÈòµpÁõ∏‰πòÔºõÁü©ÈòµPËΩ¨ÁΩÆÁöÑÂ§ßÂ∞èÊòØd x vÔºõdÊòØËØçÂêëÈáèÁöÑÁª¥Â∫¶ÔºõvÊòØÂ≠óÂÖ∏ÈáåËØçÊ±áÁöÑÊï∞ÈáèÔºõÁªìÊûú‰∏∫x_iÔºõx_iÂ∞±ÊòØ‰∏Ä‰∏™ËØçÂêëÈáèÔºõÂ¶ÇÊûúone-hotÂêëÈáèÁöÑÁ¨¨‰∏âË°å‰∏∫1ÔºõÈÇ£‰πàx_iÂ∞±ÊòØPËΩ¨ÁΩÆÁü©ÈòµÁöÑÁ¨¨‰∏âÂàóÔºàÂÖ∂‰ΩôÂàóÈÉΩ‰∏∫0ÔºâÔºõÊâÄ‰ª•PËΩ¨ÁΩÆÊØè‰∏ÄÂàóÈÉΩÊòØ‰∏Ä‰∏™ËØçÂêëÈáèÔºõÊâÄ‰ª•Áü©ÈòµPÊú¨Ë∫´ÁöÑÊØè‰∏ÄË°åÂ∞±ÊòØ‰∏Ä‰∏™ËØçÂêëÈáèÔºõÂÖ∂Ë°åÊï∞‰∏∫vÔºõÂç≥vocabularyÔºåËØçÊ±áÈáèÔºõÊØè‰∏ÄË°åÂØπÂ∫î‰∏Ä‰∏™ÂçïËØçÔºõÁü©ÈòµÁöÑÂàóÊï∞‰∏∫dÔºõdÊòØÁî®Êà∑ÂÜ≥ÂÆöÁöÑÔºõdÁöÑÂ§ßÂ∞è‰ºöÂÜ≥ÂÆöÊú∫Âô®Â≠¶‰π†Ê®°ÂûãÁöÑË°®Áé∞ÔºõÂ∫îËØ•Áî®xxxÊù•ÈÄâÊã©‰∏Ä‰∏™ÊØîËæÉÂ•ΩÁöÑdÔºõ\nÊàë‰ª¨ÁöÑ‰ªªÂä°ÊòØÁúãËØÑËÆ∫ÊòØÊ≠£Èù¢ÁöÑËøòÊòØË¥üÈù¢ÁöÑÔºõÂèÇÊï∞Áü©ÈòµÊòØ‰ªéËÆ≠ÁªÉÊï∞ÊçÆ‰∏≠Â≠¶‰π†Âá∫Êù•ÁöÑÔºåÊâÄ‰ª•Â≠¶Âá∫Êù•ÁöÑËØçÂêëÈáèÊòØÂ∏¶ÊúâÊÑüÊÉÖËâ≤ÂΩ©ÁöÑÔºõÂÅáËÆæËøô‰∫õËØçÂêëÈáèÈÉΩÊòØ‰∫åÁª¥ÁöÑÔºåÂàôÂèØ‰ª•Âú®Âπ≥Èù¢ÂùêÊ†áÁ≥ª‰∏≠Ê†áÂá∫‰∏ãÈù¢ËØçÂêëÈáè\nkerasÊèê‰æõembeddingÂ±ÇÔºõÁî®Êà∑ÂèØ‰ª•ÊåáÂÆövocabularyÂ§ßÂ∞èÂíådÁöÑÂ§ßÂ∞èÔºõ‰ª•ÂèäÊØè‰∏Ä‰∏™sequenceÁöÑÈïøÂ∫¶ÔºõdÊòØÊ†πÊçÆÁÆóÊ≥ïÈÄâÂá∫Êù•ÁöÑ Âà∞Ëøô‰∏ÄÊ≠•ÔºåÊàë‰ª¨Â∑≤ÁªèÂÆåÊàê‰∫ÜÊñáÊú¨Â§ÑÁêÜÂíåword embedding„ÄÇÊé•‰∏ãÊù•Â∞±ÊòØÁî®Logistic Regression for Binary ClassificationÂÅö‰∫åÂàÜÁ±ªÔºõ\n","permalink":"http://localhost:1313/posts/nlp-2/","summary":"\u003ch3 id=\"text-to-sequence\"\u003eText to Sequence\u003c/h3\u003e\n\u003cp\u003eÊñáÊú¨Â§ÑÁêÜ\u003c/p\u003e\n\u003cp\u003eStep1: Tokenization\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\n\u003cp\u003eTokenization breaks a piece of text down into a list of tokens.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003eHere, a token is a word. (A token can be a character in some applications.)\u003c/p\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003eTokenizationËÆ≤Á©∂ÂæàÂ§öÔºå‰æãÂ¶ÇÊòØÂê¶Â∫îËØ•ÊääÂ§ßÂÜôÊîπÊàêÂ∞èÂÜôÂë¢ÔºüËøõË°åtypo correctionÁ≠âÁ≠â\u003c/p\u003e\n\u003cp\u003e\u003cimg alt=\"image-20250322150322238\" loading=\"lazy\" src=\"./NLP-2.assets/image-20250322150322238.png\"\u003e\u003c/p\u003e\n\u003cp\u003eStep2: Build Dictionary\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\n\u003cp\u003eUse a dictionary (hash table) to count word frequencies.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003eThe dictionary maps word to index.\u003c/p\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003eÂèØ‰ª•È¶ñÂÖàÁªüËÆ°ËØçÈ¢ëÂéªÊéâ‰ΩéÈ¢ëËØçÔºåÁÑ∂ÂêéËÆ©ÊØè‰∏™ËØçÂØπÂ∫î‰∏Ä‰∏™Ê≠£Êï¥Êï∞ÔºõËøôÊ†∑ÁöÑËØùÔºå‰∏ÄÂè•ËØùÂ∞±ÂèØ‰ª•Áî®‰∏Ä‰∏™Ê≠£Êï¥Êï∞ÂàóË°®Ë°®Á§∫ÔºåËøô‰∏™ÂàóË°®Â∞±Âè´sequenceÔºõÂ¶ÇÊûúÂøÖË¶ÅÂ∞±ËøòÂæóÂÅöone-hot encoding„ÄÇ\u003cimg alt=\"image-20250322150620890\" loading=\"lazy\" src=\"./NLP-2.assets/image-20250322150620890.png\"\u003e\u003c/p\u003e\n\u003cp\u003eÁªìÊûú\u003c/p\u003e\n\u003cp\u003e\u003cimg alt=\"image-20250322150754528\" loading=\"lazy\" src=\"./NLP-2.assets/image-20250322150754528.png\"\u003e\u003c/p\u003e\n\u003cp\u003e‰ΩÜÊòØÈïøÂ∫¶‰∏çÁªü‰∏Ä\u003c/p\u003e\n\u003cp\u003eStep4: ÂØπÈΩêsequence\u003c/p\u003e\n\u003cp\u003e\u003cimg alt=\"image-20250322150854986\" loading=\"lazy\" src=\"./NLP-2.assets/image-20250322150854986.png\"\u003e\u003c/p\u003e\n\u003cp\u003eËß£ÂÜ≥ÊñπÊ°àÊòØËøôÊ†∑ÁöÑÔºöÂèØ‰ª•Âõ∫ÂÆöÈïøÂ∫¶‰∏∫wÔºåÂä†ÂÖ•‰∏Ä‰∏™Â∫èÂàóÈïøÂ∫¶Â§™ÈïøÔºåÂ∞±Á†çÊéâÂâçÈù¢ÁöÑËØçÔºåÂè™‰øùÁïôÊúÄÂêéw‰∏™ËØçÔºõÂ¶ÇÊûú‰∏Ä‰∏™Â∫èÂàóÂ§™Áü≠ÔºåÂ∞±ÂÅözero paddingÔºåÁî®0Â°´ÂÖÖ\u003c/p\u003e\n\u003cp\u003e\u003cimg alt=\"image-20250322151030119\" loading=\"lazy\" src=\"./NLP-2.assets/image-20250322151030119.png\"\u003e\u003c/p\u003e\n\u003cp\u003eËøôÊ†∑‰∏ÄÊù•ÔºåÊâÄÊúâÁöÑÂ∫èÂàóÈïøÂ∫¶Â∞±Áªü‰∏Ä‰∫Ü\u003c/p\u003e\n\u003cp\u003e\u003cimg alt=\"image-20250322151117125\" loading=\"lazy\" src=\"./NLP-2.assets/image-20250322151117125.png\"\u003e\u003c/p\u003e\n\u003cp\u003eÊñáÊú¨Â§ÑÁêÜÂÆåÊàê‰∫ÜÔºåÊé•‰∏ãÊù•ÊòØword embeddingÔºåÊääÂçïËØçË°®Á§∫‰∏∫‰∏Ä‰∏™‰ΩéÁª¥ÂêëÈáèÔºõ\u003c/p\u003e\n\u003cp\u003e\u003cimg alt=\"image-20250322151252837\" loading=\"lazy\" src=\"./NLP-2.assets/image-20250322151252837.png\"\u003e\u003c/p\u003e","title":""},{"content":"üëã About me Hello! I\u0026rsquo;m Xu Zongsi, a passionate technology enthusiast currently pursuing my Master of Science in ECIC at The University of Hong Kong. With a solid background in Software Engineering from the Beijing Institute of Technology, I specialize in artificial intelligence areas like machine learning, deep learning, natural language processing, computer vision, and reinforcement learning.\nInspired by OpenAI\u0026rsquo;s five-step plan towards superintelligence, I am excited about AGI and have developed a keen interest in LLM agents, MLLM, and knowledge graphs. I see great potential in these fields and aspire to contribute to innovative solutions.\nüìö Education üá≠üá∞ The University of Hong Kong 09/2024 - Expected 11/2025 School of Computing and Data Science Master of Science in Electronic Commerce \u0026amp; Internet Computing Relevant Courses: Machine learning for business and e-commerce, Knowledge graphs, Financial fraud analytics, Internet infrastructure technologies, Website engineering, Blockchain and cryptocurrency, etc. üá®üá≥ Beijing Institute of Technology 09/2020 - 06/2024 School of Computer Science \u0026amp; Technology Bachelor of Engineering in Software Engineering, last two years GPA: 3.7/4 Relevant Courses: Reinforcement Learning, Deep Learning and Computer Vision, Artificial Intelligence and Robot Ethics, Almost Human: Mind, Brain and Artificial Intelligence, Mathematical Analysis for Engineering, Linear Algebra, Probability and Mathematical Statistics, etc. Skills: Python, Java, common data structures, design patterns, machine learning basics and algorithms, Linux, PyTorch, and some development tools (git, conda, etc.). üèÜ Awards \u0026amp; Honors Beijing Institute of Technology Undergraduate Scholarship (Top 20% of Grade) 06/2023 3rd Prize of China International \u0026#34;Internet \u0026#43;\u0026#34; College Student\u0026#39;s Innovation Competition 08/2022 Bronze Prize of \u0026#34;Challenge Cup\u0026#34; Capital University Entrepreneurship Competition 05/2022 üíº Project Experience üîç Online Transaction Fraud Detection 09/2024 ‚Äì 01/2025 Independent project, supervised by Dr. Vivien Chan Focused on addressing financial fraud in e-commerce to enhance the accuracy of transaction anomaly detection, while independently managing the entire case study that included data preprocessing, feature engineering, model building, evaluation, and results analysis. Effectively resolved class imbalance issues using SMOTE and ROSE techniques. Built various models including Logistic Regression, Random Forest, XGBoost, and LightGBM, ultimately selecting the LightGBM model to achieve a recall rate of 95.45% and an AUC of 99.84%. Wrote efficient and maintainable code, enhancing model training and data processing efficiency through parallel computing and logging. ü§ñ Multi-Model Intelligent Text Keyword Extraction System 08/2023 ‚Äì 09/2023 Group project, supervised by Associate Prof. Xiaolin Zhao Designed and implemented an intelligent text summary system that automatically extracts keywords from article titles and abstracts, enhancing the understanding and summarization of text information. Participated in the planning of the technical route and built a hybrid model combining extractive and generative approaches, utilizing advanced natural language processing techniques including KeyBERT, Sentence Transformer, BERT, and T5 models. Responsible for data preprocessing and tokenization, as well as the end-to-end implementation and training of the T5 model, optimizing the model architecture and hyperparameters, achieving satisfactory results after only 3 epochs of training. Model evaluation results showed that the Rouge-1, Rouge-2, and Rouge-L metrics reached 0.6345, 0.5038, and 0.5282, respectively, in the third epoch, validating the model\u0026rsquo;s effectiveness in the summarization task. üéì Cambridge University Machine Learning Summer Project 07/2023 ‚Äì 08/2023 Group project, supervised by Prof. Pietro Li√≤ Participated in the Cambridge University deep learning summer project, focusing on deep reinforcement learning; explored multi-agent learning algorithms across different environments. Reproduced the Multi-Agent Deep Deterministic Policy Gradient (MADDPG) algorithm in the Simple Adversary environment and studied the effect of agent numbers on convergence speed and stability, finding optimal stability at 21 agents. Designed and implemented comparative experiments inspired by the Rainbow algorithm, assessing target network strategies versus the Double Deep Q-Network (Double DQN). The results demonstrated that Double DQN significantly enhanced convergence speed, optimizing the overall learning process. Co-authored a group project paper on agent numbers and strategies effectiveness in multi-agent systems, achieving a score of 71% in the summer program (the highest in my group) and a \u0026ldquo;First Class\u0026rdquo; classification in the UK grading system. üëÅÔ∏è Deep Learning and Computer Vision Semester Project 09/2022 ‚Äì 12/2022 Independent project, supervised by Associate Prof. Guangyu Gao Designed and implemented a waste classifier using the ResNet model to improve classification accuracy and reduce resource waste. The project also enhanced understanding of transfer learning techniques with ResNet. Collected a dataset of 16 waste categories and preprocessed the images for uniformity and standardization, incorporating data augmentation techniques to enhance the dataset. Conducted experiments using ResNet34 and ResNet50 models through transfer learning, accelerating network convergence by leveraging pretrained weights. During training, techniques such as Batch Normalization and Dropout were applied to mitigate the risk of overfitting. The final model achieved an accuracy of 90% on the training set, while the performance on the test set was 61%, indicating a significant overfitting phenomenon during the training process. üéì Internship ‚öõÔ∏è Beijing Academy of Quantum Information Science 08/2023 ‚Äì 01/2024 Research Intern at Quantum Computation Department Proposed a quantum convolution kernel design based on variational quantum circuits and developed a universal quantum convolution layer, successfully integrating it into classical CNN architectures such as VGG, GoogLeNet, and ResNet. Developed and evaluated various hybrid models, including a simple model named HQCCNN-2, which achieved 84.45% accuracy on the FashionMNIST dataset, surpassing the traditional CNN\u0026rsquo;s 80.72%. This demonstrates the effectiveness of the quantum convolution layer in improving model performance. Tested on a real quantum computer further validated the effectiveness of the hybrid model, demonstrating the viable integration of quantum computing with deep learning, and highlighting the potential for leveraging quantum properties to enhance model performance. üèÖ Competition Experience ü•â China International \u0026#34;Internet \u0026#43;\u0026#34; College Students\u0026#39; Innovation Competition 08/2022 üõ°Ô∏è Zhongke Ushield: Deep Learning-based Face Privacy Protection Authentication System Responsible for constructing a localized facial feature extraction engine based on MobileFaceNet, ensuring feature extraction is completed on end devices (such as mobile phones and cameras), guaranteeing that raw data does not leave the domain and is not stored, thus enhancing user privacy protection while improving recognition efficiency. ü•â \u0026#34;Challenge Cup\u0026#34; Capital University Entrepreneurship Competition 05/2022 üå≥ Smart Orchard Responsible for the development of the fruit detection, ripeness prediction, and pest identification system, using deep convolutional neural network (CNN) technology for intelligent monitoring of crop growth conditions. Applied advanced object detection algorithms such as Faster R-CNN and YOLO to achieve high precision in apple detection and ripeness assessment, with an accuracy rate exceeding 90%, significantly enhancing the intelligence level of orchard management. Built and trained a dedicated dataset containing various pest samples, optimizing pest detection accuracy through data preprocessing (such as image normalization and resizing) and data augmentation techniques (like rotation, flipping, and noise addition), enabling the real-time monitoring system to accurately identify over 80% of pests, providing effective scientific maintenance recommendations to help farmers reduce crop losses. üìã Extracurricular Activities Vice President, Cyber Security Club, Beijing Institute of Technology 09/2021-09/2022 Backbone, Media Center of the Student Union of Beijing Institute of Technology 10/2020-06/2021 üì´ Contact üìß Email: zongsi.xu@outlook.com üëî LinkedIn: Zongsi (Tristan) Xu üíª GitHub: BaizeXS üìç Location: Hong Kong SAR, China ","permalink":"http://localhost:1313/resume/","summary":"Personal resume of Zongsi (Tristan) Xu","title":"Zongsi (Tristan) Xu"},{"content":"‰∏Ä„ÄÅÊï∞ÂÄºÁâπÂæÅ‰∏éÁ±ªÂà´ÁâπÂæÅ Êï∞ÂÄºÁâπÂæÅ (Numeric Features) ÂÖ∑ÊúâÂèØÂä†ÂáèÁöÑÊÑè‰πâÔºå‰∏îÂ≠òÂú®Â§ßÂ∞èÈ°∫Â∫è„ÄÇ ‰æãÂ≠êÔºöÂπ¥ÈæÑ„ÄÅÊ∏©Â∫¶Á≠â„ÄÇÂèØ‰ª•Áõ¥Êé•‰øùÁïôÂÖ∂Êï¥Êï∞ÊàñÊµÆÁÇπÊï∞ÂΩ¢Âºè‰æõÊ®°Âûã‰ΩøÁî®„ÄÇ Á±ªÂà´ÁâπÂæÅ (Categorical Features) Êï∞ÊçÆÂÄºÁ¶ªÊï£Ôºå‰∏çÂÖ∑Â§á‚ÄúÊï∞ÂÄºÂ§ßÂ∞è‚ÄùÈó¥ÁöÑÂèØÊØîÊÑè‰πâ„ÄÇ ‰æãÂ≠êÔºöÂõΩÁ±çÔºàÁæéÂõΩ/‰∏≠ÂõΩ/Âç∞Â∫¶Á≠âÔºâ„ÄÅÊÄßÂà´ÔºàÁî∑/Â•≥ÔºâÁ≠â„ÄÇ ÈóÆÈ¢òÔºöËã•‰ªÖÁî®Êï¥Êï∞Ë°®Á§∫ÔºàÁæéÂõΩ=1, ‰∏≠ÂõΩ=2ÔºâÔºå‰ºöÂºïÂÖ•ÈîôËØØÁöÑÊï∞ÂÄºËøêÁÆóÂÖ≥Á≥ªÔºåÂ¶Ç ‚ÄúÁæéÂõΩ + ‰∏≠ÂõΩ = Âç∞Â∫¶‚Äù„ÄÇ ‰∫å„ÄÅOne-HotÁºñÁ†ÅÁöÑÂä®Êú∫‰∏éÊµÅÁ®ã ‰∏∫‰ªÄ‰πà‰ΩøÁî®One-Hot\nÈÄöËøáÂ∞ÜÁ±ªÂà´Êò†Â∞Ñ‰∏∫ÂêëÈáèÔºåÈÅøÂÖçÊï¥Êï∞ÁºñÁ†ÅÂºïÂÖ•ÁöÑ‰º™Êï∞ÂÄºÂÖ≥Á≥ª„ÄÇ ÂêåÊó∂‰øùÁïôÂêÑÁßçÂèØËÉΩÁ±ªÂà´ÁöÑ‰ø°ÊÅØÔºå‰∏î‰ªÖÂú®ÂØπÂ∫î‰ΩçÁΩÆ‰∏∫1ÔºåÂÖ∂‰ªñ‰ΩçÁΩÆ‰∏∫0„ÄÇ Âª∫Á´ãÊò†Â∞ÑÔºö‰ªéÁ±ªÂà´Âà∞Á¥¢Âºï\n‰∏∫ÊØè‰∏™Á±ªÂà´ÂàÜÈÖç‰∏Ä‰∏™ÂîØ‰∏ÄÁ¥¢ÂºïÔºåÈÄöÂ∏∏‰ªé1ÂºÄÂßã„ÄÇ È¢ÑÁïôÁ¥¢Âºï0Ë°®Á§∫‚ÄúÊú™Áü•‚ÄùÊàñ‚ÄúÁº∫Â§±‚ÄùÔºåÂØπÂ∫îÂÖ®0ÂêëÈáè„ÄÇ ËΩ¨Êç¢‰∏∫One-HotÂêëÈáè\nËã•Á±ªÂà´ÊÄªÊï∞‰∏∫197ÔºåÂàôÁî®197Áª¥ÂêëÈáèË°®Á§∫„ÄÇ ‰æãÂ≠êÔºöÁæéÂõΩ [1, 0, 0, 0, ‚Ä¶]Ôºå ‰∏≠ÂõΩ [0, 1, 0, 0, ‚Ä¶]„ÄÇ Á§∫‰æãÔºöË°®Á§∫‰∏Ä‰∏™‰∫∫ÁöÑÁâπÂæÅ\nÁâπÂæÅÂåÖÂê´ÔºàÂπ¥ÈæÑ, ÊÄßÂà´, ÂõΩÁ±çÔºåÂÖ∂‰∏≠ÂõΩÁ±ç197ÁßçÔºâ Áª¥Â∫¶ÊÄªÂíåÔºö1Áª¥_age + 1Áª¥_gender + 197Áª¥_nationality = 199Áª¥„ÄÇ ‰æãÂ¶Ç (28, Â•≥, ‰∏≠ÂõΩ) ‚Üí [28, 0, 0, 1, 0, ‚Ä¶, 0]„ÄÇ ‰∏â„ÄÅÊñáÊú¨Êï∞ÊçÆÂ§ÑÁêÜÊµÅÁ®ã ÊñáÊú¨Âú®Ëá™ÁÑ∂ËØ≠Ë®ÄÂ§ÑÁêÜÔºàNLPÔºâ‰∏≠‰Ωú‰∏∫Â∏∏ËßÅÁöÑÂéüÂßãËæìÂÖ•ÔºåÈúÄË¶ÅÊï∞ÂÄºÂåñÊâçËÉΩÈÄÅÂÖ•Ê®°Âûã„ÄÇ‰∏ÄËà¨Ê≠•È™§Â¶Ç‰∏ãÔºö\nÂàÜËØç (Tokenization)\nÂ∞ÜÊñáÊú¨ÊãÜÂàÜ‰∏∫‰∏Ä‰∏™‰∏™ÂçïËØçÔºàTokenÔºâ„ÄÇ ‰æãÂ≠êÔºö\u0026quot;... to be or not to be...\u0026quot; ‚Üí [\u0026quot;...\u0026quot;, \u0026quot;to\u0026quot;, \u0026quot;be\u0026quot;, \u0026quot;or\u0026quot;, \u0026quot;not\u0026quot;, \u0026quot;to\u0026quot;, \u0026quot;be\u0026quot;, \u0026quot;...\u0026quot;]„ÄÇ ÁªüËÆ°ËØçÈ¢ë \u0026amp; ÊûÑÂª∫ËØçÂÖ∏\nËØçÈ¢ëÁªüËÆ° Áî®ÂìàÂ∏åË°®/Â≠óÂÖ∏ËÆ∞ÂΩïÊØè‰∏™ÂçïËØçÂá∫Áé∞Ê¨°Êï∞„ÄÇ ÈÅçÂéÜÊñáÊú¨Êó∂ÔºåËã•ÂçïËØçÂ∞öÊú™ÂÖ•Ë°®ÔºåÂàôÊñ∞Âª∫ËÆ∞ÂΩïÔºõËã•Â∑≤Â≠òÂú®ÔºåÂàôËÆ°Êï∞+1„ÄÇ ÊéíÂ∫è‰∏éÁ¥¢Âºï ÊåâËØçÈ¢ëÈôçÂ∫èÊéíÂ∫èÔºåËØçÈ¢ëÊúÄÈ´òÁöÑÂçïËØçÊéíÂú®ÂâçÈù¢„ÄÇ Á¥¢Âºï‰ªé1ÂºÄÂßãÔºå0ÁïôÁªô‚ÄúÊú™Áü•‚Äù„ÄÇ ËØçÂÖ∏ËßÑÊ®°ÔºàvocabularyÔºâÂèØËßÜÈúÄÊ±ÇÊà™Êñ≠Ôºà‰æãÂ¶ÇÂè™‰øùÁïôTop 10kÔºâ„ÄÇ ‰∏∫‰ªÄ‰πàÁßªÈô§‰ΩéÈ¢ëËØç ‰ΩéÈ¢ëËØçÂèØËÉΩÊòØÊãºÂÜôÈîôËØØ„ÄÅÁΩïËßÅ‰∫∫ÂêçÁ≠âÔºåÂØπÊ®°ÂûãÂ∏ÆÂä©ÊúâÈôê„ÄÇ ÂáèÂ∞ëËØçÂÖ∏ËßÑÊ®°ÂèØÈôç‰ΩéËøêÁÆóÂºÄÈîÄ„ÄÅÂä†Âø´Ê®°ÂûãËÆ≠ÁªÉ‰∏éÊé®ÁêÜÈÄüÂ∫¶„ÄÇ Áã¨ÁÉ≠ÁºñÁ†Å (One-Hot Encoding)\nÂ∞ÜÊØè‰∏™ÂçïËØçÊò†Â∞Ñ‰∏∫ËØçÂÖ∏‰∏≠ÁöÑÁ¥¢ÂºïÂêéÔºàÂ¶Ç [2, 4, 1, 8, ‚Ä¶]ÔºâÔºåÂèØËøõ‰∏ÄÊ≠•ËΩ¨Êç¢ÊàêOne-HotÂêëÈáè„ÄÇ One-HotÁª¥Â∫¶ÂèñÂÜ≥‰∫é‰øùÁïô‰∏ãÊù•ÁöÑËØçÂÖ∏Â§ßÂ∞èÔºà‰æãÂ¶Ç1‰∏áÔºâ„ÄÇ Êú™Êî∂ÂΩïÂçïËØçÂèØËÉΩÁõ¥Êé•ÂøΩÁï•ÔºåÊàñÁªü‰∏ÄÁî®Á¥¢Âºï0‰ª£Êõø„ÄÇ Âõõ„ÄÅÊ†∏ÂøÉÊî∂Ëé∑‰∏éÂ∫îÁî® Á±ªÂà´ÁâπÂæÅÂøÖÈúÄÊï∞ÂÄºÂåñÔºö\n‰ΩøÁî®Êï¥Êï∞1,2,3‚Ä¶‰ªÖË°®Á§∫Á±ªÂà´‚ÄúÊ†áËØÜ‚ÄùÔºåÂπ∂‰∏ç‰ª£Ë°®ÂÆÉ‰ª¨ÂèØËøõË°åÊï∞ÂÄºËøêÁÆó„ÄÇ Âõ†Ê≠§ÈúÄË¶ÅOne-HotÁ≠âÁºñÁ†ÅÊñπÂºèÔºåÈÅøÂÖçÊï∞ÂÄºËØØËß£„ÄÇ ÊñáÊú¨Êï∞ÊçÆÈ¢ÑÂ§ÑÁêÜÔºö\nÂàÜËØç„ÄÅËØçÈ¢ëÁªüËÆ°„ÄÅÊûÑÂª∫ËØçÂÖ∏„ÄÅÁ¥¢ÂºïÂåñ„ÄÅOne-HotÊàñÂÖ∂‰ªñÊñπÂºèÔºàÂ¶ÇËØçÂµåÂÖ•ÔºâÊòØÂ∏∏ËßÅÊµÅÁ®ã„ÄÇ Ê≠£Á°ÆÁöÑÊñáÊú¨È¢ÑÂ§ÑÁêÜÂèØÊòæËëóÂΩ±ÂìçÊ®°ÂûãÊÄßËÉΩÂíåÊïàÁéá„ÄÇ ‰øùÁïôÊú™Áü•Á¥¢ÂºïÔºö\n‰øùËØÅÂØπÁº∫Â§±Êï∞ÊçÆÊàñÂ≠óÂÖ∏Â§ñÊñ∞ËØçËÉΩÊúâÂü∫Êú¨ÁöÑË°®Á§∫ÔºåÊèêÂçáÊ®°ÂûãÂÆπÈîôÊÄß„ÄÇ ÂÆûÈôÖ‰ΩøÁî®Ôºö\nÂØπ‰∫éÂ∞èËßÑÊ®°Á±ªÂà´ÂèØÁõ¥Êé•One-HotÁºñÁ†ÅÔºõÂØπ‰∫éËØçÂÖ∏ÂæàÂ§ßÁöÑÂú∫ÊôØÔºåÈÄöÂ∏∏‰ºöËøõ‰∏ÄÊ≠•ËÄÉËôëËØçÂµåÂÖ•ÔºàWord EmbeddingÔºâÊàñÈ¢ÑËÆ≠ÁªÉËØ≠Ë®ÄÊ®°Âûã„ÄÇ ","permalink":"http://localhost:1313/posts/nlp-1/","summary":"\u003ch2 id=\"‰∏ÄÊï∞ÂÄºÁâπÂæÅ‰∏éÁ±ªÂà´ÁâπÂæÅ\"\u003e‰∏Ä„ÄÅÊï∞ÂÄºÁâπÂæÅ‰∏éÁ±ªÂà´ÁâπÂæÅ\u003c/h2\u003e\n\u003col\u003e\n\u003cli\u003e\u003cstrong\u003eÊï∞ÂÄºÁâπÂæÅ (Numeric Features)\u003c/strong\u003e\n\u003cul\u003e\n\u003cli\u003eÂÖ∑ÊúâÂèØÂä†ÂáèÁöÑÊÑè‰πâÔºå‰∏îÂ≠òÂú®Â§ßÂ∞èÈ°∫Â∫è„ÄÇ\u003c/li\u003e\n\u003cli\u003e‰æãÂ≠êÔºöÂπ¥ÈæÑ„ÄÅÊ∏©Â∫¶Á≠â„ÄÇÂèØ‰ª•Áõ¥Êé•‰øùÁïôÂÖ∂Êï¥Êï∞ÊàñÊµÆÁÇπÊï∞ÂΩ¢Âºè‰æõÊ®°Âûã‰ΩøÁî®„ÄÇ\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003eÁ±ªÂà´ÁâπÂæÅ (Categorical Features)\u003c/strong\u003e\n\u003cul\u003e\n\u003cli\u003eÊï∞ÊçÆÂÄºÁ¶ªÊï£Ôºå‰∏çÂÖ∑Â§á‚ÄúÊï∞ÂÄºÂ§ßÂ∞è‚ÄùÈó¥ÁöÑÂèØÊØîÊÑè‰πâ„ÄÇ\u003c/li\u003e\n\u003cli\u003e‰æãÂ≠êÔºöÂõΩÁ±çÔºàÁæéÂõΩ/‰∏≠ÂõΩ/Âç∞Â∫¶Á≠âÔºâ„ÄÅÊÄßÂà´ÔºàÁî∑/Â•≥ÔºâÁ≠â„ÄÇ\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003eÈóÆÈ¢ò\u003c/strong\u003eÔºöËã•‰ªÖÁî®Êï¥Êï∞Ë°®Á§∫ÔºàÁæéÂõΩ=1, ‰∏≠ÂõΩ=2ÔºâÔºå‰ºöÂºïÂÖ•ÈîôËØØÁöÑÊï∞ÂÄºËøêÁÆóÂÖ≥Á≥ªÔºåÂ¶Ç ‚ÄúÁæéÂõΩ + ‰∏≠ÂõΩ = Âç∞Â∫¶‚Äù„ÄÇ\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003c/ol\u003e\n\u003ch2 id=\"‰∫åone-hotÁºñÁ†ÅÁöÑÂä®Êú∫‰∏éÊµÅÁ®ã\"\u003e‰∫å„ÄÅOne-HotÁºñÁ†ÅÁöÑÂä®Êú∫‰∏éÊµÅÁ®ã\u003c/h2\u003e\n\u003col\u003e\n\u003cli\u003e\n\u003cp\u003e\u003cstrong\u003e‰∏∫‰ªÄ‰πà‰ΩøÁî®One-Hot\u003c/strong\u003e\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eÈÄöËøáÂ∞ÜÁ±ªÂà´Êò†Â∞Ñ‰∏∫ÂêëÈáèÔºåÈÅøÂÖçÊï¥Êï∞ÁºñÁ†ÅÂºïÂÖ•ÁöÑ‰º™Êï∞ÂÄºÂÖ≥Á≥ª„ÄÇ\u003c/li\u003e\n\u003cli\u003eÂêåÊó∂‰øùÁïôÂêÑÁßçÂèØËÉΩÁ±ªÂà´ÁöÑ‰ø°ÊÅØÔºå‰∏î‰ªÖÂú®ÂØπÂ∫î‰ΩçÁΩÆ‰∏∫1ÔºåÂÖ∂‰ªñ‰ΩçÁΩÆ‰∏∫0„ÄÇ\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003e\u003cstrong\u003eÂª∫Á´ãÊò†Â∞ÑÔºö‰ªéÁ±ªÂà´Âà∞Á¥¢Âºï\u003c/strong\u003e\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e‰∏∫ÊØè‰∏™Á±ªÂà´ÂàÜÈÖç‰∏Ä‰∏™ÂîØ‰∏ÄÁ¥¢ÂºïÔºåÈÄöÂ∏∏‰ªé1ÂºÄÂßã„ÄÇ\u003c/li\u003e\n\u003cli\u003eÈ¢ÑÁïôÁ¥¢Âºï0Ë°®Á§∫‚ÄúÊú™Áü•‚ÄùÊàñ‚ÄúÁº∫Â§±‚ÄùÔºåÂØπÂ∫îÂÖ®0ÂêëÈáè„ÄÇ\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003e\u003cstrong\u003eËΩ¨Êç¢‰∏∫One-HotÂêëÈáè\u003c/strong\u003e\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eËã•Á±ªÂà´ÊÄªÊï∞‰∏∫197ÔºåÂàôÁî®197Áª¥ÂêëÈáèË°®Á§∫„ÄÇ\u003c/li\u003e\n\u003cli\u003e‰æãÂ≠êÔºöÁæéÂõΩ \u003ccode\u003e[1, 0, 0, 0, ‚Ä¶]\u003c/code\u003eÔºå ‰∏≠ÂõΩ \u003ccode\u003e[0, 1, 0, 0, ‚Ä¶]\u003c/code\u003e„ÄÇ\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003e\u003cstrong\u003eÁ§∫‰æãÔºöË°®Á§∫‰∏Ä‰∏™‰∫∫ÁöÑÁâπÂæÅ\u003c/strong\u003e\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eÁâπÂæÅÂåÖÂê´ÔºàÂπ¥ÈæÑ, ÊÄßÂà´, ÂõΩÁ±çÔºåÂÖ∂‰∏≠ÂõΩÁ±ç197ÁßçÔºâ\u003c/li\u003e\n\u003cli\u003eÁª¥Â∫¶ÊÄªÂíåÔºö1Áª¥_age + 1Áª¥_gender + 197Áª¥_nationality = 199Áª¥„ÄÇ\u003c/li\u003e\n\u003cli\u003e‰æãÂ¶Ç \u003ccode\u003e(28, Â•≥, ‰∏≠ÂõΩ)\u003c/code\u003e ‚Üí \u003ccode\u003e[28, 0, 0, 1, 0, ‚Ä¶, 0]\u003c/code\u003e„ÄÇ\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003c/ol\u003e\n\u003ch2 id=\"‰∏âÊñáÊú¨Êï∞ÊçÆÂ§ÑÁêÜÊµÅÁ®ã\"\u003e‰∏â„ÄÅÊñáÊú¨Êï∞ÊçÆÂ§ÑÁêÜÊµÅÁ®ã\u003c/h2\u003e\n\u003cp\u003eÊñáÊú¨Âú®Ëá™ÁÑ∂ËØ≠Ë®ÄÂ§ÑÁêÜÔºàNLPÔºâ‰∏≠‰Ωú‰∏∫Â∏∏ËßÅÁöÑÂéüÂßãËæìÂÖ•ÔºåÈúÄË¶ÅÊï∞ÂÄºÂåñÊâçËÉΩÈÄÅÂÖ•Ê®°Âûã„ÄÇ‰∏ÄËà¨Ê≠•È™§Â¶Ç‰∏ãÔºö\u003c/p\u003e\n\u003col\u003e\n\u003cli\u003e\n\u003cp\u003e\u003cstrong\u003eÂàÜËØç (Tokenization)\u003c/strong\u003e\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eÂ∞ÜÊñáÊú¨ÊãÜÂàÜ‰∏∫‰∏Ä‰∏™‰∏™ÂçïËØçÔºàTokenÔºâ„ÄÇ\u003c/li\u003e\n\u003cli\u003e‰æãÂ≠êÔºö\u003ccode\u003e\u0026quot;... to be or not to be...\u0026quot;\u003c/code\u003e ‚Üí \u003ccode\u003e[\u0026quot;...\u0026quot;, \u0026quot;to\u0026quot;, \u0026quot;be\u0026quot;, \u0026quot;or\u0026quot;, \u0026quot;not\u0026quot;, \u0026quot;to\u0026quot;, \u0026quot;be\u0026quot;, \u0026quot;...\u0026quot;]\u003c/code\u003e„ÄÇ\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003e\u003cstrong\u003eÁªüËÆ°ËØçÈ¢ë \u0026amp; ÊûÑÂª∫ËØçÂÖ∏\u003c/strong\u003e\u003c/p\u003e","title":""},{"content":"Text to Sequence ÊñáÊú¨Â§ÑÁêÜ\nStep1: Tokenization\nTokenization breaks a piece of text down into a list of tokens.\nHere, a token is a word. (A token can be a character in some applications.)\nTokenizationËÆ≤Á©∂ÂæàÂ§öÔºå‰æãÂ¶ÇÊòØÂê¶Â∫îËØ•ÊääÂ§ßÂÜôÊîπÊàêÂ∞èÂÜôÂë¢ÔºüËøõË°åtypo correctionÁ≠âÁ≠â\nStep2: Build Dictionary\nUse a dictionary (hash table) to count word frequencies.\nThe dictionary maps word to index.\nÂèØ‰ª•È¶ñÂÖàÁªüËÆ°ËØçÈ¢ëÂéªÊéâ‰ΩéÈ¢ëËØçÔºåÁÑ∂ÂêéËÆ©ÊØè‰∏™ËØçÂØπÂ∫î‰∏Ä‰∏™Ê≠£Êï¥Êï∞ÔºõËøôÊ†∑ÁöÑËØùÔºå‰∏ÄÂè•ËØùÂ∞±ÂèØ‰ª•Áî®‰∏Ä‰∏™Ê≠£Êï¥Êï∞ÂàóË°®Ë°®Á§∫ÔºåËøô‰∏™ÂàóË°®Â∞±Âè´sequenceÔºõÂ¶ÇÊûúÂøÖË¶ÅÂ∞±ËøòÂæóÂÅöone-hot encoding„ÄÇ\nÁªìÊûú\n‰ΩÜÊòØÈïøÂ∫¶‰∏çÁªü‰∏Ä\nStep4: ÂØπÈΩêsequence\nËß£ÂÜ≥ÊñπÊ°àÊòØËøôÊ†∑ÁöÑÔºöÂèØ‰ª•Âõ∫ÂÆöÈïøÂ∫¶‰∏∫wÔºåÂä†ÂÖ•‰∏Ä‰∏™Â∫èÂàóÈïøÂ∫¶Â§™ÈïøÔºåÂ∞±Á†çÊéâÂâçÈù¢ÁöÑËØçÔºåÂè™‰øùÁïôÊúÄÂêéw‰∏™ËØçÔºõÂ¶ÇÊûú‰∏Ä‰∏™Â∫èÂàóÂ§™Áü≠ÔºåÂ∞±ÂÅözero paddingÔºåÁî®0Â°´ÂÖÖ\nËøôÊ†∑‰∏ÄÊù•ÔºåÊâÄÊúâÁöÑÂ∫èÂàóÈïøÂ∫¶Â∞±Áªü‰∏Ä‰∫Ü\nÊñáÊú¨Â§ÑÁêÜÂÆåÊàê‰∫ÜÔºåÊé•‰∏ãÊù•ÊòØword embeddingÔºåÊääÂçïËØçË°®Á§∫‰∏∫‰∏Ä‰∏™‰ΩéÁª¥ÂêëÈáèÔºõ\nÁÑ∂ËÄåËøôÊ†∑ÂÅöÁöÑËØùÔºåÂ¶ÇÊûúÊòØ10000‰∏™ÂçïËØçÔºåÁª¥Â∫¶Â∞±ÊòØ10000Áª¥ÔºåÁª¥Â∫¶Â§™È´ò‰∫ÜÔºõÂõ†Ê≠§Ë¶ÅÂÅöword embeddingÔºõ\nÂÖ∑‰ΩìÂÅöÊ≥ïÂ∞±ÊòØÊääone-hotÂêëÈáèe_iÂíåÂèÇÊï∞Áü©ÈòµpÁõ∏‰πòÔºõÁü©ÈòµPËΩ¨ÁΩÆÁöÑÂ§ßÂ∞èÊòØd x vÔºõdÊòØËØçÂêëÈáèÁöÑÁª¥Â∫¶ÔºõvÊòØÂ≠óÂÖ∏ÈáåËØçÊ±áÁöÑÊï∞ÈáèÔºõÁªìÊûú‰∏∫x_iÔºõx_iÂ∞±ÊòØ‰∏Ä‰∏™ËØçÂêëÈáèÔºõÂ¶ÇÊûúone-hotÂêëÈáèÁöÑÁ¨¨‰∏âË°å‰∏∫1ÔºõÈÇ£‰πàx_iÂ∞±ÊòØPËΩ¨ÁΩÆÁü©ÈòµÁöÑÁ¨¨‰∏âÂàóÔºàÂÖ∂‰ΩôÂàóÈÉΩ‰∏∫0ÔºâÔºõÊâÄ‰ª•PËΩ¨ÁΩÆÊØè‰∏ÄÂàóÈÉΩÊòØ‰∏Ä‰∏™ËØçÂêëÈáèÔºõÊâÄ‰ª•Áü©ÈòµPÊú¨Ë∫´ÁöÑÊØè‰∏ÄË°åÂ∞±ÊòØ‰∏Ä‰∏™ËØçÂêëÈáèÔºõÂÖ∂Ë°åÊï∞‰∏∫vÔºõÂç≥vocabularyÔºåËØçÊ±áÈáèÔºõÊØè‰∏ÄË°åÂØπÂ∫î‰∏Ä‰∏™ÂçïËØçÔºõÁü©ÈòµÁöÑÂàóÊï∞‰∏∫dÔºõdÊòØÁî®Êà∑ÂÜ≥ÂÆöÁöÑÔºõdÁöÑÂ§ßÂ∞è‰ºöÂÜ≥ÂÆöÊú∫Âô®Â≠¶‰π†Ê®°ÂûãÁöÑË°®Áé∞ÔºõÂ∫îËØ•Áî®xxxÊù•ÈÄâÊã©‰∏Ä‰∏™ÊØîËæÉÂ•ΩÁöÑdÔºõ\nÊàë‰ª¨ÁöÑ‰ªªÂä°ÊòØÁúãËØÑËÆ∫ÊòØÊ≠£Èù¢ÁöÑËøòÊòØË¥üÈù¢ÁöÑÔºõÂèÇÊï∞Áü©ÈòµÊòØ‰ªéËÆ≠ÁªÉÊï∞ÊçÆ‰∏≠Â≠¶‰π†Âá∫Êù•ÁöÑÔºåÊâÄ‰ª•Â≠¶Âá∫Êù•ÁöÑËØçÂêëÈáèÊòØÂ∏¶ÊúâÊÑüÊÉÖËâ≤ÂΩ©ÁöÑÔºõÂÅáËÆæËøô‰∫õËØçÂêëÈáèÈÉΩÊòØ‰∫åÁª¥ÁöÑÔºåÂàôÂèØ‰ª•Âú®Âπ≥Èù¢ÂùêÊ†áÁ≥ª‰∏≠Ê†áÂá∫‰∏ãÈù¢ËØçÂêëÈáè\nkerasÊèê‰æõembeddingÂ±ÇÔºõÁî®Êà∑ÂèØ‰ª•ÊåáÂÆövocabularyÂ§ßÂ∞èÂíådÁöÑÂ§ßÂ∞èÔºõ‰ª•ÂèäÊØè‰∏Ä‰∏™sequenceÁöÑÈïøÂ∫¶ÔºõdÊòØÊ†πÊçÆÁÆóÊ≥ïÈÄâÂá∫Êù•ÁöÑ Âà∞Ëøô‰∏ÄÊ≠•ÔºåÊàë‰ª¨Â∑≤ÁªèÂÆåÊàê‰∫ÜÊñáÊú¨Â§ÑÁêÜÂíåword embedding„ÄÇÊé•‰∏ãÊù•Â∞±ÊòØÁî®Logistic Regression for Binary ClassificationÂÅö‰∫åÂàÜÁ±ªÔºõ\n","permalink":"http://localhost:1313/posts/nlp-2/","summary":"\u003ch3 id=\"text-to-sequence\"\u003eText to Sequence\u003c/h3\u003e\n\u003cp\u003eÊñáÊú¨Â§ÑÁêÜ\u003c/p\u003e\n\u003cp\u003eStep1: Tokenization\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\n\u003cp\u003eTokenization breaks a piece of text down into a list of tokens.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003eHere, a token is a word. (A token can be a character in some applications.)\u003c/p\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003eTokenizationËÆ≤Á©∂ÂæàÂ§öÔºå‰æãÂ¶ÇÊòØÂê¶Â∫îËØ•ÊääÂ§ßÂÜôÊîπÊàêÂ∞èÂÜôÂë¢ÔºüËøõË°åtypo correctionÁ≠âÁ≠â\u003c/p\u003e\n\u003cp\u003e\u003cimg alt=\"image-20250322150322238\" loading=\"lazy\" src=\"./NLP-2.assets/image-20250322150322238.png\"\u003e\u003c/p\u003e\n\u003cp\u003eStep2: Build Dictionary\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\n\u003cp\u003eUse a dictionary (hash table) to count word frequencies.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003eThe dictionary maps word to index.\u003c/p\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003eÂèØ‰ª•È¶ñÂÖàÁªüËÆ°ËØçÈ¢ëÂéªÊéâ‰ΩéÈ¢ëËØçÔºåÁÑ∂ÂêéËÆ©ÊØè‰∏™ËØçÂØπÂ∫î‰∏Ä‰∏™Ê≠£Êï¥Êï∞ÔºõËøôÊ†∑ÁöÑËØùÔºå‰∏ÄÂè•ËØùÂ∞±ÂèØ‰ª•Áî®‰∏Ä‰∏™Ê≠£Êï¥Êï∞ÂàóË°®Ë°®Á§∫ÔºåËøô‰∏™ÂàóË°®Â∞±Âè´sequenceÔºõÂ¶ÇÊûúÂøÖË¶ÅÂ∞±ËøòÂæóÂÅöone-hot encoding„ÄÇ\u003cimg alt=\"image-20250322150620890\" loading=\"lazy\" src=\"./NLP-2.assets/image-20250322150620890.png\"\u003e\u003c/p\u003e\n\u003cp\u003eÁªìÊûú\u003c/p\u003e\n\u003cp\u003e\u003cimg alt=\"image-20250322150754528\" loading=\"lazy\" src=\"./NLP-2.assets/image-20250322150754528.png\"\u003e\u003c/p\u003e\n\u003cp\u003e‰ΩÜÊòØÈïøÂ∫¶‰∏çÁªü‰∏Ä\u003c/p\u003e\n\u003cp\u003eStep4: ÂØπÈΩêsequence\u003c/p\u003e\n\u003cp\u003e\u003cimg alt=\"image-20250322150854986\" loading=\"lazy\" src=\"./NLP-2.assets/image-20250322150854986.png\"\u003e\u003c/p\u003e\n\u003cp\u003eËß£ÂÜ≥ÊñπÊ°àÊòØËøôÊ†∑ÁöÑÔºöÂèØ‰ª•Âõ∫ÂÆöÈïøÂ∫¶‰∏∫wÔºåÂä†ÂÖ•‰∏Ä‰∏™Â∫èÂàóÈïøÂ∫¶Â§™ÈïøÔºåÂ∞±Á†çÊéâÂâçÈù¢ÁöÑËØçÔºåÂè™‰øùÁïôÊúÄÂêéw‰∏™ËØçÔºõÂ¶ÇÊûú‰∏Ä‰∏™Â∫èÂàóÂ§™Áü≠ÔºåÂ∞±ÂÅözero paddingÔºåÁî®0Â°´ÂÖÖ\u003c/p\u003e\n\u003cp\u003e\u003cimg alt=\"image-20250322151030119\" loading=\"lazy\" src=\"./NLP-2.assets/image-20250322151030119.png\"\u003e\u003c/p\u003e\n\u003cp\u003eËøôÊ†∑‰∏ÄÊù•ÔºåÊâÄÊúâÁöÑÂ∫èÂàóÈïøÂ∫¶Â∞±Áªü‰∏Ä‰∫Ü\u003c/p\u003e\n\u003cp\u003e\u003cimg alt=\"image-20250322151117125\" loading=\"lazy\" src=\"./NLP-2.assets/image-20250322151117125.png\"\u003e\u003c/p\u003e\n\u003cp\u003eÊñáÊú¨Â§ÑÁêÜÂÆåÊàê‰∫ÜÔºåÊé•‰∏ãÊù•ÊòØword embeddingÔºåÊääÂçïËØçË°®Á§∫‰∏∫‰∏Ä‰∏™‰ΩéÁª¥ÂêëÈáèÔºõ\u003c/p\u003e\n\u003cp\u003e\u003cimg alt=\"image-20250322151252837\" loading=\"lazy\" src=\"./NLP-2.assets/image-20250322151252837.png\"\u003e\u003c/p\u003e","title":""},{"content":"üëã About me Hello! I\u0026rsquo;m Xu Zongsi, a passionate technology enthusiast currently pursuing my Master of Science in ECIC at The University of Hong Kong. With a solid background in Software Engineering from the Beijing Institute of Technology, I specialize in artificial intelligence areas like machine learning, deep learning, natural language processing, computer vision, and reinforcement learning.\nInspired by OpenAI\u0026rsquo;s five-step plan towards superintelligence, I am excited about AGI and have developed a keen interest in LLM agents, MLLM, and knowledge graphs. I see great potential in these fields and aspire to contribute to innovative solutions.\nüìö Education üá≠üá∞ The University of Hong Kong 09/2024 - Expected 11/2025 School of Computing and Data Science Master of Science in Electronic Commerce \u0026amp; Internet Computing Relevant Courses: Machine learning for business and e-commerce, Knowledge graphs, Financial fraud analytics, Internet infrastructure technologies, Website engineering, Blockchain and cryptocurrency, etc. üá®üá≥ Beijing Institute of Technology 09/2020 - 06/2024 School of Computer Science \u0026amp; Technology Bachelor of Engineering in Software Engineering, last two years GPA: 3.7/4 Relevant Courses: Reinforcement Learning, Deep Learning and Computer Vision, Artificial Intelligence and Robot Ethics, Almost Human: Mind, Brain and Artificial Intelligence, Mathematical Analysis for Engineering, Linear Algebra, Probability and Mathematical Statistics, etc. Skills: Python, Java, common data structures, design patterns, machine learning basics and algorithms, Linux, PyTorch, and some development tools (git, conda, etc.). üèÜ Awards \u0026amp; Honors Beijing Institute of Technology Undergraduate Scholarship (Top 20% of Grade) 06/2023 3rd Prize of China International \u0026#34;Internet \u0026#43;\u0026#34; College Student\u0026#39;s Innovation Competition 08/2022 Bronze Prize of \u0026#34;Challenge Cup\u0026#34; Capital University Entrepreneurship Competition 05/2022 üíº Project Experience üîç Online Transaction Fraud Detection 09/2024 ‚Äì 01/2025 Independent project, supervised by Dr. Vivien Chan Focused on addressing financial fraud in e-commerce to enhance the accuracy of transaction anomaly detection, while independently managing the entire case study that included data preprocessing, feature engineering, model building, evaluation, and results analysis. Effectively resolved class imbalance issues using SMOTE and ROSE techniques. Built various models including Logistic Regression, Random Forest, XGBoost, and LightGBM, ultimately selecting the LightGBM model to achieve a recall rate of 95.45% and an AUC of 99.84%. Wrote efficient and maintainable code, enhancing model training and data processing efficiency through parallel computing and logging. ü§ñ Multi-Model Intelligent Text Keyword Extraction System 08/2023 ‚Äì 09/2023 Group project, supervised by Associate Prof. Xiaolin Zhao Designed and implemented an intelligent text summary system that automatically extracts keywords from article titles and abstracts, enhancing the understanding and summarization of text information. Participated in the planning of the technical route and built a hybrid model combining extractive and generative approaches, utilizing advanced natural language processing techniques including KeyBERT, Sentence Transformer, BERT, and T5 models. Responsible for data preprocessing and tokenization, as well as the end-to-end implementation and training of the T5 model, optimizing the model architecture and hyperparameters, achieving satisfactory results after only 3 epochs of training. Model evaluation results showed that the Rouge-1, Rouge-2, and Rouge-L metrics reached 0.6345, 0.5038, and 0.5282, respectively, in the third epoch, validating the model\u0026rsquo;s effectiveness in the summarization task. üéì Cambridge University Machine Learning Summer Project 07/2023 ‚Äì 08/2023 Group project, supervised by Prof. Pietro Li√≤ Participated in the Cambridge University deep learning summer project, focusing on deep reinforcement learning; explored multi-agent learning algorithms across different environments. Reproduced the Multi-Agent Deep Deterministic Policy Gradient (MADDPG) algorithm in the Simple Adversary environment and studied the effect of agent numbers on convergence speed and stability, finding optimal stability at 21 agents. Designed and implemented comparative experiments inspired by the Rainbow algorithm, assessing target network strategies versus the Double Deep Q-Network (Double DQN). The results demonstrated that Double DQN significantly enhanced convergence speed, optimizing the overall learning process. Co-authored a group project paper on agent numbers and strategies effectiveness in multi-agent systems, achieving a score of 71% in the summer program (the highest in my group) and a \u0026ldquo;First Class\u0026rdquo; classification in the UK grading system. üëÅÔ∏è Deep Learning and Computer Vision Semester Project 09/2022 ‚Äì 12/2022 Independent project, supervised by Associate Prof. Guangyu Gao Designed and implemented a waste classifier using the ResNet model to improve classification accuracy and reduce resource waste. The project also enhanced understanding of transfer learning techniques with ResNet. Collected a dataset of 16 waste categories and preprocessed the images for uniformity and standardization, incorporating data augmentation techniques to enhance the dataset. Conducted experiments using ResNet34 and ResNet50 models through transfer learning, accelerating network convergence by leveraging pretrained weights. During training, techniques such as Batch Normalization and Dropout were applied to mitigate the risk of overfitting. The final model achieved an accuracy of 90% on the training set, while the performance on the test set was 61%, indicating a significant overfitting phenomenon during the training process. üéì Internship ‚öõÔ∏è Beijing Academy of Quantum Information Science 08/2023 ‚Äì 01/2024 Research Intern at Quantum Computation Department Proposed a quantum convolution kernel design based on variational quantum circuits and developed a universal quantum convolution layer, successfully integrating it into classical CNN architectures such as VGG, GoogLeNet, and ResNet. Developed and evaluated various hybrid models, including a simple model named HQCCNN-2, which achieved 84.45% accuracy on the FashionMNIST dataset, surpassing the traditional CNN\u0026rsquo;s 80.72%. This demonstrates the effectiveness of the quantum convolution layer in improving model performance. Tested on a real quantum computer further validated the effectiveness of the hybrid model, demonstrating the viable integration of quantum computing with deep learning, and highlighting the potential for leveraging quantum properties to enhance model performance. üèÖ Competition Experience ü•â China International \u0026#34;Internet \u0026#43;\u0026#34; College Students\u0026#39; Innovation Competition 08/2022 üõ°Ô∏è Zhongke Ushield: Deep Learning-based Face Privacy Protection Authentication System Responsible for constructing a localized facial feature extraction engine based on MobileFaceNet, ensuring feature extraction is completed on end devices (such as mobile phones and cameras), guaranteeing that raw data does not leave the domain and is not stored, thus enhancing user privacy protection while improving recognition efficiency. ü•â \u0026#34;Challenge Cup\u0026#34; Capital University Entrepreneurship Competition 05/2022 üå≥ Smart Orchard Responsible for the development of the fruit detection, ripeness prediction, and pest identification system, using deep convolutional neural network (CNN) technology for intelligent monitoring of crop growth conditions. Applied advanced object detection algorithms such as Faster R-CNN and YOLO to achieve high precision in apple detection and ripeness assessment, with an accuracy rate exceeding 90%, significantly enhancing the intelligence level of orchard management. Built and trained a dedicated dataset containing various pest samples, optimizing pest detection accuracy through data preprocessing (such as image normalization and resizing) and data augmentation techniques (like rotation, flipping, and noise addition), enabling the real-time monitoring system to accurately identify over 80% of pests, providing effective scientific maintenance recommendations to help farmers reduce crop losses. üìã Extracurricular Activities Vice President, Cyber Security Club, Beijing Institute of Technology 09/2021-09/2022 Backbone, Media Center of the Student Union of Beijing Institute of Technology 10/2020-06/2021 üì´ Contact üìß Email: zongsi.xu@outlook.com üëî LinkedIn: Zongsi (Tristan) Xu üíª GitHub: BaizeXS üìç Location: Hong Kong SAR, China ","permalink":"http://localhost:1313/resume/","summary":"Personal resume of Zongsi (Tristan) Xu","title":"Zongsi (Tristan) Xu"},{"content":"‰∏Ä„ÄÅÊï∞ÂÄºÁâπÂæÅ‰∏éÁ±ªÂà´ÁâπÂæÅ Êï∞ÂÄºÁâπÂæÅ (Numeric Features) ÂÖ∑ÊúâÂèØÂä†ÂáèÁöÑÊÑè‰πâÔºå‰∏îÂ≠òÂú®Â§ßÂ∞èÈ°∫Â∫è„ÄÇ ‰æãÂ≠êÔºöÂπ¥ÈæÑ„ÄÅÊ∏©Â∫¶Á≠â„ÄÇÂèØ‰ª•Áõ¥Êé•‰øùÁïôÂÖ∂Êï¥Êï∞ÊàñÊµÆÁÇπÊï∞ÂΩ¢Âºè‰æõÊ®°Âûã‰ΩøÁî®„ÄÇ Á±ªÂà´ÁâπÂæÅ (Categorical Features) Êï∞ÊçÆÂÄºÁ¶ªÊï£Ôºå‰∏çÂÖ∑Â§á‚ÄúÊï∞ÂÄºÂ§ßÂ∞è‚ÄùÈó¥ÁöÑÂèØÊØîÊÑè‰πâ„ÄÇ ‰æãÂ≠êÔºöÂõΩÁ±çÔºàÁæéÂõΩ/‰∏≠ÂõΩ/Âç∞Â∫¶Á≠âÔºâ„ÄÅÊÄßÂà´ÔºàÁî∑/Â•≥ÔºâÁ≠â„ÄÇ ÈóÆÈ¢òÔºöËã•‰ªÖÁî®Êï¥Êï∞Ë°®Á§∫ÔºàÁæéÂõΩ=1, ‰∏≠ÂõΩ=2ÔºâÔºå‰ºöÂºïÂÖ•ÈîôËØØÁöÑÊï∞ÂÄºËøêÁÆóÂÖ≥Á≥ªÔºåÂ¶Ç ‚ÄúÁæéÂõΩ + ‰∏≠ÂõΩ = Âç∞Â∫¶‚Äù„ÄÇ ‰∫å„ÄÅOne-HotÁºñÁ†ÅÁöÑÂä®Êú∫‰∏éÊµÅÁ®ã ‰∏∫‰ªÄ‰πà‰ΩøÁî®One-Hot\nÈÄöËøáÂ∞ÜÁ±ªÂà´Êò†Â∞Ñ‰∏∫ÂêëÈáèÔºåÈÅøÂÖçÊï¥Êï∞ÁºñÁ†ÅÂºïÂÖ•ÁöÑ‰º™Êï∞ÂÄºÂÖ≥Á≥ª„ÄÇ ÂêåÊó∂‰øùÁïôÂêÑÁßçÂèØËÉΩÁ±ªÂà´ÁöÑ‰ø°ÊÅØÔºå‰∏î‰ªÖÂú®ÂØπÂ∫î‰ΩçÁΩÆ‰∏∫1ÔºåÂÖ∂‰ªñ‰ΩçÁΩÆ‰∏∫0„ÄÇ Âª∫Á´ãÊò†Â∞ÑÔºö‰ªéÁ±ªÂà´Âà∞Á¥¢Âºï\n‰∏∫ÊØè‰∏™Á±ªÂà´ÂàÜÈÖç‰∏Ä‰∏™ÂîØ‰∏ÄÁ¥¢ÂºïÔºåÈÄöÂ∏∏‰ªé1ÂºÄÂßã„ÄÇ È¢ÑÁïôÁ¥¢Âºï0Ë°®Á§∫‚ÄúÊú™Áü•‚ÄùÊàñ‚ÄúÁº∫Â§±‚ÄùÔºåÂØπÂ∫îÂÖ®0ÂêëÈáè„ÄÇ ËΩ¨Êç¢‰∏∫One-HotÂêëÈáè\nËã•Á±ªÂà´ÊÄªÊï∞‰∏∫197ÔºåÂàôÁî®197Áª¥ÂêëÈáèË°®Á§∫„ÄÇ ‰æãÂ≠êÔºöÁæéÂõΩ [1, 0, 0, 0, ‚Ä¶]Ôºå ‰∏≠ÂõΩ [0, 1, 0, 0, ‚Ä¶]„ÄÇ Á§∫‰æãÔºöË°®Á§∫‰∏Ä‰∏™‰∫∫ÁöÑÁâπÂæÅ\nÁâπÂæÅÂåÖÂê´ÔºàÂπ¥ÈæÑ, ÊÄßÂà´, ÂõΩÁ±çÔºåÂÖ∂‰∏≠ÂõΩÁ±ç197ÁßçÔºâ Áª¥Â∫¶ÊÄªÂíåÔºö1Áª¥_age + 1Áª¥_gender + 197Áª¥_nationality = 199Áª¥„ÄÇ ‰æãÂ¶Ç (28, Â•≥, ‰∏≠ÂõΩ) ‚Üí [28, 0, 0, 1, 0, ‚Ä¶, 0]„ÄÇ ‰∏â„ÄÅÊñáÊú¨Êï∞ÊçÆÂ§ÑÁêÜÊµÅÁ®ã ÊñáÊú¨Âú®Ëá™ÁÑ∂ËØ≠Ë®ÄÂ§ÑÁêÜÔºàNLPÔºâ‰∏≠‰Ωú‰∏∫Â∏∏ËßÅÁöÑÂéüÂßãËæìÂÖ•ÔºåÈúÄË¶ÅÊï∞ÂÄºÂåñÊâçËÉΩÈÄÅÂÖ•Ê®°Âûã„ÄÇ‰∏ÄËà¨Ê≠•È™§Â¶Ç‰∏ãÔºö\nÂàÜËØç (Tokenization)\nÂ∞ÜÊñáÊú¨ÊãÜÂàÜ‰∏∫‰∏Ä‰∏™‰∏™ÂçïËØçÔºàTokenÔºâ„ÄÇ ‰æãÂ≠êÔºö\u0026quot;... to be or not to be...\u0026quot; ‚Üí [\u0026quot;...\u0026quot;, \u0026quot;to\u0026quot;, \u0026quot;be\u0026quot;, \u0026quot;or\u0026quot;, \u0026quot;not\u0026quot;, \u0026quot;to\u0026quot;, \u0026quot;be\u0026quot;, \u0026quot;...\u0026quot;]„ÄÇ ÁªüËÆ°ËØçÈ¢ë \u0026amp; ÊûÑÂª∫ËØçÂÖ∏\nËØçÈ¢ëÁªüËÆ° Áî®ÂìàÂ∏åË°®/Â≠óÂÖ∏ËÆ∞ÂΩïÊØè‰∏™ÂçïËØçÂá∫Áé∞Ê¨°Êï∞„ÄÇ ÈÅçÂéÜÊñáÊú¨Êó∂ÔºåËã•ÂçïËØçÂ∞öÊú™ÂÖ•Ë°®ÔºåÂàôÊñ∞Âª∫ËÆ∞ÂΩïÔºõËã•Â∑≤Â≠òÂú®ÔºåÂàôËÆ°Êï∞+1„ÄÇ ÊéíÂ∫è‰∏éÁ¥¢Âºï ÊåâËØçÈ¢ëÈôçÂ∫èÊéíÂ∫èÔºåËØçÈ¢ëÊúÄÈ´òÁöÑÂçïËØçÊéíÂú®ÂâçÈù¢„ÄÇ Á¥¢Âºï‰ªé1ÂºÄÂßãÔºå0ÁïôÁªô‚ÄúÊú™Áü•‚Äù„ÄÇ ËØçÂÖ∏ËßÑÊ®°ÔºàvocabularyÔºâÂèØËßÜÈúÄÊ±ÇÊà™Êñ≠Ôºà‰æãÂ¶ÇÂè™‰øùÁïôTop 10kÔºâ„ÄÇ ‰∏∫‰ªÄ‰πàÁßªÈô§‰ΩéÈ¢ëËØç ‰ΩéÈ¢ëËØçÂèØËÉΩÊòØÊãºÂÜôÈîôËØØ„ÄÅÁΩïËßÅ‰∫∫ÂêçÁ≠âÔºåÂØπÊ®°ÂûãÂ∏ÆÂä©ÊúâÈôê„ÄÇ ÂáèÂ∞ëËØçÂÖ∏ËßÑÊ®°ÂèØÈôç‰ΩéËøêÁÆóÂºÄÈîÄ„ÄÅÂä†Âø´Ê®°ÂûãËÆ≠ÁªÉ‰∏éÊé®ÁêÜÈÄüÂ∫¶„ÄÇ Áã¨ÁÉ≠ÁºñÁ†Å (One-Hot Encoding)\nÂ∞ÜÊØè‰∏™ÂçïËØçÊò†Â∞Ñ‰∏∫ËØçÂÖ∏‰∏≠ÁöÑÁ¥¢ÂºïÂêéÔºàÂ¶Ç [2, 4, 1, 8, ‚Ä¶]ÔºâÔºåÂèØËøõ‰∏ÄÊ≠•ËΩ¨Êç¢ÊàêOne-HotÂêëÈáè„ÄÇ One-HotÁª¥Â∫¶ÂèñÂÜ≥‰∫é‰øùÁïô‰∏ãÊù•ÁöÑËØçÂÖ∏Â§ßÂ∞èÔºà‰æãÂ¶Ç1‰∏áÔºâ„ÄÇ Êú™Êî∂ÂΩïÂçïËØçÂèØËÉΩÁõ¥Êé•ÂøΩÁï•ÔºåÊàñÁªü‰∏ÄÁî®Á¥¢Âºï0‰ª£Êõø„ÄÇ Âõõ„ÄÅÊ†∏ÂøÉÊî∂Ëé∑‰∏éÂ∫îÁî® Á±ªÂà´ÁâπÂæÅÂøÖÈúÄÊï∞ÂÄºÂåñÔºö\n‰ΩøÁî®Êï¥Êï∞1,2,3‚Ä¶‰ªÖË°®Á§∫Á±ªÂà´‚ÄúÊ†áËØÜ‚ÄùÔºåÂπ∂‰∏ç‰ª£Ë°®ÂÆÉ‰ª¨ÂèØËøõË°åÊï∞ÂÄºËøêÁÆó„ÄÇ Âõ†Ê≠§ÈúÄË¶ÅOne-HotÁ≠âÁºñÁ†ÅÊñπÂºèÔºåÈÅøÂÖçÊï∞ÂÄºËØØËß£„ÄÇ ÊñáÊú¨Êï∞ÊçÆÈ¢ÑÂ§ÑÁêÜÔºö\nÂàÜËØç„ÄÅËØçÈ¢ëÁªüËÆ°„ÄÅÊûÑÂª∫ËØçÂÖ∏„ÄÅÁ¥¢ÂºïÂåñ„ÄÅOne-HotÊàñÂÖ∂‰ªñÊñπÂºèÔºàÂ¶ÇËØçÂµåÂÖ•ÔºâÊòØÂ∏∏ËßÅÊµÅÁ®ã„ÄÇ Ê≠£Á°ÆÁöÑÊñáÊú¨È¢ÑÂ§ÑÁêÜÂèØÊòæËëóÂΩ±ÂìçÊ®°ÂûãÊÄßËÉΩÂíåÊïàÁéá„ÄÇ ‰øùÁïôÊú™Áü•Á¥¢ÂºïÔºö\n‰øùËØÅÂØπÁº∫Â§±Êï∞ÊçÆÊàñÂ≠óÂÖ∏Â§ñÊñ∞ËØçËÉΩÊúâÂü∫Êú¨ÁöÑË°®Á§∫ÔºåÊèêÂçáÊ®°ÂûãÂÆπÈîôÊÄß„ÄÇ ÂÆûÈôÖ‰ΩøÁî®Ôºö\nÂØπ‰∫éÂ∞èËßÑÊ®°Á±ªÂà´ÂèØÁõ¥Êé•One-HotÁºñÁ†ÅÔºõÂØπ‰∫éËØçÂÖ∏ÂæàÂ§ßÁöÑÂú∫ÊôØÔºåÈÄöÂ∏∏‰ºöËøõ‰∏ÄÊ≠•ËÄÉËôëËØçÂµåÂÖ•ÔºàWord EmbeddingÔºâÊàñÈ¢ÑËÆ≠ÁªÉËØ≠Ë®ÄÊ®°Âûã„ÄÇ ","permalink":"http://localhost:1313/posts/nlp-1/","summary":"\u003ch2 id=\"‰∏ÄÊï∞ÂÄºÁâπÂæÅ‰∏éÁ±ªÂà´ÁâπÂæÅ\"\u003e‰∏Ä„ÄÅÊï∞ÂÄºÁâπÂæÅ‰∏éÁ±ªÂà´ÁâπÂæÅ\u003c/h2\u003e\n\u003col\u003e\n\u003cli\u003e\u003cstrong\u003eÊï∞ÂÄºÁâπÂæÅ (Numeric Features)\u003c/strong\u003e\n\u003cul\u003e\n\u003cli\u003eÂÖ∑ÊúâÂèØÂä†ÂáèÁöÑÊÑè‰πâÔºå‰∏îÂ≠òÂú®Â§ßÂ∞èÈ°∫Â∫è„ÄÇ\u003c/li\u003e\n\u003cli\u003e‰æãÂ≠êÔºöÂπ¥ÈæÑ„ÄÅÊ∏©Â∫¶Á≠â„ÄÇÂèØ‰ª•Áõ¥Êé•‰øùÁïôÂÖ∂Êï¥Êï∞ÊàñÊµÆÁÇπÊï∞ÂΩ¢Âºè‰æõÊ®°Âûã‰ΩøÁî®„ÄÇ\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003eÁ±ªÂà´ÁâπÂæÅ (Categorical Features)\u003c/strong\u003e\n\u003cul\u003e\n\u003cli\u003eÊï∞ÊçÆÂÄºÁ¶ªÊï£Ôºå‰∏çÂÖ∑Â§á‚ÄúÊï∞ÂÄºÂ§ßÂ∞è‚ÄùÈó¥ÁöÑÂèØÊØîÊÑè‰πâ„ÄÇ\u003c/li\u003e\n\u003cli\u003e‰æãÂ≠êÔºöÂõΩÁ±çÔºàÁæéÂõΩ/‰∏≠ÂõΩ/Âç∞Â∫¶Á≠âÔºâ„ÄÅÊÄßÂà´ÔºàÁî∑/Â•≥ÔºâÁ≠â„ÄÇ\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003eÈóÆÈ¢ò\u003c/strong\u003eÔºöËã•‰ªÖÁî®Êï¥Êï∞Ë°®Á§∫ÔºàÁæéÂõΩ=1, ‰∏≠ÂõΩ=2ÔºâÔºå‰ºöÂºïÂÖ•ÈîôËØØÁöÑÊï∞ÂÄºËøêÁÆóÂÖ≥Á≥ªÔºåÂ¶Ç ‚ÄúÁæéÂõΩ + ‰∏≠ÂõΩ = Âç∞Â∫¶‚Äù„ÄÇ\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003c/ol\u003e\n\u003ch2 id=\"‰∫åone-hotÁºñÁ†ÅÁöÑÂä®Êú∫‰∏éÊµÅÁ®ã\"\u003e‰∫å„ÄÅOne-HotÁºñÁ†ÅÁöÑÂä®Êú∫‰∏éÊµÅÁ®ã\u003c/h2\u003e\n\u003col\u003e\n\u003cli\u003e\n\u003cp\u003e\u003cstrong\u003e‰∏∫‰ªÄ‰πà‰ΩøÁî®One-Hot\u003c/strong\u003e\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eÈÄöËøáÂ∞ÜÁ±ªÂà´Êò†Â∞Ñ‰∏∫ÂêëÈáèÔºåÈÅøÂÖçÊï¥Êï∞ÁºñÁ†ÅÂºïÂÖ•ÁöÑ‰º™Êï∞ÂÄºÂÖ≥Á≥ª„ÄÇ\u003c/li\u003e\n\u003cli\u003eÂêåÊó∂‰øùÁïôÂêÑÁßçÂèØËÉΩÁ±ªÂà´ÁöÑ‰ø°ÊÅØÔºå‰∏î‰ªÖÂú®ÂØπÂ∫î‰ΩçÁΩÆ‰∏∫1ÔºåÂÖ∂‰ªñ‰ΩçÁΩÆ‰∏∫0„ÄÇ\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003e\u003cstrong\u003eÂª∫Á´ãÊò†Â∞ÑÔºö‰ªéÁ±ªÂà´Âà∞Á¥¢Âºï\u003c/strong\u003e\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e‰∏∫ÊØè‰∏™Á±ªÂà´ÂàÜÈÖç‰∏Ä‰∏™ÂîØ‰∏ÄÁ¥¢ÂºïÔºåÈÄöÂ∏∏‰ªé1ÂºÄÂßã„ÄÇ\u003c/li\u003e\n\u003cli\u003eÈ¢ÑÁïôÁ¥¢Âºï0Ë°®Á§∫‚ÄúÊú™Áü•‚ÄùÊàñ‚ÄúÁº∫Â§±‚ÄùÔºåÂØπÂ∫îÂÖ®0ÂêëÈáè„ÄÇ\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003e\u003cstrong\u003eËΩ¨Êç¢‰∏∫One-HotÂêëÈáè\u003c/strong\u003e\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eËã•Á±ªÂà´ÊÄªÊï∞‰∏∫197ÔºåÂàôÁî®197Áª¥ÂêëÈáèË°®Á§∫„ÄÇ\u003c/li\u003e\n\u003cli\u003e‰æãÂ≠êÔºöÁæéÂõΩ \u003ccode\u003e[1, 0, 0, 0, ‚Ä¶]\u003c/code\u003eÔºå ‰∏≠ÂõΩ \u003ccode\u003e[0, 1, 0, 0, ‚Ä¶]\u003c/code\u003e„ÄÇ\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003e\u003cstrong\u003eÁ§∫‰æãÔºöË°®Á§∫‰∏Ä‰∏™‰∫∫ÁöÑÁâπÂæÅ\u003c/strong\u003e\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eÁâπÂæÅÂåÖÂê´ÔºàÂπ¥ÈæÑ, ÊÄßÂà´, ÂõΩÁ±çÔºåÂÖ∂‰∏≠ÂõΩÁ±ç197ÁßçÔºâ\u003c/li\u003e\n\u003cli\u003eÁª¥Â∫¶ÊÄªÂíåÔºö1Áª¥_age + 1Áª¥_gender + 197Áª¥_nationality = 199Áª¥„ÄÇ\u003c/li\u003e\n\u003cli\u003e‰æãÂ¶Ç \u003ccode\u003e(28, Â•≥, ‰∏≠ÂõΩ)\u003c/code\u003e ‚Üí \u003ccode\u003e[28, 0, 0, 1, 0, ‚Ä¶, 0]\u003c/code\u003e„ÄÇ\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003c/ol\u003e\n\u003ch2 id=\"‰∏âÊñáÊú¨Êï∞ÊçÆÂ§ÑÁêÜÊµÅÁ®ã\"\u003e‰∏â„ÄÅÊñáÊú¨Êï∞ÊçÆÂ§ÑÁêÜÊµÅÁ®ã\u003c/h2\u003e\n\u003cp\u003eÊñáÊú¨Âú®Ëá™ÁÑ∂ËØ≠Ë®ÄÂ§ÑÁêÜÔºàNLPÔºâ‰∏≠‰Ωú‰∏∫Â∏∏ËßÅÁöÑÂéüÂßãËæìÂÖ•ÔºåÈúÄË¶ÅÊï∞ÂÄºÂåñÊâçËÉΩÈÄÅÂÖ•Ê®°Âûã„ÄÇ‰∏ÄËà¨Ê≠•È™§Â¶Ç‰∏ãÔºö\u003c/p\u003e\n\u003col\u003e\n\u003cli\u003e\n\u003cp\u003e\u003cstrong\u003eÂàÜËØç (Tokenization)\u003c/strong\u003e\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eÂ∞ÜÊñáÊú¨ÊãÜÂàÜ‰∏∫‰∏Ä‰∏™‰∏™ÂçïËØçÔºàTokenÔºâ„ÄÇ\u003c/li\u003e\n\u003cli\u003e‰æãÂ≠êÔºö\u003ccode\u003e\u0026quot;... to be or not to be...\u0026quot;\u003c/code\u003e ‚Üí \u003ccode\u003e[\u0026quot;...\u0026quot;, \u0026quot;to\u0026quot;, \u0026quot;be\u0026quot;, \u0026quot;or\u0026quot;, \u0026quot;not\u0026quot;, \u0026quot;to\u0026quot;, \u0026quot;be\u0026quot;, \u0026quot;...\u0026quot;]\u003c/code\u003e„ÄÇ\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003e\u003cstrong\u003eÁªüËÆ°ËØçÈ¢ë \u0026amp; ÊûÑÂª∫ËØçÂÖ∏\u003c/strong\u003e\u003c/p\u003e","title":""},{"content":"Text to Sequence ÊñáÊú¨Â§ÑÁêÜ\nStep1: Tokenization\nTokenization breaks a piece of text down into a list of tokens.\nHere, a token is a word. (A token can be a character in some applications.)\nTokenizationËÆ≤Á©∂ÂæàÂ§öÔºå‰æãÂ¶ÇÊòØÂê¶Â∫îËØ•ÊääÂ§ßÂÜôÊîπÊàêÂ∞èÂÜôÂë¢ÔºüËøõË°åtypo correctionÁ≠âÁ≠â\nStep2: Build Dictionary\nUse a dictionary (hash table) to count word frequencies.\nThe dictionary maps word to index.\nÂèØ‰ª•È¶ñÂÖàÁªüËÆ°ËØçÈ¢ëÂéªÊéâ‰ΩéÈ¢ëËØçÔºåÁÑ∂ÂêéËÆ©ÊØè‰∏™ËØçÂØπÂ∫î‰∏Ä‰∏™Ê≠£Êï¥Êï∞ÔºõËøôÊ†∑ÁöÑËØùÔºå‰∏ÄÂè•ËØùÂ∞±ÂèØ‰ª•Áî®‰∏Ä‰∏™Ê≠£Êï¥Êï∞ÂàóË°®Ë°®Á§∫ÔºåËøô‰∏™ÂàóË°®Â∞±Âè´sequenceÔºõÂ¶ÇÊûúÂøÖË¶ÅÂ∞±ËøòÂæóÂÅöone-hot encoding„ÄÇ\nÁªìÊûú\n‰ΩÜÊòØÈïøÂ∫¶‰∏çÁªü‰∏Ä\nStep4: ÂØπÈΩêsequence\nËß£ÂÜ≥ÊñπÊ°àÊòØËøôÊ†∑ÁöÑÔºöÂèØ‰ª•Âõ∫ÂÆöÈïøÂ∫¶‰∏∫wÔºåÂä†ÂÖ•‰∏Ä‰∏™Â∫èÂàóÈïøÂ∫¶Â§™ÈïøÔºåÂ∞±Á†çÊéâÂâçÈù¢ÁöÑËØçÔºåÂè™‰øùÁïôÊúÄÂêéw‰∏™ËØçÔºõÂ¶ÇÊûú‰∏Ä‰∏™Â∫èÂàóÂ§™Áü≠ÔºåÂ∞±ÂÅözero paddingÔºåÁî®0Â°´ÂÖÖ\nËøôÊ†∑‰∏ÄÊù•ÔºåÊâÄÊúâÁöÑÂ∫èÂàóÈïøÂ∫¶Â∞±Áªü‰∏Ä‰∫Ü\nÊñáÊú¨Â§ÑÁêÜÂÆåÊàê‰∫ÜÔºåÊé•‰∏ãÊù•ÊòØword embeddingÔºåÊääÂçïËØçË°®Á§∫‰∏∫‰∏Ä‰∏™‰ΩéÁª¥ÂêëÈáèÔºõ\nÁÑ∂ËÄåËøôÊ†∑ÂÅöÁöÑËØùÔºåÂ¶ÇÊûúÊòØ10000‰∏™ÂçïËØçÔºåÁª¥Â∫¶Â∞±ÊòØ10000Áª¥ÔºåÁª¥Â∫¶Â§™È´ò‰∫ÜÔºõÂõ†Ê≠§Ë¶ÅÂÅöword embeddingÔºõ\nÂÖ∑‰ΩìÂÅöÊ≥ïÂ∞±ÊòØÊääone-hotÂêëÈáèe_iÂíåÂèÇÊï∞Áü©ÈòµpÁõ∏‰πòÔºõÁü©ÈòµPËΩ¨ÁΩÆÁöÑÂ§ßÂ∞èÊòØd x vÔºõdÊòØËØçÂêëÈáèÁöÑÁª¥Â∫¶ÔºõvÊòØÂ≠óÂÖ∏ÈáåËØçÊ±áÁöÑÊï∞ÈáèÔºõÁªìÊûú‰∏∫x_iÔºõx_iÂ∞±ÊòØ‰∏Ä‰∏™ËØçÂêëÈáèÔºõÂ¶ÇÊûúone-hotÂêëÈáèÁöÑÁ¨¨‰∏âË°å‰∏∫1ÔºõÈÇ£‰πàx_iÂ∞±ÊòØPËΩ¨ÁΩÆÁü©ÈòµÁöÑÁ¨¨‰∏âÂàóÔºàÂÖ∂‰ΩôÂàóÈÉΩ‰∏∫0ÔºâÔºõÊâÄ‰ª•PËΩ¨ÁΩÆÊØè‰∏ÄÂàóÈÉΩÊòØ‰∏Ä‰∏™ËØçÂêëÈáèÔºõÊâÄ‰ª•Áü©ÈòµPÊú¨Ë∫´ÁöÑÊØè‰∏ÄË°åÂ∞±ÊòØ‰∏Ä‰∏™ËØçÂêëÈáèÔºõÂÖ∂Ë°åÊï∞‰∏∫vÔºõÂç≥vocabularyÔºåËØçÊ±áÈáèÔºõÊØè‰∏ÄË°åÂØπÂ∫î‰∏Ä‰∏™ÂçïËØçÔºõÁü©ÈòµÁöÑÂàóÊï∞‰∏∫dÔºõdÊòØÁî®Êà∑ÂÜ≥ÂÆöÁöÑÔºõdÁöÑÂ§ßÂ∞è‰ºöÂÜ≥ÂÆöÊú∫Âô®Â≠¶‰π†Ê®°ÂûãÁöÑË°®Áé∞ÔºõÂ∫îËØ•Áî®xxxÊù•ÈÄâÊã©‰∏Ä‰∏™ÊØîËæÉÂ•ΩÁöÑdÔºõ\nÊàë‰ª¨ÁöÑ‰ªªÂä°ÊòØÁúãËØÑËÆ∫ÊòØÊ≠£Èù¢ÁöÑËøòÊòØË¥üÈù¢ÁöÑÔºõÂèÇÊï∞Áü©ÈòµÊòØ‰ªéËÆ≠ÁªÉÊï∞ÊçÆ‰∏≠Â≠¶‰π†Âá∫Êù•ÁöÑÔºåÊâÄ‰ª•Â≠¶Âá∫Êù•ÁöÑËØçÂêëÈáèÊòØÂ∏¶ÊúâÊÑüÊÉÖËâ≤ÂΩ©ÁöÑÔºõÂÅáËÆæËøô‰∫õËØçÂêëÈáèÈÉΩÊòØ‰∫åÁª¥ÁöÑÔºåÂàôÂèØ‰ª•Âú®Âπ≥Èù¢ÂùêÊ†áÁ≥ª‰∏≠Ê†áÂá∫‰∏ãÈù¢ËØçÂêëÈáè\nkerasÊèê‰æõembeddingÂ±ÇÔºõÁî®Êà∑ÂèØ‰ª•ÊåáÂÆövocabularyÂ§ßÂ∞èÂíådÁöÑÂ§ßÂ∞èÔºõ‰ª•ÂèäÊØè‰∏Ä‰∏™sequenceÁöÑÈïøÂ∫¶ÔºõdÊòØÊ†πÊçÆÁÆóÊ≥ïÈÄâÂá∫Êù•ÁöÑ Âà∞Ëøô‰∏ÄÊ≠•ÔºåÊàë‰ª¨Â∑≤ÁªèÂÆåÊàê‰∫ÜÊñáÊú¨Â§ÑÁêÜÂíåword embedding„ÄÇÊé•‰∏ãÊù•Â∞±ÊòØÁî®Logistic Regression for Binary ClassificationÂÅö‰∫åÂàÜÁ±ªÔºõ\n","permalink":"http://localhost:1313/posts/nlp-2/","summary":"\u003ch3 id=\"text-to-sequence\"\u003eText to Sequence\u003c/h3\u003e\n\u003cp\u003eÊñáÊú¨Â§ÑÁêÜ\u003c/p\u003e\n\u003cp\u003eStep1: Tokenization\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\n\u003cp\u003eTokenization breaks a piece of text down into a list of tokens.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003eHere, a token is a word. (A token can be a character in some applications.)\u003c/p\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003eTokenizationËÆ≤Á©∂ÂæàÂ§öÔºå‰æãÂ¶ÇÊòØÂê¶Â∫îËØ•ÊääÂ§ßÂÜôÊîπÊàêÂ∞èÂÜôÂë¢ÔºüËøõË°åtypo correctionÁ≠âÁ≠â\u003c/p\u003e\n\u003cp\u003e\u003cimg alt=\"image-20250322150322238\" loading=\"lazy\" src=\"./NLP-2.assets/image-20250322150322238.png\"\u003e\u003c/p\u003e\n\u003cp\u003eStep2: Build Dictionary\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\n\u003cp\u003eUse a dictionary (hash table) to count word frequencies.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003eThe dictionary maps word to index.\u003c/p\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003eÂèØ‰ª•È¶ñÂÖàÁªüËÆ°ËØçÈ¢ëÂéªÊéâ‰ΩéÈ¢ëËØçÔºåÁÑ∂ÂêéËÆ©ÊØè‰∏™ËØçÂØπÂ∫î‰∏Ä‰∏™Ê≠£Êï¥Êï∞ÔºõËøôÊ†∑ÁöÑËØùÔºå‰∏ÄÂè•ËØùÂ∞±ÂèØ‰ª•Áî®‰∏Ä‰∏™Ê≠£Êï¥Êï∞ÂàóË°®Ë°®Á§∫ÔºåËøô‰∏™ÂàóË°®Â∞±Âè´sequenceÔºõÂ¶ÇÊûúÂøÖË¶ÅÂ∞±ËøòÂæóÂÅöone-hot encoding„ÄÇ\u003cimg alt=\"image-20250322150620890\" loading=\"lazy\" src=\"./NLP-2.assets/image-20250322150620890.png\"\u003e\u003c/p\u003e\n\u003cp\u003eÁªìÊûú\u003c/p\u003e\n\u003cp\u003e\u003cimg alt=\"image-20250322150754528\" loading=\"lazy\" src=\"./NLP-2.assets/image-20250322150754528.png\"\u003e\u003c/p\u003e\n\u003cp\u003e‰ΩÜÊòØÈïøÂ∫¶‰∏çÁªü‰∏Ä\u003c/p\u003e\n\u003cp\u003eStep4: ÂØπÈΩêsequence\u003c/p\u003e\n\u003cp\u003e\u003cimg alt=\"image-20250322150854986\" loading=\"lazy\" src=\"./NLP-2.assets/image-20250322150854986.png\"\u003e\u003c/p\u003e\n\u003cp\u003eËß£ÂÜ≥ÊñπÊ°àÊòØËøôÊ†∑ÁöÑÔºöÂèØ‰ª•Âõ∫ÂÆöÈïøÂ∫¶‰∏∫wÔºåÂä†ÂÖ•‰∏Ä‰∏™Â∫èÂàóÈïøÂ∫¶Â§™ÈïøÔºåÂ∞±Á†çÊéâÂâçÈù¢ÁöÑËØçÔºåÂè™‰øùÁïôÊúÄÂêéw‰∏™ËØçÔºõÂ¶ÇÊûú‰∏Ä‰∏™Â∫èÂàóÂ§™Áü≠ÔºåÂ∞±ÂÅözero paddingÔºåÁî®0Â°´ÂÖÖ\u003c/p\u003e\n\u003cp\u003e\u003cimg alt=\"image-20250322151030119\" loading=\"lazy\" src=\"./NLP-2.assets/image-20250322151030119.png\"\u003e\u003c/p\u003e\n\u003cp\u003eËøôÊ†∑‰∏ÄÊù•ÔºåÊâÄÊúâÁöÑÂ∫èÂàóÈïøÂ∫¶Â∞±Áªü‰∏Ä‰∫Ü\u003c/p\u003e\n\u003cp\u003e\u003cimg alt=\"image-20250322151117125\" loading=\"lazy\" src=\"./NLP-2.assets/image-20250322151117125.png\"\u003e\u003c/p\u003e\n\u003cp\u003eÊñáÊú¨Â§ÑÁêÜÂÆåÊàê‰∫ÜÔºåÊé•‰∏ãÊù•ÊòØword embeddingÔºåÊääÂçïËØçË°®Á§∫‰∏∫‰∏Ä‰∏™‰ΩéÁª¥ÂêëÈáèÔºõ\u003c/p\u003e\n\u003cp\u003e\u003cimg alt=\"image-20250322151252837\" loading=\"lazy\" src=\"./NLP-2.assets/image-20250322151252837.png\"\u003e\u003c/p\u003e","title":""},{"content":"üëã About me Hello! I\u0026rsquo;m Xu Zongsi, a passionate technology enthusiast currently pursuing my Master of Science in ECIC at The University of Hong Kong. With a solid background in Software Engineering from the Beijing Institute of Technology, I specialize in artificial intelligence areas like machine learning, deep learning, natural language processing, computer vision, and reinforcement learning.\nInspired by OpenAI\u0026rsquo;s five-step plan towards superintelligence, I am excited about AGI and have developed a keen interest in LLM agents, MLLM, and knowledge graphs. I see great potential in these fields and aspire to contribute to innovative solutions.\nüìö Education üá≠üá∞ The University of Hong Kong 09/2024 - Expected 11/2025 School of Computing and Data Science Master of Science in Electronic Commerce \u0026amp; Internet Computing Relevant Courses: Machine learning for business and e-commerce, Knowledge graphs, Financial fraud analytics, Internet infrastructure technologies, Website engineering, Blockchain and cryptocurrency, etc. üá®üá≥ Beijing Institute of Technology 09/2020 - 06/2024 School of Computer Science \u0026amp; Technology Bachelor of Engineering in Software Engineering, last two years GPA: 3.7/4 Relevant Courses: Reinforcement Learning, Deep Learning and Computer Vision, Artificial Intelligence and Robot Ethics, Almost Human: Mind, Brain and Artificial Intelligence, Mathematical Analysis for Engineering, Linear Algebra, Probability and Mathematical Statistics, etc. Skills: Python, Java, common data structures, design patterns, machine learning basics and algorithms, Linux, PyTorch, and some development tools (git, conda, etc.). üèÜ Awards \u0026amp; Honors Beijing Institute of Technology Undergraduate Scholarship (Top 20% of Grade) 06/2023 3rd Prize of China International \u0026#34;Internet \u0026#43;\u0026#34; College Student\u0026#39;s Innovation Competition 08/2022 Bronze Prize of \u0026#34;Challenge Cup\u0026#34; Capital University Entrepreneurship Competition 05/2022 üíº Project Experience üîç Online Transaction Fraud Detection 09/2024 ‚Äì 01/2025 Independent project, supervised by Dr. Vivien Chan Focused on addressing financial fraud in e-commerce to enhance the accuracy of transaction anomaly detection, while independently managing the entire case study that included data preprocessing, feature engineering, model building, evaluation, and results analysis. Effectively resolved class imbalance issues using SMOTE and ROSE techniques. Built various models including Logistic Regression, Random Forest, XGBoost, and LightGBM, ultimately selecting the LightGBM model to achieve a recall rate of 95.45% and an AUC of 99.84%. Wrote efficient and maintainable code, enhancing model training and data processing efficiency through parallel computing and logging. ü§ñ Multi-Model Intelligent Text Keyword Extraction System 08/2023 ‚Äì 09/2023 Group project, supervised by Associate Prof. Xiaolin Zhao Designed and implemented an intelligent text summary system that automatically extracts keywords from article titles and abstracts, enhancing the understanding and summarization of text information. Participated in the planning of the technical route and built a hybrid model combining extractive and generative approaches, utilizing advanced natural language processing techniques including KeyBERT, Sentence Transformer, BERT, and T5 models. Responsible for data preprocessing and tokenization, as well as the end-to-end implementation and training of the T5 model, optimizing the model architecture and hyperparameters, achieving satisfactory results after only 3 epochs of training. Model evaluation results showed that the Rouge-1, Rouge-2, and Rouge-L metrics reached 0.6345, 0.5038, and 0.5282, respectively, in the third epoch, validating the model\u0026rsquo;s effectiveness in the summarization task. üéì Cambridge University Machine Learning Summer Project 07/2023 ‚Äì 08/2023 Group project, supervised by Prof. Pietro Li√≤ Participated in the Cambridge University deep learning summer project, focusing on deep reinforcement learning; explored multi-agent learning algorithms across different environments. Reproduced the Multi-Agent Deep Deterministic Policy Gradient (MADDPG) algorithm in the Simple Adversary environment and studied the effect of agent numbers on convergence speed and stability, finding optimal stability at 21 agents. Designed and implemented comparative experiments inspired by the Rainbow algorithm, assessing target network strategies versus the Double Deep Q-Network (Double DQN). The results demonstrated that Double DQN significantly enhanced convergence speed, optimizing the overall learning process. Co-authored a group project paper on agent numbers and strategies effectiveness in multi-agent systems, achieving a score of 71% in the summer program (the highest in my group) and a \u0026ldquo;First Class\u0026rdquo; classification in the UK grading system. üëÅÔ∏è Deep Learning and Computer Vision Semester Project 09/2022 ‚Äì 12/2022 Independent project, supervised by Associate Prof. Guangyu Gao Designed and implemented a waste classifier using the ResNet model to improve classification accuracy and reduce resource waste. The project also enhanced understanding of transfer learning techniques with ResNet. Collected a dataset of 16 waste categories and preprocessed the images for uniformity and standardization, incorporating data augmentation techniques to enhance the dataset. Conducted experiments using ResNet34 and ResNet50 models through transfer learning, accelerating network convergence by leveraging pretrained weights. During training, techniques such as Batch Normalization and Dropout were applied to mitigate the risk of overfitting. The final model achieved an accuracy of 90% on the training set, while the performance on the test set was 61%, indicating a significant overfitting phenomenon during the training process. üéì Internship ‚öõÔ∏è Beijing Academy of Quantum Information Science 08/2023 ‚Äì 01/2024 Research Intern at Quantum Computation Department Proposed a quantum convolution kernel design based on variational quantum circuits and developed a universal quantum convolution layer, successfully integrating it into classical CNN architectures such as VGG, GoogLeNet, and ResNet. Developed and evaluated various hybrid models, including a simple model named HQCCNN-2, which achieved 84.45% accuracy on the FashionMNIST dataset, surpassing the traditional CNN\u0026rsquo;s 80.72%. This demonstrates the effectiveness of the quantum convolution layer in improving model performance. Tested on a real quantum computer further validated the effectiveness of the hybrid model, demonstrating the viable integration of quantum computing with deep learning, and highlighting the potential for leveraging quantum properties to enhance model performance. üèÖ Competition Experience ü•â China International \u0026#34;Internet \u0026#43;\u0026#34; College Students\u0026#39; Innovation Competition 08/2022 üõ°Ô∏è Zhongke Ushield: Deep Learning-based Face Privacy Protection Authentication System Responsible for constructing a localized facial feature extraction engine based on MobileFaceNet, ensuring feature extraction is completed on end devices (such as mobile phones and cameras), guaranteeing that raw data does not leave the domain and is not stored, thus enhancing user privacy protection while improving recognition efficiency. ü•â \u0026#34;Challenge Cup\u0026#34; Capital University Entrepreneurship Competition 05/2022 üå≥ Smart Orchard Responsible for the development of the fruit detection, ripeness prediction, and pest identification system, using deep convolutional neural network (CNN) technology for intelligent monitoring of crop growth conditions. Applied advanced object detection algorithms such as Faster R-CNN and YOLO to achieve high precision in apple detection and ripeness assessment, with an accuracy rate exceeding 90%, significantly enhancing the intelligence level of orchard management. Built and trained a dedicated dataset containing various pest samples, optimizing pest detection accuracy through data preprocessing (such as image normalization and resizing) and data augmentation techniques (like rotation, flipping, and noise addition), enabling the real-time monitoring system to accurately identify over 80% of pests, providing effective scientific maintenance recommendations to help farmers reduce crop losses. üìã Extracurricular Activities Vice President, Cyber Security Club, Beijing Institute of Technology 09/2021-09/2022 Backbone, Media Center of the Student Union of Beijing Institute of Technology 10/2020-06/2021 üì´ Contact üìß Email: zongsi.xu@outlook.com üëî LinkedIn: Zongsi (Tristan) Xu üíª GitHub: BaizeXS üìç Location: Hong Kong SAR, China ","permalink":"http://localhost:1313/resume/","summary":"Personal resume of Zongsi (Tristan) Xu","title":"Zongsi (Tristan) Xu"},{"content":"‰∏Ä„ÄÅÊï∞ÂÄºÁâπÂæÅ‰∏éÁ±ªÂà´ÁâπÂæÅ Êï∞ÂÄºÁâπÂæÅ (Numeric Features) ÂÖ∑ÊúâÂèØÂä†ÂáèÁöÑÊÑè‰πâÔºå‰∏îÂ≠òÂú®Â§ßÂ∞èÈ°∫Â∫è„ÄÇ ‰æãÂ≠êÔºöÂπ¥ÈæÑ„ÄÅÊ∏©Â∫¶Á≠â„ÄÇÂèØ‰ª•Áõ¥Êé•‰øùÁïôÂÖ∂Êï¥Êï∞ÊàñÊµÆÁÇπÊï∞ÂΩ¢Âºè‰æõÊ®°Âûã‰ΩøÁî®„ÄÇ Á±ªÂà´ÁâπÂæÅ (Categorical Features) Êï∞ÊçÆÂÄºÁ¶ªÊï£Ôºå‰∏çÂÖ∑Â§á‚ÄúÊï∞ÂÄºÂ§ßÂ∞è‚ÄùÈó¥ÁöÑÂèØÊØîÊÑè‰πâ„ÄÇ ‰æãÂ≠êÔºöÂõΩÁ±çÔºàÁæéÂõΩ/‰∏≠ÂõΩ/Âç∞Â∫¶Á≠âÔºâ„ÄÅÊÄßÂà´ÔºàÁî∑/Â•≥ÔºâÁ≠â„ÄÇ ÈóÆÈ¢òÔºöËã•‰ªÖÁî®Êï¥Êï∞Ë°®Á§∫ÔºàÁæéÂõΩ=1, ‰∏≠ÂõΩ=2ÔºâÔºå‰ºöÂºïÂÖ•ÈîôËØØÁöÑÊï∞ÂÄºËøêÁÆóÂÖ≥Á≥ªÔºåÂ¶Ç ‚ÄúÁæéÂõΩ + ‰∏≠ÂõΩ = Âç∞Â∫¶‚Äù„ÄÇ ‰∫å„ÄÅOne-HotÁºñÁ†ÅÁöÑÂä®Êú∫‰∏éÊµÅÁ®ã ‰∏∫‰ªÄ‰πà‰ΩøÁî®One-Hot\nÈÄöËøáÂ∞ÜÁ±ªÂà´Êò†Â∞Ñ‰∏∫ÂêëÈáèÔºåÈÅøÂÖçÊï¥Êï∞ÁºñÁ†ÅÂºïÂÖ•ÁöÑ‰º™Êï∞ÂÄºÂÖ≥Á≥ª„ÄÇ ÂêåÊó∂‰øùÁïôÂêÑÁßçÂèØËÉΩÁ±ªÂà´ÁöÑ‰ø°ÊÅØÔºå‰∏î‰ªÖÂú®ÂØπÂ∫î‰ΩçÁΩÆ‰∏∫1ÔºåÂÖ∂‰ªñ‰ΩçÁΩÆ‰∏∫0„ÄÇ Âª∫Á´ãÊò†Â∞ÑÔºö‰ªéÁ±ªÂà´Âà∞Á¥¢Âºï\n‰∏∫ÊØè‰∏™Á±ªÂà´ÂàÜÈÖç‰∏Ä‰∏™ÂîØ‰∏ÄÁ¥¢ÂºïÔºåÈÄöÂ∏∏‰ªé1ÂºÄÂßã„ÄÇ È¢ÑÁïôÁ¥¢Âºï0Ë°®Á§∫‚ÄúÊú™Áü•‚ÄùÊàñ‚ÄúÁº∫Â§±‚ÄùÔºåÂØπÂ∫îÂÖ®0ÂêëÈáè„ÄÇ ËΩ¨Êç¢‰∏∫One-HotÂêëÈáè\nËã•Á±ªÂà´ÊÄªÊï∞‰∏∫197ÔºåÂàôÁî®197Áª¥ÂêëÈáèË°®Á§∫„ÄÇ ‰æãÂ≠êÔºöÁæéÂõΩ [1, 0, 0, 0, ‚Ä¶]Ôºå ‰∏≠ÂõΩ [0, 1, 0, 0, ‚Ä¶]„ÄÇ Á§∫‰æãÔºöË°®Á§∫‰∏Ä‰∏™‰∫∫ÁöÑÁâπÂæÅ\nÁâπÂæÅÂåÖÂê´ÔºàÂπ¥ÈæÑ, ÊÄßÂà´, ÂõΩÁ±çÔºåÂÖ∂‰∏≠ÂõΩÁ±ç197ÁßçÔºâ Áª¥Â∫¶ÊÄªÂíåÔºö1Áª¥_age + 1Áª¥_gender + 197Áª¥_nationality = 199Áª¥„ÄÇ ‰æãÂ¶Ç (28, Â•≥, ‰∏≠ÂõΩ) ‚Üí [28, 0, 0, 1, 0, ‚Ä¶, 0]„ÄÇ ‰∏â„ÄÅÊñáÊú¨Êï∞ÊçÆÂ§ÑÁêÜÊµÅÁ®ã ÊñáÊú¨Âú®Ëá™ÁÑ∂ËØ≠Ë®ÄÂ§ÑÁêÜÔºàNLPÔºâ‰∏≠‰Ωú‰∏∫Â∏∏ËßÅÁöÑÂéüÂßãËæìÂÖ•ÔºåÈúÄË¶ÅÊï∞ÂÄºÂåñÊâçËÉΩÈÄÅÂÖ•Ê®°Âûã„ÄÇ‰∏ÄËà¨Ê≠•È™§Â¶Ç‰∏ãÔºö\nÂàÜËØç (Tokenization)\nÂ∞ÜÊñáÊú¨ÊãÜÂàÜ‰∏∫‰∏Ä‰∏™‰∏™ÂçïËØçÔºàTokenÔºâ„ÄÇ ‰æãÂ≠êÔºö\u0026quot;... to be or not to be...\u0026quot; ‚Üí [\u0026quot;...\u0026quot;, \u0026quot;to\u0026quot;, \u0026quot;be\u0026quot;, \u0026quot;or\u0026quot;, \u0026quot;not\u0026quot;, \u0026quot;to\u0026quot;, \u0026quot;be\u0026quot;, \u0026quot;...\u0026quot;]„ÄÇ ÁªüËÆ°ËØçÈ¢ë \u0026amp; ÊûÑÂª∫ËØçÂÖ∏\nËØçÈ¢ëÁªüËÆ° Áî®ÂìàÂ∏åË°®/Â≠óÂÖ∏ËÆ∞ÂΩïÊØè‰∏™ÂçïËØçÂá∫Áé∞Ê¨°Êï∞„ÄÇ ÈÅçÂéÜÊñáÊú¨Êó∂ÔºåËã•ÂçïËØçÂ∞öÊú™ÂÖ•Ë°®ÔºåÂàôÊñ∞Âª∫ËÆ∞ÂΩïÔºõËã•Â∑≤Â≠òÂú®ÔºåÂàôËÆ°Êï∞+1„ÄÇ ÊéíÂ∫è‰∏éÁ¥¢Âºï ÊåâËØçÈ¢ëÈôçÂ∫èÊéíÂ∫èÔºåËØçÈ¢ëÊúÄÈ´òÁöÑÂçïËØçÊéíÂú®ÂâçÈù¢„ÄÇ Á¥¢Âºï‰ªé1ÂºÄÂßãÔºå0ÁïôÁªô‚ÄúÊú™Áü•‚Äù„ÄÇ ËØçÂÖ∏ËßÑÊ®°ÔºàvocabularyÔºâÂèØËßÜÈúÄÊ±ÇÊà™Êñ≠Ôºà‰æãÂ¶ÇÂè™‰øùÁïôTop 10kÔºâ„ÄÇ ‰∏∫‰ªÄ‰πàÁßªÈô§‰ΩéÈ¢ëËØç ‰ΩéÈ¢ëËØçÂèØËÉΩÊòØÊãºÂÜôÈîôËØØ„ÄÅÁΩïËßÅ‰∫∫ÂêçÁ≠âÔºåÂØπÊ®°ÂûãÂ∏ÆÂä©ÊúâÈôê„ÄÇ ÂáèÂ∞ëËØçÂÖ∏ËßÑÊ®°ÂèØÈôç‰ΩéËøêÁÆóÂºÄÈîÄ„ÄÅÂä†Âø´Ê®°ÂûãËÆ≠ÁªÉ‰∏éÊé®ÁêÜÈÄüÂ∫¶„ÄÇ Áã¨ÁÉ≠ÁºñÁ†Å (One-Hot Encoding)\nÂ∞ÜÊØè‰∏™ÂçïËØçÊò†Â∞Ñ‰∏∫ËØçÂÖ∏‰∏≠ÁöÑÁ¥¢ÂºïÂêéÔºàÂ¶Ç [2, 4, 1, 8, ‚Ä¶]ÔºâÔºåÂèØËøõ‰∏ÄÊ≠•ËΩ¨Êç¢ÊàêOne-HotÂêëÈáè„ÄÇ One-HotÁª¥Â∫¶ÂèñÂÜ≥‰∫é‰øùÁïô‰∏ãÊù•ÁöÑËØçÂÖ∏Â§ßÂ∞èÔºà‰æãÂ¶Ç1‰∏áÔºâ„ÄÇ Êú™Êî∂ÂΩïÂçïËØçÂèØËÉΩÁõ¥Êé•ÂøΩÁï•ÔºåÊàñÁªü‰∏ÄÁî®Á¥¢Âºï0‰ª£Êõø„ÄÇ Âõõ„ÄÅÊ†∏ÂøÉÊî∂Ëé∑‰∏éÂ∫îÁî® Á±ªÂà´ÁâπÂæÅÂøÖÈúÄÊï∞ÂÄºÂåñÔºö\n‰ΩøÁî®Êï¥Êï∞1,2,3‚Ä¶‰ªÖË°®Á§∫Á±ªÂà´‚ÄúÊ†áËØÜ‚ÄùÔºåÂπ∂‰∏ç‰ª£Ë°®ÂÆÉ‰ª¨ÂèØËøõË°åÊï∞ÂÄºËøêÁÆó„ÄÇ Âõ†Ê≠§ÈúÄË¶ÅOne-HotÁ≠âÁºñÁ†ÅÊñπÂºèÔºåÈÅøÂÖçÊï∞ÂÄºËØØËß£„ÄÇ ÊñáÊú¨Êï∞ÊçÆÈ¢ÑÂ§ÑÁêÜÔºö\nÂàÜËØç„ÄÅËØçÈ¢ëÁªüËÆ°„ÄÅÊûÑÂª∫ËØçÂÖ∏„ÄÅÁ¥¢ÂºïÂåñ„ÄÅOne-HotÊàñÂÖ∂‰ªñÊñπÂºèÔºàÂ¶ÇËØçÂµåÂÖ•ÔºâÊòØÂ∏∏ËßÅÊµÅÁ®ã„ÄÇ Ê≠£Á°ÆÁöÑÊñáÊú¨È¢ÑÂ§ÑÁêÜÂèØÊòæËëóÂΩ±ÂìçÊ®°ÂûãÊÄßËÉΩÂíåÊïàÁéá„ÄÇ ‰øùÁïôÊú™Áü•Á¥¢ÂºïÔºö\n‰øùËØÅÂØπÁº∫Â§±Êï∞ÊçÆÊàñÂ≠óÂÖ∏Â§ñÊñ∞ËØçËÉΩÊúâÂü∫Êú¨ÁöÑË°®Á§∫ÔºåÊèêÂçáÊ®°ÂûãÂÆπÈîôÊÄß„ÄÇ ÂÆûÈôÖ‰ΩøÁî®Ôºö\nÂØπ‰∫éÂ∞èËßÑÊ®°Á±ªÂà´ÂèØÁõ¥Êé•One-HotÁºñÁ†ÅÔºõÂØπ‰∫éËØçÂÖ∏ÂæàÂ§ßÁöÑÂú∫ÊôØÔºåÈÄöÂ∏∏‰ºöËøõ‰∏ÄÊ≠•ËÄÉËôëËØçÂµåÂÖ•ÔºàWord EmbeddingÔºâÊàñÈ¢ÑËÆ≠ÁªÉËØ≠Ë®ÄÊ®°Âûã„ÄÇ ","permalink":"http://localhost:1313/posts/nlp-1/","summary":"\u003ch2 id=\"‰∏ÄÊï∞ÂÄºÁâπÂæÅ‰∏éÁ±ªÂà´ÁâπÂæÅ\"\u003e‰∏Ä„ÄÅÊï∞ÂÄºÁâπÂæÅ‰∏éÁ±ªÂà´ÁâπÂæÅ\u003c/h2\u003e\n\u003col\u003e\n\u003cli\u003e\u003cstrong\u003eÊï∞ÂÄºÁâπÂæÅ (Numeric Features)\u003c/strong\u003e\n\u003cul\u003e\n\u003cli\u003eÂÖ∑ÊúâÂèØÂä†ÂáèÁöÑÊÑè‰πâÔºå‰∏îÂ≠òÂú®Â§ßÂ∞èÈ°∫Â∫è„ÄÇ\u003c/li\u003e\n\u003cli\u003e‰æãÂ≠êÔºöÂπ¥ÈæÑ„ÄÅÊ∏©Â∫¶Á≠â„ÄÇÂèØ‰ª•Áõ¥Êé•‰øùÁïôÂÖ∂Êï¥Êï∞ÊàñÊµÆÁÇπÊï∞ÂΩ¢Âºè‰æõÊ®°Âûã‰ΩøÁî®„ÄÇ\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003eÁ±ªÂà´ÁâπÂæÅ (Categorical Features)\u003c/strong\u003e\n\u003cul\u003e\n\u003cli\u003eÊï∞ÊçÆÂÄºÁ¶ªÊï£Ôºå‰∏çÂÖ∑Â§á‚ÄúÊï∞ÂÄºÂ§ßÂ∞è‚ÄùÈó¥ÁöÑÂèØÊØîÊÑè‰πâ„ÄÇ\u003c/li\u003e\n\u003cli\u003e‰æãÂ≠êÔºöÂõΩÁ±çÔºàÁæéÂõΩ/‰∏≠ÂõΩ/Âç∞Â∫¶Á≠âÔºâ„ÄÅÊÄßÂà´ÔºàÁî∑/Â•≥ÔºâÁ≠â„ÄÇ\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003eÈóÆÈ¢ò\u003c/strong\u003eÔºöËã•‰ªÖÁî®Êï¥Êï∞Ë°®Á§∫ÔºàÁæéÂõΩ=1, ‰∏≠ÂõΩ=2ÔºâÔºå‰ºöÂºïÂÖ•ÈîôËØØÁöÑÊï∞ÂÄºËøêÁÆóÂÖ≥Á≥ªÔºåÂ¶Ç ‚ÄúÁæéÂõΩ + ‰∏≠ÂõΩ = Âç∞Â∫¶‚Äù„ÄÇ\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003c/ol\u003e\n\u003ch2 id=\"‰∫åone-hotÁºñÁ†ÅÁöÑÂä®Êú∫‰∏éÊµÅÁ®ã\"\u003e‰∫å„ÄÅOne-HotÁºñÁ†ÅÁöÑÂä®Êú∫‰∏éÊµÅÁ®ã\u003c/h2\u003e\n\u003col\u003e\n\u003cli\u003e\n\u003cp\u003e\u003cstrong\u003e‰∏∫‰ªÄ‰πà‰ΩøÁî®One-Hot\u003c/strong\u003e\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eÈÄöËøáÂ∞ÜÁ±ªÂà´Êò†Â∞Ñ‰∏∫ÂêëÈáèÔºåÈÅøÂÖçÊï¥Êï∞ÁºñÁ†ÅÂºïÂÖ•ÁöÑ‰º™Êï∞ÂÄºÂÖ≥Á≥ª„ÄÇ\u003c/li\u003e\n\u003cli\u003eÂêåÊó∂‰øùÁïôÂêÑÁßçÂèØËÉΩÁ±ªÂà´ÁöÑ‰ø°ÊÅØÔºå‰∏î‰ªÖÂú®ÂØπÂ∫î‰ΩçÁΩÆ‰∏∫1ÔºåÂÖ∂‰ªñ‰ΩçÁΩÆ‰∏∫0„ÄÇ\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003e\u003cstrong\u003eÂª∫Á´ãÊò†Â∞ÑÔºö‰ªéÁ±ªÂà´Âà∞Á¥¢Âºï\u003c/strong\u003e\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e‰∏∫ÊØè‰∏™Á±ªÂà´ÂàÜÈÖç‰∏Ä‰∏™ÂîØ‰∏ÄÁ¥¢ÂºïÔºåÈÄöÂ∏∏‰ªé1ÂºÄÂßã„ÄÇ\u003c/li\u003e\n\u003cli\u003eÈ¢ÑÁïôÁ¥¢Âºï0Ë°®Á§∫‚ÄúÊú™Áü•‚ÄùÊàñ‚ÄúÁº∫Â§±‚ÄùÔºåÂØπÂ∫îÂÖ®0ÂêëÈáè„ÄÇ\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003e\u003cstrong\u003eËΩ¨Êç¢‰∏∫One-HotÂêëÈáè\u003c/strong\u003e\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eËã•Á±ªÂà´ÊÄªÊï∞‰∏∫197ÔºåÂàôÁî®197Áª¥ÂêëÈáèË°®Á§∫„ÄÇ\u003c/li\u003e\n\u003cli\u003e‰æãÂ≠êÔºöÁæéÂõΩ \u003ccode\u003e[1, 0, 0, 0, ‚Ä¶]\u003c/code\u003eÔºå ‰∏≠ÂõΩ \u003ccode\u003e[0, 1, 0, 0, ‚Ä¶]\u003c/code\u003e„ÄÇ\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003e\u003cstrong\u003eÁ§∫‰æãÔºöË°®Á§∫‰∏Ä‰∏™‰∫∫ÁöÑÁâπÂæÅ\u003c/strong\u003e\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eÁâπÂæÅÂåÖÂê´ÔºàÂπ¥ÈæÑ, ÊÄßÂà´, ÂõΩÁ±çÔºåÂÖ∂‰∏≠ÂõΩÁ±ç197ÁßçÔºâ\u003c/li\u003e\n\u003cli\u003eÁª¥Â∫¶ÊÄªÂíåÔºö1Áª¥_age + 1Áª¥_gender + 197Áª¥_nationality = 199Áª¥„ÄÇ\u003c/li\u003e\n\u003cli\u003e‰æãÂ¶Ç \u003ccode\u003e(28, Â•≥, ‰∏≠ÂõΩ)\u003c/code\u003e ‚Üí \u003ccode\u003e[28, 0, 0, 1, 0, ‚Ä¶, 0]\u003c/code\u003e„ÄÇ\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003c/ol\u003e\n\u003ch2 id=\"‰∏âÊñáÊú¨Êï∞ÊçÆÂ§ÑÁêÜÊµÅÁ®ã\"\u003e‰∏â„ÄÅÊñáÊú¨Êï∞ÊçÆÂ§ÑÁêÜÊµÅÁ®ã\u003c/h2\u003e\n\u003cp\u003eÊñáÊú¨Âú®Ëá™ÁÑ∂ËØ≠Ë®ÄÂ§ÑÁêÜÔºàNLPÔºâ‰∏≠‰Ωú‰∏∫Â∏∏ËßÅÁöÑÂéüÂßãËæìÂÖ•ÔºåÈúÄË¶ÅÊï∞ÂÄºÂåñÊâçËÉΩÈÄÅÂÖ•Ê®°Âûã„ÄÇ‰∏ÄËà¨Ê≠•È™§Â¶Ç‰∏ãÔºö\u003c/p\u003e\n\u003col\u003e\n\u003cli\u003e\n\u003cp\u003e\u003cstrong\u003eÂàÜËØç (Tokenization)\u003c/strong\u003e\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eÂ∞ÜÊñáÊú¨ÊãÜÂàÜ‰∏∫‰∏Ä‰∏™‰∏™ÂçïËØçÔºàTokenÔºâ„ÄÇ\u003c/li\u003e\n\u003cli\u003e‰æãÂ≠êÔºö\u003ccode\u003e\u0026quot;... to be or not to be...\u0026quot;\u003c/code\u003e ‚Üí \u003ccode\u003e[\u0026quot;...\u0026quot;, \u0026quot;to\u0026quot;, \u0026quot;be\u0026quot;, \u0026quot;or\u0026quot;, \u0026quot;not\u0026quot;, \u0026quot;to\u0026quot;, \u0026quot;be\u0026quot;, \u0026quot;...\u0026quot;]\u003c/code\u003e„ÄÇ\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003e\u003cstrong\u003eÁªüËÆ°ËØçÈ¢ë \u0026amp; ÊûÑÂª∫ËØçÂÖ∏\u003c/strong\u003e\u003c/p\u003e","title":""},{"content":"Text to Sequence ÊñáÊú¨Â§ÑÁêÜ\nStep1: Tokenization\nTokenization breaks a piece of text down into a list of tokens.\nHere, a token is a word. (A token can be a character in some applications.)\nTokenizationËÆ≤Á©∂ÂæàÂ§öÔºå‰æãÂ¶ÇÊòØÂê¶Â∫îËØ•ÊääÂ§ßÂÜôÊîπÊàêÂ∞èÂÜôÂë¢ÔºüËøõË°åtypo correctionÁ≠âÁ≠â\nStep2: Build Dictionary\nUse a dictionary (hash table) to count word frequencies.\nThe dictionary maps word to index.\nÂèØ‰ª•È¶ñÂÖàÁªüËÆ°ËØçÈ¢ëÂéªÊéâ‰ΩéÈ¢ëËØçÔºåÁÑ∂ÂêéËÆ©ÊØè‰∏™ËØçÂØπÂ∫î‰∏Ä‰∏™Ê≠£Êï¥Êï∞ÔºõËøôÊ†∑ÁöÑËØùÔºå‰∏ÄÂè•ËØùÂ∞±ÂèØ‰ª•Áî®‰∏Ä‰∏™Ê≠£Êï¥Êï∞ÂàóË°®Ë°®Á§∫ÔºåËøô‰∏™ÂàóË°®Â∞±Âè´sequenceÔºõÂ¶ÇÊûúÂøÖË¶ÅÂ∞±ËøòÂæóÂÅöone-hot encoding„ÄÇ\nÁªìÊûú\n‰ΩÜÊòØÈïøÂ∫¶‰∏çÁªü‰∏Ä\nStep4: ÂØπÈΩêsequence\nËß£ÂÜ≥ÊñπÊ°àÊòØËøôÊ†∑ÁöÑÔºöÂèØ‰ª•Âõ∫ÂÆöÈïøÂ∫¶‰∏∫wÔºåÂä†ÂÖ•‰∏Ä‰∏™Â∫èÂàóÈïøÂ∫¶Â§™ÈïøÔºåÂ∞±Á†çÊéâÂâçÈù¢ÁöÑËØçÔºåÂè™‰øùÁïôÊúÄÂêéw‰∏™ËØçÔºõÂ¶ÇÊûú‰∏Ä‰∏™Â∫èÂàóÂ§™Áü≠ÔºåÂ∞±ÂÅözero paddingÔºåÁî®0Â°´ÂÖÖ\nËøôÊ†∑‰∏ÄÊù•ÔºåÊâÄÊúâÁöÑÂ∫èÂàóÈïøÂ∫¶Â∞±Áªü‰∏Ä‰∫Ü\nÊñáÊú¨Â§ÑÁêÜÂÆåÊàê‰∫ÜÔºåÊé•‰∏ãÊù•ÊòØword embeddingÔºåÊääÂçïËØçË°®Á§∫‰∏∫‰∏Ä‰∏™‰ΩéÁª¥ÂêëÈáèÔºõ\nÁÑ∂ËÄåËøôÊ†∑ÂÅöÁöÑËØùÔºåÂ¶ÇÊûúÊòØ10000‰∏™ÂçïËØçÔºåÁª¥Â∫¶Â∞±ÊòØ10000Áª¥ÔºåÁª¥Â∫¶Â§™È´ò‰∫ÜÔºõÂõ†Ê≠§Ë¶ÅÂÅöword embeddingÔºõ\nÂÖ∑‰ΩìÂÅöÊ≥ïÂ∞±ÊòØÊääone-hotÂêëÈáèe_iÂíåÂèÇÊï∞Áü©ÈòµpÁõ∏‰πòÔºõÁü©ÈòµPËΩ¨ÁΩÆÁöÑÂ§ßÂ∞èÊòØd x vÔºõdÊòØËØçÂêëÈáèÁöÑÁª¥Â∫¶ÔºõvÊòØÂ≠óÂÖ∏ÈáåËØçÊ±áÁöÑÊï∞ÈáèÔºõÁªìÊûú‰∏∫x_iÔºõx_iÂ∞±ÊòØ‰∏Ä‰∏™ËØçÂêëÈáèÔºõÂ¶ÇÊûúone-hotÂêëÈáèÁöÑÁ¨¨‰∏âË°å‰∏∫1ÔºõÈÇ£‰πàx_iÂ∞±ÊòØPËΩ¨ÁΩÆÁü©ÈòµÁöÑÁ¨¨‰∏âÂàóÔºàÂÖ∂‰ΩôÂàóÈÉΩ‰∏∫0ÔºâÔºõÊâÄ‰ª•PËΩ¨ÁΩÆÊØè‰∏ÄÂàóÈÉΩÊòØ‰∏Ä‰∏™ËØçÂêëÈáèÔºõÊâÄ‰ª•Áü©ÈòµPÊú¨Ë∫´ÁöÑÊØè‰∏ÄË°åÂ∞±ÊòØ‰∏Ä‰∏™ËØçÂêëÈáèÔºõÂÖ∂Ë°åÊï∞‰∏∫vÔºõÂç≥vocabularyÔºåËØçÊ±áÈáèÔºõÊØè‰∏ÄË°åÂØπÂ∫î‰∏Ä‰∏™ÂçïËØçÔºõÁü©ÈòµÁöÑÂàóÊï∞‰∏∫dÔºõdÊòØÁî®Êà∑ÂÜ≥ÂÆöÁöÑÔºõdÁöÑÂ§ßÂ∞è‰ºöÂÜ≥ÂÆöÊú∫Âô®Â≠¶‰π†Ê®°ÂûãÁöÑË°®Áé∞ÔºõÂ∫îËØ•Áî®xxxÊù•ÈÄâÊã©‰∏Ä‰∏™ÊØîËæÉÂ•ΩÁöÑdÔºõ\nÊàë‰ª¨ÁöÑ‰ªªÂä°ÊòØÁúãËØÑËÆ∫ÊòØÊ≠£Èù¢ÁöÑËøòÊòØË¥üÈù¢ÁöÑÔºõÂèÇÊï∞Áü©ÈòµÊòØ‰ªéËÆ≠ÁªÉÊï∞ÊçÆ‰∏≠Â≠¶‰π†Âá∫Êù•ÁöÑÔºåÊâÄ‰ª•Â≠¶Âá∫Êù•ÁöÑËØçÂêëÈáèÊòØÂ∏¶ÊúâÊÑüÊÉÖËâ≤ÂΩ©ÁöÑÔºõÂÅáËÆæËøô‰∫õËØçÂêëÈáèÈÉΩÊòØ‰∫åÁª¥ÁöÑÔºåÂàôÂèØ‰ª•Âú®Âπ≥Èù¢ÂùêÊ†áÁ≥ª‰∏≠Ê†áÂá∫‰∏ãÈù¢ËØçÂêëÈáè\nkerasÊèê‰æõembeddingÂ±ÇÔºõÁî®Êà∑ÂèØ‰ª•ÊåáÂÆövocabularyÂ§ßÂ∞èÂíådÁöÑÂ§ßÂ∞èÔºõ‰ª•ÂèäÊØè‰∏Ä‰∏™sequenceÁöÑÈïøÂ∫¶ÔºõdÊòØÊ†πÊçÆÁÆóÊ≥ïÈÄâÂá∫Êù•ÁöÑ Âà∞Ëøô‰∏ÄÊ≠•ÔºåÊàë‰ª¨Â∑≤ÁªèÂÆåÊàê‰∫ÜÊñáÊú¨Â§ÑÁêÜÂíåword embedding„ÄÇÊé•‰∏ãÊù•Â∞±ÊòØÁî®Logistic Regression for Binary ClassificationÂÅö‰∫åÂàÜÁ±ªÔºõ\n","permalink":"http://localhost:1313/posts/nlp-2/","summary":"\u003ch3 id=\"text-to-sequence\"\u003eText to Sequence\u003c/h3\u003e\n\u003cp\u003eÊñáÊú¨Â§ÑÁêÜ\u003c/p\u003e\n\u003cp\u003eStep1: Tokenization\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\n\u003cp\u003eTokenization breaks a piece of text down into a list of tokens.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003eHere, a token is a word. (A token can be a character in some applications.)\u003c/p\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003eTokenizationËÆ≤Á©∂ÂæàÂ§öÔºå‰æãÂ¶ÇÊòØÂê¶Â∫îËØ•ÊääÂ§ßÂÜôÊîπÊàêÂ∞èÂÜôÂë¢ÔºüËøõË°åtypo correctionÁ≠âÁ≠â\u003c/p\u003e\n\u003cp\u003e\u003cimg alt=\"image-20250322150322238\" loading=\"lazy\" src=\"./NLP-2.assets/image-20250322150322238.png\"\u003e\u003c/p\u003e\n\u003cp\u003eStep2: Build Dictionary\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\n\u003cp\u003eUse a dictionary (hash table) to count word frequencies.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003eThe dictionary maps word to index.\u003c/p\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003eÂèØ‰ª•È¶ñÂÖàÁªüËÆ°ËØçÈ¢ëÂéªÊéâ‰ΩéÈ¢ëËØçÔºåÁÑ∂ÂêéËÆ©ÊØè‰∏™ËØçÂØπÂ∫î‰∏Ä‰∏™Ê≠£Êï¥Êï∞ÔºõËøôÊ†∑ÁöÑËØùÔºå‰∏ÄÂè•ËØùÂ∞±ÂèØ‰ª•Áî®‰∏Ä‰∏™Ê≠£Êï¥Êï∞ÂàóË°®Ë°®Á§∫ÔºåËøô‰∏™ÂàóË°®Â∞±Âè´sequenceÔºõÂ¶ÇÊûúÂøÖË¶ÅÂ∞±ËøòÂæóÂÅöone-hot encoding„ÄÇ\u003cimg alt=\"image-20250322150620890\" loading=\"lazy\" src=\"./NLP-2.assets/image-20250322150620890.png\"\u003e\u003c/p\u003e\n\u003cp\u003eÁªìÊûú\u003c/p\u003e\n\u003cp\u003e\u003cimg alt=\"image-20250322150754528\" loading=\"lazy\" src=\"./NLP-2.assets/image-20250322150754528.png\"\u003e\u003c/p\u003e\n\u003cp\u003e‰ΩÜÊòØÈïøÂ∫¶‰∏çÁªü‰∏Ä\u003c/p\u003e\n\u003cp\u003eStep4: ÂØπÈΩêsequence\u003c/p\u003e\n\u003cp\u003e\u003cimg alt=\"image-20250322150854986\" loading=\"lazy\" src=\"./NLP-2.assets/image-20250322150854986.png\"\u003e\u003c/p\u003e\n\u003cp\u003eËß£ÂÜ≥ÊñπÊ°àÊòØËøôÊ†∑ÁöÑÔºöÂèØ‰ª•Âõ∫ÂÆöÈïøÂ∫¶‰∏∫wÔºåÂä†ÂÖ•‰∏Ä‰∏™Â∫èÂàóÈïøÂ∫¶Â§™ÈïøÔºåÂ∞±Á†çÊéâÂâçÈù¢ÁöÑËØçÔºåÂè™‰øùÁïôÊúÄÂêéw‰∏™ËØçÔºõÂ¶ÇÊûú‰∏Ä‰∏™Â∫èÂàóÂ§™Áü≠ÔºåÂ∞±ÂÅözero paddingÔºåÁî®0Â°´ÂÖÖ\u003c/p\u003e\n\u003cp\u003e\u003cimg alt=\"image-20250322151030119\" loading=\"lazy\" src=\"./NLP-2.assets/image-20250322151030119.png\"\u003e\u003c/p\u003e\n\u003cp\u003eËøôÊ†∑‰∏ÄÊù•ÔºåÊâÄÊúâÁöÑÂ∫èÂàóÈïøÂ∫¶Â∞±Áªü‰∏Ä‰∫Ü\u003c/p\u003e\n\u003cp\u003e\u003cimg alt=\"image-20250322151117125\" loading=\"lazy\" src=\"./NLP-2.assets/image-20250322151117125.png\"\u003e\u003c/p\u003e\n\u003cp\u003eÊñáÊú¨Â§ÑÁêÜÂÆåÊàê‰∫ÜÔºåÊé•‰∏ãÊù•ÊòØword embeddingÔºåÊääÂçïËØçË°®Á§∫‰∏∫‰∏Ä‰∏™‰ΩéÁª¥ÂêëÈáèÔºõ\u003c/p\u003e\n\u003cp\u003e\u003cimg alt=\"image-20250322151252837\" loading=\"lazy\" src=\"./NLP-2.assets/image-20250322151252837.png\"\u003e\u003c/p\u003e","title":""},{"content":"üëã About me Hello! I\u0026rsquo;m Xu Zongsi, a passionate technology enthusiast currently pursuing my Master of Science in ECIC at The University of Hong Kong. With a solid background in Software Engineering from the Beijing Institute of Technology, I specialize in artificial intelligence areas like machine learning, deep learning, natural language processing, computer vision, and reinforcement learning.\nInspired by OpenAI\u0026rsquo;s five-step plan towards superintelligence, I am excited about AGI and have developed a keen interest in LLM agents, MLLM, and knowledge graphs. I see great potential in these fields and aspire to contribute to innovative solutions.\nüìö Education üá≠üá∞ The University of Hong Kong 09/2024 - Expected 11/2025 School of Computing and Data Science Master of Science in Electronic Commerce \u0026amp; Internet Computing Relevant Courses: Machine learning for business and e-commerce, Knowledge graphs, Financial fraud analytics, Internet infrastructure technologies, Website engineering, Blockchain and cryptocurrency, etc. üá®üá≥ Beijing Institute of Technology 09/2020 - 06/2024 School of Computer Science \u0026amp; Technology Bachelor of Engineering in Software Engineering, last two years GPA: 3.7/4 Relevant Courses: Reinforcement Learning, Deep Learning and Computer Vision, Artificial Intelligence and Robot Ethics, Almost Human: Mind, Brain and Artificial Intelligence, Mathematical Analysis for Engineering, Linear Algebra, Probability and Mathematical Statistics, etc. Skills: Python, Java, common data structures, design patterns, machine learning basics and algorithms, Linux, PyTorch, and some development tools (git, conda, etc.). üèÜ Awards \u0026amp; Honors Beijing Institute of Technology Undergraduate Scholarship (Top 20% of Grade) 06/2023 3rd Prize of China International \u0026#34;Internet \u0026#43;\u0026#34; College Student\u0026#39;s Innovation Competition 08/2022 Bronze Prize of \u0026#34;Challenge Cup\u0026#34; Capital University Entrepreneurship Competition 05/2022 üíº Project Experience üîç Online Transaction Fraud Detection 09/2024 ‚Äì 01/2025 Independent project, supervised by Dr. Vivien Chan Focused on addressing financial fraud in e-commerce to enhance the accuracy of transaction anomaly detection, while independently managing the entire case study that included data preprocessing, feature engineering, model building, evaluation, and results analysis. Effectively resolved class imbalance issues using SMOTE and ROSE techniques. Built various models including Logistic Regression, Random Forest, XGBoost, and LightGBM, ultimately selecting the LightGBM model to achieve a recall rate of 95.45% and an AUC of 99.84%. Wrote efficient and maintainable code, enhancing model training and data processing efficiency through parallel computing and logging. ü§ñ Multi-Model Intelligent Text Keyword Extraction System 08/2023 ‚Äì 09/2023 Group project, supervised by Associate Prof. Xiaolin Zhao Designed and implemented an intelligent text summary system that automatically extracts keywords from article titles and abstracts, enhancing the understanding and summarization of text information. Participated in the planning of the technical route and built a hybrid model combining extractive and generative approaches, utilizing advanced natural language processing techniques including KeyBERT, Sentence Transformer, BERT, and T5 models. Responsible for data preprocessing and tokenization, as well as the end-to-end implementation and training of the T5 model, optimizing the model architecture and hyperparameters, achieving satisfactory results after only 3 epochs of training. Model evaluation results showed that the Rouge-1, Rouge-2, and Rouge-L metrics reached 0.6345, 0.5038, and 0.5282, respectively, in the third epoch, validating the model\u0026rsquo;s effectiveness in the summarization task. üéì Cambridge University Machine Learning Summer Project 07/2023 ‚Äì 08/2023 Group project, supervised by Prof. Pietro Li√≤ Participated in the Cambridge University deep learning summer project, focusing on deep reinforcement learning; explored multi-agent learning algorithms across different environments. Reproduced the Multi-Agent Deep Deterministic Policy Gradient (MADDPG) algorithm in the Simple Adversary environment and studied the effect of agent numbers on convergence speed and stability, finding optimal stability at 21 agents. Designed and implemented comparative experiments inspired by the Rainbow algorithm, assessing target network strategies versus the Double Deep Q-Network (Double DQN). The results demonstrated that Double DQN significantly enhanced convergence speed, optimizing the overall learning process. Co-authored a group project paper on agent numbers and strategies effectiveness in multi-agent systems, achieving a score of 71% in the summer program (the highest in my group) and a \u0026ldquo;First Class\u0026rdquo; classification in the UK grading system. üëÅÔ∏è Deep Learning and Computer Vision Semester Project 09/2022 ‚Äì 12/2022 Independent project, supervised by Associate Prof. Guangyu Gao Designed and implemented a waste classifier using the ResNet model to improve classification accuracy and reduce resource waste. The project also enhanced understanding of transfer learning techniques with ResNet. Collected a dataset of 16 waste categories and preprocessed the images for uniformity and standardization, incorporating data augmentation techniques to enhance the dataset. Conducted experiments using ResNet34 and ResNet50 models through transfer learning, accelerating network convergence by leveraging pretrained weights. During training, techniques such as Batch Normalization and Dropout were applied to mitigate the risk of overfitting. The final model achieved an accuracy of 90% on the training set, while the performance on the test set was 61%, indicating a significant overfitting phenomenon during the training process. üéì Internship ‚öõÔ∏è Beijing Academy of Quantum Information Science 08/2023 ‚Äì 01/2024 Research Intern at Quantum Computation Department Proposed a quantum convolution kernel design based on variational quantum circuits and developed a universal quantum convolution layer, successfully integrating it into classical CNN architectures such as VGG, GoogLeNet, and ResNet. Developed and evaluated various hybrid models, including a simple model named HQCCNN-2, which achieved 84.45% accuracy on the FashionMNIST dataset, surpassing the traditional CNN\u0026rsquo;s 80.72%. This demonstrates the effectiveness of the quantum convolution layer in improving model performance. Tested on a real quantum computer further validated the effectiveness of the hybrid model, demonstrating the viable integration of quantum computing with deep learning, and highlighting the potential for leveraging quantum properties to enhance model performance. üèÖ Competition Experience ü•â China International \u0026#34;Internet \u0026#43;\u0026#34; College Students\u0026#39; Innovation Competition 08/2022 üõ°Ô∏è Zhongke Ushield: Deep Learning-based Face Privacy Protection Authentication System Responsible for constructing a localized facial feature extraction engine based on MobileFaceNet, ensuring feature extraction is completed on end devices (such as mobile phones and cameras), guaranteeing that raw data does not leave the domain and is not stored, thus enhancing user privacy protection while improving recognition efficiency. ü•â \u0026#34;Challenge Cup\u0026#34; Capital University Entrepreneurship Competition 05/2022 üå≥ Smart Orchard Responsible for the development of the fruit detection, ripeness prediction, and pest identification system, using deep convolutional neural network (CNN) technology for intelligent monitoring of crop growth conditions. Applied advanced object detection algorithms such as Faster R-CNN and YOLO to achieve high precision in apple detection and ripeness assessment, with an accuracy rate exceeding 90%, significantly enhancing the intelligence level of orchard management. Built and trained a dedicated dataset containing various pest samples, optimizing pest detection accuracy through data preprocessing (such as image normalization and resizing) and data augmentation techniques (like rotation, flipping, and noise addition), enabling the real-time monitoring system to accurately identify over 80% of pests, providing effective scientific maintenance recommendations to help farmers reduce crop losses. üìã Extracurricular Activities Vice President, Cyber Security Club, Beijing Institute of Technology 09/2021-09/2022 Backbone, Media Center of the Student Union of Beijing Institute of Technology 10/2020-06/2021 üì´ Contact üìß Email: zongsi.xu@outlook.com üëî LinkedIn: Zongsi (Tristan) Xu üíª GitHub: BaizeXS üìç Location: Hong Kong SAR, China ","permalink":"http://localhost:1313/resume/","summary":"Personal resume of Zongsi (Tristan) Xu","title":"Zongsi (Tristan) Xu"},{"content":"‰∏Ä„ÄÅÊï∞ÂÄºÁâπÂæÅ‰∏éÁ±ªÂà´ÁâπÂæÅ Êï∞ÂÄºÁâπÂæÅ (Numeric Features) ÂÖ∑ÊúâÂèØÂä†ÂáèÁöÑÊÑè‰πâÔºå‰∏îÂ≠òÂú®Â§ßÂ∞èÈ°∫Â∫è„ÄÇ ‰æãÂ≠êÔºöÂπ¥ÈæÑ„ÄÅÊ∏©Â∫¶Á≠â„ÄÇÂèØ‰ª•Áõ¥Êé•‰øùÁïôÂÖ∂Êï¥Êï∞ÊàñÊµÆÁÇπÊï∞ÂΩ¢Âºè‰æõÊ®°Âûã‰ΩøÁî®„ÄÇ Á±ªÂà´ÁâπÂæÅ (Categorical Features) Êï∞ÊçÆÂÄºÁ¶ªÊï£Ôºå‰∏çÂÖ∑Â§á‚ÄúÊï∞ÂÄºÂ§ßÂ∞è‚ÄùÈó¥ÁöÑÂèØÊØîÊÑè‰πâ„ÄÇ ‰æãÂ≠êÔºöÂõΩÁ±çÔºàÁæéÂõΩ/‰∏≠ÂõΩ/Âç∞Â∫¶Á≠âÔºâ„ÄÅÊÄßÂà´ÔºàÁî∑/Â•≥ÔºâÁ≠â„ÄÇ ÈóÆÈ¢òÔºöËã•‰ªÖÁî®Êï¥Êï∞Ë°®Á§∫ÔºàÁæéÂõΩ=1, ‰∏≠ÂõΩ=2ÔºâÔºå‰ºöÂºïÂÖ•ÈîôËØØÁöÑÊï∞ÂÄºËøêÁÆóÂÖ≥Á≥ªÔºåÂ¶Ç ‚ÄúÁæéÂõΩ + ‰∏≠ÂõΩ = Âç∞Â∫¶‚Äù„ÄÇ ‰∫å„ÄÅOne-HotÁºñÁ†ÅÁöÑÂä®Êú∫‰∏éÊµÅÁ®ã ‰∏∫‰ªÄ‰πà‰ΩøÁî®One-Hot\nÈÄöËøáÂ∞ÜÁ±ªÂà´Êò†Â∞Ñ‰∏∫ÂêëÈáèÔºåÈÅøÂÖçÊï¥Êï∞ÁºñÁ†ÅÂºïÂÖ•ÁöÑ‰º™Êï∞ÂÄºÂÖ≥Á≥ª„ÄÇ ÂêåÊó∂‰øùÁïôÂêÑÁßçÂèØËÉΩÁ±ªÂà´ÁöÑ‰ø°ÊÅØÔºå‰∏î‰ªÖÂú®ÂØπÂ∫î‰ΩçÁΩÆ‰∏∫1ÔºåÂÖ∂‰ªñ‰ΩçÁΩÆ‰∏∫0„ÄÇ Âª∫Á´ãÊò†Â∞ÑÔºö‰ªéÁ±ªÂà´Âà∞Á¥¢Âºï\n‰∏∫ÊØè‰∏™Á±ªÂà´ÂàÜÈÖç‰∏Ä‰∏™ÂîØ‰∏ÄÁ¥¢ÂºïÔºåÈÄöÂ∏∏‰ªé1ÂºÄÂßã„ÄÇ È¢ÑÁïôÁ¥¢Âºï0Ë°®Á§∫‚ÄúÊú™Áü•‚ÄùÊàñ‚ÄúÁº∫Â§±‚ÄùÔºåÂØπÂ∫îÂÖ®0ÂêëÈáè„ÄÇ ËΩ¨Êç¢‰∏∫One-HotÂêëÈáè\nËã•Á±ªÂà´ÊÄªÊï∞‰∏∫197ÔºåÂàôÁî®197Áª¥ÂêëÈáèË°®Á§∫„ÄÇ ‰æãÂ≠êÔºöÁæéÂõΩ [1, 0, 0, 0, ‚Ä¶]Ôºå ‰∏≠ÂõΩ [0, 1, 0, 0, ‚Ä¶]„ÄÇ Á§∫‰æãÔºöË°®Á§∫‰∏Ä‰∏™‰∫∫ÁöÑÁâπÂæÅ\nÁâπÂæÅÂåÖÂê´ÔºàÂπ¥ÈæÑ, ÊÄßÂà´, ÂõΩÁ±çÔºåÂÖ∂‰∏≠ÂõΩÁ±ç197ÁßçÔºâ Áª¥Â∫¶ÊÄªÂíåÔºö1Áª¥_age + 1Áª¥_gender + 197Áª¥_nationality = 199Áª¥„ÄÇ ‰æãÂ¶Ç (28, Â•≥, ‰∏≠ÂõΩ) ‚Üí [28, 0, 0, 1, 0, ‚Ä¶, 0]„ÄÇ ‰∏â„ÄÅÊñáÊú¨Êï∞ÊçÆÂ§ÑÁêÜÊµÅÁ®ã ÊñáÊú¨Âú®Ëá™ÁÑ∂ËØ≠Ë®ÄÂ§ÑÁêÜÔºàNLPÔºâ‰∏≠‰Ωú‰∏∫Â∏∏ËßÅÁöÑÂéüÂßãËæìÂÖ•ÔºåÈúÄË¶ÅÊï∞ÂÄºÂåñÊâçËÉΩÈÄÅÂÖ•Ê®°Âûã„ÄÇ‰∏ÄËà¨Ê≠•È™§Â¶Ç‰∏ãÔºö\nÂàÜËØç (Tokenization)\nÂ∞ÜÊñáÊú¨ÊãÜÂàÜ‰∏∫‰∏Ä‰∏™‰∏™ÂçïËØçÔºàTokenÔºâ„ÄÇ ‰æãÂ≠êÔºö\u0026quot;... to be or not to be...\u0026quot; ‚Üí [\u0026quot;...\u0026quot;, \u0026quot;to\u0026quot;, \u0026quot;be\u0026quot;, \u0026quot;or\u0026quot;, \u0026quot;not\u0026quot;, \u0026quot;to\u0026quot;, \u0026quot;be\u0026quot;, \u0026quot;...\u0026quot;]„ÄÇ ÁªüËÆ°ËØçÈ¢ë \u0026amp; ÊûÑÂª∫ËØçÂÖ∏\nËØçÈ¢ëÁªüËÆ° Áî®ÂìàÂ∏åË°®/Â≠óÂÖ∏ËÆ∞ÂΩïÊØè‰∏™ÂçïËØçÂá∫Áé∞Ê¨°Êï∞„ÄÇ ÈÅçÂéÜÊñáÊú¨Êó∂ÔºåËã•ÂçïËØçÂ∞öÊú™ÂÖ•Ë°®ÔºåÂàôÊñ∞Âª∫ËÆ∞ÂΩïÔºõËã•Â∑≤Â≠òÂú®ÔºåÂàôËÆ°Êï∞+1„ÄÇ ÊéíÂ∫è‰∏éÁ¥¢Âºï ÊåâËØçÈ¢ëÈôçÂ∫èÊéíÂ∫èÔºåËØçÈ¢ëÊúÄÈ´òÁöÑÂçïËØçÊéíÂú®ÂâçÈù¢„ÄÇ Á¥¢Âºï‰ªé1ÂºÄÂßãÔºå0ÁïôÁªô‚ÄúÊú™Áü•‚Äù„ÄÇ ËØçÂÖ∏ËßÑÊ®°ÔºàvocabularyÔºâÂèØËßÜÈúÄÊ±ÇÊà™Êñ≠Ôºà‰æãÂ¶ÇÂè™‰øùÁïôTop 10kÔºâ„ÄÇ ‰∏∫‰ªÄ‰πàÁßªÈô§‰ΩéÈ¢ëËØç ‰ΩéÈ¢ëËØçÂèØËÉΩÊòØÊãºÂÜôÈîôËØØ„ÄÅÁΩïËßÅ‰∫∫ÂêçÁ≠âÔºåÂØπÊ®°ÂûãÂ∏ÆÂä©ÊúâÈôê„ÄÇ ÂáèÂ∞ëËØçÂÖ∏ËßÑÊ®°ÂèØÈôç‰ΩéËøêÁÆóÂºÄÈîÄ„ÄÅÂä†Âø´Ê®°ÂûãËÆ≠ÁªÉ‰∏éÊé®ÁêÜÈÄüÂ∫¶„ÄÇ Áã¨ÁÉ≠ÁºñÁ†Å (One-Hot Encoding)\nÂ∞ÜÊØè‰∏™ÂçïËØçÊò†Â∞Ñ‰∏∫ËØçÂÖ∏‰∏≠ÁöÑÁ¥¢ÂºïÂêéÔºàÂ¶Ç [2, 4, 1, 8, ‚Ä¶]ÔºâÔºåÂèØËøõ‰∏ÄÊ≠•ËΩ¨Êç¢ÊàêOne-HotÂêëÈáè„ÄÇ One-HotÁª¥Â∫¶ÂèñÂÜ≥‰∫é‰øùÁïô‰∏ãÊù•ÁöÑËØçÂÖ∏Â§ßÂ∞èÔºà‰æãÂ¶Ç1‰∏áÔºâ„ÄÇ Êú™Êî∂ÂΩïÂçïËØçÂèØËÉΩÁõ¥Êé•ÂøΩÁï•ÔºåÊàñÁªü‰∏ÄÁî®Á¥¢Âºï0‰ª£Êõø„ÄÇ Âõõ„ÄÅÊ†∏ÂøÉÊî∂Ëé∑‰∏éÂ∫îÁî® Á±ªÂà´ÁâπÂæÅÂøÖÈúÄÊï∞ÂÄºÂåñÔºö\n‰ΩøÁî®Êï¥Êï∞1,2,3‚Ä¶‰ªÖË°®Á§∫Á±ªÂà´‚ÄúÊ†áËØÜ‚ÄùÔºåÂπ∂‰∏ç‰ª£Ë°®ÂÆÉ‰ª¨ÂèØËøõË°åÊï∞ÂÄºËøêÁÆó„ÄÇ Âõ†Ê≠§ÈúÄË¶ÅOne-HotÁ≠âÁºñÁ†ÅÊñπÂºèÔºåÈÅøÂÖçÊï∞ÂÄºËØØËß£„ÄÇ ÊñáÊú¨Êï∞ÊçÆÈ¢ÑÂ§ÑÁêÜÔºö\nÂàÜËØç„ÄÅËØçÈ¢ëÁªüËÆ°„ÄÅÊûÑÂª∫ËØçÂÖ∏„ÄÅÁ¥¢ÂºïÂåñ„ÄÅOne-HotÊàñÂÖ∂‰ªñÊñπÂºèÔºàÂ¶ÇËØçÂµåÂÖ•ÔºâÊòØÂ∏∏ËßÅÊµÅÁ®ã„ÄÇ Ê≠£Á°ÆÁöÑÊñáÊú¨È¢ÑÂ§ÑÁêÜÂèØÊòæËëóÂΩ±ÂìçÊ®°ÂûãÊÄßËÉΩÂíåÊïàÁéá„ÄÇ ‰øùÁïôÊú™Áü•Á¥¢ÂºïÔºö\n‰øùËØÅÂØπÁº∫Â§±Êï∞ÊçÆÊàñÂ≠óÂÖ∏Â§ñÊñ∞ËØçËÉΩÊúâÂü∫Êú¨ÁöÑË°®Á§∫ÔºåÊèêÂçáÊ®°ÂûãÂÆπÈîôÊÄß„ÄÇ ÂÆûÈôÖ‰ΩøÁî®Ôºö\nÂØπ‰∫éÂ∞èËßÑÊ®°Á±ªÂà´ÂèØÁõ¥Êé•One-HotÁºñÁ†ÅÔºõÂØπ‰∫éËØçÂÖ∏ÂæàÂ§ßÁöÑÂú∫ÊôØÔºåÈÄöÂ∏∏‰ºöËøõ‰∏ÄÊ≠•ËÄÉËôëËØçÂµåÂÖ•ÔºàWord EmbeddingÔºâÊàñÈ¢ÑËÆ≠ÁªÉËØ≠Ë®ÄÊ®°Âûã„ÄÇ ","permalink":"http://localhost:1313/posts/nlp-1/","summary":"\u003ch2 id=\"‰∏ÄÊï∞ÂÄºÁâπÂæÅ‰∏éÁ±ªÂà´ÁâπÂæÅ\"\u003e‰∏Ä„ÄÅÊï∞ÂÄºÁâπÂæÅ‰∏éÁ±ªÂà´ÁâπÂæÅ\u003c/h2\u003e\n\u003col\u003e\n\u003cli\u003e\u003cstrong\u003eÊï∞ÂÄºÁâπÂæÅ (Numeric Features)\u003c/strong\u003e\n\u003cul\u003e\n\u003cli\u003eÂÖ∑ÊúâÂèØÂä†ÂáèÁöÑÊÑè‰πâÔºå‰∏îÂ≠òÂú®Â§ßÂ∞èÈ°∫Â∫è„ÄÇ\u003c/li\u003e\n\u003cli\u003e‰æãÂ≠êÔºöÂπ¥ÈæÑ„ÄÅÊ∏©Â∫¶Á≠â„ÄÇÂèØ‰ª•Áõ¥Êé•‰øùÁïôÂÖ∂Êï¥Êï∞ÊàñÊµÆÁÇπÊï∞ÂΩ¢Âºè‰æõÊ®°Âûã‰ΩøÁî®„ÄÇ\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003eÁ±ªÂà´ÁâπÂæÅ (Categorical Features)\u003c/strong\u003e\n\u003cul\u003e\n\u003cli\u003eÊï∞ÊçÆÂÄºÁ¶ªÊï£Ôºå‰∏çÂÖ∑Â§á‚ÄúÊï∞ÂÄºÂ§ßÂ∞è‚ÄùÈó¥ÁöÑÂèØÊØîÊÑè‰πâ„ÄÇ\u003c/li\u003e\n\u003cli\u003e‰æãÂ≠êÔºöÂõΩÁ±çÔºàÁæéÂõΩ/‰∏≠ÂõΩ/Âç∞Â∫¶Á≠âÔºâ„ÄÅÊÄßÂà´ÔºàÁî∑/Â•≥ÔºâÁ≠â„ÄÇ\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003eÈóÆÈ¢ò\u003c/strong\u003eÔºöËã•‰ªÖÁî®Êï¥Êï∞Ë°®Á§∫ÔºàÁæéÂõΩ=1, ‰∏≠ÂõΩ=2ÔºâÔºå‰ºöÂºïÂÖ•ÈîôËØØÁöÑÊï∞ÂÄºËøêÁÆóÂÖ≥Á≥ªÔºåÂ¶Ç ‚ÄúÁæéÂõΩ + ‰∏≠ÂõΩ = Âç∞Â∫¶‚Äù„ÄÇ\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003c/ol\u003e\n\u003ch2 id=\"‰∫åone-hotÁºñÁ†ÅÁöÑÂä®Êú∫‰∏éÊµÅÁ®ã\"\u003e‰∫å„ÄÅOne-HotÁºñÁ†ÅÁöÑÂä®Êú∫‰∏éÊµÅÁ®ã\u003c/h2\u003e\n\u003col\u003e\n\u003cli\u003e\n\u003cp\u003e\u003cstrong\u003e‰∏∫‰ªÄ‰πà‰ΩøÁî®One-Hot\u003c/strong\u003e\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eÈÄöËøáÂ∞ÜÁ±ªÂà´Êò†Â∞Ñ‰∏∫ÂêëÈáèÔºåÈÅøÂÖçÊï¥Êï∞ÁºñÁ†ÅÂºïÂÖ•ÁöÑ‰º™Êï∞ÂÄºÂÖ≥Á≥ª„ÄÇ\u003c/li\u003e\n\u003cli\u003eÂêåÊó∂‰øùÁïôÂêÑÁßçÂèØËÉΩÁ±ªÂà´ÁöÑ‰ø°ÊÅØÔºå‰∏î‰ªÖÂú®ÂØπÂ∫î‰ΩçÁΩÆ‰∏∫1ÔºåÂÖ∂‰ªñ‰ΩçÁΩÆ‰∏∫0„ÄÇ\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003e\u003cstrong\u003eÂª∫Á´ãÊò†Â∞ÑÔºö‰ªéÁ±ªÂà´Âà∞Á¥¢Âºï\u003c/strong\u003e\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e‰∏∫ÊØè‰∏™Á±ªÂà´ÂàÜÈÖç‰∏Ä‰∏™ÂîØ‰∏ÄÁ¥¢ÂºïÔºåÈÄöÂ∏∏‰ªé1ÂºÄÂßã„ÄÇ\u003c/li\u003e\n\u003cli\u003eÈ¢ÑÁïôÁ¥¢Âºï0Ë°®Á§∫‚ÄúÊú™Áü•‚ÄùÊàñ‚ÄúÁº∫Â§±‚ÄùÔºåÂØπÂ∫îÂÖ®0ÂêëÈáè„ÄÇ\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003e\u003cstrong\u003eËΩ¨Êç¢‰∏∫One-HotÂêëÈáè\u003c/strong\u003e\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eËã•Á±ªÂà´ÊÄªÊï∞‰∏∫197ÔºåÂàôÁî®197Áª¥ÂêëÈáèË°®Á§∫„ÄÇ\u003c/li\u003e\n\u003cli\u003e‰æãÂ≠êÔºöÁæéÂõΩ \u003ccode\u003e[1, 0, 0, 0, ‚Ä¶]\u003c/code\u003eÔºå ‰∏≠ÂõΩ \u003ccode\u003e[0, 1, 0, 0, ‚Ä¶]\u003c/code\u003e„ÄÇ\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003e\u003cstrong\u003eÁ§∫‰æãÔºöË°®Á§∫‰∏Ä‰∏™‰∫∫ÁöÑÁâπÂæÅ\u003c/strong\u003e\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eÁâπÂæÅÂåÖÂê´ÔºàÂπ¥ÈæÑ, ÊÄßÂà´, ÂõΩÁ±çÔºåÂÖ∂‰∏≠ÂõΩÁ±ç197ÁßçÔºâ\u003c/li\u003e\n\u003cli\u003eÁª¥Â∫¶ÊÄªÂíåÔºö1Áª¥_age + 1Áª¥_gender + 197Áª¥_nationality = 199Áª¥„ÄÇ\u003c/li\u003e\n\u003cli\u003e‰æãÂ¶Ç \u003ccode\u003e(28, Â•≥, ‰∏≠ÂõΩ)\u003c/code\u003e ‚Üí \u003ccode\u003e[28, 0, 0, 1, 0, ‚Ä¶, 0]\u003c/code\u003e„ÄÇ\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003c/ol\u003e\n\u003ch2 id=\"‰∏âÊñáÊú¨Êï∞ÊçÆÂ§ÑÁêÜÊµÅÁ®ã\"\u003e‰∏â„ÄÅÊñáÊú¨Êï∞ÊçÆÂ§ÑÁêÜÊµÅÁ®ã\u003c/h2\u003e\n\u003cp\u003eÊñáÊú¨Âú®Ëá™ÁÑ∂ËØ≠Ë®ÄÂ§ÑÁêÜÔºàNLPÔºâ‰∏≠‰Ωú‰∏∫Â∏∏ËßÅÁöÑÂéüÂßãËæìÂÖ•ÔºåÈúÄË¶ÅÊï∞ÂÄºÂåñÊâçËÉΩÈÄÅÂÖ•Ê®°Âûã„ÄÇ‰∏ÄËà¨Ê≠•È™§Â¶Ç‰∏ãÔºö\u003c/p\u003e\n\u003col\u003e\n\u003cli\u003e\n\u003cp\u003e\u003cstrong\u003eÂàÜËØç (Tokenization)\u003c/strong\u003e\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eÂ∞ÜÊñáÊú¨ÊãÜÂàÜ‰∏∫‰∏Ä‰∏™‰∏™ÂçïËØçÔºàTokenÔºâ„ÄÇ\u003c/li\u003e\n\u003cli\u003e‰æãÂ≠êÔºö\u003ccode\u003e\u0026quot;... to be or not to be...\u0026quot;\u003c/code\u003e ‚Üí \u003ccode\u003e[\u0026quot;...\u0026quot;, \u0026quot;to\u0026quot;, \u0026quot;be\u0026quot;, \u0026quot;or\u0026quot;, \u0026quot;not\u0026quot;, \u0026quot;to\u0026quot;, \u0026quot;be\u0026quot;, \u0026quot;...\u0026quot;]\u003c/code\u003e„ÄÇ\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003e\u003cstrong\u003eÁªüËÆ°ËØçÈ¢ë \u0026amp; ÊûÑÂª∫ËØçÂÖ∏\u003c/strong\u003e\u003c/p\u003e","title":""},{"content":"Text to Sequence ÊñáÊú¨Â§ÑÁêÜ\nStep1: Tokenization\nTokenization breaks a piece of text down into a list of tokens.\nHere, a token is a word. (A token can be a character in some applications.)\nTokenizationËÆ≤Á©∂ÂæàÂ§öÔºå‰æãÂ¶ÇÊòØÂê¶Â∫îËØ•ÊääÂ§ßÂÜôÊîπÊàêÂ∞èÂÜôÂë¢ÔºüËøõË°åtypo correctionÁ≠âÁ≠â\nStep2: Build Dictionary\nUse a dictionary (hash table) to count word frequencies.\nThe dictionary maps word to index.\nÂèØ‰ª•È¶ñÂÖàÁªüËÆ°ËØçÈ¢ëÂéªÊéâ‰ΩéÈ¢ëËØçÔºåÁÑ∂ÂêéËÆ©ÊØè‰∏™ËØçÂØπÂ∫î‰∏Ä‰∏™Ê≠£Êï¥Êï∞ÔºõËøôÊ†∑ÁöÑËØùÔºå‰∏ÄÂè•ËØùÂ∞±ÂèØ‰ª•Áî®‰∏Ä‰∏™Ê≠£Êï¥Êï∞ÂàóË°®Ë°®Á§∫ÔºåËøô‰∏™ÂàóË°®Â∞±Âè´sequenceÔºõÂ¶ÇÊûúÂøÖË¶ÅÂ∞±ËøòÂæóÂÅöone-hot encoding„ÄÇ\nÁªìÊûú\n‰ΩÜÊòØÈïøÂ∫¶‰∏çÁªü‰∏Ä\nStep4: ÂØπÈΩêsequence\nËß£ÂÜ≥ÊñπÊ°àÊòØËøôÊ†∑ÁöÑÔºöÂèØ‰ª•Âõ∫ÂÆöÈïøÂ∫¶‰∏∫wÔºåÂä†ÂÖ•‰∏Ä‰∏™Â∫èÂàóÈïøÂ∫¶Â§™ÈïøÔºåÂ∞±Á†çÊéâÂâçÈù¢ÁöÑËØçÔºåÂè™‰øùÁïôÊúÄÂêéw‰∏™ËØçÔºõÂ¶ÇÊûú‰∏Ä‰∏™Â∫èÂàóÂ§™Áü≠ÔºåÂ∞±ÂÅözero paddingÔºåÁî®0Â°´ÂÖÖ\nËøôÊ†∑‰∏ÄÊù•ÔºåÊâÄÊúâÁöÑÂ∫èÂàóÈïøÂ∫¶Â∞±Áªü‰∏Ä‰∫Ü\nÊñáÊú¨Â§ÑÁêÜÂÆåÊàê‰∫ÜÔºåÊé•‰∏ãÊù•ÊòØword embeddingÔºåÊääÂçïËØçË°®Á§∫‰∏∫‰∏Ä‰∏™‰ΩéÁª¥ÂêëÈáèÔºõ\nÁÑ∂ËÄåËøôÊ†∑ÂÅöÁöÑËØùÔºåÂ¶ÇÊûúÊòØ10000‰∏™ÂçïËØçÔºåÁª¥Â∫¶Â∞±ÊòØ10000Áª¥ÔºåÁª¥Â∫¶Â§™È´ò‰∫ÜÔºõÂõ†Ê≠§Ë¶ÅÂÅöword embeddingÔºõ\nÂÖ∑‰ΩìÂÅöÊ≥ïÂ∞±ÊòØÊääone-hotÂêëÈáèe_iÂíåÂèÇÊï∞Áü©ÈòµpÁõ∏‰πòÔºõÁü©ÈòµPËΩ¨ÁΩÆÁöÑÂ§ßÂ∞èÊòØd x vÔºõdÊòØËØçÂêëÈáèÁöÑÁª¥Â∫¶ÔºõvÊòØÂ≠óÂÖ∏ÈáåËØçÊ±áÁöÑÊï∞ÈáèÔºõÁªìÊûú‰∏∫x_iÔºõx_iÂ∞±ÊòØ‰∏Ä‰∏™ËØçÂêëÈáèÔºõÂ¶ÇÊûúone-hotÂêëÈáèÁöÑÁ¨¨‰∏âË°å‰∏∫1ÔºõÈÇ£‰πàx_iÂ∞±ÊòØPËΩ¨ÁΩÆÁü©ÈòµÁöÑÁ¨¨‰∏âÂàóÔºàÂÖ∂‰ΩôÂàóÈÉΩ‰∏∫0ÔºâÔºõÊâÄ‰ª•PËΩ¨ÁΩÆÊØè‰∏ÄÂàóÈÉΩÊòØ‰∏Ä‰∏™ËØçÂêëÈáèÔºõÊâÄ‰ª•Áü©ÈòµPÊú¨Ë∫´ÁöÑÊØè‰∏ÄË°åÂ∞±ÊòØ‰∏Ä‰∏™ËØçÂêëÈáèÔºõÂÖ∂Ë°åÊï∞‰∏∫vÔºõÂç≥vocabularyÔºåËØçÊ±áÈáèÔºõÊØè‰∏ÄË°åÂØπÂ∫î‰∏Ä‰∏™ÂçïËØçÔºõÁü©ÈòµÁöÑÂàóÊï∞‰∏∫dÔºõdÊòØÁî®Êà∑ÂÜ≥ÂÆöÁöÑÔºõdÁöÑÂ§ßÂ∞è‰ºöÂÜ≥ÂÆöÊú∫Âô®Â≠¶‰π†Ê®°ÂûãÁöÑË°®Áé∞ÔºõÂ∫îËØ•Áî®xxxÊù•ÈÄâÊã©‰∏Ä‰∏™ÊØîËæÉÂ•ΩÁöÑdÔºõ\nÊàë‰ª¨ÁöÑ‰ªªÂä°ÊòØÁúãËØÑËÆ∫ÊòØÊ≠£Èù¢ÁöÑËøòÊòØË¥üÈù¢ÁöÑÔºõÂèÇÊï∞Áü©ÈòµÊòØ‰ªéËÆ≠ÁªÉÊï∞ÊçÆ‰∏≠Â≠¶‰π†Âá∫Êù•ÁöÑÔºåÊâÄ‰ª•Â≠¶Âá∫Êù•ÁöÑËØçÂêëÈáèÊòØÂ∏¶ÊúâÊÑüÊÉÖËâ≤ÂΩ©ÁöÑÔºõÂÅáËÆæËøô‰∫õËØçÂêëÈáèÈÉΩÊòØ‰∫åÁª¥ÁöÑÔºåÂàôÂèØ‰ª•Âú®Âπ≥Èù¢ÂùêÊ†áÁ≥ª‰∏≠Ê†áÂá∫‰∏ãÈù¢ËØçÂêëÈáè\nkerasÊèê‰æõembeddingÂ±ÇÔºõÁî®Êà∑ÂèØ‰ª•ÊåáÂÆövocabularyÂ§ßÂ∞èÂíådÁöÑÂ§ßÂ∞èÔºõ‰ª•ÂèäÊØè‰∏Ä‰∏™sequenceÁöÑÈïøÂ∫¶ÔºõdÊòØÊ†πÊçÆÁÆóÊ≥ïÈÄâÂá∫Êù•ÁöÑ Âà∞Ëøô‰∏ÄÊ≠•ÔºåÊàë‰ª¨Â∑≤ÁªèÂÆåÊàê‰∫ÜÊñáÊú¨Â§ÑÁêÜÂíåword embedding„ÄÇÊé•‰∏ãÊù•Â∞±ÊòØÁî®Logistic Regression for Binary ClassificationÂÅö‰∫åÂàÜÁ±ªÔºõ\n","permalink":"http://localhost:1313/posts/nlp-2/","summary":"\u003ch3 id=\"text-to-sequence\"\u003eText to Sequence\u003c/h3\u003e\n\u003cp\u003eÊñáÊú¨Â§ÑÁêÜ\u003c/p\u003e\n\u003cp\u003eStep1: Tokenization\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\n\u003cp\u003eTokenization breaks a piece of text down into a list of tokens.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003eHere, a token is a word. (A token can be a character in some applications.)\u003c/p\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003eTokenizationËÆ≤Á©∂ÂæàÂ§öÔºå‰æãÂ¶ÇÊòØÂê¶Â∫îËØ•ÊääÂ§ßÂÜôÊîπÊàêÂ∞èÂÜôÂë¢ÔºüËøõË°åtypo correctionÁ≠âÁ≠â\u003c/p\u003e\n\u003cp\u003e\u003cimg alt=\"image-20250322150322238\" loading=\"lazy\" src=\"./NLP-2.assets/image-20250322150322238.png\"\u003e\u003c/p\u003e\n\u003cp\u003eStep2: Build Dictionary\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\n\u003cp\u003eUse a dictionary (hash table) to count word frequencies.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003eThe dictionary maps word to index.\u003c/p\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003eÂèØ‰ª•È¶ñÂÖàÁªüËÆ°ËØçÈ¢ëÂéªÊéâ‰ΩéÈ¢ëËØçÔºåÁÑ∂ÂêéËÆ©ÊØè‰∏™ËØçÂØπÂ∫î‰∏Ä‰∏™Ê≠£Êï¥Êï∞ÔºõËøôÊ†∑ÁöÑËØùÔºå‰∏ÄÂè•ËØùÂ∞±ÂèØ‰ª•Áî®‰∏Ä‰∏™Ê≠£Êï¥Êï∞ÂàóË°®Ë°®Á§∫ÔºåËøô‰∏™ÂàóË°®Â∞±Âè´sequenceÔºõÂ¶ÇÊûúÂøÖË¶ÅÂ∞±ËøòÂæóÂÅöone-hot encoding„ÄÇ\u003cimg alt=\"image-20250322150620890\" loading=\"lazy\" src=\"./NLP-2.assets/image-20250322150620890.png\"\u003e\u003c/p\u003e\n\u003cp\u003eÁªìÊûú\u003c/p\u003e\n\u003cp\u003e\u003cimg alt=\"image-20250322150754528\" loading=\"lazy\" src=\"./NLP-2.assets/image-20250322150754528.png\"\u003e\u003c/p\u003e\n\u003cp\u003e‰ΩÜÊòØÈïøÂ∫¶‰∏çÁªü‰∏Ä\u003c/p\u003e\n\u003cp\u003eStep4: ÂØπÈΩêsequence\u003c/p\u003e\n\u003cp\u003e\u003cimg alt=\"image-20250322150854986\" loading=\"lazy\" src=\"./NLP-2.assets/image-20250322150854986.png\"\u003e\u003c/p\u003e\n\u003cp\u003eËß£ÂÜ≥ÊñπÊ°àÊòØËøôÊ†∑ÁöÑÔºöÂèØ‰ª•Âõ∫ÂÆöÈïøÂ∫¶‰∏∫wÔºåÂä†ÂÖ•‰∏Ä‰∏™Â∫èÂàóÈïøÂ∫¶Â§™ÈïøÔºåÂ∞±Á†çÊéâÂâçÈù¢ÁöÑËØçÔºåÂè™‰øùÁïôÊúÄÂêéw‰∏™ËØçÔºõÂ¶ÇÊûú‰∏Ä‰∏™Â∫èÂàóÂ§™Áü≠ÔºåÂ∞±ÂÅözero paddingÔºåÁî®0Â°´ÂÖÖ\u003c/p\u003e\n\u003cp\u003e\u003cimg alt=\"image-20250322151030119\" loading=\"lazy\" src=\"./NLP-2.assets/image-20250322151030119.png\"\u003e\u003c/p\u003e\n\u003cp\u003eËøôÊ†∑‰∏ÄÊù•ÔºåÊâÄÊúâÁöÑÂ∫èÂàóÈïøÂ∫¶Â∞±Áªü‰∏Ä‰∫Ü\u003c/p\u003e\n\u003cp\u003e\u003cimg alt=\"image-20250322151117125\" loading=\"lazy\" src=\"./NLP-2.assets/image-20250322151117125.png\"\u003e\u003c/p\u003e\n\u003cp\u003eÊñáÊú¨Â§ÑÁêÜÂÆåÊàê‰∫ÜÔºåÊé•‰∏ãÊù•ÊòØword embeddingÔºåÊääÂçïËØçË°®Á§∫‰∏∫‰∏Ä‰∏™‰ΩéÁª¥ÂêëÈáèÔºõ\u003c/p\u003e\n\u003cp\u003e\u003cimg alt=\"image-20250322151252837\" loading=\"lazy\" src=\"./NLP-2.assets/image-20250322151252837.png\"\u003e\u003c/p\u003e","title":""},{"content":"üëã About me Hello! I\u0026rsquo;m Xu Zongsi, a passionate technology enthusiast currently pursuing my Master of Science in ECIC at The University of Hong Kong. With a solid background in Software Engineering from the Beijing Institute of Technology, I specialize in artificial intelligence areas like machine learning, deep learning, natural language processing, computer vision, and reinforcement learning.\nInspired by OpenAI\u0026rsquo;s five-step plan towards superintelligence, I am excited about AGI and have developed a keen interest in LLM agents, MLLM, and knowledge graphs. I see great potential in these fields and aspire to contribute to innovative solutions.\nüìö Education üá≠üá∞ The University of Hong Kong 09/2024 - Expected 11/2025 School of Computing and Data Science Master of Science in Electronic Commerce \u0026amp; Internet Computing Relevant Courses: Machine learning for business and e-commerce, Knowledge graphs, Financial fraud analytics, Internet infrastructure technologies, Website engineering, Blockchain and cryptocurrency, etc. üá®üá≥ Beijing Institute of Technology 09/2020 - 06/2024 School of Computer Science \u0026amp; Technology Bachelor of Engineering in Software Engineering, last two years GPA: 3.7/4 Relevant Courses: Reinforcement Learning, Deep Learning and Computer Vision, Artificial Intelligence and Robot Ethics, Almost Human: Mind, Brain and Artificial Intelligence, Mathematical Analysis for Engineering, Linear Algebra, Probability and Mathematical Statistics, etc. Skills: Python, Java, common data structures, design patterns, machine learning basics and algorithms, Linux, PyTorch, and some development tools (git, conda, etc.). üèÜ Awards \u0026amp; Honors Beijing Institute of Technology Undergraduate Scholarship (Top 20% of Grade) 06/2023 3rd Prize of China International \u0026#34;Internet \u0026#43;\u0026#34; College Student\u0026#39;s Innovation Competition 08/2022 Bronze Prize of \u0026#34;Challenge Cup\u0026#34; Capital University Entrepreneurship Competition 05/2022 üíº Project Experience üîç Online Transaction Fraud Detection 09/2024 ‚Äì 01/2025 Independent project, supervised by Dr. Vivien Chan Focused on addressing financial fraud in e-commerce to enhance the accuracy of transaction anomaly detection, while independently managing the entire case study that included data preprocessing, feature engineering, model building, evaluation, and results analysis. Effectively resolved class imbalance issues using SMOTE and ROSE techniques. Built various models including Logistic Regression, Random Forest, XGBoost, and LightGBM, ultimately selecting the LightGBM model to achieve a recall rate of 95.45% and an AUC of 99.84%. Wrote efficient and maintainable code, enhancing model training and data processing efficiency through parallel computing and logging. ü§ñ Multi-Model Intelligent Text Keyword Extraction System 08/2023 ‚Äì 09/2023 Group project, supervised by Associate Prof. Xiaolin Zhao Designed and implemented an intelligent text summary system that automatically extracts keywords from article titles and abstracts, enhancing the understanding and summarization of text information. Participated in the planning of the technical route and built a hybrid model combining extractive and generative approaches, utilizing advanced natural language processing techniques including KeyBERT, Sentence Transformer, BERT, and T5 models. Responsible for data preprocessing and tokenization, as well as the end-to-end implementation and training of the T5 model, optimizing the model architecture and hyperparameters, achieving satisfactory results after only 3 epochs of training. Model evaluation results showed that the Rouge-1, Rouge-2, and Rouge-L metrics reached 0.6345, 0.5038, and 0.5282, respectively, in the third epoch, validating the model\u0026rsquo;s effectiveness in the summarization task. üéì Cambridge University Machine Learning Summer Project 07/2023 ‚Äì 08/2023 Group project, supervised by Prof. Pietro Li√≤ Participated in the Cambridge University deep learning summer project, focusing on deep reinforcement learning; explored multi-agent learning algorithms across different environments. Reproduced the Multi-Agent Deep Deterministic Policy Gradient (MADDPG) algorithm in the Simple Adversary environment and studied the effect of agent numbers on convergence speed and stability, finding optimal stability at 21 agents. Designed and implemented comparative experiments inspired by the Rainbow algorithm, assessing target network strategies versus the Double Deep Q-Network (Double DQN). The results demonstrated that Double DQN significantly enhanced convergence speed, optimizing the overall learning process. Co-authored a group project paper on agent numbers and strategies effectiveness in multi-agent systems, achieving a score of 71% in the summer program (the highest in my group) and a \u0026ldquo;First Class\u0026rdquo; classification in the UK grading system. üëÅÔ∏è Deep Learning and Computer Vision Semester Project 09/2022 ‚Äì 12/2022 Independent project, supervised by Associate Prof. Guangyu Gao Designed and implemented a waste classifier using the ResNet model to improve classification accuracy and reduce resource waste. The project also enhanced understanding of transfer learning techniques with ResNet. Collected a dataset of 16 waste categories and preprocessed the images for uniformity and standardization, incorporating data augmentation techniques to enhance the dataset. Conducted experiments using ResNet34 and ResNet50 models through transfer learning, accelerating network convergence by leveraging pretrained weights. During training, techniques such as Batch Normalization and Dropout were applied to mitigate the risk of overfitting. The final model achieved an accuracy of 90% on the training set, while the performance on the test set was 61%, indicating a significant overfitting phenomenon during the training process. üéì Internship ‚öõÔ∏è Beijing Academy of Quantum Information Science 08/2023 ‚Äì 01/2024 Research Intern at Quantum Computation Department Proposed a quantum convolution kernel design based on variational quantum circuits and developed a universal quantum convolution layer, successfully integrating it into classical CNN architectures such as VGG, GoogLeNet, and ResNet. Developed and evaluated various hybrid models, including a simple model named HQCCNN-2, which achieved 84.45% accuracy on the FashionMNIST dataset, surpassing the traditional CNN\u0026rsquo;s 80.72%. This demonstrates the effectiveness of the quantum convolution layer in improving model performance. Tested on a real quantum computer further validated the effectiveness of the hybrid model, demonstrating the viable integration of quantum computing with deep learning, and highlighting the potential for leveraging quantum properties to enhance model performance. üèÖ Competition Experience ü•â China International \u0026#34;Internet \u0026#43;\u0026#34; College Students\u0026#39; Innovation Competition 08/2022 üõ°Ô∏è Zhongke Ushield: Deep Learning-based Face Privacy Protection Authentication System Responsible for constructing a localized facial feature extraction engine based on MobileFaceNet, ensuring feature extraction is completed on end devices (such as mobile phones and cameras), guaranteeing that raw data does not leave the domain and is not stored, thus enhancing user privacy protection while improving recognition efficiency. ü•â \u0026#34;Challenge Cup\u0026#34; Capital University Entrepreneurship Competition 05/2022 üå≥ Smart Orchard Responsible for the development of the fruit detection, ripeness prediction, and pest identification system, using deep convolutional neural network (CNN) technology for intelligent monitoring of crop growth conditions. Applied advanced object detection algorithms such as Faster R-CNN and YOLO to achieve high precision in apple detection and ripeness assessment, with an accuracy rate exceeding 90%, significantly enhancing the intelligence level of orchard management. Built and trained a dedicated dataset containing various pest samples, optimizing pest detection accuracy through data preprocessing (such as image normalization and resizing) and data augmentation techniques (like rotation, flipping, and noise addition), enabling the real-time monitoring system to accurately identify over 80% of pests, providing effective scientific maintenance recommendations to help farmers reduce crop losses. üìã Extracurricular Activities Vice President, Cyber Security Club, Beijing Institute of Technology 09/2021-09/2022 Backbone, Media Center of the Student Union of Beijing Institute of Technology 10/2020-06/2021 üì´ Contact üìß Email: zongsi.xu@outlook.com üëî LinkedIn: Zongsi (Tristan) Xu üíª GitHub: BaizeXS üìç Location: Hong Kong SAR, China ","permalink":"http://localhost:1313/resume/","summary":"Personal resume of Zongsi (Tristan) Xu","title":"Zongsi (Tristan) Xu"},{"content":"‰∏Ä„ÄÅÊï∞ÂÄºÁâπÂæÅ‰∏éÁ±ªÂà´ÁâπÂæÅ Êï∞ÂÄºÁâπÂæÅ (Numeric Features) ÂÖ∑ÊúâÂèØÂä†ÂáèÁöÑÊÑè‰πâÔºå‰∏îÂ≠òÂú®Â§ßÂ∞èÈ°∫Â∫è„ÄÇ ‰æãÂ≠êÔºöÂπ¥ÈæÑ„ÄÅÊ∏©Â∫¶Á≠â„ÄÇÂèØ‰ª•Áõ¥Êé•‰øùÁïôÂÖ∂Êï¥Êï∞ÊàñÊµÆÁÇπÊï∞ÂΩ¢Âºè‰æõÊ®°Âûã‰ΩøÁî®„ÄÇ Á±ªÂà´ÁâπÂæÅ (Categorical Features) Êï∞ÊçÆÂÄºÁ¶ªÊï£Ôºå‰∏çÂÖ∑Â§á‚ÄúÊï∞ÂÄºÂ§ßÂ∞è‚ÄùÈó¥ÁöÑÂèØÊØîÊÑè‰πâ„ÄÇ ‰æãÂ≠êÔºöÂõΩÁ±çÔºàÁæéÂõΩ/‰∏≠ÂõΩ/Âç∞Â∫¶Á≠âÔºâ„ÄÅÊÄßÂà´ÔºàÁî∑/Â•≥ÔºâÁ≠â„ÄÇ ÈóÆÈ¢òÔºöËã•‰ªÖÁî®Êï¥Êï∞Ë°®Á§∫ÔºàÁæéÂõΩ=1, ‰∏≠ÂõΩ=2ÔºâÔºå‰ºöÂºïÂÖ•ÈîôËØØÁöÑÊï∞ÂÄºËøêÁÆóÂÖ≥Á≥ªÔºåÂ¶Ç ‚ÄúÁæéÂõΩ + ‰∏≠ÂõΩ = Âç∞Â∫¶‚Äù„ÄÇ ‰∫å„ÄÅOne-HotÁºñÁ†ÅÁöÑÂä®Êú∫‰∏éÊµÅÁ®ã ‰∏∫‰ªÄ‰πà‰ΩøÁî®One-Hot\nÈÄöËøáÂ∞ÜÁ±ªÂà´Êò†Â∞Ñ‰∏∫ÂêëÈáèÔºåÈÅøÂÖçÊï¥Êï∞ÁºñÁ†ÅÂºïÂÖ•ÁöÑ‰º™Êï∞ÂÄºÂÖ≥Á≥ª„ÄÇ ÂêåÊó∂‰øùÁïôÂêÑÁßçÂèØËÉΩÁ±ªÂà´ÁöÑ‰ø°ÊÅØÔºå‰∏î‰ªÖÂú®ÂØπÂ∫î‰ΩçÁΩÆ‰∏∫1ÔºåÂÖ∂‰ªñ‰ΩçÁΩÆ‰∏∫0„ÄÇ Âª∫Á´ãÊò†Â∞ÑÔºö‰ªéÁ±ªÂà´Âà∞Á¥¢Âºï\n‰∏∫ÊØè‰∏™Á±ªÂà´ÂàÜÈÖç‰∏Ä‰∏™ÂîØ‰∏ÄÁ¥¢ÂºïÔºåÈÄöÂ∏∏‰ªé1ÂºÄÂßã„ÄÇ È¢ÑÁïôÁ¥¢Âºï0Ë°®Á§∫‚ÄúÊú™Áü•‚ÄùÊàñ‚ÄúÁº∫Â§±‚ÄùÔºåÂØπÂ∫îÂÖ®0ÂêëÈáè„ÄÇ ËΩ¨Êç¢‰∏∫One-HotÂêëÈáè\nËã•Á±ªÂà´ÊÄªÊï∞‰∏∫197ÔºåÂàôÁî®197Áª¥ÂêëÈáèË°®Á§∫„ÄÇ ‰æãÂ≠êÔºöÁæéÂõΩ [1, 0, 0, 0, ‚Ä¶]Ôºå ‰∏≠ÂõΩ [0, 1, 0, 0, ‚Ä¶]„ÄÇ Á§∫‰æãÔºöË°®Á§∫‰∏Ä‰∏™‰∫∫ÁöÑÁâπÂæÅ\nÁâπÂæÅÂåÖÂê´ÔºàÂπ¥ÈæÑ, ÊÄßÂà´, ÂõΩÁ±çÔºåÂÖ∂‰∏≠ÂõΩÁ±ç197ÁßçÔºâ Áª¥Â∫¶ÊÄªÂíåÔºö1Áª¥_age + 1Áª¥_gender + 197Áª¥_nationality = 199Áª¥„ÄÇ ‰æãÂ¶Ç (28, Â•≥, ‰∏≠ÂõΩ) ‚Üí [28, 0, 0, 1, 0, ‚Ä¶, 0]„ÄÇ ‰∏â„ÄÅÊñáÊú¨Êï∞ÊçÆÂ§ÑÁêÜÊµÅÁ®ã ÊñáÊú¨Âú®Ëá™ÁÑ∂ËØ≠Ë®ÄÂ§ÑÁêÜÔºàNLPÔºâ‰∏≠‰Ωú‰∏∫Â∏∏ËßÅÁöÑÂéüÂßãËæìÂÖ•ÔºåÈúÄË¶ÅÊï∞ÂÄºÂåñÊâçËÉΩÈÄÅÂÖ•Ê®°Âûã„ÄÇ‰∏ÄËà¨Ê≠•È™§Â¶Ç‰∏ãÔºö\nÂàÜËØç (Tokenization)\nÂ∞ÜÊñáÊú¨ÊãÜÂàÜ‰∏∫‰∏Ä‰∏™‰∏™ÂçïËØçÔºàTokenÔºâ„ÄÇ ‰æãÂ≠êÔºö\u0026quot;... to be or not to be...\u0026quot; ‚Üí [\u0026quot;...\u0026quot;, \u0026quot;to\u0026quot;, \u0026quot;be\u0026quot;, \u0026quot;or\u0026quot;, \u0026quot;not\u0026quot;, \u0026quot;to\u0026quot;, \u0026quot;be\u0026quot;, \u0026quot;...\u0026quot;]„ÄÇ ÁªüËÆ°ËØçÈ¢ë \u0026amp; ÊûÑÂª∫ËØçÂÖ∏\nËØçÈ¢ëÁªüËÆ° Áî®ÂìàÂ∏åË°®/Â≠óÂÖ∏ËÆ∞ÂΩïÊØè‰∏™ÂçïËØçÂá∫Áé∞Ê¨°Êï∞„ÄÇ ÈÅçÂéÜÊñáÊú¨Êó∂ÔºåËã•ÂçïËØçÂ∞öÊú™ÂÖ•Ë°®ÔºåÂàôÊñ∞Âª∫ËÆ∞ÂΩïÔºõËã•Â∑≤Â≠òÂú®ÔºåÂàôËÆ°Êï∞+1„ÄÇ ÊéíÂ∫è‰∏éÁ¥¢Âºï ÊåâËØçÈ¢ëÈôçÂ∫èÊéíÂ∫èÔºåËØçÈ¢ëÊúÄÈ´òÁöÑÂçïËØçÊéíÂú®ÂâçÈù¢„ÄÇ Á¥¢Âºï‰ªé1ÂºÄÂßãÔºå0ÁïôÁªô‚ÄúÊú™Áü•‚Äù„ÄÇ ËØçÂÖ∏ËßÑÊ®°ÔºàvocabularyÔºâÂèØËßÜÈúÄÊ±ÇÊà™Êñ≠Ôºà‰æãÂ¶ÇÂè™‰øùÁïôTop 10kÔºâ„ÄÇ ‰∏∫‰ªÄ‰πàÁßªÈô§‰ΩéÈ¢ëËØç ‰ΩéÈ¢ëËØçÂèØËÉΩÊòØÊãºÂÜôÈîôËØØ„ÄÅÁΩïËßÅ‰∫∫ÂêçÁ≠âÔºåÂØπÊ®°ÂûãÂ∏ÆÂä©ÊúâÈôê„ÄÇ ÂáèÂ∞ëËØçÂÖ∏ËßÑÊ®°ÂèØÈôç‰ΩéËøêÁÆóÂºÄÈîÄ„ÄÅÂä†Âø´Ê®°ÂûãËÆ≠ÁªÉ‰∏éÊé®ÁêÜÈÄüÂ∫¶„ÄÇ Áã¨ÁÉ≠ÁºñÁ†Å (One-Hot Encoding)\nÂ∞ÜÊØè‰∏™ÂçïËØçÊò†Â∞Ñ‰∏∫ËØçÂÖ∏‰∏≠ÁöÑÁ¥¢ÂºïÂêéÔºàÂ¶Ç [2, 4, 1, 8, ‚Ä¶]ÔºâÔºåÂèØËøõ‰∏ÄÊ≠•ËΩ¨Êç¢ÊàêOne-HotÂêëÈáè„ÄÇ One-HotÁª¥Â∫¶ÂèñÂÜ≥‰∫é‰øùÁïô‰∏ãÊù•ÁöÑËØçÂÖ∏Â§ßÂ∞èÔºà‰æãÂ¶Ç1‰∏áÔºâ„ÄÇ Êú™Êî∂ÂΩïÂçïËØçÂèØËÉΩÁõ¥Êé•ÂøΩÁï•ÔºåÊàñÁªü‰∏ÄÁî®Á¥¢Âºï0‰ª£Êõø„ÄÇ Âõõ„ÄÅÊ†∏ÂøÉÊî∂Ëé∑‰∏éÂ∫îÁî® Á±ªÂà´ÁâπÂæÅÂøÖÈúÄÊï∞ÂÄºÂåñÔºö\n‰ΩøÁî®Êï¥Êï∞1,2,3‚Ä¶‰ªÖË°®Á§∫Á±ªÂà´‚ÄúÊ†áËØÜ‚ÄùÔºåÂπ∂‰∏ç‰ª£Ë°®ÂÆÉ‰ª¨ÂèØËøõË°åÊï∞ÂÄºËøêÁÆó„ÄÇ Âõ†Ê≠§ÈúÄË¶ÅOne-HotÁ≠âÁºñÁ†ÅÊñπÂºèÔºåÈÅøÂÖçÊï∞ÂÄºËØØËß£„ÄÇ ÊñáÊú¨Êï∞ÊçÆÈ¢ÑÂ§ÑÁêÜÔºö\nÂàÜËØç„ÄÅËØçÈ¢ëÁªüËÆ°„ÄÅÊûÑÂª∫ËØçÂÖ∏„ÄÅÁ¥¢ÂºïÂåñ„ÄÅOne-HotÊàñÂÖ∂‰ªñÊñπÂºèÔºàÂ¶ÇËØçÂµåÂÖ•ÔºâÊòØÂ∏∏ËßÅÊµÅÁ®ã„ÄÇ Ê≠£Á°ÆÁöÑÊñáÊú¨È¢ÑÂ§ÑÁêÜÂèØÊòæËëóÂΩ±ÂìçÊ®°ÂûãÊÄßËÉΩÂíåÊïàÁéá„ÄÇ ‰øùÁïôÊú™Áü•Á¥¢ÂºïÔºö\n‰øùËØÅÂØπÁº∫Â§±Êï∞ÊçÆÊàñÂ≠óÂÖ∏Â§ñÊñ∞ËØçËÉΩÊúâÂü∫Êú¨ÁöÑË°®Á§∫ÔºåÊèêÂçáÊ®°ÂûãÂÆπÈîôÊÄß„ÄÇ ÂÆûÈôÖ‰ΩøÁî®Ôºö\nÂØπ‰∫éÂ∞èËßÑÊ®°Á±ªÂà´ÂèØÁõ¥Êé•One-HotÁºñÁ†ÅÔºõÂØπ‰∫éËØçÂÖ∏ÂæàÂ§ßÁöÑÂú∫ÊôØÔºåÈÄöÂ∏∏‰ºöËøõ‰∏ÄÊ≠•ËÄÉËôëËØçÂµåÂÖ•ÔºàWord EmbeddingÔºâÊàñÈ¢ÑËÆ≠ÁªÉËØ≠Ë®ÄÊ®°Âûã„ÄÇ ","permalink":"http://localhost:1313/posts/nlp-1/","summary":"\u003ch2 id=\"‰∏ÄÊï∞ÂÄºÁâπÂæÅ‰∏éÁ±ªÂà´ÁâπÂæÅ\"\u003e‰∏Ä„ÄÅÊï∞ÂÄºÁâπÂæÅ‰∏éÁ±ªÂà´ÁâπÂæÅ\u003c/h2\u003e\n\u003col\u003e\n\u003cli\u003e\u003cstrong\u003eÊï∞ÂÄºÁâπÂæÅ (Numeric Features)\u003c/strong\u003e\n\u003cul\u003e\n\u003cli\u003eÂÖ∑ÊúâÂèØÂä†ÂáèÁöÑÊÑè‰πâÔºå‰∏îÂ≠òÂú®Â§ßÂ∞èÈ°∫Â∫è„ÄÇ\u003c/li\u003e\n\u003cli\u003e‰æãÂ≠êÔºöÂπ¥ÈæÑ„ÄÅÊ∏©Â∫¶Á≠â„ÄÇÂèØ‰ª•Áõ¥Êé•‰øùÁïôÂÖ∂Êï¥Êï∞ÊàñÊµÆÁÇπÊï∞ÂΩ¢Âºè‰æõÊ®°Âûã‰ΩøÁî®„ÄÇ\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003eÁ±ªÂà´ÁâπÂæÅ (Categorical Features)\u003c/strong\u003e\n\u003cul\u003e\n\u003cli\u003eÊï∞ÊçÆÂÄºÁ¶ªÊï£Ôºå‰∏çÂÖ∑Â§á‚ÄúÊï∞ÂÄºÂ§ßÂ∞è‚ÄùÈó¥ÁöÑÂèØÊØîÊÑè‰πâ„ÄÇ\u003c/li\u003e\n\u003cli\u003e‰æãÂ≠êÔºöÂõΩÁ±çÔºàÁæéÂõΩ/‰∏≠ÂõΩ/Âç∞Â∫¶Á≠âÔºâ„ÄÅÊÄßÂà´ÔºàÁî∑/Â•≥ÔºâÁ≠â„ÄÇ\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003eÈóÆÈ¢ò\u003c/strong\u003eÔºöËã•‰ªÖÁî®Êï¥Êï∞Ë°®Á§∫ÔºàÁæéÂõΩ=1, ‰∏≠ÂõΩ=2ÔºâÔºå‰ºöÂºïÂÖ•ÈîôËØØÁöÑÊï∞ÂÄºËøêÁÆóÂÖ≥Á≥ªÔºåÂ¶Ç ‚ÄúÁæéÂõΩ + ‰∏≠ÂõΩ = Âç∞Â∫¶‚Äù„ÄÇ\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003c/ol\u003e\n\u003ch2 id=\"‰∫åone-hotÁºñÁ†ÅÁöÑÂä®Êú∫‰∏éÊµÅÁ®ã\"\u003e‰∫å„ÄÅOne-HotÁºñÁ†ÅÁöÑÂä®Êú∫‰∏éÊµÅÁ®ã\u003c/h2\u003e\n\u003col\u003e\n\u003cli\u003e\n\u003cp\u003e\u003cstrong\u003e‰∏∫‰ªÄ‰πà‰ΩøÁî®One-Hot\u003c/strong\u003e\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eÈÄöËøáÂ∞ÜÁ±ªÂà´Êò†Â∞Ñ‰∏∫ÂêëÈáèÔºåÈÅøÂÖçÊï¥Êï∞ÁºñÁ†ÅÂºïÂÖ•ÁöÑ‰º™Êï∞ÂÄºÂÖ≥Á≥ª„ÄÇ\u003c/li\u003e\n\u003cli\u003eÂêåÊó∂‰øùÁïôÂêÑÁßçÂèØËÉΩÁ±ªÂà´ÁöÑ‰ø°ÊÅØÔºå‰∏î‰ªÖÂú®ÂØπÂ∫î‰ΩçÁΩÆ‰∏∫1ÔºåÂÖ∂‰ªñ‰ΩçÁΩÆ‰∏∫0„ÄÇ\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003e\u003cstrong\u003eÂª∫Á´ãÊò†Â∞ÑÔºö‰ªéÁ±ªÂà´Âà∞Á¥¢Âºï\u003c/strong\u003e\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e‰∏∫ÊØè‰∏™Á±ªÂà´ÂàÜÈÖç‰∏Ä‰∏™ÂîØ‰∏ÄÁ¥¢ÂºïÔºåÈÄöÂ∏∏‰ªé1ÂºÄÂßã„ÄÇ\u003c/li\u003e\n\u003cli\u003eÈ¢ÑÁïôÁ¥¢Âºï0Ë°®Á§∫‚ÄúÊú™Áü•‚ÄùÊàñ‚ÄúÁº∫Â§±‚ÄùÔºåÂØπÂ∫îÂÖ®0ÂêëÈáè„ÄÇ\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003e\u003cstrong\u003eËΩ¨Êç¢‰∏∫One-HotÂêëÈáè\u003c/strong\u003e\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eËã•Á±ªÂà´ÊÄªÊï∞‰∏∫197ÔºåÂàôÁî®197Áª¥ÂêëÈáèË°®Á§∫„ÄÇ\u003c/li\u003e\n\u003cli\u003e‰æãÂ≠êÔºöÁæéÂõΩ \u003ccode\u003e[1, 0, 0, 0, ‚Ä¶]\u003c/code\u003eÔºå ‰∏≠ÂõΩ \u003ccode\u003e[0, 1, 0, 0, ‚Ä¶]\u003c/code\u003e„ÄÇ\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003e\u003cstrong\u003eÁ§∫‰æãÔºöË°®Á§∫‰∏Ä‰∏™‰∫∫ÁöÑÁâπÂæÅ\u003c/strong\u003e\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eÁâπÂæÅÂåÖÂê´ÔºàÂπ¥ÈæÑ, ÊÄßÂà´, ÂõΩÁ±çÔºåÂÖ∂‰∏≠ÂõΩÁ±ç197ÁßçÔºâ\u003c/li\u003e\n\u003cli\u003eÁª¥Â∫¶ÊÄªÂíåÔºö1Áª¥_age + 1Áª¥_gender + 197Áª¥_nationality = 199Áª¥„ÄÇ\u003c/li\u003e\n\u003cli\u003e‰æãÂ¶Ç \u003ccode\u003e(28, Â•≥, ‰∏≠ÂõΩ)\u003c/code\u003e ‚Üí \u003ccode\u003e[28, 0, 0, 1, 0, ‚Ä¶, 0]\u003c/code\u003e„ÄÇ\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003c/ol\u003e\n\u003ch2 id=\"‰∏âÊñáÊú¨Êï∞ÊçÆÂ§ÑÁêÜÊµÅÁ®ã\"\u003e‰∏â„ÄÅÊñáÊú¨Êï∞ÊçÆÂ§ÑÁêÜÊµÅÁ®ã\u003c/h2\u003e\n\u003cp\u003eÊñáÊú¨Âú®Ëá™ÁÑ∂ËØ≠Ë®ÄÂ§ÑÁêÜÔºàNLPÔºâ‰∏≠‰Ωú‰∏∫Â∏∏ËßÅÁöÑÂéüÂßãËæìÂÖ•ÔºåÈúÄË¶ÅÊï∞ÂÄºÂåñÊâçËÉΩÈÄÅÂÖ•Ê®°Âûã„ÄÇ‰∏ÄËà¨Ê≠•È™§Â¶Ç‰∏ãÔºö\u003c/p\u003e\n\u003col\u003e\n\u003cli\u003e\n\u003cp\u003e\u003cstrong\u003eÂàÜËØç (Tokenization)\u003c/strong\u003e\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eÂ∞ÜÊñáÊú¨ÊãÜÂàÜ‰∏∫‰∏Ä‰∏™‰∏™ÂçïËØçÔºàTokenÔºâ„ÄÇ\u003c/li\u003e\n\u003cli\u003e‰æãÂ≠êÔºö\u003ccode\u003e\u0026quot;... to be or not to be...\u0026quot;\u003c/code\u003e ‚Üí \u003ccode\u003e[\u0026quot;...\u0026quot;, \u0026quot;to\u0026quot;, \u0026quot;be\u0026quot;, \u0026quot;or\u0026quot;, \u0026quot;not\u0026quot;, \u0026quot;to\u0026quot;, \u0026quot;be\u0026quot;, \u0026quot;...\u0026quot;]\u003c/code\u003e„ÄÇ\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003e\u003cstrong\u003eÁªüËÆ°ËØçÈ¢ë \u0026amp; ÊûÑÂª∫ËØçÂÖ∏\u003c/strong\u003e\u003c/p\u003e","title":""},{"content":"Text to Sequence ÊñáÊú¨Â§ÑÁêÜ\nStep1: Tokenization\nTokenization breaks a piece of text down into a list of tokens.\nHere, a token is a word. (A token can be a character in some applications.)\nTokenizationËÆ≤Á©∂ÂæàÂ§öÔºå‰æãÂ¶ÇÊòØÂê¶Â∫îËØ•ÊääÂ§ßÂÜôÊîπÊàêÂ∞èÂÜôÂë¢ÔºüËøõË°åtypo correctionÁ≠âÁ≠â\nStep2: Build Dictionary\nUse a dictionary (hash table) to count word frequencies.\nThe dictionary maps word to index.\nÂèØ‰ª•È¶ñÂÖàÁªüËÆ°ËØçÈ¢ëÂéªÊéâ‰ΩéÈ¢ëËØçÔºåÁÑ∂ÂêéËÆ©ÊØè‰∏™ËØçÂØπÂ∫î‰∏Ä‰∏™Ê≠£Êï¥Êï∞ÔºõËøôÊ†∑ÁöÑËØùÔºå‰∏ÄÂè•ËØùÂ∞±ÂèØ‰ª•Áî®‰∏Ä‰∏™Ê≠£Êï¥Êï∞ÂàóË°®Ë°®Á§∫ÔºåËøô‰∏™ÂàóË°®Â∞±Âè´sequenceÔºõÂ¶ÇÊûúÂøÖË¶ÅÂ∞±ËøòÂæóÂÅöone-hot encoding„ÄÇ\nÁªìÊûú\n‰ΩÜÊòØÈïøÂ∫¶‰∏çÁªü‰∏Ä\nStep4: ÂØπÈΩêsequence\nËß£ÂÜ≥ÊñπÊ°àÊòØËøôÊ†∑ÁöÑÔºöÂèØ‰ª•Âõ∫ÂÆöÈïøÂ∫¶‰∏∫wÔºåÂä†ÂÖ•‰∏Ä‰∏™Â∫èÂàóÈïøÂ∫¶Â§™ÈïøÔºåÂ∞±Á†çÊéâÂâçÈù¢ÁöÑËØçÔºåÂè™‰øùÁïôÊúÄÂêéw‰∏™ËØçÔºõÂ¶ÇÊûú‰∏Ä‰∏™Â∫èÂàóÂ§™Áü≠ÔºåÂ∞±ÂÅözero paddingÔºåÁî®0Â°´ÂÖÖ\nËøôÊ†∑‰∏ÄÊù•ÔºåÊâÄÊúâÁöÑÂ∫èÂàóÈïøÂ∫¶Â∞±Áªü‰∏Ä‰∫Ü\nÊñáÊú¨Â§ÑÁêÜÂÆåÊàê‰∫ÜÔºåÊé•‰∏ãÊù•ÊòØword embeddingÔºåÊääÂçïËØçË°®Á§∫‰∏∫‰∏Ä‰∏™‰ΩéÁª¥ÂêëÈáèÔºõ\nÁÑ∂ËÄåËøôÊ†∑ÂÅöÁöÑËØùÔºåÂ¶ÇÊûúÊòØ10000‰∏™ÂçïËØçÔºåÁª¥Â∫¶Â∞±ÊòØ10000Áª¥ÔºåÁª¥Â∫¶Â§™È´ò‰∫ÜÔºõÂõ†Ê≠§Ë¶ÅÂÅöword embeddingÔºõ\nÂÖ∑‰ΩìÂÅöÊ≥ïÂ∞±ÊòØÊääone-hotÂêëÈáèe_iÂíåÂèÇÊï∞Áü©ÈòµpÁõ∏‰πòÔºõÁü©ÈòµPËΩ¨ÁΩÆÁöÑÂ§ßÂ∞èÊòØd x vÔºõdÊòØËØçÂêëÈáèÁöÑÁª¥Â∫¶ÔºõvÊòØÂ≠óÂÖ∏ÈáåËØçÊ±áÁöÑÊï∞ÈáèÔºõÁªìÊûú‰∏∫x_iÔºõx_iÂ∞±ÊòØ‰∏Ä‰∏™ËØçÂêëÈáèÔºõÂ¶ÇÊûúone-hotÂêëÈáèÁöÑÁ¨¨‰∏âË°å‰∏∫1ÔºõÈÇ£‰πàx_iÂ∞±ÊòØPËΩ¨ÁΩÆÁü©ÈòµÁöÑÁ¨¨‰∏âÂàóÔºàÂÖ∂‰ΩôÂàóÈÉΩ‰∏∫0ÔºâÔºõÊâÄ‰ª•PËΩ¨ÁΩÆÊØè‰∏ÄÂàóÈÉΩÊòØ‰∏Ä‰∏™ËØçÂêëÈáèÔºõÊâÄ‰ª•Áü©ÈòµPÊú¨Ë∫´ÁöÑÊØè‰∏ÄË°åÂ∞±ÊòØ‰∏Ä‰∏™ËØçÂêëÈáèÔºõÂÖ∂Ë°åÊï∞‰∏∫vÔºõÂç≥vocabularyÔºåËØçÊ±áÈáèÔºõÊØè‰∏ÄË°åÂØπÂ∫î‰∏Ä‰∏™ÂçïËØçÔºõÁü©ÈòµÁöÑÂàóÊï∞‰∏∫dÔºõdÊòØÁî®Êà∑ÂÜ≥ÂÆöÁöÑÔºõdÁöÑÂ§ßÂ∞è‰ºöÂÜ≥ÂÆöÊú∫Âô®Â≠¶‰π†Ê®°ÂûãÁöÑË°®Áé∞ÔºõÂ∫îËØ•Áî®xxxÊù•ÈÄâÊã©‰∏Ä‰∏™ÊØîËæÉÂ•ΩÁöÑdÔºõ\nÊàë‰ª¨ÁöÑ‰ªªÂä°ÊòØÁúãËØÑËÆ∫ÊòØÊ≠£Èù¢ÁöÑËøòÊòØË¥üÈù¢ÁöÑÔºõÂèÇÊï∞Áü©ÈòµÊòØ‰ªéËÆ≠ÁªÉÊï∞ÊçÆ‰∏≠Â≠¶‰π†Âá∫Êù•ÁöÑÔºåÊâÄ‰ª•Â≠¶Âá∫Êù•ÁöÑËØçÂêëÈáèÊòØÂ∏¶ÊúâÊÑüÊÉÖËâ≤ÂΩ©ÁöÑÔºõÂÅáËÆæËøô‰∫õËØçÂêëÈáèÈÉΩÊòØ‰∫åÁª¥ÁöÑÔºåÂàôÂèØ‰ª•Âú®Âπ≥Èù¢ÂùêÊ†áÁ≥ª‰∏≠Ê†áÂá∫‰∏ãÈù¢ËØçÂêëÈáè\nkerasÊèê‰æõembeddingÂ±ÇÔºõÁî®Êà∑ÂèØ‰ª•ÊåáÂÆövocabularyÂ§ßÂ∞èÂíådÁöÑÂ§ßÂ∞èÔºõ‰ª•ÂèäÊØè‰∏Ä‰∏™sequenceÁöÑÈïøÂ∫¶ÔºõdÊòØÊ†πÊçÆÁÆóÊ≥ïÈÄâÂá∫Êù•ÁöÑ Âà∞Ëøô‰∏ÄÊ≠•ÔºåÊàë‰ª¨Â∑≤ÁªèÂÆåÊàê‰∫ÜÊñáÊú¨Â§ÑÁêÜÂíåword embedding„ÄÇÊé•‰∏ãÊù•Â∞±ÊòØÁî®Logistic Regression for Binary ClassificationÂÅö‰∫åÂàÜÁ±ªÔºõ\n","permalink":"http://localhost:1313/posts/nlp-2/","summary":"\u003ch3 id=\"text-to-sequence\"\u003eText to Sequence\u003c/h3\u003e\n\u003cp\u003eÊñáÊú¨Â§ÑÁêÜ\u003c/p\u003e\n\u003cp\u003eStep1: Tokenization\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\n\u003cp\u003eTokenization breaks a piece of text down into a list of tokens.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003eHere, a token is a word. (A token can be a character in some applications.)\u003c/p\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003eTokenizationËÆ≤Á©∂ÂæàÂ§öÔºå‰æãÂ¶ÇÊòØÂê¶Â∫îËØ•ÊääÂ§ßÂÜôÊîπÊàêÂ∞èÂÜôÂë¢ÔºüËøõË°åtypo correctionÁ≠âÁ≠â\u003c/p\u003e\n\u003cp\u003e\u003cimg alt=\"image-20250322150322238\" loading=\"lazy\" src=\"./NLP-2.assets/image-20250322150322238.png\"\u003e\u003c/p\u003e\n\u003cp\u003eStep2: Build Dictionary\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\n\u003cp\u003eUse a dictionary (hash table) to count word frequencies.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003eThe dictionary maps word to index.\u003c/p\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003eÂèØ‰ª•È¶ñÂÖàÁªüËÆ°ËØçÈ¢ëÂéªÊéâ‰ΩéÈ¢ëËØçÔºåÁÑ∂ÂêéËÆ©ÊØè‰∏™ËØçÂØπÂ∫î‰∏Ä‰∏™Ê≠£Êï¥Êï∞ÔºõËøôÊ†∑ÁöÑËØùÔºå‰∏ÄÂè•ËØùÂ∞±ÂèØ‰ª•Áî®‰∏Ä‰∏™Ê≠£Êï¥Êï∞ÂàóË°®Ë°®Á§∫ÔºåËøô‰∏™ÂàóË°®Â∞±Âè´sequenceÔºõÂ¶ÇÊûúÂøÖË¶ÅÂ∞±ËøòÂæóÂÅöone-hot encoding„ÄÇ\u003cimg alt=\"image-20250322150620890\" loading=\"lazy\" src=\"./NLP-2.assets/image-20250322150620890.png\"\u003e\u003c/p\u003e\n\u003cp\u003eÁªìÊûú\u003c/p\u003e\n\u003cp\u003e\u003cimg alt=\"image-20250322150754528\" loading=\"lazy\" src=\"./NLP-2.assets/image-20250322150754528.png\"\u003e\u003c/p\u003e\n\u003cp\u003e‰ΩÜÊòØÈïøÂ∫¶‰∏çÁªü‰∏Ä\u003c/p\u003e\n\u003cp\u003eStep4: ÂØπÈΩêsequence\u003c/p\u003e\n\u003cp\u003e\u003cimg alt=\"image-20250322150854986\" loading=\"lazy\" src=\"./NLP-2.assets/image-20250322150854986.png\"\u003e\u003c/p\u003e\n\u003cp\u003eËß£ÂÜ≥ÊñπÊ°àÊòØËøôÊ†∑ÁöÑÔºöÂèØ‰ª•Âõ∫ÂÆöÈïøÂ∫¶‰∏∫wÔºåÂä†ÂÖ•‰∏Ä‰∏™Â∫èÂàóÈïøÂ∫¶Â§™ÈïøÔºåÂ∞±Á†çÊéâÂâçÈù¢ÁöÑËØçÔºåÂè™‰øùÁïôÊúÄÂêéw‰∏™ËØçÔºõÂ¶ÇÊûú‰∏Ä‰∏™Â∫èÂàóÂ§™Áü≠ÔºåÂ∞±ÂÅözero paddingÔºåÁî®0Â°´ÂÖÖ\u003c/p\u003e\n\u003cp\u003e\u003cimg alt=\"image-20250322151030119\" loading=\"lazy\" src=\"./NLP-2.assets/image-20250322151030119.png\"\u003e\u003c/p\u003e\n\u003cp\u003eËøôÊ†∑‰∏ÄÊù•ÔºåÊâÄÊúâÁöÑÂ∫èÂàóÈïøÂ∫¶Â∞±Áªü‰∏Ä‰∫Ü\u003c/p\u003e\n\u003cp\u003e\u003cimg alt=\"image-20250322151117125\" loading=\"lazy\" src=\"./NLP-2.assets/image-20250322151117125.png\"\u003e\u003c/p\u003e\n\u003cp\u003eÊñáÊú¨Â§ÑÁêÜÂÆåÊàê‰∫ÜÔºåÊé•‰∏ãÊù•ÊòØword embeddingÔºåÊääÂçïËØçË°®Á§∫‰∏∫‰∏Ä‰∏™‰ΩéÁª¥ÂêëÈáèÔºõ\u003c/p\u003e\n\u003cp\u003e\u003cimg alt=\"image-20250322151252837\" loading=\"lazy\" src=\"./NLP-2.assets/image-20250322151252837.png\"\u003e\u003c/p\u003e","title":""},{"content":"üëã About me Hello! I\u0026rsquo;m Xu Zongsi, a passionate technology enthusiast currently pursuing my Master of Science in ECIC at The University of Hong Kong. With a solid background in Software Engineering from the Beijing Institute of Technology, I specialize in artificial intelligence areas like machine learning, deep learning, natural language processing, computer vision, and reinforcement learning.\nInspired by OpenAI\u0026rsquo;s five-step plan towards superintelligence, I am excited about AGI and have developed a keen interest in LLM agents, MLLM, and knowledge graphs. I see great potential in these fields and aspire to contribute to innovative solutions.\nüìö Education üá≠üá∞ The University of Hong Kong 09/2024 - Expected 11/2025 School of Computing and Data Science Master of Science in Electronic Commerce \u0026amp; Internet Computing Relevant Courses: Machine learning for business and e-commerce, Knowledge graphs, Financial fraud analytics, Internet infrastructure technologies, Website engineering, Blockchain and cryptocurrency, etc. üá®üá≥ Beijing Institute of Technology 09/2020 - 06/2024 School of Computer Science \u0026amp; Technology Bachelor of Engineering in Software Engineering, last two years GPA: 3.7/4 Relevant Courses: Reinforcement Learning, Deep Learning and Computer Vision, Artificial Intelligence and Robot Ethics, Almost Human: Mind, Brain and Artificial Intelligence, Mathematical Analysis for Engineering, Linear Algebra, Probability and Mathematical Statistics, etc. Skills: Python, Java, common data structures, design patterns, machine learning basics and algorithms, Linux, PyTorch, and some development tools (git, conda, etc.). üèÜ Awards \u0026amp; Honors Beijing Institute of Technology Undergraduate Scholarship (Top 20% of Grade) 06/2023 3rd Prize of China International \u0026#34;Internet \u0026#43;\u0026#34; College Student\u0026#39;s Innovation Competition 08/2022 Bronze Prize of \u0026#34;Challenge Cup\u0026#34; Capital University Entrepreneurship Competition 05/2022 üíº Project Experience üîç Online Transaction Fraud Detection 09/2024 ‚Äì 01/2025 Independent project, supervised by Dr. Vivien Chan Focused on addressing financial fraud in e-commerce to enhance the accuracy of transaction anomaly detection, while independently managing the entire case study that included data preprocessing, feature engineering, model building, evaluation, and results analysis. Effectively resolved class imbalance issues using SMOTE and ROSE techniques. Built various models including Logistic Regression, Random Forest, XGBoost, and LightGBM, ultimately selecting the LightGBM model to achieve a recall rate of 95.45% and an AUC of 99.84%. Wrote efficient and maintainable code, enhancing model training and data processing efficiency through parallel computing and logging. ü§ñ Multi-Model Intelligent Text Keyword Extraction System 08/2023 ‚Äì 09/2023 Group project, supervised by Associate Prof. Xiaolin Zhao Designed and implemented an intelligent text summary system that automatically extracts keywords from article titles and abstracts, enhancing the understanding and summarization of text information. Participated in the planning of the technical route and built a hybrid model combining extractive and generative approaches, utilizing advanced natural language processing techniques including KeyBERT, Sentence Transformer, BERT, and T5 models. Responsible for data preprocessing and tokenization, as well as the end-to-end implementation and training of the T5 model, optimizing the model architecture and hyperparameters, achieving satisfactory results after only 3 epochs of training. Model evaluation results showed that the Rouge-1, Rouge-2, and Rouge-L metrics reached 0.6345, 0.5038, and 0.5282, respectively, in the third epoch, validating the model\u0026rsquo;s effectiveness in the summarization task. üéì Cambridge University Machine Learning Summer Project 07/2023 ‚Äì 08/2023 Group project, supervised by Prof. Pietro Li√≤ Participated in the Cambridge University deep learning summer project, focusing on deep reinforcement learning; explored multi-agent learning algorithms across different environments. Reproduced the Multi-Agent Deep Deterministic Policy Gradient (MADDPG) algorithm in the Simple Adversary environment and studied the effect of agent numbers on convergence speed and stability, finding optimal stability at 21 agents. Designed and implemented comparative experiments inspired by the Rainbow algorithm, assessing target network strategies versus the Double Deep Q-Network (Double DQN). The results demonstrated that Double DQN significantly enhanced convergence speed, optimizing the overall learning process. Co-authored a group project paper on agent numbers and strategies effectiveness in multi-agent systems, achieving a score of 71% in the summer program (the highest in my group) and a \u0026ldquo;First Class\u0026rdquo; classification in the UK grading system. üëÅÔ∏è Deep Learning and Computer Vision Semester Project 09/2022 ‚Äì 12/2022 Independent project, supervised by Associate Prof. Guangyu Gao Designed and implemented a waste classifier using the ResNet model to improve classification accuracy and reduce resource waste. The project also enhanced understanding of transfer learning techniques with ResNet. Collected a dataset of 16 waste categories and preprocessed the images for uniformity and standardization, incorporating data augmentation techniques to enhance the dataset. Conducted experiments using ResNet34 and ResNet50 models through transfer learning, accelerating network convergence by leveraging pretrained weights. During training, techniques such as Batch Normalization and Dropout were applied to mitigate the risk of overfitting. The final model achieved an accuracy of 90% on the training set, while the performance on the test set was 61%, indicating a significant overfitting phenomenon during the training process. üéì Internship ‚öõÔ∏è Beijing Academy of Quantum Information Science 08/2023 ‚Äì 01/2024 Research Intern at Quantum Computation Department Proposed a quantum convolution kernel design based on variational quantum circuits and developed a universal quantum convolution layer, successfully integrating it into classical CNN architectures such as VGG, GoogLeNet, and ResNet. Developed and evaluated various hybrid models, including a simple model named HQCCNN-2, which achieved 84.45% accuracy on the FashionMNIST dataset, surpassing the traditional CNN\u0026rsquo;s 80.72%. This demonstrates the effectiveness of the quantum convolution layer in improving model performance. Tested on a real quantum computer further validated the effectiveness of the hybrid model, demonstrating the viable integration of quantum computing with deep learning, and highlighting the potential for leveraging quantum properties to enhance model performance. üèÖ Competition Experience ü•â China International \u0026#34;Internet \u0026#43;\u0026#34; College Students\u0026#39; Innovation Competition 08/2022 üõ°Ô∏è Zhongke Ushield: Deep Learning-based Face Privacy Protection Authentication System Responsible for constructing a localized facial feature extraction engine based on MobileFaceNet, ensuring feature extraction is completed on end devices (such as mobile phones and cameras), guaranteeing that raw data does not leave the domain and is not stored, thus enhancing user privacy protection while improving recognition efficiency. ü•â \u0026#34;Challenge Cup\u0026#34; Capital University Entrepreneurship Competition 05/2022 üå≥ Smart Orchard Responsible for the development of the fruit detection, ripeness prediction, and pest identification system, using deep convolutional neural network (CNN) technology for intelligent monitoring of crop growth conditions. Applied advanced object detection algorithms such as Faster R-CNN and YOLO to achieve high precision in apple detection and ripeness assessment, with an accuracy rate exceeding 90%, significantly enhancing the intelligence level of orchard management. Built and trained a dedicated dataset containing various pest samples, optimizing pest detection accuracy through data preprocessing (such as image normalization and resizing) and data augmentation techniques (like rotation, flipping, and noise addition), enabling the real-time monitoring system to accurately identify over 80% of pests, providing effective scientific maintenance recommendations to help farmers reduce crop losses. üìã Extracurricular Activities Vice President, Cyber Security Club, Beijing Institute of Technology 09/2021-09/2022 Backbone, Media Center of the Student Union of Beijing Institute of Technology 10/2020-06/2021 üì´ Contact üìß Email: zongsi.xu@outlook.com üëî LinkedIn: Zongsi (Tristan) Xu üíª GitHub: BaizeXS üìç Location: Hong Kong SAR, China ","permalink":"http://localhost:1313/resume/","summary":"Personal resume of Zongsi (Tristan) Xu","title":"Zongsi (Tristan) Xu"},{"content":"‰∏Ä„ÄÅÊï∞ÂÄºÁâπÂæÅ‰∏éÁ±ªÂà´ÁâπÂæÅ Êï∞ÂÄºÁâπÂæÅ (Numeric Features) ÂÖ∑ÊúâÂèØÂä†ÂáèÁöÑÊÑè‰πâÔºå‰∏îÂ≠òÂú®Â§ßÂ∞èÈ°∫Â∫è„ÄÇ ‰æãÂ≠êÔºöÂπ¥ÈæÑ„ÄÅÊ∏©Â∫¶Á≠â„ÄÇÂèØ‰ª•Áõ¥Êé•‰øùÁïôÂÖ∂Êï¥Êï∞ÊàñÊµÆÁÇπÊï∞ÂΩ¢Âºè‰æõÊ®°Âûã‰ΩøÁî®„ÄÇ Á±ªÂà´ÁâπÂæÅ (Categorical Features) Êï∞ÊçÆÂÄºÁ¶ªÊï£Ôºå‰∏çÂÖ∑Â§á‚ÄúÊï∞ÂÄºÂ§ßÂ∞è‚ÄùÈó¥ÁöÑÂèØÊØîÊÑè‰πâ„ÄÇ ‰æãÂ≠êÔºöÂõΩÁ±çÔºàÁæéÂõΩ/‰∏≠ÂõΩ/Âç∞Â∫¶Á≠âÔºâ„ÄÅÊÄßÂà´ÔºàÁî∑/Â•≥ÔºâÁ≠â„ÄÇ ÈóÆÈ¢òÔºöËã•‰ªÖÁî®Êï¥Êï∞Ë°®Á§∫ÔºàÁæéÂõΩ=1, ‰∏≠ÂõΩ=2ÔºâÔºå‰ºöÂºïÂÖ•ÈîôËØØÁöÑÊï∞ÂÄºËøêÁÆóÂÖ≥Á≥ªÔºåÂ¶Ç ‚ÄúÁæéÂõΩ + ‰∏≠ÂõΩ = Âç∞Â∫¶‚Äù„ÄÇ ‰∫å„ÄÅOne-HotÁºñÁ†ÅÁöÑÂä®Êú∫‰∏éÊµÅÁ®ã ‰∏∫‰ªÄ‰πà‰ΩøÁî®One-Hot\nÈÄöËøáÂ∞ÜÁ±ªÂà´Êò†Â∞Ñ‰∏∫ÂêëÈáèÔºåÈÅøÂÖçÊï¥Êï∞ÁºñÁ†ÅÂºïÂÖ•ÁöÑ‰º™Êï∞ÂÄºÂÖ≥Á≥ª„ÄÇ ÂêåÊó∂‰øùÁïôÂêÑÁßçÂèØËÉΩÁ±ªÂà´ÁöÑ‰ø°ÊÅØÔºå‰∏î‰ªÖÂú®ÂØπÂ∫î‰ΩçÁΩÆ‰∏∫1ÔºåÂÖ∂‰ªñ‰ΩçÁΩÆ‰∏∫0„ÄÇ Âª∫Á´ãÊò†Â∞ÑÔºö‰ªéÁ±ªÂà´Âà∞Á¥¢Âºï\n‰∏∫ÊØè‰∏™Á±ªÂà´ÂàÜÈÖç‰∏Ä‰∏™ÂîØ‰∏ÄÁ¥¢ÂºïÔºåÈÄöÂ∏∏‰ªé1ÂºÄÂßã„ÄÇ È¢ÑÁïôÁ¥¢Âºï0Ë°®Á§∫‚ÄúÊú™Áü•‚ÄùÊàñ‚ÄúÁº∫Â§±‚ÄùÔºåÂØπÂ∫îÂÖ®0ÂêëÈáè„ÄÇ ËΩ¨Êç¢‰∏∫One-HotÂêëÈáè\nËã•Á±ªÂà´ÊÄªÊï∞‰∏∫197ÔºåÂàôÁî®197Áª¥ÂêëÈáèË°®Á§∫„ÄÇ ‰æãÂ≠êÔºöÁæéÂõΩ [1, 0, 0, 0, ‚Ä¶]Ôºå ‰∏≠ÂõΩ [0, 1, 0, 0, ‚Ä¶]„ÄÇ Á§∫‰æãÔºöË°®Á§∫‰∏Ä‰∏™‰∫∫ÁöÑÁâπÂæÅ\nÁâπÂæÅÂåÖÂê´ÔºàÂπ¥ÈæÑ, ÊÄßÂà´, ÂõΩÁ±çÔºåÂÖ∂‰∏≠ÂõΩÁ±ç197ÁßçÔºâ Áª¥Â∫¶ÊÄªÂíåÔºö1Áª¥_age + 1Áª¥_gender + 197Áª¥_nationality = 199Áª¥„ÄÇ ‰æãÂ¶Ç (28, Â•≥, ‰∏≠ÂõΩ) ‚Üí [28, 0, 0, 1, 0, ‚Ä¶, 0]„ÄÇ ‰∏â„ÄÅÊñáÊú¨Êï∞ÊçÆÂ§ÑÁêÜÊµÅÁ®ã ÊñáÊú¨Âú®Ëá™ÁÑ∂ËØ≠Ë®ÄÂ§ÑÁêÜÔºàNLPÔºâ‰∏≠‰Ωú‰∏∫Â∏∏ËßÅÁöÑÂéüÂßãËæìÂÖ•ÔºåÈúÄË¶ÅÊï∞ÂÄºÂåñÊâçËÉΩÈÄÅÂÖ•Ê®°Âûã„ÄÇ‰∏ÄËà¨Ê≠•È™§Â¶Ç‰∏ãÔºö\nÂàÜËØç (Tokenization)\nÂ∞ÜÊñáÊú¨ÊãÜÂàÜ‰∏∫‰∏Ä‰∏™‰∏™ÂçïËØçÔºàTokenÔºâ„ÄÇ ‰æãÂ≠êÔºö\u0026quot;... to be or not to be...\u0026quot; ‚Üí [\u0026quot;...\u0026quot;, \u0026quot;to\u0026quot;, \u0026quot;be\u0026quot;, \u0026quot;or\u0026quot;, \u0026quot;not\u0026quot;, \u0026quot;to\u0026quot;, \u0026quot;be\u0026quot;, \u0026quot;...\u0026quot;]„ÄÇ ÁªüËÆ°ËØçÈ¢ë \u0026amp; ÊûÑÂª∫ËØçÂÖ∏\nËØçÈ¢ëÁªüËÆ° Áî®ÂìàÂ∏åË°®/Â≠óÂÖ∏ËÆ∞ÂΩïÊØè‰∏™ÂçïËØçÂá∫Áé∞Ê¨°Êï∞„ÄÇ ÈÅçÂéÜÊñáÊú¨Êó∂ÔºåËã•ÂçïËØçÂ∞öÊú™ÂÖ•Ë°®ÔºåÂàôÊñ∞Âª∫ËÆ∞ÂΩïÔºõËã•Â∑≤Â≠òÂú®ÔºåÂàôËÆ°Êï∞+1„ÄÇ ÊéíÂ∫è‰∏éÁ¥¢Âºï ÊåâËØçÈ¢ëÈôçÂ∫èÊéíÂ∫èÔºåËØçÈ¢ëÊúÄÈ´òÁöÑÂçïËØçÊéíÂú®ÂâçÈù¢„ÄÇ Á¥¢Âºï‰ªé1ÂºÄÂßãÔºå0ÁïôÁªô‚ÄúÊú™Áü•‚Äù„ÄÇ ËØçÂÖ∏ËßÑÊ®°ÔºàvocabularyÔºâÂèØËßÜÈúÄÊ±ÇÊà™Êñ≠Ôºà‰æãÂ¶ÇÂè™‰øùÁïôTop 10kÔºâ„ÄÇ ‰∏∫‰ªÄ‰πàÁßªÈô§‰ΩéÈ¢ëËØç ‰ΩéÈ¢ëËØçÂèØËÉΩÊòØÊãºÂÜôÈîôËØØ„ÄÅÁΩïËßÅ‰∫∫ÂêçÁ≠âÔºåÂØπÊ®°ÂûãÂ∏ÆÂä©ÊúâÈôê„ÄÇ ÂáèÂ∞ëËØçÂÖ∏ËßÑÊ®°ÂèØÈôç‰ΩéËøêÁÆóÂºÄÈîÄ„ÄÅÂä†Âø´Ê®°ÂûãËÆ≠ÁªÉ‰∏éÊé®ÁêÜÈÄüÂ∫¶„ÄÇ Áã¨ÁÉ≠ÁºñÁ†Å (One-Hot Encoding)\nÂ∞ÜÊØè‰∏™ÂçïËØçÊò†Â∞Ñ‰∏∫ËØçÂÖ∏‰∏≠ÁöÑÁ¥¢ÂºïÂêéÔºàÂ¶Ç [2, 4, 1, 8, ‚Ä¶]ÔºâÔºåÂèØËøõ‰∏ÄÊ≠•ËΩ¨Êç¢ÊàêOne-HotÂêëÈáè„ÄÇ One-HotÁª¥Â∫¶ÂèñÂÜ≥‰∫é‰øùÁïô‰∏ãÊù•ÁöÑËØçÂÖ∏Â§ßÂ∞èÔºà‰æãÂ¶Ç1‰∏áÔºâ„ÄÇ Êú™Êî∂ÂΩïÂçïËØçÂèØËÉΩÁõ¥Êé•ÂøΩÁï•ÔºåÊàñÁªü‰∏ÄÁî®Á¥¢Âºï0‰ª£Êõø„ÄÇ Âõõ„ÄÅÊ†∏ÂøÉÊî∂Ëé∑‰∏éÂ∫îÁî® Á±ªÂà´ÁâπÂæÅÂøÖÈúÄÊï∞ÂÄºÂåñÔºö\n‰ΩøÁî®Êï¥Êï∞1,2,3‚Ä¶‰ªÖË°®Á§∫Á±ªÂà´‚ÄúÊ†áËØÜ‚ÄùÔºåÂπ∂‰∏ç‰ª£Ë°®ÂÆÉ‰ª¨ÂèØËøõË°åÊï∞ÂÄºËøêÁÆó„ÄÇ Âõ†Ê≠§ÈúÄË¶ÅOne-HotÁ≠âÁºñÁ†ÅÊñπÂºèÔºåÈÅøÂÖçÊï∞ÂÄºËØØËß£„ÄÇ ÊñáÊú¨Êï∞ÊçÆÈ¢ÑÂ§ÑÁêÜÔºö\nÂàÜËØç„ÄÅËØçÈ¢ëÁªüËÆ°„ÄÅÊûÑÂª∫ËØçÂÖ∏„ÄÅÁ¥¢ÂºïÂåñ„ÄÅOne-HotÊàñÂÖ∂‰ªñÊñπÂºèÔºàÂ¶ÇËØçÂµåÂÖ•ÔºâÊòØÂ∏∏ËßÅÊµÅÁ®ã„ÄÇ Ê≠£Á°ÆÁöÑÊñáÊú¨È¢ÑÂ§ÑÁêÜÂèØÊòæËëóÂΩ±ÂìçÊ®°ÂûãÊÄßËÉΩÂíåÊïàÁéá„ÄÇ ‰øùÁïôÊú™Áü•Á¥¢ÂºïÔºö\n‰øùËØÅÂØπÁº∫Â§±Êï∞ÊçÆÊàñÂ≠óÂÖ∏Â§ñÊñ∞ËØçËÉΩÊúâÂü∫Êú¨ÁöÑË°®Á§∫ÔºåÊèêÂçáÊ®°ÂûãÂÆπÈîôÊÄß„ÄÇ ÂÆûÈôÖ‰ΩøÁî®Ôºö\nÂØπ‰∫éÂ∞èËßÑÊ®°Á±ªÂà´ÂèØÁõ¥Êé•One-HotÁºñÁ†ÅÔºõÂØπ‰∫éËØçÂÖ∏ÂæàÂ§ßÁöÑÂú∫ÊôØÔºåÈÄöÂ∏∏‰ºöËøõ‰∏ÄÊ≠•ËÄÉËôëËØçÂµåÂÖ•ÔºàWord EmbeddingÔºâÊàñÈ¢ÑËÆ≠ÁªÉËØ≠Ë®ÄÊ®°Âûã„ÄÇ ","permalink":"http://localhost:1313/posts/nlp-1/","summary":"\u003ch2 id=\"‰∏ÄÊï∞ÂÄºÁâπÂæÅ‰∏éÁ±ªÂà´ÁâπÂæÅ\"\u003e‰∏Ä„ÄÅÊï∞ÂÄºÁâπÂæÅ‰∏éÁ±ªÂà´ÁâπÂæÅ\u003c/h2\u003e\n\u003col\u003e\n\u003cli\u003e\u003cstrong\u003eÊï∞ÂÄºÁâπÂæÅ (Numeric Features)\u003c/strong\u003e\n\u003cul\u003e\n\u003cli\u003eÂÖ∑ÊúâÂèØÂä†ÂáèÁöÑÊÑè‰πâÔºå‰∏îÂ≠òÂú®Â§ßÂ∞èÈ°∫Â∫è„ÄÇ\u003c/li\u003e\n\u003cli\u003e‰æãÂ≠êÔºöÂπ¥ÈæÑ„ÄÅÊ∏©Â∫¶Á≠â„ÄÇÂèØ‰ª•Áõ¥Êé•‰øùÁïôÂÖ∂Êï¥Êï∞ÊàñÊµÆÁÇπÊï∞ÂΩ¢Âºè‰æõÊ®°Âûã‰ΩøÁî®„ÄÇ\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003eÁ±ªÂà´ÁâπÂæÅ (Categorical Features)\u003c/strong\u003e\n\u003cul\u003e\n\u003cli\u003eÊï∞ÊçÆÂÄºÁ¶ªÊï£Ôºå‰∏çÂÖ∑Â§á‚ÄúÊï∞ÂÄºÂ§ßÂ∞è‚ÄùÈó¥ÁöÑÂèØÊØîÊÑè‰πâ„ÄÇ\u003c/li\u003e\n\u003cli\u003e‰æãÂ≠êÔºöÂõΩÁ±çÔºàÁæéÂõΩ/‰∏≠ÂõΩ/Âç∞Â∫¶Á≠âÔºâ„ÄÅÊÄßÂà´ÔºàÁî∑/Â•≥ÔºâÁ≠â„ÄÇ\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003eÈóÆÈ¢ò\u003c/strong\u003eÔºöËã•‰ªÖÁî®Êï¥Êï∞Ë°®Á§∫ÔºàÁæéÂõΩ=1, ‰∏≠ÂõΩ=2ÔºâÔºå‰ºöÂºïÂÖ•ÈîôËØØÁöÑÊï∞ÂÄºËøêÁÆóÂÖ≥Á≥ªÔºåÂ¶Ç ‚ÄúÁæéÂõΩ + ‰∏≠ÂõΩ = Âç∞Â∫¶‚Äù„ÄÇ\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003c/ol\u003e\n\u003ch2 id=\"‰∫åone-hotÁºñÁ†ÅÁöÑÂä®Êú∫‰∏éÊµÅÁ®ã\"\u003e‰∫å„ÄÅOne-HotÁºñÁ†ÅÁöÑÂä®Êú∫‰∏éÊµÅÁ®ã\u003c/h2\u003e\n\u003col\u003e\n\u003cli\u003e\n\u003cp\u003e\u003cstrong\u003e‰∏∫‰ªÄ‰πà‰ΩøÁî®One-Hot\u003c/strong\u003e\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eÈÄöËøáÂ∞ÜÁ±ªÂà´Êò†Â∞Ñ‰∏∫ÂêëÈáèÔºåÈÅøÂÖçÊï¥Êï∞ÁºñÁ†ÅÂºïÂÖ•ÁöÑ‰º™Êï∞ÂÄºÂÖ≥Á≥ª„ÄÇ\u003c/li\u003e\n\u003cli\u003eÂêåÊó∂‰øùÁïôÂêÑÁßçÂèØËÉΩÁ±ªÂà´ÁöÑ‰ø°ÊÅØÔºå‰∏î‰ªÖÂú®ÂØπÂ∫î‰ΩçÁΩÆ‰∏∫1ÔºåÂÖ∂‰ªñ‰ΩçÁΩÆ‰∏∫0„ÄÇ\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003e\u003cstrong\u003eÂª∫Á´ãÊò†Â∞ÑÔºö‰ªéÁ±ªÂà´Âà∞Á¥¢Âºï\u003c/strong\u003e\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e‰∏∫ÊØè‰∏™Á±ªÂà´ÂàÜÈÖç‰∏Ä‰∏™ÂîØ‰∏ÄÁ¥¢ÂºïÔºåÈÄöÂ∏∏‰ªé1ÂºÄÂßã„ÄÇ\u003c/li\u003e\n\u003cli\u003eÈ¢ÑÁïôÁ¥¢Âºï0Ë°®Á§∫‚ÄúÊú™Áü•‚ÄùÊàñ‚ÄúÁº∫Â§±‚ÄùÔºåÂØπÂ∫îÂÖ®0ÂêëÈáè„ÄÇ\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003e\u003cstrong\u003eËΩ¨Êç¢‰∏∫One-HotÂêëÈáè\u003c/strong\u003e\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eËã•Á±ªÂà´ÊÄªÊï∞‰∏∫197ÔºåÂàôÁî®197Áª¥ÂêëÈáèË°®Á§∫„ÄÇ\u003c/li\u003e\n\u003cli\u003e‰æãÂ≠êÔºöÁæéÂõΩ \u003ccode\u003e[1, 0, 0, 0, ‚Ä¶]\u003c/code\u003eÔºå ‰∏≠ÂõΩ \u003ccode\u003e[0, 1, 0, 0, ‚Ä¶]\u003c/code\u003e„ÄÇ\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003e\u003cstrong\u003eÁ§∫‰æãÔºöË°®Á§∫‰∏Ä‰∏™‰∫∫ÁöÑÁâπÂæÅ\u003c/strong\u003e\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eÁâπÂæÅÂåÖÂê´ÔºàÂπ¥ÈæÑ, ÊÄßÂà´, ÂõΩÁ±çÔºåÂÖ∂‰∏≠ÂõΩÁ±ç197ÁßçÔºâ\u003c/li\u003e\n\u003cli\u003eÁª¥Â∫¶ÊÄªÂíåÔºö1Áª¥_age + 1Áª¥_gender + 197Áª¥_nationality = 199Áª¥„ÄÇ\u003c/li\u003e\n\u003cli\u003e‰æãÂ¶Ç \u003ccode\u003e(28, Â•≥, ‰∏≠ÂõΩ)\u003c/code\u003e ‚Üí \u003ccode\u003e[28, 0, 0, 1, 0, ‚Ä¶, 0]\u003c/code\u003e„ÄÇ\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003c/ol\u003e\n\u003ch2 id=\"‰∏âÊñáÊú¨Êï∞ÊçÆÂ§ÑÁêÜÊµÅÁ®ã\"\u003e‰∏â„ÄÅÊñáÊú¨Êï∞ÊçÆÂ§ÑÁêÜÊµÅÁ®ã\u003c/h2\u003e\n\u003cp\u003eÊñáÊú¨Âú®Ëá™ÁÑ∂ËØ≠Ë®ÄÂ§ÑÁêÜÔºàNLPÔºâ‰∏≠‰Ωú‰∏∫Â∏∏ËßÅÁöÑÂéüÂßãËæìÂÖ•ÔºåÈúÄË¶ÅÊï∞ÂÄºÂåñÊâçËÉΩÈÄÅÂÖ•Ê®°Âûã„ÄÇ‰∏ÄËà¨Ê≠•È™§Â¶Ç‰∏ãÔºö\u003c/p\u003e\n\u003col\u003e\n\u003cli\u003e\n\u003cp\u003e\u003cstrong\u003eÂàÜËØç (Tokenization)\u003c/strong\u003e\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eÂ∞ÜÊñáÊú¨ÊãÜÂàÜ‰∏∫‰∏Ä‰∏™‰∏™ÂçïËØçÔºàTokenÔºâ„ÄÇ\u003c/li\u003e\n\u003cli\u003e‰æãÂ≠êÔºö\u003ccode\u003e\u0026quot;... to be or not to be...\u0026quot;\u003c/code\u003e ‚Üí \u003ccode\u003e[\u0026quot;...\u0026quot;, \u0026quot;to\u0026quot;, \u0026quot;be\u0026quot;, \u0026quot;or\u0026quot;, \u0026quot;not\u0026quot;, \u0026quot;to\u0026quot;, \u0026quot;be\u0026quot;, \u0026quot;...\u0026quot;]\u003c/code\u003e„ÄÇ\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003e\u003cstrong\u003eÁªüËÆ°ËØçÈ¢ë \u0026amp; ÊûÑÂª∫ËØçÂÖ∏\u003c/strong\u003e\u003c/p\u003e","title":""},{"content":"Text to Sequence ÊñáÊú¨Â§ÑÁêÜ\nStep1: Tokenization\nTokenization breaks a piece of text down into a list of tokens.\nHere, a token is a word. (A token can be a character in some applications.)\nTokenizationËÆ≤Á©∂ÂæàÂ§öÔºå‰æãÂ¶ÇÊòØÂê¶Â∫îËØ•ÊääÂ§ßÂÜôÊîπÊàêÂ∞èÂÜôÂë¢ÔºüËøõË°åtypo correctionÁ≠âÁ≠â\nStep2: Build Dictionary\nUse a dictionary (hash table) to count word frequencies.\nThe dictionary maps word to index.\nÂèØ‰ª•È¶ñÂÖàÁªüËÆ°ËØçÈ¢ëÂéªÊéâ‰ΩéÈ¢ëËØçÔºåÁÑ∂ÂêéËÆ©ÊØè‰∏™ËØçÂØπÂ∫î‰∏Ä‰∏™Ê≠£Êï¥Êï∞ÔºõËøôÊ†∑ÁöÑËØùÔºå‰∏ÄÂè•ËØùÂ∞±ÂèØ‰ª•Áî®‰∏Ä‰∏™Ê≠£Êï¥Êï∞ÂàóË°®Ë°®Á§∫ÔºåËøô‰∏™ÂàóË°®Â∞±Âè´sequenceÔºõÂ¶ÇÊûúÂøÖË¶ÅÂ∞±ËøòÂæóÂÅöone-hot encoding„ÄÇ\nÁªìÊûú\n‰ΩÜÊòØÈïøÂ∫¶‰∏çÁªü‰∏Ä\nStep4: ÂØπÈΩêsequence\nËß£ÂÜ≥ÊñπÊ°àÊòØËøôÊ†∑ÁöÑÔºöÂèØ‰ª•Âõ∫ÂÆöÈïøÂ∫¶‰∏∫wÔºåÂä†ÂÖ•‰∏Ä‰∏™Â∫èÂàóÈïøÂ∫¶Â§™ÈïøÔºåÂ∞±Á†çÊéâÂâçÈù¢ÁöÑËØçÔºåÂè™‰øùÁïôÊúÄÂêéw‰∏™ËØçÔºõÂ¶ÇÊûú‰∏Ä‰∏™Â∫èÂàóÂ§™Áü≠ÔºåÂ∞±ÂÅözero paddingÔºåÁî®0Â°´ÂÖÖ\nËøôÊ†∑‰∏ÄÊù•ÔºåÊâÄÊúâÁöÑÂ∫èÂàóÈïøÂ∫¶Â∞±Áªü‰∏Ä‰∫Ü\nÊñáÊú¨Â§ÑÁêÜÂÆåÊàê‰∫ÜÔºåÊé•‰∏ãÊù•ÊòØword embeddingÔºåÊääÂçïËØçË°®Á§∫‰∏∫‰∏Ä‰∏™‰ΩéÁª¥ÂêëÈáèÔºõ\nÁÑ∂ËÄåËøôÊ†∑ÂÅöÁöÑËØùÔºåÂ¶ÇÊûúÊòØ10000‰∏™ÂçïËØçÔºåÁª¥Â∫¶Â∞±ÊòØ10000Áª¥ÔºåÁª¥Â∫¶Â§™È´ò‰∫ÜÔºõÂõ†Ê≠§Ë¶ÅÂÅöword embeddingÔºõ\nÂÖ∑‰ΩìÂÅöÊ≥ïÂ∞±ÊòØÊääone-hotÂêëÈáèe_iÂíåÂèÇÊï∞Áü©ÈòµpÁõ∏‰πòÔºõÁü©ÈòµPËΩ¨ÁΩÆÁöÑÂ§ßÂ∞èÊòØd x vÔºõdÊòØËØçÂêëÈáèÁöÑÁª¥Â∫¶ÔºõvÊòØÂ≠óÂÖ∏ÈáåËØçÊ±áÁöÑÊï∞ÈáèÔºõÁªìÊûú‰∏∫x_iÔºõx_iÂ∞±ÊòØ‰∏Ä‰∏™ËØçÂêëÈáèÔºõÂ¶ÇÊûúone-hotÂêëÈáèÁöÑÁ¨¨‰∏âË°å‰∏∫1ÔºõÈÇ£‰πàx_iÂ∞±ÊòØPËΩ¨ÁΩÆÁü©ÈòµÁöÑÁ¨¨‰∏âÂàóÔºàÂÖ∂‰ΩôÂàóÈÉΩ‰∏∫0ÔºâÔºõÊâÄ‰ª•PËΩ¨ÁΩÆÊØè‰∏ÄÂàóÈÉΩÊòØ‰∏Ä‰∏™ËØçÂêëÈáèÔºõÊâÄ‰ª•Áü©ÈòµPÊú¨Ë∫´ÁöÑÊØè‰∏ÄË°åÂ∞±ÊòØ‰∏Ä‰∏™ËØçÂêëÈáèÔºõÂÖ∂Ë°åÊï∞‰∏∫vÔºõÂç≥vocabularyÔºåËØçÊ±áÈáèÔºõÊØè‰∏ÄË°åÂØπÂ∫î‰∏Ä‰∏™ÂçïËØçÔºõÁü©ÈòµÁöÑÂàóÊï∞‰∏∫dÔºõdÊòØÁî®Êà∑ÂÜ≥ÂÆöÁöÑÔºõdÁöÑÂ§ßÂ∞è‰ºöÂÜ≥ÂÆöÊú∫Âô®Â≠¶‰π†Ê®°ÂûãÁöÑË°®Áé∞ÔºõÂ∫îËØ•Áî®xxxÊù•ÈÄâÊã©‰∏Ä‰∏™ÊØîËæÉÂ•ΩÁöÑdÔºõ\nÊàë‰ª¨ÁöÑ‰ªªÂä°ÊòØÁúãËØÑËÆ∫ÊòØÊ≠£Èù¢ÁöÑËøòÊòØË¥üÈù¢ÁöÑÔºõÂèÇÊï∞Áü©ÈòµÊòØ‰ªéËÆ≠ÁªÉÊï∞ÊçÆ‰∏≠Â≠¶‰π†Âá∫Êù•ÁöÑÔºåÊâÄ‰ª•Â≠¶Âá∫Êù•ÁöÑËØçÂêëÈáèÊòØÂ∏¶ÊúâÊÑüÊÉÖËâ≤ÂΩ©ÁöÑÔºõÂÅáËÆæËøô‰∫õËØçÂêëÈáèÈÉΩÊòØ‰∫åÁª¥ÁöÑÔºåÂàôÂèØ‰ª•Âú®Âπ≥Èù¢ÂùêÊ†áÁ≥ª‰∏≠Ê†áÂá∫‰∏ãÈù¢ËØçÂêëÈáè\nkerasÊèê‰æõembeddingÂ±ÇÔºõÁî®Êà∑ÂèØ‰ª•ÊåáÂÆövocabularyÂ§ßÂ∞èÂíådÁöÑÂ§ßÂ∞èÔºõ‰ª•ÂèäÊØè‰∏Ä‰∏™sequenceÁöÑÈïøÂ∫¶ÔºõdÊòØÊ†πÊçÆÁÆóÊ≥ïÈÄâÂá∫Êù•ÁöÑ Âà∞Ëøô‰∏ÄÊ≠•ÔºåÊàë‰ª¨Â∑≤ÁªèÂÆåÊàê‰∫ÜÊñáÊú¨Â§ÑÁêÜÂíåword embedding„ÄÇÊé•‰∏ãÊù•Â∞±ÊòØÁî®Logistic Regression for Binary ClassificationÂÅö‰∫åÂàÜÁ±ªÔºõ\n","permalink":"http://localhost:1313/posts/nlp-2/","summary":"\u003ch3 id=\"text-to-sequence\"\u003eText to Sequence\u003c/h3\u003e\n\u003cp\u003eÊñáÊú¨Â§ÑÁêÜ\u003c/p\u003e\n\u003cp\u003eStep1: Tokenization\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\n\u003cp\u003eTokenization breaks a piece of text down into a list of tokens.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003eHere, a token is a word. (A token can be a character in some applications.)\u003c/p\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003eTokenizationËÆ≤Á©∂ÂæàÂ§öÔºå‰æãÂ¶ÇÊòØÂê¶Â∫îËØ•ÊääÂ§ßÂÜôÊîπÊàêÂ∞èÂÜôÂë¢ÔºüËøõË°åtypo correctionÁ≠âÁ≠â\u003c/p\u003e\n\u003cp\u003e\u003cimg alt=\"image-20250322150322238\" loading=\"lazy\" src=\"./NLP-2.assets/image-20250322150322238.png\"\u003e\u003c/p\u003e\n\u003cp\u003eStep2: Build Dictionary\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\n\u003cp\u003eUse a dictionary (hash table) to count word frequencies.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003eThe dictionary maps word to index.\u003c/p\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003eÂèØ‰ª•È¶ñÂÖàÁªüËÆ°ËØçÈ¢ëÂéªÊéâ‰ΩéÈ¢ëËØçÔºåÁÑ∂ÂêéËÆ©ÊØè‰∏™ËØçÂØπÂ∫î‰∏Ä‰∏™Ê≠£Êï¥Êï∞ÔºõËøôÊ†∑ÁöÑËØùÔºå‰∏ÄÂè•ËØùÂ∞±ÂèØ‰ª•Áî®‰∏Ä‰∏™Ê≠£Êï¥Êï∞ÂàóË°®Ë°®Á§∫ÔºåËøô‰∏™ÂàóË°®Â∞±Âè´sequenceÔºõÂ¶ÇÊûúÂøÖË¶ÅÂ∞±ËøòÂæóÂÅöone-hot encoding„ÄÇ\u003cimg alt=\"image-20250322150620890\" loading=\"lazy\" src=\"./NLP-2.assets/image-20250322150620890.png\"\u003e\u003c/p\u003e\n\u003cp\u003eÁªìÊûú\u003c/p\u003e\n\u003cp\u003e\u003cimg alt=\"image-20250322150754528\" loading=\"lazy\" src=\"./NLP-2.assets/image-20250322150754528.png\"\u003e\u003c/p\u003e\n\u003cp\u003e‰ΩÜÊòØÈïøÂ∫¶‰∏çÁªü‰∏Ä\u003c/p\u003e\n\u003cp\u003eStep4: ÂØπÈΩêsequence\u003c/p\u003e\n\u003cp\u003e\u003cimg alt=\"image-20250322150854986\" loading=\"lazy\" src=\"./NLP-2.assets/image-20250322150854986.png\"\u003e\u003c/p\u003e\n\u003cp\u003eËß£ÂÜ≥ÊñπÊ°àÊòØËøôÊ†∑ÁöÑÔºöÂèØ‰ª•Âõ∫ÂÆöÈïøÂ∫¶‰∏∫wÔºåÂä†ÂÖ•‰∏Ä‰∏™Â∫èÂàóÈïøÂ∫¶Â§™ÈïøÔºåÂ∞±Á†çÊéâÂâçÈù¢ÁöÑËØçÔºåÂè™‰øùÁïôÊúÄÂêéw‰∏™ËØçÔºõÂ¶ÇÊûú‰∏Ä‰∏™Â∫èÂàóÂ§™Áü≠ÔºåÂ∞±ÂÅözero paddingÔºåÁî®0Â°´ÂÖÖ\u003c/p\u003e\n\u003cp\u003e\u003cimg alt=\"image-20250322151030119\" loading=\"lazy\" src=\"./NLP-2.assets/image-20250322151030119.png\"\u003e\u003c/p\u003e\n\u003cp\u003eËøôÊ†∑‰∏ÄÊù•ÔºåÊâÄÊúâÁöÑÂ∫èÂàóÈïøÂ∫¶Â∞±Áªü‰∏Ä‰∫Ü\u003c/p\u003e\n\u003cp\u003e\u003cimg alt=\"image-20250322151117125\" loading=\"lazy\" src=\"./NLP-2.assets/image-20250322151117125.png\"\u003e\u003c/p\u003e\n\u003cp\u003eÊñáÊú¨Â§ÑÁêÜÂÆåÊàê‰∫ÜÔºåÊé•‰∏ãÊù•ÊòØword embeddingÔºåÊääÂçïËØçË°®Á§∫‰∏∫‰∏Ä‰∏™‰ΩéÁª¥ÂêëÈáèÔºõ\u003c/p\u003e\n\u003cp\u003e\u003cimg alt=\"image-20250322151252837\" loading=\"lazy\" src=\"./NLP-2.assets/image-20250322151252837.png\"\u003e\u003c/p\u003e","title":""},{"content":"üëã About me Hello! I\u0026rsquo;m Xu Zongsi, a passionate technology enthusiast currently pursuing my Master of Science in ECIC at The University of Hong Kong. With a solid background in Software Engineering from the Beijing Institute of Technology, I specialize in artificial intelligence areas like machine learning, deep learning, natural language processing, computer vision, and reinforcement learning.\nInspired by OpenAI\u0026rsquo;s five-step plan towards superintelligence, I am excited about AGI and have developed a keen interest in LLM agents, MLLM, and knowledge graphs. I see great potential in these fields and aspire to contribute to innovative solutions.\nüìö Education üá≠üá∞ The University of Hong Kong 09/2024 - Expected 11/2025 School of Computing and Data Science Master of Science in Electronic Commerce \u0026amp; Internet Computing Relevant Courses: Machine learning for business and e-commerce, Knowledge graphs, Financial fraud analytics, Internet infrastructure technologies, Website engineering, Blockchain and cryptocurrency, etc. üá®üá≥ Beijing Institute of Technology 09/2020 - 06/2024 School of Computer Science \u0026amp; Technology Bachelor of Engineering in Software Engineering, last two years GPA: 3.7/4 Relevant Courses: Reinforcement Learning, Deep Learning and Computer Vision, Artificial Intelligence and Robot Ethics, Almost Human: Mind, Brain and Artificial Intelligence, Mathematical Analysis for Engineering, Linear Algebra, Probability and Mathematical Statistics, etc. Skills: Python, Java, common data structures, design patterns, machine learning basics and algorithms, Linux, PyTorch, and some development tools (git, conda, etc.). üèÜ Awards \u0026amp; Honors Beijing Institute of Technology Undergraduate Scholarship (Top 20% of Grade) 06/2023 3rd Prize of China International \u0026#34;Internet \u0026#43;\u0026#34; College Student\u0026#39;s Innovation Competition 08/2022 Bronze Prize of \u0026#34;Challenge Cup\u0026#34; Capital University Entrepreneurship Competition 05/2022 üíº Project Experience üîç Online Transaction Fraud Detection 09/2024 ‚Äì 01/2025 Independent project, supervised by Dr. Vivien Chan Focused on addressing financial fraud in e-commerce to enhance the accuracy of transaction anomaly detection, while independently managing the entire case study that included data preprocessing, feature engineering, model building, evaluation, and results analysis. Effectively resolved class imbalance issues using SMOTE and ROSE techniques. Built various models including Logistic Regression, Random Forest, XGBoost, and LightGBM, ultimately selecting the LightGBM model to achieve a recall rate of 95.45% and an AUC of 99.84%. Wrote efficient and maintainable code, enhancing model training and data processing efficiency through parallel computing and logging. ü§ñ Multi-Model Intelligent Text Keyword Extraction System 08/2023 ‚Äì 09/2023 Group project, supervised by Associate Prof. Xiaolin Zhao Designed and implemented an intelligent text summary system that automatically extracts keywords from article titles and abstracts, enhancing the understanding and summarization of text information. Participated in the planning of the technical route and built a hybrid model combining extractive and generative approaches, utilizing advanced natural language processing techniques including KeyBERT, Sentence Transformer, BERT, and T5 models. Responsible for data preprocessing and tokenization, as well as the end-to-end implementation and training of the T5 model, optimizing the model architecture and hyperparameters, achieving satisfactory results after only 3 epochs of training. Model evaluation results showed that the Rouge-1, Rouge-2, and Rouge-L metrics reached 0.6345, 0.5038, and 0.5282, respectively, in the third epoch, validating the model\u0026rsquo;s effectiveness in the summarization task. üéì Cambridge University Machine Learning Summer Project 07/2023 ‚Äì 08/2023 Group project, supervised by Prof. Pietro Li√≤ Participated in the Cambridge University deep learning summer project, focusing on deep reinforcement learning; explored multi-agent learning algorithms across different environments. Reproduced the Multi-Agent Deep Deterministic Policy Gradient (MADDPG) algorithm in the Simple Adversary environment and studied the effect of agent numbers on convergence speed and stability, finding optimal stability at 21 agents. Designed and implemented comparative experiments inspired by the Rainbow algorithm, assessing target network strategies versus the Double Deep Q-Network (Double DQN). The results demonstrated that Double DQN significantly enhanced convergence speed, optimizing the overall learning process. Co-authored a group project paper on agent numbers and strategies effectiveness in multi-agent systems, achieving a score of 71% in the summer program (the highest in my group) and a \u0026ldquo;First Class\u0026rdquo; classification in the UK grading system. üëÅÔ∏è Deep Learning and Computer Vision Semester Project 09/2022 ‚Äì 12/2022 Independent project, supervised by Associate Prof. Guangyu Gao Designed and implemented a waste classifier using the ResNet model to improve classification accuracy and reduce resource waste. The project also enhanced understanding of transfer learning techniques with ResNet. Collected a dataset of 16 waste categories and preprocessed the images for uniformity and standardization, incorporating data augmentation techniques to enhance the dataset. Conducted experiments using ResNet34 and ResNet50 models through transfer learning, accelerating network convergence by leveraging pretrained weights. During training, techniques such as Batch Normalization and Dropout were applied to mitigate the risk of overfitting. The final model achieved an accuracy of 90% on the training set, while the performance on the test set was 61%, indicating a significant overfitting phenomenon during the training process. üéì Internship ‚öõÔ∏è Beijing Academy of Quantum Information Science 08/2023 ‚Äì 01/2024 Research Intern at Quantum Computation Department Proposed a quantum convolution kernel design based on variational quantum circuits and developed a universal quantum convolution layer, successfully integrating it into classical CNN architectures such as VGG, GoogLeNet, and ResNet. Developed and evaluated various hybrid models, including a simple model named HQCCNN-2, which achieved 84.45% accuracy on the FashionMNIST dataset, surpassing the traditional CNN\u0026rsquo;s 80.72%. This demonstrates the effectiveness of the quantum convolution layer in improving model performance. Tested on a real quantum computer further validated the effectiveness of the hybrid model, demonstrating the viable integration of quantum computing with deep learning, and highlighting the potential for leveraging quantum properties to enhance model performance. üèÖ Competition Experience ü•â China International \u0026#34;Internet \u0026#43;\u0026#34; College Students\u0026#39; Innovation Competition 08/2022 üõ°Ô∏è Zhongke Ushield: Deep Learning-based Face Privacy Protection Authentication System Responsible for constructing a localized facial feature extraction engine based on MobileFaceNet, ensuring feature extraction is completed on end devices (such as mobile phones and cameras), guaranteeing that raw data does not leave the domain and is not stored, thus enhancing user privacy protection while improving recognition efficiency. ü•â \u0026#34;Challenge Cup\u0026#34; Capital University Entrepreneurship Competition 05/2022 üå≥ Smart Orchard Responsible for the development of the fruit detection, ripeness prediction, and pest identification system, using deep convolutional neural network (CNN) technology for intelligent monitoring of crop growth conditions. Applied advanced object detection algorithms such as Faster R-CNN and YOLO to achieve high precision in apple detection and ripeness assessment, with an accuracy rate exceeding 90%, significantly enhancing the intelligence level of orchard management. Built and trained a dedicated dataset containing various pest samples, optimizing pest detection accuracy through data preprocessing (such as image normalization and resizing) and data augmentation techniques (like rotation, flipping, and noise addition), enabling the real-time monitoring system to accurately identify over 80% of pests, providing effective scientific maintenance recommendations to help farmers reduce crop losses. üìã Extracurricular Activities Vice President, Cyber Security Club, Beijing Institute of Technology 09/2021-09/2022 Backbone, Media Center of the Student Union of Beijing Institute of Technology 10/2020-06/2021 üì´ Contact üìß Email: zongsi.xu@outlook.com üëî LinkedIn: Zongsi (Tristan) Xu üíª GitHub: BaizeXS üìç Location: Hong Kong SAR, China ","permalink":"http://localhost:1313/resume/","summary":"Personal resume of Zongsi (Tristan) Xu","title":"Zongsi (Tristan) Xu"},{"content":"‰∏Ä„ÄÅÊï∞ÂÄºÁâπÂæÅ‰∏éÁ±ªÂà´ÁâπÂæÅ Êï∞ÂÄºÁâπÂæÅ (Numeric Features) ÂÖ∑ÊúâÂèØÂä†ÂáèÁöÑÊÑè‰πâÔºå‰∏îÂ≠òÂú®Â§ßÂ∞èÈ°∫Â∫è„ÄÇ ‰æãÂ≠êÔºöÂπ¥ÈæÑ„ÄÅÊ∏©Â∫¶Á≠â„ÄÇÂèØ‰ª•Áõ¥Êé•‰øùÁïôÂÖ∂Êï¥Êï∞ÊàñÊµÆÁÇπÊï∞ÂΩ¢Âºè‰æõÊ®°Âûã‰ΩøÁî®„ÄÇ Á±ªÂà´ÁâπÂæÅ (Categorical Features) Êï∞ÊçÆÂÄºÁ¶ªÊï£Ôºå‰∏çÂÖ∑Â§á‚ÄúÊï∞ÂÄºÂ§ßÂ∞è‚ÄùÈó¥ÁöÑÂèØÊØîÊÑè‰πâ„ÄÇ ‰æãÂ≠êÔºöÂõΩÁ±çÔºàÁæéÂõΩ/‰∏≠ÂõΩ/Âç∞Â∫¶Á≠âÔºâ„ÄÅÊÄßÂà´ÔºàÁî∑/Â•≥ÔºâÁ≠â„ÄÇ ÈóÆÈ¢òÔºöËã•‰ªÖÁî®Êï¥Êï∞Ë°®Á§∫ÔºàÁæéÂõΩ=1, ‰∏≠ÂõΩ=2ÔºâÔºå‰ºöÂºïÂÖ•ÈîôËØØÁöÑÊï∞ÂÄºËøêÁÆóÂÖ≥Á≥ªÔºåÂ¶Ç ‚ÄúÁæéÂõΩ + ‰∏≠ÂõΩ = Âç∞Â∫¶‚Äù„ÄÇ ‰∫å„ÄÅOne-HotÁºñÁ†ÅÁöÑÂä®Êú∫‰∏éÊµÅÁ®ã ‰∏∫‰ªÄ‰πà‰ΩøÁî®One-Hot\nÈÄöËøáÂ∞ÜÁ±ªÂà´Êò†Â∞Ñ‰∏∫ÂêëÈáèÔºåÈÅøÂÖçÊï¥Êï∞ÁºñÁ†ÅÂºïÂÖ•ÁöÑ‰º™Êï∞ÂÄºÂÖ≥Á≥ª„ÄÇ ÂêåÊó∂‰øùÁïôÂêÑÁßçÂèØËÉΩÁ±ªÂà´ÁöÑ‰ø°ÊÅØÔºå‰∏î‰ªÖÂú®ÂØπÂ∫î‰ΩçÁΩÆ‰∏∫1ÔºåÂÖ∂‰ªñ‰ΩçÁΩÆ‰∏∫0„ÄÇ Âª∫Á´ãÊò†Â∞ÑÔºö‰ªéÁ±ªÂà´Âà∞Á¥¢Âºï\n‰∏∫ÊØè‰∏™Á±ªÂà´ÂàÜÈÖç‰∏Ä‰∏™ÂîØ‰∏ÄÁ¥¢ÂºïÔºåÈÄöÂ∏∏‰ªé1ÂºÄÂßã„ÄÇ È¢ÑÁïôÁ¥¢Âºï0Ë°®Á§∫‚ÄúÊú™Áü•‚ÄùÊàñ‚ÄúÁº∫Â§±‚ÄùÔºåÂØπÂ∫îÂÖ®0ÂêëÈáè„ÄÇ ËΩ¨Êç¢‰∏∫One-HotÂêëÈáè\nËã•Á±ªÂà´ÊÄªÊï∞‰∏∫197ÔºåÂàôÁî®197Áª¥ÂêëÈáèË°®Á§∫„ÄÇ ‰æãÂ≠êÔºöÁæéÂõΩ [1, 0, 0, 0, ‚Ä¶]Ôºå ‰∏≠ÂõΩ [0, 1, 0, 0, ‚Ä¶]„ÄÇ Á§∫‰æãÔºöË°®Á§∫‰∏Ä‰∏™‰∫∫ÁöÑÁâπÂæÅ\nÁâπÂæÅÂåÖÂê´ÔºàÂπ¥ÈæÑ, ÊÄßÂà´, ÂõΩÁ±çÔºåÂÖ∂‰∏≠ÂõΩÁ±ç197ÁßçÔºâ Áª¥Â∫¶ÊÄªÂíåÔºö1Áª¥_age + 1Áª¥_gender + 197Áª¥_nationality = 199Áª¥„ÄÇ ‰æãÂ¶Ç (28, Â•≥, ‰∏≠ÂõΩ) ‚Üí [28, 0, 0, 1, 0, ‚Ä¶, 0]„ÄÇ ‰∏â„ÄÅÊñáÊú¨Êï∞ÊçÆÂ§ÑÁêÜÊµÅÁ®ã ÊñáÊú¨Âú®Ëá™ÁÑ∂ËØ≠Ë®ÄÂ§ÑÁêÜÔºàNLPÔºâ‰∏≠‰Ωú‰∏∫Â∏∏ËßÅÁöÑÂéüÂßãËæìÂÖ•ÔºåÈúÄË¶ÅÊï∞ÂÄºÂåñÊâçËÉΩÈÄÅÂÖ•Ê®°Âûã„ÄÇ‰∏ÄËà¨Ê≠•È™§Â¶Ç‰∏ãÔºö\nÂàÜËØç (Tokenization)\nÂ∞ÜÊñáÊú¨ÊãÜÂàÜ‰∏∫‰∏Ä‰∏™‰∏™ÂçïËØçÔºàTokenÔºâ„ÄÇ ‰æãÂ≠êÔºö\u0026quot;... to be or not to be...\u0026quot; ‚Üí [\u0026quot;...\u0026quot;, \u0026quot;to\u0026quot;, \u0026quot;be\u0026quot;, \u0026quot;or\u0026quot;, \u0026quot;not\u0026quot;, \u0026quot;to\u0026quot;, \u0026quot;be\u0026quot;, \u0026quot;...\u0026quot;]„ÄÇ ÁªüËÆ°ËØçÈ¢ë \u0026amp; ÊûÑÂª∫ËØçÂÖ∏\nËØçÈ¢ëÁªüËÆ° Áî®ÂìàÂ∏åË°®/Â≠óÂÖ∏ËÆ∞ÂΩïÊØè‰∏™ÂçïËØçÂá∫Áé∞Ê¨°Êï∞„ÄÇ ÈÅçÂéÜÊñáÊú¨Êó∂ÔºåËã•ÂçïËØçÂ∞öÊú™ÂÖ•Ë°®ÔºåÂàôÊñ∞Âª∫ËÆ∞ÂΩïÔºõËã•Â∑≤Â≠òÂú®ÔºåÂàôËÆ°Êï∞+1„ÄÇ ÊéíÂ∫è‰∏éÁ¥¢Âºï ÊåâËØçÈ¢ëÈôçÂ∫èÊéíÂ∫èÔºåËØçÈ¢ëÊúÄÈ´òÁöÑÂçïËØçÊéíÂú®ÂâçÈù¢„ÄÇ Á¥¢Âºï‰ªé1ÂºÄÂßãÔºå0ÁïôÁªô‚ÄúÊú™Áü•‚Äù„ÄÇ ËØçÂÖ∏ËßÑÊ®°ÔºàvocabularyÔºâÂèØËßÜÈúÄÊ±ÇÊà™Êñ≠Ôºà‰æãÂ¶ÇÂè™‰øùÁïôTop 10kÔºâ„ÄÇ ‰∏∫‰ªÄ‰πàÁßªÈô§‰ΩéÈ¢ëËØç ‰ΩéÈ¢ëËØçÂèØËÉΩÊòØÊãºÂÜôÈîôËØØ„ÄÅÁΩïËßÅ‰∫∫ÂêçÁ≠âÔºåÂØπÊ®°ÂûãÂ∏ÆÂä©ÊúâÈôê„ÄÇ ÂáèÂ∞ëËØçÂÖ∏ËßÑÊ®°ÂèØÈôç‰ΩéËøêÁÆóÂºÄÈîÄ„ÄÅÂä†Âø´Ê®°ÂûãËÆ≠ÁªÉ‰∏éÊé®ÁêÜÈÄüÂ∫¶„ÄÇ Áã¨ÁÉ≠ÁºñÁ†Å (One-Hot Encoding)\nÂ∞ÜÊØè‰∏™ÂçïËØçÊò†Â∞Ñ‰∏∫ËØçÂÖ∏‰∏≠ÁöÑÁ¥¢ÂºïÂêéÔºàÂ¶Ç [2, 4, 1, 8, ‚Ä¶]ÔºâÔºåÂèØËøõ‰∏ÄÊ≠•ËΩ¨Êç¢ÊàêOne-HotÂêëÈáè„ÄÇ One-HotÁª¥Â∫¶ÂèñÂÜ≥‰∫é‰øùÁïô‰∏ãÊù•ÁöÑËØçÂÖ∏Â§ßÂ∞èÔºà‰æãÂ¶Ç1‰∏áÔºâ„ÄÇ Êú™Êî∂ÂΩïÂçïËØçÂèØËÉΩÁõ¥Êé•ÂøΩÁï•ÔºåÊàñÁªü‰∏ÄÁî®Á¥¢Âºï0‰ª£Êõø„ÄÇ Âõõ„ÄÅÊ†∏ÂøÉÊî∂Ëé∑‰∏éÂ∫îÁî® Á±ªÂà´ÁâπÂæÅÂøÖÈúÄÊï∞ÂÄºÂåñÔºö\n‰ΩøÁî®Êï¥Êï∞1,2,3‚Ä¶‰ªÖË°®Á§∫Á±ªÂà´‚ÄúÊ†áËØÜ‚ÄùÔºåÂπ∂‰∏ç‰ª£Ë°®ÂÆÉ‰ª¨ÂèØËøõË°åÊï∞ÂÄºËøêÁÆó„ÄÇ Âõ†Ê≠§ÈúÄË¶ÅOne-HotÁ≠âÁºñÁ†ÅÊñπÂºèÔºåÈÅøÂÖçÊï∞ÂÄºËØØËß£„ÄÇ ÊñáÊú¨Êï∞ÊçÆÈ¢ÑÂ§ÑÁêÜÔºö\nÂàÜËØç„ÄÅËØçÈ¢ëÁªüËÆ°„ÄÅÊûÑÂª∫ËØçÂÖ∏„ÄÅÁ¥¢ÂºïÂåñ„ÄÅOne-HotÊàñÂÖ∂‰ªñÊñπÂºèÔºàÂ¶ÇËØçÂµåÂÖ•ÔºâÊòØÂ∏∏ËßÅÊµÅÁ®ã„ÄÇ Ê≠£Á°ÆÁöÑÊñáÊú¨È¢ÑÂ§ÑÁêÜÂèØÊòæËëóÂΩ±ÂìçÊ®°ÂûãÊÄßËÉΩÂíåÊïàÁéá„ÄÇ ‰øùÁïôÊú™Áü•Á¥¢ÂºïÔºö\n‰øùËØÅÂØπÁº∫Â§±Êï∞ÊçÆÊàñÂ≠óÂÖ∏Â§ñÊñ∞ËØçËÉΩÊúâÂü∫Êú¨ÁöÑË°®Á§∫ÔºåÊèêÂçáÊ®°ÂûãÂÆπÈîôÊÄß„ÄÇ ÂÆûÈôÖ‰ΩøÁî®Ôºö\nÂØπ‰∫éÂ∞èËßÑÊ®°Á±ªÂà´ÂèØÁõ¥Êé•One-HotÁºñÁ†ÅÔºõÂØπ‰∫éËØçÂÖ∏ÂæàÂ§ßÁöÑÂú∫ÊôØÔºåÈÄöÂ∏∏‰ºöËøõ‰∏ÄÊ≠•ËÄÉËôëËØçÂµåÂÖ•ÔºàWord EmbeddingÔºâÊàñÈ¢ÑËÆ≠ÁªÉËØ≠Ë®ÄÊ®°Âûã„ÄÇ ","permalink":"http://localhost:1313/posts/nlp-1/","summary":"\u003ch2 id=\"‰∏ÄÊï∞ÂÄºÁâπÂæÅ‰∏éÁ±ªÂà´ÁâπÂæÅ\"\u003e‰∏Ä„ÄÅÊï∞ÂÄºÁâπÂæÅ‰∏éÁ±ªÂà´ÁâπÂæÅ\u003c/h2\u003e\n\u003col\u003e\n\u003cli\u003e\u003cstrong\u003eÊï∞ÂÄºÁâπÂæÅ (Numeric Features)\u003c/strong\u003e\n\u003cul\u003e\n\u003cli\u003eÂÖ∑ÊúâÂèØÂä†ÂáèÁöÑÊÑè‰πâÔºå‰∏îÂ≠òÂú®Â§ßÂ∞èÈ°∫Â∫è„ÄÇ\u003c/li\u003e\n\u003cli\u003e‰æãÂ≠êÔºöÂπ¥ÈæÑ„ÄÅÊ∏©Â∫¶Á≠â„ÄÇÂèØ‰ª•Áõ¥Êé•‰øùÁïôÂÖ∂Êï¥Êï∞ÊàñÊµÆÁÇπÊï∞ÂΩ¢Âºè‰æõÊ®°Âûã‰ΩøÁî®„ÄÇ\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003eÁ±ªÂà´ÁâπÂæÅ (Categorical Features)\u003c/strong\u003e\n\u003cul\u003e\n\u003cli\u003eÊï∞ÊçÆÂÄºÁ¶ªÊï£Ôºå‰∏çÂÖ∑Â§á‚ÄúÊï∞ÂÄºÂ§ßÂ∞è‚ÄùÈó¥ÁöÑÂèØÊØîÊÑè‰πâ„ÄÇ\u003c/li\u003e\n\u003cli\u003e‰æãÂ≠êÔºöÂõΩÁ±çÔºàÁæéÂõΩ/‰∏≠ÂõΩ/Âç∞Â∫¶Á≠âÔºâ„ÄÅÊÄßÂà´ÔºàÁî∑/Â•≥ÔºâÁ≠â„ÄÇ\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003eÈóÆÈ¢ò\u003c/strong\u003eÔºöËã•‰ªÖÁî®Êï¥Êï∞Ë°®Á§∫ÔºàÁæéÂõΩ=1, ‰∏≠ÂõΩ=2ÔºâÔºå‰ºöÂºïÂÖ•ÈîôËØØÁöÑÊï∞ÂÄºËøêÁÆóÂÖ≥Á≥ªÔºåÂ¶Ç ‚ÄúÁæéÂõΩ + ‰∏≠ÂõΩ = Âç∞Â∫¶‚Äù„ÄÇ\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003c/ol\u003e\n\u003ch2 id=\"‰∫åone-hotÁºñÁ†ÅÁöÑÂä®Êú∫‰∏éÊµÅÁ®ã\"\u003e‰∫å„ÄÅOne-HotÁºñÁ†ÅÁöÑÂä®Êú∫‰∏éÊµÅÁ®ã\u003c/h2\u003e\n\u003col\u003e\n\u003cli\u003e\n\u003cp\u003e\u003cstrong\u003e‰∏∫‰ªÄ‰πà‰ΩøÁî®One-Hot\u003c/strong\u003e\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eÈÄöËøáÂ∞ÜÁ±ªÂà´Êò†Â∞Ñ‰∏∫ÂêëÈáèÔºåÈÅøÂÖçÊï¥Êï∞ÁºñÁ†ÅÂºïÂÖ•ÁöÑ‰º™Êï∞ÂÄºÂÖ≥Á≥ª„ÄÇ\u003c/li\u003e\n\u003cli\u003eÂêåÊó∂‰øùÁïôÂêÑÁßçÂèØËÉΩÁ±ªÂà´ÁöÑ‰ø°ÊÅØÔºå‰∏î‰ªÖÂú®ÂØπÂ∫î‰ΩçÁΩÆ‰∏∫1ÔºåÂÖ∂‰ªñ‰ΩçÁΩÆ‰∏∫0„ÄÇ\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003e\u003cstrong\u003eÂª∫Á´ãÊò†Â∞ÑÔºö‰ªéÁ±ªÂà´Âà∞Á¥¢Âºï\u003c/strong\u003e\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e‰∏∫ÊØè‰∏™Á±ªÂà´ÂàÜÈÖç‰∏Ä‰∏™ÂîØ‰∏ÄÁ¥¢ÂºïÔºåÈÄöÂ∏∏‰ªé1ÂºÄÂßã„ÄÇ\u003c/li\u003e\n\u003cli\u003eÈ¢ÑÁïôÁ¥¢Âºï0Ë°®Á§∫‚ÄúÊú™Áü•‚ÄùÊàñ‚ÄúÁº∫Â§±‚ÄùÔºåÂØπÂ∫îÂÖ®0ÂêëÈáè„ÄÇ\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003e\u003cstrong\u003eËΩ¨Êç¢‰∏∫One-HotÂêëÈáè\u003c/strong\u003e\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eËã•Á±ªÂà´ÊÄªÊï∞‰∏∫197ÔºåÂàôÁî®197Áª¥ÂêëÈáèË°®Á§∫„ÄÇ\u003c/li\u003e\n\u003cli\u003e‰æãÂ≠êÔºöÁæéÂõΩ \u003ccode\u003e[1, 0, 0, 0, ‚Ä¶]\u003c/code\u003eÔºå ‰∏≠ÂõΩ \u003ccode\u003e[0, 1, 0, 0, ‚Ä¶]\u003c/code\u003e„ÄÇ\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003e\u003cstrong\u003eÁ§∫‰æãÔºöË°®Á§∫‰∏Ä‰∏™‰∫∫ÁöÑÁâπÂæÅ\u003c/strong\u003e\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eÁâπÂæÅÂåÖÂê´ÔºàÂπ¥ÈæÑ, ÊÄßÂà´, ÂõΩÁ±çÔºåÂÖ∂‰∏≠ÂõΩÁ±ç197ÁßçÔºâ\u003c/li\u003e\n\u003cli\u003eÁª¥Â∫¶ÊÄªÂíåÔºö1Áª¥_age + 1Áª¥_gender + 197Áª¥_nationality = 199Áª¥„ÄÇ\u003c/li\u003e\n\u003cli\u003e‰æãÂ¶Ç \u003ccode\u003e(28, Â•≥, ‰∏≠ÂõΩ)\u003c/code\u003e ‚Üí \u003ccode\u003e[28, 0, 0, 1, 0, ‚Ä¶, 0]\u003c/code\u003e„ÄÇ\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003c/ol\u003e\n\u003ch2 id=\"‰∏âÊñáÊú¨Êï∞ÊçÆÂ§ÑÁêÜÊµÅÁ®ã\"\u003e‰∏â„ÄÅÊñáÊú¨Êï∞ÊçÆÂ§ÑÁêÜÊµÅÁ®ã\u003c/h2\u003e\n\u003cp\u003eÊñáÊú¨Âú®Ëá™ÁÑ∂ËØ≠Ë®ÄÂ§ÑÁêÜÔºàNLPÔºâ‰∏≠‰Ωú‰∏∫Â∏∏ËßÅÁöÑÂéüÂßãËæìÂÖ•ÔºåÈúÄË¶ÅÊï∞ÂÄºÂåñÊâçËÉΩÈÄÅÂÖ•Ê®°Âûã„ÄÇ‰∏ÄËà¨Ê≠•È™§Â¶Ç‰∏ãÔºö\u003c/p\u003e\n\u003col\u003e\n\u003cli\u003e\n\u003cp\u003e\u003cstrong\u003eÂàÜËØç (Tokenization)\u003c/strong\u003e\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eÂ∞ÜÊñáÊú¨ÊãÜÂàÜ‰∏∫‰∏Ä‰∏™‰∏™ÂçïËØçÔºàTokenÔºâ„ÄÇ\u003c/li\u003e\n\u003cli\u003e‰æãÂ≠êÔºö\u003ccode\u003e\u0026quot;... to be or not to be...\u0026quot;\u003c/code\u003e ‚Üí \u003ccode\u003e[\u0026quot;...\u0026quot;, \u0026quot;to\u0026quot;, \u0026quot;be\u0026quot;, \u0026quot;or\u0026quot;, \u0026quot;not\u0026quot;, \u0026quot;to\u0026quot;, \u0026quot;be\u0026quot;, \u0026quot;...\u0026quot;]\u003c/code\u003e„ÄÇ\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003e\u003cstrong\u003eÁªüËÆ°ËØçÈ¢ë \u0026amp; ÊûÑÂª∫ËØçÂÖ∏\u003c/strong\u003e\u003c/p\u003e","title":""},{"content":"Text to Sequence ÊñáÊú¨Â§ÑÁêÜ\nStep1: Tokenization\nTokenization breaks a piece of text down into a list of tokens.\nHere, a token is a word. (A token can be a character in some applications.)\nTokenizationËÆ≤Á©∂ÂæàÂ§öÔºå‰æãÂ¶ÇÊòØÂê¶Â∫îËØ•ÊääÂ§ßÂÜôÊîπÊàêÂ∞èÂÜôÂë¢ÔºüËøõË°åtypo correctionÁ≠âÁ≠â\nStep2: Build Dictionary\nUse a dictionary (hash table) to count word frequencies.\nThe dictionary maps word to index.\nÂèØ‰ª•È¶ñÂÖàÁªüËÆ°ËØçÈ¢ëÂéªÊéâ‰ΩéÈ¢ëËØçÔºåÁÑ∂ÂêéËÆ©ÊØè‰∏™ËØçÂØπÂ∫î‰∏Ä‰∏™Ê≠£Êï¥Êï∞ÔºõËøôÊ†∑ÁöÑËØùÔºå‰∏ÄÂè•ËØùÂ∞±ÂèØ‰ª•Áî®‰∏Ä‰∏™Ê≠£Êï¥Êï∞ÂàóË°®Ë°®Á§∫ÔºåËøô‰∏™ÂàóË°®Â∞±Âè´sequenceÔºõÂ¶ÇÊûúÂøÖË¶ÅÂ∞±ËøòÂæóÂÅöone-hot encoding„ÄÇ\nÁªìÊûú\n‰ΩÜÊòØÈïøÂ∫¶‰∏çÁªü‰∏Ä\nStep4: ÂØπÈΩêsequence\nËß£ÂÜ≥ÊñπÊ°àÊòØËøôÊ†∑ÁöÑÔºöÂèØ‰ª•Âõ∫ÂÆöÈïøÂ∫¶‰∏∫wÔºåÂä†ÂÖ•‰∏Ä‰∏™Â∫èÂàóÈïøÂ∫¶Â§™ÈïøÔºåÂ∞±Á†çÊéâÂâçÈù¢ÁöÑËØçÔºåÂè™‰øùÁïôÊúÄÂêéw‰∏™ËØçÔºõÂ¶ÇÊûú‰∏Ä‰∏™Â∫èÂàóÂ§™Áü≠ÔºåÂ∞±ÂÅözero paddingÔºåÁî®0Â°´ÂÖÖ\nËøôÊ†∑‰∏ÄÊù•ÔºåÊâÄÊúâÁöÑÂ∫èÂàóÈïøÂ∫¶Â∞±Áªü‰∏Ä‰∫Ü\nÊñáÊú¨Â§ÑÁêÜÂÆåÊàê‰∫ÜÔºåÊé•‰∏ãÊù•ÊòØword embeddingÔºåÊääÂçïËØçË°®Á§∫‰∏∫‰∏Ä‰∏™‰ΩéÁª¥ÂêëÈáèÔºõ\nÁÑ∂ËÄåËøôÊ†∑ÂÅöÁöÑËØùÔºåÂ¶ÇÊûúÊòØ10000‰∏™ÂçïËØçÔºåÁª¥Â∫¶Â∞±ÊòØ10000Áª¥ÔºåÁª¥Â∫¶Â§™È´ò‰∫ÜÔºõÂõ†Ê≠§Ë¶ÅÂÅöword embeddingÔºõ\nÂÖ∑‰ΩìÂÅöÊ≥ïÂ∞±ÊòØÊääone-hotÂêëÈáèe_iÂíåÂèÇÊï∞Áü©ÈòµpÁõ∏‰πòÔºõÁü©ÈòµPËΩ¨ÁΩÆÁöÑÂ§ßÂ∞èÊòØd x vÔºõdÊòØËØçÂêëÈáèÁöÑÁª¥Â∫¶ÔºõvÊòØÂ≠óÂÖ∏ÈáåËØçÊ±áÁöÑÊï∞ÈáèÔºõÁªìÊûú‰∏∫x_iÔºõx_iÂ∞±ÊòØ‰∏Ä‰∏™ËØçÂêëÈáèÔºõÂ¶ÇÊûúone-hotÂêëÈáèÁöÑÁ¨¨‰∏âË°å‰∏∫1ÔºõÈÇ£‰πàx_iÂ∞±ÊòØPËΩ¨ÁΩÆÁü©ÈòµÁöÑÁ¨¨‰∏âÂàóÔºàÂÖ∂‰ΩôÂàóÈÉΩ‰∏∫0ÔºâÔºõÊâÄ‰ª•PËΩ¨ÁΩÆÊØè‰∏ÄÂàóÈÉΩÊòØ‰∏Ä‰∏™ËØçÂêëÈáèÔºõÊâÄ‰ª•Áü©ÈòµPÊú¨Ë∫´ÁöÑÊØè‰∏ÄË°åÂ∞±ÊòØ‰∏Ä‰∏™ËØçÂêëÈáèÔºõÂÖ∂Ë°åÊï∞‰∏∫vÔºõÂç≥vocabularyÔºåËØçÊ±áÈáèÔºõÊØè‰∏ÄË°åÂØπÂ∫î‰∏Ä‰∏™ÂçïËØçÔºõÁü©ÈòµÁöÑÂàóÊï∞‰∏∫dÔºõdÊòØÁî®Êà∑ÂÜ≥ÂÆöÁöÑÔºõdÁöÑÂ§ßÂ∞è‰ºöÂÜ≥ÂÆöÊú∫Âô®Â≠¶‰π†Ê®°ÂûãÁöÑË°®Áé∞ÔºõÂ∫îËØ•Áî®xxxÊù•ÈÄâÊã©‰∏Ä‰∏™ÊØîËæÉÂ•ΩÁöÑdÔºõ\nÊàë‰ª¨ÁöÑ‰ªªÂä°ÊòØÁúãËØÑËÆ∫ÊòØÊ≠£Èù¢ÁöÑËøòÊòØË¥üÈù¢ÁöÑÔºõÂèÇÊï∞Áü©ÈòµÊòØ‰ªéËÆ≠ÁªÉÊï∞ÊçÆ‰∏≠Â≠¶‰π†Âá∫Êù•ÁöÑÔºåÊâÄ‰ª•Â≠¶Âá∫Êù•ÁöÑËØçÂêëÈáèÊòØÂ∏¶ÊúâÊÑüÊÉÖËâ≤ÂΩ©ÁöÑÔºõÂÅáËÆæËøô‰∫õËØçÂêëÈáèÈÉΩÊòØ‰∫åÁª¥ÁöÑÔºåÂàôÂèØ‰ª•Âú®Âπ≥Èù¢ÂùêÊ†áÁ≥ª‰∏≠Ê†áÂá∫‰∏ãÈù¢ËØçÂêëÈáè\nkerasÊèê‰æõembeddingÂ±ÇÔºõÁî®Êà∑ÂèØ‰ª•ÊåáÂÆövocabularyÂ§ßÂ∞èÂíådÁöÑÂ§ßÂ∞èÔºõ‰ª•ÂèäÊØè‰∏Ä‰∏™sequenceÁöÑÈïøÂ∫¶ÔºõdÊòØÊ†πÊçÆÁÆóÊ≥ïÈÄâÂá∫Êù•ÁöÑ Âà∞Ëøô‰∏ÄÊ≠•ÔºåÊàë‰ª¨Â∑≤ÁªèÂÆåÊàê‰∫ÜÊñáÊú¨Â§ÑÁêÜÂíåword embedding„ÄÇÊé•‰∏ãÊù•Â∞±ÊòØÁî®Logistic Regression for Binary ClassificationÂÅö‰∫åÂàÜÁ±ªÔºõ\n","permalink":"http://localhost:1313/posts/nlp-2/","summary":"\u003ch3 id=\"text-to-sequence\"\u003eText to Sequence\u003c/h3\u003e\n\u003cp\u003eÊñáÊú¨Â§ÑÁêÜ\u003c/p\u003e\n\u003cp\u003eStep1: Tokenization\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\n\u003cp\u003eTokenization breaks a piece of text down into a list of tokens.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003eHere, a token is a word. (A token can be a character in some applications.)\u003c/p\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003eTokenizationËÆ≤Á©∂ÂæàÂ§öÔºå‰æãÂ¶ÇÊòØÂê¶Â∫îËØ•ÊääÂ§ßÂÜôÊîπÊàêÂ∞èÂÜôÂë¢ÔºüËøõË°åtypo correctionÁ≠âÁ≠â\u003c/p\u003e\n\u003cp\u003e\u003cimg alt=\"image-20250322150322238\" loading=\"lazy\" src=\"./NLP-2.assets/image-20250322150322238.png\"\u003e\u003c/p\u003e\n\u003cp\u003eStep2: Build Dictionary\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\n\u003cp\u003eUse a dictionary (hash table) to count word frequencies.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003eThe dictionary maps word to index.\u003c/p\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003eÂèØ‰ª•È¶ñÂÖàÁªüËÆ°ËØçÈ¢ëÂéªÊéâ‰ΩéÈ¢ëËØçÔºåÁÑ∂ÂêéËÆ©ÊØè‰∏™ËØçÂØπÂ∫î‰∏Ä‰∏™Ê≠£Êï¥Êï∞ÔºõËøôÊ†∑ÁöÑËØùÔºå‰∏ÄÂè•ËØùÂ∞±ÂèØ‰ª•Áî®‰∏Ä‰∏™Ê≠£Êï¥Êï∞ÂàóË°®Ë°®Á§∫ÔºåËøô‰∏™ÂàóË°®Â∞±Âè´sequenceÔºõÂ¶ÇÊûúÂøÖË¶ÅÂ∞±ËøòÂæóÂÅöone-hot encoding„ÄÇ\u003cimg alt=\"image-20250322150620890\" loading=\"lazy\" src=\"./NLP-2.assets/image-20250322150620890.png\"\u003e\u003c/p\u003e\n\u003cp\u003eÁªìÊûú\u003c/p\u003e\n\u003cp\u003e\u003cimg alt=\"image-20250322150754528\" loading=\"lazy\" src=\"./NLP-2.assets/image-20250322150754528.png\"\u003e\u003c/p\u003e\n\u003cp\u003e‰ΩÜÊòØÈïøÂ∫¶‰∏çÁªü‰∏Ä\u003c/p\u003e\n\u003cp\u003eStep4: ÂØπÈΩêsequence\u003c/p\u003e\n\u003cp\u003e\u003cimg alt=\"image-20250322150854986\" loading=\"lazy\" src=\"./NLP-2.assets/image-20250322150854986.png\"\u003e\u003c/p\u003e\n\u003cp\u003eËß£ÂÜ≥ÊñπÊ°àÊòØËøôÊ†∑ÁöÑÔºöÂèØ‰ª•Âõ∫ÂÆöÈïøÂ∫¶‰∏∫wÔºåÂä†ÂÖ•‰∏Ä‰∏™Â∫èÂàóÈïøÂ∫¶Â§™ÈïøÔºåÂ∞±Á†çÊéâÂâçÈù¢ÁöÑËØçÔºåÂè™‰øùÁïôÊúÄÂêéw‰∏™ËØçÔºõÂ¶ÇÊûú‰∏Ä‰∏™Â∫èÂàóÂ§™Áü≠ÔºåÂ∞±ÂÅözero paddingÔºåÁî®0Â°´ÂÖÖ\u003c/p\u003e\n\u003cp\u003e\u003cimg alt=\"image-20250322151030119\" loading=\"lazy\" src=\"./NLP-2.assets/image-20250322151030119.png\"\u003e\u003c/p\u003e\n\u003cp\u003eËøôÊ†∑‰∏ÄÊù•ÔºåÊâÄÊúâÁöÑÂ∫èÂàóÈïøÂ∫¶Â∞±Áªü‰∏Ä‰∫Ü\u003c/p\u003e\n\u003cp\u003e\u003cimg alt=\"image-20250322151117125\" loading=\"lazy\" src=\"./NLP-2.assets/image-20250322151117125.png\"\u003e\u003c/p\u003e\n\u003cp\u003eÊñáÊú¨Â§ÑÁêÜÂÆåÊàê‰∫ÜÔºåÊé•‰∏ãÊù•ÊòØword embeddingÔºåÊääÂçïËØçË°®Á§∫‰∏∫‰∏Ä‰∏™‰ΩéÁª¥ÂêëÈáèÔºõ\u003c/p\u003e\n\u003cp\u003e\u003cimg alt=\"image-20250322151252837\" loading=\"lazy\" src=\"./NLP-2.assets/image-20250322151252837.png\"\u003e\u003c/p\u003e","title":""},{"content":"üëã About me Hello! I\u0026rsquo;m Xu Zongsi, a passionate technology enthusiast currently pursuing my Master of Science in ECIC at The University of Hong Kong. With a solid background in Software Engineering from the Beijing Institute of Technology, I specialize in artificial intelligence areas like machine learning, deep learning, natural language processing, computer vision, and reinforcement learning.\nInspired by OpenAI\u0026rsquo;s five-step plan towards superintelligence, I am excited about AGI and have developed a keen interest in LLM agents, MLLM, and knowledge graphs. I see great potential in these fields and aspire to contribute to innovative solutions.\nüìö Education üá≠üá∞ The University of Hong Kong 09/2024 - Expected 11/2025 School of Computing and Data Science Master of Science in Electronic Commerce \u0026amp; Internet Computing Relevant Courses: Machine learning for business and e-commerce, Knowledge graphs, Financial fraud analytics, Internet infrastructure technologies, Website engineering, Blockchain and cryptocurrency, etc. üá®üá≥ Beijing Institute of Technology 09/2020 - 06/2024 School of Computer Science \u0026amp; Technology Bachelor of Engineering in Software Engineering, last two years GPA: 3.7/4 Relevant Courses: Reinforcement Learning, Deep Learning and Computer Vision, Artificial Intelligence and Robot Ethics, Almost Human: Mind, Brain and Artificial Intelligence, Mathematical Analysis for Engineering, Linear Algebra, Probability and Mathematical Statistics, etc. Skills: Python, Java, common data structures, design patterns, machine learning basics and algorithms, Linux, PyTorch, and some development tools (git, conda, etc.). üèÜ Awards \u0026amp; Honors Beijing Institute of Technology Undergraduate Scholarship (Top 20% of Grade) 06/2023 3rd Prize of China International \u0026#34;Internet \u0026#43;\u0026#34; College Student\u0026#39;s Innovation Competition 08/2022 Bronze Prize of \u0026#34;Challenge Cup\u0026#34; Capital University Entrepreneurship Competition 05/2022 üíº Project Experience üîç Online Transaction Fraud Detection 09/2024 ‚Äì 01/2025 Independent project, supervised by Dr. Vivien Chan Focused on addressing financial fraud in e-commerce to enhance the accuracy of transaction anomaly detection, while independently managing the entire case study that included data preprocessing, feature engineering, model building, evaluation, and results analysis. Effectively resolved class imbalance issues using SMOTE and ROSE techniques. Built various models including Logistic Regression, Random Forest, XGBoost, and LightGBM, ultimately selecting the LightGBM model to achieve a recall rate of 95.45% and an AUC of 99.84%. Wrote efficient and maintainable code, enhancing model training and data processing efficiency through parallel computing and logging. ü§ñ Multi-Model Intelligent Text Keyword Extraction System 08/2023 ‚Äì 09/2023 Group project, supervised by Associate Prof. Xiaolin Zhao Designed and implemented an intelligent text summary system that automatically extracts keywords from article titles and abstracts, enhancing the understanding and summarization of text information. Participated in the planning of the technical route and built a hybrid model combining extractive and generative approaches, utilizing advanced natural language processing techniques including KeyBERT, Sentence Transformer, BERT, and T5 models. Responsible for data preprocessing and tokenization, as well as the end-to-end implementation and training of the T5 model, optimizing the model architecture and hyperparameters, achieving satisfactory results after only 3 epochs of training. Model evaluation results showed that the Rouge-1, Rouge-2, and Rouge-L metrics reached 0.6345, 0.5038, and 0.5282, respectively, in the third epoch, validating the model\u0026rsquo;s effectiveness in the summarization task. üéì Cambridge University Machine Learning Summer Project 07/2023 ‚Äì 08/2023 Group project, supervised by Prof. Pietro Li√≤ Participated in the Cambridge University deep learning summer project, focusing on deep reinforcement learning; explored multi-agent learning algorithms across different environments. Reproduced the Multi-Agent Deep Deterministic Policy Gradient (MADDPG) algorithm in the Simple Adversary environment and studied the effect of agent numbers on convergence speed and stability, finding optimal stability at 21 agents. Designed and implemented comparative experiments inspired by the Rainbow algorithm, assessing target network strategies versus the Double Deep Q-Network (Double DQN). The results demonstrated that Double DQN significantly enhanced convergence speed, optimizing the overall learning process. Co-authored a group project paper on agent numbers and strategies effectiveness in multi-agent systems, achieving a score of 71% in the summer program (the highest in my group) and a \u0026ldquo;First Class\u0026rdquo; classification in the UK grading system. üëÅÔ∏è Deep Learning and Computer Vision Semester Project 09/2022 ‚Äì 12/2022 Independent project, supervised by Associate Prof. Guangyu Gao Designed and implemented a waste classifier using the ResNet model to improve classification accuracy and reduce resource waste. The project also enhanced understanding of transfer learning techniques with ResNet. Collected a dataset of 16 waste categories and preprocessed the images for uniformity and standardization, incorporating data augmentation techniques to enhance the dataset. Conducted experiments using ResNet34 and ResNet50 models through transfer learning, accelerating network convergence by leveraging pretrained weights. During training, techniques such as Batch Normalization and Dropout were applied to mitigate the risk of overfitting. The final model achieved an accuracy of 90% on the training set, while the performance on the test set was 61%, indicating a significant overfitting phenomenon during the training process. üéì Internship ‚öõÔ∏è Beijing Academy of Quantum Information Science 08/2023 ‚Äì 01/2024 Research Intern at Quantum Computation Department Proposed a quantum convolution kernel design based on variational quantum circuits and developed a universal quantum convolution layer, successfully integrating it into classical CNN architectures such as VGG, GoogLeNet, and ResNet. Developed and evaluated various hybrid models, including a simple model named HQCCNN-2, which achieved 84.45% accuracy on the FashionMNIST dataset, surpassing the traditional CNN\u0026rsquo;s 80.72%. This demonstrates the effectiveness of the quantum convolution layer in improving model performance. Tested on a real quantum computer further validated the effectiveness of the hybrid model, demonstrating the viable integration of quantum computing with deep learning, and highlighting the potential for leveraging quantum properties to enhance model performance. üèÖ Competition Experience ü•â China International \u0026#34;Internet \u0026#43;\u0026#34; College Students\u0026#39; Innovation Competition 08/2022 üõ°Ô∏è Zhongke Ushield: Deep Learning-based Face Privacy Protection Authentication System Responsible for constructing a localized facial feature extraction engine based on MobileFaceNet, ensuring feature extraction is completed on end devices (such as mobile phones and cameras), guaranteeing that raw data does not leave the domain and is not stored, thus enhancing user privacy protection while improving recognition efficiency. ü•â \u0026#34;Challenge Cup\u0026#34; Capital University Entrepreneurship Competition 05/2022 üå≥ Smart Orchard Responsible for the development of the fruit detection, ripeness prediction, and pest identification system, using deep convolutional neural network (CNN) technology for intelligent monitoring of crop growth conditions. Applied advanced object detection algorithms such as Faster R-CNN and YOLO to achieve high precision in apple detection and ripeness assessment, with an accuracy rate exceeding 90%, significantly enhancing the intelligence level of orchard management. Built and trained a dedicated dataset containing various pest samples, optimizing pest detection accuracy through data preprocessing (such as image normalization and resizing) and data augmentation techniques (like rotation, flipping, and noise addition), enabling the real-time monitoring system to accurately identify over 80% of pests, providing effective scientific maintenance recommendations to help farmers reduce crop losses. üìã Extracurricular Activities Vice President, Cyber Security Club, Beijing Institute of Technology 09/2021-09/2022 Backbone, Media Center of the Student Union of Beijing Institute of Technology 10/2020-06/2021 üì´ Contact üìß Email: zongsi.xu@outlook.com üëî LinkedIn: Zongsi (Tristan) Xu üíª GitHub: BaizeXS üìç Location: Hong Kong SAR, China ","permalink":"http://localhost:1313/resume/","summary":"Personal resume of Zongsi (Tristan) Xu","title":"Zongsi (Tristan) Xu"},{"content":"‰∏Ä„ÄÅÊï∞ÂÄºÁâπÂæÅ‰∏éÁ±ªÂà´ÁâπÂæÅ Êï∞ÂÄºÁâπÂæÅ (Numeric Features) ÂÖ∑ÊúâÂèØÂä†ÂáèÁöÑÊÑè‰πâÔºå‰∏îÂ≠òÂú®Â§ßÂ∞èÈ°∫Â∫è„ÄÇ ‰æãÂ≠êÔºöÂπ¥ÈæÑ„ÄÅÊ∏©Â∫¶Á≠â„ÄÇÂèØ‰ª•Áõ¥Êé•‰øùÁïôÂÖ∂Êï¥Êï∞ÊàñÊµÆÁÇπÊï∞ÂΩ¢Âºè‰æõÊ®°Âûã‰ΩøÁî®„ÄÇ Á±ªÂà´ÁâπÂæÅ (Categorical Features) Êï∞ÊçÆÂÄºÁ¶ªÊï£Ôºå‰∏çÂÖ∑Â§á‚ÄúÊï∞ÂÄºÂ§ßÂ∞è‚ÄùÈó¥ÁöÑÂèØÊØîÊÑè‰πâ„ÄÇ ‰æãÂ≠êÔºöÂõΩÁ±çÔºàÁæéÂõΩ/‰∏≠ÂõΩ/Âç∞Â∫¶Á≠âÔºâ„ÄÅÊÄßÂà´ÔºàÁî∑/Â•≥ÔºâÁ≠â„ÄÇ ÈóÆÈ¢òÔºöËã•‰ªÖÁî®Êï¥Êï∞Ë°®Á§∫ÔºàÁæéÂõΩ=1, ‰∏≠ÂõΩ=2ÔºâÔºå‰ºöÂºïÂÖ•ÈîôËØØÁöÑÊï∞ÂÄºËøêÁÆóÂÖ≥Á≥ªÔºåÂ¶Ç ‚ÄúÁæéÂõΩ + ‰∏≠ÂõΩ = Âç∞Â∫¶‚Äù„ÄÇ ‰∫å„ÄÅOne-HotÁºñÁ†ÅÁöÑÂä®Êú∫‰∏éÊµÅÁ®ã ‰∏∫‰ªÄ‰πà‰ΩøÁî®One-Hot\nÈÄöËøáÂ∞ÜÁ±ªÂà´Êò†Â∞Ñ‰∏∫ÂêëÈáèÔºåÈÅøÂÖçÊï¥Êï∞ÁºñÁ†ÅÂºïÂÖ•ÁöÑ‰º™Êï∞ÂÄºÂÖ≥Á≥ª„ÄÇ ÂêåÊó∂‰øùÁïôÂêÑÁßçÂèØËÉΩÁ±ªÂà´ÁöÑ‰ø°ÊÅØÔºå‰∏î‰ªÖÂú®ÂØπÂ∫î‰ΩçÁΩÆ‰∏∫1ÔºåÂÖ∂‰ªñ‰ΩçÁΩÆ‰∏∫0„ÄÇ Âª∫Á´ãÊò†Â∞ÑÔºö‰ªéÁ±ªÂà´Âà∞Á¥¢Âºï\n‰∏∫ÊØè‰∏™Á±ªÂà´ÂàÜÈÖç‰∏Ä‰∏™ÂîØ‰∏ÄÁ¥¢ÂºïÔºåÈÄöÂ∏∏‰ªé1ÂºÄÂßã„ÄÇ È¢ÑÁïôÁ¥¢Âºï0Ë°®Á§∫‚ÄúÊú™Áü•‚ÄùÊàñ‚ÄúÁº∫Â§±‚ÄùÔºåÂØπÂ∫îÂÖ®0ÂêëÈáè„ÄÇ ËΩ¨Êç¢‰∏∫One-HotÂêëÈáè\nËã•Á±ªÂà´ÊÄªÊï∞‰∏∫197ÔºåÂàôÁî®197Áª¥ÂêëÈáèË°®Á§∫„ÄÇ ‰æãÂ≠êÔºöÁæéÂõΩ [1, 0, 0, 0, ‚Ä¶]Ôºå ‰∏≠ÂõΩ [0, 1, 0, 0, ‚Ä¶]„ÄÇ Á§∫‰æãÔºöË°®Á§∫‰∏Ä‰∏™‰∫∫ÁöÑÁâπÂæÅ\nÁâπÂæÅÂåÖÂê´ÔºàÂπ¥ÈæÑ, ÊÄßÂà´, ÂõΩÁ±çÔºåÂÖ∂‰∏≠ÂõΩÁ±ç197ÁßçÔºâ Áª¥Â∫¶ÊÄªÂíåÔºö1Áª¥_age + 1Áª¥_gender + 197Áª¥_nationality = 199Áª¥„ÄÇ ‰æãÂ¶Ç (28, Â•≥, ‰∏≠ÂõΩ) ‚Üí [28, 0, 0, 1, 0, ‚Ä¶, 0]„ÄÇ ‰∏â„ÄÅÊñáÊú¨Êï∞ÊçÆÂ§ÑÁêÜÊµÅÁ®ã ÊñáÊú¨Âú®Ëá™ÁÑ∂ËØ≠Ë®ÄÂ§ÑÁêÜÔºàNLPÔºâ‰∏≠‰Ωú‰∏∫Â∏∏ËßÅÁöÑÂéüÂßãËæìÂÖ•ÔºåÈúÄË¶ÅÊï∞ÂÄºÂåñÊâçËÉΩÈÄÅÂÖ•Ê®°Âûã„ÄÇ‰∏ÄËà¨Ê≠•È™§Â¶Ç‰∏ãÔºö\nÂàÜËØç (Tokenization)\nÂ∞ÜÊñáÊú¨ÊãÜÂàÜ‰∏∫‰∏Ä‰∏™‰∏™ÂçïËØçÔºàTokenÔºâ„ÄÇ ‰æãÂ≠êÔºö\u0026quot;... to be or not to be...\u0026quot; ‚Üí [\u0026quot;...\u0026quot;, \u0026quot;to\u0026quot;, \u0026quot;be\u0026quot;, \u0026quot;or\u0026quot;, \u0026quot;not\u0026quot;, \u0026quot;to\u0026quot;, \u0026quot;be\u0026quot;, \u0026quot;...\u0026quot;]„ÄÇ ÁªüËÆ°ËØçÈ¢ë \u0026amp; ÊûÑÂª∫ËØçÂÖ∏\nËØçÈ¢ëÁªüËÆ° Áî®ÂìàÂ∏åË°®/Â≠óÂÖ∏ËÆ∞ÂΩïÊØè‰∏™ÂçïËØçÂá∫Áé∞Ê¨°Êï∞„ÄÇ ÈÅçÂéÜÊñáÊú¨Êó∂ÔºåËã•ÂçïËØçÂ∞öÊú™ÂÖ•Ë°®ÔºåÂàôÊñ∞Âª∫ËÆ∞ÂΩïÔºõËã•Â∑≤Â≠òÂú®ÔºåÂàôËÆ°Êï∞+1„ÄÇ ÊéíÂ∫è‰∏éÁ¥¢Âºï ÊåâËØçÈ¢ëÈôçÂ∫èÊéíÂ∫èÔºåËØçÈ¢ëÊúÄÈ´òÁöÑÂçïËØçÊéíÂú®ÂâçÈù¢„ÄÇ Á¥¢Âºï‰ªé1ÂºÄÂßãÔºå0ÁïôÁªô‚ÄúÊú™Áü•‚Äù„ÄÇ ËØçÂÖ∏ËßÑÊ®°ÔºàvocabularyÔºâÂèØËßÜÈúÄÊ±ÇÊà™Êñ≠Ôºà‰æãÂ¶ÇÂè™‰øùÁïôTop 10kÔºâ„ÄÇ ‰∏∫‰ªÄ‰πàÁßªÈô§‰ΩéÈ¢ëËØç ‰ΩéÈ¢ëËØçÂèØËÉΩÊòØÊãºÂÜôÈîôËØØ„ÄÅÁΩïËßÅ‰∫∫ÂêçÁ≠âÔºåÂØπÊ®°ÂûãÂ∏ÆÂä©ÊúâÈôê„ÄÇ ÂáèÂ∞ëËØçÂÖ∏ËßÑÊ®°ÂèØÈôç‰ΩéËøêÁÆóÂºÄÈîÄ„ÄÅÂä†Âø´Ê®°ÂûãËÆ≠ÁªÉ‰∏éÊé®ÁêÜÈÄüÂ∫¶„ÄÇ Áã¨ÁÉ≠ÁºñÁ†Å (One-Hot Encoding)\nÂ∞ÜÊØè‰∏™ÂçïËØçÊò†Â∞Ñ‰∏∫ËØçÂÖ∏‰∏≠ÁöÑÁ¥¢ÂºïÂêéÔºàÂ¶Ç [2, 4, 1, 8, ‚Ä¶]ÔºâÔºåÂèØËøõ‰∏ÄÊ≠•ËΩ¨Êç¢ÊàêOne-HotÂêëÈáè„ÄÇ One-HotÁª¥Â∫¶ÂèñÂÜ≥‰∫é‰øùÁïô‰∏ãÊù•ÁöÑËØçÂÖ∏Â§ßÂ∞èÔºà‰æãÂ¶Ç1‰∏áÔºâ„ÄÇ Êú™Êî∂ÂΩïÂçïËØçÂèØËÉΩÁõ¥Êé•ÂøΩÁï•ÔºåÊàñÁªü‰∏ÄÁî®Á¥¢Âºï0‰ª£Êõø„ÄÇ Âõõ„ÄÅÊ†∏ÂøÉÊî∂Ëé∑‰∏éÂ∫îÁî® Á±ªÂà´ÁâπÂæÅÂøÖÈúÄÊï∞ÂÄºÂåñÔºö\n‰ΩøÁî®Êï¥Êï∞1,2,3‚Ä¶‰ªÖË°®Á§∫Á±ªÂà´‚ÄúÊ†áËØÜ‚ÄùÔºåÂπ∂‰∏ç‰ª£Ë°®ÂÆÉ‰ª¨ÂèØËøõË°åÊï∞ÂÄºËøêÁÆó„ÄÇ Âõ†Ê≠§ÈúÄË¶ÅOne-HotÁ≠âÁºñÁ†ÅÊñπÂºèÔºåÈÅøÂÖçÊï∞ÂÄºËØØËß£„ÄÇ ÊñáÊú¨Êï∞ÊçÆÈ¢ÑÂ§ÑÁêÜÔºö\nÂàÜËØç„ÄÅËØçÈ¢ëÁªüËÆ°„ÄÅÊûÑÂª∫ËØçÂÖ∏„ÄÅÁ¥¢ÂºïÂåñ„ÄÅOne-HotÊàñÂÖ∂‰ªñÊñπÂºèÔºàÂ¶ÇËØçÂµåÂÖ•ÔºâÊòØÂ∏∏ËßÅÊµÅÁ®ã„ÄÇ Ê≠£Á°ÆÁöÑÊñáÊú¨È¢ÑÂ§ÑÁêÜÂèØÊòæËëóÂΩ±ÂìçÊ®°ÂûãÊÄßËÉΩÂíåÊïàÁéá„ÄÇ ‰øùÁïôÊú™Áü•Á¥¢ÂºïÔºö\n‰øùËØÅÂØπÁº∫Â§±Êï∞ÊçÆÊàñÂ≠óÂÖ∏Â§ñÊñ∞ËØçËÉΩÊúâÂü∫Êú¨ÁöÑË°®Á§∫ÔºåÊèêÂçáÊ®°ÂûãÂÆπÈîôÊÄß„ÄÇ ÂÆûÈôÖ‰ΩøÁî®Ôºö\nÂØπ‰∫éÂ∞èËßÑÊ®°Á±ªÂà´ÂèØÁõ¥Êé•One-HotÁºñÁ†ÅÔºõÂØπ‰∫éËØçÂÖ∏ÂæàÂ§ßÁöÑÂú∫ÊôØÔºåÈÄöÂ∏∏‰ºöËøõ‰∏ÄÊ≠•ËÄÉËôëËØçÂµåÂÖ•ÔºàWord EmbeddingÔºâÊàñÈ¢ÑËÆ≠ÁªÉËØ≠Ë®ÄÊ®°Âûã„ÄÇ ","permalink":"http://localhost:1313/posts/nlp-1/","summary":"\u003ch2 id=\"‰∏ÄÊï∞ÂÄºÁâπÂæÅ‰∏éÁ±ªÂà´ÁâπÂæÅ\"\u003e‰∏Ä„ÄÅÊï∞ÂÄºÁâπÂæÅ‰∏éÁ±ªÂà´ÁâπÂæÅ\u003c/h2\u003e\n\u003col\u003e\n\u003cli\u003e\u003cstrong\u003eÊï∞ÂÄºÁâπÂæÅ (Numeric Features)\u003c/strong\u003e\n\u003cul\u003e\n\u003cli\u003eÂÖ∑ÊúâÂèØÂä†ÂáèÁöÑÊÑè‰πâÔºå‰∏îÂ≠òÂú®Â§ßÂ∞èÈ°∫Â∫è„ÄÇ\u003c/li\u003e\n\u003cli\u003e‰æãÂ≠êÔºöÂπ¥ÈæÑ„ÄÅÊ∏©Â∫¶Á≠â„ÄÇÂèØ‰ª•Áõ¥Êé•‰øùÁïôÂÖ∂Êï¥Êï∞ÊàñÊµÆÁÇπÊï∞ÂΩ¢Âºè‰æõÊ®°Âûã‰ΩøÁî®„ÄÇ\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003eÁ±ªÂà´ÁâπÂæÅ (Categorical Features)\u003c/strong\u003e\n\u003cul\u003e\n\u003cli\u003eÊï∞ÊçÆÂÄºÁ¶ªÊï£Ôºå‰∏çÂÖ∑Â§á‚ÄúÊï∞ÂÄºÂ§ßÂ∞è‚ÄùÈó¥ÁöÑÂèØÊØîÊÑè‰πâ„ÄÇ\u003c/li\u003e\n\u003cli\u003e‰æãÂ≠êÔºöÂõΩÁ±çÔºàÁæéÂõΩ/‰∏≠ÂõΩ/Âç∞Â∫¶Á≠âÔºâ„ÄÅÊÄßÂà´ÔºàÁî∑/Â•≥ÔºâÁ≠â„ÄÇ\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003eÈóÆÈ¢ò\u003c/strong\u003eÔºöËã•‰ªÖÁî®Êï¥Êï∞Ë°®Á§∫ÔºàÁæéÂõΩ=1, ‰∏≠ÂõΩ=2ÔºâÔºå‰ºöÂºïÂÖ•ÈîôËØØÁöÑÊï∞ÂÄºËøêÁÆóÂÖ≥Á≥ªÔºåÂ¶Ç ‚ÄúÁæéÂõΩ + ‰∏≠ÂõΩ = Âç∞Â∫¶‚Äù„ÄÇ\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003c/ol\u003e\n\u003ch2 id=\"‰∫åone-hotÁºñÁ†ÅÁöÑÂä®Êú∫‰∏éÊµÅÁ®ã\"\u003e‰∫å„ÄÅOne-HotÁºñÁ†ÅÁöÑÂä®Êú∫‰∏éÊµÅÁ®ã\u003c/h2\u003e\n\u003col\u003e\n\u003cli\u003e\n\u003cp\u003e\u003cstrong\u003e‰∏∫‰ªÄ‰πà‰ΩøÁî®One-Hot\u003c/strong\u003e\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eÈÄöËøáÂ∞ÜÁ±ªÂà´Êò†Â∞Ñ‰∏∫ÂêëÈáèÔºåÈÅøÂÖçÊï¥Êï∞ÁºñÁ†ÅÂºïÂÖ•ÁöÑ‰º™Êï∞ÂÄºÂÖ≥Á≥ª„ÄÇ\u003c/li\u003e\n\u003cli\u003eÂêåÊó∂‰øùÁïôÂêÑÁßçÂèØËÉΩÁ±ªÂà´ÁöÑ‰ø°ÊÅØÔºå‰∏î‰ªÖÂú®ÂØπÂ∫î‰ΩçÁΩÆ‰∏∫1ÔºåÂÖ∂‰ªñ‰ΩçÁΩÆ‰∏∫0„ÄÇ\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003e\u003cstrong\u003eÂª∫Á´ãÊò†Â∞ÑÔºö‰ªéÁ±ªÂà´Âà∞Á¥¢Âºï\u003c/strong\u003e\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e‰∏∫ÊØè‰∏™Á±ªÂà´ÂàÜÈÖç‰∏Ä‰∏™ÂîØ‰∏ÄÁ¥¢ÂºïÔºåÈÄöÂ∏∏‰ªé1ÂºÄÂßã„ÄÇ\u003c/li\u003e\n\u003cli\u003eÈ¢ÑÁïôÁ¥¢Âºï0Ë°®Á§∫‚ÄúÊú™Áü•‚ÄùÊàñ‚ÄúÁº∫Â§±‚ÄùÔºåÂØπÂ∫îÂÖ®0ÂêëÈáè„ÄÇ\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003e\u003cstrong\u003eËΩ¨Êç¢‰∏∫One-HotÂêëÈáè\u003c/strong\u003e\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eËã•Á±ªÂà´ÊÄªÊï∞‰∏∫197ÔºåÂàôÁî®197Áª¥ÂêëÈáèË°®Á§∫„ÄÇ\u003c/li\u003e\n\u003cli\u003e‰æãÂ≠êÔºöÁæéÂõΩ \u003ccode\u003e[1, 0, 0, 0, ‚Ä¶]\u003c/code\u003eÔºå ‰∏≠ÂõΩ \u003ccode\u003e[0, 1, 0, 0, ‚Ä¶]\u003c/code\u003e„ÄÇ\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003e\u003cstrong\u003eÁ§∫‰æãÔºöË°®Á§∫‰∏Ä‰∏™‰∫∫ÁöÑÁâπÂæÅ\u003c/strong\u003e\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eÁâπÂæÅÂåÖÂê´ÔºàÂπ¥ÈæÑ, ÊÄßÂà´, ÂõΩÁ±çÔºåÂÖ∂‰∏≠ÂõΩÁ±ç197ÁßçÔºâ\u003c/li\u003e\n\u003cli\u003eÁª¥Â∫¶ÊÄªÂíåÔºö1Áª¥_age + 1Áª¥_gender + 197Áª¥_nationality = 199Áª¥„ÄÇ\u003c/li\u003e\n\u003cli\u003e‰æãÂ¶Ç \u003ccode\u003e(28, Â•≥, ‰∏≠ÂõΩ)\u003c/code\u003e ‚Üí \u003ccode\u003e[28, 0, 0, 1, 0, ‚Ä¶, 0]\u003c/code\u003e„ÄÇ\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003c/ol\u003e\n\u003ch2 id=\"‰∏âÊñáÊú¨Êï∞ÊçÆÂ§ÑÁêÜÊµÅÁ®ã\"\u003e‰∏â„ÄÅÊñáÊú¨Êï∞ÊçÆÂ§ÑÁêÜÊµÅÁ®ã\u003c/h2\u003e\n\u003cp\u003eÊñáÊú¨Âú®Ëá™ÁÑ∂ËØ≠Ë®ÄÂ§ÑÁêÜÔºàNLPÔºâ‰∏≠‰Ωú‰∏∫Â∏∏ËßÅÁöÑÂéüÂßãËæìÂÖ•ÔºåÈúÄË¶ÅÊï∞ÂÄºÂåñÊâçËÉΩÈÄÅÂÖ•Ê®°Âûã„ÄÇ‰∏ÄËà¨Ê≠•È™§Â¶Ç‰∏ãÔºö\u003c/p\u003e\n\u003col\u003e\n\u003cli\u003e\n\u003cp\u003e\u003cstrong\u003eÂàÜËØç (Tokenization)\u003c/strong\u003e\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eÂ∞ÜÊñáÊú¨ÊãÜÂàÜ‰∏∫‰∏Ä‰∏™‰∏™ÂçïËØçÔºàTokenÔºâ„ÄÇ\u003c/li\u003e\n\u003cli\u003e‰æãÂ≠êÔºö\u003ccode\u003e\u0026quot;... to be or not to be...\u0026quot;\u003c/code\u003e ‚Üí \u003ccode\u003e[\u0026quot;...\u0026quot;, \u0026quot;to\u0026quot;, \u0026quot;be\u0026quot;, \u0026quot;or\u0026quot;, \u0026quot;not\u0026quot;, \u0026quot;to\u0026quot;, \u0026quot;be\u0026quot;, \u0026quot;...\u0026quot;]\u003c/code\u003e„ÄÇ\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003e\u003cstrong\u003eÁªüËÆ°ËØçÈ¢ë \u0026amp; ÊûÑÂª∫ËØçÂÖ∏\u003c/strong\u003e\u003c/p\u003e","title":""},{"content":"Text to Sequence ÊñáÊú¨Â§ÑÁêÜ\nStep1: Tokenization\nTokenization breaks a piece of text down into a list of tokens.\nHere, a token is a word. (A token can be a character in some applications.)\nTokenizationËÆ≤Á©∂ÂæàÂ§öÔºå‰æãÂ¶ÇÊòØÂê¶Â∫îËØ•ÊääÂ§ßÂÜôÊîπÊàêÂ∞èÂÜôÂë¢ÔºüËøõË°åtypo correctionÁ≠âÁ≠â\nStep2: Build Dictionary\nUse a dictionary (hash table) to count word frequencies.\nThe dictionary maps word to index.\nÂèØ‰ª•È¶ñÂÖàÁªüËÆ°ËØçÈ¢ëÂéªÊéâ‰ΩéÈ¢ëËØçÔºåÁÑ∂ÂêéËÆ©ÊØè‰∏™ËØçÂØπÂ∫î‰∏Ä‰∏™Ê≠£Êï¥Êï∞ÔºõËøôÊ†∑ÁöÑËØùÔºå‰∏ÄÂè•ËØùÂ∞±ÂèØ‰ª•Áî®‰∏Ä‰∏™Ê≠£Êï¥Êï∞ÂàóË°®Ë°®Á§∫ÔºåËøô‰∏™ÂàóË°®Â∞±Âè´sequenceÔºõÂ¶ÇÊûúÂøÖË¶ÅÂ∞±ËøòÂæóÂÅöone-hot encoding„ÄÇ\nÁªìÊûú\n‰ΩÜÊòØÈïøÂ∫¶‰∏çÁªü‰∏Ä\nStep4: ÂØπÈΩêsequence\nËß£ÂÜ≥ÊñπÊ°àÊòØËøôÊ†∑ÁöÑÔºöÂèØ‰ª•Âõ∫ÂÆöÈïøÂ∫¶‰∏∫wÔºåÂä†ÂÖ•‰∏Ä‰∏™Â∫èÂàóÈïøÂ∫¶Â§™ÈïøÔºåÂ∞±Á†çÊéâÂâçÈù¢ÁöÑËØçÔºåÂè™‰øùÁïôÊúÄÂêéw‰∏™ËØçÔºõÂ¶ÇÊûú‰∏Ä‰∏™Â∫èÂàóÂ§™Áü≠ÔºåÂ∞±ÂÅözero paddingÔºåÁî®0Â°´ÂÖÖ\nËøôÊ†∑‰∏ÄÊù•ÔºåÊâÄÊúâÁöÑÂ∫èÂàóÈïøÂ∫¶Â∞±Áªü‰∏Ä‰∫Ü\nÊñáÊú¨Â§ÑÁêÜÂÆåÊàê‰∫ÜÔºåÊé•‰∏ãÊù•ÊòØword embeddingÔºåÊääÂçïËØçË°®Á§∫‰∏∫‰∏Ä‰∏™‰ΩéÁª¥ÂêëÈáèÔºõ\nÁÑ∂ËÄåËøôÊ†∑ÂÅöÁöÑËØùÔºåÂ¶ÇÊûúÊòØ10000‰∏™ÂçïËØçÔºåÁª¥Â∫¶Â∞±ÊòØ10000Áª¥ÔºåÁª¥Â∫¶Â§™È´ò‰∫ÜÔºõÂõ†Ê≠§Ë¶ÅÂÅöword embeddingÔºõ\nÂÖ∑‰ΩìÂÅöÊ≥ïÂ∞±ÊòØÊääone-hotÂêëÈáèe_iÂíåÂèÇÊï∞Áü©ÈòµpÁõ∏‰πòÔºõÁü©ÈòµPËΩ¨ÁΩÆÁöÑÂ§ßÂ∞èÊòØd x vÔºõdÊòØËØçÂêëÈáèÁöÑÁª¥Â∫¶ÔºõvÊòØÂ≠óÂÖ∏ÈáåËØçÊ±áÁöÑÊï∞ÈáèÔºõÁªìÊûú‰∏∫x_iÔºõx_iÂ∞±ÊòØ‰∏Ä‰∏™ËØçÂêëÈáèÔºõÂ¶ÇÊûúone-hotÂêëÈáèÁöÑÁ¨¨‰∏âË°å‰∏∫1ÔºõÈÇ£‰πàx_iÂ∞±ÊòØPËΩ¨ÁΩÆÁü©ÈòµÁöÑÁ¨¨‰∏âÂàóÔºàÂÖ∂‰ΩôÂàóÈÉΩ‰∏∫0ÔºâÔºõÊâÄ‰ª•PËΩ¨ÁΩÆÊØè‰∏ÄÂàóÈÉΩÊòØ‰∏Ä‰∏™ËØçÂêëÈáèÔºõÊâÄ‰ª•Áü©ÈòµPÊú¨Ë∫´ÁöÑÊØè‰∏ÄË°åÂ∞±ÊòØ‰∏Ä‰∏™ËØçÂêëÈáèÔºõÂÖ∂Ë°åÊï∞‰∏∫vÔºõÂç≥vocabularyÔºåËØçÊ±áÈáèÔºõÊØè‰∏ÄË°åÂØπÂ∫î‰∏Ä‰∏™ÂçïËØçÔºõÁü©ÈòµÁöÑÂàóÊï∞‰∏∫dÔºõdÊòØÁî®Êà∑ÂÜ≥ÂÆöÁöÑÔºõdÁöÑÂ§ßÂ∞è‰ºöÂÜ≥ÂÆöÊú∫Âô®Â≠¶‰π†Ê®°ÂûãÁöÑË°®Áé∞ÔºõÂ∫îËØ•Áî®xxxÊù•ÈÄâÊã©‰∏Ä‰∏™ÊØîËæÉÂ•ΩÁöÑdÔºõ\nÊàë‰ª¨ÁöÑ‰ªªÂä°ÊòØÁúãËØÑËÆ∫ÊòØÊ≠£Èù¢ÁöÑËøòÊòØË¥üÈù¢ÁöÑÔºõÂèÇÊï∞Áü©ÈòµÊòØ‰ªéËÆ≠ÁªÉÊï∞ÊçÆ‰∏≠Â≠¶‰π†Âá∫Êù•ÁöÑÔºåÊâÄ‰ª•Â≠¶Âá∫Êù•ÁöÑËØçÂêëÈáèÊòØÂ∏¶ÊúâÊÑüÊÉÖËâ≤ÂΩ©ÁöÑÔºõÂÅáËÆæËøô‰∫õËØçÂêëÈáèÈÉΩÊòØ‰∫åÁª¥ÁöÑÔºåÂàôÂèØ‰ª•Âú®Âπ≥Èù¢ÂùêÊ†áÁ≥ª‰∏≠Ê†áÂá∫‰∏ãÈù¢ËØçÂêëÈáè\nkerasÊèê‰æõembeddingÂ±ÇÔºõÁî®Êà∑ÂèØ‰ª•ÊåáÂÆövocabularyÂ§ßÂ∞èÂíådÁöÑÂ§ßÂ∞èÔºõ‰ª•ÂèäÊØè‰∏Ä‰∏™sequenceÁöÑÈïøÂ∫¶ÔºõdÊòØÊ†πÊçÆÁÆóÊ≥ïÈÄâÂá∫Êù•ÁöÑ Âà∞Ëøô‰∏ÄÊ≠•ÔºåÊàë‰ª¨Â∑≤ÁªèÂÆåÊàê‰∫ÜÊñáÊú¨Â§ÑÁêÜÂíåword embedding„ÄÇÊé•‰∏ãÊù•Â∞±ÊòØÁî®Logistic Regression for Binary ClassificationÂÅö‰∫åÂàÜÁ±ªÔºõ\n","permalink":"http://localhost:1313/posts/nlp-2/","summary":"\u003ch3 id=\"text-to-sequence\"\u003eText to Sequence\u003c/h3\u003e\n\u003cp\u003eÊñáÊú¨Â§ÑÁêÜ\u003c/p\u003e\n\u003cp\u003eStep1: Tokenization\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\n\u003cp\u003eTokenization breaks a piece of text down into a list of tokens.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003eHere, a token is a word. (A token can be a character in some applications.)\u003c/p\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003eTokenizationËÆ≤Á©∂ÂæàÂ§öÔºå‰æãÂ¶ÇÊòØÂê¶Â∫îËØ•ÊääÂ§ßÂÜôÊîπÊàêÂ∞èÂÜôÂë¢ÔºüËøõË°åtypo correctionÁ≠âÁ≠â\u003c/p\u003e\n\u003cp\u003e\u003cimg alt=\"image-20250322150322238\" loading=\"lazy\" src=\"./NLP-2.assets/image-20250322150322238.png\"\u003e\u003c/p\u003e\n\u003cp\u003eStep2: Build Dictionary\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\n\u003cp\u003eUse a dictionary (hash table) to count word frequencies.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003eThe dictionary maps word to index.\u003c/p\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003eÂèØ‰ª•È¶ñÂÖàÁªüËÆ°ËØçÈ¢ëÂéªÊéâ‰ΩéÈ¢ëËØçÔºåÁÑ∂ÂêéËÆ©ÊØè‰∏™ËØçÂØπÂ∫î‰∏Ä‰∏™Ê≠£Êï¥Êï∞ÔºõËøôÊ†∑ÁöÑËØùÔºå‰∏ÄÂè•ËØùÂ∞±ÂèØ‰ª•Áî®‰∏Ä‰∏™Ê≠£Êï¥Êï∞ÂàóË°®Ë°®Á§∫ÔºåËøô‰∏™ÂàóË°®Â∞±Âè´sequenceÔºõÂ¶ÇÊûúÂøÖË¶ÅÂ∞±ËøòÂæóÂÅöone-hot encoding„ÄÇ\u003cimg alt=\"image-20250322150620890\" loading=\"lazy\" src=\"./NLP-2.assets/image-20250322150620890.png\"\u003e\u003c/p\u003e\n\u003cp\u003eÁªìÊûú\u003c/p\u003e\n\u003cp\u003e\u003cimg alt=\"image-20250322150754528\" loading=\"lazy\" src=\"./NLP-2.assets/image-20250322150754528.png\"\u003e\u003c/p\u003e\n\u003cp\u003e‰ΩÜÊòØÈïøÂ∫¶‰∏çÁªü‰∏Ä\u003c/p\u003e\n\u003cp\u003eStep4: ÂØπÈΩêsequence\u003c/p\u003e\n\u003cp\u003e\u003cimg alt=\"image-20250322150854986\" loading=\"lazy\" src=\"./NLP-2.assets/image-20250322150854986.png\"\u003e\u003c/p\u003e\n\u003cp\u003eËß£ÂÜ≥ÊñπÊ°àÊòØËøôÊ†∑ÁöÑÔºöÂèØ‰ª•Âõ∫ÂÆöÈïøÂ∫¶‰∏∫wÔºåÂä†ÂÖ•‰∏Ä‰∏™Â∫èÂàóÈïøÂ∫¶Â§™ÈïøÔºåÂ∞±Á†çÊéâÂâçÈù¢ÁöÑËØçÔºåÂè™‰øùÁïôÊúÄÂêéw‰∏™ËØçÔºõÂ¶ÇÊûú‰∏Ä‰∏™Â∫èÂàóÂ§™Áü≠ÔºåÂ∞±ÂÅözero paddingÔºåÁî®0Â°´ÂÖÖ\u003c/p\u003e\n\u003cp\u003e\u003cimg alt=\"image-20250322151030119\" loading=\"lazy\" src=\"./NLP-2.assets/image-20250322151030119.png\"\u003e\u003c/p\u003e\n\u003cp\u003eËøôÊ†∑‰∏ÄÊù•ÔºåÊâÄÊúâÁöÑÂ∫èÂàóÈïøÂ∫¶Â∞±Áªü‰∏Ä‰∫Ü\u003c/p\u003e\n\u003cp\u003e\u003cimg alt=\"image-20250322151117125\" loading=\"lazy\" src=\"./NLP-2.assets/image-20250322151117125.png\"\u003e\u003c/p\u003e\n\u003cp\u003eÊñáÊú¨Â§ÑÁêÜÂÆåÊàê‰∫ÜÔºåÊé•‰∏ãÊù•ÊòØword embeddingÔºåÊääÂçïËØçË°®Á§∫‰∏∫‰∏Ä‰∏™‰ΩéÁª¥ÂêëÈáèÔºõ\u003c/p\u003e\n\u003cp\u003e\u003cimg alt=\"image-20250322151252837\" loading=\"lazy\" src=\"./NLP-2.assets/image-20250322151252837.png\"\u003e\u003c/p\u003e","title":""},{"content":"üëã About me Hello! I\u0026rsquo;m Xu Zongsi, a passionate technology enthusiast currently pursuing my Master of Science in ECIC at The University of Hong Kong. With a solid background in Software Engineering from the Beijing Institute of Technology, I specialize in artificial intelligence areas like machine learning, deep learning, natural language processing, computer vision, and reinforcement learning.\nInspired by OpenAI\u0026rsquo;s five-step plan towards superintelligence, I am excited about AGI and have developed a keen interest in LLM agents, MLLM, and knowledge graphs. I see great potential in these fields and aspire to contribute to innovative solutions.\nüìö Education üá≠üá∞ The University of Hong Kong 09/2024 - Expected 11/2025 School of Computing and Data Science Master of Science in Electronic Commerce \u0026amp; Internet Computing Relevant Courses: Machine learning for business and e-commerce, Knowledge graphs, Financial fraud analytics, Internet infrastructure technologies, Website engineering, Blockchain and cryptocurrency, etc. üá®üá≥ Beijing Institute of Technology 09/2020 - 06/2024 School of Computer Science \u0026amp; Technology Bachelor of Engineering in Software Engineering, last two years GPA: 3.7/4 Relevant Courses: Reinforcement Learning, Deep Learning and Computer Vision, Artificial Intelligence and Robot Ethics, Almost Human: Mind, Brain and Artificial Intelligence, Mathematical Analysis for Engineering, Linear Algebra, Probability and Mathematical Statistics, etc. Skills: Python, Java, common data structures, design patterns, machine learning basics and algorithms, Linux, PyTorch, and some development tools (git, conda, etc.). üèÜ Awards \u0026amp; Honors Beijing Institute of Technology Undergraduate Scholarship (Top 20% of Grade) 06/2023 3rd Prize of China International \u0026#34;Internet \u0026#43;\u0026#34; College Student\u0026#39;s Innovation Competition 08/2022 Bronze Prize of \u0026#34;Challenge Cup\u0026#34; Capital University Entrepreneurship Competition 05/2022 üíº Project Experience üîç Online Transaction Fraud Detection 09/2024 ‚Äì 01/2025 Independent project, supervised by Dr. Vivien Chan Focused on addressing financial fraud in e-commerce to enhance the accuracy of transaction anomaly detection, while independently managing the entire case study that included data preprocessing, feature engineering, model building, evaluation, and results analysis. Effectively resolved class imbalance issues using SMOTE and ROSE techniques. Built various models including Logistic Regression, Random Forest, XGBoost, and LightGBM, ultimately selecting the LightGBM model to achieve a recall rate of 95.45% and an AUC of 99.84%. Wrote efficient and maintainable code, enhancing model training and data processing efficiency through parallel computing and logging. ü§ñ Multi-Model Intelligent Text Keyword Extraction System 08/2023 ‚Äì 09/2023 Group project, supervised by Associate Prof. Xiaolin Zhao Designed and implemented an intelligent text summary system that automatically extracts keywords from article titles and abstracts, enhancing the understanding and summarization of text information. Participated in the planning of the technical route and built a hybrid model combining extractive and generative approaches, utilizing advanced natural language processing techniques including KeyBERT, Sentence Transformer, BERT, and T5 models. Responsible for data preprocessing and tokenization, as well as the end-to-end implementation and training of the T5 model, optimizing the model architecture and hyperparameters, achieving satisfactory results after only 3 epochs of training. Model evaluation results showed that the Rouge-1, Rouge-2, and Rouge-L metrics reached 0.6345, 0.5038, and 0.5282, respectively, in the third epoch, validating the model\u0026rsquo;s effectiveness in the summarization task. üéì Cambridge University Machine Learning Summer Project 07/2023 ‚Äì 08/2023 Group project, supervised by Prof. Pietro Li√≤ Participated in the Cambridge University deep learning summer project, focusing on deep reinforcement learning; explored multi-agent learning algorithms across different environments. Reproduced the Multi-Agent Deep Deterministic Policy Gradient (MADDPG) algorithm in the Simple Adversary environment and studied the effect of agent numbers on convergence speed and stability, finding optimal stability at 21 agents. Designed and implemented comparative experiments inspired by the Rainbow algorithm, assessing target network strategies versus the Double Deep Q-Network (Double DQN). The results demonstrated that Double DQN significantly enhanced convergence speed, optimizing the overall learning process. Co-authored a group project paper on agent numbers and strategies effectiveness in multi-agent systems, achieving a score of 71% in the summer program (the highest in my group) and a \u0026ldquo;First Class\u0026rdquo; classification in the UK grading system. üëÅÔ∏è Deep Learning and Computer Vision Semester Project 09/2022 ‚Äì 12/2022 Independent project, supervised by Associate Prof. Guangyu Gao Designed and implemented a waste classifier using the ResNet model to improve classification accuracy and reduce resource waste. The project also enhanced understanding of transfer learning techniques with ResNet. Collected a dataset of 16 waste categories and preprocessed the images for uniformity and standardization, incorporating data augmentation techniques to enhance the dataset. Conducted experiments using ResNet34 and ResNet50 models through transfer learning, accelerating network convergence by leveraging pretrained weights. During training, techniques such as Batch Normalization and Dropout were applied to mitigate the risk of overfitting. The final model achieved an accuracy of 90% on the training set, while the performance on the test set was 61%, indicating a significant overfitting phenomenon during the training process. üéì Internship ‚öõÔ∏è Beijing Academy of Quantum Information Science 08/2023 ‚Äì 01/2024 Research Intern at Quantum Computation Department Proposed a quantum convolution kernel design based on variational quantum circuits and developed a universal quantum convolution layer, successfully integrating it into classical CNN architectures such as VGG, GoogLeNet, and ResNet. Developed and evaluated various hybrid models, including a simple model named HQCCNN-2, which achieved 84.45% accuracy on the FashionMNIST dataset, surpassing the traditional CNN\u0026rsquo;s 80.72%. This demonstrates the effectiveness of the quantum convolution layer in improving model performance. Tested on a real quantum computer further validated the effectiveness of the hybrid model, demonstrating the viable integration of quantum computing with deep learning, and highlighting the potential for leveraging quantum properties to enhance model performance. üèÖ Competition Experience ü•â China International \u0026#34;Internet \u0026#43;\u0026#34; College Students\u0026#39; Innovation Competition 08/2022 üõ°Ô∏è Zhongke Ushield: Deep Learning-based Face Privacy Protection Authentication System Responsible for constructing a localized facial feature extraction engine based on MobileFaceNet, ensuring feature extraction is completed on end devices (such as mobile phones and cameras), guaranteeing that raw data does not leave the domain and is not stored, thus enhancing user privacy protection while improving recognition efficiency. ü•â \u0026#34;Challenge Cup\u0026#34; Capital University Entrepreneurship Competition 05/2022 üå≥ Smart Orchard Responsible for the development of the fruit detection, ripeness prediction, and pest identification system, using deep convolutional neural network (CNN) technology for intelligent monitoring of crop growth conditions. Applied advanced object detection algorithms such as Faster R-CNN and YOLO to achieve high precision in apple detection and ripeness assessment, with an accuracy rate exceeding 90%, significantly enhancing the intelligence level of orchard management. Built and trained a dedicated dataset containing various pest samples, optimizing pest detection accuracy through data preprocessing (such as image normalization and resizing) and data augmentation techniques (like rotation, flipping, and noise addition), enabling the real-time monitoring system to accurately identify over 80% of pests, providing effective scientific maintenance recommendations to help farmers reduce crop losses. üìã Extracurricular Activities Vice President, Cyber Security Club, Beijing Institute of Technology 09/2021-09/2022 Backbone, Media Center of the Student Union of Beijing Institute of Technology 10/2020-06/2021 üì´ Contact üìß Email: zongsi.xu@outlook.com üëî LinkedIn: Zongsi (Tristan) Xu üíª GitHub: BaizeXS üìç Location: Hong Kong SAR, China ","permalink":"http://localhost:1313/resume/","summary":"Personal resume of Zongsi (Tristan) Xu","title":"Zongsi (Tristan) Xu"}]